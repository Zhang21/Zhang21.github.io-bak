[{"categories":["english","英语","读书笔记"],"content":"韦小绿 Merriam-Webster’s Vocabulary Builder ","date":"2023-02-13","objectID":"/mw-vocabulary-builder/:0:0","tags":["english","vocabulary"],"title":"韦小绿笔记","uri":"/mw-vocabulary-builder/"},{"categories":["database"],"content":"Doris相关知识","date":"2022-09-20","objectID":"/doris/","tags":["database","doris"],"title":"Doris","uri":"/doris/"},{"categories":["database"],"content":"参考: Doris文档 Dorish官方仓库 \r \r介绍 Apache Doris能够较好的满足报表分析、即席查询、统一数仓构建、数据湖联邦查询加速等使用场景，用户可以在此之上构建用户行为分析、AB 实验平台、日志检索分析、用户画像分析、订单分析等应用。 \r","date":"2022-09-20","objectID":"/doris/:0:0","tags":["database","doris"],"title":"Doris","uri":"/doris/"},{"categories":["database"],"content":"使用场景 如下图所示，数据源经过各种数据集成和加工处理后，通常会入库到实时数仓 Doris 和离线湖仓，Apache Doris 被广泛应用在以下场景中。 \r 报表分析 实时看板 面向企业内部的报表 面向客户的报表分析 即席查询：面向分析师的自助分析 统一数仓构建：一个平台满足统一的数仓（如Spark、Hive、Kudu、Hbase等组成的旧架构）建设需求，简化繁琐的大数据软件栈 数据湖联邦查询 \r\r","date":"2022-09-20","objectID":"/doris/:1:0","tags":["database","doris"],"title":"Doris","uri":"/doris/"},{"categories":["database"],"content":"技术概述 架构： Frontend(FE)：主要负责用户请求的接入、查询解析规划、元数据的管理、节点管理等工作。 Backend(BE)：主要负责数据存储、查询计划的执行。 两类进程都可横向扩展，通过一致性协议来保证服务的高可用和数据的高可靠。 \r在使用接口方面，Doris 采用 MySQL 协议，高度兼容 MySQL 语法，支持标准 SQL，用户可以通过各类客户端工具来访问 Doris，并支持与BI工具的无缝对接。 在存储引擎方面，Doris 采用列式存储，按列进行数据的编码压缩和读取，能够实现极高的压缩比，同时减少大量非相关数据的扫描，从而更加有效利用 IO 和 CPU 资源。 在查询引擎方面，Doris 采用 MPP 的模型，节点间和节点内都并行执行，也支持多个大表的分布式 Shuffle Join，从而能够更好应对复杂查询。 Doris 查询引擎是向量化的查询引擎，所有的内存结构能够按照列式布局，能够达到大幅减少虚函数调用、提升 Cache 命中率，高效利用 SIMD 指令的效果。 \r \r快速开始 注意Doris需要的系统、软件、硬件、内核参数、限制等要求。 \r","date":"2022-09-20","objectID":"/doris/:2:0","tags":["database","doris"],"title":"Doris","uri":"/doris/"},{"categories":["database"],"content":"下载 # 在此页面下载doris相关软件包 https://doris.apache.org/zh-CN/download/ # 解压 tar -zxf apache-doris-版本.tar.gz mv apache-doris-版本 /opt \r\r","date":"2022-09-20","objectID":"/doris/:3:0","tags":["database","doris"],"title":"Doris","uri":"/doris/"},{"categories":["database"],"content":"配置 配置和启动FE。 cd /opt/apache-doris-版本/fe # 修改配置 conf/fe.conf # 主要修改两个参数 # priority_networks=172.23.16.0/24 # meta_dir=/data/doris/doris-meta # 启动 /opt/apache-doris-版本/bin/start_fe.sh --daemon # 停止 /opt/apache-doris-版本/bin/stop_fe.sh # 查看状态 # 或者直接访问界面也可以（默认用户root，密码为空） curl http://127.0.0.1:8030/api/bootstrap # 连接 mysql -uroot -P9030 -h127.0.0.1 # 查看运行状态 mysql\u003e show frontends\\G \r配置和启动BE。 cd /opt/apache-doris-版本/be # 修改配置 conf/be.conf # 主要修改两个参数 # priority_networks=172.23.16.0/24 # storage_root=/data/doris/doris_be # 启动 /opt/apache-doris-版本/bin/start_be.sh --daemon # 停止 /opt/apache-doris-版本/bin/stop_be.sh # 首先连接到fe mysql -hxxx -Pxxx -uroot # 添加BE节点到集群 mysql\u003e ALTER SYSTEM ADD BACKEND \"be_host_ip:heartbeat_service_port\"; # 查看状态 mysql\u003e HOW BACKENDS\\G; \r\r","date":"2022-09-20","objectID":"/doris/:4:0","tags":["database","doris"],"title":"Doris","uri":"/doris/"},{"categories":["database"],"content":"创建数据库 #创建库createdatabasedemo;#创建表usedemo;CREATETABLEIFNOTEXISTSdemo.example_tbl(`user_id`LARGEINTNOTNULLCOMMENT\"用户id\",`date`DATENOTNULLCOMMENT\"数据灌入日期时间\",`city`VARCHAR(20)COMMENT\"用户所在城市\",`age`SMALLINTCOMMENT\"用户年龄\",`sex`TINYINTCOMMENT\"用户性别\",`last_visit_date`DATETIMEREPLACEDEFAULT\"1970-01-01 00:00:00\"COMMENT\"用户最后一次访问时间\",`cost`BIGINTSUMDEFAULT\"0\"COMMENT\"用户总消费\",`max_dwell_time`INTMAXDEFAULT\"0\"COMMENT\"用户最大停留时间\",`min_dwell_time`INTMINDEFAULT\"99999\"COMMENT\"用户最小停留时间\")AGGREGATEKEY(`user_id`,`date`,`city`,`age`,`sex`)DISTRIBUTEDBYHASH(`user_id`)BUCKETS1PROPERTIES(\"replication_allocation\"=\"tag.location.default: 1\"); 将一个示例csv文件数据导入： curl --location-trusted -u root: -T test.csv -H \"column_separator:,\" http://127.0.0.1:8030/api/demo/example_tbl/_stream_load \r\r","date":"2022-09-20","objectID":"/doris/:5:0","tags":["database","doris"],"title":"Doris","uri":"/doris/"},{"categories":["database"],"content":"查询数据 mysql -hxxx -Pxxx -uroot mysql\u003e use demo; mysql\u003e select * from example_tbl; mysql\u003e select * from example_tbl where city=\"上海\"; \r \r安装和部署 \r","date":"2022-09-20","objectID":"/doris/:6:0","tags":["database","doris"],"title":"Doris","uri":"/doris/"},{"categories":["database"],"content":"要求 安装之前的一些要求： CentOS 7.1+ Ubuntu 16.04+ Java 1.8+ GCC 4.8.2+ 时钟同步 limits修改 关闭swap 推荐使用ext4文件系统 推荐使用SSD FE主要用于存储元数据，包括日志和image。 BE主要用于存放用户数据，总磁盘空间按用户总数据量乘以3(3副本)，然后再预留40%的空间用作其它数据的存放。 8c8g以上配置 # 设置系统最大打开文件句柄数 vi /etc/security/limits.conf * soft nofile 65536 * hard nofile 65536 \r\r","date":"2022-09-20","objectID":"/doris/:7:0","tags":["database","doris"],"title":"Doris","uri":"/doris/"},{"categories":["database"],"content":"节点数量 FE角色分为Follower和Observer（Leader为Follower组中选举出，也称为Follower）。 FE 节点数据至少为1（1 个 Follower）。当部署 1个Follower 和 1 个 Observer 时，可以实现读高可用。当部署 3 个 Follower 时，可以实现读写高可用（HA）。 Follower 的数量必须为奇数，Observer 数量随意。 当集群可用性要求很高时（比如提供在线业务），可以部署3个 Follower 和 1-3 个 Observer。如果是离线业务，建议部署 1 个 Follower 和 1-3 个 Observer。 如果 FE 和 BE 混部，需注意资源竞争问题，并保证元数据目录和数据目录分属不同磁盘。 一般情况3个机器FE/BE复用应该就满足最基本的高可用了。 \r\r","date":"2022-09-20","objectID":"/doris/:8:0","tags":["database","doris"],"title":"Doris","uri":"/doris/"},{"categories":["database"],"content":"端口信息 doris个实例使用的端口详情。 实例 端口名 默认端口 通讯方向 说明 BE be_port 9060 FE-\u003eBE thrift server 的端口，用于接收来自 FE 的请求 BE webserver_port 8040 BE\u003c-\u003eBE http server 的端口 BE heartbeat_service_port 9050 FE-\u003eBE 心跳服务端口（thrift），用于接收来自 FE 的心跳 BE brpc_port 8060 FE\u003c-\u003eBE, BE\u003c-\u003eBE brpc 端口，用于 BE 之间通讯 FE http_port 8030 FE\u003c-\u003eFE, 用户\u003c-\u003eFE http server 端口 FE rpc_port 9020 BE-\u003eFE, FE\u003c-\u003eFE thrift server 端口，每个fe的配置需要保持一致 FE query_port 9030 用户\u003c-\u003eFE FE 上的 mysql server 端口 FE edit_log_port 9010 FE\u003c-\u003eFE bdbje 之间通信用的端口 Broker broker_ipc_port 8000 FE-\u003eBroker, BE-\u003eBroker thrift server，用于接收请求 \rBroker 是用于访问外部数据源（如 hdfs）的进程。通常，在每台机器上部署一个 broker 实例即可。 当部署多个 FE 实例时，要保证 FE 的 http_port 配置相同。 因为有多网卡的存在，或因为安装过 docker 等环境导致的虚拟网卡的存在，同一个主机可能存在多个不同的 ip。当前 Doris 并不能自动识别可用 IP。所以当遇到部署主机上有多个 IP 时，必须通过 priority_networks 配置项来强制指定正确的 IP。 当配置完 priority_networks 并启动 FE 或 BE 后，只是保证了 FE 或 BE 自身的 IP 进行了正确的绑定。而在使用 ADD BACKEND 或 ADD FRONTEND 语句中，也需要指定和 priority_networks 配置匹配的 IP，否则集群无法建立。 \r\r","date":"2022-09-20","objectID":"/doris/:9:0","tags":["database","doris"],"title":"Doris","uri":"/doris/"},{"categories":["database"],"content":"集群部署 下载软件包到对应的机器上，修改对应配置，启动进程。 将以将数据保存到单独的SSD数据盘目录。 JAVA_OPTS 默认 java 最大堆内存为 4GB，建议生产环境调整至 8G 以上。请合理注意自己实际机器的内存来修改此值。 如果是SSD磁盘要在目录后面加上.SSD,HDD磁盘在目录后面加.HDD。如storage_root_path=/home/disk1/doris.HDD;/home/disk2/doris.SSD;/home/disk2/doris，不加默认表示存储介质是HDD。 不论HDD磁盘目录还是SSD磁盘目录，都无需添加后缀，storage_root_path参数里指定medium即可。如storage_root_path=/home/disk1/doris,medium:hdd;/home/disk2/doris,medium:ssd。 在生产环境中，所有实例都应使用守护进程启动，以保证进程退出后，会被自动拉起，如 Supervisor，请记得修改supervisord.conf的文件打开数配置。 # fe配置 conf/fe.conf # be配置 conf/be.conf # 一般只需修改监听网络和存储路径 # priority_networks, meta_dir # priority_networks, storage_root_path \r\r","date":"2022-09-20","objectID":"/doris/:10:0","tags":["database","doris"],"title":"Doris","uri":"/doris/"},{"categories":["database"],"content":"添加节点 首先确认 FE 和 BE 进程都已经单独正常启动，并确认已经通过 ADD BACKEND 或者 ADD FOLLOWER/OBSERVER 语句添加了所有节点。 BE 节点需要先在 FE 中添加，才可加入集群。 # 在fe中添加be节点 # 连接到fe mysql-client -h fe_host -P query_port -uroot # 添加be节点 mysql\u003e ALTER SYSTEM ADD BACKEND \"be_host:heartbeat-service_port\"; # 添加fe follower/observer mysql\u003e ALTER SYSTEM ADD FOLLOWER \"fe_host:edit_log_port\"; mysql\u003e ALTER SYSTEM ADD OBSERVER \"fe_host:edit_log_port\"; #查看 mysql\u003e show frontends\\G; mysql\u003e show backends\\G; \r\r","date":"2022-09-20","objectID":"/doris/:11:0","tags":["database","doris"],"title":"Doris","uri":"/doris/"},{"categories":["database"],"content":"Broker Broker以插件的形式，独立于Doris部署。如果需要从第三方存储系统导入数据，需要部署相应的 Broker，默认提供了读取 HDFS 、对象存储的 fs_broker。fs_broker 是无状态的，建议每一个 FE 和 BE 节点都部署一个 Broker。 ","date":"2022-09-20","objectID":"/doris/:12:0","tags":["database","doris"],"title":"Doris","uri":"/doris/"},{"categories":["devops"],"content":"参考: argo-cd官方文档 \r \r概述 \r","date":"2022-08-12","objectID":"/argo-cd/:0:0","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["devops"],"content":"argo-cd是什么 argo-cd是一个用于k8s的声明式、gitops持续交付(continuous delivery)工具。 argo-cd配置存在在k8s资源中，application和project是CRDs，cluster credentials存储为secret或configmap。不需要PVC/PV/VOLUME。 \r\r","date":"2022-08-12","objectID":"/argo-cd/:1:0","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["devops"],"content":"为什么是argo-cd Why Argo CD 应用程序定义、配置和环境应该是声明式和版本控制的。应用程序的部署和生命周期管理应该自动化、可审核和易于理解。 \r\r","date":"2022-08-12","objectID":"/argo-cd/:2:0","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["devops"],"content":"入门 Getting Started 快速开始: kubectl create namespace argocd kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml \r\r","date":"2022-08-12","objectID":"/argo-cd/:3:0","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["devops"],"content":"如何运作 How it works argo-cd遵循gitops模式，使用git仓库作为定义期望的应用程序状态的真实来源。 k8s manifests可通过以下方式指定: kustomize helm chart jsonnet k8s yaml 任一自定义配置管理工具 \rargo-cd在指定的目标环境中自动部署所需的应用程序状态。应用程序部署可以跟踪branch、tag或git commit固定到特定版本的清单。 \r\r","date":"2022-08-12","objectID":"/argo-cd/:4:0","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["devops"],"content":"架构 Architecture 架构 argocd被实现为一个k8s controller，它持续监视正在运行的应用程序并将当前的活动状态于所需的目标状态进行比较。实时状态偏离目标状态的已部署应用程序会被视为OutOfSync。argocd报告和可视化差异，同时提供自动或手动将实时状态同步到期望的目标状态。任何对git仓库中对期望状态所做的修改都可以自动应用并反映在指定的目标环境中。 \r\r","date":"2022-08-12","objectID":"/argo-cd/:5:0","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["devops"],"content":"功能 Features 将应用程序自动部署到指定的目标环境 支持多种配置管理工具/模板工具 能够管理和部署到多个集群 SSO集成 用于授权的多租户和RBAC策略 git仓库中对任一应用程序配置的提交，回滚或滚动 应用程序资源的健康状态分析 自动配置漂移检测和可视化 自动或手动同步应用到期望状态 Web界面提供了应用程序活动的实时试图 CLI用于自动化和CI集成 Webhook集成 Access Token 支持复杂应用程序推出的钩子：PreSync, Sync, PostSync 用于应用程序事件和API调用的审计跟踪 Prometheus指标 参数可覆盖helm参数 \r \r基础知识 Basics 在使用argo-cd之前，你应该了解以下基础知识: git docker k8s helm/kustomize ci cd gitops … \r \r核心概念 Core Concepts 以下是argo-cd的一些概念： Application(应用): 由清单定义的一组k8s资源，CRD。 Application source type(应用资源类型): 用于构建应用的工具。 Target state(目标状态): 应用的期望状态，由git仓库中的文件来表示。 Live state(实时状态): 应用的实时状态。 Sync status(同步状态): 实时状态是否于目标状态相匹配。 Sync(同步): 将应用转移到目标状态的过程。 Sync operation status(同步操作状态): 同步是否成功。 Refresh(刷新): 将git仓库中的最新代码与实时状态进行比较，弄清楚有什么不同。 Health(健康状态): 应用的健康状态，是否正常运行？是否可以服务请求？ \r \r入门 Getting Started \r","date":"2022-08-12","objectID":"/argo-cd/:6:0","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["devops"],"content":"安装 注意 由于默认安装的argocd服务都没有资源限制，因此建议添加上资源限制。 \r kubectl create namespace argocd kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml argo-cd的几个服务: argcd-server: 中枢程序 argocd-repo-server: git仓库的本地缓存 argocd-applicationset-controller: 一个k8s控制器，用于比较原版本和目标版本 argocd-dex-server: SSO服务 argocd-redis: 一次性缓存 argocd-notifications-controller： 发送通知 \r\r","date":"2022-08-12","objectID":"/argo-cd/:7:0","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["devops"],"content":"下载argo-cd命令行 下载地址: https://github.com/argoproj/argo-cd/releases/latest \r\r","date":"2022-08-12","objectID":"/argo-cd/:8:0","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["devops"],"content":"访问argo-cd的api地址 默认安装时，argo-cd并未提供外部访问地址。因此，可根据需要创建外部访问地址: ingress nodePort port forwarding ingress如果未配置证书，会出现无线重定向问题。要么就配置上证书，要么就关闭argocd-server的安全选项，在启动参数添加-insecure。 \r\r","date":"2022-08-12","objectID":"/argo-cd/:9:0","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["devops"],"content":"使用命令行登录 默认admin用户的密码存在名为argocd-initial-admin-secret的密钥中。 kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d; echo # 输入用户和密码进行登录 argocd login \u003cARGOCD_SERVER\u003e 请注意，如果你修改了密码，请从此命名空间中删除argocd-initial-admin-secret这个密钥。 \r\r","date":"2022-08-12","objectID":"/argo-cd/:10:0","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["devops"],"content":"注册一个集群到部署 Register A Cluster To Deploy Apps To (Optional) 此步骤将集群的凭证注册到argo-cd中，并且至于在部署到外部集群时才有必要。当部署到内部集群（也就是argo-cd正在运行的同一个集群），https://kubernetes.default.svc将作为应用程序的k8s api的地址。 # 添加外部集群 kubectl config get-contexts -o name # 安装一个serviceaccount(argocd-manager)到kube-system命名空间中 # 并绑定此服务账号到ClusterRole管理员级别 argocd cluster add xxx \r\r","date":"2022-08-12","objectID":"/argo-cd/:11:0","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["devops"],"content":"从git仓库创建一个应用 Create An Application From A Git Repository 如从示例https://github.com/argoproj/argocd-example-apps.git来演示argo-cd是如何工作的。 \r如果从git私有仓库拉取，需要配置私钥和unknown host。 \r","date":"2022-08-12","objectID":"/argo-cd/:12:0","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["devops"],"content":"从命令行创建应用 Creating Apps Via CLI argocd app create guestbook --repo https://github.com/argoproj/argocd-example-apps.git --path guestbook --dest-server https://kubernetes.default.svc --dest-namespace default \r","date":"2022-08-12","objectID":"/argo-cd/:12:1","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["devops"],"content":"从界面创建应用 登录argo-cd界面，创建应用，写入具体配置信息。 \r\r","date":"2022-08-12","objectID":"/argo-cd/:12:2","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["devops"],"content":"同步应用 Sync (Deploy) The Application 默认三分钟从仓库同步一次。 \r","date":"2022-08-12","objectID":"/argo-cd/:13:0","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["devops"],"content":"通过命令行同步 Syncing via CLI # 查看应用状态 argocd app get guestbook # 同步状态 argocd app sync guestbook 之后可通过界面查看相关信息。 \r \r运维手册 Operator Manual \r \r用户指南 User Guide \r","date":"2022-08-12","objectID":"/argo-cd/:13:1","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["devops"],"content":"最佳实践 Best Practices \r","date":"2022-08-12","objectID":"/argo-cd/:14:0","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["devops"],"content":"分离配置和源代码仓库 Separating Config Vs. Source Code Repositories 由于以下原因，强烈建议使用单独的git仓库来保存你的配置(k8s yaml, helm chart等)，并将配置与源代码分开： 提供了应用程序与应用程序配置的干净分离。有时候，你希望修改配置清单而不触发整个CI构建。 更干净的审计日志。处于审计目的，仅保留配置的仓库将具有更干净的git历史记录。 你的应用程序可能由多个git仓库的服务组成，但仅被部署为一个单元。将配置清单存储在单个组件的一个源代码仓库中可能没有意义。 访问分离。开发人员不一定是可以/应该有意/无意地推向生产环境的人。通过单独的仓库，可以控制不同的权限。 对于CI流水线来说也更细化和好控制。 \r","date":"2022-08-12","objectID":"/argo-cd/:14:1","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["devops"],"content":"Leaving Room For Imperativeness 由于某些不完善或自动化，可能希望离开房间(leave room)，并且不要在git仓库中定义所有内容。例如，如果想通过hpa来管理副本数量，那你肯定不希望在git中追踪replica。 apiVersion:apps/v1kind:Deploymentmetadata:name:nginx-deploymentspec:# do not include replicas in the manifests if you want replicas to be controlled by HPA# replicas: 1template:spec:containers:- image:nginx:1.7.9name:nginxports:- containerPort:80... \r","date":"2022-08-12","objectID":"/argo-cd/:14:2","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["devops"],"content":"确保git修订中的配置清单是真正不变的 Ensuring Manifests At Git Revisions Are Truly Immutable 当使用helm或kustomize等模板工具时，表明可以配置清单将其含义从一天更改为另一天。这通常是由上游helm仓库或kustomize base的更改引起的。 如下面这个kustomization.yaml，默认指向远程仓库的HEAD revision。但这并不是一个稳定的目标，此仓库可能会突然发生变化。 bases:- github.com/argoproj/argo-cd//manifests/cluster-install 更好的版本是使用git tag或commit sha。如: bases:- github.com/argoproj/argo-cd//manifests/cluster-install?ref=v0.11.1 ","date":"2022-08-12","objectID":"/argo-cd/:14:3","tags":["devops","cicd","gitops","argo"],"title":"Argo-CD文档","uri":"/argo-cd/"},{"categories":["cncf"],"content":"参考: RKE文档 \r版本: rke1 \r \r介绍 Rancher Kubernetes Engine，简称 RKE，是一个经过 CNCF 认证的 Kubernetes 安装程序。 \r\r要求 RKE对操作系统、软件、端口、SSH和硬件等的要求。 \r总体要求： SSH用户：使用SSH访问节点的用户必须是节点docker用户组成员。如usermod -aG docker \u003cuser_name\u003e 禁用swap 修改sysctl配置: net.bridge.bridge-nf-call-iptables=1 内核版本 k8s和docker版本 查看和选择网络插件 Calico Flannel Weave \r软件要求： OpenSSH Kubernetes：参考rke版本支持的k8s版本 Docker：请注意k8s支持的docker版本 \r硬件要求： 测试环境plane(etcd, controplane)节点和worker节点可以复用 正式环境建议分开部署 硬件至少4c8g起步 \r端口要求: 节点之间需要放开6443端口 \rSSH Server配置 # /etc/ssh/sshd_config # 允许TCP转发 AllowTcpForwarding yes \r \r安装介绍 \r","date":"2022-05-20","objectID":"/rke/:0:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"下载二进制 \r\r","date":"2022-05-20","objectID":"/rke/:1:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"为k8s集群准备节点 \r\r","date":"2022-05-20","objectID":"/rke/:2:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"创建集群配置文件 RKE使用集群配置文件cluster.yml来规划集群中的节点。如集群应该包含哪些节点，节点角色，如何部署k8s等等。 # 创建配置我呢见 rke config --name cluster.yml \r\r","date":"2022-05-20","objectID":"/rke/:3:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"高可用集群 可在配置中配置多个controlplane节点来启用rke的高可用集群。RKE会把master节点的组件部署在所有的controlplane节点上（一般是三个），同时把kubelets的默认连接地址配置为127.0.0.1:6443，这个地址是nginx-proxy请求的master节点的地址。 镜像: rancher/rke-tools 容器: nginx-proxy 它通过nginx本地6443端口代理到controlplane(k8s master)节点上的多个apiserver地址 \r\r","date":"2022-05-20","objectID":"/rke/:3:1","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"证书 默认情况下，Kubernetes 集群需要用到证书，而 RKE 会自动为所有集群组件生成证书。 \r\r","date":"2022-05-20","objectID":"/rke/:3:2","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"部署k8s集群 在配置文件cluster.yml文件目录下，运行rke up命令部署集群。 集群部署成功后，会生成名称为kube_config_cluster.yml的kubeconfig集群控制文件。 \r\r","date":"2022-05-20","objectID":"/rke/:4:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"保存文件 注意 请保存下面列出来的重要文件，这些文件用于维护集群，排查问题和升级集群。 \r请将这些文件复制并保存到安全的地方： cluster.yml：RKE集群的配置文件。 kube_config_cluster.yml：k8s集群所有权限的认证凭据。 cluster.rkestate：k8s集群状态文件，包含了获取该集群所有权限的认证凭据。 k8s集群状态文件用配置文件cluster.yml以及集群中的组件证书组成。 \r\r","date":"2022-05-20","objectID":"/rke/:5:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"操作集群 可以将kube_config_cluster.yml复制到~/.kube/config里，然后用kubectl操作集群。 通过命令行参数指定也可以： kubectl --kubeconfig kube_config_cluster.yml version \r \r自定义证书 自定义证书 \r默认情况下，Kubernetes 集群需要用到证书，而 RKE 会自动为所有集群组件生成证书。您也可以使用自定义证书。 \r \r升级指南 使用 RKE 部署 Kubernetes 后，您可以升级 Kubernetes 集群中组件的版本、编辑Kubernetes services 列表或编辑插件。 \r \r备份和恢复指南 RKE 集群可以自动备份 etcd 节点的快照。在灾难场景下，您可以使用这些快照恢复集群。RKE 将快照保存本地/opt/rke/etcd-snapshots路径下。 \r","date":"2022-05-20","objectID":"/rke/:6:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"创建一次性快照 一些更详细的参数请看rke etcd snapshot-save的可配置参数 运行下面命令时，RKE会创建一个用于备份快照的容器。完成备份后，RKE会删除该容器。 # 创建了一个快照，保存在/opt/rke/etcd-snapshots路径下 # 不指定--config，则默认使用cluster.yml文件 rke etcd snapshot-save --config cluster.yml --name snapshot-name \r\r","date":"2022-05-20","objectID":"/rke/:7:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"创建定时快照 Etcd-Snapshot 服务的可配置参数 RKE默认是每12小时自动备份etcd节点的快照。 运行已经启用etcd-snapshot的集群时，您可以在命令行工具中输入docker logs etcd-rolling-snapshots，查看etcd-rolling-snapshots日志，确认集群是否已开启定时快照功能。 \r\r","date":"2022-05-20","objectID":"/rke/:8:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"恢复集群 如果你的k8s集群发生了灾难，你可以使用rke etcd snapshot-restore来恢复您的etcd。这个命令可以将 etcd 恢复到特定的快照，应该在遭受灾难的特定集群的 etcd 节点上运行。 警告: 在运行rke etcd snapshot-restore之前，您应该备份集群中的任何重要数据，因为该命令会删除你当前的kubernetes集群，并用新的集群替换。 \r","date":"2022-05-20","objectID":"/rke/:9:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"从本地快照恢复的示例 运行以下命令，从本地快照中还原etcd； rke etcd snapshot-restore --config cluster.yml --name mysnapshot \r\r","date":"2022-05-20","objectID":"/rke/:9:1","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"示例 主要分为以下步骤： 备份集群 模拟节点failure 新建etcd节点 使用备份恢复新建节点的数据 确认恢复后的集群处于正常状态 # 备份 rke etcd snapshot-save --name snapshot.db --config cluster.yml # 关闭node2节点，让它不可用 # 新建etcd节点 nodes: - address: 10.0.0.1 hostname_override: node1 user: ubuntu role: - controlplane - worker # - address: 10.0.0.2 # hostname_override: node2 # user: ubuntu # role: # - etcd - address: 10.0.0.3 hostname_override: node3 user: ubuntu role: - etcd # 使用备份恢复新建节点的数据 # 先决条件：开始恢复节点前，请确保您的cluster.rkestate文件有效，因为该文件包含了集群所需的证书数据。 rke etcd snapshot-restore --name snapshot.db --config cluster.yml # 确认集群状态 kubectl get pod \r \r证书管理 证书是 Kubernetes 集群的重要组成部分，所有的 Kubernetes 组件都需要用到证书。您可以使用RKE的rke cert命令管理证书。 \r \r节点管理 \r","date":"2022-05-20","objectID":"/rke/:10:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"添加节点 修改cluster.yml文件内容，添加额外的节点，并指定它们在k8s集群中的角色。 # 使用--update-only添加或删除 worker 节点时，可能会触发插件或其他组件的重新部署或更新。 rke up --update-only \r \rk8s配置项 编辑RKE的cluster.yml文件时，您可以在文件中配置多种不同的选项，控制 RKE 如何启动 Kubernetes。 \r","date":"2022-05-20","objectID":"/rke/:11:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"集群选项 # 集群名称# 默认为 localcluster_name:mycluster# 检查docker版本# 默认情况下，RKE 会检查所有主机上已安装的 Docker 的版本号，如果 Kubernetes 不支持该版本的 Docker，会导致 RKE 运行失败并且报错。# 默认为 falseignore_docker_version:false# k8s版本# 可通过rke config --list-version -all# RKE 支持升级，但目前不支持回滚 Kubernetes 版本kubernetes_version:v1.1x-xxx# 前缀路径# 默认路径前缀: /opt/rkeprefix_path:/opt/custom_path# 集群层面的SSH密钥路径# 如果在集群级和节点级都定义了 ssh 密钥路径，那么 RKE 会优先使用节点层级的密钥。ssh_key_path:~/.ssh/id_rsa# SSH Agent# 默认falsessh_agent_auth:false# 插件job连接超时# 默认30s \r\r","date":"2022-05-20","objectID":"/rke/:12:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"节点选项 RKE 用来指定集群节点、用于访问节点的 ssh 凭证以及这些节点在 Kubernetes 集群中的角色。 \r","date":"2022-05-20","objectID":"/rke/:13:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"角色 k8s角色: controlplane etcd worker \retcd保存着集群的状态，是最重要的组件，是集群的单一真相来源。etcd节点的污点如下： Taint Key Taint Value Taint Effect node-role.kubernetes.io/etcd true NoExecute \rControlplane，k8s master的apiserver, scheduler, controller。controlplane节点的污点如下： Taint Key Taint Value Taint Effect node-role.kubernetes.io/controlplane true NoSchedule \rWorker， 任何Pod都会落在这些节点上。 \r\r","date":"2022-05-20","objectID":"/rke/:14:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"节点选项 address：用于设置主机名或IP地址，RKE必须能够连接到此地址。 internal_address：提供了让具有多个地址的节点设置一个特定的地址用于私有网络上的主机间通信的能力。没有设置，则使用address进行主机键通信。 hostname_override：能够提供一个友好的名称。没有设置，则使用address值。 role：k8s角色 port：ssh端口，默认22 user：ssh用户，连接到节点的用户，必须是docker组成员。 ssh_key_path：用于连接到节点要使用的私钥，默认是~/.ssh/id_rsa。 ssh_key：可以不设置SSH密钥的路径，而是指定实际的密钥内容。 ssh_cert_path：用于连接到这个节点时要使用的签名 SSH 证书路径 ssh_cert：SSH证书内容 docker_socket：docker套接字 labels： 为节点添加标签。 taints： 为节点添加污点。 \r\r","date":"2022-05-20","objectID":"/rke/:15:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"节点配置示例 # cluster.yml# 节点配置示例nodes:- address:1.1.1.1user:ubunturole:- controlplane- etcdssh_key_path:/home/user/.ssh/id_rsaport:2222- address:2.2.2.2user:ubunturole:- workerssh_key:|------BEGIN RSA PRIVATE KEY----- -----END RSA PRIVATE KEY------ address:3.3.3.3user:ubunturole:- workerssh_key_path:/home/user/.ssh/id_rsassh_cert_path:/home/user/.ssh/id_rsa-cert.pub- address:4.4.4.4user:ubunturole:- workerssh_key_path:/home/user/.ssh/id_rsassh_cert:|-ssh-rsa-cert-v01@openssh.com AAAAHHNza...taints:# Available as of v0.3.0- key:test-keyvalue:test-valueeffect:NoSchedule- address:example.comuser:ubunturole:- workerhostname_override:node3internal_address:192.168.1.6labels:app:ingress \r\r","date":"2022-05-20","objectID":"/rke/:16:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"私有镜像仓库 RKE支持在cluster.yml中配置多个私有镜像仓库，然后从私有镜像仓库拉取镜像。 # 不需要加上httpsprivate_registries:- url:registry.comuser:Usernamepassword:password- url:myregistry.comuser:myuserpassword:mypassword \r\r","date":"2022-05-20","objectID":"/rke/:17:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"系统镜像 RKE在部署k8s时，会从镜像仓库中拉取k8s系统组件镜像。 从v0.1.6开始，多个系统镜像的功能被整合到一个rancher/rke-tools镜像中，以简化和加快部署过程。镜像很多，所以可以提前在每个节点上先把镜像拉取下来。 你可以配置网络插件、ingress controller和dns provider这些附加组件和选项。 \rKubernetes的默认版本是与特定版本的系统镜像绑定的： 对于RKE v0.2.x及以下版本，版本和系统镜像版本位于： https://github.com/rancher/types/blob/release/v2.2/apis/management.cattle.io/v3/k8s_defaults.go 对于RKE v0.3.0及以上版本，版本和系统镜像版本位于：https://github.com/rancher/kontainer-driver-metadata/blob/master/rke/k8s_rke_system_images.go \r随着RKE版本的发布，镜像的标签也是会变化。下面是v1.10.3-rancher2的示例： system_images:etcd:rancher/coreos-etcd:v3.2.24alpine:rancher/rke-tools:v0.1.24nginx_proxy:rancher/rke-tools:v0.1.24cert_downloader:rancher/rke-tools:v0.1.24kubernetes:rancher/hyperkube:v1.13.1-rancher1kubernetes_services_sidecar:rancher/rke-tools:v0.1.24pod_infra_container:rancher/pause-amd64:3.1# kube-dns imageskubedns:rancher/k8s-dns-kube-dns-amd64:1.15.0dnsmasq:rancher/k8s-dns-dnsmasq-nanny-amd64:1.15.0kubedns_sidecar:rancher/k8s-dns-sidecar-amd64:1.15.0kubedns_autoscaler:rancher/cluster-proportional-autoscaler-amd64:1.0.0# CoreDNS imagescoredns:coredns/coredns:1.2.6coredns_autoscaler:rancher/cluster-proportional-autoscaler-amd64:1.0.0# Flannel imagesflannel:rancher/coreos-flannel:v0.10.0flannel_cni:rancher/coreos-flannel-cni:v0.3.0# Calico imagescalico_node:rancher/calico-node:v3.4.0calico_cni:rancher/calico-cni:v3.4.0calico_controllers:\"\"calico_ctl:rancher/calico-ctl:v2.0.0# Canal imagescanal_node:rancher/calico-node:v3.4.0canal_cni:rancher/calico-cni:v3.4.0canal_flannel:rancher/coreos-flannel:v0.10.0# Weave imagesweave_node:weaveworks/weave-kube:2.5.0weave_cni:weaveworks/weave-npc:2.5.0# Ingress controller imagesingress:rancher/nginx-ingress-controller:0.21.0-rancher1ingress_backend:rancher/nginx-ingress-controller-defaultbackend:1.4# Metrics server imagemetrics_server:rancher/metrics-server-amd64:v0.3.1 \r\r","date":"2022-05-20","objectID":"/rke/:18:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"默认的k8s服务 k8s的核心服务： etcd kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy 目前，RKE 并不支持scheduler服务的任何特定选项。RKE 不支持 “kubeproxy “服务的任何特定选项。栗子： services:# kube-apiserverkube-api:# 在Kubernetes上创建的服务的IP范围。# 必须与kube-controller中的service_cluster_ip_range匹配service_cluster_ip_range:10.43.0.0/16# 为NodePort服务提供不同的端口范围service_node_port_range:30000-32767pod_security_policy:false# 启用AlwaysPullImagesAdmission controller插件# v0.2.0或更新版本可用always_pull_images:falsesecrets_encryption_config:enabled:true# kube-controller-managerkube-controller:# CIDR pool used to assign IP addresses to pods in the clustercluster_cidr:10.42.0.0/16# IP range for any services created on Kubernetes# This must match the service_cluster_ip_range in kube-apiservice_cluster_ip_range:10.43.0.0/16# kubeletkubelet:# Base domain for the clustercluster_domain:cluster.local# IP address for the DNS service endpointcluster_dns_server:10.43.0.10# Fail if swap is onfail_swap_on:false# Generate per node serving certificategenerate_serving_certificate:false \r\r","date":"2022-05-20","objectID":"/rke/:19:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"自定义参数 RKE支持用户添加自定义参数、挂载存储卷和添加额外的环境变量。 对于任何一个k8s服务，可以使用extra_args来改变现有的默认值。可以使用extra_binds参数为服务添加额外的存储卷绑定。可以使用extra_env参数为服务添加额外的环境变量。 \r\r","date":"2022-05-20","objectID":"/rke/:19:1","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"外部etcd RKE不接受外部 etcd 服务器与节点一起使用etcd角色。 \r\r","date":"2022-05-20","objectID":"/rke/:19:2","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"事件速率限制 使用EventRateLimit接纳控制对 API 服务器在特定时间段内接受的事件数量进行限制。在一个大型多租户集群中，可能会有一小部分租户用事件请求淹没服务器，这可能会对集群的整体性能产生重大影响。因此，建议限制 API 服务器接受事件的速率。 可以为服务器、命名空间、用户或源和对象的组合配置速率限制。 \r\r","date":"2022-05-20","objectID":"/rke/:20:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"RKE插件 包括: 网络插件 Ingress controller插件 DNS提供商插件 Metrics Server插件 \r对于每个Kubernetes版本，都有与每个插件相关联的默认镜像版本，但这些镜像可以通过更改system_images中的镜像来覆盖。 RKE使用kubernetes job的方式部署插件。 \r","date":"2022-05-20","objectID":"/rke/:21:0","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"网络插件 RKE 提供了以下网络插件，作为附加组件部署： Flannel Calico Cannal Weave 在你启动集群后，你不能改变你的网络供应商。因此，仔细选择你要使用的网络供应商，因为Kubernetes不允许在网络供应商之间切换。一旦用网络提供商创建了一个集群，改变网络提供商将需要你拆掉整个集群及其所有的应用程序。 # rke默认使用canal网络插件network:plugin:canal \r\r","date":"2022-05-20","objectID":"/rke/:21:1","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"DNS提供商 RKE提供了以下三种DNS提供商，作为附加组件部署： NodeLocal DNS CoreDNS kube-dns # CoreDNS只能在Kubernetes v1.14.0及以上版本上使用。# 调度dns到特定节点nodes:- address:1.1.1.1role:[controlplane, worker, etcd]user:rootlabels:app:dnsdns:provider:coredns# 节点选择器node_selector:app:dns# 上游DNS服务器upstreamnameservers:- 1.1.1.1- 8.8.4.4# 容忍度# tolerations \r\r","date":"2022-05-20","objectID":"/rke/:21:2","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"K8s Ingress Controllers 默认情况下，RKE会在所有worker节点上部署nginx ingress controller。 RKE 将以 DaemonSet 的形式部署 Ingress Controller，并使用 hostnetwork: true，因此在部署控制器的每个节点上都会打开 80和443端口。 如果只想在特定的节点上部署Ingress Controller，可以设置节点选择器(node_selector)将其调度到特定的节点上。 ingress:provider:nginxoptions:key:xxxextra_args:key:xxx# 默认启用了默认后端(default backend 404)default_backend:true \r\r","date":"2022-05-20","objectID":"/rke/:21:3","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["cncf"],"content":"Metrics Server 默认情况下，RKE 会部署 Metrics Server来提供集群中资源的指标。 \r \r配置文件示例 一个cluster.yml配置文件示例： nodes:- address:1.1.1.1user:ubunturole:- controlplane- etcdport:2222docker_socket:/var/run/docker.sock- address:2.2.2.2user:ubunturole:- workerssh_key_path:/home/user/.ssh/id_rsassh_key:|------BEGIN RSA PRIVATE KEY----- -----END RSA PRIVATE KEY-----ssh_cert_path:/home/user/.ssh/test-key-cert.pubssh_cert:|-ssh-rsa-cert-v01@openssh.com AAAAHHNzaC1yc2EtY2VydC12MDFAb3Bl....- address:example.comuser:ubunturole:- workerhostname_override:node3internal_address:192.168.1.6labels:app:ingresstaints:- key:test-keyvalue:test-valueeffect:NoSchedule# If set to true, RKE will not fail when unsupported Docker version# are foundignore_docker_version:false# Enable running cri-dockerd# Up to Kubernetes 1.23, kubelet contained code called dockershim # to support Docker runtime. The replacement is called cri-dockerd # and should be enabled if you want to keep using Docker as your# container runtime# Only available to enable in Kubernetes 1.21 and higherenable_cri_dockerd:true# Cluster level SSH private key# Used if no ssh information is set for the nodessh_key_path:~/.ssh/test# Enable use of SSH agent to use SSH private keys with passphrase# This requires the environment `SSH_AUTH_SOCK` configured pointing#to your SSH agent which has the private key addedssh_agent_auth:true# List of registry credentials# If you are using a Docker Hub registry, you can omit the `url`# or set it to `docker.io`# is_default set to `true` will override the system default# registry set in the global settingsprivate_registries:- url:registry.comuser:Usernamepassword:passwordis_default:true# Bastion/Jump host configurationbastion_host:address:x.x.x.xuser:ubuntuport:22ssh_key_path:/home/user/.ssh/bastion_rsa# or# ssh_key: |-# -----BEGIN RSA PRIVATE KEY-----## -----END RSA PRIVATE KEY-----# Set the name of the Kubernetes clustercluster_name:mycluster# The Kubernetes version used. The default versions of Kubernetes# are tied to specific versions of the system images.## For RKE v0.2.x and below, the map of Kubernetes versions and their system images is# located here:# https://github.com/rancher/types/blob/release/v2.2/apis/management.cattle.io/v3/k8s_defaults.go## For RKE v0.3.0 and above, the map of Kubernetes versions and their system images is# located here:# https://github.com/rancher/kontainer-driver-metadata/blob/master/rke/k8s_rke_system_images.go## In case the kubernetes_version and kubernetes image in# system_images are defined, the system_images configuration# will take precedence over kubernetes_version.kubernetes_version:v1.10.3-rancher2# System Images are defaulted to a tag that is mapped to a specific# Kubernetes Version and not required in a cluster.yml.# Each individual system image can be specified if you want to use a different tag.## For RKE v0.2.x and below, the map of Kubernetes versions and their system images is# located here:# https://github.com/rancher/types/blob/release/v2.2/apis/management.cattle.io/v3/k8s_defaults.go## For RKE v0.3.0 and above, the map of Kubernetes versions and their system images is# located here:# https://github.com/rancher/kontainer-driver-metadata/blob/master/rke/k8s_rke_system_images.go#system_images:kubernetes:rancher/hyperkube:v1.10.3-rancher2etcd:rancher/coreos-etcd:v3.1.12alpine:rancher/rke-tools:v0.1.9nginx_proxy:rancher/rke-tools:v0.1.9cert_downloader:rancher/rke-tools:v0.1.9kubernetes_services_sidecar:rancher/rke-tools:v0.1.9kubedns:rancher/k8s-dns-kube-dns-amd64:1.14.8dnsmasq:rancher/k8s-dns-dnsmasq-nanny-amd64:1.14.8kubedns_sidecar:rancher/k8s-dns-sidecar-amd64:1.14.8kubedns_autoscaler:rancher/cluster-proportional-autoscaler-amd64:1.0.0pod_infra_container:rancher/pause-amd64:3.1services:etcd:# Custom uid/guid for etcd directory and filesuid:52034gid:52034# if external etcd is used# path: /etcdcluster# external_urls:# - https://etcd-example.com:2379# ca_cert: |-# -----BEGIN CERTIFICATE-----# xxxxxxxxxx# -----END CERTIFICATE-----# cer","date":"2022-05-20","objectID":"/rke/:21:4","tags":["rancher","rke","kubernetes","k8s"],"title":"RKE","uri":"/rke/"},{"categories":["devops"],"content":"Jenkins相关知识","date":"2022-05-09","objectID":"/jenkins/","tags":["cicd","jenkins"],"title":"Jenkins","uri":"/jenkins/"},{"categories":["devops"],"content":"参考: jenkins文档 \r\r入门 Jenkins是一款开源的CICD软件，用于自动化各种任务。 Jenkins有很多插件，可以帮助完成许多工作。 \r","date":"2022-05-09","objectID":"/jenkins/:0:0","tags":["cicd","jenkins"],"title":"Jenkins","uri":"/jenkins/"},{"categories":["devops"],"content":"入门指南 准备工作: 机器要求 内存512MB+ 磁盘10GB+ 软件要求 Java8 Docker \r下载并运行jenkins: mkdir /opt/jenkins cd /opt/jenkins wget http://mirrors.jenkins.io/war-stable/latest/jenkins.war java -jar jenkins.war --httpPort=8080 \r\r","date":"2022-05-09","objectID":"/jenkins/:1:0","tags":["cicd","jenkins"],"title":"Jenkins","uri":"/jenkins/"},{"categories":["devops"],"content":"创建第一个流水线 Jenkins Pipeline是一套插件，将持续交付的实现和实施集成到Jenkins中。Jenkins Pipeline通常写入Jenkinsfile的文本文件中，放入版本控制的仓库中。 可直接在Jenkins界面上创建作业，编写流水线，保存并运行。 pipeline { agent any stages { stage('Build') { steps { echo 'Building... } } stage('Test') { steps { echo 'Testing... } } stage('Deploy') { steps { echo 'Deploying...' } } } } \r\r","date":"2022-05-09","objectID":"/jenkins/:2:0","tags":["cicd","jenkins"],"title":"Jenkins","uri":"/jenkins/"},{"categories":["devops"],"content":"执行多个步骤 流水线由多个步骤组成。可以把步骤看作一个执行单一动作的单一的命令。当一个步骤运行成功时继续执行下一个步骤。当任何一个步骤失败时，流水线的执行结果也视为失败。 如基于Unix-Like系统中的shell命令，对应的sh步骤。 pipeline { agent any stages { stage('Build') { steps { sh 'echo \"Hello World\"' sh ''' echo \"Multiline shell steps\" ls -lah ''' } } } } \r超时和重试等。 pipeline { agent any stages { stage('Deploy') { steps { retry(3) { sh './xxx.sh' } timeout(time: 3, unit: 'MINUTES') { sh './health-check.sh' } } } } } \r完成时的一些动作。 pipeline { agent any stages { stage('Test') { steps { sh 'echo \"Fail!\"; exit 1' } } } post { always { echo '总是会运行' } success { echo '成功才运行' } failure { echo '失败才运行' } unstable { echo '被标记为unstable才运行' } changed { echo '流水线状态改变才运行' echo '例如，流水线之前失败，现在成功' } } } \r\r","date":"2022-05-09","objectID":"/jenkins/:3:0","tags":["cicd","jenkins"],"title":"Jenkins","uri":"/jenkins/"},{"categories":["devops"],"content":"定义执行环境 agent指令告诉Jenkins在哪里以及如何执行流水线，所有的流水线都需要agent指令。 如使用Docker运行： pipeline { agent { docker {image 'node:7-alpine'} } stages { stage('Test') { steps { sh 'node --version' } } } } \r\r","date":"2022-05-09","objectID":"/jenkins/:4:0","tags":["cicd","jenkins"],"title":"Jenkins","uri":"/jenkins/"},{"categories":["devops"],"content":"使用环境变量 环境变量既可以是全局的，也可以是阶段级别的。 pipeline { agent any environment { DISABLE_AUTH = 'true' DB_ENGINE = 'sqlite' } } \r\r","date":"2022-05-09","objectID":"/jenkins/:5:0","tags":["cicd","jenkins"],"title":"Jenkins","uri":"/jenkins/"},{"categories":["devops"],"content":"记录测试和构建结果 虽然测试是良好的持续交付过程中的关键部分，但大多数人并不希望筛选数千行控制台输出来查找有关失败测试的信息。 为了简化操作，只要您的测试运行时可以输出测试结果文件，Jenkins 就可以记录和汇总这些测试结果。 Jenkins通常与junit步骤捆绑在一起，但如果您的测试运行结果无法输出 JUnit 样式的 XML 报告， 那么还有其他插件可以处理任何广泛使用的测试报告格式。 pipeline { agent any stages { stage('Test') { steps { sh './gradlew check' } } } post { always { junit 'build/reports/**/*.xml' } } } \r\r","date":"2022-05-09","objectID":"/jenkins/:6:0","tags":["cicd","jenkins"],"title":"Jenkins","uri":"/jenkins/"},{"categories":["devops"],"content":"清理和通知 在post部分添加通知、清理或其它步骤。 \r\r","date":"2022-05-09","objectID":"/jenkins/:7:0","tags":["cicd","jenkins"],"title":"Jenkins","uri":"/jenkins/"},{"categories":["devops"],"content":"部署 一个常见的模式是扩展阶段的数量以获取额外的部署环境信息。 人工确认，是否可以继续运行。使用input步骤来完成。 pipeline { agent any stages { /* \"Build\" 和 \"Test\" 这里忽略了 */ stage('Deploy - Staging') { steps { sh './deploy staging' sh './run-smoke-tests' } } stage(Sanity check) { steps { input \"Does the staging environment look ok?\" } } state('Deploy - Production') { steps { sh './deploy production' } } } } \r \r用户手册","date":"2022-05-09","objectID":"/jenkins/:8:0","tags":["cicd","jenkins"],"title":"Jenkins","uri":"/jenkins/"},{"categories":["other"],"content":" 由于hexo渲染速度太慢了，将博客从hexo迁移到hugo。 安装hugo，使用LoveIt主题，使用algolia搜索，评论系统还是使用之前的Disqus。 每次生成的搜索的json文件，通过npm和脚本，上传到algolia。 在public目录下添加git remote。 ","date":"2022-05-07","objectID":"/hexo-hugo/:0:0","tags":["hexo","hugo"],"title":"Hexo迁移到Hugo","uri":"/hexo-hugo/"},{"categories":["devops"],"content":"Terraform相关知识","date":"2022-05-05","objectID":"/terraform/","tags":["terraform","iac","基础架构即代码","基础设施即代码"],"title":"Terraform","uri":"/terraform/"},{"categories":["devops"],"content":"参考: Terraform 什么是基础架构即代码 \r\r\r\r基础架构即代码 基础架构即代码(IaC, Infrastructure as Code)，是通过代码（而非手动流程）来管理和置备基础架构（网络、虚拟机、负载均衡器和连接拓扑）的方法。 利用IaC，我们可以创建包含基础架构规范的配置文件，从而便于编辑和分发配置。此外，它还可确保每次置备的环境都完全相同。 版本控制是IaC的一个重要组成部分，就像其他任何软件源代码文件一样，配置文件也应该在源代码控制之下。 \r \rTerraform介绍 \r","date":"2022-05-05","objectID":"/terraform/:0:0","tags":["terraform","iac","基础架构即代码","基础设施即代码"],"title":"Terraform","uri":"/terraform/"},{"categories":["devops"],"content":"Terraform是什么 Terraform是一个基础设施即代码的工具，可让你安全有效地构建，更改和版本化基础设施。这包含了两个组件，低级别的如计算实例，存储和网络；高级别的DNS和SaaS功能。 Terraform通过其API在云平台或其它服务上创建和管理资源。供应商(provider)使得Terraform几乎可以使用任何平台和服务。可以在Terrafrom Registry上查询对应的供应商。如aws, gcp, azure, alicloud, tencentcloud等。 \rTerraform的工作流由三个阶段组成： Write: 定义资源。 Plan: 基于现有基础架构和配置，描述是创建、更新或摧毁基础架构。 Apply: 执行操作。 \r\r","date":"2022-05-05","objectID":"/terraform/:1:0","tags":["terraform","iac","基础架构即代码","基础设施即代码"],"title":"Terraform","uri":"/terraform/"},{"categories":["devops"],"content":"用例 多云部署 应用基础设施部署，扩展和监控工具 自助集群 政策合规性和管理 Paas应用配置 软件定义的网络 Kubernetes 并行环境 软件演示 \r\r","date":"2022-05-05","objectID":"/terraform/:2:0","tags":["terraform","iac","基础架构即代码","基础设施即代码"],"title":"Terraform","uri":"/terraform/"},{"categories":["devops"],"content":"快速开始 \r","date":"2022-05-05","objectID":"/terraform/:3:0","tags":["terraform","iac","基础架构即代码","基础设施即代码"],"title":"Terraform","uri":"/terraform/"},{"categories":["devops"],"content":"AWS示例 \r导入aws相关认证 export AWS_ACCESS_KEY_ID=\"\u003cYOUR_AWS_ACCESS_KEY_ID\u003e\" export AWS_SECRET_ACCESS_KEY=\"\u003cYOUR_AWS_SECRET_ACCESS_KEY\u003e\" export AWS_DEFAULT_REGION=\"\u003cYOUR_AWS_DEFAULT_REGION\u003e\" \r编写配置 mkdir learn-terraform-aws-instance cd learn-terraform-aws-instance touch main.tf \r配置内容 # terraform块包含Terraform设置 # 包含需要的provider terraform { required_providers { aws = { source = \"hashicorp/aws\" version = \"~\u003e 3.27\" } } required_version = \"\u003e= 0.14.9\" }# provider块配置特定的provider provider \"aws\" { profile = \"default\" region = \"us-west-2\" }# resource块定义基础设施的组件 resource \"aws_instance\" \"app_server\" { ami = \"ami-830c94e3\" instance_type = \"t2.micro\" tags = { Name = \"ExampleAppServerInstance\" } } \r初始化目录 terraform init \r格式化和验证配置 terraform fmt terraform validate \r查看变更和创建基础设施 terraform plan terraform apply \r\r查看状态 terraform show terraform state list \r定义变量 创建variables.tf文件，定义变量。 variable \"instance_name\" { description = \"value of the name tag for ec2 instance\" type = string default = \"ExampleAppServerInstance\" } 使用变量 resource \"aws_instance\" \"app_server\" { ami = \"ami-08d70e59c07c61a3a\" instance_type = \"t2.micro\" tags = { - Name = \"ExampleAppServerInstance\" + Name = var.instance_name } } 也可以在命令上上使用-var \"instance_name=YetAnotherName\"来设置变量。 \r在输出中查询数据 编写output.tf output \"instance_id\" { description = \"ID of the EC2 instance\" value = aws_instance.app_server.id } output \"instance_public_ip\" { description = \"Public IP address of the EC2 instance\" value = aws_instance.app_server.public_ip } \r查看输出内容 terraform output instance_id = \"i-0bf954919ed765de1\" instance_public_ip = \"54.186.202.254\" \r \rTerraform语言 Terraform使用HCL(Hashicorp Configuration Language)。 Terraform语言的语法由一些基础元素组成: resource \"aws_vpc\" \"main\" { cidr_block = var.base_cidr_block } \u003cBLOCK TYPE\u003e \"\u003cBLOCK LABEL\u003e\" \"\u003cBLOCK LABEL\u003e\" { # Block body \u003cIDENTIFIER\u003e = \u003cEXPRESSION\u003e # Agrument } \r示例: terraform { required_providers { aws = { source = \"hashicorp/aws\" version = \"~\u003e 1.0.4\" } } } variable \"aws_region\" {} variable \"base_cidr_block\" { description = \"A /16 CIDR range definition, such as 10.1.0.0/16, that the VPC will use\" default = \"10.1.0.0/16\" } variable \"availability_zones\" { description = \"A list of availability zones in which to create subnets\" type =list(string) } provider \"aws\" { region = var.aws_region } resource \"aws_vpc\" \"main\" {# Referencing the base_cidr_block variable allows the network address # to be changed without modifying the configuration. cidr_block = var.base_cidr_block } resource \"aws_subnet\" \"az\" {# Create one subnet for each given availability zone. count =length(var.availability_zones)# For each subnet, use one of the specified availability zones. availability_zone = var.availability_zones[count.index]# By referencing the aws_vpc.main object, Terraform knows that the subnet # must be created only after the VPC is created. vpc_id = aws_vpc.main.id# Built-in functions and operators can be used for simple transformations of # values, such as computing a subnet address. Here we create a /20 prefix for # each subnet, using consecutive addresses for each availability zone, # such as 10.1.16.0/20 . cidr_block = cidrsubnet(aws_vpc.main.cidr_block, 4, count.index+1) } ","date":"2022-05-05","objectID":"/terraform/:3:1","tags":["terraform","iac","基础架构即代码","基础设施即代码"],"title":"Terraform","uri":"/terraform/"},{"categories":["database"],"content":"参考: MongoDB权威指南 \r环境: centos7 mongodb4.2+ \r\r\r\r简介 MongoDB中没有预定义模式，文档键值的类型和大小不是固定的，因此按需添加或删除字段变得很容易。 MongoDB的设计采用了横向扩展。面向文档的数据模型使跨多台服务器拆分数据更加容易。MongoDB会自动平衡跨集群的数据和负载，自动重新分配文档，并将读写操作路由到正确的机器上。 MongoDB包含了索引、聚合、特殊的集合和索引类型、文件存储等功能。 MongoDB在其WiredTiger存储引擎中使用了机会锁，以最大限度地提高并发和吞吐量。它会使用尽可能多的RAM作为缓存，并尝试为查询自动选择正确的索引。 \r \r入门指南 一些基本概念: 文档是基本数据单元，可理解为行。 集合，可理解为表。 数据库 每个文档都有一个特殊的键_id，其在所属的集合中是唯一的。 mongo shell是一个功能强大的javascript解释器。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:0:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"文档 文档是一组有序键值的集合，不能包含重复的键。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:1:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"集合 集合就是一组文档。集合具有动态模式的特性，这意味着一个集合中的文档可以具有任意数量的不同形状。但创建模式并将相关类型的文档放在一起非常合理。通过将单一类型的文档放入集合，可以更高效地对集合进行索引。 使用子集合来组织数据在很多场景中是一个好方法。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:2:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"库 数据库对集合进行分组。库名称长度限制为64字节。一个推荐的做法是将单个应用程序的所有数据都存储在一个库里。 将库和集合名称连接起来，可以获得一个完全限定的集合名称，称位命名空间。命名空间长度限制为120字节，实际应该小于100字节。 一些库名是保留的，有特殊含义： admin: 身份认证和授权。 local: 特定于单个服务器的数据会存储在此数据库中。在副本集中，用于存储复制过程中所使用的数据，而local库不会被复制。 config: 分片集群使用它来存储分片的信息。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:3:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"数据类型 MongoDB中文档可以被认为是类似于JSON的形式。 常见的类型有以下几种: null: 空值或不存在的值 布尔 数值: 默认使用64为浮点数 字符串: 任何utf8字符串 日期: 将日期存储为64为整数，表示自Unix纪元以来的毫秒数。 正则表达式: 与js的正则语法相同 数组 内嵌文档 Object ID: 12字节的ID，是文档的唯一标识。_id默认为此类型。 二进制数据: 如果要将非utf8字符串存入数据库，使用二进制数据是唯一的办法。 代码: 任意js代码 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:4:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"mongo shell 因为mongo shell就是一个js shell，所以可通过js的在线文档获得大量帮助。可以输入help命令进行访问。 可以使用mongo shell执行js脚本。 \rmongo shell辅助函数对应的js函数: 辅助函数 等价函数 use db1 db.getSisterDB(“db1”) show dbs db.getMongo().getDBs() show collections db.getCollectionNames() \r如果你有一些需要频繁被加载的脚本，那么可将它们添加到.mongorc.js文件中。此文件会在启动mongo shell时自动执行。 最常见的用途是移除哪些比较问现的mongo shell命令，调用下面这些命令会打印出错误消息。 var no = function() { print(\"Not on my watch.\") } // 禁止删除数据库 db.dropDatabase = DB.prototype.dropDatabase = no; // 禁止删除集合 DBCollection.prototype.drop = no; // 禁止删除单个索引 DBCollection.prototype.dropIndex = no; // 禁止删除多个索引 DBCollection.prototype.dropIndexes = no; \r \r增删查改 数据库的CRUD操作。 MongoDB会对插入的数据进行最基本的检查，检查文档的基本结构，如果不存在_id字段，则自动添加一个。其中一项最基本的结构检查是文档大小，所有文档都必须小于16MB。可使用Object.bsonsize(doc)来查看文档的bson大小。 为了让你对16MB的数据量有一个概念，以《战争与和平》为例，整部著作也只有3.14MB。 不建议使用insert()，应该使用insertOne()或insertMany()。 不建议使用remove()，应该使用deleteOne()或deleteMany()。 使用updateOnt()或updateMany()。 replaceOne()会用新文档完全替换匹配的文档，这对于大规模模式迁移的场景非常有用。 upsert()是一种特殊类型的更新。如果找不到与筛选条件相匹配的文档，则会以这个条件和更新文档为基础来创建一个新文档；如果找到了匹配的文档，则进行正常的更新。 \r通常文档只会有一部分需要更新，可以使用原子的更新运算符更新文档中的特定字段。应该始终使用修饰符$来增加、修改或删除键。 $inc $set, $unset $push, $pop $sort $slice $ne … \r \r查询 涵盖以下方面: 使用$条件进行范围查询、数据集合查询、不等式查询和其它查询； 查询会返回一个数据库游标，其只会在需要时才惰性地进行批量返回； 有很多可以针对游标执行的元操作，包括跳过一定数量的结果、限定返回结果的数量，以及对结果进行排序。 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:5:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"find 传递给数据库的查询文档的值必须是常量。 // 空查询条件会匹配所有内容 db.c.find() // age 27的所有文档 db.users.find({\"age\": 27}) // 返回指定的键 db.users.find({\"name\": \"joe\", \"age\": 27}, {\"username\": 1, \"email\": 1, \"_id\": 0}) \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:6:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"查询条件 更加复杂的条件。 // $lt, $lte, $gt, $gte, $ne db.users.find({\"aget\": {\"$gte\": 18, \"$lte\": 30}}) start = new Date(\"01/01/2007\") db.users.find({\"registered\": {\"$lt\": start}}) // $in, $nin, $or, $not, $mod db.users.find({\"user_id\": {\"$in\": [123, 456]}}) db.users.find({\"$or\": [{\"name\": {\"$in\": [\"a\", \"b\"]}}, {\"winner\": true}]}) \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:7:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"特定类型的查询 null的行为有一些特别。 // 仅匹配值为null的文档 db.c.find({\"z\": {\"$eq\": null, \"$exists\": true}}) \r$regex可在查询中为字符串的模式匹配提供正则表达式功能。 db.users.find({\"name\": {\"$regex\": /joey?/i}}) \r查询数组元素的方式与查询标量值相同。 db.food.insertOne({\"fruit\": [\"apple\", \"banana\", \"peach\"]) // 查询其中一个内容也可以成功匹配到文档 db.food.find({\"fruit\": \"banana\"}) // 如果需要通过多个元素来匹配数组，使用 $all db.food.find({\"fruit\": {\"$all\": [\"apple\", \"banana\"]}}) // 可以使用数组下标来查询 db.food.find({\"fruit.2\": \"peach\"}) // $size 查询特定长度的数组 db.food.find({\"fruit\": {\"$size\": 3}}) // $slice 返回数组中特定子集 db.blog.posts.findOne(criteria, {\"comments\": {\"$slice\": -1}}) // 返回查询条件匹配的任意数组元素 db.blog.posts.find({\"comments.name\": \"Bob\"}, {\"comments.$\": 1}) \r要正确指定一组条件而无须指定每个键，请使用$elemMatch。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:8:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"$where查询 $where字句允许在查询中执行任意的JavaScript代码。为了安全起见，应该严格限制或消除$where的使用。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:9:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"游标 数据库会使用游标返回find的执行结果。游标的客户端实现通常能够在很大程度上对查询的最终输出进行控制。 \r最常用的查询选项是限制(limit)返回结果的数量、略过(skip)一定数量的结果以及排序(sort)。所有这些选项必须在查询被发送到数据库之前指定。 db.c.find().limit(3) db.c.find().skip(3) // 1升序， -1降序 db.c.find().sort({\"username\": 1, \"age\": -1}) \r略过大量的结果会导致性能问题。因为需要找到被略过的结果，然后再丢弃这些数据。 \r游标包括两个部分：面向客户端的游标，和由客户端游标所表示的数据库游标。 在服务器端，游标会占用内存和资源，一旦游标遍历完结果之后，或者客户端发送一条消息要求终止，数据库就可以释放它正在使用的资源。释放这些资源可以让数据库将其用于其他用途，这是非常有益的，因此要确保可以尽快释放游标。 如果10分钟没有被使用的话，数据库游标也将自动销毁。 有时可能需要一个游标维持很长时间。这种情况下，许多驱动程序实现了一个称为immportal的函数，或者类似的机制。它告诉数据库不要让游标超时。如果关闭了游标超时，则必须遍历完所有结果或主动将其销毁以确保游标被关闭。否则，它会一直占用数据库的资源，知道服务器重新启动。 \r \r索引 索引使你能够高效地执行查询。为集合选择正确的索引对性能至关重要。主要内容： 什么是索引？为什么要使用索引？ 如何选择要创建索引的字段？ 如何强制使用索引？如何对索引的使用进行评估？ 创建及删除索引的管理细节。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:10:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"索引简介 数据库索引类似于图书索引。有了索引便不需要浏览整本书，而是可以采取一种快捷方式，只查看一个有内容引用的有序列表。这使得MongoDB的查找速度提高了好几个数量级。 不适用索引的查询称为集合扫描(全表扫描)，这意味着服务器端必须浏览整本书才能得到查询的结果。 栗子，创建一个包含百万文档的集合: for (i=0; i\u003c1000000; 1++) { db.users.insertOne( { \"i\": i, \"username\": \"user\" + i, \"age\": Math.floor(Math.random()*120), \"created\": new Date() } ); } 通过不使用索引和使用索引，研究这个集合中查询的性能差异。 可以在查询中使用explain命令来产看MongoDB在执行查询时所需要做的事情。 db.users.find({\"usename\": \"user101\"}).explain(\"executionStats\") // 省略部分结果 { ... \"executionStats\" : { \"executionSuccess\" : true, \"nReturned\" : 1, \"executionTimeMillis\" : 419, \"totalKeysExamined\" : 0, \"totalDocsExamined\" : 1000000, \"executionStages\" : { \"stage\" : \"COLLSCAN\", \"filter\" : { \"username\" : { \"$eq\" : \"user101\" } }, \"nReturned\" : 1, \"executionTimeMillisEstimate\" : 375, \"works\" : 100002, \"advanced\" : 1, \"needTime\" : 1000000, \"needYield\" : 0, \"saveState\" : 7822, \"restoreState\" : 7822, \"isEOF\" : 1, \"invalidates\" : 0, \"direction\" : \"forward\", \"docsExamined\" : 1000000 } }, } 介绍下executionStats字段下的内嵌文档。 totalDocsExamined是MongoDB在试图查询时查看的文档总数，可以看到，集合中的每个文档都被扫描过了。也就是说，MongoDB必须查看每个文档中的每个字段。 executionTimeMills字段显示了执行查询所用的毫秒数。 nTeturned字段显示返回的结果数是1，因为只有一个用户名为user101的用户。注意，MongoDB必须在集合的每个文档中查找匹配项，因为它不知道用户名是唯一的。 为了使MongoDB高效地响应查询，应用程序中的所有查询模式都应该有索引支持。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:11:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"创建索引 使用createIndex方法在username字段上创建索引: db.users.createIndex({\"username\": 1}) // 建索引过程会阻塞其它数据库操作，background可指定以后台方式创建索引 db.users.createIndex({\"username\": 1}, {\"background\": true}) // 查看索引 db.users.getIndexes() 索引的创建时间和集合大小有关。可以使用db.currentOp()查看索引创建进度。 在此执行之前的查询： db.users.find({\"username\": \"user101\"}).explain(\"executionStats\") { ... \"executionStats\" : { \"executionSuccess\" : true, \"nReturned\" : 1, \"executionTimeMillis\" : 1, \"totalKeysExamined\" : 1, \"totalDocsExamined\" : 1, \"executionStages\" : { \"stage\" : \"FETCH\", \"nReturned\" : 1, \"executionTimeMillisEstimate\" : 0, \"works\" : 2, \"advanced\" : 1, \"needTime\" : 0, \"needYield\" : 0, \"saveState\" : 0, \"restoreState\" : 0, \"isEOF\" : 1, \"invalidates\" : 0, \"docsExamined\" : 1, \"alreadyHasObj\" : 0, \"inputStage\" : { \"stage\" : \"IXSCAN\", \"nReturned\" : 1, \"executionTimeMillisEstimate\" : 0, \"works\" : 2, \"advanced\" : 1, \"needTime\" : 0, \"needYield\" : 0, \"saveState\" : 0, \"restoreState\" : 0, \"isEOF\" : 1, \"invalidates\" : 0, \"keyPattern\" : { \"username\" : 1 }, \"indexName\" : \"username_1\", \"isMultiKey\" : false, \"multiKeyPaths\" : { \"username\" : [ ] }, \"isUnique\" : false, \"isSparse\" : false, \"isPartial\" : false, \"indexVersion\" : 2, \"direction\" : \"forward\", \"indexBounds\" : { \"username\" : [ \"[\\\"user101\\\", \\\"user101\\\"]\" ] }, \"keysExamined\" : 1, \"seeks\" : 1, \"dupsTested\" : 0, \"dupsDropped\" : 0, \"seenInvalidated\" : 0 } } }, ... } 可以看到，查询几乎是一瞬间完成的。而且查询任何用户名所花费的时间基本上是一致的。 \r索引可以显著缩短查询时间。然而，使用索引是有代价的：修改索引字段的写操作（插入、更新和删除）会花费更长的时间。这是因为在更改数据时，除了更新字段，还必须更新索引。通常来说，这个代价是值得的。关键是要找出要索引的字段。 要选择为哪些字段创建索引，可以查看常用的查询以及哪些需要快速执行的查询，并尝试从中找到一组通用的键。 如果这是一个很少用到的查询或是由管理员执行的不太关心时间消耗的查询，那么就不应该在此上面创建索引。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:11:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"复合索引 对于很多查询模式来说，在两个或更多的键上创建索引是必要的。这称为复合索引(compound index)。如果查询中有多个排序方向或者查询条件中有多个键，那么这个索引会很有用。复合索引是创建在多个字段上的索引。 db.users.createIndex({\"age\": 1, \"username\": 1}, {\"background\": true}) 上面的索引会是下面这个样子: [0, \"user100010\"] -\u003e 8623513776 [0, \"user1002\"] -\u003e 8599246768 ... [0, \"user100414\"] -\u003e 8623564208 [1, \"user100113\"] -\u003e 8623525680 ... [1, \"user100626\"] -\u003e 8623591344 [2, \"user100191\"] -\u003e 8623535664 ... \r db.users.find({\"age\": {\"$gte\": 21, \"$lte\": 30}}) 这是范围查询，用于查找与多个值相匹配的文档（上例指21岁到30岁）。MongoDB会使用索引中的第一个键，即age，以返回匹配的文档。如下所示： [21, \"user100154\"] -\u003e 8623530928 ... [22, \"user100017\"] -\u003e 8623513392 ... [30, \"user100098\"] -\u003e 8623532720 ... 通常来说，如果MongoDB使用索引进行查询，那么它会按照索引顺序返回结果文档。 在设计复合索引时，将排序键放在第一位通常是一个好策略。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:11:2","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"如何选择索引 MongoDB是如何选择索引来满足查询的？ 假设有5个索引。当有查询进来时，MongoDB会查看这个查询的形状。这个形状与要搜索的字段和一些附加信息（比如是否有排序）有关。基于这些信息，系统会识别出一组可能用于满足查询的候选索引。 假设有一个查询进入，5个索引中的3个被标识为改查询的候选索引。然后，MongoDB会创建3个查询计划，分别为每个索引创建1个，并在3个并行线程中运行此查询，每个线程使用不同的索引。 这样做的目的是看哪一个能够最快地返回结果。到达目标状态的第一个查询计划成为赢家。更重要的是，以后会选择它作为索引，用于具有相同形状的其他查询。 每个计划会相互竞争一段时间（成为试用期），之后每一次的结果都会用来在总体上计算出一个获胜的计划。 让多个查询计划相互竞争的真正价值在于，对于具有相同形状的后续查询，MongoDB会知道要选择哪个索引。服务器端维护了查询计划的缓存。一个获胜的计划存储在缓存中，以备在将来用于进行该形状的查询。随着时间的推移以及集合和索引的变化，查询计划可能会从缓存中被淘汰。而MongoDB会再次进行尝试，以找到最适合当前集合和索引集的查询计划。 其他会导致计划从缓存中被淘汰的事件有：重建特定的索引、添加或删除索引，显式清楚计划缓存。重启mongod进程也会导致查询计划缓存丢失。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:11:3","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"使用复合索引 复合索引要比单键索引要复杂一些，但也更强大。设计复合索引时需要进行各种思考，目标是使读写操作尽可能高效。 首先需要考虑的是索引的选择性。对于给定的查询模式，索引将在多大程度上减少扫描的记录数。 \r示例，包含一百万条记录的学生数据集，内容就像下面这样: { \"_id\": Object(\"585d817db4743f74e2da067c\"), \"student_id\": 0, \"scores\": [ { \"type\": \"exam\", \"score\": 38.05 }, { \"type\": \"quiz\", \"score\": 79.45 }, { \"type\": \"homework\", \"score\" 74.50 } ], \"class_id:: 127 } 我们将从两个索引开始，看看MongoDB如何使用（或不使用）这些索引来满足查询。 db.students.createIndex({\"class_id\": 1}) db.students.createIndex({\"student_id\": 1, class_id: 1}) 会围绕以下查询，因为这个查询可以说明在设计索引时必须考虑的几个问题。 db.students.find({student_id: {$gt: 500000}, class_id: 54}) .sort({student_id: 1}) .explain(\"executionStats\") 此查询对student_id大于500000的所有记录进行了请求，这会有一半的记录。我们还将搜索限制在了class_id为54的记录中。最后，根据student_id按升序进行排序。 通过查看explain方法提供的执行统计信息，来说明MongoDB如何使用索引来完成这个查询。 { ... \"executionStats\": { \"executionSuccess\": true, \"nReturned\": 9903, \"executionTimeMillis\": 4325, \"totalKeysExamined\": 850477, \"totalDocsExamined\": 9903, \"executionStages\": { } }, ... } 在executionStats中，先看一下totalKeysExamined。这个字段描述的是，为了生成结果集，MongoDB在索引中遍历了多少个键。 可以将totalKeysExamined与nReturned进行比较，以了解MongoDB必须遍历多少索引才能找到与查询匹配的文档。在本例中，为了定位9903个索引，一共检查了850477个索引键。这表示用于完成此查询的索引选择性比较低。 explain输出的前面部分是获胜的查询计划（参见winningPlan字段）。查询计划描述了MongoDB用来满足查询的步骤。我们尤其对使用了哪个索引以及MongoDB必须在内存中进行排序感兴趣。 \"winningPlan\": { \"stage\": \"FETCH\", \"inputStage\": { \"stage\": \"IXSCAN\", \"keyPattern\": { \"student_id\": 1, \"class_id\": 1 }, \"indexName\": \"student_id_1_class_id_1\", ... }, ... } expalin的输出查询计划显示为一颗包含各个阶段的树。一个阶段可以有一个或多个输入阶段，这取决于它有多少个子阶段。输入阶段向其父阶段提供文档或索引键。 本例中有一个输入阶段，即索引扫描。该扫描阶段向其父阶段FETCH提供了哪些匹配查询的文档的记录ID。然后，FETCH阶段会获取文档本身，并将其分批返回给发出请求的客户端。 \r失败的查询计划（本例只有一个）则会使用基于class_id的索引，但之后它必须进行内存排序。当在查询计划中看到SORT阶段时，意味着MongoDB将无法使用索引对数据库中的结果集进行排序，而必须执行内存排序。 \"rejectedPlans\": [ { \"stage\": \"SORT\", \"sortPattern\": { \"student_id\": 1 }, } ] 对于这个查询，获胜的索引是能够返回排序输出的索引。要获胜，只需要获取测试数量的已排序结果文档。而对于另一个计划，这个查询线程必须要返回整个结果集（将近10000个文档），因为需要将这些结果在内存中进行排序。 \r上面运行的这个查询，同时包含了多值部分和等值部分。class_id再植行查询时更具选择性，它经结果集限制在了10000条以下，而不是多值部分所定位到的850000多条。 换句话说，在当前情况下，如果可以使用基于calss_id的索引则会比较好。 \r游标的hint方法能够通过索引的形状或名称来指定要使用的特定索引。 如下所示，如果使用hint稍微更改以下查询，那么explain的输出结果会完全不同。 db.students.find({student_id: {$gt: 500000}, class_id: 54}) .sort({{student_id: 1}}) .hint({class_id: 1}) .explain(\"executionStats\") \"executionStats\": [ \"nReturned\": 9903, \"executionTimeMillis\": 272, \"totalKeysExamined\": 20076, \"totalDocsExamined\": 20076, ... ] 结果显示，为了得到略少于一万条的结果集，从扫描大约850000个索引键降低到了大约20000个。此外，执行时间仅为272毫秒，而不是之前使用另一个索引时那个查询的4.3秒。 然而，我们真正希望看到的是nReturned与totalKeysExamined非常接近。此外，为了更有效地执行此查询，我们希望可以不使用hint。解决这两个问题的方法是设计一个更好的索引。 对于这里所讨论的查询模式，更好的索引应该基于class_id和student_id，两个键的顺序不能变。以class_id作为前缀，在查询中使用等值过滤来限制索引需要考虑的键。这是查询中最具选择性的部分，从而有效限制了MongoDB完成此查询所需考虑的键的数量。 创建如下索引： db.students.createIndex({class_id: 1, student_id: 1}) \r虽然不是所有数据集都这样，但通常在设计复合索引时，应将等值过滤字段排在多值过滤字段之前。 有了新索引之后，重新执行查询时就不需要提示了。可从explain的输出结果中的executionStats字段看到，查询速度非常快（37毫秒），其中返回的结果数(nReturned)等于索引所扫描的键数(totalKeysExamined)。还可以看到，这个结果是因为executionStages所对应的获胜的查询计划包含了一个索引扫描，它使用了新创建的索引。 \"executionStats\": { \"executionSucess\": true, \"nReturned\": 9903, \"executionTimeMills\": 37, \"totalKeysExamined\": 9903, \"totalDocsExamined\": 9903, ... } \r如果思考以下创建索引的原理，就能明白为什么会有这样的结果。[class_id, student_id]索引由如下一对对键组成。由于学生ID在其中是有序的，因此为了满足排序要求，MongoDB只需从class_id为54的第一对键开始全部进行遍历。 ... [53, 999617] [53, 999916] [54, 500001], [54, 500048] ... 在考虑复合索引的设计时，需要知道对于利用索引的通用查询模式，如何处理其等值过滤、多值过滤以及排序这些部分。对于所有复合索引都必须考虑这3个因素，而且如果在设计索引时可以正确地平衡这些关注点，那么你的查询就会从MongoDB中获得最佳的性能。 \r为了消除这个例子中的特殊情况，我们改为按照最终成绩进行排序，更改后的查询如下。 db.statudents.find({student_id: {$gt: 500000}, class_id: 54}) .sort({final_grade: 1}) .explain(\"executionStats\") 运行这个查询并查看explain输出，就会发现这里使用了内存排序。虽然查询速度仍然很快（136毫秒），但由于使用了内存排序，因此比在student_id上排序慢了一个数量级。可以看到，在进行内存排序时，获胜的查询计划包含一个SORT阶段。 ... \"executionStats\": { \"executionSuccess\": true, \"nReturned\": 9903, \"executionTimeMillis\": 136, \"totalKeysExamined\": 9903, \"totalDocsExamined\": 9903, \"executionStages\": { \"stage\": \"SORT\", ... } } 如果可以的话，应该用更好的索引设计来避免内存排序。这样便能从数据集大小和系统负载两个方面更容易地进行扩展。 但要做到这一点，必须做出权衡。这在设计复合索引时是很常见的情况。 为了避免内存排序，需要检查比返回的文档数量更多的键，这对于复合索引来说往往是必需的。为了使用索","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:11:4","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"复合索引的最佳实践 概括来说，在设计复合索引时： 等值过滤的键应该在最前面 用于排序的键应该在多值字段之前 多值过滤的键应该在最后面 在设计复合索引时应遵循这些准则，然后在实际的工作负载下进行测试，这样就可以确定索引所支持的查询模式都有哪些。 \r\r选择键的方向 到目前为止，我们的所有索引都是升序的。 注意，相互反转的索引是等价的，如{\"age\" 1, \"username\": -1}使用的查询与{\"age\": -1, \"username\": 1}完全一样。 只有基于多个查询条件进行排序时，索引方向才是重要的。如果只是基于一个键进行排序，那么MongoDB可以简单地从反方向读取索引。只有在基于多建排序时，方向才重要。 \r\r使用覆盖查询 在上面的例子中，索引都是用来查找正确的文档，然后跟随指针去获取实际的文档。然而，如果查询只需要查询索引中包含的字段，那么就没哟u必要去获取实际的文档。 当一个索引包含用户请求的所有字段时，这个索引就覆盖了本次查询。只要切实可行，就应该优先使用覆盖查询，而不是去获取实际的文档，这样可以使工作集大幅减少。 为了确保查询只是用索引就可以完成，应该使用投射（只返回查询中指定的字段）来避免返回_id字段（除非它是索引的一部分）。 db.users.find({\"username\": \"user1010\"}, {\"_id\": 0, \"username\": 1, \"email\": 1}) 如果对一个被覆盖的查询运行explain，那么结果中会有一个并不处于FETCH阶段之下的IXSCAN阶段，并且在executionStats中，totalDocsExamined的值是0。 \r\r隐式索引 复合索引具有双重功能，而且针对不同的查询可以充当不同的功索引。 如果有一个在{age: 1, username: 1}上的索引，那么age字段的排序方式就和在{age: 1}上的索引相同。因此，这个复合索引就可以当作{age: 1}索引一样使用。 这可以推广到所需的任意多个键：如果一个拥有N个键的索引，那么你同时免费得到了所有这些键的前缀所组成的索引。如果有一个类似{a: 1, b: 1, c: 1, ..., z: 1}的索引，那么实际上也等于有了{a: 1}, {a: 1, b:1}, {a: 1, b: 1, c: 1}等一系列索引。 注意，这一点并不适用与这些键的任意子集。如{b: 1}, {a: 1, c: 1}作为索引的查询是不是被优化的。只有能够使用索引前缀的查询才能从中受益。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:11:5","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"$运算符如何使用索引 \r \r副本集 本章内容如下： 什么是副本集 如何创建副本集 副本集成员有哪些可用的配置项 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:11:6","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"复制简介 复制是将数据的相同副本保留在多台服务器上的一种方法，建议将其用于所有生产部署中。 在MongoDB中，创建副本集(replica set)后就可以使用复制功能。副本集是一组服务器，其中一个是用于处理写操作的主节点(primary)，还有多个用于保存主节点的数据副本的从节点(secondary)。如果主节点崩溃了，则从节点会从其中选取出一个新的主节点。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:12:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"安全注意事项 配置副本集时，应该启用授权控制并指定身份认证。另外，最好对磁盘上的数据和副本集成员之间以及副本集与客户端之间的通信进行加密。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:13:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"建立副本集 在生产环境中，应该始终使用副本集并为每个成员分配一个专用主机，以避免资源争用，并针对服务器故障提供隔离。为了提供更多的弹性，还应该使用DNS种子列表连接(seedlist connection)格式指定应用程序如何连接到副本集。 cd /test/mongodb/ mkdir ./rs{1,2,3} # 启动副本 mongod --replSet mdbDefGuide --dbpath /test/mongodb/rs1 --port 17017 --smallfiles --oplogSize 200 mongod --replSet mdbDefGuide --dbpath /test/mongodb/rs2 --port 27017 --smallfiles --oplogSize 200 mongod --replSet mdbDefGuide --dbpath /test/mongodb/rs3 --port 37017 --smallfiles --oplogSize 200 \r目前，每个mongod都不知道其他mongod的存在。为了能够彼此交互，需要创建一个包含每个成员的配置，并将此配置发送给其中一个mongod进程。它负责将此配置传播给其他成员。 副本集配置有几个重要组成部分。配置项_id是在命令行中传递的副本集名称，请确保此名称完全一致。副本集成员组成的数组，每个成员都需要_id和host这两个字段。 rsconf = { _id: \"mdbDefGuide\", members: [ {_id: 0, host: \"localhost:27017\"}, {_id: 1, host: \"localhost:27018\"}, {_id: 2, host: \"localhost:27019\"} ] } rs.initiate(rsconf) rs.status() 这个配置文档就是副本集的配置。在某个mongod上运行的成员会解析配置并将消息发送给其他成员（不能在多个成员上使用数据初始化副本集），提醒它们存在新的配置。一旦所有成员都加载了配置，它们就会选择一个主节点并开始处理读写请求。 副本集会选举出一个主节点，可使用rs.status()或db.isMaster()命令来查看副本集的状态。 \r 注意 不能在不停止运行的情况下将单机服务器转换为副本集，以重新启动并初始化该副本集。因此，即使一开始只有一台服务器，你也希望将其配置为一个单成员的副本集。这样，如果以后想添加更多成员，则可以在不停止运行的情况下进行添加。 \r rs辅助函数 rs是一个含有复制辅助函数的全局变量。这些函数大部分是数据库命令的封装。 如rs.initiate(config)命令等同于db.adminCommand({\"replSetInitiate\": config})。最好能同时熟悉辅助函数和底层命令，因为使用命令形式代替辅助函数可能会更简单。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:14:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"观察副本集 连接到mongod，你应该会发现提示符发生变化: mdbDefGuide:PRIMARY\u003e # 或 mdbDefGuide:SECONDARY\u003e \r从节点可能会落后于主节点（延迟）而缺少最新的写入，所以默认情况下从节点会拒绝读请求，以防止应用程序意外读取过期数据。 从节点不接受写操作。从节点只能通过复制功能写入数据，不接受客户端的写请求。 因此，如果尝试在从节点上查询，则会弹出一条表明它不是主节点的错误消息。想要在从节点上进行查询操作，可以设置在从节点中读取是没有问题的标志。注意，slaveOk是在**连接(secondaryConn)**上设置，而不是在数据库(secodaryDB)上。 如果主节点停止运行，那么其中一个从节点将自动被选举为主节点。 secondaryConn.setSlaveOk() rs.slaveOk() rs.secondaryOk() \r需要注意的几个关键概念： 客户端在单台服务器上执行的请求都可以发送到主节点执行（读操作、写操作、执行命令、创建索引等）。 客户端不能在从节点上执行写操作。 默认情况下，客户端不能再从节点上读取数据，但可以启用从节点读取数据的功能。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:15:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"更改副本集配置 可以随时更改副本集配置：添加、修改或删除成员。 rs.add(\"localhost:27017\") rs.remove(\"localhost:27017\") rs.config() var config = rs.config() config.members[0].host = \"localhost:27017\" # 配置文件修改正确，需要使用rs.reconfig()辅助函数将其发送到数据库 rs.reconfig(config) # 每次更改副本集配置时，version字段都会自增。版本的初始值为1。 对于复杂的操作，比如更改成员配置或者一次性添加/删除多个成员，rs.reconfig()通常比rs.add()和rs.remove()更有用。可以使用这个命令来进行所需的任何合法的配置更改：只需要简单地创建代表所需配置的配置文档，然后将其传递给rs.reconfig()。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:16:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"如何设计副本集 副本集中的重要概念——大多数(majority)。选举主节点时需要由大多数决定，这节点只有在得到大多数支持时才能继续作为主节点，写操作被复制到到多数成员时就是安全的写操作。这里的大多数定义为副本集一半以上的成员。 副本集成员总数 副本集大多数 1 1 2 2 3 2 4 3 5 3 6 4 7 4 也就是如下数学公式：$大多数 = n/2 + 1$ \r如果副本集中只有少数节点可用，那么所有成员将变为从节点。 配置副本集时很重要的一点就是只能有一个主节点。MongoDB选择只支持单一主节点，这样可以使开发更容易，但是可能导致副本集变为只读状态。 \r两种推荐的副本集配置方式： 将大多数成员放在一个数据中心 在两个数据中心各自放置相等的成员，在第三个地方放置一个用于打破僵局的副本集成员。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:17:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"如何进行选举 RAFT是一种共识算法，它被分解成了相对独立的子问题。共识是指对台服务器或进程在一些值上达成一致的过程。RAFT确保了一致性，使得同一序列的命令产生相同序列的结果，并在所部署的各个成员中达到相同序列的状态。 \r当一个从节点无法与主节点连通时，它就会联系并请求其他的副本集成员将自己选举为主节点。其他成员会做几项健全性检查：它们能否连接到一个主节点，而这个主节点时发起选举的节点无法连接的？这个发起选举的从节点是否有最新数据？有没有其他更高优先级的成员可以被选举为主节点？ MongoDB在3.2版本中引入了第一版复制协议，基于斯坦福大学开发的RAFT共识协议。这是一个类RAFT的协议，并且包含了一些特定于MongoDB的副本集概念，比如仲裁节点、优先级、非选举成员、写入关注点(write concern)等。第一版协议提供了很多新特性的基础，比如更短的故障转移时间，以及大大减少了检测主节点失效的时间。它还通过使用term ID来防止重复投票。 \r副本集成员相互间每隔两秒发送一次心跳(heartbeat)（相当于ping）。如果某个成员在10秒内没有反馈心跳，则其他成员会将该不良成员标记为无法访问。选举算法将尽最大努力尝试让具有最高优先级的从节点发起选举。成员优先级会影响选举的时机和结果。优先级高的从节点要比优先级低的从节点更快地发起选举，而且也更有可能成为主节点。然而，低优先级的从节点也可能短暂地被选为主节点，即使还存在一个可用的高优先级的从节点。副本集成员会继续发起选举知道可用的最高优先级成员被选为主节点。 就所有能连接到的成员，被选为主节点的成员必须拥有最新的复制数据。严格地说，所有的操作都必须比任何一个成员的操作都要高，因此所有的操作都必须比任何一个成员的操作都要晚。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:18:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"成员配置选项 你可能希望让某个成员拥有优先选举成为主节点的权力，或者将某个成员设置为对客户端不可见以便阻止将请求发送给它。 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:19:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"优先级 优先级用于表示一个成员渴望成为主节点的程度。它的取值范围是0到100，默认是1。将priority设置为0有特殊的含义：优先级为0的成员永远不可能成为主节点。这样的成员称为**被动(passive)**成员。 拥有最高优先级的成员总是会被选举为主节点（只要他能连接到副本集中的大多数成员，并且拥有最新的数据）。 # 添加一个优先级为1.5的成员 rs.add({\"host\": \"server-4:27017\", \"priority\": 1.5}) 设置优先级并不会导致副本集中无法选举出主节点，也不是使在数据同步中落后的成员称为主节点（一直到它的数据更新到最新）。 优先级(priority)的绝对值只与它是否大于或小于副本集中的其他优先级相关，优先级为100、1和1的一组成员，与优先级为2、1和1的另一组成员的行为方式相同。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:19:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"隐藏成员 客户端不会向隐藏成员发送请求，隐藏成员也不会优先作为副本集的数据源（尽管当其他复制源不可用时隐藏成员也会被使用）。因此，很多人会将性能较弱的服务器或者备份服务器隐藏起来。 只有优先级为0的成员才能被隐藏，不能隐藏主节点。将hidden设置为true即可隐藏节点，要将隐藏成员设置非隐藏，只需将配置中的hidden设为false，或删除此选项。 var config = rs.confg() config.members[3].hidden = true config.members[3].priority = 0 rs.reconfig(config) 使用rs.status()和rs.config()能够看到隐藏成员，隐藏成员只对isMaster不可见。当客户端连接到副本集时，会调用isMaster来查看副本集中的成员。因此，隐藏成员永远不会收到客户端的读请求。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:19:2","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"选举仲裁者 对于大多数需求来说，两节点的副本集具有明显的缺点。然而，许多小型部署不希望保存三份数据副本集，觉得两份副本集就足够了，而保存第三份副本集会付出不必要的管理、操作和财务成本。 MongoDB支持一种特殊类型的成员，称为仲裁者(arbiter)，其唯一作用就是参与选举。仲裁者并不保存数据，也不会为客户端提供服务。它只是为了帮助具有两个成员的副本集满足大多数这个条件。通常来说，最好使用没有仲裁者的部署。 由于仲裁者并不需要履行传统mongod服务器端的责任，因此可以将其作为轻量级进程运行在配置比较差的服务器上。如果可能，应将找那个踩着与其他成员分开，放在单独的故障域(failure domain)，以便它以一个外部视角来看待副本集中的成员。 # 添加仲裁者 # 有两种方式 rs.addArb(\"server-5:27017\") rs.add({\"_id\": 4, \"host\": \"server-5:27017\", \"arbiterOnly\": true}) 成员一旦以仲裁者的身份被添加到副本集中，它就永远只能是仲裁者。无法将仲裁者重新配置为非仲裁者，反之易燃。 \r使用仲裁者需要考虑以下几件事： 最多只能使用一个仲裁者：添加额外的仲裁者并不能加快选举，也不能提供更好的数据安全性。 使用仲裁者的缺点：在不知道将一个成员作为数据节点还是仲裁者时，应将其作为数据节点。如果可能，尽可能在副本集中使用奇数个数据成员，而不是使用仲裁者。 \r 在具有主-从-仲裁(PSA)架构的三成员副本集或具有PSA分片的分片集群中，如果两个数据节点的任何一个停止运行并启用了majority的读关注(read concern)，则必然存在缓存压力增加的问题。理想情况下，应该将仲裁者替换为数据成员。或者为了防止存储缓存压力，可以在部署或分片中的每个mongod实例上禁用majority的读关注。 \r注意两个关键词： 读关注(read concern) 写关注(write concern) \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:19:3","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"创建索引 有时从节点不需要具有与主节点上相同的索引，甚至可以没有索引。如果仅使用从节点备份数据或脱机批量处理作业，则可以在成员配置中指定\"buildIndexed\": false，此选项可防止从节点创建任何索引。 与隐藏成员一样，此选项要求成员的优先级为0。 \r \r副本集的组成 本章介绍副本集的各个部分时如何组织在一起的，包括： 副本集成员如何复制新数据 如何让新成员开始工作 选举是如何进行的 可能出现的服务器端和网络故障场景 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:19:4","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"同步 复制是指在多台服务器上保持相同的数据副本。MongoDB实现此功能的方式是保存操作日志(oplog)，其中包含了主节点执行的每一次写操作。oplog是存在于主节点local数据库中的一个固定集合。从节点通过查询此集合以获取需要复制的操作。 每个从节点都维护着自己的oplog，用来记录它从主节点复制的每个操作。这使得每个成员都可以被用作其他成员的同步源。从节点从同步源中获取操作，将其应用到自己的数据集上，然后再写入oplog中。如果应用某个操作失败（只有再基础数据已损坏或数据与主节点不一致时才会发生此情况），则从节点会停止从当前数据源复制数据。 如果一个从节点由于某种原因而停止运行，那么当它重新启动后，就会从oplog中的最后一个操作开始同步。由于这些操作是先应用到数据上然后再写入oplog，因此从节点可能会重复已经应用到其数据上的操作。MongoDB在设计时就考虑到了这种情况：将oplog中的同一个操作执行多次与执行一次的效果是一样的。oplog中的每个操作都是幂等的。也就是说，无论对目标数据集应用一次还是多次，oplog操作都会产生相同的结果。 由于oplog的大小是固定的，因此它只能容纳一定数量的操作。在大多数情况下，默认的oplog大小就足够了。但你也可以修改oplog的大小。 在mongod进程创建oplog之前，可以使用oplogSizeMB选项指定其大小。然而，在第一次启动副本集成员后，只能使用更改oplog大小这个流程来更改oplog。 \rMongoDB中存在两种形式的数据同步： 初始化同步用于向新成员中添加完整的数据集 复制用于将正在发生的变更应用到整个数据集 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:20:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"初始化同步 MongoDB在执行初始化同步时，会将所有数据从副本集中的一个成员复制到另一个成员中。当一个副本集成员启动时，它会检查自身的有效状态，以确定是否可以开始从其他成员中同步数据。如果状态有效，它就会尝试从该副本集的另一个成员中复制数据的完整副本。 首先，MongoDB会克隆除local数据库之外的所有数据库。mongod会扫描源数据库中的每个集合，并将所有数据插入目标成员上这些集合的对应副本中。在开始克隆操作之前，目标成员上的任何现有数据都将被删除。 一旦所有的数据库都被克隆，mongod就会使用这些来自同步源的oplog记录来更新它的数据集以反映副本集的当前状态，并将复制过程中发生的所有变更应用到数据集上。成员在完成初始化同步后会过度到正常同步流程，这使其成为从节点。 从操作者的角度来看，进行初始化同步的过程非常容易，只需要一个干净的数据目录启动mongod。然而，更推荐从备份中进行恢复。从备份中恢复通常比通过mongod复制所有数据要快。 进行初始化同步时一个最常见的问题就是时间过长。在这种情况下，新成员可能会从同步源的oplog末尾脱离，由于同步源的oplog已经覆盖了成员计息复制所需的数据，因此新成员会远远落后于同步源并且无法再跟上。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:20:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"复制 MongoDB执行的第二种同步是复制。从节点成员在初始化之后会持续复制数据。它们从同步源复制oplog，并在一个异步进程中应用这些操作。从节点可以根据需要自动更改同步源，以应对ping时间及其他成员复制状态的变化。 有一些规则可以控制给定节点从哪些成员进行同步。例如，拥有投票权的副本集成员不能从没有投票权的成员那里同步数据，从节点不能从延迟成员和隐藏成员那里同步数据。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:20:2","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"处理过时数据 如果某个从节点远远落后于同步源当前的操作，那么这个从节点就是过时的。过时的从节点无法赶上同步源，因为同步源上的操作过于领先。如果继续同步，从节点就需要跳过一些操作。这种情况可能发生在以下场景中： 从节点服务器停止运行 写操作超过了自身处理能力 忙于处理过多的读请求 \r当一个从节点过期时，它将依次尝试从副本集中的每个成员进行复制，看看是否有成员拥有更长的oplog以继续进行同步。如果没有一个成员拥有足够长的oplog，那么该成员上的复制将停止，并且需要重新进行完全同步或从最近的备份中恢复。 为了避免出现不同步的从节点，让主节点拥有一个比较大的oplog以保存足够多的操作日志很重要。根据经验，oplog应该可以覆盖两到三天的正常操作。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:20:3","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"心跳 每个成员需要知道其他成员的状态：谁是主节点？谁可以作为同步源？谁停止运行了？ 为了维护副本集的最新视图，所有成员每隔两秒会向副本集其他成员发送一个心跳请求。心跳请求用于检查每个成员的状态。 心跳的一个最重要的功能是让主节点知道自己是否满足副本集大多数的条件。如果主节点不再得到大多数节点的支持，它就会降级，成为一个从节点。 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:21:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"成员状态 成员的一些状态： STARTUP：成员第一次启动时的状态，这时MongoDB正在尝试加载它副本集配置。一旦配置被加载，它就转换到STARTUP2状态。 STARTUP2：初始同步过程会持续处于这个状态。然后转到RECOVERING。 RECOVERING：成员运行正常，但不能处理请求。有以下原因： 在启动时，成员必须做一些检查以确保自己处于有效的状态，之后才能接收读请求。因此，在启动过程中，所有成员在成为从节点之前都需要经历短暂的REVOVERING状态。在处理一些耗时操作时，成员也有可能进入此状态。 如果一个成员远远落后于其他成员而无法赶上时，也会进入RECOVERING状态。通常来说，这是需要进行重新同步的无效状态。这时，该成员不会进入错误状态，因为它希望找到一个拥有足够长oplog的成员，从而引导自己回到非过时状态。 ARBITER：仲裁节点独有的一种特殊状态，并在其正常运行期间应该始终处于此状态。 DOWN：如果一个成员正常启动，但后来变为不可访问，那么就会进入这种状态。 UNKNOWN：如果一个成员从未能访问到另一个成员，那么就不知道它处于什么状态。 REMOVED：表示此成员以被从副本集中移除。如果被移除的成员被添加到副本集，它就会转换回正常的状态。 ROLLBACK：当成员正在回滚数据时会处于此状态。在回滚结束时，服务器回转换回RECOVERING状态，然后成为从节点。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:21:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"选举 当一个成员无法访问到主节点（而且本身有资格成为主节点）时，便会申请选举。申请选举的成员会向其所能访问的所有成员发出通知。如果这个成员不适合作为主节点那么其他成员会知道原因：如此成员的数据落后于副本集，或已有一个主节点在申请选举，而那个失败的成员无法访问到此节点。在这些情况下，其他成员将投票反对该成员的申请。 假如没有理由反对，其他成员就会为申请当选的成员投赞成票。如果申请选举的成员从副本集中获得了大多数选票，选举就成功了，该成员将过渡到PRIMARY状态。如果没有获得大多数选票，那么它会继续处于从节点状态，以后可能会试图再次成为主节点。主节点会一直处于主节点状态，知道不能满足大多数的要求、停止运行、降级，或者副本集被重新配置为止。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:22:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"回滚 如果主节点执行一个写操作之后停止了运行，而从节点还没来得及复制此操作，那么新选举出的主节点可能会丢失这个写操作。 比如这个操作是126，而从节点上只有125操作。 当恢复后，服务器会寻找之前的126操作以开始与其他服务器的同步，但无法找到这个操作。当这种情况发生时，A和B将开始一个名为**回滚(rollback)**的过程。回滚用于撤销在故障转移前未复制的操作。具有126号操作的服务器会在另一个数据中心服务器的oplog中寻找公共的操作点。它们会发现125号操作是相互匹配的最后一个操作。 这时，服务器会遍历这些操作，并接受这些操作影响的每个文档写入一个bson文件，保存在数据目录下的rollback目录中。 一个经常被误用的成员配置选项是每个成员的投票数量设置。改变成员的投票数量通常不会得到想要的结果，并且会导致大量的回滚。除非做好了定期处理回滚的准备，否则不要更改成员的投票数量。 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:23:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"当回滚失败时 在旧版本的MongoDB中，如果要回滚的内容太多，则可能导致回滚无法执行。从MongoDB 4.0开始，回滚的数据量就没有限制了。在4.0之前，如果要回滚的数据量超过300MB或者要回滚的操作超过30分钟，那么回滚可能会失败。在这些情况下，对于回滚失败的节点，必须重新进行同步。 这种情况最常见 的原因是从节点存在同步延迟，而主节点停止运行了。如果其中一个从节点变成了主节点，那么之前主节点中的许多操作会丢失。为了确保在回滚过程中不会失败，最好的方法是让从节点的数据尽可能保持最新。 \r \r从应用程序连接到副本集 本章介绍如何在应用程序中与副本集进行交互，包括： 如何连接到副本集以及故障转移的工作机制； 在进行写操作时等待复制； 将读请求路由到正确的成员。 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:23:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"客户端到副本集的连接行为 MongoDB的客户端开发库（驱动程序）用于管理与MongoDB服务端的通信。对于副本集，默认情况下，驱动程序会连接到主节点，并将所有流量都路由到此节点。应用程序可以像与单机服务器通信一样执行读写操作，同时副本集会在后台悄悄地处理热备份。 种子列表就是服务器地址列表。种子时应用程序将读取和写入数据的副本集成员。你不需要列出种子列表中的所有成员（尽管也可以）。当驱动程序连接到种子服务器时，它可以从其中发现其他成员。 # 一个连接字符串类似于下 \"mongodb://server-1:27017,server-2:27017,server-3:27017\" \r所有MongoDB驱动程序都遵守服务器发现和监控(SDAM)规范。驱动程序会持续监视副本集的拓扑结构，以检测应用程序对集合中成员的访问能力是否有变化。此外，驱动程序会监视副本集，以维护关于哪个成员是主节点的信息。 如果一个主节点发生故障，则驱动程序会自动找到新的主节点，并将请求尽快路由到新的主节点。不过，当没有可达的主节点时，应用程序将无法执行写操作。 在选举过程中，主节点可能短暂地不可用。如果没有可达成员能够成为主节点，则主节点可能长时间不可用。默认情况下，驱动程序在此期间不会处理任何请求（无论读还是写）。如果应用需要，则可以配置驱动程序将读请求路由到从节点。 驱动程序处理MongoDB故障转移的策略： 不重试 在重试一定次数后放弃 最多只重试一次 MongoDB从3.6开始，服务端以及所有MongoDB驱动程序都支持可重试写选项。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:24:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"在写入时等待复制 在某个时刻，一个从节点可能被选为主节点并开始接收新的写入。当之前的主节点恢复时，会发现它有一些不存在于新主节点上的写操作。为了纠正这一点，它会撤销与当前主节点的操作序列不匹配的任何写操作。这些操作不会丢失，而是会被写入特殊的回滚文件中，这些文件必须手动应用于当前的主节点。MongoDB不能自动应用这些写操作，因为它们可能与崩溃 后发生的其他写操作冲突。因此，这些写操作会消失，知道管理员有机会将回滚文件应用于当前的主节点。 如果对写入大多数成员有要求，则可以防止这种情况的出现。如果应用程序得到了写入成功的确认，那么新的主节点必须拥有该写入的副本。如果应用程序没有收到来自服务器端的确认消息或收到了错误消息，那么它会知道需要进行重试，因为在主节点崩溃之前，写操作没有传播到副本集的大多数成员。 因此，如果要保证无论副本集出现什么情况写操作都可以被持久化，那么必须确保每个写操作都传播到副本集的大多数成员。可以使用**写关注(writeConcern)**实现这一点。 // javascript 写关注的示例 // 写关注指定为 majority(大多数) try { db.products.insertOne( {\"_id\": 10, \"item\": \"envelopes\", \"qty\": 100, type: \"Self-Sealing\"}, {\"writeConcern\": {\"w\": \"majority\", \"wtimeout\": 100}} ); } catche (e) { print (e); } 但在这个写操作被复制到副本集的大多数成员之前，服务器端不会发出响应。只有这样，应用程序才会收到这个写操作成功的确认。如果在指定的超时时间之内没有写入成功，则服务器端会恢复一条错误消息。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:25:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"自定义复制保证规则 副本集运行你创建可以传递给getLastError的自定义规则，以确保写操作被复制到所需的任何服务器组合上。 如： 保证复制到每个数据中心的一台服务器上 保证写操作被复制到大多数非隐藏节点 创建其他保证规则 尽管规则的理解和设置都比较复杂，但它是一种非常强大的副本集配置方式。除非有相当特殊的复制请求，否则使用\"w\": \"majority\"是非常安全的。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:26:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"将读请求发送到从节点 默认情况下，驱动程序会将所有请求路由到主节点。但可以通过设置驱动程序的**读偏好(read preference)**来配置其他选项。 将读请求发送到从节点通常不是一个好主意。虽然这在某些特定的情况下是有意义的，但通常应该将所有请求发送到主节点。如果你正在考虑将读请求发动到从节点，那么请确保在此之前已非常仔细低权衡利弊。 读偏好的五种模式： primary(默认) primaryPreferred nearest secondary secondaryPreferred \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:27:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"一致性考虑 对一致性要求非常高的应用程序不应该从从节点读取数据。 通常从节点会落后于主节点的时间在几毫秒之内。然而，这一点无法保证。驱动程序无法知道从节点的数据有多新，因此可能会将查询发送到一个远远落后的从节点上。因此，如果应用程序需要读取最新的数据，那么就不应该从从节点读取。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:27:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"负载考虑 服务器过载通常会使它的执行速度变慢，进一步降低副本集的处理能力，迫使其他成员承担更多的负载，这样就会陷入恶性循环。 过载还会导致复制的速度变慢，使得剩余的从节点落后于主节点。突然间，你的副本集中有的成员崩溃了，有的成员发生了滞后，所有成员都过载了，没有任何回旋的余地。 一个更好的选择是使用分片来分配负载。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:27:2","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"由从节点读取的场景 在某些情况下，将应用程序的读请求发送到从节点是合理的。 注意，如果应用程序需要低延迟读和低延迟写，则必须使用分片：副本集只允许在主节点上进行写操作（无论主节点在什么位置）。 如果从落后的从节点读取数据，则必须牺牲一致性。另外，如果希望等待写操作复制到所有成员，则需要牺牲写入速度。 如果应用程序确实能够接受陈旧的数据，那么可以使用secondary或secondaryPreferred作为读偏好。 secondary：总是将读请求发送给从节点。如果没有可用的从节点，则会出现错误，而不是将请求发送给主节点。 secondaryPreferred：如果从节点可用，则将读请求发送到从节点。否则，请求被发送到主节点。 \r有时候，读负载与写负载有很大的不同，比如，正在读取的数据与正在写入的数据是完全不同的。为了进行离线处理，你可能需要很多索引，而又不希望将这些索引创建在主节点上。在这种情况下，可以设置一个具有与主节点不同索引的从节点。如果想以这种方式使用从节点，那么么就需要让驱动程序直接连接到从节点，而不是使用副本集连接。 \r \r副本集管理 本章介绍副本集管理的相关内容，包括： 对独立的成员进行维护； 对各种不同情况下配置副本集； 获取oplog相关信息以及调整oplog大小； 使用特殊的副本集配置； 将主从模式转换为副本集模式。 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:27:3","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"以单机模式启动成员 许多维护任务不能在从节点上执行（因为涉及了写操作），也不应该在主节点上执行，因为这会对应用程序性能造成影响。因此，以下各节经常会提到以单机模式启动服务器。这意味着需要重新启动成员，使其成员单机运行的服务器，而不再是一个副本集的成员（只是临时的）。 保持dbpath不间，因为以这种方式重启是为了对这台服务器的数据进行一些操作。 # 查看用于启动的命令行选项 db.serverCmdLineOpts() # 关闭服务器 db.shutdownServer() # 以单机而不是副本启动 /path/bin/mongod --port 新端口 --dbpath /var/lib/db 当完成了对服务器的维护后，可以使用原始的副本集选项重启启动它。重启之后，它会自动与副本集的其它成员进行同步。复制它在离开期间错过的所有操作。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:28:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"副本集配置 副本集配置总是保存在local.system.replset集合的文档中。这个文档在副本集的所有成员上都是相同的。不要使用update更新这个文档，应该使用rs辅助函数或replSetReconfig命令。 \r可以通过重新配置来修改成员的设置。修改成员设置时有一些限制： 不能更改成员的_id字段； 不能将接收重新配置命令的成员（通常是主节点）的优先级设置为0； 不能把仲裁者变为非仲裁者，反之亦然； 不能将成员的buildIndexed字段从false改为true。 \r副本集成员最多只能有50个成员，其中只有7个成员拥有投票权。这是为了减少每个成员发送心跳所需的网络流量，并限制选举所需的时间。 如果要创建一个超过7个成员的副本集，那么额外的成员都必须被赋予0投票权(\"votes\": 0)，使这些成员无法在选举中投票。 # 创建副本集 var config = { \"_id\": 副本集名称, \"members\": [ {xxxx}, {xxx}, ] } # 只需要对副本集中的一个成员调用rs.initiate()。接受配置的成员将把配置传递给其他成员。 rs.initiate(config) # 更改副本集成员 rs.add() # rs.remove() var config = rs.confg() config.members[2].host = \"xxxx\" rs.reconfig(config) # 无投票权的节点 rs.add({\"_id\": 7, \"host\": \"server-7:27017\", \"votes\": 0}) \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:29:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"控制成员状态 有多种方式可以手动控制成员的状态，以进行维护或应对负载的变化。需要注意，无法强制一个成员成为主节点，只能对副本集进行适当的配置，即为副本集成员设置高于任何其他成员的优先级。 # 把主节点降级为从节点 # 使主节点降级为从并维持60s rs.stepDown() # 指定秒为单位的时间 rs.stepDown(300) # 阻止选举 # 以秒为单位 # 强制让成员保持为从节点 rs.freeze(600) # 释放，也可以使用此命令将已退位的主节点解冻 rs.freeze(0) \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:30:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"监控复制 能够监控副本集的状态是很重要的，不仅要监控所有成员是否启动，还要监控它们所处的状态以及数据的新旧程度。 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:31:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"获取状态 replSetGetStatus或rs.status()命令可以获取副本集成员的当前信息。下面是一些有用的字段： self stateStr: 状态字符串 uptime: 从成员可被访问一直到现在所经历的秒数 optimeDate：每个成员的oplog中最后一个操作发生的时间 lastHeartbeat：此服务器最后一次收到来自self这个成员心跳的时间 pingMs：心跳达到此服务器的平均时间，这用于确定要从哪个成员进行同步 errmsg：成员在心跳请求中选择返回的状态信息 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:31:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"可视化复制图谱 如果在从节点上运行rs.status()，则会有一个名为syncingTo的顶级字段，它表示成员正从哪个成员复制数据。MongoDB会根据ping的时间来决定同步源。 自动复制链(automatic replication chaining)有一个缺点：更多的复制链节点意味着将写操作复制到复制到所有服务器需要更长的时间。 MongoDB的复制路径可能会变成一条线（虽然可能性很低），复制链中的每个节点都比它前面的从节点落后一些。可以使用replSetSyncFrom命令(rs.syncFrom())修改成员的复制源来解决这个问题。 # 从节点修改复制源 secondary.adminCommand({\"replSetSyncFrom\": \"server-0:27017\"}) \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:31:2","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"复制循环 当几个成员彼此进行复制时，就发生了复制循环。 当成员自动选择同步源时，复制循环是不可能发生的。不过，使用replSetSyncFrom命令可能会强制复制循环发生。在手动更改同步目标之前，请仔细检查rs.status()的输出，注意不要造成循环。 当选择的同步成员并不比自身领先之时，replSetSyncFrom命令会给出警告，但仍然允许这样做。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:31:3","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"禁用复制链 链式复制指一个从节点从另一个从节点（而不是主节点）进行同步。可以禁用复制链，通过将chainingAllowed设置为false（默认为true），强制每个成员从主节点进行同步。如果主节点不可用，那么它们就会从其它从节点同步数据。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:31:4","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"计算延迟 对于复制来说，最重要的指标之一就是从节点和主节点之间的延迟情况。**延迟(lag)**是指从节点相对于主节点的落后程度，也就是主节点执行的最后一个操作的时间戳与从节点应用的最后一个操作的时间戳之间的差值。 # 可以使用下列命令来查看成员的复制状态 rs.status() rs.printReplicationInfo() rs.printSlaveReplicationInfo() \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:31:5","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"调整oplog大小 应该将主节点的oplog长度视为维护工作的时间窗口。如果主节点的oplog长度是一小时，那么就只有一小时的时间来修复所有的问题。因此，你通常会希望oplog可以保存几天到一周的数据据，以便在出现问题时给自己一些应对的空间。 要增加oplog的大小，请执行以下步骤。 连接到副本集 查看local库中oplog的当前大小 更改oplog的大小 如果减少了oplog的大小，可能需要运行compact命令来回收被分配出来的磁盘空间。不要对主节点运行此命令。 use local # 以MB显示 db.oplog.rs.stats(1024*1024).maxSize # 更改为16000M db.adminCommand({replSetResizeOplog: 1, size: 16000}) 一般情况下，不应该减少oplog的大小。oplog不会占用有价值的像RAM或CPU这样的资源，只要有足够的磁盘空间来容纳它即可。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:31:6","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"创建索引 如果向主节点发送创建索引的命令，那么主节点会正常创建索引，然后从节点会在复制创建索引这条操作时进行索引的创建。 索引创建是资源密集型操作，可能会导致成员不可用。如果所有从节点同时创建索引，那么副本集中的大部分成员将处于离线状态，直到索引创建完成。这个过程只适用于副本集。 \r 注意: 在创建unique索引时，必须停止对集合的所有写操作。如果没有停止写操作，那么整个副本集成员的数据可能会不一致。 \r因此，你可能希望一次只在一个成员上创建索引，以最小化对应用程序的应用。步骤如下： 关闭一个从节点 将其以单机模式重新启动 在单机服务器上创建索引 当索引创建完成后，以副本集成员的身份重新启动服务器 对其他从节点执行上述步骤 副本集中除了主节点以外的每个成员都成功创建了索引。现在你有两个选择，应该根据实际情况选择对生产环境影响最小的那个： 在主节点上创建索引。如果系统有一段流量较少的空闲期，那么这可能是一个很好的创建索引的时机。你还可能修改读偏好，以便在创建过程中临时将更多负载分流到从节点。主节点仍然会把索引创建命令复制到从节点，但由于从节点已经有了这些索引，因此这不会产生任何操作。 将主节点退位为从节点，然后按照前面描述的步骤操作。 如果要创建唯一索引，请确保主节点中没有插入重复的数据，或者应该首先在主节点上创建索引。否则，主节点可能会插入重复数据，这将导致从节点上的复制错误。如果发生这种情况，那么从节点会自动关闭。你必须将其作为单机服务器重新启动，删除唯一索引，然后重新启动它。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:31:7","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"在预算有限的情况下进行复制 如果预算有限，不能购买多台高性能服务器，则可以考虑将从节点服务器只用于灾难恢复，这样的服务器不需要太高的配置。始终将高性能服务器作为主节点，便宜的服务器不处理任何客户端流量（配置客户端所有请求发送到主节点）。 可以为这样的从节点配置以下选项： # 节点永远不会成为主节点 \"priority\": 0 # 客户端不会向此从节点发送请求 \"hidden\": true \"buildIndexes\": false \"votes\": 0 \r \r分片 本章介绍如何扩展MongoDB，包括： 分片和集群组件 如何配置分片 分片与应用程序的交互 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:31:8","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"什么是分片 分片是指扩机器拆分数据的过程，有时也用术语分区(partitioning)。 通过在每台机器上防止数据的子集，无须功能强大的机器，只使用大量功能稍弱的机器，就可以存储更多的数据并处理更多的负载。分片还可以用于其他目的，包括将经常访问的数据放置在更高性能的硬件上，或基于地理位置来拆分集合中的文档以使它们接近最常对其进行访问的应用服务器。 无论从开发还是运维的角度来看，分片都是最复杂的MongoDB配置。在使用分片集群之前，应该首先熟悉单机服务和副本集。 \r可以在单台机器上快速启动一个分片集群，然后使用ShardingTest类创建集群。 mongo --nodb --norc st = ShardingTest({ name: \"one-min-shards\", chunkSize: 1, shards: 2, rs: { nodes: 3, oplogSize: 10 }, other: { enableBalancer: true } }); \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:32:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"理解集群组件 注意 许多人对复制和分片感到困惑。复制是在多台服务器上创建了数据的精确副本，因此每台服务器都是其他服务器的镜像。而每个分片包含了不同的数据子集。 MongoDB的分片机制允许你创建一个由许多机器（分片）组成的集群，并将集合中的数据分散在集群中，在每个分片上放置数据的一个子集。这允许应用程序超出超级服务器或副本集的资源限制。 记住，分片的主要使用场景是拆分数据集以解决硬件和成本的限制，或为应用程序提供更好的性能。 MongoDB分片集群的几个组件： mongos: 路由服务器。 mongod config server：配置服务器 mongod: 分片副本集 路由服务器知道哪些数据在哪个分片上，可以将请求转发到适当的分片。如果有对请求的响应，路由服务器会收集它们，并在必要时进行合并，然后在发送回应用程序。mongos读取的信息都位于config server中。 你不需要知道任何关于分片的信息，比如有多少个分片或它们的地址是什么。只要有分片存在，就可以将请求发送给mongos，并允许其转发到合适的分片上。 启用均衡器可以确保数据均匀分布在两个分片上。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:33:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"进行分片 可以使用sh.status()来获得集群的总体视图。此命令会提供一个分片、数据库以及集合的摘要。 MongoDB现在还不能自动分发数据，因为它不知道你希望如何或者是否进行分发。你必须明确指出，在每个集合中应该如何分布数据。 要对一个特定的集合进行分片，首先需要在集合的数据库上启用分片。 在对集合进行分片时，需要选择一个片键(shard key)。片键是MongoDB用来拆分数据的一个或几个字段。 如果选择在username字段上分片，MongoDB就会根据用户名的范围对数据进行拆分。如a1-xxx到defcon，defcon1到hohaha1998，等等。可以将选择一个片键看作为集合中的数据选择一个排列顺序。这与索引的概念类似，也十分合理。 随着集合的增大，片键会成为集合中最重要的索引。只有创建了索引的字段才能够作为片键。选择片键需要仔细斟酌。 # 对accounts数据库启动分片 sh.enableSharding(\"accounts\") # 现在可以对accounts数据库中的集合进行分片了 # 在启用分片之前，必须在想要分片的键上创建一个索引 db.users.createIndex({\"username\": 1}) # 现在通过username来对集合进行分片 sh.shardCollection(\"accounts.users\", {\"username\": 1}) 可以看到集合被分成了多少块，每个块是数据的一个子集。这些是按照片键范围排列的。 # 数据库范围 # \"on\": shard部分 表示分布在那个分片上 {\"username\": minValue} --\u003e\u003e {\"username\": maxValue} 在分片之前，集合实际上是一个单独的块。分片根据片键将其拆分成更小的块(chunk)。 注意块列表开始和结束的键，即$minKey和$maxKey。minKey可被认为是负无穷，这个值比MongoDB中的其他值都要小。类似地，maxKey相当于正无穷，它比任何其它值都要打。因此，总会在块范围中看到这两个极值。片键的值始终位于这两者之间。 这两个值实际上是BSON类型，不应该用在应用程序中，它们主要是供内部使用。如果希望在shell中引用它们，可以使用MinKey和MaxKey常量。 \r现在可以使用explain来看看MongoDB在幕后是如何处理的。通常来说，如果在查询中没有使用片键，mongos就不得不将查询发送到所有分片上。 db.usrs.find({username: \"user12345\"}).explain() 包含片键并可以发送到单个分片或分片子集的查询称为定向查询(targeted query)。必须发送到所有分片的查询称为分散-收集查询(scatter-gather query)，也称为广播查询：mongos会将查询分散到所有分片，然后再从各个分片收集结果。 \r \r配置分片 主要介绍： 如何创建配置服务器、分片以及mongos进程 如何增加集群的容量 数据是如何存储和分布的 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:34:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"何时分片 通常情况下，分片用于： 增加可用RAM 增加可用磁盘空间 减少服务器的负载 处理单个mongod无法承受的吞吐量 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:35:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"启动服务器 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:36:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"配置服务器 配置服务器(configsvr)是集群的大脑，保存在关于每个服务器包含哪些数据的所有元数据。因此，必须首先创建配置服务器。configsvr选项向Mongod表明将其用作配置服务器。在运行此选项的服务器上，除了config和admin库之外，客户端不能对任何其他数据库写入数据。 由于配置服务器所保存的数据非常重要，因此必须确保它在运行时启用了日志功能，并确保它的数据存储在非临时性的驱动器上。在生产环境中，配置服务器副本集至少应该包含3个成员（一主两从），每个配置服务器应该位于单独的物理机器上。 admin数据库包含了与身份认证和授权相关的集合，以及其他以system.*开头的集合以供内部使用。 config数据库包含了保存分片集群元数据的集合。在元数据发生变化（比如数据块迁移、数据块拆分等）时，MongoDB会将数据写入此库。 当对配置服务器进行写入时，MongoDB会使用majority的writeConcern级别。类似地，当从配置服务器读取数据时，MongoDB会使用majority的readConcern级别。这确保了分片集群元数据在不发生回滚的情况下才会被提交到配置服务器副本集。它还确保了只有那些不受配置服务器故障影响的元数据才能被读取。这可以确保所有mongos路由节点对分片集群中的数据组织方式具有一致的看法。 \r 如果所有配置服务器都丢失了，那么你必须对分片上的数据进行分析，以确定数据的位置。这是可以做到的，但过程缓慢且令人厌烦。应该经常备份配置服务器的数据。在执行任何集群维护之前，应该总是对配置服务器进行备份。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:36:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"mongos进程 在三个配置服务器都运行后，启动一个或多个mongos进程以供应用程序进行连接。mongos进程需要知道配置服务器的地址，因此需要使用configdb配置项。 默认情况下，mongos运行在27017端口上。注意，不需要指定数据目录（mongos本身没有数据，它在启动时从配置服务器加载集群配置） 应该启动一定数量的mongos进程，确保高可用。并尽可能将其放在靠近所有分片的位置。这样可以提高需要访问多个分片或执行分散-收集操作时的查询性能。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:36:2","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"将副本集转换为分片 分片集群的分片mongod实例必须指定shardsvr配置项。创建一个分片实例的副本集（如rs0）。 然后连接到mongos添加分片: sh.addShard(\"rs0/mongo1:port,mongo2:port,mongo3:port\") 集合名rs0被用作 这个分片的标识符。如果想删除这个分片或将数据迁移到其中，可以使用rs0来对其进行标识。 将副本集作为分片添加到集群中后，就可以将应用程序从连接到副本集修改为连接到mongos了。在添加这个分片时，mongos会将副本集中的所有数据库注册为分片所拥有的数据库，因此它会将所有的查询发送到新分片上。mongos还会像客户端一样自动处理应用程序的故障转移，也同样会将错误返回。 \r 在添加分片之后，必须设置所有客户端将请求发送到mongos而不是副本集。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:36:3","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"增加集群容量 如果需要更多的容量，则可以添加更多的分片。要添加新的分片，可以先创建一个副本集。确保副本集与任何其他分片具有不同的名称。然后通过mongos运行addShard命令将其加入到集群中。 如果有几个现有的副本集不是分片，那么只要没有任何同名的数据库，就可以将它们全部作为新分片添加到集群中。如果有一个副本集，库名与分片中的库名冲突，那么mongos将拒绝将其添加到集群中。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:36:4","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"数据分片 只有在明确制定了规则之后，MongoDB才会对数据进行拆分。在希望对数据进行拆分时，必须明确地告知数据库和集合。 // 为数据库启用分片 sh.enableSharding(\"testdb\") // 对集合进行分片 sh.shardCollection(\"testdb.users\", {\"name\": 1}) 现在users集合会按照name键分片，如果是对一个已经存在的集合进行分片，则必须在name字段上有索引，否则，shardCollection调用将返回错误。如果出现了错误，则需要先创建索引，并重新运行shardCollection命令。 如果要分片的集合还不存在，则mongos会自动在片键上创建索引。 shardCollection命令会将集合拆分成多个数据块，这些块是MongoDB用来移动数据的单元。一旦命令成功返回，MongoDB就会开始在集群中的分片间均匀地分散聚合中的数据。这个过程不是瞬间完成的。对于大型集合来说，完成这一初始平衡可能需要数小时。这段时间可以通过预拆分来缩短。即在加载数据之前，预先在分片上创建数据块。之后加载的数据就会直接插入当前分片，而不再需要额外的平衡。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:36:5","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"MongoDB如何追踪集群数据 每个mongos都必须能够根据给定的片键来找到一个文档。理论上，MongoDB可以跟踪每个文档的位置，但对于包含数百万或数十亿的集合来说，这种方式会变得难以处理。因此，MongoDB会将文档以数据块形式进行分组，这些数据块是片键指定范围内的文档。块总是存在于分片上，因此MongoDB可以用一个较小的表来维护数据块和分片的映射。 如果一个用户集合的片键是{\"age\": 1}，那么某个块可能是有所有age字段在3和17之间的文档组成。如果mongos收到一个{\"age\": 5}的查询，那么它就可以将该查询路由到该块所在的分片上。 \r 块与块之间的范围不能重叠。 一个文档总是术语且仅术语一个块。这条规则意味着，不能使用数组字段作为片键，因为MongoDB会为数组创建多个索引项。 一旦一个块增长到一定的大小，MongoDB就会自动将它分成两个更小的块。 一个常见的误解是，同一个块的数据应保存在磁盘的同一片区域中。这是不正确的。块对mongod如何存储集合中的数据没有影响。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:37:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"块范围 每个块都是由它所包含的文档范围来描述的。新分片的集合起初只有一个块，所有文档都位于这个块中。该块的边界从负无穷($minKey)到正无穷($maxKey)。 随着块的增长，MongoDB会自动将其拆分为两个块，范围分别是从负无穷到某个值，某个值到无穷大。这里的某个值被称为拆分点(split point)。 块信息存储在config.chunks集合中。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:37:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"拆分块 各个分片的主节点mongod进程会跟踪它们当前的块，一旦达到某个阈值，就会检查该块是否需要拆分。如果该块确实需要拆分，那么mongod会从配置服务器请求全局块大小配置值，然后执行块拆分并更新配置服务器上的元数据。配置服务器会创建新的块文档，并修改旧块的范围。如果该块位于分片顶部，则mongod会请求均衡器将其移动到其他分片上。这种方式 是为了防止在片键单调递增的情况下，某个分片成为热点。 因此，拥有不同的片键值很重要。 如果mongod试图进行拆分时其中一个配置服务器停止运行，那么mongod将无法更新元数据。在进行拆分时，所有的配置服务器都必须启动并可以识别。如果mongod不断收到对一个块的写请求，则它会持续尝试拆分该块失败。只要配置服务器没有处于健康状态，拆分就无法继续，而所有这些拆分尝试都会拖慢mongod和涉及的分片。 mongod反复尝试分裂某个块却无法成功的过程成为拆分风暴(split storm)。防止拆分风暴的唯一方法是确保配置服务器尽可能正常运行。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:37:2","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"均衡器 **均衡器(balancer)**负责数据的迁移。它会定期检查分片之间是否存在不均衡，如果存在，就会对块进行迁移。 在MongoDB v3.4之后的版本中，均衡器位于配置服务器副本集的主节点成员上。在MongoDB v3.4及之前的版本中，每个mongos会偶尔扮演均衡器的角色。 均衡器是配置服务器副本集主节点上的后台进程，它会监视每个分片上的块数量。只有当一个分片的块数量达到特定迁移阈值时，均衡器才会被激活。 假设一些集合已经达到了阈值，则均衡器会开始对块进行迁移。它会从负载较大的分片中选择一个块，并询问该分片是否应该在迁移之前对块进行拆分。在完成必要的拆分后，就会将块迁移到具有较少块的机器上。 使用集群的应用程序不需要感知数据的迁移：所有读写请求都会路由到旧的块上，知道迁移完成。一旦元数据被更新，任何试图访问旧位置数据的mongos进程都会收到一个错误。这个错误对客户端是不可见的，mongos会默默地处理这个错误并在新的分片上重试此操作。 有时可能会在mongos日志中看到\"unable to setShardVersion\"的信息，这是一个常见的错误。当mongos收到这种类型的错误时，它会从配置服务器查找数据的新位置，并更新块分布表，然后重新执行之前的请求。如果成功从新位置检索到数据，则会将数据返回给客户端，就像没有发生过任何错误一样。 如果mongos因配置服务器不可用而无法检索到新块的位置，则它会向客户端返回一个错误。这也是让配置服务器始终处于正常运行状态非常重要的另一个原因。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:37:3","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"排序规则 MongoDB中的排序规则允许指定特定于语言的字符串比较规则。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:38:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"变更流 **变更流(change stream)**允许应用程序跟踪数据块中数据的实时变更。 \r \r选择片键 使用分片时最重要的任务是选择数据的分发方式。必须了解MongoDB是如何分发数据的。包括： 如何在多个可用的片键中做出选择 不同使用场景中的片键选择 哪些键不能作为片键 自定义数据分发方式的可选策略 如何手动对数据分片 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:39:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"评估使用情况 注意: 一旦对一个集合进行了分片，就不能更改片键了。 在对集合进行分片时，需要选择一两个字段来对数据进行拆分。这个键（这些键）称为片键。一旦对一个集合进行了分片，就不能更改片键了。因此正确选择片键是十分重要的。 对于计划分片的每个集合，首先回答以下问题： 计划进行多少个分片? 3个分片的集群比100个分片的集群具有更大的灵活性。随着集群的增长，不应该使用会触发所有分片的查询，因此大部分查询应该包含片键。 分片是为了减少读写延迟吗？降低写延迟通常包括将请求发送到地理位置更近或功能更强大的机器上。 分片是为了提高读写的吞吐量吗？（吞吐量指集群在同一时间可以处理的请求数量。）提高吞吐量通常需要增加更多的并行化，并确保请求在集群中均匀分发。 分片是为了增加系统资源吗？如果这样，你可能希望保持工作集尽可能小。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:40:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"描绘分发情况 最常见的数据拆分方式是升序片键、随机分发的片键和基于位置的片键。 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:41:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"升序片键 升序片键通常类似与date字段或ObjectId，随着时间稳步增长的字段。自增主键是升序字段的另一个例子。 最大块(max chunk)，持续增长，并被拆分成多个块。 这种模式通常会使MongoDB更难保持块的均衡，因为所有的块都是由一个分片创建的。因此，MongoDB必须不断地将数据块移动到其它分片上，而不能像在一个更均匀分发的系统中那样，只纠正一些可能出现的比较小的不均衡。 在MongoDB 4.2中，自动拆分的功能被移动到了分片主节点的mongod中，这增加了对顶部数据块的优化，从而得以解决升序片键模式的问题。均衡器会决定在哪个分片中放置顶部块。这有助于避免在一个分片上创建所有新块的情况。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:41:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"随机分发的片键 随机分发的片键可以是用户名、电子邮件、UUID、MD5哈希值或数据集中没有可识别模式的任何其它键。 随着更多的数据被插入，数据的随机性意味着新插入的数据应该相当均匀地名中每个块。 由于写操作是随机分发的，因此分片应该以大致相同的速度增长，从而减少需要进行的迁移操作数量。 随机分发片键的唯一缺点是MongoDB在随机访问超出RAM大小的数据时效率不高。但是，如果有足够的资源或者不介意性能影响，那么随机片键可以很好地在集群中分配负载。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:41:2","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"基于位置的片键 基于位置的片键可以是用户的IP、经纬度或地址。无论如何，基于位置的键就是将具有某些相似性的文档根据这个字段划分进同一个范围。这对于将数据放在离用户很近的地方以及将相关数据保存在磁盘的同一块区域中都很方便。MongoDB使用区域分片(zoned sharding)对其进行管理。 在MongoDB 4.0.3以上版本中，可以在对集合进行分片之前定义区域以及区域的范围，这回针对区域范围和片键的值填充数据块，并执行他们的初始块分配。这大大降低了分片区域设置的复杂性。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:41:3","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"片键策略 为各种类型的应用程序提供一些片键选择。 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:42:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"哈希片键 为了尽可能快地加载数据，哈希片键是最好的选择。哈希片键可以使任何字段随机分发。因此，如果打算在大量查询中使用升序键，但又希望写操作随机分发，那么哈希片键是不错的选择。 不过，我们永远都无法使用哈希片键执行指定目标的范围查询。如果不打算执行范围查询，那么哈希片键是一个很好的选择。 # 要创建哈希片键，首先需要创建一个哈希索引 db.users.createIndex({\"username\": \"hashed\"}) # 接下来对集合进行分片 sh.shardCollection(\"app.users\", {\"username\": \"hashed\"}) 使用哈希片键有一些限制。首先，不能使用unique选项。其次，与其他片键一样，不能使用数组字段。最后，浮点型的值在哈希之前会被取整，因此1和1.9999会被哈希定义为相同的值。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:42:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"GridFS的哈希片键 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:42:2","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"消防水管策略 如果有一些服务器比其他服务器更强大，那么你可能希望让它们处理更多的负载。可以强制将所有新数据插入功能更强大的分片中，然后让均衡器将旧的块移动到其他分片上。这样可以提供较低的写入延迟。 这种策略的另一个缺点是需要一些变更来进行扩展。如果最强大的服务器无法再写入的数量，则没有简单的方法可以再这台服务器和另一台服务器之间分配负载。 如果没有高性能的服务器，或者没有使用区域分片，就不要使用升序键作为片键。这样做会将所有写操作都路由到同一个分片上。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:42:3","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"多热点 创建多个热点，以便写操作在集群中均匀分发，但在同一个分片中的写操作是递增的。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:42:4","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"片键规则和指导方针 确定要分片的键并创建片键会让人想起索引，因为这两个概念是相似的。事实上，通常你的片键可能就是你最常使用的索引（或索引的一些变体）。 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:43:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"片键的限制 片键不能是数组。如果任何键有数组值，那么sh.shardCollection()就会失败，并且将数组插入该字段是不允许的。 文档在插入之后，起片键值可能会被修改，除非片键字段是不可变的_id字段。在MongoDB4.2之前的旧版本中，是不可以修改文档的片键值的。 大多数特殊类型的索引不能用作片键。特别是，不能在地理空间索引上进行分片。如前所述，允许使用哈希索引作为片键。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:43:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"片键的基数 无论片键是跳跃的还是稳定增长的，选择值会发生变化的键很重要。 与索引一样，在高基数字段上进行分片的性能会更好。如果一个logLevel键只有DEBUG, WARN和ERROR这几个值，则MongoDB无法将数据拆分成3个以上的块（因为片键只有3个不同的值）。如果想把一个变化不大的值用作片键，那么可以使用改键和另一个拥有多样值的键组成一个复合键。比如logLevel和timestamp。 重要的是，键的组合要具有很高的基数。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:43:2","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"控制数据分发 也就是手动控制分发。 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:44:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"对多个数据库和集合使用一个集群 向MongoDB明确指定你希望数据被保存的位置。 使用sh.addShardToZone()辅助函数。如将不同的集合分配给不同的分片（重要的数据集合分配到高性能的服务器，低价值的数据集合分配到低性能的服务器）。 为集合指定区域键范围不会立即生效。它只是给均衡器一条指令，说明当它运行时，可以将集合移动到这些目标分片上。 如果出现失误或改变了注意，可以使用sh.removeShardFromZone()从区域中删除分片。 如果从某个区域键范围内的区域中移除了所有分片，则均衡器不会再将数据分发到任何地方，因为没有任何位置是有效的。所有数据仍然是可读且可写的，除非修改标签或标签范围，否则它无法呗迁移到其他位置。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:44:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"手动分片 如果不希望对数据进行自动分发，可以关闭均衡器，并使用moveChunk命令手动分发数据。 # 禁用均衡器 # 连接到mongos sh.stopBalancer() 如果当前正在进行迁移，则此设置在迁移完成之前不会生效。然而，一旦正在进行的迁移完成，均衡器就会停止移动数据。 然而，除非遇到特殊情况，否则应该使用MongoDB的自动分片而不是手动分片。如果某个分片上出现了一个预料之外的热点，那么大部分数据可能会出现在这个分片上。 尤其不要再均衡器开启时手动进行一些不寻常的分发。如果均衡器检测到块的数量不均匀，那么它回对数据进行调整和重新分发，使集合再次均衡。 \r \r分片管理 手动管理分片集群，包括一下几项内容： 检查集群状态：集群有哪些成员，数据保存在哪里？哪些连接是打开的？ 添加、删除以及修改集群的成员 管理数据移动和手动移动数据 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:44:2","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"查看当前状态 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:45:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"查看摘要信息 # 提供了分片、数据库以及分片集合的概要信息 # 它显示的所有信息都是从config数据库中收集的 sh.status() \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:45:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"查看配置信息 分片集群的所有配置信息都保存在配置服务器(configsvr)的config数据库中。 通常来说，不应该直接更改config数据库中的任何数据。如果确实修改了，也需要重启所有的mongos进程才能看到效果。 config数据库中的一些集合: config.shards: shards集合会跟踪集群中的所有分片 config.databases: databases集合会跟踪集群所知道的所有数据库，既包括分片数据库，也包括非分片数据库 config.collections: collections集合会跟踪所有分片集合的信息，不显示非分片集合 config.chunks: chunks集合会保存集合中每个块的记录 config.changelog: changelog集合对于跟踪集群的当前操作非常有用，它记录了所有已经发生的拆分和迁移 \r db.shards.find() { \"_id\": \"shard01\", \"host\": \"shard01/h1:p1,h2:p2,h3:p3\", \"state\": 1 } { \"_id\": \"shard02\", \"host\": \"shard02/h1:p1,h2:p2,h3:p3\", \"state\": 1 } ... _id是从副本集名称中获取的，因此集群中的每个副本集必须有一个唯一的名称。 \r db.databases.find() { \"_id\": \"video\", \"primary\": \"shard02\", \"partitioned\": true, \"version\": { \"uuid\": UUID(\"xxx-xx-xxx\"), \"lastMod: 1} } 如果已经在数据库上运行过enablesharding，则partitioned字段将为true。primary是数据库的主基地。默认情况下，数据库中的所有新集合都会在数据库的主分片上创建。 \r db.collections.find().pretty() { \"_id\": \"config.system.session\", \"lastmodEpoch\": ObjectId(\"xxxx\"), \"lastmod\": ISODate(\"1970-02-xxxx\"), \"dropped\": false, \"key\": { \"_id\": 1 }, \"unique\": false, \"uuid\": UUID(\"xxxxx\") } ... _id 集合的命名空间 key 片键 unique 表明片键是否是唯一索引 \r db.chunks.find().skip(1).limit(1).pretty() { \"_id\": \"video.movies-imdbId_MinKey\", \"lastmod\": Timestamp(2, 0), \"lastmodEpoch\": ObjectId(\"xxxxx\"), \"ns\": \"video.movies\", \"min\": { \"imdbId\": { \"$minKey\": 1} }, \"max\": { \"imdbId\": NumberLong(\"-xxxxxx\") }, \"shard\": \"shard01\", \"history\": [ { \"validAfter\": Timestamp(xxxx, xxx), \"shard\": \"shard01\" } ] } _id 块的唯一标识符。通常包括命名空间、片键和块的下边界值 ns 块所属集合名称 min 块范围的最小值 max 块中的所有值都小于这个值 shard 块所属的分片 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:45:2","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"跟踪网络连接 集群组件之间有大量连接。 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:46:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"获取连接统计 connPoolStats命令返回从当前数据实例到分片集群或副本集其他成员的连接信息。 db.adminCommand({\"connPollStats\": 1}) totalAvailable显示了从当前mongod或mongos实例向分片集群或副本集其他成员的可用传出连接总数 totalCreated报告了当前mongod或mongos实例向分片集群或副本集其他成员创建的传出连接总数 totalInUse提供了从当前mongod或mongos实例向当前正在使用的分片集群或副本集其他成员的传出连接总数 totalRefreshing显示了从当前mongod或mongos实例向当前正在刷新的分片集群或副本集其他成员的传出连接总数 numClientConnections标识了了从当前mongod或mongos实例向分片集群或副本集其他成员的活动并被保存的传出同步连接数量 numAScopedConnection报告了从当前mongod或mongos实例向分片集群或副本其他成员的活动并被保存的传出作用域同步连接数量 pools显示了按连接池分组的连接统计信息（正在使用/可用/已创建/刷新）。mongod或mongos有两个不同的外传连接池 基于DBClient的连接池 基于NetworkInterfaceTL的连接池 hosts显示了按主机分组的连接统计信息。它报告了当前mongod或mongos实例与分片集群或副本集每个成员之间的连接。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:46:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"限制连接数量 当客户端连接到mongos时，mongos会创建一个连接，此连接至少会连接到一个分片以传递客户端的请求。因此，每个连接到mongos的客户端至少会产生一个从mongos到分片的传出连接。 如果有多个mongos进程，则可能会创建超过分片处理能力的连接。默认情况下，一个mongos(mongod)可以接受65535个连接。可以在mongos配置中使用maxConns选项来限制其可以创建的连接数。 一个分片可以处理的单个mongos的最大连接数公式: $$maxConns = maxConnsPrimary - (numMembersPerReplicaSet * 3) - \\frac{(other * 3)}{numMongosProcesses}$$ # 主节点上的最大连接数，通常为20000，避免mongos的连接冲垮分片 maxConnsPrimary # 主节点会与每个从节点创建一个连接，而每个从节点会与主节点创建两个连接，所以总共有3个连接 numMembersPerReplicaSet*3 # 指可能连接到mongos的各种进程的数量 other*3 # 分片集群中mongos的总数 numMongosProcesses \r注意，maxConns只会阻止mongos创建超过这个数量的连接。当达到这个限制时，它不会做任何有帮助的事情，它只会阻塞请求，并等待连接被释放。因此，必须防止应用程序使用这么多的连接，特别是mongos进程的数量不断增长时。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:46:2","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"服务器管理 如何添加和删除服务器。 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:47:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"添加服务器 可以在任何时候添加mongos进程，确保配置正确的配置服务器地址就行。 可以使用addShard命令添加新的分片。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:47:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"修改分片中的服务器 要更改一个分片的成员，需要直接连接到该分片的主节点（不是通过mongos，而是连接到副本的主节点），重新配置副本集。集群配置会检测到变更并自动更新config.shards，不要手动修改config.shards。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:47:2","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"删除分片 通常来说，不应该从集群中删除分片。如果经常添加和删除分片，则会给系统带来不必要的压力。如果添加了过多的分片，那么最好让系统增长到这些分片的体量，而不是先删除分片然后等需要时再添加。 首先确保均衡器时打开的。均衡器的任务是把要删除分片上的所有数据移动到其他分片上，这个过程称为排空(draining)。要排空数据，可以运行removeShard命令，将该分片上的所有块移动到其他分片上。 db.adminCommand({\"removeShard\": \"shard03\"}) # 再次运行此命令来获得当前的状态 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:47:3","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"数据均衡 通常来说，MongoDB会自动处理数据均衡。本节介绍如何启用和禁用自动均衡，以及如何干预均衡的过程。 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:48:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"均衡器 关闭均衡器时大部分管理操作的先决条件。 sh.setBalancerState(false) 随着均衡器被关闭，新的均衡器流程将不会再开始，但是关闭均衡器不会迫使正在进行的均衡过程立即停止，也就是说，迁移过程通常不能立即停止。因此，应该检查config.locks集合以查看是否仍有均衡过程正在进行。 db.locks.find({\"_id\": \"balancer})[\"state\"] # 0 表示均衡器已关闭 均衡过程会增加系统的负载，目标分片必须查询源分片块中的所有文档，将文档插入目标分片的块中，然后源分片必须删除这些文档。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:48:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"修改块的大小 默认情况下，块的大小为64MB。块大小的取值范围在1MB到1024MB。 这是一个集群范围的设置，它会影响所有的集合和数据库。如果MongoDB的迁移过于频繁或所使用的文档太大，则可能需要增加块的大小。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:48:2","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"移动块 可以使用moveChunk辅助函数对块进行手动移动。必须使用片键来查找要移动的块。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:48:3","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"超大块 当一个块大于config.settings中设置的最大块大小时，均衡器就不允许移动这个块了。这些不可拆分、不可移动的块被称为超大块(jumbo chunk)，这种块非常难以处理。 在使用sh.status()查看时，超大块会被标记具有jumbo属性。 sh.status() ... { \"x\": -7 } --\u003e\u003e { \"x\": 5 } on : shard001 { \"x\": 5 } --\u003e\u003e { \"x\": 6} on : shard0001 jumbo ... 要修复因超大块而引起的集群不均衡，就必须将超大块均匀地分配到各个分片中。 对于超大块的问题，应该优先避免这种情况的出现。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:48:4","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"刷新配置 有时候mongos不能从配置服务器正确更新配置，则可以使用flushRouterConfig命令手动清除所有缓存。 db.adminCommand({\"flushRouterConfig\": 1}) 如果执行了上述命令仍没有解决问题，则需要重启所有的mongos或mongod进程以清除所有缓存数据。 \r \r了解程序的动态 了解MongoDB正在作什么，以及细节情况。将学到： 找出并终止慢操作 获取并解析有关集合和数据库的统计数据 使用命令行工具来获得MongoDB正在作什么的信息 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:48:5","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"查看当前操作 使用db.currentOp()函数查看正在运行的操作。 db.currentOp() ... opid: 操作的唯一标识符 active: 操作是否正在运行 secs_running: 操作的持续时间 op: 操作类型 query insert update remove desc: 客户端的标识符。这个字段可与日志中的消息相关联。 locks: 描述操作所获取的锁的类型 waitingForLock: 操作当前是否处于阻塞并等待获取锁 numYields: 操作释放锁以允许其他操作进行的次数 lockstats.timeAcquiringMicros: 操作为了获取锁所花费的时间 可以通过过滤currentOp来查找满足特定条件的操作: db.currentOp( { \"active\": true, \"sec_running\": { \"$gt\": 3 }, \"ns\": /^db1\\./ }) \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:49:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"寻找有问题的操作 db.currentOp()最常见的用途是查找慢操作。可以带条件来查找超过一定时间的查询，这些查询可能是缺少索引或对不适当的字段进行了过滤。 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:49:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"终止操作 如果找到了想要停止的操作，那么可以将opid作为参数传递给db.killOp()来终止它。 db.killOp(12345) 并不是所有的操作都能被终止，持有或等待锁的操作不能被终止。 在MongoDB 4.0中，killOp可以在mongos上运行。在以前的版本中，需要在每个分片的主节点实例上手动发出终止命令。 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:49:2","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"假象 在查找耗时过长的操作时，可能会看到结果中列出了一些长时间运行的内部操作。最常见的是复制线程和用于分片的回写监听器。任何在local.oplog.rs上长时间运行的请求以及任何回写监听命令都可以被忽略。 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:49:3","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"防止幻象操作 如果在加载数据时使用了未确认写入的机制，那么应用程序触发写操作的速度可能比MongoDB处理它们的速度更快。如果MongoDB中的请求发生了堆积，那么这些写操作将堆积在操作系统的套接字缓冲区中。当终止MongoDB正在进行的写操作时，就会让MongoDB开始处理缓冲区中的写操作。即使客户端停止发送写操作，MongoDB也会处理那些写入缓冲区的操作，因为它们已经被接收了（只是没有被处理）。 防止这些幻象写入的最好方法是执行写入确认机制，让每次写操作都等待，知道前一个写操作完成，而不是仅仅等到前一个写操作处于数据库服务器的缓冲区中就开始下一次写入。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:49:4","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"使用系统分析器 要查找速度较慢的操作，可以使用系统分析器，它会在一个特殊的system.profile集合中对操作进行记录。分析器可以提供大量关于耗时过长操作的信息，但这是有代价的。它会降低mongod的整体性能。 默认情况下，分析器是关闭的。分析级别不是持久的，重启数据库会清除级别的设定值。 db.getProfilingLevel() # 记录超过10s db.setProfilingLevel(1, 10000) {\"was\": 0, \"slowms\": 100, \"ok\": 1} db.system.profile.find().pretty() db.setProfilingLevel(0) 将slowns设置较低通常不是一个好主意。即使分析器关闭，slowms也会对mongod产生影响，因为它决定了在日志中打印慢速操作的阈值。如果将slowms设置为100，那么每个耗时超过100ms的操作都将显示在日志中，即使分析器是关闭的。因此，如果调低了slowns来分析某些东西，那么可能需要在关闭分析器之前将它重新调高。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:50:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"计算大小 为了配置正确的磁盘和RAM，了解文档、索引、集合和数据库占用了多少空间是很有用的。 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:51:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"文档大小 使用Object.bsonsize()函数获取文档大小。 Object.bsonsize(db.user.findOne()) 此方法显示出文档在磁盘上占用了多少字节。不过，这并不包括填充或索引，而二者是影响集合大小的重要因素。 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:51:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"集合大小 stats()函数可以查看整个集合的信息: db.movies.stats() { \"ns\": \"test.movies\", \"size\": \"1234567\", \"count\": 12345, \"avgObjSize\": 123, \"storageSize\": 1122334, ... } db.big.stats(1024*1024*1024) 随着集合不断增长，阅读数十亿字节或更大字节的stats输出可能会变得很困难。因此，可以传入一个缩放因子作为参数：1024表示KB, 1024*1024表示MB，以此类推。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:51:2","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"数据库大小 数据库的stats函数与集合类似: db.stats() { \"db\": \"sample_mflix\", \"collections\": 5, \"views\": 0, \"objects\": 98308, \"avgObjSize\": 819.868, \"dataSize\": 80599593, \"storageSize\": 53620736, \"numExtents\": 0, \"indexes\": 12, \"indexSize\": 47001600, \"scaleFactor\": 1, \"fsUsedSize\": 355637043200, \"fsTotalSize\": 499963174912, \"ok\": 1 } \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:51:3","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"使用mongotop和mongostat mongotop # 获取每个数据库的锁统计信息 mongotop --locks # 提供整个服务器范围的信息 # 快速了解数据库正在做什么 mongostat mongostat的输出内容: insert/query/update/delete/getmore/command: 每种操作发生次数的简单计数 flushes: 将数据刷新到磁盘的次数 mapped: 映射的内存数量，这大约等于数据目录的大小 vsize: 使用的虚拟内存数量，这通常是数据目录大小的两倍（一倍用于映射文件，一倍用于记录日志） res: 正在使用的内存数量 locked db: 在上一个时间片中锁定时间最长的数据库。这个百分比是根据数据库被锁定的时间结合全局锁被持有的时间来计算的，这意味着值可能超过100% idx miss: 导致缺页错误的索引访问百分比（由于要查找的索引条目或索引内容不在内存中，因此mongod必须到磁盘中去读取） qr/qw: 读操作和写操作的队列大小（比如有多少读操作和写操作正处于阻塞中，等待被处理） ar/aw: 有多少活跃的客户端（比如当前执行读操作或写操作的客户端） netIn: 网络传入字节数 netOut: 网络传出字节数 conn: 打开的连接数，包括传入和传出 time: 进行这些统计所花费的时间 \r \rMongoDB安全介绍 为了保护MongoDB集群及其中的数据，可以采用一下安全措施： 启用授权并执行身份验证 对通信进行加密 对数据进行加密 通过使用MongoDB对x.509的支持来配置身份验证和传输层加密，以确保MongoDB副本集中客户端和服务段之间的安全通信。 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:52:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"身份认证和授权 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:53:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"身份验证机制 在MongoDB集群上启用授权会强制进行验证，并确保用户只能执行搜全的操作，这是由用户的角色决定的。MongoDB社区版提供了对SCRAM和x.509证书验证的支持。 x.509数字证书使用了被广泛接受的x.509公钥基础设施(PKI)标准来验证公钥的所有人。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:53:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"授权 MongoDB在添加用户时，必须在指定的数据库中创建此用户。该数据库时针对此用户的身份验证数据库。对于身份验证，可以使用任何数据库（一般使用admin库）。 用户名和身份验证数据库一起作为用户的唯一标识符。然而，用户的权限并不局限在身份验证数据库中。在创建用户时，可以为其指定任何资源上（集群、库、集合）的操作权限。 MongoDB默认不启用身份验证和授权，需要显示启用它们。 配置副本集，首先在不启用认证和授权的情况下启用，然后创建用户，启用认证，重启进程。 \rMongoDB提供的内置角色： read: 读取所有非系统集合中的的数据 readWrite: 读取和修改非系统集合的数据 dbAdmin: 执行管理任务 userAdmin: 创建和修改角色及用户 dbOwner: 结合了readWrite, dbAdmin, userAdmin这三个权限 clusterManger: 对集群进行管理和监控 clusterMonitor: 为监控工具提供只读的访问权限 hostManager: 监控和管理服务器 clusterAdmin: 结合了clusterManager, clusterMonitor, hostManager, dropDatabase的权限 backup: 提供了足够的权限来备份整个实例 restore: 提供了除去system.profile集合的备份中恢复数据的权限 readAnyDatabase: 除去local和config，提供读取的权限，以及在集群上执行listDatabase的权限 readWriteAnyDatabase: 除去local和config，提供读写的权限，以及在集群上执行listDatabase的权限 userAdminAnyDatabase: 除去local和config，提供userAdmin的权限（实际上就是超级用户角色） dbAdminAnyDatabase: 除去local和config，提供adAdmin的权限，以及在集群上执行listDatabase的权限 root: 所有权限 用户自定义角色 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:53:2","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"使用x.509证书对成员和客户端进行身份验证 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:53:3","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"认证和传输层加密教程 \r \r持久性 持久性是数据库系统的一种属性，它保证了提交给数据库的写操作将永久保存在数据库中。对于MongoDB来说，需要考虑的是集群（更具体地说是副本集）级别的持久性。 本章内容： MongoDB如果通过日志(journal)机制保证副本集成员级别的持久性 MongoDB如何使用写关注(writeConcern)来保证集群级别的持久性 如何配置应用程序和MongoDB集群，以提供所需的持久性级别 MongoDB如何使用读关注保证集群级别的持久性 如何在副本集中设置事务的持久性级别 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:54:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"使用日志机制的成员级别持久性 为了在服务器发生故障时提供持久性，MongoDB使用了一种称为日志(journal)的预写式(WAL)机制。WAL是数据库系统中一种常用的持久性技术，其基本原理是，在将对数据库所作的更改应用到数据库本身之前，将对这些更改的一种表示写道持久介质（如磁盘）上。 从MongoDB4.0开始，当应用程序对副本集执行写操作时，MongoDB会使用与oplog相同的格式创建日志条目。oplog中的语句是对写操作影响的每个文档所做的实际更改的表示。因此，oplog语句很容易应用于副本集的其他成员，而无须考虑版本、硬件或副本集成员之间的其他差异。此外，每个oplog语句都是幂等的，这意味着它可以被应用任意次数，而对数据库的更改结果总是相同的。 像大多数数据库一样，MongoDB同时维护了日志和数据库文件的内存试图。默认情况下，它每50毫秒会将日志条目刷新到磁盘上，每60秒会将数据库文件刷新到磁盘上。刷新数据文件的60秒间隔称为检查点(checkpoint)。日志用于为上一个检查点以来写入的数据提供持久性。关于持久性的问题，如果服务器突然停了了，那么在其重新启动时，可以使用日志重放在关闭前没有刷新到磁盘的所有写操作。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:55:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"使用写关注的集群级别持久性 通过写关注(writeConcern)，可以指定应用程序在响应写请求时需要何种级别的确认。 \rmongodb查询语言支持为所有插入和更新方法指定写关注。假设有一个电子商务应用程序，希望确保所有的订单都是持久的。 try { db.test.insertOne( {sku: \"t111\", item: \"test ha\", quantity: 3}, {writeConcern: {w: \"majority\", wtimeout: 100}} ); } catche (e) { print (e); } 这个示例写关注表示，希望得到服务器的确认。只有当写入成功被成功复制到副本集的大多数成员时才能算成功完成。此外，如果没有在100ms内复制到大多数副本集成员，则应该返回错误。这种情况下，MongoDB不会撤销写关注超过时间限制之前成功执行的数据修改，而应该由应用程序决定如何处理这种情况下的超时。 \r还可以在写关注中使用j选项(journal)来要求对写操作的日志写入情况进行确认。 try { db.test.insertOne( {sku: \"t111\", item: \"test ha\", quantity: 3}, {writeConcern: {w: \"majority\", wtimeout: 100, j: true}} ); } catche (e) { print (e); } \r在解决持久性问题时，必须仔细评估应用程序的需求，并权衡设置对性能的影响。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:56:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"使用读关注的集群级别持久性 在MongoDB中，读关注(readConcern)允许对合适读取结果进行配置。这可以让客户端在写操作被持久化之前就看到写入的结果。读关注可以和写关注一起使用，以控制对应用程序的一致性和可用性的保证级别。 不要将读关注和读偏好(read preference)相混淆，读偏好处理从何处读取数据（默认是从主节点读取）。 读关注决定了正在读取的数据的一致性和隔离性。默认的readConcern是local，它所返回的数据不保证已经被写入了大多数承载数据的副本集成员。这可能导致数据在将来的某个时刻被回滚。majority读关注只返回被大多数副本集成员确认的持久数据。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:57:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"使用写关注的事务持久性 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:58:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"检查数据损坏 validate命令可用于检查集合是否损坏。查看数据结果中的valid字段是否为true，否则它会给出所发现数据损坏细节。 db.test.validate({full: true}) \r \r生产环境的配置 包括: 常用选项 启动和停止 安全相关的选项 日志相关的注意事项 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:59:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"启动 启动方式: 命令行参数启动 配置文件启动 MongoDB的配置文件使用YAML格式。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:60:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"停止 安全停止正在运行的MongoDB服务器和能够启动服务器一样重要。 有几种方式: 使用shutdown命令 使用kill发送信号 当在主节点运行时，shutdown命令在关闭服务器之前会将主节点退位，并等待从节点追赶上同步进度。这可以将回滚的可能性降到最低，但无法保证关闭的成功（也就是可能不会被关闭）。 # 温柔的关闭 use admin db.shutdownServer() # 强制关闭 db.adminCommand({\"shutdown\": 1, \"force\": true}) # 发送关闭信号 kill PID \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:61:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"安全性 应该尽可能严格地限制外部对MongoDB的访问。最好的方法是设置防火墙，只允许内部网络地址对MongoDB的访问。 bind_ip: 指定监听端口，内部地址最好 nounixsocket: 禁用Unix套接字的监听。如果不打算通过文件系统套接字进行连接，那么同样可以禁用此选项。 noscripting: 禁用服务器的JavaScript的执行 \rMongoDB企业版提供了数据加密的功能，但MongoDB的社区版不支持这些选项。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:62:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"SSL连接 MongoDB支持使用TLS/SSL对传输进行加密。默认情况下，连接到MongoDB的数据传输是不加密的。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:63:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"日志 默认情况下，mongod会将日志发送到标准输出。 日志级别的更改。 MongoDB默认会记录运行超过100ms的查询信息。可以通过setProfilingLevel更改此值。 logpath: 将日志发送到文件 logappend: 在使用日志文件的前提下，日志追加 \r \r监控MongoDB 包括: 内存使用情况 应用程序的性能指标 诊断复制中的问题 \r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:64:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"内存使用情况 访问内存中的数据速度很快，而访问磁盘中的数据速度会比较慢。计算机中一般会有容量小、昂贵但访问速度快的内存，以及容器大、便宜但访问速度慢的磁盘。 当请求存储在磁盘上（还不在内存中）的数据页时，系统回发生缺页错误(page fault)，并将该页从磁盘复制到内存中。然后就可以快速地访问内存中的数据页了。如果程序没有定期使用该页的内容，并且内存又被其他页占满，那么旧页就会从内存中呗清除，只存在于磁盘上。 将一个页面从磁盘复制到内存，比从内存中读取这个页面花费的时间要长的多。因此，MongoDB从磁盘复制数据的次数越少越好。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:65:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"跟踪内存使用情况 MongoDB会报告三种类型的内存：常驻内存、虚拟内存和映射内存。 常驻内存(resident)是MongoDB在RAM中显式拥有的内存。如果查询一个文档，并将其加载进内存中，那么这个页面就会被添加到MongoDB的常驻内存中。 MongoDB会获得该页的地址。这个地址不是RAM中页面的真实地址，而是一个虚拟地址。MongoDB可以将它传递给内核，内核会查找出页面的真正位置。这样，如果内核需要从内核中清除该页面，那么MongoDB仍可以使用该地址对其进行访问。它会向内核请求内存，然后内核会查看页面缓存，如果发现页面不存在，就产生缺页错误并将页面复制到内存中，最后再返回给MongoDB。 MongoDB的映射内存包括MongoDB曾经访问过的所有数据。它的大小通常和整个数据集的大小差不多。 虚拟内存是操作系统提供的一种抽象，它对软件进程隐藏了物理存储的细节。每个进程都可以看到一个连续的内存地址空间。 MongoDB内存指标网往相当稳定，但随着数据集的增长，虚拟内存也会随之增长。常驻内存会增长到可用RAM的大小。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:65:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"跟踪缺页错误 缺页错误数量表示MongoDB所查找的数据不在RAM中的频率。 无论应用程序能否处理这些延迟，当磁盘超载时，缺页错误都会成为一个问题。磁盘能够处理的负载量不是线性的：一旦磁盘超载，每个操作都必须等待越来越长的时间，从而引发连锁反应。通常存在一个临界点，超出临界点后磁盘性能会迅速下降。因此，应该尽量避免磁盘在其最大负载下运转。 \r 应该不断跟踪缺页错误的数量。如果在缺页错误达到某一数量时应用程序运行良好，那么就有了一个系统可以处理多少缺页错误的基线。如果随着缺页错误的上升性能开始下降，那么就有了一个系统可以处理多少缺页错误的继线。如果随着缺页错误的上升性能开始下降，那么就有了一个应该发出告警的阈值。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:65:2","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"IO等待 缺页错误通常与CPU空闲等待磁盘响应(IO等待)的时间密切相关。一些IO等待是正常的，MongoDB有时不得不去磁盘读取数据，并且无法完全避免对其他操作的妨碍。重要的是，要确保IO等待不会持续等在或接近100%。 IO等待处于100%，表明磁盘正在超载。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:65:3","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"计算工作集的大小 通常来说，内存中的数据越多，MongoDB的运行速度就越快。因此，按照从最快到最慢的顺序，应用程序可能有以下几种情况： 整个数据集都在内存中。这非常好，但通常代价很大或不可行。对于某些依赖于快速响应时间的应用程序来说，这可能是必要的。 工作集在内存中。这是最常见的选择。工作集是应用程序使用的数据和索引。这可能是其所有内容，但通常会有一个涵盖90%请求的核心数据集（比如users集合和最近一个月的活动）。如果这个工作集能够放入RAM中，那么MongoDB的运行速度通常会很快。只有在遇到一些不寻常的请求时才需要访问磁盘。 索引在内存中。 索引的工作集在内存中。 内存中没有可用的数据子集。如果可能的话，应该避免这种情况。这回非常慢。 只有知道工作集的内容和大小，才能知道是否可以将其保存在内存中。计算工作集大小的最佳方法时跟踪分析常用的操作，以确定应用程序的读写量。假设应用程序每周会创建2GB的新数据，其中800MB的数据时经常被访问的。用户倾向于访问最近一个月的数据，超过一个月的数据通常不会被用到。这样工作集的大小大约是3.2GB(800x4)，加上预估的索引大小，总共为5GB。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:66:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"跟踪性能情况 跟踪查询的性能并使其保持稳定通常很重要。 对于MongoDB来说，CPU的大部分占用时间与IO相关。WiredTiger存储引擎是多线程的，可以利用额外的CPU核。然而，如果用户或系统时间接近100%（或100%乘以CPU数量），那么最常见的原因是缺少了某个常用查询的索引。跟踪CPU使用情况是一个很好的方法，这样可以确保所有查询都按照其期望的方式运行。 另一个类似的指标是队列长度，即有多少请求在等待MongoDB的处理。当一个请求在等待读操作或写操作的锁时，即被认为是在队列中。 可以查看进入队列的请求数量以判断是否发生了请求堆积。通常，队列大小的数值应该较低。一个很长且始终存在的队列表示mongod无法处理这个负载。这时应该尽快降低该服务器上的负载。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:67:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"跟踪剩余空间 磁盘使用情况也是一个重要的监控指标。 当磁盘空间不足时，有以下几种选择： 如果正在使用分片，那么可以再添加一个分片。 删除未使用的索引。可以对特定集合使用$indexStats聚合来识别它们。 如果还没有进行过要锁操作，那么可以再一个从节点上执行压缩来看看是否有帮助。这通常只有在从集合中删除了大量数据或索引且没有新数据替换的情况下才有用。 关闭副本集的成员（一次一个），将其数据复制到更大的磁盘中并进行挂载。重新启动该成员，然后继续对下一个成员重复此操作。 用较大驱动器的成员替换副本集中的成员，添加新成员，让新成员追上旧成员，然后删除旧成员。 如果使用了directoryperdb选项，并且数据库增长速度非常快，则可以将数据库移动到其自身的驱动器中。然后将磁盘卷作为一个数据目录进行挂载。这样其他数据就不需要移动。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:68:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"监控复制情况 复制延迟和oplog长度是需要跟踪的重要指标。延迟是指从节点无法跟上主节点的速度。延迟应该尽可能接近于0，并且通常是毫秒级别的。 如果从节点复制写操作的速度比主节点的写入速度慢，就会出现非零的延迟。这可能是由于网络问题或缺少_id索引造成的。要使复制正常工作，每个集合都需要这个索引。 如果一个集合缺少_id索引，则将服务器从副本集中脱离并作为单机服务启动，然后创建_id索引。确保将_id索引创建为唯一索引。一旦创建，_id索引就不能被删除或更改（除非删除整个集合）。 这节点不会为了帮助从节点赶上来而限制写操作，因此在一个超载的系统中，从节点落后很常见。可以在写关注中使用w，在一定程度上强制对主节点进行限制。 写操作比较少的系统会产生延迟的假象。在一个负载非常低的系统中，可能会看到另一个有趣的现象。复制延迟突然出现峰值。这其实并不是延迟，而是由抽样变化引起的。 另一个需要跟踪的重要的复制指标是每个成员的oplog长度。通常来说，只要有足够的磁盘空间，oplog就应该就可能长。oplog的使用方式基本上不占用任何内存，而一个长的oplog可能意味着运维体验上的天壤之别。 \r \r备份 定期对系统进行备份很重要。本章涵盖了几种常用的备份选项： 对单一服务器进行备份，包括快照的备份和恢复； 对副本集进行备份时的特别考虑； 对分片集群进行备份。 只有在紧急情况下有信心迅速完成对备份的部署时，备份才是有用的。因此，对于选择任何备份技术，都要确保同时对备份和恢复的操作进行练习，知道恢复过程为止。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:69:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"对服务器进行备份 有多种方法可以创建备份。但无论那种方法，备份操作都会对系统造成压力，因此，备份应该在从节点上空闲时进行。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:70:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"文件系统快照 文件系统快照使用系统级别的工具创建MongoDB数据文件设备的副本。此方式耗时很短，并且很可靠。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:70:1","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"磁盘快照 直接给整个磁盘定期打快照。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:70:2","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"复制数据文件 单机服务器，复制数据目录中的所有内容。因为没有文件系统支持的情况下无法同时复制所有文件，所以在进行复制时必须防止数据文件发生变化。此方法很慢。 db.fsyncLock(); 复制 db.fsyncUnlock(); \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:70:3","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"mongodump工具 单机服务器，此方式也很慢（无论是创建还是恢复），并且在处理副本集时也存在一些问题。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:70:4","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"副本集的特殊注意事项 在备份副本集时，除了所需数据之外，还需要获取副本集的状态，以确保生成整个部署集群的准确时间点快照。 通常，应该在从节点上进行备份。建议使用快照的方式。 当启用复制时，mongodump的使用就不那么简单了。必须使用--oplog选项，以获得某个时间点的快照。否则备份的状态会与集群中任何其他成员的状态都不匹配。恢复时，还必须创建一份oplog，否则被恢复的成员就不知道它被同步到哪里了。 要从mongodump备份恢复副本集成员，需要将目标副本集成员作为单机服务器启动，并使用--oplogReplay选项在其上运行mongorestore。 \r\r","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:71:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["database"],"content":"分片集群的特殊注意事项 在处理分片集群时，我们会将重点放在对部分组件的备份上：单独备份配置服务器和副本集。 在分片集群上执行任何备份或恢复操作之前都需要先关闭均衡器。 \r \r部署MongoDB 生产环境部署的相关建议： 建议SSD 磁盘阵列建议RAID10 不要使用网络磁盘 MongoDB对CPU的负载不高。如果在速度和核数间选择，应该选择速度。 64位Linux操作系统的稳定版本 内存根据实际情况配置 时钟同步 建议关闭SWAP交换空间 建议使用XFS文件系统 内存过度分配(memory overcommit) 关闭NUMA 禁用区域回收 禁用透明大内存页(THP)，透明大内存页会导致更多的磁盘IO。 修改限制，文件打开数、进程允许创建的线程数，通常都应该设置为无限制。 注意IO利用率 注意缺页错误率 注意TCP丢包 注意OOM killer \r # 内存过度分配, 建议为2 # 0 让内核来猜测过度分配的大小 # 1 内存分配总是成功 # 2 分配的虚拟地址空间最多不超过交换空间与一定过度分配比例的和 # 修改此参数无需重启MongoDB进程 echo 2 \u003e /proc/sys/vm/overcommit_memory # 禁用区域回收 sysctl -w vm.zone_reclaim_mode=0 ","date":"2022-04-29","objectID":"/mongodb-definitive-guide/:72:0","tags":["database","mongodb","nosql"],"title":"MongoDB权威指南","uri":"/mongodb-definitive-guide/"},{"categories":["middleware"],"content":"参考: docs: https://kafka.apache.org/documentation \r版本: kafka: v3.0 \r\r\r\r介绍 Kafka是一个分布式流式平台。 \r \r术语 kafka使用中的一些标准词汇。 Producer(生产者): 消息的发布者 Consumer(消费者): 消息的使用者 Broker(节点): 集群包含多个节点 Replication(备份机制): 每个节点有相同的副本 Replica(副本) Leader Replica Follower Replica Topic(主题): 每个主题配置M个分区 Partitioning(分区): 一组有序的消息，从0开始。每个分区配置N个副本，1个领导者副本，N-1个追随者副本。 Segment(段) Record(消息): 每条消息包含键、值和时间戳 Offset(偏移): 分区中的每条消息都会分配一个有序的id，从0开始 Consumer Group(消费者组) Consumer Offset(偏移): 记录每个消费者当前的消费位置 ","date":"2022-03-08","objectID":"/kafka/:0:0","tags":["middleware","kafka"],"title":"kafka","uri":"/kafka/"},{"categories":["cncf"],"content":"参考: github: https://github.com/traefik/traefik doc: https://doc.traefik.io/traefik/ 版本: traefik: v2.6 \r\r \r\r欢迎 \r请注意traefik的版本，v2和v1不兼容。 traefik是一个开源的边缘路由器，使你的服务发布轻松而有趣。它代表你的系统接收请求，并发现哪些组件负责处理它们。它会自动发现你的服务的正确配置。当traefik检查你的基础架构时，它会找到信息并发现哪些服务提供请求。 traefik原生地符合主要的集群技术，如k8s, docker, swarm, aws, mesos等。 使用traefik，无需维护和同步单独的配置文件，一切都是实时和自动发生(无需重启和连接中断)。你将花费时间开发和部署新功能，而不是配置和维护其工作状态。 \r\r \r\r入门 Getting Started \r\r","date":"2022-03-03","objectID":"/traefik/:0:0","tags":["traefik","load-balancer","reverse-proxy"],"title":"traefik","uri":"/traefik/"},{"categories":["cncf"],"content":"概念 Concepts 你需要知道的一切。 \rEdge Router 边缘路由器。traefik是一个边缘路由器，这意味着它是你平台的大门，并且它拦截和路由每一个传入请求，它知道所有逻辑和每条规则，来决定哪个服务处理哪个请求(基于path, host, headers等)。 \rAuto Service Discovery 自动服务发现。传统的边缘路由器(反向代理)需要一个配置文件，包含到服务的每个可能的路由，traefik从服务自身获取。 部署服务，你附上信息告诉traefik服务可以处理的请求的特征。这意味着当部署服务时，traefik立刻检测到它并实时更新路由规则。反之亦然，当你移除服务，该路由相应地消失。 你不再需要创建和同步包含路由规则的配置文件。 \r\r","date":"2022-03-03","objectID":"/traefik/:1:0","tags":["traefik","load-balancer","reverse-proxy"],"title":"traefik","uri":"/traefik/"},{"categories":["cncf"],"content":"快速开始 Quick Start 使用Docker的一个简单示例。 \r","date":"2022-03-03","objectID":"/traefik/:2:0","tags":["traefik","load-balancer","reverse-proxy"],"title":"traefik","uri":"/traefik/"},{"categories":["cncf"],"content":"使用Docker启动traefik Launch Traefik With the Docker Provider # docker-compose.ymlversion:'3'services:reverse-proxy:# The official v2 Traefik docker imageimage:traefik:v2.6# Enables the web UI and tells Traefik to listen to dockercommand:--api.insecure=true --providers.dockerports:# The HTTP port- \"80:80\"# The Web UI (enabled by --api.insecure=true)- \"8080:8080\"volumes:# So that Traefik can listen to the Docker events- /var/run/docker.sock:/var/run/docker.sock 启动reverse-proxy服务: docker-compose up -d reverse-proxy \r\r","date":"2022-03-03","objectID":"/traefik/:2:1","tags":["traefik","load-balancer","reverse-proxy"],"title":"traefik","uri":"/traefik/"},{"categories":["cncf"],"content":"检测新服务和创建路由 Traefik Detects New Services and Creates the Route for You 在上面的文件添加内容。 # ...whoami:# A container that exposes an API to show its IP addressimage:traefik/whoamilabels:- \"traefik.http.routers.whoami.rule=Host(`whoami.docker.localhost`)\" 启动whoami服务: docker-compose up -d whoami 访问localhost:8080/api/rawdata，可看到traefik自动检测新容器并更新了自己的配置。 当traefik检测新服务，它自动创建相关路由。 # 执行 curl -H Host:whoami.docker.localhost http://127.0.0.1 # 输出结果 Hostname: a656c8ddca6c IP: 172.27.0.3 ... \r\r","date":"2022-03-03","objectID":"/traefik/:2:2","tags":["traefik","load-balancer","reverse-proxy"],"title":"traefik","uri":"/traefik/"},{"categories":["cncf"],"content":"负载均衡 More Instances? Traefik Load Balances Them # 扩展whoami的副本数 docker-compose up -d --scale whoami=2 # 查看 curl -H Host:whoami.docker.localhost http://127.0.0.1 # 结果 Hostname: a656c8ddca6c IP: 172.27.0.3 # 或 Hostname: s458f154e1f1 IP: 172.27.0.4 \r\r","date":"2022-03-03","objectID":"/traefik/:3:0","tags":["traefik","load-balancer","reverse-proxy"],"title":"traefik","uri":"/traefik/"},{"categories":["cncf"],"content":"配置 Configuration Introduction \rtraefik里的配置可以指向两种不同的事物： 完整地动态路由配置(动态配置) 启动配置(静态配置) 静态配置中的元素设置和提供程序的连接，并定义traefik将监听的入口点(这些元素不会经常更改)。 动态配置包含定义系统如何处理请求的一切事物。此配置可以更改，并可无缝热加载，而不会有任何请求中断或连接丢失。 \r\r","date":"2022-03-03","objectID":"/traefik/:4:0","tags":["traefik","load-balancer","reverse-proxy"],"title":"traefik","uri":"/traefik/"},{"categories":["cncf"],"content":"动态配置 The Dynamic Configuration traefik从提供商处获得动态配置，无论事协调程序、服务注册还是普通的旧配置文件。 \r\r","date":"2022-03-03","objectID":"/traefik/:4:1","tags":["traefik","load-balancer","reverse-proxy"],"title":"traefik","uri":"/traefik/"},{"categories":["cncf"],"content":"静态配置 The Static Configuration 有三种不同的，互相排斥的(意味着你只能使用一种)，在traefik中定义静态配置的方法: 配置文件 命令行参数 环境变量 如果没有提供，则使用默认值。 \r\r配置文件 Configuration File 配置文件traefik.yaml(或traefik.toml)通常位于: /etc/traefik/ $XDG_CONFIG_HOME $HOME/.config/ . traefik --configFile=/dir/path/myconfig.yaml \r\r参数 Arguments treafik --help # or docker run traefik[:version] --help \r\r环境变量 Environment Variables \r\r","date":"2022-03-03","objectID":"/traefik/:4:2","tags":["traefik","load-balancer","reverse-proxy"],"title":"traefik","uri":"/traefik/"},{"categories":["cncf"],"content":"安装 Install Traefik 有多种方式安装: docker helm binary source \r\r","date":"2022-03-03","objectID":"/traefik/:5:0","tags":["traefik","load-balancer","reverse-proxy"],"title":"traefik","uri":"/traefik/"},{"categories":["cncf"],"content":"FAQ \r \r配置发现 Configuration Discovery \r","date":"2022-03-03","objectID":"/traefik/:6:0","tags":["traefik","load-balancer","reverse-proxy"],"title":"traefik","uri":"/traefik/"},{"categories":["cncf"],"content":"概述","date":"2022-03-03","objectID":"/traefik/:7:0","tags":["traefik","load-balancer","reverse-proxy"],"title":"traefik","uri":"/traefik/"},{"categories":["database"],"content":"参考: etcd文档 \r环境: RHEL 7 etcd v3.5 \r\r \r\r快速开始 快速安装和运行单节点的etcd集群。 # 二进制安装 # 启动 etcd # 设置一个key etcdctl put greeting \"Hello, etcd\" # 获取一个key etcdctl get greeting \r\r \r\r术语表 Glossary Alarm 每当集群需要操作员干预以保持可靠性时，etcd server都会发出警报。 Authentication 管理验证etcd资源的用户访问权限。 Client etcd连接到etcd集群以发出服务请求。 Cluster 集群由一些成员组成。每个成员的节点都遵循raft一致性协议来复制日志。集群接受来自成员的提案，提交并应用到本地存储。 Compaction 压缩会丢弃给定修订之前的所有etcd事件历史记录核被取代的键。它用于回收etcd后端数据库中的存储空间。 Election etcd集群在其成员之间举行选举，选择领导者作为raft一致性协议的一部分。 Endpoint 指向etcd服务或资源的URL。 Key 用户定义的标识符，用于在etcd中存储核检索用户定义的值。 Key Range 一组键。 Keyspace etcd集群中所有键的集合。 Lease 一种短期的租赁合同，在到期时删除与其关联的键。类似于Redis Key TTL。 Member 参与etcd集群提供服务的逻辑etcd server。 Peer 对等体是同一个集群中的另一个成员。 Proposal 提议是需要通过raft协议的请求。 Quorum 协商一致修改集群状态所需的活跃的成员数。 Revision 校订是一个64位集群范围的计数器，从1开始，每次修改键空间都会递增。 Role 一组键的权限单位，可授予一组用户进行访问控制。 Snapshot etcd集群状态的时间点备份。 Store 支持集群键空间的物理存储。 Transaction 原子执行的一组操作。事务中所有已修改的键共享相同的修订版本。 Key Version 自键创建以来的写入次数，从1开始。不存在或删除的键的版本为0。 Watcher 客户端打开一个观察者以观察给定键范围上的更新。 \r\r \r\r教程 Tutorials 包含以下这些： 访问etcd 访问key，访问特定前缀的key 删除key 在一个事务中做多个写入 观察key 创建lease(租约) 创建lock(分布式锁) 在etcd集群中进行领导选举 检查集群状态 保存数据库 添加和删除节点 \r # 写入 etcdctl --endpoints=xxx put foo \"Hello World\" # 获取 etcdctl get foo etcdctl --write-out=\"json\" get foo etcdctl get web --prefix # 删除 etcdctl delete key etcdctl delete keyaa --prefix # 一个事务中多个写入 etcdctl txn --interactive # 观察 etcdctl watch key1 # 租约 etcdctl lease grant 300 # lease 2be7547fbc6a5afa granted with TTL(300s) etcdctl put key1 value --lease=2be7547fbc6a5afa etcdctl lease keep-alive 2be7547fbc6a5afa etcdctl lease revoke 2be7547fbc6a5afa # 锁 etcdctl lock mutex1 # 选举 etcdctl elect one p1 # 集群状态 etcdctl --write-out=table endpoint status etcdctl endpoint healty # 保存数据库 etcdctl snapshot save my.db etcdctl --write-out=table snapshot status my.db \r\r \r\rFAQ Frequently asked questionshttps://etcd.io/docs/v3.5/faq/ \r\r","date":"2021-12-10","objectID":"/etcd/:0:0","tags":["database","etcd"],"title":"etcd","uri":"/etcd/"},{"categories":["database"],"content":"通用 etcd是什么？ etcd是一个一致性、分布式的k-v存储。主要用作分布式系统的单独协调服务。旨在持有少量的数据就可以完成时候。 \retcd如何发音？ 发音为/ˈɛtsiːdiː/，意为distributed etc directory。 \r客户端必须向etcd领导者发送请求吗？ Raft是基于领导者的，领导者处理需要集群一致(consensus)的所有客户端请求。但是，客户端不需要知道哪个节点是领导者。任何发送到跟随者(follower)的需要一致的请求都会自动转发给领导者。任何集群成员都可以处理不需要一致的请求。 \r\r","date":"2021-12-10","objectID":"/etcd/:1:0","tags":["database","etcd"],"title":"etcd","uri":"/etcd/"},{"categories":["database"],"content":"配置 listen-client-urls, listen-peer-urls, advertise-client-urls, initial-advertise-per-urls之间的区别？ listen-client-urls和listen-peer-urls指定etcd server绑定的本地地址，来接受传入的连接。要监听所有接口，指定0.0.0.0作为监听地址。 advertise-client-urls和initial-advertise-peer-urls指定etcd 客户端或其它成员用于与etcd server联系的地址。彼此之间必须能访问到这个地址。不要使用如localhost或0.0.0.0地址，因为可能远程机器无法到达。 \r为什么不改变 –listen-peer-urls 或 –initial-advertise-peer-urls 在 etcdctl member list更新中？ 成员的peer urls来自集群初始化引导的 –initial-advertise-peer-urls。可能会造成脑裂。使用 etcdctl member update 更新一个成员的peer urls。 \r\r","date":"2021-12-10","objectID":"/etcd/:2:0","tags":["database","etcd"],"title":"etcd","uri":"/etcd/"},{"categories":["database"],"content":"部署 系统要求。 由于etcd写入数据到磁盘，它非常依赖磁盘性能，强烈推荐SSD。为了防止性能劣化或无意中重载键值存储，默认情况下，etcd可配置的存储大小为2GB。为了避免swapping或OOM，机器至少应具有尽可能多的RAM以覆盖配额。如果要配置超过2GB，8GB是一个建议的最大的值。 \r为什么是奇数节点集群成员？ etcd需要大多数节点，一个仲裁，以达成集群状态的更新。对于一个n成员的集群，仲裁是(n/2)+1。对于任何奇数集群，添加一个节点将始终增加仲裁所需的节点数量。虽然对奇数集群添加一个节点多了节点，似乎更好，但由于在相同节点不丢失仲裁，容错性更差了，因此可能有更多节点可能会失败。如果集群处于无法再容忍任何故障的状态，则在删除节点之前添加节点是危险的。因为如果新节点无法注册到集群（如地址配置错误），仲裁将永久丢失。 \r最大集群数量？ 没有硬性规定。但是，etcd集群不应该超过7个节点。建议运行5个节点。一个5成员的etcd集群可以容忍2个成员故障，这在大多数场景下足够了。尽管较大的集群提供更好的容错能力，但由于必须在更多计算机上复制数据，因此写入性能可能会受到影响。 \r容错是什么？ 只有可以建立成员仲裁，etcd集群就会运行。如果仲裁因暂时性网络故障而丢失，etcd在网络恢复并恢复仲裁后自动完全地恢复，Raft强制执行集群的一致性。对于断电，etcd将Raft日志保存早磁盘，etcd将日志重播到故障点并恢复集群参与。对于永久性硬件故障，通过运行时重载配置从集群中删除故障节点。 建议奇数成员集群。 Cluster Size Majority Failure Tolerance 1 1 0 2 2 0 3 2 1 4 3 1 5 3 2 \retcd是否可以跨地区或跨数据中心部署？ 跨地区部署etcd提高了容错，代价是一致性请求延迟可能更高。由于etcd依赖成员仲裁来达成一致，选举和心跳可能也会受到网络延迟的影响。 \r\r","date":"2021-12-10","objectID":"/etcd/:3:0","tags":["database","etcd"],"title":"etcd","uri":"/etcd/"},{"categories":["database"],"content":"操作 如何备份etcd集群？ etcdctl提供了snapshot命令来创建备份。 \r在移除一个不健康的成员之前应该添加一个成员吗？ 当替换一个etcd节点时，重要的是先移除节点，之后再添加替换节点。 \r为什么etcd不接受我的成员资源变更？ etcd设置了 strict-reconfig-check 以拒绝可能导致仲裁丢失的重载配置的请求。遗弃仲裁确实存在风险（尤其是当集群已经处于不健康状态时）。在添加新成员时，如果仲裁丢失，可能会尝试禁用仲裁，这可能导致全面的集群不一致性。对于许多应用，这可能让问题变得更糟。 \r为什么etcd会因磁盘延迟高峰而失去领导者地位？ 磁盘延迟也是领导者活动的一部分。假设集群领导者需要一分钟将Raft日志更新同步到磁盘，但etcd集群有一秒钟的选举超时。即使领导者可以在选举间隔内处理网络消息，但它实际上不可用，因为它无法提交任何新提案，它在等待慢磁盘。如果集群由于磁盘延迟而频繁地丢失其领导者，请尝试调整磁盘设置或etcd时间参数。 \retcd警告\"request ignored(cluster ID mismatch)“意味着什么？ 每个新的etcd集群都会根据初始集群配置和用户提供的唯一初始化令牌生成一个新的集群ID。通过唯一的集群ID，etcd可以防止可能破坏集群的跨集群交互。 通常，此警告发生在拆除旧集群，然后重用新集群的某些对等地址之后。如果旧集群中任何etcd进程仍在运行，它将尝试联系新集群。新集群识别到集群ID不匹配，然后忽略改请求并发出此警告。通过确保不通集群中的对等地址不相交来清除此警告。 \r“mvcc: database space exceeded\"是什么意思，如何修复它？ \r\r","date":"2021-12-10","objectID":"/etcd/:4:0","tags":["database","etcd"],"title":"etcd","uri":"/etcd/"},{"categories":["database"],"content":"性能 etcd警告 “apply entries took too long\"是什么意思？ 在大多数etcd成员统一提交请求后，每个etcd服务器都会将请求应用到其数据库，并将结果保存到磁盘。应用一个请求通常应小于50ms。如果平均持续时间超过100ms，etcd将警告条目应用时间多长（entries are taking too long to apply）。 通常这个问题由慢磁盘导致。 第二个最常见的原因是CPU饥饿。如果CPU使用率很高，则etcd可能没有足够的计算容量。 访问太多keys的昂贵的用户请求也可能导致长延迟，这类似与数据库的全表扫描。 \retcd警告\"failed to send out heartbeat on time\"是什么意思？ etcd使用基于领导者的一致协议进行一致性的数据复制和日志执行。集群成员选举一个领导者，其它成员都成为追随者。当选的领导者必须定期向其追随者发送心跳，以保持其领导者地位。如果选举间隔内未收到心跳检测，则追随者推断领导者失败并触发选举。如果领导者没有及时发送心跳，但它仍在运行，那么选举就是虚假的，很可能是由资源不足引起的。如果领导者跳过两个检测信号，etcd就会警告未能按时发送检测信号。 此问题通常由慢磁盘导致的。在领导者发送附加了元数据(metadata)的检测信号之前，它可能需要将元数据保存到磁盘。 第二个常见的原因是CPU饥饿。 慢网络也可能导致这个问题。 \retcd警告\"snapshotting is taking more than x seconds to finish …“是什么意思？ etcd发送其完整键值存储的快照，来刷新慢追随者和备份。 \r\r \r\r操作指南 operations guide \r","date":"2021-12-10","objectID":"/etcd/:5:0","tags":["database","etcd"],"title":"etcd","uri":"/etcd/"},{"categories":["database"],"content":"认证指南 Authentication Guides ","date":"2021-12-10","objectID":"/etcd/:6:0","tags":["database","etcd"],"title":"etcd","uri":"/etcd/"},{"categories":["SRE"],"content":"参考: School Of SRE: https://linkedin.github.io/school-of-sre/ \r\r \r\r介绍 站点可靠性工程师(Site Reliability Engineers, SREs)位于软件工程和系统工程的交叉点。 课程Level： 1xx: freshman 2xx: sophomore 3xx: junior 4xx: senior 目前涵盖的SRE课程： Level 101 Fundamentals Series Linux Basics Linux Networking Python和Web Data Relational databases NoSQL Big Data Systems Design Scalability Availability Fault Tolerance Metrics and Monitoring Security Level 102 Linux Intermediate Package Management Storage Media Archiving and Backup VIM BASH Linux Advanced Containers and orchestration System Calls and Signals Networking Security Scale RTT Infrastructure Services System Design Large System Design Scaling Scaling Beyond the Data Center Resiliency System troubleshooting and performance improvements CI/CD \r\r基础系列 Fundamentals Series \r","date":"2021-08-24","objectID":"/sre/:0:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"Linux基础知识 Linux Basics: https://linkedin.github.io/school-of-sre/level101/linux_basics/intro/ \r\r","date":"2021-08-24","objectID":"/sre/:1:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"本课程的期望 本课程分为三部分： Linux操作系统基础 Linux基本命令 Linux系统管理 \r\r","date":"2021-08-24","objectID":"/sre/:1:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"Linux介绍 内核(kernel)是一个操作系统最重要的部分，它执行进程管理，内存管理，文件系统管理等重要功能。 Windows操作系统基于Windows NT kernel。 Linux操作系统基于Linux Kernel(免费且开源)。基于Linux的操作系统包含Linux Kernel, GUI/CLI, system libraries, system utilities. Linux是一个内核，而不是一个完整的操作系统。Linux Kenel与GNU相结合来创建完整的操作系统。因此，基于Linux的操作系统也成为GNU/Linux系统。 \r\rLinux发行版 Linux发行版是基于Linux内核和包管理系统的操作系统。软件通常是适配各个发行版的特定格式。 流行的Linux发行版： Fedora Ubuntu Debian Centos Red Hat Enterprise Linux Suse Arch Linux 包管理 发行版 包管理 Debian Style(.deb) Debian, Ubuntu APT RedHat style(.rpm) Federa, CentOS, RedHatEL YUM linux架构图。 The Linux kernel is monolithic in nature. System calls are used to interact with the Linux kernel space. Kernel code can only be executed in the kernel mode. Non-kernel code is executed in the user mode. Device drivers are used to communicate with the hardware devices. \r\rLinux操作系统用例 广泛使用Linux内核操作系统的有： Personal computers Servers Mobile phones Embedded devices Satellites Network devices \r\rShell与Terminal Shell是一个从用户处获取命令的程序，并将其提供给操作系统进行处理。Shell是CLI的示例。Bash是Linux服务器上最受欢迎的shell程序。 Terminal是一个打开窗口让你与Shell交互的程序。 \r\r","date":"2021-08-24","objectID":"/sre/:1:2","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"命令行基础 docs: https://linkedin.github.io/school-of-sre/level101/linux_basics/command_line_basics/ \r\r命令 命令(command)是告诉操作系统执行特定工作的程序。程序在Linux中存储为文件。因此，命令也是存储在磁盘某处的文件。 使用--help或man来获取帮助信息。 \r\r文件系统组织 File System Organization Linux文件系统具有分层(hierarchical)(或树形(tree-like))结构，最高级别的目录称位根目录/。 特定目录的作用： bin: The executable program of most commonly used commands reside in bin directory sbin: This directory contains programs used for system administration. home: This directory contains user related files and directories. lib: This directory contains all the library files etc: This directory contains all the system configuration files proc: This directory contains files related to the running processes on the system dev: This directory contains files related to devices on the system mnt: This directory contains files related to mounted devices on the system tmp: This directory is used to store temporary files on the system usr: This directory is used to store application programs on the system \r\r导航文件系统的命令 Commands for Navigating the File System ls:list files and directoriespwd:print working directorycd:change directory \r\r操作文件的命令 Commands for Manipulating Files touch:create new filemkdir:create new directoriesrm:delete files and directoriescp:copy files and directoriesmv:move files and directories \r\r查看文件的命令 Commands for Viewing Files cat:concatenate files and print on the standard outputhead:output the first part of filestail:output the last part of filesmore:file perusal filter for crt viewingless:opposite of more \r\recho命令 echo:display a line of text \r\r文本处理命令 Text Processing Commands grep:print lines matching a patternsed:stream editor for filtering and transforming textsort:sort lines of text files \r\rIO重定向 每个打开的文件都会分配文件描述符(file descriptor)。文件描述符是系统中打开的文件的唯一标识符。 有三个默认的文件打开：stdin, stdout, stderr Everything is a file in linux. `\u003e`:重定向操作符`|`:管道符 \r\r","date":"2021-08-24","objectID":"/sre/:1:3","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"服务器管理 Server Administration: https://linkedin.github.io/school-of-sre/level101/linux_basics/linux_server_administration/ \r\r多用户操作系统 Multi-User Operating Systems Linux操作系统本质上是多用户，因为它允许多个用户同时访问系统。多个用户通过SSH远程登录并。 由于Linux支持多个用户，我们需要一种方法可以保护用户彼此。用户不应该能够访问和修改其它用户。 \r\r用户和组管理 User/Group Management Users in Linux has an associated user ID called UID attached to them. Users also has a home directory and a login shell associated with them. A group is a collection of one or more users. A group makes it easier to share permissions among a group of users. Each group has a group ID called GID associated with it. root user or superuser is the most privileged user with unrestricted access to all the resources on the system. It has UID 0 id:print real and effective user and group IDswhoami:print effective userid#用户和组相关联的重要文件/etc/passwd:Stores the user name, the uid, the gid, the home directory, the login shell etc/etc/shadow:Stores the password associated with the users/etc/group:Stores information about different groups on the system \r\r用户管理相关命令 Important commands for managing users useradd:Creates a new userpasswd:Adds or modifies passwords for a userusermod:Modifies attributes of an useruserdel:Deletes an user cat /etc/shadow apache:!!:18759:::::: \"!!\" in an account entry in shadow means the account of an user has been created, but not yet given a password. \r\r组管理相关命令 Important commands for managing groups groupadd:Creates a new groupgroupmod:Modifies attributes of a groupgroupdel:Deletes a groupgpasswd:Modifies password for group \r\r成为超级用户 Becoming a Superuser sudo:The sudo command allows a user to run commands with the security privileges of the root usersu:switch users in Linux \r\r文件权限 File Permissions Linux系统上，每个文件和目录都分配了对应属主(owner)、组(group)、其他人(other)的对应权限。 文件权限的一些命令: chmod:modify files and directories permissionschown:change the owner of files or directorieschgrp:change the group ownership of files or directories \r\rSSH命令 ssh命令用于登录远程系统，传输文件，执行命令等。 使用SSH进行无密码认证(Passwordless Authentication Using SSH)。 在远程主机上执行命令。 在主机之间传输文件。 \r\r包管理 Package Management 包管理是系统上安装和管理软件的进程。 yum(dnf) apt \r\r进程管理 Process Management ps:know the information of a process or list of processestop:show information about Linux processes running on the system in real time \r\r内存管理 Memory Management free:display the memory usage of the systemvmstat:display the memory usage along with additional information about io and cpu usage \r\r检测磁盘 Checking Disk Space df(disk free):display the free and available space for each mounted file systemdu(disk usage):display disk usage of files and directories on the systemfdisk:manipulate disk partition table \r\rDaemons 以后台进程运行的程序称位daemon。通常来讲，守护进程名称会以d结尾，如sshd, httpd等。我们无法与守护进程进行交互，因为它们在后台运行。 \r\rSystemd systemd是Linux操作系统上的系统和服务管理程序。systemd units是Systemd的构成组件。这些单元由配置文件表示(/usr/lib/systemd/system)。 service units以.service文件扩展结尾。systemctl命令用于管理由systemd管理的服务。 \r\rLogs /var/log/ dmesg: kernel logs \r\r\r","date":"2021-08-24","objectID":"/sre/:1:4","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"Git \r","date":"2021-08-24","objectID":"/sre/:2:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"git基础知识 git: https://linkedin.github.io/school-of-sre/level101/git/git-basics/ # 创建一个git仓库 git init # 一个空的git仓库 # 所有信息都在.git目录下 ls .git/ branches config description HEAD hooks info objects refs git status git add # Commit is a snapshot of the repo git commit -m git log --oneline --graph git cat-file -p commit-id ls .git/objects/xx/xxxx # 版本控制 git checkout cat .git/HEAD echo commit-id \u003e .git/refs/heads/master All commits are stored as a tree like data structure internally by git. That means there can be two or more children commits of a given commit. Everything in git is an object. \r\r","date":"2021-08-24","objectID":"/sre/:2:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"分支 Working With Branches: https://linkedin.github.io/school-of-sre/level101/git/branches/ 在同一个仓库中，不同的功能同时并行工作，使用分支。 在内部，git只是一颗提交树。分支名称(人类可读)是指向树中那些提交的指针。我们使用各种git命令来处理树结构和引用。git相应地修改我们仓库的内容。 如果仓库中有很多分支，那么分支合并可能会出现很多合并提交信息。这样，与单一的开发历史相比，看起来很难看。所以，让我们来看看另外的方法(rebase)。 git branch git checkout -b git checkout git merge git rebase git merge --rebase \r\r","date":"2021-08-24","objectID":"/sre/:2:2","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"钩子 github and hooks: https://linkedin.github.io/school-of-sre/level101/git/github-hooks/ git还有一个很好的特性叫做钩子(hooks)。钩子基本上是脚本，当某个事件发生时会被调用。 钩子的名称是解释性的。当你想在某个事件发生时做某些事情，这些钩子很有用。 git remote git pull git push # hooks ls .git/hooks/ applypatch-msg.sample fsmonitor-watchman.sample pre-applypatch.sample pre-push.sample pre-receive.sample update.sample commit-msg.sample post-update.sample pre-commit.sample pre-rebase.sample prepare-commit-msg.sample \r\r\r","date":"2021-08-24","objectID":"/sre/:2:3","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"Linux网络 \r","date":"2021-08-24","objectID":"/sre/:3:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"网络基础 Linux Networking Fundamentals: https://linkedin.github.io/school-of-sre/level101/linux_networking/intro/ 当你在浏览器中访问linkedin.com时，会发生什么？本课程遵循TCP/IP协议栈的流程。 更具体地说，涵盖了： 应用层协议: DNS, HTTP 传输层协议: UDP, TCP 网络层协议: IP 数据链路层协议 \r\r","date":"2021-08-24","objectID":"/sre/:3:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"DNS dns: https://linkedin.github.io/school-of-sre/level101/linux_networking/dns/ 域名是网站的简单人类可读的名称。互联网只能理解IP地址，但由于记忆不想关的号码不实用，因此使用域名。这些域名被DNS基础架构转换为IP地址。 当在浏览器打开www.linkedin.com时，浏览器尝试讲域名转换为IP地址，这个过程被称为DNS解析。 域名解析 -\u003e 查看本地缓存 -有\u003e 返回ip -无\u003e 请求DNS服务器 -\u003e 返回ip www.linked.com -\u003e . -\u003e .com -\u003e linkedin.com . root domain # Linux操作系统文件 /etc/nsswitch.conf /etc/hosts /etc/resolv.conf # 命令 nslookup dig dig linkedin.com linkedin.com. 33 IN A 13.107.42.14 域名解析结果有五个字段: 第一个字段：请求 第二个字段：TTL 第三个字段：信息类别 第四个字段：记录类型 A: IPv4 AAAA: IPv6 NS: authoritative nameserver TXT PTR MX CNAME: 别名 第五个字段： 响应 \rApplications in SRE role SRE可以从DNS获取的一些常见的解决方案： 自己的DNS基础架构 DNS可用于服务发现 云服务商CDN服务商提供的DNS 在分布式系统中，DNS可用于使客户端将IP地址更靠近其位置，以提供更快的响应 DNS验证和欺骗(https, dnssec) 陈旧的DNS缓存可能会是一个问题 DNS负载均衡和服务发现也必须了解TTL，并且只有在等待TTL后才能从池中删除、更改DNS记录 \r\r","date":"2021-08-24","objectID":"/sre/:3:2","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"UDP udp: https://linkedin.github.io/school-of-sre/level101/linux_networking/udp/ UDP是一个传输层协议。DNS是一个运行在UDP之上的应用层协议。 传输层确保DNS请求到达DNS服务端，并确保响应到达DNS客户端。当客户端进行DNS请求时，在填充必要的应用程序有效应用载荷(application payload)后，它通过sendto系统调用将有效应用载荷传递给内核。内核选择一个大于1024的随机端口作为源端口，DNS服务器端口(默认53)作为目的端口，并发送包到更低的层。当DNS服务端的内核接收到这个包，它检查它的端口号，并且数据包队列到DNS程序的应用缓冲取(application buffer)，该过程调用recvfrom系统调用并读取数据包。这个内核的过程被称为多路复用(multiplexing)和多路分用(demultiplexing)。多路复用和多路分解有传输层完成。 多路复用：从多个应用程序组合数据包到相同的底层 多路分用：将数据包从单个下层分离到多个应用程序 UDP是最简单的传输层协议之一，它只有多路复用和多路分用。另一个常见的传输层协议是TCP，它是可靠的通信、流量控制、拥塞控制。UDP旨在轻便，处理略微开销的通信。所以UDP在多路复用和分用之外不做任何事。 \r\r","date":"2021-08-24","objectID":"/sre/:3:3","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"HTTP HTTP: https://linkedin.github.io/school-of-sre/level101/linux_networking/http/ Linked的html页面是由浏览器渲染的HTTP协议提供的。浏览器给前面解析的IP服务器发送HTTP请求。请求包含方法、路径和参数等。 HTTP is called stateless protocol. HTTP是不安全的，使用HTTPS。 HTTPS必须提供客户端和服务段直接的数据的服务器标识和加密。服务器管理员必须生成私有公钥对和证书请求。该证书请求必须由证书机构签名，证书机构将证书请求转换为证书。证书有关于服务器的详细信息（如域名，过期时间等）。私钥是服务器的秘密，丢失私钥就失去了服务器的提供的信任。 当客户端连接，客户端发送HELLO。服务器将其证书发送给客户端。如果证书未过期，客户端检查证书的有效性，如果它由受信任的机构签名，并且证书中的主机名与服务器相同。这个验证过程确保服务器的正确性，避免网络钓鱼。一旦验证，客户端通过协商与服务器的公钥加密协商，客户端通过服务器协商对称密钥和密码。除了具有私钥的服务器之外，没有人可以理解这些数据。一旦协商完成，对称密钥和算法将用于进一步加密，这可以仅由客户端和服务端从其上解密，因为只有它们知道对称密钥和算法。 \r\r","date":"2021-08-24","objectID":"/sre/:3:4","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"TCP TCP: https://linkedin.github.io/school-of-sre/level101/linux_networking/tcp/ TCP是一种传输层协议，它保证了可靠性、流量控制和拥塞控制。通过使用序列号保证可靠的交付。 TCP连接通过三次握手建立。客户端发送带有计划使用的起始序列号的SYN包，服务器确认SYN包并以其序列号发送SYN包。一旦客户端确认了SYN数据包，就建立了连接。一旦有关方收到该序列的确认，从此处传输的每个数据包被认为是可靠的。 TCP通过四次挥手断开连接。关闭连接时，客户端、服务端调用close syscall。假设客户端想要断开连接。客户端的内核将发送FIN包给服务器。服务器的内核无法关闭连接，知道服务器应用程序调用close syscall。一旦服务器应用程序调用close，服务器同样发送一个FIN包，客户端进入时间等待状态(2MSS, 120s)，以便在该时间段中重复使用此套接字以防止由于杂散陈旧数据包引起的认证TCP状态损坏。 \r\r","date":"2021-08-24","objectID":"/sre/:3:5","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"路由 IP Routing and Data Link Layer: https://linkedin.github.io/school-of-sre/level101/linux_networking/ipr/ 我们将挖掘离开客户端的数据包到达服务器，反之亦然。当数据包到达IP层时，传输层填充源端口和目的端口。IP网络层填充目标IP，然后查找路由表上对应的路由。 路由表中0.0.0.0的网关，意味着不需要网络层hop来发送数据包。源和目的都在同一个网络中。内核必须弄清楚目的地的MAC并适当地填充源和目的MAC，并将数据包发送出来，以便它到达目的地而没有中间的任何一层跳跃。 \r\r \r\rPython和Web \r\r \r\r数据 \r","date":"2021-08-24","objectID":"/sre/:3:6","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"关系型数据库 Relational Databases \r","date":"2021-08-24","objectID":"/sre/:4:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"关键概念 Key Concepts: https://linkedin.github.io/school-of-sre/level101/databases_sql/concepts/ 关系型数据库用于存储数据。即使是文件也可用于存储数据。但关系型数据库设计具有特定的目标: 效率 易于访问和管理 有组织的 处理数据直接的关系(表示为表) 事务(Transaction): 可以包含多个语句的工作单位，一起执行 ACID属性 原子性(Atomicity): 每个事务都是原子的（完成成功或完全失败） 一致性(Consistency)：事务仅导致有效状态 隔绝性(Isolation)：每个事务都在并发系统内安全地单独执行 持久性(Durability)：保证已提交的事务将永久存在 CRUD操作 Create Read Update Delete 查询的四种类型 DDL(definition) DML(manipulation) DCL(control) TCL(transactions) 约束(Constraint)：可以存储的数据的规则 索引(Index)：大多数索引使用B+tree结构 联结(Join)：多表关联 访问控制(Access control) \r\r流行的数据库系统 商业版 Oracle MS SQL Server IBM DB2 开源版 MySQL MariaDB PostgreSQL \r\r","date":"2021-08-24","objectID":"/sre/:4:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"MySQL \r\r","date":"2021-08-24","objectID":"/sre/:4:2","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"InnoDB \r\r","date":"2021-08-24","objectID":"/sre/:4:3","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"备份和还原 Backup and Recovery \r\r","date":"2021-08-24","objectID":"/sre/:4:4","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"MySQL副本 MySQL Replication \r\r","date":"2021-08-24","objectID":"/sre/:4:5","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"查询语句 \r\r","date":"2021-08-24","objectID":"/sre/:4:6","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"查询优化 Query Performance: https://linkedin.github.io/school-of-sre/level101/databases_sql/query_performance/ 查询性能是关系型数据库一个非常重要的方面。重要任务是识别慢查询，并尝试通过重写它们或在涉及的表中创建适当的索引来提高其性能。 \r\r","date":"2021-08-24","objectID":"/sre/:4:7","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"NoSQL 通常，术语NoSQL数据库指的是任何非关系型数据库。术语NoSQL(non SQL)指的是not only SQL。无论那种方式，大多数人都同意NoSQL数据库是存储关系表以外格式的数据库。 常见的误解是NoSQL数据库或非关系型数据库不会很好地存储关系数据。NoSQL数据库可以存储关系数据，只是与关系型数据库不同地存储。实际上，与SQL数据库相比，许多查找在NoSQL数据库中的建模关系更容易，因为相关数据不必在表之间拆分。 随着敏捷开发的兴起，NoSQL数据库专注于伸缩(scaling)，高性能，同时允许频繁地应用更改，并轻松地进行编程。 NoSQL数据库的类型: 文档型(Document)：存储在文档中的数据(BSON)类似与JSON对象。每个文档包含一组键值对。值通常可以是各种类型：字符串、数字、布尔、数组和对象，它们通常与开发人员对齐的结构与代码一起使用。有点包括直观的数据模型和灵活模式。由于值类型很宽泛和强大的查询语言，文档数据库非常适合各种用例，可用作通用数据库。它可以快速和无限的横向扩展。 MongoDB Couchbase 键值对(Key-Value)：简单的键值数据库。它非常适合你需要存储大量数据但不需要执行复杂查询来检索它的情况。 Redis DynamoDB 宽列(Wide-column)：数据存储在表、行和动态的列中。宽列存储提供了对关系数据库的大量灵活性，因为每行都不需要具有相同的列。宽列存储通常用于用户配置文件和数据的网络数据。 HBase Cassandra 图(Graph)：数据存储在节点(node)和边缘(edge)中。节点通常存储有关人员、地方和事物的信息，而边缘存储节点之间的关系的信息。 Neo4j \r比较 类型 性能 扩展性 灵活性 复杂性 功能性 k-v high high high none Variable document high Variable(high) high low Variable(low) Column DB high high moderate low minimal Graph Variable Variable high high Graph theory SQL和NoSQL的不同之处 项 SQL数据库 NoSQL数据库 数据存储模型 具有固定行和列的表 Document: JSON文档 K-V: 键值对 Wide-column：具有行和动态列的表 Graph：节点和边缘 首要目标 一般用途 Document：一般用途 K-V：具有简单查询的大量数据 Wide-column：具有可预测查询模式的大量数据 Graph：在关联的数据之间分析和遍历关系 模式(Schema) 严格且生硬(Rigid) 灵活 扩展性 垂直 水平 多记录ACID事务 支持 大多数不支持，MongoDB支持 联结 通常需要 通常不需要 数据到对象映射 需要ORM(object-relational mapping) 大多不需要 优点 灵活的数据模型 水平伸缩 快速查询 开发者生产力 \r\r","date":"2021-08-24","objectID":"/sre/:5:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"关键概念 Key Concepts: https://linkedin.github.io/school-of-sre/level101/databases_nosql/key_concepts/ \rCAP定理 CAP(Consistency, Availability, Partition Tolerance) 一致性(Consistency)：系统在执行后的一致性 可用性(Availability)：由于软件或硬件故障，系统如何响应不同不系统的功能丢失 分区容错(Partition Tolerance)：系统在网络分区中继续操作的能力 大规模应用中越来越多的用例倾向于重视可靠性，这意味着可用性和冗余比一致性更有价值。结果，这些系统致力于满足ACID属性。通过对一致性要求松开来实现这一目标，即最终一致性(Eventual Consistency)。 最终一致性意味着所有读者都会看到写入，随着时间流逝，在稳定状态下，系统最终将返回最后一个写入值。因此，当更新进行时，客户端可能面临数据不一致状态。 例如，在复制的数据库更新中可以转到一个几点，该节点将最新版本复制到包含修改数据集的副本的所有其它节点，使得副本节点最终将具有最新版本。 NoSQL系统支持不同级别的最终一致性模型： Read Your Own Writes Consistency：客户端将在编写后立即看到它们的更新。 Session Consistency：客户将在会话范围内看到对数据的更新。 Casual Consistency：按照系统的每个过程都可以看到潜在的因果关系相关的写操作。 \r Choice Traits 示例 Consistency + Availability 2-phase commits Cache invalidation protocols Single-site databases Cluster databases LDAP xFS file system Consistency + Partition tolerance Pessimistic locking Make minority partitions unavailable Distributed databases Distributed locking Majority protocols Availability + Partition tolerance expirations/leases conflict resolution optimistic DNS Web caching \r\r分布式系统中的数据版本 Versioning of Data in distributed systems 当数据跨界点分布时，它可以同时在不同的节点上进行修改。对并发更新的冲突解决而产生的问题。一些流行的冲突解决机制： Timestamps：这是最明显的解决方案。根据时间序列对更新进行排序，然后选择最新的更新。这依赖于基础设施的不同部分的时钟同步。当系统遍布不同的地理位置时，这将会变得更加复杂。 Optimistic Locking：给每个数据更新关联了一个唯一的值（如时钟或指针）。这意味着你需要跟踪数据版本的历史。 Vector Clocks：向量时钟被定义为来自每个节点的时钟值的元组。在分布式环境中，每个节点维护一个表示节点本身及其对或副本状态的时钟值元组。时钟值可以是源自本地时钟或版本号的实时时间戳。 \r向量时钟有一下优点： 没有对时钟同步的依赖 不需要完整的利息记录序列 \r\r分区 Partitioning 当数据量交叉单个节点的容量时，我们需要考虑分割数据，为负载均衡和灾难恢复创建副本。根据基础设施的动态程度，我们有几种方法可以采取： Memory cached：用于暂时数据的内存数据库分区。这些数据库通常用于RDBMS的前面。最常使用的数据从RDBMS复制到内存数据库中以促进快速查询并从后端DB切出负载。（如memcached数据库） Clustering：传统集群机制摘要客户端的集群拓扑。客户端不知道实际数据驻留在哪里以及它正在与之交谈的哪个节点。集群化常用于传统的RDBMS中，在那里它可以帮助在一定程度上伸缩持久化层到特定规模。 Separating reads from writes：在此方法中，你有多个相同数据的副本。写入通常被发送到单个节点(Leader)，或副本节点(multi-Leaser)，其余的副本(Follower)处理读请求。Leader异步复制写操作到所有Followers。然而避免不了写入之后(write lag)。有时Leader可在将所有数据复制到Followers之前奔溃。当发生这种情况时，一个最符合最一致数据的follorer将变为leader。你还需要考虑读取和写入流量的比率。当写入高于读取时，此模型没有意义。复制方法也可以差异很大。一些系统定期使用全量转移，而其它系统则使用增量转移。 Sharding：共享是指以这样的方式划分数据(dividing data)，即数据在节点集群中均匀地分发。它还可以暗示数据局部性，这意味着类似的和相关的数据存储在一起以促进更快地访问。分片可以进一步分支以满足负载均衡或灾难恢复的要求。单分片副本可能采用所有写入(single leader)，或多个副本写入(multi-leader)。读取可以跨多个副本分发。由于数据现在分布在多个节点上，因此客户端应该能够始终如一地弄清楚数据托管的位置。分片的缺点是碎片之间的连接是不可能的。因此，上下游应用程序必须从多个分片汇总结果。 \r\r\rHashing 哈希函数是映射一片数据的函数。通常用于描述某种物体，称为哈希码或简单地散列。在分区数据库中，重要的是要一致地将key映射到server/replica。 这种简单哈希的缺点是，每当集群拓扑发生变化时，数据分布也会发生变化。当你处理内存缓存时，它将很容易分发分区。每当节点加入或离开拓扑时，分区可以重新排序，可从后端数据库重新填充缓存未命中(cache miss)。然而，当你查看持久性数据时，由于新节点没有所需的数据，因此无法提供服务。这使我们能够保持一致的散列。 Consistent Hashing 一致散列是分布式散列方案，通过将其分配在抽象圆圈或散列圈上的位置，独立于分布式哈希表中的服务器或对象的数量来操作。这允许服务器和对象扩展而不影响整体系统。 \r\rQuorum 分布式系统仲裁(quorum)是集群中必须在线且能够相互通信的最小节点数，它是一种用来保证数据冗余和最终一致性的投票算法，其主要数学思想来源于格巢原理。如果在此阈值之外发生任何其他节点故障，则集群将停止运行。 为了获得仲裁，你需要大部分节点，通常是(N/2+1)。 网络问题可能导致集群节点之间的通信故障。一组节点可能能够在网络的运行部分中一起通信，但不能够与网络的另一部分中的不同节点通信。这称为集群分区中的脑裂(split brain)。 现在允许具有仲裁的分区继续运行应用程序。其它分区已从集群中删除。 例如，在一个5个节点的集群中，考虑如果节点1，2，3可以彼此通信，但无法与4，5节点通信。节点1，2，3作为多数，并且它们继续作为一个集群运行。节点4，5是少数，停止作为集群运行。如果节点3丢失与其它节点的通信，则所有节点都停止作为集群运行，由于集群可用节点数小于(N/2+1)这，意味这集群已经不可用了。但是，所有功能节点都将继续监听通信，以便在网络恢复时，集群可以形成并开始运行。 \r\r","date":"2021-08-24","objectID":"/sre/:5:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"大数据 Big Data 大数据是无法使用传统计算技术处理的大型数据集的集合。它不是一个单一的技术或工具，而是一个完整的主题，涉及到各种工具，技术和框架。 大数据可能包括：结构化数据，非结构化数据，半结构化数据。 大数据的特征：Volume，Variety，Velocity，Variability。 大数据的例子包括：证券交易所，社交媒体网站，喷气发动机… \r\r \r\r系统设计 Systems Design 思考和设计可扩展性、可用性和可靠性的大规模软件系统。 随着软件和硬件系统具有多种可移动部件，我们需要考虑这些部件如何生长，其失败模式，其依赖关系，如何影响用户和业务。没有一蹴而就的方法，我们只有通过设计和迭代来学习设计系统。 \r","date":"2021-08-24","objectID":"/sre/:6:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"可扩展性 Scalability: https://linkedin.github.io/school-of-sre/level101/systems_design/scalability/ 可扩展性对系统、服务意味着什么？一个系统由服务或组件构成，每个服务、组件的可扩展性需要单独处理，系统的可扩展性是一个整体。如果在向系统添加资源时，以与添加的资源成正比的方式提高性能，则称该服务是可扩展的。 如果添加资源以促进冗余不会导致性能损失，则称永远在线的服务是可扩展的。 \r","date":"2021-08-24","objectID":"/sre/:7:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"Scale Cube Scale Cube是一个用于分割服务、定义微服务和扩展产品的模型。以下章节讨论基于对AFK cube的推断。 \r\r","date":"2021-08-24","objectID":"/sre/:7:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"水平伸缩 Scalability - Horizontal scaling 水平伸缩代表应用程序或服务的克隆，这样工作就可以轻松地跨实例分发，绝对没有偏见。 示例里数据库从应用程序分开扩展。这是为了让你知道每个组件的扩展性可能不同。通常web应用可以通过添加资源来进行扩展，除非应用程序内部存储了状态（有状态服务）。但是DB可以通过添加更多的Followers来仅针对读取进行扩展，而写入必须只转到一位Leader以确保数据的一致性。 有一些DB支持多主(multi-leades)写操作。 应用程序应该能够区分独写，以选择适当的数据库服务器。负载均衡器可以透明地拆分相同服务器之间的流量。 \rWHAT：复制服务或数据库以传播负载。 WHEN TO USE：具有很高独写率的数据库。因为仅有读副本可以扩展，而不是主。 HOW TO USE：简单地克隆服务并执行负载均衡器。对于数据库，请确保访问代码了解读取和写入之间的差异。 WHY：允许以重复数据和功能的成本快速进行扩展。 KEY TAKEAWAYS：这是快速实现，从开发人员的角度来看，较低的成本，并且可以很好地伸缩交易卷。然而，他们往往从数据运行成本的角度来看高成本。 \r\r负载均衡 Scalability Pattern - Load Balancing 改善跨多个计算资源，如计算机集群、网络链接、中央处理器、磁盘驱动的工作负载分布。一种常用的技术是跨相同服务器集群的负载均衡流量。类似的原理有用于跨网络链接的ECMP，RAID的磁盘驱动的负载均衡。 旨在优化资源使用、最大化吞吐量、最小化响应时间并避免任何单个资源过载。使用具有负载均衡的多个组件的冗余效果，来替代单个组件，可以提高可靠性和可用性。 执行负载均衡的设备或系统称为负载均衡器，简称LB。 \r\r负载均衡的任务 Scalability Pattern - LB Tasks 负载均衡做什么： 服务发现(Service discovery) 健康检查(Health checking) 负载均衡(Load balancing) \r\r负载均衡的方法 Scalability Pattern - LB Methods 常用的负载均衡方法： 最小连接(Least Connection Method) 最小响应时间(Least Response Time Method) 轮询(Round Robin Method) IP哈希(IP Hash) \r\rCDN Scalability Pattern - Caching - Content Delivery Networks (CDN) CDN更加靠近客户的位置。不长更改的静态数据，则可以使用CDN缓存。 \r\r","date":"2021-08-24","objectID":"/sre/:7:2","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"微服务 Scalability - Microservices 此模式表示应用程序中的服务或功能的拆分。微服务旨在解决与代码库和数据集中增长和复杂相关的问题（解耦）。意图是创建故障隔离和响应时间。 微服务可以扩展事务、数据大小和代码库大小。这个的开销比水平伸缩多一些，因为工程团队需要重写服务或分解程序。 \r\r","date":"2021-08-24","objectID":"/sre/:7:3","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"分片 Scalability - Sharding 此模式表示基于在事务时查找，或确定的属性的工作分离。通常，这些是由请求者，或客户端的拆分来实现。 分片伸缩事件增长，伸缩指令集，减少处理时间（通过限制执行任何事务所需的数据）。这在客户端伸缩增长方面更有效。它可以帮助灾难恢复，并限制事件的影响仅限于一个特定客户段。 这里，认证数据基于用户名分配，使得数据库可以减少在查询期间的数据量，更快地响应。 \r这里也还有其它的方式： 这里整个数据中心被分割和复制，客户端基于地理位置引导到数据中心。这有助于提高性能，使客户端被引导到最接近的数据中心。使用此方法有一些复制和一致性方面的开销。 \r\r","date":"2021-08-24","objectID":"/sre/:7:4","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"可用性 Availability: https://linkedin.github.io/school-of-sre/level101/systems_design/availability/ 可用性通常用9来表示。 Availability% Downtime per year Downtime per month Downtime per week Downtime per day 99%(Two Nines) 3.65 days 7.31 hours 1.68 hours 14.40 minutes 99.5%(Two and a half Nines) 1.83 days 3.65 hours 50.40 minutes 7.20 minutes 99.9%(Three Nines) 8.77 hours 43.83 minutes 10.08 minutes 1.44 minutes 99.95%(Three and a half Nines) 4.38 hours 21.92 minutes 5.04 minutes 43.20 seconds 99.99%(Four Nines) 52.60 minutes 4.38 minutes 1.01 minutes 8.64 seconds 99.995%(Four and a half Nines) 26.30 minutes 2.19 minutes 30.24 seconds 4.32 seconds 99.999%(Five Nines) 5.26 minutes 26.30 seconds 6.05 seconds 864.0 ms \r","date":"2021-08-24","objectID":"/sre/:8:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"可用性串行组件 HA - Availability Serial Components 如果组件故障，则导致系统无法操作。 例如，如果LB故障，则应用的所有访问都异常。 \r\r","date":"2021-08-24","objectID":"/sre/:8:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"可用性并行组件 HA - Availability Parallel Components 如果组件故障，则导致系统启动并联操作。 如果我们有不止一个LB，当一个LB故障时，可以让其它LB接管并运行。 \r\r","date":"2021-08-24","objectID":"/sre/:8:2","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"核心准则 HA - Core Principles 消除单点故障(SPOF, Elimination of single points of failure)：意味着增加系统冗余，组件故障并不意味着整个系统的故障。 可靠交叉(Reliable crossover)：在冗余的系统同，交叉点往往成为单点故障。因此，可靠的系统必须提供可靠的交叉。 检测失败(Detection of failures as they occur)：如果观察到上述两个原则，那么用户可能永远不会看到失败。 \r高可用的架构图可能如下: \r\r","date":"2021-08-24","objectID":"/sre/:8:3","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"容错 Fault Tolerance: https://linkedin.github.io/school-of-sre/level101/systems_design/fault-tolerance/ 故障在任何系统中都无法避免，并且可能随时会发生，因此我们需要构建可以容忍故障，或可以从故障中恢复的系统。 在系统中，失败是常态而不是例外。 可能出错的事情就会出错。 复杂系统包含在它们内部的故障潜伏的变化。 \r","date":"2021-08-24","objectID":"/sre/:9:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"故障指标 Failure Metrics 测量和追踪系统的常见的故障指标： 平均恢复时间(MTTR, Mean time to repair)：恢复故障的系统的平均时间 平均故障间隔时间(MTBF, Mean time between failures)：一个故障和下一个故障之间的平均操作时间 平均失败时间(MTTF, Mean time to failure)：预期在系统故障前系统的平均时间 平均检测时间(MTTD, Mean time to detect)：从故障出现到检测到的平均时间 平均调查时间(MTTI, Mean time to investigate)：从检测到故障到调查原因和解决方法之间的平均时间 平均恢复服务的时间(MTRS, Mean time to restore service)：从检测到故障的组件到用户可用的平均经过时间 系统事件的平均时间(MTBSI, Mean time between system incidents)：两个连续事件检测之间的平均经过时间（MTBSI = MTBF + MTRS） 故障率(Failure rate)：故障发生的频率 \r\r","date":"2021-08-24","objectID":"/sre/:9:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"故障隔离 Fault Isolation Terms 系统应具有短路(short circuit)。如果通知不起作用，则站点应该通过删除功能，而不是让整个站点挂掉，来优雅地处理该故障。 泳道(Swinlane)是最常用的故障隔离方法之一。它从其它服务中增加了障碍到服务中，以便故障不会影响到其它服务。 假设我们有一个广告系统，我们可以有两个架构： 如果在每个新闻请求期间同步生成广告，则广告功能中的故障将传播到新闻功能中。相反，如果我们使用泳道隔离新闻和广告，广告故障将不会划入到新闻，如果广告不符合SLA，最坏的情况是，我们可以没有广告。 让我们来看一个新模型的示例。 \r\r","date":"2021-08-24","objectID":"/sre/:9:2","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"泳道 准则(Swimlane Principles)： 尽可能少的共享(share as little as possible)。在泳道内共享的越少，泳道更容易变得孤立。 没有什么跨越泳道边界。同步通信从未跨越泳道边界。 方法(Swimlane Approaches)： 泳道就是摇钱树。永远不要允许你的收银器向其它系统妥协。 泳道是最大的事件来源。识别疼痛的重复原因并分离它们。 泳道是天然屏障。 \r\r \r\r指标和监控系统 Metrics and Monitoring: https://linkedin.github.io/school-of-sre/level101/metrics_and_monitoring/introduction/ 监控是任何系统的一个组成部分。作为SRE，你需要了解监控服务基础架构。也可参考Google SRE book。 有以下主题： 监控是什么 需要测量什么 聚集的指标如何用于改善业务决策和整体可靠性 告警 日志处理 什么是可观测性 分布式追踪 日志 指标 监控的四个黄金信号 Four golden signals of monitoring 流量(Traffic) 延迟(Latency) 错误(Error) 饱和度(Saturation) \r监控为什么重要 一些关键用例： 即使解决问题(Reduction in time to resolve issues) 商业决策(Business decisions) 资源计划(Resource planning) \r一些基本术语： metric Node/Host QPS Latency Error rate Graph Dashboard Incident MTTD MTTR \r监控基础架构： \r\r","date":"2021-08-24","objectID":"/sre/:9:3","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"命令行工具 Command-line tools 大多数的Linux发行版都带有一组监控性能的工具集。 ps/top ss free df/du sar iftop iotop tcpdump \r\r","date":"2021-08-24","objectID":"/sre/:10:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"告警 \r\r","date":"2021-08-24","objectID":"/sre/:11:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"最佳实践 Best practices for monitoring 使用正确的指标类型 Gauge Timer Counter 避免过度监控 防止告警疲劳 有告警流程 \r\r","date":"2021-08-24","objectID":"/sre/:12:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"可观测性 Observability 展示 Grafana 日志 ELK stack 追踪 Jaeger Zipkin \r\r \r\r安全性 Security: https://linkedin.github.io/school-of-sre/level101/security/intro/ \r","date":"2021-08-24","objectID":"/sre/:13:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"基础知识 Fundamentals \r","date":"2021-08-24","objectID":"/sre/:14:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"概述 Introduction to Security Overview for SRE SRE和安全工程(Security Engineering)都与保持系统可用相关 发生中断、容量短缺和配置错误等问题可能导致系统无法使用 破坏用户信任的安全或隐私事件也会破坏系统的实用性 系统安全应该是SRE的首要考虑因素 SRE应该参与重要的设计讨论和实际的系统更改 有助于防止可能影响基础设施整体安全性的不良设计和实施 成功地设计、实施和维护系统，需要对完整的系统生命周期做出承诺 信息安全核心： 保密性(Confidentiality) 完整性(Integrity) 可用性(Availability) 像安全工程师一样思考 启动新应用应该考虑： 有缺陷吗？ 如何滥用一个功能可能导致设计缺陷？ 默认情况下是否需要此功能？ OWASP安全准则(Open Web Application Security Project) 最小化攻击面(Minimize attack surface area) 添加到应用程序的每个功能都会为整个程序增加一定的风险。安全开发的目的是通过减少攻击面积来降低整体风险。 建立安全默认值(Establish secure defaults) 开箱即用的功能应该默认是安全的。例如，默认情况下，应启用用户密码复杂度和老化。用户可以关闭功能。 最小化权限的原则(Least privilege) 建议账户具有执行业务流程所需的最小的权限。 深度防御原则(Defense in depth) 安全地失败(Fail securely) 不要相信服务(Don’t trust services) 不要过度信任第三方服务 职责分离(Separation of duties) 欺诈行为的关键是职责分离 管理员不应该是程序运行用户 通过模糊来避免安全性(Avoid security by obscurity) 保持安全性简单化(Keep security simple) 正确修复安全问题(Fix security issues correctly) 一旦确定了安全问题，在不引入回归的情况下开发正确的修复是必不可少的。 可靠性和安全性(Reliability and Security) \r\r","date":"2021-08-24","objectID":"/sre/:14:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"认证和授权 Authentication and Authorization 密码是常见的认证因素。还有MFA多因子认证。 授权是提供用户权限访问特定资源或功能。 \r常见认证流程： 用户注册 应用程序存储用户信息到数据库 应用发送验证信息来验证 用户登录 用户访问 \rOpenID和OAuth： OpenID是一个认证协议，允许我们在不使用本地认证系统的情况下验证用户。 OAuth是一种授权机制，允许你的应用用户访问特定内容提供者（如Gmail/Facebok/Ins/…）。 \r\r","date":"2021-08-24","objectID":"/sre/:14:2","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"密码学 Cryptography 它是一门科学和研究，将任何文本隐藏起来，只有指定的收件人或授权人员才能阅读。 密码学是保护关键信息的必要方法，通过编码一些纯文本将其转化为私有数据。 \r密码 Ciphers 密码是密码学的基石。密码是一组对消息进行加密(encryption)或解密(decryption)的算法。 # 加密算法E，密钥k，消息内容m，加密文件c E(k, m) = c # 解密算法D，密钥k，加密文件c，消息内容m D(k, c) = m D(k, E(k, m)) = m \r流密码(stream Ciphers)： 消息被分解成字符(characters)或位(bits)，并使用密钥或密钥流(随机且独立于消息生成)进行加密，密钥或密钥流的长度和明文流相同。 如果密钥流是随机的，此方案是不可破解的，除非获得密钥流。密钥流必须以安全的方式提供给双发，以防止其释放。 \r块密码(Block Ciphers)： 以块的形式处理消息，然后对每个块进行加密或解密。 块密码是一个对称密码，其中测录快作为整体处理并用于生成密文块。块大小通常为64bits或128bits。 \r加密(Encryption) 对称加密(Secret Key, Symmetric Key)：相同的密钥用于加密和解密。 非对称加密(Public Key, Asymmetric Key)：在非对称密钥中，加密和解密密钥是不同的，但又互相关联。加密密钥称为公钥(publick key)，解密密钥称为私钥(private key)。公私钥称为密钥对。 \r对称密钥加密(Symmetric Key Encryption) DES(Data Encryption Standard) 55bits的对称加密算法，由于长度不够，它易于具有足够资源的暴力攻击。 通常在块密码中操作，由此它将在64bits块中加密数据。 基于简单的数学函数，所以它可以在硬件中轻松实现加速。 3DES(Triple DES) 原始的56bits长度不够，无法承受有限预算的攻击。 将DES三次连续应用。 AES 具有可变block长度和key长度 AES替代DES和3DES，因为它们太弱了。AES更快更有效，如果使用纯软件加速，AES也更适合高吞吐量。由于它比较年轻，更成熟的算法总是更信任。 \r非对称密钥加密算法(Asymmetric Key Algorithm) \r Diffie-Hellman RSA Hashing Algorithms 哈希基于单向数学函数，反向则很难。 MD5 MD5是一种单向函数，它很容易从给定的数据计算处哈希值，反之则不行。 SHA-1, SHA-256 由于MD5具有一些弱点，所以认为MD5比SHA-1弱一些 数字证书(Digital Certificates) 数字签名，提供数字验证设备和个人用户的方法。 密钥管理被认为加密系统中困难的任务。 PKI(Public Key Infrastructure)为管理数字安全属性提供了分层框架。每个PKI参与者都拥有一个由CA发布的数字证书。证书包含多个当事方协商安全连接时使用的属性。这些属性必须包括证书有效期，最终主机标识信息，安全通信的加密密钥，CA的签名。其它可选属性取决于PKI的要求。 CA是可以信任的第三方。 要验证CA的签名，接收方必须知道CA的公钥。 CA Enrollment process 终端主机生成密钥对。 终端主机生成证书请求，它转发到CA。 手动人为干预需要批准CA收到的请求。 CA操作员批准请求后，CA使用私钥签署证书请求，并将已完成的证书返回到终端主机。 终端主机将证书写入非易失性存储区域 \r\r","date":"2021-08-24","objectID":"/sre/:14:3","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"登录安全 Login Security \rSSH SSH(Secure Shell)，一种流行的、强大的、基于软件的网络安全方法。 每当计算机向网络发送数据时，SSH都会自动对其进行加密。当数据到达预期接收者时，SSH会自动对其进行解密。 结果时透明加密的，用户可以正常工作，不知道他们的通信在网络上时安全加密的。此外，SSH可以根据其配置方式使用现代安全的加密算法。 SSH是C/S架构。 SSH创建一个通道，用于在远程机器上运行shell，并在两个系统之间进行端到端加密。 通过强加密保护你的数据隐私 保证通信的完整性，保证没有被篡改 认证 授权 转发或隧道加密其它基于TCP/IP的会话 \r\rKerberos 根据希腊神话，Kerberos(Cerberus)是一只巨大的三头犬，它守卫这冥界的大门，以防止死者离开。 在计算机科学中，它是一种计算机网络认证协议，对个人通信以安全的手段进行身份认证。目前是微软ActiveDirectory中使用的默认技术。 使用对称密钥加密，并需要一个可信的第三方身份验证服务来验证用户身份。 客户端：用户或服务 服务端：Keberos保护主机驻留 \rKDC(Key Distribution Center)，充当可信的第三方认证服务。KDC包含以下两个服务器： 认证服务器(AS, Authentication Server)：performs the initial authentication and issues ticket-granting tickets(TGT) for users. 票务授权服务器(TGS, Ticket-Granting Server)：issues service tickets that are based on the initial ticket-granting tickets. \r\r证书链 Certificate Chain OpenSSL命令的输出的第一部分显示了编号为0, 1, 2(不再是2)的三个证书。每个证书有一个subject和issuer。第一个证书编号0，称为端实体证书(end-entiy certificate)。主题行告诉我们，它对任何google.com的任何子域都有效，因为它的主题设置为*.google.com。 openssl s_client -connect www.google.com:443 -CApath /etc/ssl/certs CONNECTED(00000005) depth=2 OU = GlobalSign Root CA - R2, O = GlobalSign, CN = GlobalSign verify return:1 depth=1 C = US, O = Google Trust Services, CN = GTS CA 1O1 verify return:1 depth=0 C = US, ST = California, L = Mountain View, O = Google LLC, CN = www.google.com verify return:1 --- Certificate chain 0 s:/C=US/ST=California/L=Mountain View/O=Google LLC/CN=www.google.com i:/C=US/O=Google Trust Services/CN=GTS CA 1O1 1 s:/C=US/O=Google Trust Services/CN=GTS CA 1O1 i:/OU=GlobalSign Root CA - R2/O=GlobalSign/CN=GlobalSign --- Server certificate -----BEGIN CERTIFICATE----- xxx -----END CERTIFICATE----- subject= issuer= \r\rTLS握手 TLS Handshake 客户端发送HELLO消息给服务端，其中包含它所支持的协议和算法。 服务端返回HELLO并发送其证书链。基于客户端的功能，服务器选择密码套件。 如果密码套件支持短信密钥(ephemeral key)交换，则服务端和客户端用Diffie-Hellman算法协商一个主密钥(premaster-key)。 客户端和服务端创建一个会话密钥(session key)，用于加密通过连接传输的数据。 在握手的末尾，双方拥有用于加密其余连接的数据的私密会话密钥(secret session key)。这是OpenSSL指作为Master-Key的原因。 \r\r\r","date":"2021-08-24","objectID":"/sre/:14:4","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"网络安全 Network Security: https://linkedin.github.io/school-of-sre/level101/security/network_security/ \r\r","date":"2021-08-24","objectID":"/sre/:15:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"介绍 Introduction TCP/IP是当今占主导地位的网络技术。它是一个五层架构。除此之外，还有其它网络技术。出于方便起见，我们使用OSI网络模型来表示非TCP/IP的网络技术。不通的网络使用网关互连，网关可以放置在任何层。 OSI模型是一个七层架构。 \rOSI参考模型各层的简短描述： 应用层作为应用程序和网络程序之间的接口。它支持应用程序和终端用户处理。常见的应用层程序包括远程登录、文件传输、邮件和网页浏览。 表示层处理不同形式的数据。它允许驻留在不同平台的不同侧的应用程序能够理解彼此的数据格式，而不管它们是如何呈现的。 会话层负责创建、管理和关闭通信连接。 传输层负责提供可靠连接，如数据包排序、流量控制、拥塞控制。 网络层负责将与设备无关的数据包从当前跳路由到下一跳(hop)。 数据链路层负责将与设备无关的数据包封装成与设备有关的数据帧(frame)。它有两个子层：逻辑链路控制和媒体访问控制。 物理层负责通过某些物理介质传输与设备相关的帧。 从应用层开始，应用程序产生的数据逐层向下传递到物理层。层层封装（来自前一层的数据被封装在当前的新信封中，其中来自前一层的数据也只是包含来自更前一次的数据的信封）。在每层添加的信封包含足够的信息来处理数据包。应用层数据被分为足够小的块，以封装在下一层的信封中。 应用程序数据块在TCP/IP架构中基于以下步骤进行装扮。在发送端，当应用程序数据块传递到TCP层时，它封装在TCP数据包中。换句话说，一个TCP数据包由header和payload组成，头部对应TCP信封，有效负载是应用程序数据块。同样，TCP数据包在向下传递到IP层时将被封装在IP数据包中。IP数据包由header和payload组成，有效载荷是从TCP层传递下来的TCP数据包。当IP数据包向下传递到数据链路层时，它将被封装在依赖于设备的帧中（如以太网帧）。一个数据帧有一个头部，也可能有一个尾部。当它向下传递到物理层时，一个帧将被转换成一系列媒体信号进行传输。 在目的端，媒介信号由物理层转换成帧，向上传递到数据链路层。数据链路层将帧的有效载荷传递给IP层。IP层将有效载荷传递给TCP层。TCP层将TCP有效载荷(即应用程序数据块)传递到应用层。当数据包到达路由器时，它只能转到IP层，其中IP包头部中的某些字段被修改（TTL-1）。然后将修改的数据包向下传递给物理层以进一步传输。 \r\rPKI 公钥基础涉设施(PKI, Public Key Infrastructure) 要在网络应用程序中部署加密算法，我们需要一种使用开放网络分发私钥的方法。公钥加密是分发这些私钥的最佳方法。要使用公钥加密，我们需要构建一个公钥基础设施(PKI)来支持和管理公钥证书和证书颁发机构(CA)网络。 特别是，PKIs设置为执行以下功能： 在向他们发出公钥证书之前确定用户的合法性。 在用户请求时发出公钥证书。 在用户请求时扩展公钥证书有效时间。 在用户请求或相应的私钥泄露时撤销公钥证书。 存储和管理公钥证书。 防止数字签名的签名者否认他们的签名。 支持CA网络允许不同的CA验证其他CA拌饭的公钥证书。 X.509 \r\rIPsec IPsec: A Security Protocol at the Network Layer IPsec是网络层的主要安全协议。 IPsec为构建虚拟专用网络(VPN)提供了强力的平台。VPN是覆盖在公共网络上的专用网络。 在IP层部署加密算法的目的是加密或验证IP数据包。 IPsec还制定了如何交换密钥。因此，IPsec由身份认证协议、加密协议和密钥交换协议组成。它们称为： AH: authentication header ESP: encapsulating security payload IKE: internet key exchange \r\r电子邮件安全 PGP \u0026 S/MIME : Email Security 应用层上有几种安全协议。最常用的这些协议是名称为PGP和S/MIME的电子邮件安全协议。 SMTP（simple mail transfer protocol）用于从客户端发送和交付到服务端，通过25端口，它是传出服务器(outcoming)。相反，POP(post office protocol)允许用户拾取消息并将其下载到他们的收件箱中，它是传入服务器(incoming)，使用110端口，最新的是POP3。 \rPGP PGP实现了所有的主要加密算法，ZIP加密算法，Base64编码算法。 它用于认证和加密信息。PGP遵循如下过程：身份认证，ZIP压缩，加密和Base64编码。 Base64编码过程使消息为SMTP传输做好准备。 \rGnuPG GnuPG是另一个免费加密标准 GnuPG是赛门铁克PGP的替代平 两者主要的区别是所支持的算法。由于GnuPG是开放的，一些企业更愿意使用PGP的技术支持和用户界面。 GnuPG和PGP在兼容性上存在一些细微差别，如某些算法之间的兼容性，但在大部分应用程序在有解决方法。 \rS/MIME SMTP仅能处理7为ASCII文本消息。虽然POP可以处理7位ASCII之外的其它内容类型，但在常见的默认设置下，POP可能会将存储在邮件服务器中的所有消息下载到用户的本地计算机。之后，如果POP从邮件服务器上删除了这些消息。这使得用户难以从多台计算机读取消息。 多功能互联网邮件扩展协议(MIME, multipupose internet mail extension protocol)，旨在支持以各种格式发送和接收电子邮件，包括文档处理器、图形文件、声音文件、视频文件等非文本文件。此外，MIME允许单个消息中包含这些混合类型组合形式的数据。 互联网邮件访问协议(IMAP, internet mail access protocol)，存储传入邮件服务器的电子邮件，直到用户故意删除它们。这允许用户从多台计算机访问其邮箱，并将消息下载到本地计算机，而不从邮件服务器 的邮箱中删除它。 \rSSL/TLS SSL使用PKI通过要求服务器使用可信的CA签署的安全的证书，来决定服务器的公钥是否值得信赖。 Netscape Navigator 1.0，它信任由RSA数据安全公司操作的CA。 服务器的public RSA keys用于存储在安全证书中，然后浏览器可以使用它来建立安全的通信通道。我们今天使用的安全证书依赖于Netscape Navigator 1.0当时使用的相同标准(X.509)。 网景打算培训用户（尽管后来没有成功），区分安全通信和不安全通信，因此他们在浏览器地址栏旁边放了一个锁图标。当锁打开时，通信是不安全的。关闭的锁意味着通信已使用SSL进行保护，这需要服务器提供签名证书。网景的工程师真正创建了安全互联网的标准。 SSL 3.0在2015年开始弃用。为了标准化SSL，IETF创建了一个稍微修改的SSL 3.0，并于1999年将其发布为TLS 1.0。SSL和TLS之间的名称更改使很多人感到困惑。正式地讲，TLS是新的SSL，但在实践中，人们交替使用SSL和TLS来谈论任何版本的协议。 \r\r","date":"2021-08-24","objectID":"/sre/:15:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"网络外围安全 Network Perimeter Security \r通用防火墙框架 General Firewall Framework 防火墙是必须的，因为加密算法无法有效阻止恶意数据包进入边缘网络。 无论是加密的数据包，都可以始终转发到边缘网络中。 防火墙在1990年代被开发来帮助限制网络访问。防火墙可以是硬件设备，软件包或两者的解和。 在数据包允许进入(从外部进入内部网络)之前先评估它。防火墙的一个关键元素是它能够检查数据包而不对通信速度产生负面影响，同时为内部网络提供安全保护。 防火墙检查数据包的几种方法。基于防火墙使用的特定方法，它可以表征为包过滤器、电路网关、应用网关、动态包过滤器。 \r\r包过滤器 Packet Filters 它检查从外部到内部网络的入数据包，检查从内部网络到外部的出数据包。 包过滤仅检查IP和TCP头部信息，不包括有效载荷。 包过滤防火墙使用一组规则来确定是否应该允许或拒绝它。 两种类型： Stateless：它将每个数据包视为一个独立的对象，它不会跟踪任何先前处理的数据包。换句话说，它检查数据包并不留下检查记录。 Stateful：连接状态过滤，追踪内部主机和外部主机之间的连接。连接状态指示它是TCP还是UDP连接，以及是否建立连接。 \r\r电路网关 Circuit Gateways 电路网关，也称为电路级网关，通常在传输层操作。 它评估IP地址和端口信息（TCP/UDP header），并使用它们来确定是允许还是拒绝。 通常做法是组合怕过滤器和电路网关以形成动态包过滤器(DPF, dynamic packet filter)。 \r\r应用网关 Application Gateways(ALG) Aka代理服务器 应用级网关充当内部主机的代理，处理来自外部客户端的请求。 应用级网关对每个IP数据包执行深度检查 特别地，应用级网关检查包含在数据包中的应用程序数据格式(MIME, SQL…)，并决定是否允许有效载荷。 因此，应用级网关能够检测到有效载荷中包含的计算机病毒。由于它检查了有效载荷，因此它还能够检测恶意代码和隔离的数据包。另一方面，应用级网关也会引发大量的计算和开销。 \r\r可信系统和堡垒机 Trusted Systems and Bastion Hosts 可信操作系统是一个符合特定安全要求的系统。 系统设计不含缺陷(defects)。 系统软件不包含漏洞(loopholes)。 系统配置正确。 系统管理是合适的。 堡垒机 堡垒机是具有强大防御机制的计算机。 堡垒机也主要用于受控进入点(controlled ingress)，以便安全检测可以更狭隘地关注在单点紧密的动作。 \r\r","date":"2021-08-24","objectID":"/sre/:15:2","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"扫描和抓包 Scannings, Packet Capturing \r使用nmap扫描端口 Scanning Ports with Nmap nmap(network mapper)是一个免费且开源的使用工具，用于网络发现和安全审计。nmap通常用于确定网络中的活动主机，这些主机上的开放端口，这些开放端口上运行的服务和版本。 \rnmap使用6种不同的端口状态： Open：开放的端口主动接收TCP, UDP或SCTP连接。开放的端口是最受欢迎的东西，因为它是易受攻击的事物。开放的端口还显示了网络上的可用服务。 Closed：接收并响应nmap探测数据包，但此端口上没有侦听应用程序。用于检测主机或系统的端口。 Filtered：nmap无法确定端口是否打开，因为数据包过滤可阻止其探针到达端口。过滤可能来自防火墙或路由器规则。 Unfiltered：端口可访问，但nmap不知道它是否开启还是关闭。 Open/Filtered：nmap无法确定是打开还是过滤。当打开的端口没有响应时，回发生这种情况。 Closed/Filtered：nmap无法确定是关闭还是过滤。 \rnmap扫描的类型： TCP连接 TCP连接扫描完成三次握手 如果端口打开，则操作系统完成TCP三次握手，端口扫描器立即关闭连接以避免DOS攻击。 UDP扫描 检查UDP端口是否侦听 由于UDP不像TCP那样响应一个积极的ACK，并且当端口关闭时才能响应传入的UDP包。 SYN扫描 SYN扫描是其它形式的TCP扫描 此扫描也称为半开放扫描(half-open)，因为它永远不会完全打开完整的TCP连接。 端口扫描器生成SYN包。如果目标端口是打开的，它将使用SYN-ACK包进行响应。扫描器主机响应RST包，在握手完成之前关闭连接。 如果端口关闭到未过滤，则目标立即响应RST包。 SYN扫描有个有点，各个服务从未实际接收连接。 FIN扫描 ACK扫描 ACK扫描确定端口是否过滤 空扫描 将所有TCP header flags设置为off或null 这通常不是有效的数据包，有些主机不知道该怎么办 XMAS扫描 RPC扫描 IDLE扫描 \r\rOpenVAS 一个全功能的漏洞扫描器 一个服务和工具的框架，提供全面而强大的漏洞扫描和包管理 一个开源程序 由三部分组成： NVTs(Network Vulnerability Tests) Scanner SQLite3用于存储配置和扫描结果 \r\rWireShark 一个协议分析器。 \r\rDumpCap 一个网络流量转存工具。它从实时网络捕获数据包，并将数据包写入文件。dumpcap原生捕获的文件格式是pcapng，这也是wireshark使用的格式。 \r\rDaemonLogger DaemonLogger是一个数据包记录应用程序，专门用于网络和系统管理环境。 \r\rNetSniff-NG NetSniff-NG是一个高性能的数据包捕获工具。 \r\rNetflow Netflow是1996年思科路由器上引入的功能，提供了收集IP网络流量的功能，因为路由器是进出口。通过分析Netflow提供的数据，网络管理员可以确定流量、服务类型和拥塞原因。 \r\rIDS 一种在环境中检测到安全事件相关的安全解决方案，但不会阻止它们。IDS传感器可以是软件和基于硬件的用于收集和分析网络流量。这些传感器有两个类型，网络IDS和主机IDS。 host IDS是一个在服务器上运行的特定服务器的代理，其最小开销是监控操作系统。 network IDS可以嵌入网络设备、独立设备或监控网络流量的模块种。 \r\r","date":"2021-08-24","objectID":"/sre/:15:3","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"TCP/IP安全事件 TCP/IP Security Issues \r\rIP欺骗 IP Spoofing 攻击者替换IP地址（发送端或接收端）。 通常用于利用目标主机来启动DOS攻击(denial-of-service)。 在DOS攻击中，攻击者修改IP数据包以误导目标主机，以接受原始数据包作为在可信主机处提供的数据包。攻击者必须知道受信任的主机IP地址才能修改数据包头部，以便看起来数据包来自该主机。 \rIP欺骗检测技术： 直接TTL探测 此技术将一个数据包发送到可疑的欺骗IP主机，该主机触发回复并将TTL与可疑数据包进行比较。如果TTL不同，则这是一个欺骗性的数据包。 当攻击者和受害者位于不同的子网中时，此技术是成功的。 IP标识号。 TCP流控制 发送欺骗TCP数据包的攻击者，将不会收到目标的SYN-ACK数据包。 因此，攻击者不能响应于拥塞窗口大小的变化。 即使在窗口大小耗尽之后，接收器仍然接收流量时，大多数可能是数据包被欺骗。 \r\r隐蔽信道 Covert Channel 隐蔽或秘密通道可以最好地描述为可通过进程或应用程序以违反系统安全规划的方式进行信息来利用的两个实体之间的管道或通信信道。 更具体于TCP/IP，在某些情况下，建立隐蔽信道，并且可在两个终端系统之间秘密地传递数据。 如ICMP协议，ICMP ECHO请求消息应具有8字节头部和56字节有效载荷。有效载荷中不应携带任何数据，但这些数据包通常用于携带机密信息。ICMP数据包被稍微改变以在有效载荷中携带机密数据。这使得数据包大小较大，但协议栈中不存在无法控制以打败此行为。ICMP数据包的更改允许入侵者编程专门的C-S对。这些小片代码导出机密信息而不提醒管理员。 \r\rIP分段攻击 IP Fragmentation Attack IP协议允许对数据包进行分段 IP分段偏移用于跟踪数据报的不同部分 此字段中的信息或内容用于在目的端重组数据报 所有这些分片都具有相同的标识字段值，分片偏移指示当前分片在原始数据包上下文中的位置 许多接入路由器和防火墙并不执行数据包重组。在正常运行中，IP分段不会重叠，但攻击者可以人为地创建分段的数据包来误导路由器或防火墙。 IP分段攻击的一个栗子是死亡Ping(Ping of Death)攻击。 \rTCP标志 TCP Flags 使用TCP的数据交换发生在三次握手成功之后。此握手使用不同的标志来影响TCP分段的处理方式。 TCP header中的标志位有6bits： URG(urgent pointer field) ACK(acknowledgement field) PSH(push function) RST(reset the connection) SYN(synchronize sequence numbers) FIN(the sender is finished with this connection) 攻击者可以利用这些标志来发起DoS攻击。 \r\rSYN洪泛攻击 SYN FLOOD 攻击者经常利用三次握手中的计时器来瘫痪服务，甚至瘫痪系统。 第二次握手后，接收SYN后的等待没有时间限制。攻击者向webserver发起许多连接请求（几乎可以肯定是使用了欺骗性的IP地址）。 webserver发送的数据包(第二次握手, SYN+ACK)发送回源IP不会被回复。这使得TCP会话处于半开放状态(half-open)。多个数据包就会导致多个半开放，消耗服务器资源。 基于服务器的硬件限制，TCP会话的数量是有限的。因此，一旦达到某个限制，服务器就会拒绝任何主机的连接尝试。在新建立连接之前，这些半开放连接需要完成或超时。 \rFIN攻击 FIN Attack 在正常操作中，发送发设置TCP FIN标志，表示不再传输数据且可以关闭连接。 这是一种四次挥手机制。发送方和接收方都希望发送ACK数据包和接收FIN数据包。 在攻击期间，它试图终止连接，会构造一个欺骗性的FIN数据包。此构造的数据包还具有正确的序列号，因此数据包被目标主机视为有效。这些序列号易于预测。 \r\r连接劫持 Connection Hijacking 授权用户A通过TCP会话发送HTTP请求给webserver 只有数据包具有正确的SEQ/ACK号，webserver才接受来自用户的数据包。这些数字号对于服务端来区分不同的会话并确保它仍然于用户A交谈。 想象一下，攻击者使用正确的序列号开始向webserver发送数据包（欺骗的用户A的IP地址）。webserver接受数据包并递增ACK号。 与此同时，用户A继续发送数据包，但使用不正确的SEQ/ACK编号。由于发送未同步(unSYN)的数据包，当webserver接收时，所有来自用户A的数据都被丢弃。攻击者假装使用正确的数字号成为用户A。 最终结果是攻击者劫持了连接，用户A被完全混淆了，webserver回复假设攻击者正在发送正确的同步数据。 \r\r缓冲区溢出 Buffer Overflow 缓冲区是一个临时的数据存储区域，用于存储程序代码和数据。 当程序或进程尝试将更多数据存储在缓冲区，而不是最初预期保存，则会发生缓冲区溢出。 缓冲区是内存中的临时存储位置，其以字节为单位存储固定数量的数据。 当建索数据可以存储在缓冲区位置多时，其它信息必须进入相临的缓冲区，会导致覆盖其上保持的有效数据。 \r机制： 缓冲区溢出漏洞有多种类型。但所有缓冲区溢出攻击的整体目标是接管对特权程序的控制，如果可能的话，接管对主机的控制。 攻击者有两个目标要实现。首先，脏代码需要在程序的代码地址空间(memory)中提供。其次，特权程序应跳转到代码的特定部分，这确保了正确的参数加载到内存中。 第一种，通过在正确的地址空间中注入代码或使用现有代码并稍微修改特定参数。第二种复杂些，因为需要修改程序的控制流以使程序跳转到脏代码。 \r对策： 最重要的方法是在编写正确的代码上有一个协调一致的重点。 确保程序的数据缓冲区地址空间的代码不可执行。 \r\r更多欺骗 地址解析协议欺骗 Address Resolution Protocol Spoofing 地址解析协议(ARP)将IP地址解析或映射到MAC子层地址 使用ARP欺骗，攻击者可以通过欺骗主机的MAC地址。基本上，攻击者可以让本地网络上的任何主机或设备相信攻击者的工作站是可信任的主机。 通过在网络的所有主机和路由器中实施静态ARP表，可以防止ARP欺骗。 \rDNS欺骗 DNS欺骗是黑客让目标机器相信它要连接的系统是xxx的机器。 破解者修改了DNS映射记录。在某些情况下，DNS服务器遭到攻击。 为了对抗DNS欺骗，反向查找(reverse lookup)会检测这些攻击。反向查找验证名称和IP。 \r\r\r","date":"2021-08-24","objectID":"/sre/:15:4","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"网络攻防 Threats, Attacks, Defense: https://linkedin.github.io/school-of-sre/level101/security/threats_attacks_defences/ \r","date":"2021-08-24","objectID":"/sre/:16:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"DNS保护 DNS Protection \r缓存中毒攻击 Cache Poisoning Attack 由于缓存了DNS响应，因此可以快速响应DNS查询。DNS否定查询也会被缓存（如拼写错误的单词），并且所有缓存的数据都会定期地超时。 缓存中毒是所谓欺骗中的一个问题。该术语用于描述黑客通过伪造DNS映射将网站流量重定向到虚假网站的攻击。在这种情况下，攻击者尝试将互联网域的虚假地址插入DNS。如果服务器接受虚假记录，那就是缓存中毒，并且随后对域中的地址请求都将响应被攻击者控制的虚假地址。只要服务器缓存了假的条目，浏览器或电子邮件服务器就会自动转到受妥协的DNS服务器提供的地址。缓存条目的TTL通常是几个小时，从而会使得会有众多的用户受到攻击的影响。 \r\rDNSSEC DNS Security Extension 上面这些DNS问题的长期解决方法是身份认证。如果解析器无法在响应中区分有效数据和无效数据，则添加源身份认证。 DNSSEC防止数据欺骗和损坏，并提供对服务器和请求的认证机制，以及建立真实性和完整性的机制。 在验证DNS响应时，每个DNS区域使用私钥签名其数据。特定记录的查询返回资源记录集和它的签名。解析器使用公钥来验证响应。 DNSSEC的目标是为没有机密性或DDoS保护的DNS响应提供身份验证和完整性。 \r\rBGP 边界网关协议(BGP, border gateway protocol)，它是一种路由协议，在多个自治系统(AS, Autonomous Systems)之间交换路由信息。 自治系统是路由器或网络的集合，通常在单个管理控制下具有相同的网络策略。 BGP告诉路由器，使用哪个hop可以到达目标网络。 BGP用于在AS(内部)和多个AS之间的路由器之间传递信息。 \r\r","date":"2021-08-24","objectID":"/sre/:16:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"BGP如何工作 How BGP Works BGP负责查找到目标路由器的路径（最短和最可靠）。 该决定是通过称为链路状态(link state)的协议完成的。使用链路状态协议，每个路由器向网络中的所有其它路由器广播其链接和IP子网的状态。然后，每个路由器从其它路由器接收信息，并构建整个网络的完整拓扑视图。下一跳(next-hop)路由表基于此拓扑视图。 链路状态协议使用的是计算机科学领域最出名的算法， 迪杰斯特拉最短路径算法。我们从路由器开始考虑到所有直接邻接的路径成本。然后 采取最短路径。然后，我们重新查找我们的所有邻居，我们可以使用成本信息来达到和更新我们的链路状态。我们继续采用最短路径，直到访问每个路由器。 \r\r","date":"2021-08-24","objectID":"/sre/:16:2","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"BGP漏洞 BGP Vulnerabilities 通过腐化BGP的路由表，能够影响互联网上的流量流向。此动作称为BGP劫持(hijacking)。 通过恶意源将伪造信息向分布式BGP路由数据库注入广告信息，意外地或路由器可以扰乱互联网骨干网络。 黑洞交通(Blackholing traffic)。黑洞路由即网络路由，即路由表条目，这无处可去，并且匹配路由前缀的数据包被丢弃或忽略。只能通过监控丢失的流量来检测黑洞路由。黑洞路由是针对许多常见病毒攻击的最佳防御，流量从被注入的机器到控制的主机被丢弃了。 2008年，巴基斯坦决定通过创建一个引入黑洞的BGP路由来阻塞Youtube。把路由信息传递给香港ISP，从那时起，意外地传播到世界其它地区，这意味着数百万被路由到这个黑洞，因此无法访问Youtube。 潜在地，BGP的最大风险发生在拒绝服务发现攻击(DoS)中，其路由器被超多它处理能力的请求数据包洪泛淹没。当网络开始携带过多的BGP消息时，发生网络过载和路由器资源耗尽。 路由器震荡(router flapping)是另一种类型的攻击。路由震荡是指BGP路由表的重复变化，通常一分钟好几次。以高速撤销和重新广告可能对路由器造成严重的问题，因为它们传播了路由通知。如果这些路由震荡足够快，如每秒50次，则路由器过载，最终阻止有效路由收敛。对互联网用户的潜在影响是消息传递的放缓，在某些情况下，可以根本不提供数据包。 \rBGP Security BGP安全建议使用BGP peer认证，因为它是防止恶意活动的最强大的机制之一。认证机制是IPsec或BGP MD5。其它方法，如前缀限制(prefix limits)来避免填充路由表。 \r","date":"2021-08-24","objectID":"/sre/:16:3","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"Web攻击 Web-Based Attacks \rHTTP响应拆分攻击 HTTP Response Splitting Attacks 此攻击可能发生在服务器脚本在没有适当预防的情况下在HTTP响应头部中嵌入用户数据。 当脚本在重定向响应(HTTP 3xx)的重定向URL中嵌入用户数据时，通常回发生这种情况。或者当脚本在响应设置Cookie在Cookie值中嵌入用户数据。 此攻击可用于执行Web缓存中毒和跨站点脚本攻击。 此攻击的攻击者发送一个HTTP请求，该请求强制Web服务器形成输出流，然后将目标解释为两个而不是一个HTTP响应。 \r\r跨站点请求伪造 Cross-Site Request Forgery (CSRF or XSRF) 此攻击将受害者的浏览器授予向漏洞的Web应用程序发出命令。 漏洞是由浏览器引起的，包括用户身份认证数据，会话ID，IP地址，Windows域凭据等。 攻击者使用CSRF启动交易，如传输资金，登录登出用户，关闭账户，访问敏感信息和更改账户详细信息。 该漏洞由浏览器引起，浏览器会自动包含每个请求的凭据(如表单、脚本或图像)。CSRF也可以动态地构造为扩展点脚本攻击的有效载荷的一部分。 所有依赖于自动凭据的站点都很脆弱。流行的浏览器无法防止跨站点请求伪造。尽快登出高价值站点可以减轻CSRF风险。建议高价值网站必须要求客户端手动提供用于执行安全影响任何操作的相同的HTTP请求的身份认证数据（二次认证）。限制会话cookie的生命周期也可以减少其它恶意站点使用的机会。 OWASP推荐网站开发人员在于敏感业务函数关联的HTTP请求中包含所需的安全令牌，以便减轻CSRF攻击。 \r\r跨站点脚本攻击 Cross-Site Scripting (CSS or XSS) Attacks 在动态生成的网页显示用户输入时发生跨站点脚本，如未正确验证的登录信息，允许攻击者将恶意脚本嵌入生成的页面中，然后在任何可查看站点的用户的机器上执行脚本。 如果成功，可利用跨站点脚本漏洞来操纵和窃取Cookie，创建可能误认为时有效用户，危及机密信息或在最终用户系统上执行恶意代码的请求。 此攻击涉及在受害者浏览器上执行恶意脚本。受害者只是用户主机，而不是服务器。 \r\r文档对象模型跨站点脚本攻击 Document Object Model (DOM) XSS Attacks 基于XSS的DOM不需要Web服务器接收XSS有效载荷来实现成功的攻击。攻击者通过在客户端嵌入它们的数据来滥用运行时。攻击者可以强制客户端(浏览器)呈现页面，其中包含由攻击者控制的DOM的部分。 当页面呈现并由页面处理数据时，通常由客户端的HTML嵌入式脚本（如JS），页面的代码可能不安全地载入页面本身中的数据，从而提供跨站点脚本有效载荷。有几个DOM对象可以作为攻击车轮，用于将恶意脚本提供给受害者浏览器。 \r\r点击劫持 Clickjacking 该技术通过在合法站点的内容下面隐藏恶意链接/脚本来工作。 网站上的按钮实际上包含隐形链接，攻击者也可以放置在那。因此，点击一个视觉上的对象的人实际上被欺骗到访问恶意页面或执行恶意脚本。当鼠标移动到点击劫持时，结果是毁灭性的。 尚未有有效防御点击劫持的方法，禁用JS是唯一可行的方法。 \r\r","date":"2021-08-24","objectID":"/sre/:16:4","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"数据库攻防 DataBase Attacks Defenses \rSQL注入攻击 SQL injection Attacks 它利用数据库查询中不正确的输入验证。一个成功的利用将允许攻击者访问、修改或删除数据库中的信息。它允许攻击者窃取存储在受影响网站的后端数据库中的敏感信息。 SELECTUSERNAME,PASSWORDfromUSERSwhereUSERNAME='\u003cusername\u003e'ANDPASSWORD='\u003cpassword\u003e';#Heretheusername\u0026passwordistheinputprovidedbytheuser.Supposeanattackergivestheinputas\" OR '1'='1'\"inbothfields.ThereforetheSQLquerywilllooklike:SELECTUSERNAME,PASSWORDfromUSERSwhereUSERNAME=''OR'1'='1'ANDPASSOWRD=''OR'1'='1';#Thisqueryresultsinatruestatement\u0026theusergetsloggedin.ThisexampledepictsthebostbasictypeofSQLinjection \r\rSQL注入攻防 SQL注入可以通过过滤查询来消除恶意的语法来保护，这涉及使用一些工具来扫描源代码。 输入字段应限制为绝对最小，通常为7-12字符，并验证任何数据。 \r\r","date":"2021-08-24","objectID":"/sre/:16:5","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"VPN VPN(virtual private network)是一种通过共享公共基础设置提供安全、可靠连接的服务。思科将VPN定义为私有网络之间通过公共网络的加密连接。目前为止，有三种类型的VPN： Remote access Site-to-site Firewall-base \r\r","date":"2021-08-24","objectID":"/sre/:16:6","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"安全漏洞 Security Breach 任何导致违反机密性、完整性、可用性(CIA, confidentiality, integrity, availability)的事件都可能导致安全漏洞。 \r拒绝服务攻击 DoS, Denial of Service Attacks DoS攻击会导致宕机或用户无法访问系统。它会影响信息系统安全的可用性。它通过占用计算机来执行大量非必要的任务来拒绝服务的协调尝试。这种过度的活动使得系统无法执行有效操作。 两种常见类型的DoS攻击： 逻辑攻击(Logic attacks)，使用软件缺陷来崩溃或阻塞 远程服务器的性能。你可以安装软件的最新补丁来防止这些攻击。 洪泛攻击(Flooding attacks)，通过发送大量的无用请求，泛滥攻击使得受害者机器CPU、内存、网络瘫痪。如SYN洪泛攻击。 对DoS攻击的最佳防御之一是使用入侵防御系统(IPS, instrusion prevention system)的软件或设备，来检测和停止攻击。 \r\r分布式拒绝服务攻击 DDoS, Distributed Denial of Service Attacks DDos攻击中，攻击者劫持了成千上万台互联网计算机，在这些系统中种植自动攻击代理。然后，攻击者指示代理用伪造消息轰炸目标网站。这使得该网站过载并组织了许多合法的请求。这里的关键是代理的数量。 \r\r窃听 Wiretapping 虽然窃听术语通常与语言电话通信相关联，但攻击者还可以使用窃听以拦截数据通信。 攻击者可以偷听电话线和数据通信线。窃听可能是主动地，攻击者对该线路进行修改；也可能是被动地，其中未经授权的用户只是在不改变内容的情况下侦听传输。被动入侵可以包括用于随后活动攻击的数据复制。 主动窃听有以下两种： 在线路之间窃听(between-the-lines)，不改变合法用户发送的消息，但是当合法用户暂停时，该类型的窃听会向其中插入额外的数据。 背驼式窃听(Piggyback-entry)，拦截并修改原始信息，通过打破通信线路并将消息路由到充当主机的零一计算机。 \r\r后门 Backdoors 软件开发人员有时在他们的程序中包含了隐藏的访问方式，称为后门。后门让开发人员或支持人员能够轻易地访问系统，而无需与安全控件斗争。问题是后门并不总是保持隐藏。当攻击者发现后门时，可以利用后门来绕过现有的安全控制。 \r\r","date":"2021-08-24","objectID":"/sre/:16:7","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"恶意攻击 Malicious Attacks \r生日攻击 Birthday Attack 一旦攻击者妥协了了哈希密码文件，就会执行生日攻击。它是一种加密攻击，用于制作单向哈希的蛮力攻击。这是一种数学漏洞，是基于概率理论的生日问题。 \r\r暴力密码攻击 Brute-Force Password Attacks 在暴力密码破解中，攻击者会在系统上尝试不同的密码，直到其中一个成功。通常，攻击者使用软件程序，以尝试可能的密码组合，直到密码匹配。 \r\r字典密码攻击 Dictionary Password Attacks 字典攻击是一个简单的攻击，依赖于用户选择的糟糕的密码。一个简单的密码程序从字典文件中获取所有单词，并将其作为密码尝试。 \r\r重放攻击 Replay Attacks 重放攻击涉及从网络捕获数据包，并重新调整它们以产生未经授权的效果。收到重复、经过验证的IP数据包可能会扰乱服务或其它不期望的后果。当攻击者重用旧消息来欺骗系统用户时，可以通过重放攻击来攻破系统。这有助于入侵者获取到未经授权访问系统的信息。 \r\r中间人攻击 Man-in-the-Middle Attacks 中间人攻击中，攻击者在将他们转移到预期目的地之前拦截两方之间的消息。 网站欺骗(web spoofing)是一种中间人攻击类型，用户认为使用特定的web服务器会存在安全的会话。实际上，安全连接仅存在于攻击者，而不是web服务器。攻击者与web服务器建立安全连接，充当不可见的中间人。攻击者传递用户和web服务器之间的流量。通过这种方式，攻击者可以欺骗用户提供密码、信用卡和其它私有数据信息。 \r\r伪装 Masquerading 在伪装攻击中，一个用户或计算机会假装成另一个用户或计算机。它通常包括其它形式的主动攻击，如IP地址欺骗或重放。攻击者可以捕获身份验证序列，然后重放它们以再次登录到应用程序或操作系统。例如，攻击者可能会监视发送到弱web服务器的用户名和密码。然后，攻击者可以使用截取的凭据模拟用户登录web程序。 \r\r窃听 Eavesdropping 当主机在混杂模式下设置其网络接口时，会发生窃听或嗅探，并在通过以后分析通过的数据包。混杂模式使网络设备能够在给定时间内拦截和读取每个网络数据包，即使数据包的地址与网络设备不匹配。可以附加硬件和软件来监视和分析该传输介质上的所有数据包，而无需警告其他用户。 窃听的候选方法包括卫星、无线、移动和其它传输方式。 \r\r社会工程学 Social Engineering 攻击者经常使用一种称为社会工程学的欺骗技术来访问IT基础设施中的资源。在几乎所有的情况下，社会工程都涉及欺骗授权用户为未授权用户执行操作。社会工程学攻击的成功取决于人们想要提供帮助的基本倾向。 \r\r窃听 Phreaking 电话窃听，或简称窃听，是一个俚语，描述了研究、试验或探索电话系统、电化设备等的人们的文化活动。窃听是利用电话系统中存在的错误和故障的艺术。 \r\r网络钓鱼 Phishing 网络钓鱼是一种欺诈，攻击者视图诱骗受害者提供私人信息。 \r\r域名欺诈 Pharming 域名欺诈是另一种类型的攻击，旨在通过域欺骗来获取个人或私人财务信息。它不使用消息来诱骗受害者进入访问似乎合法的欺骗网站。相反，它中毒一个DNS上的域名，称为DNS中毒的过程。结果是，当用户请求中毒服务器的web地址，会被导航到攻击者的网站。用户的浏览器仍然显示正确的网站，这使得域名欺诈难以检测，因此更严重。 \r\r\r","date":"2021-08-24","objectID":"/sre/:16:8","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"编写安全的代码 Writing Secure Code: https://linkedin.github.io/school-of-sre/level101/security/writing_secure_code/ 减少安全性和可靠性问题的第一步也是最重要的步骤是教育开发人员。然而，即使是最佳培训的工程师也会犯错误，安全专家也可能会写出不安全的代码，SRE也可能错过可靠性问题。很难让许多考虑因素和权衡的同时建立安全和可靠的系统，特别是如果你也负责生产软件。 \r","date":"2021-08-24","objectID":"/sre/:17:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"使用框架来加强安全性和可靠性 Use frameworks to enforce security and reliability while writing code 一个更好的方法是在通用框架、语言和库中处理安全性和可靠性。多个应用程序使用同一个库或框架，如果存在安全问题，修复框架就能快速修复问题。 \r\r","date":"2021-08-24","objectID":"/sre/:17:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"常见安全漏洞 Common Security Vulnerabilities OWASP和SANS发布的常见漏洞类列表： OWASP前十漏洞 框架强化措施 SQL Injection TrustedSQL String Broken Authentication Require authentication using well tested mechanisms like OAuth before routing a request to the application. Sensitive data exposure Use distinct types to store and handle sensitive data. XML External Entities Use XML parser without XXE enabled. Broken Access Control Requires every request handler or RPC to have well defined access control restrictions. Security Misconfiguration Use a technology stack that provides secure configurations by default and restricts or doesn’t allow risky configuration options. Cross-Site Scripting XSS Use an XSS hardened template system. Insecure Deserialization Use deserialization libraries that are build for handling untrusted inputs. Usint Components with Known Vulnerabilities Choose libraries that are popular and actively maintained. Insufficient Logging Monitoring Log and monitor requests and other events as appropriate in a low level library. \r\r","date":"2021-08-24","objectID":"/sre/:17:2","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"编写简单代码 Write Simple Code 尝试使你的代码清洁和简单。 \r\r避免多级嵌套 Avoid Multi-Level Nesting 多级嵌套是一种常见的反模式(anti-pattern)，可能会导致简单的错误。如果错误位于最常见的代码路径中，则它可能会被单元测试给捕获到。然而，单元测试并不总是检查多级嵌套代码中的错误处理路径。该错误可能会导致可靠性降低或安全漏洞。 \r\r消除YAGNI气味 Eliminate YAGNI Smells 你不需要它（YAGNI, You Aren’t Gonna Need It) 有时，开发人员通过添加可能在将来有用的功能，以防万一来开发出的解决方案。这增加了不必要的复杂性，因为它需要记录、测试和维护。这与YAGNI原则相悖，这建议你仅实施你需要的代码。 总而言之，避免YAGNI代码能够提高可靠性，更简单的代码导致的安全问题也较少，维护和开发时间也较少。 \r\r偿还技术债务 Repay Technical Debt 你需要有一个清晰的过程（分配时间）来偿还相关债务。 \r\r重构 Refactoring 重构是保持代码库情节和简单的最有效的方法。无论重构的原因如何，你都应该始终遵循一个黄金原则：切勿将重构和功能改变混为代码库的单个提交。重构变化通常很大，并且很难理解。如果提交还包含了功能更改，则审阅这可能会忽略错误。 \r\r单元测试 Unit Testing 单元测试可以在发版之前确定各个软件组件中的广泛错误，提高系统安全性和可靠性。该技术涉及将软件组件打破到更小的、自包含的单元，其没有外部依赖，然后测试每个单元。 \r\r模糊测试 Fuzz Testing 模糊测试是一种用来补充前述测试技术的技术。涉及使用模糊引擎产生大量候选输入，然后通过模糊驱动传递给模糊目标。然后，模糊器分析系统如何处理输入。如文件解码器、压缩算法、音频解码器等。 \r\r集成测试 Integration Testing 集成测试超出各个单元和抽象，替换数据库或网络服务的伪造或停顿实现，具有真实的实现。因此，集成测试锻炼更完整的代码路径。由于你必须初始化和配置其它依赖，因此集成测试可能比单元测试更慢。要执行测试，此方法包含实际遍历，如服务通信中端到端的网络延迟。 \r\r其它重要部分 Code Reviews Rely on Automation Don’t check in Secrets Verifiable Builds \r\r \r\rLinux中级 Linux-Intermediate: https://linkedin.github.io/school-of-sre/level102/linux_intermediate/introduction/ \r\r","date":"2021-08-24","objectID":"/sre/:17:3","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"包管理 Package Management: https://linkedin.github.io/school-of-sre/level102/linux_intermediate/package_management/ 包管理是一种在任何操作系统上安装和维护软件程序的方法。 在Linux早期，人们需要下载软件源代码来编译和安装它。随着Linux变得成熟，开始了以包的形式来分发软件。包文件是包含软件，依赖，安装说明和元数据的压缩集合 。 软件包很少是独立的，它依赖于不同的软件，库和模块。包管理可以解决这个艰难的依赖关系并安装它们。 存储库是所有包 ，更新，依赖的存储位置。每个仓库都可以包含成千上万的软件包。 \r # 更新包信息 dnf update # 列出所有帮库 dnf repolist all # 添加仓库 dnf config-manager --add-repo http://www.example.com/example.repo \r有两种主要类型的包管理工具： 低级工具(low-level)：主要用于安装、删除和升级包文件（dpkg, dnf） 高级工具(high-level)：除了低级的功能，还可以进行元数据搜索和依赖解析（apt-get, dnf） \r\r","date":"2021-08-24","objectID":"/sre/:18:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"存储介质 Storage Media: https://linkedin.github.io/school-of-sre/level102/linux_intermediate/storage_media/ 存储介质是用于存储数据和信息的设备(device)。有多种物理存储设备（硬盘等），虚拟存储设备（RAID，LVM，网络存储等）。 使用mount命令查看和挂载存储设备，当然还有/etc/fstab文件使之变得简单。 文件系统负责任何存储设备上的数据存储、索引和检索。一些常用的文件系统： FAT NTFS ext ext4 xfs HFS HFS+ NFS \r文件系统有可能因为一些原因（电源故障、不当关机等）而遇到问题，Linux通常在启动期间检查和修复损坏的磁盘。可以使用fsck命令来手动检查和修复文件系统损坏。 \r\r","date":"2021-08-24","objectID":"/sre/:19:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"RAID 独立冗余磁盘阵列(RAID, Redundant Arrays of Independent Disks)，在多个磁盘上分配I/O，以实现更高的性能和数据冗余的技术。软件RAID使用计算机的CPU进行RAID操作，而硬件RAID在磁盘控制器上使用专用处理器来管理磁盘。 RAID的三个基本特性： 镜像(mirroring) 条纹化(striping) 奇偶性(parity) \rRAID级别： RAID 0(Striping) RAID 1(Mirroring) RAID 4(Striping with dedicated parity) RAID 5(Striping with distributed parity) RAID 6(Striping with double parity) RAID 10(RAID 1+0, Mirroring and Striping) \r\r","date":"2021-08-24","objectID":"/sre/:19:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"LVM 逻辑卷管理(LVM, Logical Volume Management) 使用LVM可以在存储分配中实现更大的灵活性，如可以缝合三个2TB磁盘以制作6TB的单个分区，或者可以将4TB的另一个物理磁盘连接到服务器，并将该磁盘添加到逻辑卷组中使其总量为10TB。 \r\r","date":"2021-08-24","objectID":"/sre/:19:2","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"归档和备份 Archiving and Backup: https://linkedin.github.io/school-of-sre/level102/linux_intermediate/archiving_backup/ \r\r","date":"2021-08-24","objectID":"/sre/:20:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"VIM \r\r","date":"2021-08-24","objectID":"/sre/:21:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"Bash脚本 \r\r \r\rLinux高级 \r","date":"2021-08-24","objectID":"/sre/:22:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"容器和编排 Containers and orchestration: https://linkedin.github.io/school-of-sre/level102/containerization_and_orchestration/intro/ 容器、Docker和K8s很酷！ \r\r","date":"2021-08-24","objectID":"/sre/:23:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"容器介绍 容器是一个标准的软件单元，打包代码和所有依赖，因此应用程序可以从一个计算环境到另一个计算环境快速且可靠地进行交付。 Why containers: 快速可靠地交付 环境变量的一致性 在单台主机上运行多个容器 每个容器都有自己孤立的环境（这意味着单片应用可以分解为微服务并打包到容器，孤立的环境不会让一个容器的应用程序的失败影响另一个，这称为故障隔离(fault isolation)） 资源配额 \r\r虚拟机和容器 虚拟机(VM, virtual machine)和容器(container)。 类似于在单个主机上运行多个容器，我们也可以在单个主机上运行多个VM，以这种方式，可以在单独的虚拟机中运行应用程序（或每个微服务）。 这里的主要关注点是虚拟机和容器的大小。虚拟机包含了访客操作系统(guest os)，因此会比容器更重。 \r\r容器如何实现 容器与主机操作系统共享相同的内核(kernel)，并为应用程序提供孤立的环境。没有像虚拟机那样在主机操作系统上运行guest os的额外开销，要感谢Linux内核的两个功能：cgroups和namespace。 容器是一个Linux进程或一组Linux进程，容器外部的进程是受限的（由namespace实现），使用的资源量（由cgroup实现），可在容器内部进行系统调用。 \r\rNamespace 容器内进程的可见性应限制在其自身内。这是Linux Kernel namespace所做的。这个的思路是命名空间中的进程不能影响那些它看不到的进程。共享单个命名空间的进程具有其所在命名空间内唯一的身份、服务和接口。 这是Linux命名空间列表： Mount：共享mount namespace的进程组共享一组单独的私有挂载点和文件系统视图。对这些命名空间挂载点所做的任何修改在此命名空间外都是不可见的。 PID：pid namespace中的进程尽在命名空间内具有唯一的进程号。一个进程可以是它自己的pid命名空间中的根进程(root process, pid 1)，并且在它下面有一个完整的进程树。 Network：每个network namespace都有自己的网络设备实例，可以配置单独的网络地址。同一个网络命名空间中的进程可以有自己的端口和路由表。 User：user namespace可以有自己的uid和gid。在主机中使用非特权用户的进程可能在用户命名空间中拥有root用户身份。 Cgroup：允许创建只能在cgroup namespace内使用的cgroup。 UTS：uts namespace有自己的主机名和域名IPC。每个IPC namespace都有自己的System V和POSIX消息队列。 \r看起来很复杂，但在Linux中创建namespace很简单。 示例，在Linux中创建一个PID namespace。 # 查看主机系统上运行的进程 ps aux # 使用unshare命令创建一个PID namespace # 并在此命名空间中创建一个bash进程 sudo unshare --fork --pid --mount-proc bash ps aux # 在同一个命名空间中创建一个其它进程 sleep 1000\u0026 ps aux # 在新开的终端，查看sleep ps aux | grep sleep # 这两者的PID不一样，但其实指向的是相同的进程。 \r\rCgroup cgroup(control group)可以定义为一组进程的计量和监控资源使用。资源可以是memory page, disk io, cpu等。事实上，cgroup是基于资源限制，并在违反了限制时采取何种行动。 cgroup中的组件，其追踪c资源使用率和控制进程行为，称为资源子系统(resource-subsystem)或资源控制器(resource controller)。 以下是EHEL对cgroup的资源控制器的介绍： blkio：此子系统限制块设备的IO cpu：限制进程的CPU使用量 cpuacct：生成cgroup中进程的CPU资源使用的报告 cpuset：为cgroup中的进程分配单独的CPU(多核)和内存节点 devices：控制进程能够访问某些设备 freezer：挂起或恢复cgroup中的进程 memory：限制进程的内存使用量 ns：控制cgroup中的进程使用不通的namespace cgroup遵循每个资源控制器的分层，树形结构，即每个控制器都存在一个cgroup。层次结构中的每个cgroup从它的父亲(parent cgroup)处继承某些属性。 \r示例，配置cgroup。 # 查看cgroup工具 mount | grep \"^cgroup\" # 如果没有，则安装工具 # sudo yum install libcgroup-tools -y # 创建一个属主为root的memory cgroup sudo cgcreate -a root -g memory:mem_group # 查看 # /sys/fs/cgroup/\u003ccgroup type\u003e ls -l /sys/fs/cgroup/memory | grep 'mem_group' # 查看内存限制，mem_group继承的父亲的属性 cat /sys/fs/cgroup/memory/mem_group/memory.limit_in_bytes # 查看parent cgroup cat /sys/fs/cgroup/memory/memory.limit_in_bytes # 现在减少它的内存限制为20KB echo 2000 \u003e /sys/fs/cgroup/memory/mem_group/memory.limit_in_bytes cat /sys/fs/cgroup/memory/mem_group/memory.limit_in_bytes # 限制很低，因此附加到mem_group的大多数进程应该都会被OOM杀死。 # 创建一个新shell附加到mem_group cgexec -g memory:mem_group bash Killed # 如预期，进程被OOM杀死了。你可以使用dmesg日志(mm_fault_error)确认情况。 \r容器与底层主机操作系统共享相同的内核，并且在内部提供应用程序的孤立环境。cgroup帮助管理容器中的进程使用的资源，namespace帮助隔离环境（network stack, pids, uids, gids, mount points），使运行在同一个主机上的其它容器相隔离。 \r\r容器引擎 容器引擎(container engine)简化了在主机中创建和管理容器的过程。怎样做？ 容器创建流程通常以容器镜像开始。 容器镜像构建、推送和拉取。 容器引擎解包镜像并为此应用创建孤立的环境。 容器镜像中的文件将挂载到孤立的环境中，以在容器内启动并运行应用程序。 有许多容器引擎，如Docker, RKT, LXC，它们需要不同的镜像格式。OCI(Open Container Initiative)是由Docker启动的协作项目，该项目旨在跨供应商间标准化容器运行时和镜像格式。 \r\r","date":"2021-08-24","objectID":"/sre/:23:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"使用Docker进行容器化 Containerization With Docker: https://linkedin.github.io/school-of-sre/level102/containerization_and_orchestration/containerization_with_docker/ 有关Docker详情参考Docker文档。 \r\r","date":"2021-08-24","objectID":"/sre/:23:2","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"使用K8s进行编排 Orchestration With Kubernetes：https://linkedin.github.io/school-of-sre/level102/containerization_and_orchestration/orchestration_with_kubernetes/ 有关K8s详情参考K8s文档。 \r\r","date":"2021-08-24","objectID":"/sre/:23:3","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"系统调用和信号 System Calls and Signals：https://linkedin.github.io/school-of-sre/level102/system_calls_and_signals/intro/ 对信号和系统调用的基本理解。 \r","date":"2021-08-24","objectID":"/sre/:24:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"信号 Signals：https://linkedin.github.io/school-of-sre/level102/system_calls_and_signals/signals/ 中断(interrupt)是改变程序正常执行流程的事件，可由硬件设备甚至CPU本身产生。当中断发生时，当前的执行流暂停，中断处理程序运行。中断处理程序运行后，恢复先前的执行流。 有三种类型的事件可能导致CPU中断：硬件中断，软件中断和异常。 信号只不过是软件中断，通知进程发生的事件。这些事件可能是来自用户的请求，或发生的系统问题。每个信号都有一个信号编号和定义的默认操作。 进程可以通过一下任何方式对它们做出反应： 操作系统提供的默认方式 以程序预定义的方式来捕获并处理信号 完全忽略信号 \r\r信号类型 Types of signals 你可以使用kill -l命令，来列出Linux系统上的可用信号。下表列出了1到20的信号。 Signal name Signal number Default Action Meaning SIGHUP 1 Terminate Hangup detected on controlling terminal or death of controlling process SIGINT 2 Terminate Interrupt from keyboard SIGQUIT 3 Core dump Quit from keyboard SIGILL 4 Core dump Illegal instruction SIGTRAP 5 Core dump Trace/breakpoint trap for debugging SIGABRT , SIGIOT 6 Core dump Abnormal termination SIGBUS 7 Core dump Bus error SIGFPE 8 Core dump Floating point exception SIGKILL 9 Terminate Kill signal(cannot be caught or ignored) SIGUSR1 10 Terminate User-defined signal 1 SIGSEGV 11 Core dump Invalid memory reference SIGUSR2 12 Terminate User-defined signal 2 SIGPIPE 13 Terminate Broken pipe;write pipe with no readers SIGALRM 14 Terminate Timer signal from alarm SIGTERM 15 Terminate Process termination SIGSTKFLT 16 Terminate Stack fault on math co-processor SIGCHLD 17 Ignore Child stopped or terminated SIGCONT 18 Continue Continue if stopped SIGSTOP 19 Stop Stop process (can not be caught or ignore) SIGTSTP 20 Stop Stop types at tty \r\r","date":"2021-08-24","objectID":"/sre/:24:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"系统调用 系统调用是内核的受控入口点，允许进程请求内核来执行一些在此进程上的操作。内核通过系统调用应用程序编程接口(system call API)为程序提供一系列服务。应用程序开发人员通常没有直接访问这些系统调用，但可以通过API访问它们。 例如，这些服务包括创建新的进程，执行IO，创建进程通信的管道。系统调用组合是固定的，每个系统调用由唯一的数字表示。 系统调用将处理器状态从用户模式(user mode)更改为内核模式(kernel mode)，以便CPU可以访问受保护的内核存储。每个系统调用可能具有一组参数，其指定要从用户空间(进程的虚拟地址空间)传输到内核空间的信息，反之亦然。从编程角度来看，调用系统调用看起来很想调用C函数。 \r\r系统调用类型 主要有五种不同的系统调用。 进程控制(process control)：用于处理与进程创建、终止等进程相关的任务。 文件管理(file management)：用于读写文件等文件相关的操作。 设备管理(device management)：用于处理设备读写入设备缓冲区等。 信息维护(information maintenance)：处理信息及在操作系统和用户程序之间的转换。 通信(communication)：用于内部进程间的通信。 \r 系统调用类型 Linux示例 进程控制 fork(), exit(), wait() 文件管理 open(), read(), write() 设备管理 ioctl(), read(), write() 信息管理 getpid(), alarm(), sleep() 通信 pipe(), shmget(), mmap() \r\r用户态和内核态 User mode, kernel mode and their transitions 现代处理器架构通常允许CPU至少有两种模式可以操作：用户态和内核态。相应地，虚拟内存区域可以被标记为用户空间或内核空间的一部分。在用户态下运行时，CPU只能访问标记在用户空间中的内存，尝试访问内核空间中的内存会导致硬件异常。 在任何给定时间，一个进程在用户态或内核态执行。可以执行的指令类型却决于模式，这在硬件级别强制执行。CPU模式(处理器模式)是一些计算机架构的中央处理单元的操作模式，该架构将限制CPU运行的某些进程执行的操作的类型和范围。内核本身不是一个进程，而是一个进程管理器。内核态假定需要内核服务的进程使用特定的编程构造——称为系统调用。 在用户态下执行程序时，它无法直接访问内核数据结构或内核程序。但是，当应用程序在内核态下执行时，这些限制不再适用。程序通常在用户态下执行，并且仅在请求内核提供的服务时切换到内核态。如果应用程序需要访问系统上的硬件资源（如外设、磁盘、内存等），则必须发出系统调用，上下文从用户态切换到内核态。读写文件时，遵循此过程。它在内核态下运行系统调用自身，而不是应用程序代码。当系统调用完成后，使用反向上下文切换，进程返回到用户态。 \r\r使用strace在Linux上Debug strace是一个用于追踪用户进程和Linux内核之间转换的工具。 ~]$ strace printf %s \"Hello world\" execve(\"/usr/bin/printf\", [\"printf\", \"%s\", \"Hello world\"], [/* 47 vars */]) = 0 brk(NULL) = 0x90d000 mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f8fc672f000 access(\"/etc/ld.so.preload\", R_OK) = -1 ENOENT (No such file or directory) open(\"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 3 fstat(3, {st_mode=S_IFREG|0644, st_size=98854, ...}) = 0 mmap(NULL, 98854, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f8fc6716000 close(3) = 0 open(\"/lib64/libc.so.6\", O_RDONLY|O_CLOEXEC) = 3 read(3, \"\\177ELF\\2\\1\\1\\3\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0\u003e\\0\\1\\0\\0\\0\\20\u0026\\2\\0\\0\\0\\0\\0\"..., 832) = 832 fstat(3, {st_mode=S_IFREG|0755, st_size=2156160, ...}) = 0 mmap(NULL, 3985888, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7f8fc6141000 mprotect(0x7f8fc6304000, 2097152, PROT_NONE) = 0 mmap(0x7f8fc6504000, 24576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1c3000) = 0x7f8fc6504000 mmap(0x7f8fc650a000, 16864, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7f8fc650a000 close(3) = 0 mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f8fc6715000 mmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f8fc6713000 arch_prctl(ARCH_SET_FS, 0x7f8fc6713740) = 0 mprotect(0x7f8fc6504000, 16384, PROT_READ) = 0 mprotect(0x60a000, 4096, PROT_READ) = 0 mprotect(0x7f8fc6730000, 4096, PROT_READ) = 0 munmap(0x7f8fc6716000, 98854) = 0 brk(NULL) = 0x90d000 brk(0x92e000) = 0x92e000 brk(NULL) = 0x92e000 open(\"/usr/lib/locale/locale-archive\", O_RDONLY|O_CLOEXEC) = 3 fstat(3, {st_mode=S_IFREG|0644, st_size=106075056, ...}) = 0 mmap(NULL, 106075056, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f8fbfc17000 close(3) = 0 open(\"/usr/share/locale/locale.alias\", O_RDONLY|O_CLOEXEC) = 3 fstat(3, {st_mode=S_IFREG|0644, st_size=2502, ...}) = 0 mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f8fc672e000 read(3, \"# Locale name alias data base.\\n#\"..., 4096) = 2502 read(3, \"\", 4096) = 0 close(3) = 0 munmap(0x7f8fc672e000, 4096) = 0 open(\"/usr/lib/locale/UTF-8/LC_CTYPE\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory) fstat(1, {st_mode=S_IFCHR|0620, st_rdev=makedev(136, 1), ...}) = 0 mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f8fc672e000 write(1, \"Hello world\", 11Hello world) = 11 close(1) = 0 munmap(0x7f8fc672e000, 4096) = 0 close(2) = 0 exit_group(0) = ? +++ exited with 0 +++ \r execve(\"/usr/bin/printf\", [\"printf\", \"%s\", \"Hello world\"], [/ 47 vars /]) = 0 第一个系统调用execve()做以下三件事： 操作系统停止重复的进程 操作系统载入新程序(printf)，并启动这个新进程 execve替换使用从printf可执行文件加载的新内容定义当前进程的内存堆栈 execve是被调用执行的系统调用的名称。第一个参数必须是二进制可执行文件或脚本的路","date":"2021-08-24","objectID":"/sre/:24:2","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"安全 Security 本节将涵盖服务内外部面临的威胁。这将触及周边安全性，DDoS保护，网络分界和操作实践。 \r\r","date":"2021-08-24","objectID":"/sre/:25:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"安全威胁 Security Threat 安全是任何基础架构中的首要考虑因素之一。有各种各样的安全威胁，可能会增加数据盗窃，服务损失，欺诈活动等。 攻击者可以使用如下技术进行攻击： 网络钓鱼(Phishing) 垃圾邮件(Spamming) 恶意软件(Malware) 拒绝服务攻击(Dos/DDos) 漏洞(Exploiting vulnerabilities) 中间人攻击(man-in-the-middle attack) \r\r","date":"2021-08-24","objectID":"/sre/:25:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"保护基础设施 Securing the infrastructure 一旦知道了不同的威胁，必须设计和实现安全防御机制。保护基础设施的一些手段： 周边安全(Perimeter security) 这是任何基础设施中防御的第一行，当不需要/意外的流量流入基础架构设施，它们应该被过滤/阻止。这些可以在边缘路由器中过滤，允许预期服务（如80/443），或设置过滤器阻止不需要的流量。 如，云安全组，第一条先默认拒绝所有，然后在此之上添加允许。如允许公网访问80,443。允许白名单访问ssh和一些特定服务。 \rDDoS缓解(mitigation) 防止DDoS攻击也是一个重要的方面。攻击流量类似于正常的用户/客户端请求，但有意洪泛外部暴露的应用程序。因此，必须在攻击流量和用户流量之间进行区分。为此，存在不同的方法在应用程序级别执行，其中一个方法是使用验证码来捕获机器流量。 对于这些有用的方法，节点应该能够处理攻击流量和正常流量。在基于云的基础架构中，可能可以通过快速添加资源以处理突峰流量；而在自建数据中心，添加资源可能具有挑战性。 为了处理大量的攻击流量，有可用的解决方案。可以检查数据包/流量，并识别不像正常连接的异常流量。如客户端启动TCP连接，但无法完成握手，或一组来源，有巨大的异常流量。一旦识别出这种不需要的流量，可在网络边缘丢弃这些流量，从而保护应用程序节点的资源。 \r网络划分(Network Demarcation) 网络分界是根据其安全性需求和攻击漏洞，将应用程序分组到不同网络中部署的一种策略。一些常见的划分，外部/互联网面对节点被分组到单独的区域，而具有敏感数据的节点被分离到另外单独的区域。在安全工具的帮助下，限制这些区域之间的任何通信，以限制不需要的访问。这些内部区域间的通信过滤器有时称为环形栅栏(ring-fencing)。 创建多区域的主要优点是，即使存在受损的主机，它也不会充当基础设施其余部分的后门。 \r节点保护(Node protection) 服务器，路由器，交换机，负载均衡器，防火墙等，每个设备都具有某些功能来保护自己。 \r其它实践 安全事件处理的标准操作流程(STANDARD OPERATING PROCEDURES)： 当安全事件发生时，告知谁 确定安全事件的规模和严重程度 使用哪些解决方案来缓解安全事件 有关安全事件的数据用于进一步分析 定期审查(PERIODIC REVIEW)基础设施的整体安全性： 识别可能瞄准基础设施的安全威胁 定期审查安全事件处理标准流程 确保软件更新/补丁及时完成 审计基础设置中任何不合规的安全标准 审查最近的安全事件，并找到提高防护的机制 \r\r\r","date":"2021-08-24","objectID":"/sre/:25:2","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"规模 Scale 部署大规模应用程序，需要更好地了解基础架构功能，如资源可用性，域名故障，伸缩选型(如使用多播)，四/七层负载均衡器，基于DNS的负载均衡。 建立大规模应用是一个复杂的活动，应该涵盖设计、开发和运营中的许多方面。 \r\r","date":"2021-08-24","objectID":"/sre/:26:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"域名故障 Failure domains 在任意基础设施中，由于硬件或软件问题导致的故障很常见，应该将这些失败保持到最低限度。 \r服务器故障 Server failures 由于硬件或软件问题，服务器可能会失败。这可能导致某些数据包丢失。因此，在设计服务时，应该考虑对于此故障的容错性。 \rToR failures 连接服务器的叶片交换机(leaf switch)不可用，这也是一个常见的问题。需要计划在不重新加载其它服务器的情况下处理多少服务器丢失。基于此，服务可以分布在多个机柜上。 \r站点故障 站点故障是一个通用术语，它可能意味着一个网站中的特定服务挂了（新版问题、防火墙问题、网络问题、DNS问题、LB问题等）。这些问题可能不常见，但会产生重大影响。 总之，在设计应用程序本身时必须考虑处理这些失败场景。应用程序内提供容错，以从意外的故障中恢复。 \r\r","date":"2021-08-24","objectID":"/sre/:26:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"资源可用性 Resource availability 另一个考虑的方面时基础结构的可用性，并且取决于服务的功能。 有如下伸缩项： 多播(anycast) 负载均衡器(load balancer) 基于DNS的负载均衡(DNS based load balancing) \r多播 这是在多个机柜中推出流量分布最快的方式。 为了在这些服务器上实现流的比例分布，重要的是在每个cabinet和pod中保持均匀性。但请记住，分发只会基于流，如果有任何大流量，则某些服务器可能会收到更高的流量。 \r负载均衡器 另一个常见的方法时使用负载均衡器。 负载均衡器可以在单臂(single-arm)模式下部署，其中到VIP的流量由LB重定向，从服务器返回的流量直接发送到客户端。另一种是双臂模式，其中返回流量也通过LB。 \r基于DNS的负载均衡 与上述类似，唯一的区别是负载均衡在DNS处完成。客户端在查询服务的DNS记录的时候，会获取到不同的IP地址来连接。DNS服务器必须进行健康检查，以了解哪个服务器处于良好状态。 \r\r","date":"2021-08-24","objectID":"/sre/:26:2","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"RTT 延迟(latency)在确定分布式服务的整体性能方面发挥着关键作用。 往返时延(RTT, Round-Trip Time)是时间的度量，数据包从A到B并返回A所需的时间。它以毫秒为单位。它的影响体现在不同服务器/服务间的调用中，以及可以实现的TCP吞吐量。 服务对其集群内的服务器或不同服务（如认证、日志、数据库等）进行多次调用，以响应每个客户端请求，这是相当常见的。这些服务器可以分布在不同的机柜，甚至不同的数据中心。随着RTT的增加，每个调用的响应时间变长，从而对发送给用户的最终响应产生级联效应。 \r\r","date":"2021-08-24","objectID":"/sre/:27:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"基础设施服务 Infrastructure Services \r","date":"2021-08-24","objectID":"/sre/:28:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"ToR连通性 ToR(The Onion Router, 洋葱路由器) 这是常见的故障点，可使用不同的选项将服务器连接到ToR。 \r\r \r\r系统设计 System Design 我们对应用的基本要求是： 为大量合理的用户工作 避免服务故障/集群奔溃 换句话说，我们希望构建一个可用，可扩展和容错的系统。 \r\r","date":"2021-08-24","objectID":"/sre/:28:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"大型系统设计 \r\r \r\r系统设计 System Design: https://linkedin.github.io/school-of-sre/level102/system_design/intro/ \r\r \r\r故障排除和性能优化 System troubleshooting and performance improvements 本章提供有关解决系统问题的一般介绍，如api故障，资源利用，网络问题，硬件和操作系统问题。还介绍了系统性能分析(profiling)和基准测试(benchmarking)。 故障排查无法通过完成一门课程来学习，它是一个持续学习的过程。包括： 日常运行和开发 查找和修复应用bug 查找和修复系统和网络问题 性能分析和改进 等 \r从SRE的角度来看，理解以下方面： 了解资源，如主机规范，CPU、内存、磁盘、网络等 理解系统设计和架构 确保正确收集重要的指标 What gets measured gets fixed. \r\r","date":"2021-08-24","objectID":"/sre/:29:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"故障排除 Troubleshooting 系统故障的排除有时可能会棘手或乏味。在这种情况下，我们需要检查服务的端到端(end-to-end)流程，所有下游，分析日志，内存泄露，CPU使用，磁盘IO，网络错误，主机问题等。了解某些实践和工具可以帮助更快地减轻故障。 故障排除流程图： \r\r","date":"2021-08-24","objectID":"/sre/:30:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"一般做法 General Practices 复现问题(Reproduce problem) 尝试破坏的请求来重现问题。 检查端到端的请求流并查看返回码(3xx, 4xx, 5xx)。 客户端侧的问题主要是静态内容的缺失或错误，异步调用等。 收集信息(Gather Information) 查找应用日志中的错误或异常（Can’t Allocate Memory，OutOfMemoryError，disk I/O error等） 检查应用和主机的指标，查看展示图。看是否有资源使用异常等情况。 查看最近的代码和配置更改，可能正在破坏系统。 了解问题(Understand the problem) 尝试将收集的数据和最近的操作相关。 QPS增加？SQL查询增加？最近代码的更改是否需要更好更多的硬件配置？ 寻找解决方案并修复(Find a solution and apply a fix) 基于上述发现，如有可能，可以快速修复。如果错误异常相关，则可以滚动回滚。 尝试修复代码，如果你想要快速修复，先在staging环境。 尝试扩展系统 如果有必要，优化数据库查询 验证完整的请求流程(Verify complete request flow) 请求并查看返回码 查看日志 查看监控指标 \r\r","date":"2021-08-24","objectID":"/sre/:30:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"一般主机问题 要知道主机是否监控，可尝试以下： Dmesg: 显示近期内核抛出的错误 ls命令：lspci, lsblk, lscpu, lsscsi /var/log/messages：显示系统相关的错误 Smartd：检查磁盘健康 \r\r","date":"2021-08-24","objectID":"/sre/:30:2","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"重要工具 Important Tools 一些重要的Linux命令，能帮助快速找到问题。 日志解析：grep, sed, awk, cut, tail, head, more, less 网络检查：nc, netstat, traceroute, mtr, ping, route, tcpdump, ss, ip dns：dig, host, nslookup 追踪系统调用：strace 通过ssh并行执行：gnu parallel, xargs ssh http检查：curl, wget 打开文件数列表：lsof 修改内核属性：sysctl 一些第三方工具也很有用： 基于ssh的工具：clusterSSH, Ansible 基于agent的工具：saltstack, puppet 日志分析工具，elk。可通过多个logstash消费kafka日志，使用同一个group，这样其实也就是logstash的高可用了。 \r\r","date":"2021-08-24","objectID":"/sre/:31:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"性能提升 Performance Improvements 性能工具是开发、运营生命周期的重要组成部分，对于理解应用程序的行为非常重要。 \r","date":"2021-08-24","objectID":"/sre/:32:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"性能分析命令 Performance analysis commands 这些命令你应该知晓： top htop iotop vmstat iostat free sar mpstat lsof perf \r\r","date":"2021-08-24","objectID":"/sre/:32:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"分析工具 Profiling tools 一些分析工具可帮助理解： FlameGraph: 可视化 Valgrind: 用于内存调试、内存泄露检测和分析的编程工具 Gprof: GNU Profiler tool采取用于收集运行时分析信息 \r\r","date":"2021-08-24","objectID":"/sre/:32:2","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"基准测试 Benchmarking 这是一种测量服务最佳性能的过程。如服务能处理的QPS，负载增加时的延迟，主机资源使用等。回归测试(regression/load testing)是在部署服务到生产环境之前必须要做的事。 一些工具： Apache Benchmark Tool Httperf Apache JMeter Wrk Locust 上面的工具有助于负载、压力测试，但这样做不测量实际的用户体验，它看不出最终用户资源如何影响应用程序性能。 \r\r","date":"2021-08-24","objectID":"/sre/:32:3","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"伸缩 Scaling 推荐阅读 A Brief History of Scaling LinkedIn \r根据资源的可用性，系统设计的最佳地执行一定的限制。始终需要持续优化，以确保其峰值处于最佳利用资源。随着QPS的增长，系统需要扩展，可以垂直或水平伸缩。 伸缩Web应用需要以下内容： 添加更多主机来缓解服务器负载 使用负载均衡器在服务器上分发流量 通过分片和增加副本数来扩展数据库 \r\r\r","date":"2021-08-24","objectID":"/sre/:32:4","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"故障排查示例 Troubleshooting Example \r","date":"2021-08-24","objectID":"/sre/:33:0","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["SRE"],"content":"内存泄露 Example - Memory leak 内存泄露问题通常会被忽视，直到服务在运行一段时间后变得无响应，直到服务重启或错误修复。在这种情况下，服务内存使用量类似与此图。 内存泄露是应用程序对内存分配的不当管理，其中不需要的内存没有被释放，在时间段里对象继续堆积在内存中，导致服务奔溃。通常，这些未释放的对象通过垃圾回收器(gc)自动地排序，但有时由于bug它失败了。调试有助于诊断应用程序的大部分内存用在了什么地方。然后，你开始追踪并过滤基于内存使用的所有内容。如果，你发现了不使用的对象，但在引用，你可以通过删除它们来避免内存泄露。 在以下的Python应用程序示例中，它附带了像tracemalloc等内置功能，此模块可以帮助指出对象首先分配的位置。几乎每种语言都带有一组工具/库来帮助查找内存问题。同样，对于Java而言，有一个名为Java VisualVM内存泄露检测工具。 要模拟进行大量的请求，我们可以使用Apacher benchmarking工具ab，测试之后可以看到内存猛增。 ab -n 10000 -c 10 -s 3 http://localhost:port 现实世界应用程序比示例更为复杂，你必须了解使用TraceMalloc可能会降低应用程序性能，因为TraceMalloc也有开销。注意其在生产环境中的使用。 \r\r \r\rCICD Continuous Integration and Continuous Delivery 涉及的知识: cicd devops pipeline 软件开发和维护 Git Docker K8s Helm Jenkins/Gitlab-ci等 \r基础设施即代码(infrastructure as code)是一个SRE在自动化重复配置任务方面应该遵顼的标准实践之一。每个配置都保持为代码，因此可以使用cicd pipeline来部署它。通过cicd pipeline将配置更改提供给生产环境，以维护版本控制，环境变化的一致性以及避免手动错误。 通常，作为SRE，你需要查看应用程序cicd pipeline，并推荐额外的阶段，如静态代码分析和代码中的安全行和隐私检查，以提高产品的安全性和可靠性。 ","date":"2021-08-24","objectID":"/sre/:33:1","tags":["sre","devops"],"title":"SRE","uri":"/sre/"},{"categories":["frontend"],"content":"参考: React docs: https://zh-hans.reactjs.org/docs/getting-started.html React github: https://github.com/facebook/react/ 版本: React: v17.0 预备知识 React是一个JavaScript库。所以你应该了解: JavaScript Node npm yarn 教程 links: https://zh-hans.reactjs.org/tutorial/tutorial.html 教程适用于边做边学的开发者。 ","date":"2021-08-06","objectID":"/react/:0:0","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"环境准备 浏览器 本地开发环境: 安装Node.js ","date":"2021-08-06","objectID":"/react/:1:0","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"概览 React是一个声明式，高效且灵活的用于构建用户界面的JavaScript库。使用React可以将一些简短、独立的代码片段组合成复杂的UI界面，这些代码片段称为组件。 大多数的React开发者使用一种名为JSX的特殊语法，JSX可以让你更轻松地书写这些结构。 在JSX中你可以任意使用JavaScript表达式，只需要用一个大括号把表达式括起来。每一个React元素事实上都是一个JavaScript对象，你可以在你的程序中把它保存在变量中或者作为参数传递。 箭头函数表达式的语法比函数表达式更简洁。函数箭头表达式更适合用于那些本来需要匿名函数的地方，并且它不能作为构造函数。 \u003cbutton className=\"square\" onClick={function() { alert('click'); }}\u003e \u003c/button\u003e \u003cbutton className=\"square\" onClick={() =\u003e alert('click)}\u003e \u003c/button\u003e 核心概念 ","date":"2021-08-06","objectID":"/react/:2:0","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"HelloWorld ReactDOM.render( \u003ch1\u003eHelloWorld!\u003c/h1\u003e document.getElementById('root') ); ","date":"2021-08-06","objectID":"/react/:3:0","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"JSX简介 https://zh-hans.reactjs.org/docs/introducing-jsx.html 建议在 React 中配合使用 JSX，JSX 可以很好地描述 UI 应该呈现出它应有交互的本质形式。JSX 可能会使人联想到模板语言，但它具有 JavaScript 的全部功能。 React 不强制要求使用 JSX，但是大多数人发现，在 JavaScript 代码中将 JSX 和 UI 放在一起时，会在视觉上有辅助作用。它还可以使 React 显示更多有用的错误和警告消息。 ","date":"2021-08-06","objectID":"/react/:4:0","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"在JSX中嵌入表达式 声明一个name变量，然后在JSX中使用它，并将它包裹在大括号中： const name = 'Josh Perez'; const element = \u003ch1\u003eHello, {name}\u003c/h1\u003e; ReactDOM.render( element, document.getElementById('root) ); 在JSX语法中，你可以在大括号中防止任何有效的JavaScript表达式。 function formatName(user) { return user.firstName + ' ' + user.lastName; } const user = { \u003ch1\u003e Hello, {formantName(user)}! \u003c/h1\u003e }; ReactDOM.renger( element, document.getElementById('root') ); 为了便于阅读，将JSX拆分为多行。同时，建议将内容包裹在括号中，虽然这样做不是强制要求，但这可以避免遇到自动插入分号陷阱。 ","date":"2021-08-06","objectID":"/react/:4:1","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"JSX也是一个表达式 在编译之后，JSX 表达式会被转为普通 JavaScript 函数调用，并且对其取值后得到 JavaScript 对象。 function getGreeting(user) { if (user) { return \u003ch1\u003eHello, {formantName(user)}!\u003c/h1\u003e; } return \u003ch1\u003eHello, Stranger.\u003c/h1\u003e; } ","date":"2021-08-06","objectID":"/react/:4:2","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"JSX特定属性 通过使用引号，来将属性值指定为字符串字面量。也可以使用大括号，在属性值中插入一个JavaScript表达式： const element = \u003cdiv tabIndex=\"0\"\u003e\u003c/div\u003e; const element = \u003cimg src={user.avatarUrl}\u003e\u003c/img\u003e; 因为JSX语法上更接近JavaScript而不是HTML，所以React DOM使用驼峰命名来定义属性的名称。 ","date":"2021-08-06","objectID":"/react/:4:3","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"使用JSX指定子元素 假如一个标签里没有内容，你可以使用/\u003e来闭合标签，就像XML语法一样。JSX标签里能够包含很多子元素。 const element = \u003cimg src={user.avatarUrl} /\u003e; const element = ( \u003cdiv\u003e \u003ch1\u003eHello!\u003c/h1\u003e \u003ch2\u003eGood to see you here.\u003c/h2\u003e \u003c/div\u003e ) ","date":"2021-08-06","objectID":"/react/:4:4","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"JSX防注入攻击 你可以安全地在JSX当中插入用户输入内容。 const title = response.potentiallyMaliciousInput; // 直接使用是安全的 const element = \u003ch1\u003e{title}\u003c/h1\u003e; React DOM在渲染所有输入内容之前，默认会进行转义。它可以确保在你的应用中，永远不会注入那些并非自己明确编写的内容。所有的内容在渲染之前都被转换成了字符串。这样可以有效防止XSS攻击。 ","date":"2021-08-06","objectID":"/react/:4:5","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"JSX表示对象 Babel 会把 JSX 转译成一个名为 React.createElement() 函数调用。 ","date":"2021-08-06","objectID":"/react/:4:6","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"元素渲染 https://zh-hans.reactjs.org/docs/rendering-elements.html 元素是构成React应用的最小砖块。元素描述了你在屏幕上想看到的内容。 与浏览器的DOM元素不通，React元素是创建开销极小的普通对象。React DOM会负责更新DOM来与React元素保持一致。 ","date":"2021-08-06","objectID":"/react/:5:0","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"将一个元素渲染为DOM ","date":"2021-08-06","objectID":"/react/:5:1","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"更新已渲染的元素 React元素是不可变对象。一旦被创建，你就无法更改它的子元素或者属性。 根据我们已有的知识，更新 UI 唯一的方式是创建一个全新的元素，并将其传入 ReactDOM.render()。 在实践中，大多数React应用只会调用一次ReactDOM.render()。 ","date":"2021-08-06","objectID":"/react/:5:2","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"只更新它需要更新的部分 React DOM 会将元素和它的子元素与它们之前的状态进行比较，并只会进行必要的更新来使 DOM 达到预期的状态。 ","date":"2021-08-06","objectID":"/react/:5:3","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"组件和props https://zh-hans.reactjs.org/docs/components-and-props.html 组件允许你将UI拆分为独立可复用的代码片段，并对每个片段进行独立构思。 组件，从概念上类似于JavaScript函数。它接受任意的入参(props)，并返回用于描述页面展示内容的React元素。 ","date":"2021-08-06","objectID":"/react/:6:0","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"函数组件和class组件 定义组件最简单的方式就是编写 JavaScript 函数。 function Welcome(props) { return \u003ch1\u003eHello, {props.name}\u003c/h1\u003e; } // 或ES6 class class Welcom extends React.Component { render() { return \u003ch1\u003eHello, {this.props.name}\u003c/h1\u003e; } } 这两个组件在React里是等效的。 ","date":"2021-08-06","objectID":"/react/:6:1","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"渲染组件 React也可以是用户自定义的组件。 const element = \u003cWelcome name=\"Sara\" /\u003e; 当React元素为用户自定义组件时，它会将JSX所接收的属性以及子组件转换为单个对象传递给组件，这个对象称位props。 // Hello, Sara function Welcome(props) { return \u003ch1\u003eHello, {props.name}\u003c/h1\u003e; } const element = \u003cWelcome name=\"Sara\" /\u003e; ReactDOM.render( element, document.getElementById('root') ); 组件名称必须以大写字母开头。React会将以小写字母开头的组件视为原生DOM标签。 ","date":"2021-08-06","objectID":"/react/:6:2","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"组合组件 组件可以在其输出中引用其它组件。 例如，我们可以创建一个多次渲染Welcome组件的App组件。 function Welcome(props) { return \u003ch1\u003eHello, {props.name}\u003c/h1\u003e; } function App() { return ( \u003cdiv\u003e \u003cWelcome name=\"A\" /\u003e \u003cWelcome name=\"B\" /\u003e \u003cWelcome name=\"C\" /\u003e \u003c/div\u003e ); } ReactDOM.render( \u003cApp /\u003e, document.getElementById('root) ); ","date":"2021-08-06","objectID":"/react/:6:3","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"提取组件 将组件拆分为更小的组件。 最初看上去，提取组件可能是一件繁重的工作，但是，在大型应用中，构建可复用组件库是完全值得的。根据经验来看，如果UI中有一部分被多次使用(Button, Panel, Avatar)，或者组件本身就足够复杂，那么它就是一个可提取出独立组件的候选项。 ","date":"2021-08-06","objectID":"/react/:6:4","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"Props只读性 组件无论是使用函数声明还是class声明，都绝不能修改自身的props。 React非常灵活，但它也有一个严格的规则。所有React组件都必须像纯函数一样保护它们的props不被更改。 备注: 纯函数: 不会尝试修改入参 ","date":"2021-08-06","objectID":"/react/:6:5","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"State和生命周期 文档: https://zh-hans.reactjs.org/docs/state-and-lifecycle.html 前面，我们只了解了通过ReactDOM.render()来修改我们想要渲染的元素。在本章节中，我们将学习如何封装真正可复用的Clock组件。它将设置自己的计时器并每秒更新一次。 我们需要使用state来实现这个功能。state与props类似，但state是私有的，并且完全受控于当前组件。 ","date":"2021-08-06","objectID":"/react/:7:0","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"将函数组件转换为class组件 通过以下五步将Clock的函数组件转换成class组件： 创建一个同名的ES6 class，并且继承于React.Component 添加一个空的render()方法 将函数体移动到render()方法之中 在render()方法中使用this.props替换props 删除剩余的空函数声明 class Clock extends React.Component { render() { return ( \u003cdiv\u003e \u003ch1\u003eHello, world!\u003c/h1\u003e \u003ch2\u003eIt is {this.props.date.toLocalTimeString()}\u003c/h2\u003e \u003c/div\u003e ); } } ","date":"2021-08-06","objectID":"/react/:7:1","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"向class组件中添加局部的state 把render()方法中的this.props.date替换成this.state.date: class Clock extends React.Component { render() { return ( \u003cdiv\u003e \u003ch1\u003eHello, world\u003c/h1\u003e \u003ch2\u003eIt is {this.state.date.toLocalTimeString()}\u003c/h2\u003e \u003c/div\u003e ); } } 添加一个class构造函数（将props传递到父类的构造函数中），然后在该函数中为this.state赋初值: class Clock extends React.Component { constructor(props) { super(props); this.state = {date: new Date()}; } render () { ... } } Class组件应该始终使用props参数来调用父类的构造函数。 移除\u003cClock /\u003e元素中的date属性: ReactDOM.render( \u003cClock /\u003e, document.getElementById('root') ); ","date":"2021-08-06","objectID":"/react/:7:2","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"将生命周期方法添加到Class中 在具有许多组件的应用程序中，当组件被销毁时释放所占用的资源是非常重要的。 当Clock组件第一次被渲染到DOM中的时候，就为其设置一个计时器。这在React中被称为挂载(mount)。 同时，当DOM中Clock组件被删除的时候，应该清除计时器。这在React中被称为卸载(unmount)。 我们可以为class组件声明一些特殊的方法，当组件挂载或卸载时就会去执行这些方法，这些方法叫做生命周期方法。 尽管this.props和this.state是React本身设置的，且都拥有特殊的含义，但其实你可以向class中随意添加不参与数据流的额外字段（如计时器ID）。 class Clock extends React.Component { constructor(props) { ... } componentDidMount() { this.timerID = setInterval( () =\u003e this.tick(), 1000 ); } componentWillUnmount() { clearInterval(this.timerID); } tick() { this.setState({ date: new Date() }); } render() { ... } } ReactDOM.render( \u003cClock /\u003e, document.getElementById('root') ); ","date":"2021-08-06","objectID":"/react/:7:3","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"正确地使用State 关于setState()你应该了解三件事： 不要直接修改State State的更新可能是异步的 State的更新会被合并 // Wrong this.state.comment = \"Hello\"; // Correct this.setState({comment: \"Hello\"}); // Wrong this.setState({ counter: this.state.counter + this.props.increment, }); // Correct this.setState((state, props) =\u003e({ counter: state.counter + props.increment })); ","date":"2021-08-06","objectID":"/react/:7:4","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"数据是向下流动的 不管是父组件还是子组件都无法知道某个组件是有状态的还是无状态的，并且它们也并不关心它是函数组件还是class组件。 这就是为什么称state为局部的或是封装的原因。除了拥有设置了它的组件，其它组件都无法访问。 组件可以选择把它的state作为props向下传递到它的子组件中。 这通常被叫做自上而下或是单向的数据流。任何的state总是所属于特定的组件，而且从改state派生的任何数据或UI只能影响树中低于它们的组件。 ","date":"2021-08-06","objectID":"/react/:7:5","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"事件处理 React元素的事件处理和DOM元素的很相似，但有一点语法上的不同： React事件的命名使用驼峰法，而不是纯小写 使用JSX语法时你需要传入一个函数作为事件处理函数，而不是一个字符串 // 传统的HTML \u003cbutton onclick=\"activateLasers()\"\u003e Activate Lasers \u003c/button\u003e // React中 \u003cbutton onClick={activateLasers}\u003e Activate Lasers \u003c/button\u003e ","date":"2021-08-06","objectID":"/react/:8:0","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"向事件处理程序传递参数 在循环中，通常我们会为事件处理函数传递额外的参数。 ","date":"2021-08-06","objectID":"/react/:8:1","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"条件渲染 文档: https://zh-hans.reactjs.org/docs/conditional-rendering.html 在React中，你可以创建不同的组件来封装各种你需要的行为。然后，依据应用的不同状态，你可以只渲染对应状态下的部分内容。 ","date":"2021-08-06","objectID":"/react/:9:0","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"元素变量 使用变量来存储元素。它可以帮助你有条件地渲染组件的一部分，而其它的渲染部分并不会因此而改变。 ","date":"2021-08-06","objectID":"/react/:9:1","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"运算符 与运算符: \u0026\u0026 三目运算符: condition ? true : false 因为在JavaScript中，true \u0026\u0026 expression总是会返回expression, 而false \u0026\u0026 expression总是会返回false。因此，如果条件是true，\u0026\u0026右侧的元素就会被渲染，如果是false，React会忽略并跳过它。 ","date":"2021-08-06","objectID":"/react/:9:2","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"阻止组件渲染 在某些情况下，你可能希望隐藏组件，即使它已经被其它组件渲染。若要完成此操作，你可以让render方法直接放回null，而不进行任何渲染。 ","date":"2021-08-06","objectID":"/react/:9:3","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"列表和Key 文档: https://zh-hans.reactjs.org/docs/lists-and-keys.html 使用map()函数让数组中的每一项变双倍，然后我们得到一个新的列表。 const numbers = [1, 2, 3, 4, 5]; const doubled = numbers.map((number) =\u003e number * 2); console.log(doubled); 在React中，把数组转化为元素列表的过程是相似的。 ","date":"2021-08-06","objectID":"/react/:10:0","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"渲染多个组件 可以通过使用花括号{}在JSX内构建一个元素集合。 const numbers = [1, 2, 3, 4, 5]; const listItems = numbers.map((number) =\u003e \u003cli\u003e{number}\u003c/li\u003e ); ReactDOM.renger( \u003cul\u003e{listItems}\u003c/ul\u003e, document.getElementById('root') ); ","date":"2021-08-06","objectID":"/react/:10:1","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"基础组件列表 通常你需要在一个组件中渲染列表。 我们可以把前面的例子重构成一个组件，这个组件接收numbers数组作为参数并输出一个元素列表。 function NumberList(props) { const numbers = props.numbers; const listIterms = numbers.map((number) =\u003e \u003cli key={number.toString()}\u003e {number} \u003c/li\u003e ); return ( \u003cul\u003e{listItems}\u003c/ul\u003e ); } const numbers = [1, 2, 3, 4, 5] ReactDOM.render( \u003cNumberList numbers={numbers} /\u003e, document.getElementById('root') ); ","date":"2021-08-06","objectID":"/react/:10:2","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"key key帮助React识别那些元素改变了，比如被添加或删除。因此你应当给数组中的每一个元素赋予一个确定的标识。 一个元素的key最好是这个元素在列表中拥有的一个独一无二的字符串。通常，我们使用数据中的id来作为元素的key。 ","date":"2021-08-06","objectID":"/react/:10:3","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"用key提取组件 元素的key只有放在就近的数组上下文中才有意义。 比方说，如果你提取出一个ListItem组件，你应该把key保留在数组中的这个\u003cListItem /\u003e元素上，而不是放在ListItem组件的\u003cli\u003e元素上。 // 正确！key 应该在数组的上下文中被指定 \u003cListItem key={number.toString()} value={number} /\u003e 一个好的经验法则，在map()方法中的元素需要设置key属性。 ","date":"2021-08-06","objectID":"/react/:10:4","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"key只是在兄弟节点之间必须唯一 数组元素中使用的key在其兄弟节点之间应该是独一无二的。然而，它们不需要是全局唯一的。 ","date":"2021-08-06","objectID":"/react/:10:5","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"在JSX中嵌入map() JSX允许在大括号中嵌入任何表达式，所以我们可以内联map()返回的结果。 function NumberList(props) { const numbers = props.numbers; return ( \u003cul\u003e {numbers.map((number) =\u003e \u003cListItem key={number.toString()} value={number} /\u003e )} \u003c/ul\u003e ); } ","date":"2021-08-06","objectID":"/react/:10:6","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"表单 文档: https://zh-hans.reactjs.org/docs/forms.html 在React里，HTML表单元素的工作方式和其它的DOM元素有些不同，这是因为表单元素通常会保持一些内部的state。 在大多数情况下，使用JavaScript函数可以很方便的处理表单的提交，同时还可以访问用户填写的表单数据。实现这种效果的标准方式是使用受控组件。 ","date":"2021-08-06","objectID":"/react/:11:0","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"受控组件 在HTML中，表单元素通常自己维护state，并根据用户输入进行更新。而在React中，可变状态通常保存在组件的state属性中，并且只能通过使用setState()来更新。 我们可以把两者结合起来，是React的state成为唯一数据源。渲染表单的React组件还控制着用户输入过程中表单发生的操作。被React以这种方式控制取值的表单输入元素就叫做受控组件。 ","date":"2021-08-06","objectID":"/react/:11:1","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"textarea标签 在HTML中，\u003ctextarea\u003e元素通过其子元素定义其文本。 而在React中，\u003ctextarea\u003e使用value属性代替。这样可以使得使用\u003ctextarea\u003e的表单和使用单行input的表单非常类似。 ","date":"2021-08-06","objectID":"/react/:11:2","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"select标签 在HTML中，\u003cselect\u003e创建下拉列表标签。 注意: 你可以将数组传递到value属性中，以支持在select标签中选择多个选项 \u003cselect multiple={true} value={['B', 'C']}\u003e ","date":"2021-08-06","objectID":"/react/:11:3","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"文件input标签 在HTML中，\u003cinput type=\"file\"\u003e允许用户从存储设备中选择一个或多个文件，将其上次到服务器，或通过JavaScript的File API进行控制。 因为它的value只读，所以它是React中的一个非受控组件。 ","date":"2021-08-06","objectID":"/react/:11:4","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"处理多个输入 当需要处理多个input元素时，我们可以给每个元素添加name属性，并让处理函数根据event.target.name的值选择要执行的操作。 ","date":"2021-08-06","objectID":"/react/:11:5","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"受控输入空值 在受控组件上指定value的prop会阻止用户更改输入。如果你指定了value，但输入仍可编辑，则可能是你意外地将value设置为undefined或null。 ","date":"2021-08-06","objectID":"/react/:11:6","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"状态提升 文档: https://zh-hans.reactjs.org/docs/lifting-state-up.html 通常，多个组件需要反映相同的变化数据，这时我们建议将共享状态提升到嘴贱的共同父组件中去。 ","date":"2021-08-06","objectID":"/react/:12:0","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"学习小结 在React应用中，任何可变数据应当只有一个相对应的唯一数据源。通常，state都是首先添加到需要渲染数据的组件中去。然后，如果其它组件也需要这个state，那么你可以将它提升至这些组件的最近共同父组件中。你应当依靠自上而下的数据流，而不是尝试在不同组件间同步state。 ","date":"2021-08-06","objectID":"/react/:12:1","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"组合和继承 文档: https://zh-hans.reactjs.org/docs/composition-vs-inheritance.html React有十分强大的组合模式。我们推荐使用组合而非继承来实现组件间的代码重用。 ","date":"2021-08-06","objectID":"/react/:13:0","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"包含关系 有些组件无法提前知晓它们子组件的具体内容。在侧边栏(sidebar)和对话框(dialog)等展现通用容器(box)的组件中特别容易遇到这种情况。 我们建议这些组件使用一个特殊的children prop来将它们的子组传递到渲染结果中。 function FancyBorder(props) { return ( \u003cdiv className={'FancyBorder FancyBorder-' + props.color}\u003e {props.children} \u003c/div\u003e ); } 这使得别的组件可以通过JSX嵌套，将任意组件作为子组件传递给它们。 function WelcomDialog() { return ( \u003cFancyBorder color=\"blue\"\u003e \u003ch1 className=\"Dialog-title\"\u003e Welcome \u003c/h1\u003e \u003cp className=\"Dialog-message\u003e Thank you for visiting our spacecraft! \u003c/p\u003e \u003c/FancyBorder\u003e ); } ","date":"2021-08-06","objectID":"/react/:13:1","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"特例关系 有些时候，我们会把一些组件看作是其它组件的特殊实例。比如WelcomeDialog可以说是Dialog的特殊实例。 在React中，我们可以通过组合来实现这一点。特殊组件可以通过props定制并渲染一般组件。 function Dialog(props) { return ( \u003cFancyBorder color=\"blue\"\u003e \u003ch1 className=\"Dialog-title\"\u003e {props.title} \u003c/h1\u003e \u003cp className=\"Dialog-message\"\u003e {props.message} \u003c/p\u003e {props.children} \u003c/FancyBorder\u003e ); } class SignUpDialog extends React.Component { constructor(props) { super(props); this.handleChange = this.handleChange.bind(this); this.handleSignUp = this.handleSignUp.bind(this); this.state = {login: ''}; } render() { return ( \u003cDialog title=\"Mars Exploration Program\" message=\"How should we refer to you?\"\u003e \u003cinput value={this.state.login} onChange={this.handleChange} /\u003e \u003cbutton onClick={this.handleSignUp}\u003e Sign Me Up! \u003c/button\u003e \u003c/Dialog\u003e ); } handleChange(e) { this.setState({login: e.target.value}); } handleSignUp() { alert(`Welcome aboard, ${this.state.login}!`); } } ","date":"2021-08-06","objectID":"/react/:13:2","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"继承 在Facebook，我们在成百上千个组件中使用React。我们并没有发现需要使用继承来构建组件层次的情况。 props和组合为你提供了清晰而安全地定制组件外观和行为的灵活方式。组件可以接受任意props，包括基本数据类型，React元素以及函数。 ","date":"2021-08-06","objectID":"/react/:13:3","tags":["React"],"title":"React","uri":"/react/"},{"categories":["frontend"],"content":"React哲学 文档: https://zh-hans.reactjs.org/docs/thinking-in-react.html 我们认为，React是用JavaScript构建快速响应的大型web应用程序的首选方式。React最棒的部分之一是引导我们思考如何构建一个应用。 从设计稿开始： 将设计好的UI划分为组件层级 用React创建一个静态版本 确定UI state的最小且完整表示 确定state放置的位置 添加反向数据流 高级指引 FAQ 文档: https://zh-hans.reactjs.org/docs/faq-state.html ","date":"2021-08-06","objectID":"/react/:14:0","tags":["React"],"title":"React","uri":"/react/"},{"categories":["linux"],"content":"参考: https://seisman.github.io/how-to-write-makefile http://www.ruanyifeng.com/blog/2015/02/make.html ","date":"2021-06-24","objectID":"/makefile/:0:0","tags":["make","gnu"],"title":"Makefile","uri":"/makefile/"},{"categories":["linux"],"content":"概述 代码编程可执行文件，叫做编译(compile)。先编译这个，再编译那个，叫做构建(build)。 make 是常用的构建工具。构建规则都写在 makefile 里，要学会如何make命令，就必须学会编写makefile文件。 ","date":"2021-06-24","objectID":"/makefile/:1:0","tags":["make","gnu"],"title":"Makefile","uri":"/makefile/"},{"categories":["linux"],"content":"Makefile文件格式 ","date":"2021-06-24","objectID":"/makefile/:2:0","tags":["make","gnu"],"title":"Makefile","uri":"/makefile/"},{"categories":["linux"],"content":"概述 Makefile文件由一系列规则构成，每条规则的形式如下： 目标(target)：必须 前置条件(prerequisites)： 可选，但前置条件和命令必须至少存在一个。 tab 命令(commands)：可选，但前置条件和命令必须至少存在一个。 \u003ctarget\u003e: \u003cprerequisites\u003e [tab] \u003ccommands\u003e 每条规则就明确两件事，构建目标的前置条件是什么，以及如何构建。 ","date":"2021-06-24","objectID":"/makefile/:2:1","tags":["make","gnu"],"title":"Makefile","uri":"/makefile/"},{"categories":["linux"],"content":"目标 目标通常是文件名（多个文件之间用空格分隔），指明make命令所要构建的对象。目标还可以是某个操作的名字，这称为 伪目标 (phony target)。 clean: rm *.o 上面代码的目标是clean，它不是文件名，而是一个操作的名字，属于伪目标。 make clean 但是，如果在当前目录中，正好有一个文件叫做clean，那么这个命令不会执行。因为make发现clean文件已存在，就认为没有必须要重新构建了，就不会执行rm命令。 为了避免这种情况，可以明确声明clean是伪目标。声明伪目标之后，make就不会去检查是否存在一个叫做clean的文件。 # 为声明伪目标 .PHONY: clean clean: rm *.o temp 如果make命令运行时没有指定目标，默认会执行Makefile文件的第一个目标。 make ","date":"2021-06-24","objectID":"/makefile/:2:2","tags":["make","gnu"],"title":"Makefile","uri":"/makefile/"},{"categories":["linux"],"content":"前置条件 前置条件通常是一组文件名，用空格分隔。它指定了目标是否需要重新构建的判断标准，只要有一个前置条件不存在，或者有过更新，目标就需要重新构建。 result.txt: source.txt cp source.txt result.txt ","date":"2021-06-24","objectID":"/makefile/:2:3","tags":["make","gnu"],"title":"Makefile","uri":"/makefile/"},{"categories":["linux"],"content":"命令 命令表示如何更新目标，它是构建目标的具体指令。 每行命令之前必须有tab键，如果想用其它键，可以使用内置的 .RECIPEPREFIX 来声明。 # 使用 \u003e 替换 tab .RECIPEPREFIX = \u003e all: \u003e echo Hello, world 需要注意的是，每行命令在一个单独的shell中执行，这些shell之间没有继承关系。不过可以多个命令写在一行，或使用反斜线(\\)，或使用 .ONESHELL 命令。 var-lost: export foo=bar echo \"foo=[$$foo]\" var-kept: export foo=bar; echo \"foo=[$$foo]\" .ONESHELL: var-kept: export foo=bar; echo \"foo=[$$foo]\" ","date":"2021-06-24","objectID":"/makefile/:2:4","tags":["make","gnu"],"title":"Makefile","uri":"/makefile/"},{"categories":["linux"],"content":"Makefile文件语法 ","date":"2021-06-24","objectID":"/makefile/:3:0","tags":["make","gnu"],"title":"Makefile","uri":"/makefile/"},{"categories":["linux"],"content":"注释 # 这里是注释 result.txt: source.txt # 这是注释 cp source.txt result.txt # 这也是注释 ","date":"2021-06-24","objectID":"/makefile/:3:1","tags":["make","gnu"],"title":"Makefile","uri":"/makefile/"},{"categories":["linux"],"content":"回声 默认情况下，make会答应每条命令，然后再执行，这叫做回声(echoing)。 可以在命令前加上 @ ，来关闭回声。 由于在构建过程中，需要了解当前执行详情，所以通常只在纯注释和显示的echo命令前面机上@。 test: @# 这是测试 @echo TODO ","date":"2021-06-24","objectID":"/makefile/:3:2","tags":["make","gnu"],"title":"Makefile","uri":"/makefile/"},{"categories":["linux"],"content":"通配符 Makefile的通配符和Bash一直，主要有 *, ?, [...]。 ","date":"2021-06-24","objectID":"/makefile/:3:3","tags":["make","gnu"],"title":"Makefile","uri":"/makefile/"},{"categories":["linux"],"content":"模式匹配 make命令允许对文件名，进行类似正则运算的匹配，主要用到的匹配符是%。 使用匹配符，可以将大量同类型的文件，只用一条规则就完成构建。 %.o: %.c ","date":"2021-06-24","objectID":"/makefile/:3:4","tags":["make","gnu"],"title":"Makefile","uri":"/makefile/"},{"categories":["linux"],"content":"变量和赋值 Makefile允许使用等号来自定义变量。 调用shell变量，需要在美元符号前多加一个美元符号。 txt = Hello World test: @echo $(txt) test2: @echo $$HOME makefile还提供了四个赋值运算符: VARIABLE = value # 在执行时扩展，允许递归扩展。 VARIABLE := value # 在定义时扩展。 VARIABLE ?= value # 只有在该变量为空时才设置值。 VARIABLE += value # 将值追加到变量的尾端。 ","date":"2021-06-24","objectID":"/makefile/:3:5","tags":["make","gnu"],"title":"Makefile","uri":"/makefile/"},{"categories":["linux"],"content":"内置变量 make提供了一系列内置变量，比如， $(CC) 指向当前使用的编译器， $(MAKE) 指向当前使用的make工具。 其它内置变量，请参考文档 ","date":"2021-06-24","objectID":"/makefile/:3:6","tags":["make","gnu"],"title":"Makefile","uri":"/makefile/"},{"categories":["linux"],"content":"自动变量 make命令还提供一些自动变量，它们的值与当前的规则有关。 # $@ 指代当前目标 a.txt b.txt: touch $@ # 等价于 a.txt: touch a.txt b.txt: touch b.txt # $\u003c 指代第一个前置条件 a.txt: b.txt c.txt cp $\u003c $@ # 等价于 a.txt: b.txt c.txt cp b.txt a.txt # $? 指代比目标更新的所有前置条件， 以空格分隔。 # $^ 指代所有前置条件，之间以空格分隔。 # $* 指代匹配符 % 匹配的部分 # $(@D) 和 $(@F) 分别指向 $@ 的目录名和文件名 # $(\u003cD) 和 $(\u003cF) 分别指向 $\u003c 的目录名和文件名 ","date":"2021-06-24","objectID":"/makefile/:3:7","tags":["make","gnu"],"title":"Makefile","uri":"/makefile/"},{"categories":["linux"],"content":"判断和循环 Makefile使用Bash语法，完成判断和循环。 LIST = one two three all: for i in $(LIST); do \\ echo $$i; \\ done # 等同于 all: for i in one two three; do \\ echo $i; \\ done ","date":"2021-06-24","objectID":"/makefile/:3:8","tags":["make","gnu"],"title":"Makefile","uri":"/makefile/"},{"categories":["linux"],"content":"函数 Makefile还可以使用函数。 $(function arguments) # 或者 ${function arguments} # shell 函数用来执行 shell 命令 srcfiles := $(shell echo src/{00..99}.txt) # wildcard 函数用来在 Makefile 中，替换 Bash 的通配符。 srcfiles := $(wildcard src/*.txt) # subst 函数用来文本替换 $(subst from,to,text) # patsubst 函数用于模式匹配的替换 $(patsubst pattern,replacement,text) # 替换后缀名函数的写法是：变量名 + 冒号 + 后缀名替换规则 min: $(OUTPUT:.js=.min.js) ","date":"2021-06-24","objectID":"/makefile/:3:9","tags":["make","gnu"],"title":"Makefile","uri":"/makefile/"},{"categories":["linux"],"content":"Makefile实例 # 执行多个目标 .PHONY: cleanall cleanobj cleandiff cleanall : cleanobj cleandiff rm program cleanobj : rm *.o cleandiff : rm *.diff ","date":"2021-06-24","objectID":"/makefile/:4:0","tags":["make","gnu"],"title":"Makefile","uri":"/makefile/"},{"categories":null,"content":"业余计算机从业人员，业余足球和游戏爱好者！ ","date":"2021-06-15","objectID":"/about/about/:0:0","tags":null,"title":"关于我","uri":"/about/about/"},{"categories":["sre"],"content":"参考: google sre book: https://sre.google/sre-book/ 序 Foreword 100%的可用性是不现实的，需要达到这个目标的成功通常远超于所能获得的价值，所以Google会针对每种产品设定一个错误预算(容错率)，既能保证用户体验又不影响创新和部署的速度。 实现细节永远支持短暂存在的，但是文档化的设计过程确实无价之宝。 可靠性应该是任何产品设计中最基本的概念：任何一个系统如果没有人能够稳定地使用，就没有存在的意义。 当一个系统已经足够可靠的时候，SRE通常将精力转而投入到研发新的功能和创造新的产品。 对一些中小型企业来说，企业内部可能已经有这样的一组人在做着与SRE非常类似的工作。这些人可能并不叫SRE这个名字，甚至可能没有受到管理层的重视。在这样的企业中，提高可靠性最好的办法往往就是去认可这些人的工作，并配备足够的激励机制。在牛顿被世界正式认可为物理学家之前，他经常被称作是最后的炼金术士。 只有靠着对细节的不断关注，做好充足的灾难预案和准备工作，时刻警惕着，不放过一切机会避免灾难发生。这就是SRE最重要的理念。 介绍 传统的研发团队和运维团队分歧的焦点主要在软件版本、新配置的变更的发布速度上。研发部门最关注的是如何能够更快速地构建和发布新功能。运维部门更关注的是如何能在他们值班期间避免发生故障。由于绝大部分生产故障都是由于部署某项变更导致的——不管是部署新版本，还是修改配置。这两个部门的目标从本质上来说是互相矛盾的。 极端来说，研发部门想要随时随地发布新功能，没有任何阻拦。而运维部门则想要一旦一个东西在生产环境中正常工作了，就不再进行任何改动。由于两个部门使用的语境不同，对风险的定义也不一致。 ","date":"2021-04-13","objectID":"/google-sre/:0:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"google解决之道 SRE SRE团队成员有如下特点： 对重复性、手工性的操作有天然的排斥感 有足够的技术能力快速开发出软件系统以替代手动操作 从本质上来说，SRE就是在用软件工程的思维和方法论完成以前由系统管理员团队手动完成的任务。这些SRE倾向于通过设计、构建自动化工具来取代人工操作。 SRE模型成功的关键在于对工程的关注。如果没有持续的、工程化的解决方案，运维的压力就会不断增加，团队也就需要更多的人来完成工作。如果一个产品非常成功，用户流量越来越大，就需要更多的团队成员来重复进行同样的事情。 为了避免这一点，运维团队必须有足够的时间编程，否则他们就会被运维工作所淹没。因此，Google为整个SRE团队所做的所有传统运维工作设立了一个50%的上限值。传统运维工作包括：工单处理、手动操作等。设立这样一个上限值确保了SRE团队有足够的时间改进所维护的服务，将其变得更稳定和更易于维护。 这个上限值并不是目标值。随着时间的推移，SRE团队应该倾向于将基本的运维工作全部消除，全力投入在研发任务上。因为整个系统可以自主运行，可以自动修复问题。我们的终极目标是推动整个系统趋向于无人化运行，而不仅仅是自动化某些人工流程。 Google的经验法则是，SRE团队必须将50%的精力花在真实的开发工作上。保障有足够的时间和精力去进行真正有创造性的、自主的研发工作。同时，也保障了SRE团队有足够的运维经验，从而让他们设计出切实解决问题的系统。 由于SRE模型中为了提高可靠性需要采取一些与常规做法违背的做法，所以需要强有力的管理层支持才能推行下去。 ","date":"2021-04-13","objectID":"/google-sre/:1:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"SRE方法论 一般来说，SRE团队要承担以下职责： 可用性改进 延迟优化 性能优化 效率优化 变更管理 监控 紧急事务处理 容量规划与管理 ","date":"2021-04-13","objectID":"/google-sre/:2:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"在保障服务SLO的前提下最大化迭代速度 考虑可靠性的几个方面： 基于用户的使用习惯、服务可靠性要达到什么程度用户才会满意？ 如果这项服务的可靠程度不够，用户是否有其它的替代选择？ 服务的可靠程度是否会影响用户对这项服务的使用模式？ 通过引进错误预算的概念，SRE团队的目标不再是零事故运行，SRE团队和产品研发团队目标一致，都是在保障业务服务可靠性需求的同时尽可能地加快功能上线速度。这个改动虽小，意义却很大。一次生产事故不再是一件坏事，而仅仅是创新流程中 一个不可避免的环节。 ","date":"2021-04-13","objectID":"/google-sre/:2:1","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"监控系统 监控系统是SRE团队监控服务质量和可用性的一个主要手段。监控系统不应该依赖人来分析警报信息，而是应该由系统自动分析，仅当需要用户执行某种操作时，才需要通知用户。 ","date":"2021-04-13","objectID":"/google-sre/:2:2","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"应急事件处理 可靠性是 MTTF(平均失败时间) 和 MTTR(平均恢复时间)的函数，评价一个团队将系统恢复到正常情况的最有效指标，就是MTTR。 一个可以自动恢复的系统即使有更多的故障发生，也要比事事都需要人工干预的系统可用性高。 ","date":"2021-04-13","objectID":"/google-sre/:2:3","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"变更管理 SRE的经验告诉我们，大概70%的生产事故由某种部署的变更而触发。变更管理的最佳实践是使用自动化来完成以下项目： 采用渐进式发布机制 迅速而准确地检测到问题的发生 当出现问题时，安全迅速地回滚改动 ","date":"2021-04-13","objectID":"/google-sre/:2:4","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"需求预测和容量规划 需求预测和容量规划，简单来说就是保障一个业务有足够的容量和冗余度去服务预测中的未来需求。 容量规划有几个步骤是必须的： 必须有一个准确的自然增长需求预测模型，需求预测的时间应该超过资源获取的时间。 规划中必须有准确的非自然增长的需求来源统计。 必须有周期性压力测试，以便准确地将系统原始资源信息与业务容量对应起来。 ","date":"2021-04-13","objectID":"/google-sre/:2:5","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"资源部署 资源的部署是变更管理与容量规划的结合物。资源通常是非常昂贵的。 ","date":"2021-04-13","objectID":"/google-sre/:2:6","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"效率与性能 高效地利用各种资源是任何盈利性服务都要关心的。如果能够通过密切关注一个服务的容量配置策略，进而改进起资源利用率，这可以非常有效地降低系统的总成本。 软件系统一般来说在负载上升的时候，会导致延迟升高。延迟升高其实和容量损失是一样的。当负载到达临界线时，一个逐渐变慢的系统最终会停止一切服务。换句话说，系统此时的延迟已经是无穷大了。SRE的目标是根据一个预设的延迟目标部署和维护足够的容量。 SRE视角 ","date":"2021-04-13","objectID":"/google-sre/:2:7","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"硬件 Google的大部分计算资源都存放在自主设计的数据中心中，拥有自己设计的供电系统、制冷系统、网络系统以及计算机硬件。 物理服务器(machine): 代表具体的硬件 软件服务器(server): 代表一个对外提供服务的软件系统 物理服务器上可以运行任何类型的软件服务器。Google使用一套集群管理系统进行资源分配，名称为Borg。这玩意应该是k8s的前身。 ","date":"2021-04-13","objectID":"/google-sre/:3:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"管理物理服务器的系统管理软件 ","date":"2021-04-13","objectID":"/google-sre/:4:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"管理物理服务器 为了管理和控制硬件设备，我们开发了一套大规模部署的系统管理软件。Borg，是一个分布式的集群操作系统。与Apache Mesos类似，Borg负责在集群层面管理任务的编排工作。 有些读者可能了解Borg的下一代，Kubernetes。 Borg不会将某个任务的全部实例都运行在某一个机柜上，避免单点故障。 如果一个任务实例的资源使用超出了它的分配范围，Borg会杀掉这个实例，并且重启它。我们发现，一个缓慢的不断重启的实例要好过一个永远不重启一直泄露资源的实例。 ","date":"2021-04-13","objectID":"/google-sre/:4:1","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"存储 存储系统负责向用户提供一套简单易用、可靠的集群存储服务。 ","date":"2021-04-13","objectID":"/google-sre/:4:2","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"网络 为了降低分布式集群的服务延迟，我们希望能够将用户指派给距离最近、用空余量的数据中心处理。 Google的全球负载均衡系统在三个层面上负责负载均衡工作： 利用地理位置进行负载均衡DNS请求（如google.com） 在用户服务层面进行负载均衡（如Youtube） 在远程调用(RPC)层面进行负载均衡 ","date":"2021-04-13","objectID":"/google-sre/:4:3","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"其它系统软件 ","date":"2021-04-13","objectID":"/google-sre/:5:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"分布式锁 Chubby可以处理异地、跨机房的锁请求。 ","date":"2021-04-13","objectID":"/google-sre/:5:1","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"监控与告警 监控系统是服务运维中不可或缺的部分。 主要有以下几种方式使用监控系统： 对真实问题进行报警 对比服务更新前后的状态变化：新版本是否让软件服务器运行的更快了？ 检查资源使用量随时间的变化情况，这个信息对合理指定资源计划很有用。 ","date":"2021-04-13","objectID":"/google-sre/:5:2","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"软件基础设施 Google的底层软件基础设施的设计目标是最高效地使用Google的硬件设施。 所有的Google服务之前都是用远程调用(RPC)通信，成为Stubby。开源实现是gRPC。 通常来说，一个软件服务器从该服务的前端接收RPC请求，同时将一些RPC发往该服务器的后端。 ","date":"2021-04-13","objectID":"/google-sre/:6:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"RPC RPC(Remote Process Call)，远程过程调用。 通过RPC框架，我们可以像调用本地函数/方法一样滴调用远程机器上的函数和方法。 也就是说两台服务器A, B，一个应用部署在A上，想要调用B上应用提供的函数/方法，由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义和传达调用的数据。 就是要像调用本地的函数一样去调用远程函数。 gRPC是Google开源的一个RPC框架。 ","date":"2021-04-13","objectID":"/google-sre/:6:1","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"研发环境 除了一些开源项目之外，其它Google软件工程师使用同一个软件仓库。 如果一个工程师遇到了他工作项目之外的一个基础组件的问题，他可以直接修改这个问题，向管理者提交一份改动申请，等待代码评审，最后直接提交修改 任何对自己项目代码的改动也需要代码评审 拥抱风险 你可能认为Google会试图构建一个百分百可靠的服务。事实证明，超过一定值后，再提高可靠性对于一项服务来说，结果可能会更差。极端的可靠性会带来成本的大幅提升：过分追求稳定性限制了新功能的开发速度和将产品交付给用户的速度，并且很大程度地增加了成本，这反过来又减少了一个团队可以提供的新功能的数量。 SRE旨在寻求快速创新和高效的服务运营业务之间的风险的平衡，而不是简单地将服务在线时间最大化。这样，我们可以优化用户的整体幸福感，平衡系统的功能、服务和性能。 ","date":"2021-04-13","objectID":"/google-sre/:7:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"管理风险 成本： 冗余服务器/计算资源的成本 机会成本 在SRE团队中，我们管理服务的可靠性很大程度上是通过管理风险来进行的。 ","date":"2021-04-13","objectID":"/google-sre/:8:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"度量服务的风险 Google的标准做法是通过一个可断的指标来体现一个待优化的系统属性。 可用性 = 系统正常运行时间 / (系统正常运行时间+停机时间) 然而，在Google内部，基于时间的可用性通常是毫无意义的。因为我们需要着眼全球范围内的分布式服务。Google所采用的故障隔离手段使得我们能够保证在任何时候、任何地方对于一个给定的服务，总是可以处理一定的用户流量。（也就是说，随时都是部分在线的）。 可用性 = 成功请求数 / 总的请求数 在一个典型的应用中，不是所有的请求都是平等的。 ","date":"2021-04-13","objectID":"/google-sre/:9:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"服务的风险容忍度 为了辨别服务的风险容忍度，SRE必须于产品负责人一起努力，将一组商业目标转化为明确的可以实现的工程目标。 ","date":"2021-04-13","objectID":"/google-sre/:10:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"辨别消费者服务的风险容忍度 评价服务风险容忍度时，有许多需要考虑的因素。如下： 需要的可用性水平是什么？ 不同类型的失败对服务有什么不同的影响？ 我们如何使用服务成本来帮助在风险曲线上定位这个服务？ 有哪些其它重要的服务指标需要考虑？ ","date":"2021-04-13","objectID":"/google-sre/:10:1","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"基础设施服务的风险容忍度 可用性目标水平 故障类型 成本 软件对故障的容忍度 测试 发布频率 金丝雀测试的持续时间和大小 服务目标质量 需要制定一个针对用户的服务质量目标，并且努力地去达到这个质量目标。 服务质量指标(SLI)、服务质量目标(SLO)、服务之里昂协议(SLA)。 事先选择好合适的指标有助于在故障发生时帮助SRE进行更好地决策，同时为SRE团队判断系统是否正常提供帮助。 ","date":"2021-04-13","objectID":"/google-sre/:10:2","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"指标 ","date":"2021-04-13","objectID":"/google-sre/:11:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"指标的标准化 汇总间隔：每一分钟汇总一次 汇总范围：集群中的全部任务 度量频率：每10秒一次 包含哪些请求 数据如何获取 数据访问延迟 减少琐事 SRE要把更多时间花费在长期项目研发上，而非日常运维中。因为术语日常运维可能会被误解，这是使用一个专有名称——琐事(toil)。 一些管理类杂务是必须做的，不应该被归类于琐事，这些事流程开销(overhead)。 到底什么是琐事？琐事就是运维服务中手动性的，重复性的，可以被自动化的，战术性，没有持久价值的工作。 SRE的一个公开目标是保持每个SRE的工作时间中运维工作(琐事)的比例低于50%。SRE至少要花50%的时间在工程项目上，以减少未来的琐事或增加服务功能。增加服务功能包括提高可靠性、性能、利用率，同时也会进一步消除琐事。 SRE公开50%这个目标是因为如果不加以控制，琐事会变得越来越多，以至于迅速占据我们每个人100%的时间。减少琐事和扩大服务规模的工作就是SRE中的E(Engineering)。 SRE的角色中，琐事是不可避免的。少量的琐事不是什么大问题，但一旦琐事变多，就有害了。 分布式系统的监控 ","date":"2021-04-13","objectID":"/google-sre/:11:1","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"术语 一些通用的术语: 监控(monitoring) 白盒监控(white-box) 黑盒监控(black-box) 监控台页面(dashboard) 警报(alert) 根源问题(root cause) 节点或机器(node/machine) 推送(push) ","date":"2021-04-13","objectID":"/google-sre/:12:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"现象与原因 监控系统应该解决两个问题： 现象：什么东西出故障了？ 愿意你：为什么出故障了？ 现象和原因的却分是构建信噪比高的监控系统时最重要的概念。 ","date":"2021-04-13","objectID":"/google-sre/:13:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"黑盒与白盒 黑盒是面向现象的，代表了目前正在发生的问题，而非预测发生的问题。即系统现在有故障。 白盒监控大量依赖对系统内部信息的检测，如系统日志、抓取提供指标信息的HTTP节点等。因此可以检测到即将发生的问题，以及那些重试所掩盖的问题等。 这里应该注意，在一个多层系统中，某一个服务的现象是另一个服务的原因。如数据库性能问题。 ","date":"2021-04-13","objectID":"/google-sre/:14:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"四个黄金指标 监控系统的4个黄金指标分别是： 延迟 流量 错误 饱和度 ","date":"2021-04-13","objectID":"/google-sre/:15:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"关于长尾效应 构建监控系统时，很多人倾向于采用某种量化指标的平均值。区分平均值的慢和长尾效应的慢的一个简单方法是将请求按延迟分组计数。 ","date":"2021-04-13","objectID":"/google-sre/:16:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"度量指标 当为监控系统和报警系统新增规则时，以下问题有助于减少误报： 该规则是否能够检测到一个目前检测不到的、紧急的、有操作性的，并且即将发生或者已经发生的用户可见故障 是否可以忽略这条告警？什么情况可能会导致用户忽略这条告警，如何避免？ 这条告警是否确实显示了用户正在受到的影响？是否存在用户受到影响也可以触发这条规则的情况？ 收到告警后，是否需要进行某个操作？是否需要立即执行，还是可以等到第二天执行？操作是否可以自动化？操作是长期的还是短期的？ 是否也会有其他人收到告警，这些告警是否是不必要的? ","date":"2021-04-13","objectID":"/google-sre/:17:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"监控系统的长期维护 关于监控系统的涉及决策应该充分考虑到长期目标。今天发出的紧急警报都会占用优化系统的时间，所以经常会牺牲一些短期内的可用性和性能问题，以换取未来系统性能的整体提升。 Google的自动化系统的演进 对于SRE而言，自动化是一种力量倍增器，而不是万能药。草率地进行自动化可能在解决问题的同时产生出其它问题。一个自治的系统。 ","date":"2021-04-13","objectID":"/google-sre/:18:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"自动化的价值 ","date":"2021-04-13","objectID":"/google-sre/:19:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"一致性 手动执行任务的方式对于整个组织和实际执行的人都不好。没有几个人能像机器一样永远保持一致，这不可避免的不一致性会导致错误、疏漏等问题。 在这个范畴内，一致性地执行范围明确、步骤已知的程序，是自动化的首要价值。 ","date":"2021-04-13","objectID":"/google-sre/:19:1","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"平台性 通过正确地设计和实现，自动化的系统可以提供一个可以扩展的、广泛适用的，甚至可能带来额外收益的平台。 一个平台同时也将错误集中化了。 ","date":"2021-04-13","objectID":"/google-sre/:19:2","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"修复速度更快 如果自动化能够始终成功运行，那么就可以降低一些常见故障的平均修复时间。随后，用户可以把时间花在其它任务上，从而提高开发速度。 在行业内普遍认同的是，在产品生命周期中一个问题越晚被发现，修复代价越高。 ","date":"2021-04-13","objectID":"/google-sre/:19:3","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"行动速度更快 在在基础设施中，SRE自动化系统应用广泛。这是因为人类通常不像机器一样快速反应。 ","date":"2021-04-13","objectID":"/google-sre/:19:4","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"节省时间 工程师对于一个特定的自动化或代码是否值得编写而摇摆不定，不停地比较写该代码所需要花费的精力与不需要手动完成任务所节省的精力。 这里很容易忽略一个事实，一旦你用自动化封装了某个任务，任何人都可以执行它们。因此，时间的节省适用于该自动化用的所有人。 将某个操作与具体操作的人解耦合是很有效的。 ","date":"2021-04-13","objectID":"/google-sre/:19:5","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"自动化对Google SRE的价值 当然，尽管Google在思想上倾向于尽可能使用机器管理机器，但实际情况需要一定的变通。将每个系统的每个组件都自动化是不合适的，同时不是所有人都有能力或倾向于在一个特定的事件开发自动化系统。 ","date":"2021-04-13","objectID":"/google-sre/:20:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"自动化的应用案例 广泛使用的工具有Puppet、Chef、Ansible，甚至Perl都提供了完成特定任务的方法，主要却别在于对帮助进行自动化的组件的抽象层次不通。 拥抱失败，承认故障是不可避免的，并通过自动化进行快速恢复。 节省的时间越多，优化和自动化其它繁琐工作的时间就越多。 自动化应该对那些隐含的安全信号非常小心。 发布工程 Release Engineering 发布工程专注于构建和交付软件。发布工程师通常对源代码管理、编译器、构建配置语言、自动化构建工具、包管理器和安装器等非常了解。 为保障服务可靠运行余姚可靠的发布流程。SRE需要保证二进制文件和配置文件是以一种可重现的、自动化的方式构建出来的。这样每一次发布才是可以重复的，而不是独特的。 SRE关注从源代码到部署的整个流程。 ","date":"2021-04-13","objectID":"/google-sre/:21:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"发布工程师的角色 负责产品更新的安全部署过程，保障这些服务可以正常运行。 ","date":"2021-04-13","objectID":"/google-sre/:22:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"发布工程学 自服务模型 追求速度 密闭性 强调策略和流程 为了应对大规模的扩张，每个团队必须能够自给自足。 越快上线越好。 构建工具必须确保一致性和可重复性。 多层安全和访问控制机制可以确保在发布过程中只有指定的人才能执行指定操作。 ","date":"2021-04-13","objectID":"/google-sre/:23:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"持续构建和部署 构建 分支 测试 打包 部署 善用PR。 一个持续测试系统会在每个主分支改动提交之后运行单元测试，这样我们可以快速检测构建错误和测试错误。 每个包有固定名称，记录构建结果的哈希值，并且会加入签名以确保真实完整性。 ","date":"2021-04-13","objectID":"/google-sre/:24:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"配置管理 将配置文件与二进制文件打包在一起 从外部服务中读取配置文件 简单化 对于大多数生产环境软件系统来说，我们想要在稳定性和灵活想上保持平衡。 对于软件而言，乏味实际上是非常正面的态度。与侦探小说不同，缺少刺激、悬念和困惑是源代码的理想特性。生产环境中的意外时SRE最大的敌人。 为了减少意外复杂度，SRE团队应该： 在他们所负责的系统中引入意外复杂度时，及时提出抗议 不断地努力消除正在接手的和已经负责运维的系统的复杂度 SRE推送保证所有的代码都有必须存在的目的的实践。审查代码以确保它确实符合商业目标，定期删除无用代码，并且在各级测试中增加代码膨胀检测。 臃肿的软件直观上来看就是不可取的。删除没用的代码。 书写一个明确的、最小的API是管理软件系统简单性的必要的部分。 在API与单个二进制文件以外，适用于面向对象编程的许多经验法则也适用于分布式系统的设计。在各种二进制和配置文件之间推行松耦合，是一种同时提高开发人员的灵活性和系统的稳定性的简化模式。 随着系统变得越来越负责，API与二进制文件之间的责任分离变得越来越重要。 正如普遍认同的，编写一个其中包含无关功能的大杂烩是一个糟糕的实践。一个设计良好的分布式系统是由一系列合作者组成的，每一个合作者都具有明确的、良好定义的范围。 简单的发布流程总的来说要比复杂的发布流程更好。 软件的简单性是可靠性的前提条件。 具体实践 简单来说，SRE的职责是运维一个服务，该服务由一些相关的系统组件组成。SRE的终极责任是确保该服务可以正常运转。为了完成这个目标，SRE需要完成以下工作：开发监控系统、规划容量，处理紧急事件，确保事故根源被跟踪修复等。 鉴于此，我们可以将一个服务的监控程序指标分为——低级需求：能够正常对外提供服务；高级需求：SRE能够主动控制服务状态，而不是被动救火。 离开了监控系统，我们就没有能力辨别一个服务是不是在正常提供服务。没有一套设计周全的监控体系就如同蒙着眼睛狂奔。作为一个合格个运维，我们需要在用户之前发现系统中存在的问题。 SRE并不是为了on-call值班而值班，on-call只是我们实现服务目标的一种工具。如果找到一种方式使得值班不在必要，SRE肯定会第一时间采用。 在应急事件处理中，由于压力很大，很多情况下人们急于解决问题，会绕开必要的流程。 如何建立起无指责、对事不对人的团队文化。 事故追踪系统，跟踪最近发生的生产事故、原因以及解决的具体过程。 当我们发现经常出现问题的组件或流程时，下一步就是如何避免它再次发生故障。通过增加测试，保证不会出现类似问题。 服务容量规划。 Google SRE一半的精力都花在设计和开发大规模软件系统上。 产品设计理念位于金字塔顶端。 告警 基于时间序列数据进行有效告警 监控，处于整个生产环境需求金字塔模型的最底层。监控是运营一个可靠的稳定服务不可缺少的部分。服务运维人员需要依靠监控数据对服务的情况做出理性判断，用科学的方法应对紧急情况。同时，监控数据也可以用来确保服务质量与产品目标保持一致。 监控一个大型系统本身是以像非常具有挑战性的工作： 大型系统中组件数量特别多，分析工作纷杂繁重 监控系统本身的维护要求非常低 一个大型系统不应该要求运维人员持续关注其中使用的无数个小组件，而是因该自动汇总所有的信息，自动抛弃其中的异常情况。监控系统应该主要从高级服务质量目标层面进行报警，但是也应该保持足够的粒度，可以追踪到某个具体的组件。 这个模型将收集时间序列信息作为监控系统的首要任务，同时发展了一种丰富的时间序列信息操作语言。这就是Google的Borgmon监控系统，类似的还有Prometheus。 Borgmon将所有数据保存在一个内存数据库中，定时保存到硬盘上。这些数据都是以类似(timestamp, value)的格式存储在一个按时间排序的链表里，该链表称为时序(time-series)。同时，每个时序链表用一组唯一的标签命名(name=value)。 一个时序链表实际上是一个单维数字矩阵，以时间为Y轴。当给时序加上各种标签时，这个矩阵就变成多维矩阵了。 在实际实现中，这个数据接口存放在固定大小的内存块中。存放区满后，同时有一个垃圾回收器，将过期的数据从内存中清除。它会定时将内存状态归档到外部时序数据库(TSDB)。 Borgmon，每个数据点大概占用24Bytes的内存，存放100万个时序，每个时序每分钟一个数据点，同时保存12小时的数据，仅需17GB内存。 时序是按照时间戳和值的序列存放的，称之为向量(vector)。就像线性代数中的向量一样，这些向量是一个存放在时序存放区中的多维矩阵中的某一列，或某一个对角线数值串。 时序的名字称为标签集合(labelset)，因为它的实现方式就是一个标签(key=value)的集合。 每个SRE团队都会将严重情况报警发送给当前on-call工程师。将重要但不紧急的报警发送给工单系统。其它报警一般用来作为历史数据或者服务监控台展示使用。 Borgmon是一个白盒监控系统，负责监控目标和服务的内部状态。 但是，白盒监控并不能完全代表一个被监控系统的所有状态。完全依赖白盒监控，意味着我们并不知道最终用户看到的是什么样。 例如，白盒监控只能看到已经接收到的请求，并不能看到由于DNS故障导致没有发送成功的请求，或者由于软件服务器奔溃而没有返回的错误。同时，报警策略也只包含了工程师能想到的错误情况。 Google SRE团队通常利用探针程序(prober)解决该问题，也就是云厂商的站点监控功能(tcp, udp, icmp, http…)。 on-call轮值 on-call轮值是很多运维和研发团队的重要职责，目标是保障服务的可靠性和可用性。但如果没有正确执行，将会给服务甚至团队带来非常严重的后果。 Google SRE和纯运维团队不同，SRE团队强调用工程化手段来应对运维问题。而这些运维问题，当达到一定规模时，也确实只有采用工程化手段才能解决。所以SRE 都是50%研发，50%运维。 一旦接收到报警消息，工程师必须确认，on-call工程师必须能够及时定位问题，并且尝试解决问题。必要的话，还可以联系其它团队。 多地团队有以下优势: 长时间执行夜间任务对人健康不利。多地团队可以利用日出而作，日落而息的轮值制度使整个团队避免夜间值班 通过限制一个团队在on-call轮值制度中的人员数量，可保障每个工程师对生产环境的熟悉程度 出现问题后，应该编写事故报告，仔细评估哪些地方有问题，哪些地方做的好是非常关键的。事故出现太多，超过了具体指标，那么管理团队必须采取一些修正措施保证运维压力下降到可持续水平。 管理层需要考虑，针对工作时间之外的on-call工作应该与合理的补贴。Google提供年假或现金补贴。同时应避免过量on-call带来的问题，如项目开发时间不够，或疲脑过度。 现代理论研究指出，在面临跳转时，一个人会主动或非主动(潜意识)低选择下列两种处理方法之一： 依赖直觉，自动化、快速型到 理性、专注、有意识地进行认知类活动 当处理复杂系统问题时，第二种行事方式更好。为了确保这样，必须要减轻on-call所带来的压力感。业务系统的重要性和操作所带来的影响程度会对on-call工程师造成巨大的精神压力，危害工程师的身体健康，并且可能导致SRE在处理问题过程中犯错误，从而影响到这个系统的可靠性。 在这些压力的影响下，on-call工程师往往会选择反应性的、未经详细考虑过的操作，并容易导致过度联想现象的产生。过度联想是on-call非常容易产生的现象。如on-call工程师收到本周内第四个同样报警信息时，很容易联想起前3次报警都是由于某个外部系统造成的虚假报警，于是很自然地将第4次报警也归类为虚假报警，从而没有认真处理，导致真实事故的发生。 在应急事故处理过程中，凭直觉操作和快速反应（如出现问题就先重启服务器）看起来都是很有用的方法，但是这些方法都有自己的缺点。直觉很可能是错误的，而且直觉一般都不是基于明确的数据支持的。因此，在处理问题的过程中，on-call工程师很有可能由于凭直觉去解释问题产生的原因而浪费宝贵的时间。快速反应主要是由习惯而产生的，习惯性的快速反应的动作后果一般都没有经过详细考虑，这可能会将灾难扩大。 在应急事件处理过程中，最理想的方法论应该这样：在有足够数据支撑的时候按步骤解决问题，同时不停地审视和验证目前所有的假设。 让on-call SRE知道他们可以寻求外部帮助，对减轻on-call压力也很有帮助。最重要的资源有： 清晰的问题升级路线 清晰定义的应急事件处理步骤 无指责、对事不对人的文化氛围 对于操作生产环境，自信心太强以及自信心不足，都不是很好。 故障排查手段 系统正常，只是该系统无数异常情况下的一种特例。 故障排查是运维分布式计算系统的一项关键技能。 从理论上讲，我们将故障排查过程定义为反复采用假设-排除手段的过程。 有很多方法可以简化和加速故障排查过程。可能最基本的是： 增加可观察性。在实现之初就给每个组件增加白盒监控指标和结构化日志 利用成熟的、观察性好的组件接口设计系统 紧急事件响应 不管一个组织有多大，做的事情有多么重要，它最明显的特质就是：在紧急事件来临时人们如何应对。 当系统出现问题时，别惊慌失措！这不是世界末日，你也不是一个人在战斗！如果你感到自己难以应付，就去找更多人参与进来。 Google经常主动进行灾难处理和应急响应演习。事故响应和事故总结。 为事故保留记录，历史就是学习其他人曾经犯的错误。 紧急事故管理 有效的紧急事故管理是控制事故影响和迅速回复运营的关键因素。如果事先没有针对可","date":"2021-04-13","objectID":"/google-sre/:25:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"无流程管理的紧急事故 在上面所说的场景中，每个人都在尽力解决问题，起码在他们自己看来是这样。那么问题怎么变得越来越糟的呢？ 有几个常见的问题导致了整个事故的失控： 过于关注技术问题 沟通不畅 不请自来 ","date":"2021-04-13","objectID":"/google-sre/:26:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"紧急事故的流程管理要素 紧急事故流程管理的技巧和手段都是为了让这些富有热情的人能够真正帮上忙。 嵌入式职责分离：在事故处理中，让每个人清除自己的职责是非常重要的。 一些角色： 事故总控 事务处理团队 发言人 规划负责人 控制中心： 受到事故影响的部分或者人需要知道他们可以与事故总控负责人联系。 实时事故状态文档：该文档可以以wiki的形式存在，但是最好能够被多人同时编辑。 明确公开的职责交接。 ","date":"2021-04-13","objectID":"/google-sre/:27:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"流程良好的事故 ","date":"2021-04-13","objectID":"/google-sre/:28:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"什么时候对外宣布事故 先宣布事故发生，随后找到一个简单解决方案，然后宣布事故结束，要比在问题已经持续很久之后才想起流程管理更好。 应当针对事故设立一个明确的宣布条件： 是否需要引入 第二个团队来帮助处理问题？ 这次事故是否正在影响最终用户？ 在集中分析一小时后，这个问题是否依然没有得到解决？ 事后总结 事后总结，从失败中学习。 学习是避免失败的最好办法。 一篇事后总结是一次事故的书面记录，包括该事故造成的影响，为缓解该事故采取的措施，事故的根本原因，以及防止未来事故重现的后续任务。 ","date":"2021-04-13","objectID":"/google-sre/:29:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"Google的事后总结哲学 在任何一个重要事故发生后，团队必须书写一份事后总结。要注意的是，书写事后总结不是一种惩罚措施，而是整个公司的一次学习机会。基本的事后总结条件： 用户可见的宕机时间，或服务质量降级程序达到一定标准 任何类型的数据丢失 on-call工程师需要人工接入的事故 问题解决耗时超过一定限制 监控问题 在SRE的文化中，最重要的就是事后总结对事不对人。一篇事后总结必须重点关注如何定位造成这次事件的根本问题，而不是指责某个人或某团队的错误或者不恰当的举动。如果因为某些错误的举动就公开指责或羞辱某个人或团队，那么人们就会自然地逃避事后总结。 避免职责，提供建设性意见。 ","date":"2021-04-13","objectID":"/google-sre/:30:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"协作和知识共享 不管采用哪些工具，请确保优先选择下列功能： 实时协作 开放的评论功能 邮件通知 跟踪故障 提高可靠性的唯一可靠办法论是建立一个基线(baseline)，同时不断跟踪改变。使用故障跟踪工具来做这些事。 将多个告警信息聚合成一个单独的故障能够有效解决这个问题，聚合功能能更好地消除重复告警，避免重复性工作。 对告警增加元数据信息（标签），更有效率。 汇总和分析一些历史告警数据。 测试可靠性 SRE的一项关键职责就是要定量地分析我们维护的某项服务的质量。 ","date":"2021-04-13","objectID":"/google-sre/:31:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"软件测试的类型 分为两类： 传统测试： 主要用来在开发过程中离线评估软件的正确性 单元测试 集成测试 系统测试 生产测试： 评估一个已经部署的软件系统是否正常工作 黑盒测试 压力测试 金丝雀测试 ","date":"2021-04-13","objectID":"/google-sre/:32:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"创造一个构建和测试环境 ","date":"2021-04-13","objectID":"/google-sre/:33:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"大规模测试 测试大规模使用的工具 针对灾难的测试 对速度的渴求 发布到生产环境 允许测试失败 生产环境探针 SRE部门中的软件工程实践 总体来说，SRE开发的工具是一个完整的软件工程项目，而不是一次性的脚本和小补丁。开发这些工具的SRE也需要针对内部用户的需求进行产品规划，指定未来的发展方向。 ","date":"2021-04-13","objectID":"/google-sre/:34:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"为什么软件工程对SRE很重要 SRE组织的一个指导思想是，团队大小不应该与用户服务规模成比例增长。在用户服务成指数增长的情况下，想要保持SRE团队以线性增长需要不断地进行自动化工具的开发，以及不停地优化工具、流程，消除一切其它日常运维相关的效率问题。 完整的软件工程项目在SRE组织内部提供了一个职业发展的方向，也提供了一些磨练编程技能的良好机会。 ","date":"2021-04-13","objectID":"/google-sre/:35:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"在SRE团队中培养软件工程风气 前端服务器的负载均衡 运维大型系统时，将所有鸡蛋放在一个篮子里是引来灾难的最好办法。 ","date":"2021-04-13","objectID":"/google-sre/:36:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"有时候硬件并不能解决问题 一台无穷大配置的机器，传输速度也会有限制，而且存在单点故障。 一个搜索请求和一个视频上传请求。用户想要快速的获取搜索结果，所以对搜索请求来说最重要的变量是延迟(latency)。而对于视频上传请求来说，最重要的变量是吞吐量(throughput)。两种请求用户的需求不同，是我们在全局层面决定最优分配方案的重要条件。 搜索请求将会被发送到最近的可用数据中心 视频上传需要寻找一条带宽没有占满的链路，这可能会牺牲一定程度的延迟 但是在局部层面，在一个数据中心内部，网往关注与优化资源的利用率，避免某个服务器负载过高。 ","date":"2021-04-13","objectID":"/google-sre/:37:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"使用DNS进行负载均衡 CDN其实也就是就近原则（最优位置）的DNS负载均衡。 ","date":"2021-04-13","objectID":"/google-sre/:38:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"虚拟IP 虚拟IP(VIP)不是绑定到某一个特定的网络接口上，它是由很多设备共享的。 数据中心内部的负载均衡系统 理想情况下，某个服务的负载会完全均匀地分发给所有的后端服务。 异常任务的简单应对方法： 流速控制。 一个可靠的识别异常任务的方法： 跛脚鸭状态（后端任务正在监听端口，并且可以服务请求，但是已经明确要求客户端停止发送请求）。 利用划分子集限制连接池大小。 负载均衡策略： 简单轮询算法 最闲轮询算法 加权轮询策略 应对过载 避免过载，是负载均衡策略的一个重要目标。但无论负载均衡策略效率有多高，随着压力的上升，系统的某个部位总会过载。运维一个可靠系统的一个根本要求，就是能够优雅地处理过载情况。 无论如何，构建良好处理资源限制的客户端和对应的后端服务是最好的。在可能的情况下重定向请求，在必要时返回降级回复，同时在最差情况下，能够妥善地处理资源受限导致的错误。 ","date":"2021-04-13","objectID":"/google-sre/:39:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"QPS陷阱 不同的请求可能需要数量迥异的资源来处理。某个请求的成本可能由各种各样的因素决定。 Google在多年的经验积累中得出，按照QPS来规划服务容量，或按照某种静态属性一般是错误的选择。 更好的解决方案是直接以可用资源来衡量可用容量。简单地使用CPU和MEM作为资源配给的主要信号就可以工作的很好。 ","date":"2021-04-13","objectID":"/google-sre/:40:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"给每个用户设置限制 过载应对策略设计的一部分是决定如何处理 全局过载(global overload) 的情况。在理想情况下，每个团队能和他们所依赖的后端服务团队直接协调功能发布，从而使后端服务永远有足够容量服务最终用户，这样全局过载就不会发生。不幸的是，现实总是很残酷。全局过载情况在实际运行中出现得非常频繁。 当全局过载发生时，使服务只针对某些异常客户返回错误是非常关键的，这样其他用户则不会受影响。为了达到这个目的，该服务的运维团队和客户团队协商一些合理的使用约定，同时使用这个约定类配置用户配额，并且配置相应的资源。 ","date":"2021-04-13","objectID":"/google-sre/:41:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"客户端侧的节流机制 有时候，可能拒绝请求、发送拒绝回复仍然会消耗一定数量的资源。如果回复数量很多，这些消耗可能也十分客观。这种情况，有可能也会让后端服务过载。 客户端侧的节流机制可以解决这个问题。客户端直接本地回复失败，而不会真正发送到网络层。 ","date":"2021-04-13","objectID":"/google-sre/:42:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"重要性 最重要 重要 可丢弃 ","date":"2021-04-13","objectID":"/google-sre/:43:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"资源利用率信号 我们的任务过载保护是基于资源利用率（使用量除以预留量）实现的。 ","date":"2021-04-13","objectID":"/google-sre/:44:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["sre"],"content":"处理过载错误","date":"2021-04-13","objectID":"/google-sre/:45:0","tags":["sre","devops","google"],"title":"google-sre","uri":"/google-sre/"},{"categories":["cncf"],"content":"参考: Istio docs: https://istio.io/docs Istio中文文档: https://istio.io/zh/docs/ Istio github: https://github.com/istio/istio 环境: RHEL7x86_64 Istio v1.9 k8s v1.18 \r\r \r\r概念 Concepts ","date":"2021-02-18","objectID":"/istio/:0:0","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"Istio是什么 What is Istio? Istio允许您连接(connect)，保护(secure)，控制(control)和观察(observe)服务。 在较高的层级上，Istio有助于降低部署的复杂性，减轻开发团队的压力。它是一个完全开源的服务网格(service mesh)，可透明地分层到现有的分布式应用程序上。它也是一个平台，包括可以将其集成到任何日志记录平台或策略系统的API。Istio的多样化功能使你能够成功，高效地运行分布式微服务(microservice)架构，并提供安全，连接和监控微服务的统一方法。 \r","date":"2021-02-18","objectID":"/istio/:1:0","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"服务网格 Service Mesh Istio解决了开发人员和运营商在单片应用程序向分布式微服务架构过渡时所面临的挑战。有必要详细了解Istio服务网格。 术语服务网格用于描述构成此类应用程序的微服务网络以及它们之间的交互。随着服务网格的大小和复杂性的增加，理解和管理变得更加困难。其要求包括: 发现(discovery) 负载均衡(load balancing) 故障恢复(failure recovery) 指标(metrics) 监控(monitoring) 服务网格通常还具有更复杂的操作要求，如: A/B测试 金丝雀部署(canary rollouts) 速率限制(rate limiting) 访问控制(access control) 端到端认证(end-to-end authentication) Istio作为一个整体提供对服务网格的行为洞察和操作控制。 \r\r","date":"2021-02-18","objectID":"/istio/:1:1","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"为什么使用它 Why use Istio? 通过负载均衡，服务到服务的身份认证，监控…使用服务代码中很少或不需要更改代码，Istio可以轻松创建已部署的服务网格。通过在整个环境中部署特殊的sidecar代理来拦截服务的Istio支持，该代理拦截微服务之间的所有网络通信，然后使用其控制平面配置和管理Istio。包括: HTTP, gRPC, WebSocket, TCP流量的自动负载均衡； 通过丰富的路由规则，重试(retries)，故障转移(failovers)，故障注入(fault injection)，对流量欣慰 进行细粒度控制； 可插入的策略层和API配置，支持访问控制，速率限制和配额； 集群中所有流浪的自动度量、日志和追踪，包括集群的ingress, egress； 通过强大的基于身份的认证和授权，在集群中实现安全的服务到服务的通信。 \r\r","date":"2021-02-18","objectID":"/istio/:1:2","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"核心功能 Core features Istio 以统一的方式提供了许多跨服务网络的关键功能。 \r流量管理 Traffic management 通过Istio简单的规则配置和流量路由，你可以控制服务之间的流量和API调用。它简化了服务级别的属性配置，如熔断器(circuit breakers)，超时(timeouts)，重试(retries)，并且可以轻松设置A/B测试，金丝片部署(canary rollouts)，基于百分比流量分割的分阶段部署等重要任务。 通过更好地了解流量和开箱即用的故障恢复功能，你可在问题出现之前发现问题，使调用更加可靠、网络更加强大。 \r\r安全 Security Istio的安全功能使开发人员可以更加专注于应用程序级别的安全性。Istio提供了底层安全通信信道，并大规模管理服务通信的认证、授权和加密。使用Istio，服务通信在默认情况下是安全的，允许你跨多种协议和运行时一致地实施策略。所有这些基本都不用对应用程序进行更改。 虽然Istio与平台无关，但与k8s网络策略一起使用时，其优势更大，包括在网络层和应用层保护pod-to-pod或service-to-service通信的能力。 \r\r可观察性 Observability Istio强大的追踪、监控和日志记录功能可以让你更深入了解服务网格部署。通过Istio的监控功能，真正了解服务性能如何影响上下游(upstream, downstream)的功能，而其自定义的仪表盘可提供对所有服务性能的可视性，并让你了解该性能如何影响你的其他进程。 Istio的**混合器（Mixer)**组件负责策略控制和遥测收集。它提供后端抽象和中间媒介，将Istio的其余部分与各个基础架构后端的实现细节隔离开来，并为运营商提供对网格网络和基础架构后端之间所有交互的细粒度控制。 这些功能使你可以更有效地设置，监控和实施服务上的SLOs。当然，最重要的是，你可以快速有效地检测和修复问题。 \r\r平台支持 Platform support Istio是独立于平台的，旨在各种环境中运行。包括跨云，内在部署，k8s，Mesos… 你可在k8s上部署Istio，或在带有Nomad的Consul上部署它。Istio目前支持: Kubernetes 上的服务部署(Service deployment on Kubernetes) 基于 Consul 的服务注册(Services registered with Consul) 服务运行在独立的虚拟机上(Services running on individual virtual machines) \r\r整合和定制 Integration and customization 可以扩展和自定义Istio的策略实施组件，来与现有的ACL，日志记录，监控，配额，审计等方案集成。 \r\r","date":"2021-02-18","objectID":"/istio/:1:3","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"架构 Architecture Istio服务网格逻辑上分为数据平面(data plane)和控制平面(data plane)。 数据平面由一组以 sidecar 方式部署的**智能代理(Envoy)**组成。这些代理可以调节和控制微服务及Mixer之间所有的网络通信。 控制平面负责管理和配置代理来路由流量。此外控制平面配置Mixer以实施策略和收集遥测数据。 \rEnvoy Istio使用Envoy代理的扩展版本，Envoy是以C++开发的高性能代理，用于调解服务网格中所有服务的所有入站和出站流量。 Envoy 的许多内置功能被 Istio 发扬光大，如: 动态服务发现(Dynamic service discovery) 负载均衡(Load balancing) TLS termination HTTP/2 and gRPC proxies 熔断器(Circuit breakers) 健康检查(Health checks) 基于百分比流量拆分的灰度发布 故障注入(Fault injection) 丰富的度量指标(Rich metrics) Envoy 被部署为 sidecar，和对应服务在同一个 k8s pod 中。这允许 Istio 将大量关于流量行为的信号作为属性提取出来，而这些属性又可以在 Mixer 中用于执行策略决策，并发送给监控系统，以提供整个网格行为的信息。 Sidecar 代理模型还可以将 Istio 的功能添加到现有部署中，而无需重新构建或重写代码。 \r\rMixer Mixer 是一个独立于平台的组件，负责在服务网格上执行访问控制和使用策略，并从 Envoy 代理和其他服务收集遥测数据。代理提取请求级属性，发送到 Mixer 进行评估。 Mixer 中包括一个灵活的插件模型，使其能够接入到各种主机环境和基础设施后端，从这些细节中抽象出 Envoy 代理和 Istio 管理的服务。 \r\rPilot Pilot 为 Envoy sidecar 提供服务发现功能，为智能路由（如 A/B测试、金丝雀部署）和弹性（超时、重试、熔断器）提供流量管理功能。 它将控制流量行为的高级路由规则转换为特定于 Envoy 的配置，并在运行时将它们传播到 sidecar。Pilot 将平台特定的服务发现机制抽象化并将其合成为符合 Envoy 数据平面 API 的任何 sidecar 都可以使用的标准格式。这种松散耦合使得 Istio 能够在多种环境下运行（如 k8s、Consul、Nomad），同时保持用于流量管理的相同操作界面。 \r\rCitadel Citadel 通过内置身份和凭证管理赋能强大的服务间和最终用户身份验证。可用于升级服务网格中未加密的流量，并为运维人员提供基于服务标识而不是网络控制的强制执行策略的能力。 \r\rGalley Galley 代表其他的 Istio 控制平面组件，用来验证用户编写的 Istio API 配置。随着时间的推移，Galley 将接管 Istio 获取配置、 处理和分配组件的顶级责任。它将负责将其他的 Istio 组件与从底层平台(如k8s)获取用户配置的细节中隔离开来。 \r\r","date":"2021-02-18","objectID":"/istio/:1:4","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"设计目标 Design Goals Istio的架构设计中有几个关键目标，这些目标对于使系统能够应对大规模流量和高性能地服务处理至关重要。 最大化透明度(Maximize Transparency) 可扩展性(Extensibility) 可移植性(Portability) 策略一致性(Policy Uniformity) \r\r\r","date":"2021-02-18","objectID":"/istio/:1:5","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"流量管理 Traffic Management Istio的流量路由规则可以让你控制服务之间的API调用。Istio 简化了服务级别属性的配置，比如熔断器、超时和重试，并且能轻松的设置重要的任务，如 A/B 测试、金丝雀发布、基于流量百分比切分的概率发布等。 Istio 的流量管理模型源于和服务一起部署的 Envoy 代理。网格内服务发送和接收的所有流量（data plane流量）都经由 Envoy 代理。 ","date":"2021-02-18","objectID":"/istio/:2:0","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"介绍 为了在网格中导流，Istio 需要知道所有的 endpoint 在哪和属于哪个服务。为了定位到service registry(服务注册中心)，Istio 会连接到一个服务发现系统。例如，如果您在 Kubernetes 集群上安装了 Istio，那么它将自动检测该集群中的服务和 endpoint。 使用此服务注册中心，Envoy 代理可以将流量定向到相关服务。大多数基于微服务的应用程序，每个服务的工作负载都有多个实例来处理流量，称为负载均衡池。默认情况下，Envoy 代理基于轮询调度模型在服务的负载均衡池内分发流量，按顺序将请求发送给池中每个成员，一旦所有服务实例均接收过一次请求后，重新回到第一个池成员。 Istio 基本的服务发现和负载均衡能力为您提供了一个可用的服务网格，但它能做到的远比这多的多。在许多情况下，您可能希望对网格的流量情况进行更细粒度的控制。作为 A/B 测试的一部分，您可能想将特定百分比的流量定向到新版本的服务，或者为特定的服务实例子集应用不同的负载均衡策略。您可能还想对进出网格的流量应用特殊的规则，或者将网格的外部依赖项添加到服务注册中心。通过使用 Istio 的流量管理 API 将流量配置添加到 Istio，就可以完成所有这些甚至更多的工作。 和其他 Istio 配置一样，这些 API 也使用 Kubernetes 的自定义资源定义（CRDs）来声明。 ","date":"2021-02-18","objectID":"/istio/:2:1","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"虚拟服务 Virtual Service 虚拟服务和目标规则是Istio流量路由功能的关键拼图。 虚拟服务让您配置如何在服务网格内将请求路由到服务，这基于 Istio 和平台提供的基本的连通性和服务发现能力。每个虚拟服务包含一组路由规则，Istio 按顺序评估它们，Istio 将每个给定的请求匹配到虚拟服务指定的实际目标地址。您的网格可以有多个虚拟服务，也可以没有，取决于您的使用场景。 为什么使用虚拟服务 虚拟服务在增强 Istio 流量管理的灵活性和有效性方面，通过对客户端请求的目标地址与真实响应请求的目标工作负载进行解耦来实现。虚拟服务同时提供了丰富的方式，为发送至这些工作负载的流量指定不同的路由规则。 如果没有虚拟服务，Envoy 会在所有的服务实例中使用轮询的负载均衡策略分发请求。使用虚拟服务，您可以为一个或多个主机名指定流量行为。在虚拟服务中使用路由规则，告诉 Envoy 如何发送虚拟服务的流量到适当的目标。路由目标地址可以是同一服务的不同版本，也可以是完全不同的服务。 一个典型的用例是将流量发送到被指定为服务子集的服务的不同版本。客户端将虚拟服务视为一个单一实体，将请求发送至虚拟服务主机，然后 Envoy 根据虚拟服务规则把流量路由到不同的版本。 虚拟服务可以让你： 通过单个虚拟服务处理多个应用程序服务。如果您的网格使用 Kubernetes，可以配置一个虚拟服务处理特定命名空间中的所有服务。映射单一的虚拟服务到多个“真实”服务特别有用，可以在不需要客户适应转换的情况下，将单体应用转换为微服务构建的复合应用系统。 和网关整合并配置流量规则来控制出入流量 虚拟服务示例 下面的虚拟服务根据请求是否来自特定的用户，把它们路由到服务的不同版本。 apiVersion:networking.istio.io/v1alpha3kind:VirtualServicemetadata:name:reviewsspec:hosts:- reviewshttp:- match:- headers:end-user:exact:jasonroute:- destination:host:reviewssubset:v2- route:- destination:host:reviewssubset:v3 介绍: hosts字段 列举虚拟服务的主机——即用户指定的目标或是路由规则设定的目标。这是客户端向服务发送请求时使用的一个或多个地址。虚拟服务主机名可以是 IP 地址、DNS 名称，或者依赖于平台的一个简称（例如 Kubernetes 服务的短名称），隐式或显式地指向一个完全限定域名（FQDN）。 路由规则 在 http 字段包含了虚拟服务的路由规则，用来描述匹配条件和路由行为，它们把 HTTP/1.1、HTTP2 和 gRPC 等流量发送到 hosts 字段指定的目标。 route 部分的 destination 字段指定了符合此条件的流量的实际目标地址。与虚拟服务的 hosts 不同，destination 的 host 必须是存在于 Istio 服务注册中心的实际目标地址，否则 Envoy 不知道该将请求发送到哪里。 路由规则优先级 路由规则按从上到下的顺序选择，虚拟服务中定义的第一条规则有最高优先级。 我们建议提供一个默认的无条件或基于权重的规则作为每一个虚拟服务的最后一条规则，如案例所示，从而确保流经虚拟服务的流量至少能够匹配一条路由规则。 路由规则的更多内容 路由规则是将特定流量子集路由到指定目标地址的强大工具。您可以在流量端口、header 字段、URI 等内容上设置匹配条件。 apiVersion:networking.istio.io/v1alpha3kind:VirtualServicemetadata:name:bookinfospec:hosts:- bookinfo.comhttp:- match:- uri:prefix:/reviewsroute:- destination:host:reviews- match:- uri:prefix:/ratingsroute:- destination:host:ratings...http:- match:sourceLabels:app:reviewsroute:... 有些匹配条件可以使用精确的值，如前缀或正则。 可以使用 AND 向同一个 match 块添加多个匹配条件，或者使用 OR 向同一个规则添加多个 match 块。 另外，使用匹配条件您可以按百分比”权重“分发请求。这在 A/B 测试和金丝雀发布中非常有用： spec:hosts:- reviewshttp:- route:- destination:host:reviewssubset:v1weight:75- destination:host:reviewssubset:v2weight:25 您也可以使用路由规则在流量上执行一些操作，如： 添加或删除header 重写URL 为调用这一目标地址的请求设置重试策略 ","date":"2021-02-18","objectID":"/istio/:2:2","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"目标规则 Destination Rule 您可以将虚拟服务视为将流量如何路由到给定目标地址，然后使用目标规则来配置该目标的流量。在评估虚拟服务路由规则之后，目标规则将应用于流量的“真实”目标地址。 您可以使用目标规则来指定命名的服务子集，例如按版本为所有给定服务的实例分组。然后可以在虚拟服务的路由规则中使用这些服务子集来控制到服务不同实例的流量。 目标规则还允许您在调用整个目的地服务或特定服务子集时定制 Envoy 的流量策略，比如您喜欢的负载均衡模型、TLS 安全模式或熔断器设置。 负载均衡选项 Load balancing options 默认情况下，Istio 使用轮询的负载均衡策略，实例池中的每个实例依次获取请求。Istio 同时支持如下的负载均衡模型： 轮询(round-robin) 随机(Random)：请求以随机的方式转到池中的实例。 权重(Weighted)：请求根据指定的百分比转到实例。 最少请求(Least requests)：请求被转到最少被访问的实例。 目标规则示例 Destination rule example 在下面的示例中，目标规则为 my-svc 目标服务配置了 3 个具有不同负载均衡策略的子集： apiVersion:networking.istio.io/v1alpha3kind:DestinationRulemetadata:name:my-destination-rulespec:host:my-svctrafficPolicy:loadBalancer:simple:RANDOMsubsets:- name:v1labels:version:v1- name:v2labels:version:v2trafficPolicy:loadBalancer:simple:ROUND_ROBIN- name:v3labels:version:v3 ","date":"2021-02-18","objectID":"/istio/:2:3","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"网关 Gateways 使用网关为网格来管理入站和出站流量，可以让您指定要进入或离开网格的流量。网关配置被用于运行在网格边界的独立 Envoy 代理，而不是服务工作负载的 sidecar 代理。 与 Kubernetes Ingress API 这种控制进入系统流量的其他机制不同，Istio 网关让您充分利用流量路由的强大能力和灵活性。您可以这么做的原因是 Istio 的网关资源可以配置 4-6 层的负载均衡属性，如对外暴露的端口、TLS 设置等。作为替代应用层流量路由（L7）到相同的 API 资源，您绑定了一个常规的 Istio 虚拟服务到网关。这让您可以像管理网格中其他数据平面的流量一样去管理网关流量。 网关主要用于管理进入的流量，但您也可以配置出口网关。出口网关让您为离开网格的流量配置一个专用的出口节点，这可以限制哪些服务可以或应该访问外部网络，或者启用出口流量安全控制为您的网格添加安全性。您也可以使用网关配置一个纯粹的内部代理。 Istio 提供了一些预先配置好的网关代理部署（istio-ingressgateway 和 istio-egressgateway）供您使用。 gateway示例 下面的示例展示了一个外部 HTTPS 入口流量的网关配置： apiVersion:networking.istio.io/v1alpha3kind:Gatewaymetadata:name:ext-host-gwyspec:selector:app:my-gateway-controllerservers:- port:number:443name:httpsprotocol:HTTPShosts:- ext-host.example.comtls:mode:SIMPLEserverCertificate:/tmp/tls.crtprivateKey:/tmp/tls.key 这个网关配置让 HTTPS 流量从 ext-host.example.com 通过 443 端口流入网格，但没有为请求指定任何路由规则。为想要工作的网关指定路由，您必须把网关绑定到虚拟服务上。 apiVersion:networking.istio.io/v1alpha3kind:VirtualServicemetadata:name:virtual-svcspec:hosts:- ext-host.example.comgateways:- ext-host-gwy ","date":"2021-02-18","objectID":"/istio/:2:4","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"服务入口 Service entries 使用服务入口来添加一个入口到 Istio 内部维护的服务注册中心。添加了服务入口后，Envoy 代理可以向服务发送流量，就好像它是网格内部的服务一样。配置服务入口允许您管理运行在网格外的服务的流量，它包括以下几种能力： 为外部目标 redirect 和转发请求。 为外部目标定义重试、超时和故障注入策略。 添加一个运行在虚拟机的服务来扩展您的网格。 从逻辑上添加来自不同集群的服务到网格，在 Kubernetes 上实现一个多集群 Istio 网格。 您不需要为网格服务要使用的每个外部服务都添加服务入口。默认情况下，Istio 配置 Envoy 代理将请求传递给未知服务。但是，您不能使用 Istio 的特性来控制没有在网格中注册的目标流量。 服务入口示例 下面示例的 mesh-external 服务入口将 ext-resource 外部依赖项添加到 Istio 的服务注册中心： apiVersion:networking.istio.io/v1alpha3kind:ServiceEntrymetadata:name:svc-entryspec:hosts:- ext-svc.example.comports:- number:443name:httpsprotocol:HTTPSlocation:MESH_EXTERNALresolution:DNS 您指定的外部资源使用 hosts 字段。可以使用完全限定名或通配符作为前缀域名。 您可以配置虚拟服务和目标规则，以更细粒度的方式控制到服务入口的流量，这与网格中的任何其他服务配置流量的方式相同。 例如，下面的目标规则配置流量路由以使用双向 TLS 来保护到 ext-svc.example.com 外部服务的连接，我们使用服务入口配置了该外部服务： apiVersion:networking.istio.io/v1alpha3kind:DestinationRulemetadata:name:ext-res-drspec:host:ext-svc.example.comtrafficPolicy:tls:mode:MUTUALclientCertificate:/etc/certs/myclientcert.pemprivateKey:/etc/certs/client_private_key.pemcaCertificates:/etc/certs/rootcacerts.pem ","date":"2021-02-18","objectID":"/istio/:2:5","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"Sidecar 默认情况下，Istio 让每个 Envoy 代理都可以访问来自和它关联的工作负载的所有端口的请求，然后转发到对应的工作负载。您可以使用 sidecar 配置去做下面的事情： 微调 Envoy 代理接受的端口和协议集。 限制 Envoy 代理可以访问的服务集合。 您可以指定将 sidecar 配置应用于特定命名空间中的所有工作负载，或者使用 workloadSelector 选择特定的工作负载。 例如，下面的 sidecar 配置将 bookinfo 命名空间中的所有服务配置为仅能访问运行在相同命名空间和 Istio 控制平面中的服务： apiVersion:networking.istio.io/v1alpha3kind:Sidecarmetadata:name:defaultnamespace:bookinfospec:egress:- hosts:- \"./*\"- \"istio-system/*\" ","date":"2021-02-18","objectID":"/istio/:2:6","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"网络弹性和测试 Network resilience and testing 除了为您的网格导流之外，Istio 还提供了可选的故障恢复和故障注入功能，您可以在运行时动态配置这些功能。使用这些特性可以让您的应用程序运行稳定，确保服务网格能够容忍故障节点，并防止局部故障级联影响到其他节点。 超时 Timeouts 超时是 Envoy 代理等待来自给定服务的答复的时间量，以确保服务不会因为等待答复而无限期的挂起，并在可预测的时间范围内调用成功或失败。HTTP 请求的默认超时时间是 15 秒，这意味着如果服务在 15 秒内没有响应，调用将失败。 对于某些应用程序和服务，Istio 的缺省超时可能不合适。为了找到并使用最佳超时设置，Istio 允许您使用虚拟服务按服务轻松地动态调整超时，而不必修改您的业务代码。 apiVersion:networking.istio.io/v1alpha3kind:VirtualServicemetadata:name:ratingsspec:hosts:- ratingshttp:- route:- destination:host:ratingssubset:v1timeout:10s 重试 Retries 重试设置指定如果初始调用失败，Envoy 代理尝试连接服务的最大次数。HTTP 请求的默认重试行为是在返回错误之前重试两次。您可以在虚拟服务中按服务调整重试设置，而不必修改业务代码。 apiVersion:networking.istio.io/v1alpha3kind:VirtualServicemetadata:name:ratingsspec:hosts:- ratingshttp:- route:- destination:host:ratingssubset:v1retries:attempts:3perTryTimeout:2s 熔断器 Circuit breakers 熔断器是 Istio 为创建具有弹性的微服务应用提供的另一个有用的机制。在熔断器中，设置一个对服务中的单个主机调用的限制，例如并发连接的数量或对该主机调用失败的次数。一旦限制被触发，熔断器就会“跳闸”并停止连接到该主机。使用熔断模式可以快速失败而不必让客户端尝试连接到过载或有故障的主机。 apiVersion:networking.istio.io/v1alpha3kind:DestinationRulemetadata:name:reviewsspec:host:reviewssubsets:- name:v1labels:version:v1trafficPolicy:connectionPool:tcp:maxConnections:100 故障注入 Fault injection 在配置了网络，包括故障恢复策略之后，可以使用 Istio 的故障注入机制来为整个应用程序测试故障恢复能力。故障注入是一种将错误引入系统以确保系统能够承受并从错误条件中恢复的测试方法。使用故障注入特别有用，能确保故障恢复策略不至于不兼容或者太严格，这会导致关键服务不可用。 与其他错误注入机制不同，Istio 允许在应用层注入错误。 您可以注入两种故障，它们都使用虚拟服务配置： 延迟(Delays)：延迟是时间故障。它们模拟增加的网络延迟或一个超载的上游服务。 终止(Aborts)：终止是崩溃失败。他们模仿上游服务的失败。终止通常以 HTTP 错误码或 TCP 连接失败的形式出现。 例如，下面的虚拟服务为千分之一的访问 ratings 服务的请求配置了一个 5 秒的延迟： apiVersion:networking.istio.io/v1alpha3kind:VirtualServicemetadata:name:ratingsspec:hosts:- ratingshttp:- fault:delay:percentage:value:0.1fixedDelay:5sroute:- destination:host:ratingssubset:v1 和您的应用程序一起运行 Working with your applications Istio 故障恢复功能对应用程序来说是完全透明的。在返回响应之前，应用程序不知道 Envoy sidecar 代理是否正在处理被调用服务的故障。这意味着，如果在应用程序代码中设置了故障恢复策略，那么您需要记住这两个策略都是独立工作的，否则会发生冲突。 虽然 Istio 故障恢复特性提高了网格中服务的可靠性和可用性，但应用程序必须处理故障或错误并采取适当的回退操作。例如，当负载均衡中的所有实例都失败时，Envoy 返回一个HTTP 503代码。应用程序必须实现回退逻辑来处理HTTP 503错误代码。 ","date":"2021-02-18","objectID":"/istio/:2:7","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"安全 Security 将单一应用程序分解为微服务可提供各种好处，包括更好的灵活性、可伸缩性以及服务复用的能力。但是，微服务也有特殊的安全需求： 为了抵御中间人攻击，需要流量加密。 为了提供灵活的服务访问控制，需要双向 TLS 和细粒度的访问策略。 要确定谁在什么时候做了什么，需要审计工具。 Istio Security 尝试提供全面的安全解决方案来解决所有这些问题。 Istio 安全功能提供强大的身份，强大的策略，透明的 TLS 加密，认证，授权和审计（AAA）工具来保护你的服务和数据。Istio 安全的目标是： 默认安全：应用程序代码和基础设施无需更改 深度防御：与现有安全系统集成以提供多层防御 零信任网络：在不受信任的网络上构建安全解决方案 ","date":"2021-02-18","objectID":"/istio/:3:0","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"高级架构 High-level architecture Istio 中的安全性涉及多个组件： 用于密钥和证书管理的证书颁发机构（CA） 配置 API 服务器分发给代理： 认证策略 授权策略 安全命名信息 Sidecar 和边缘代理作为 Policy Enforcement Points(PEPs) 以保护客户端和服务器之间的通信安全 一组 Envoy 代理扩展，用于管理遥测和审计 控制面处理来自 API server 的配置，并且在数据面中配置 PEPs。PEPs 用 Envoy 实现。下图显示了架构。 ","date":"2021-02-18","objectID":"/istio/:3:1","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"Istio身份 Istio identity 身份是任何安全基础架构的基本概念。在工作负载间通信开始时，双方必须交换包含身份信息的凭证以进行双向验证。 在客户端，根据安全命名信息检查服务器的标识，以查看它是否是该服务的授权运行程序。在服务器端，服务器可以根据授权策略确定客户端可以访问哪些信息，审计谁在什么时间访问了什么，根据他们使用的工作负载向客户收费，并拒绝任何未能支付账单的客户访问工作负载。 Istio 身份模型使用 service identity （服务身份）来确定一个请求源端的身份。这种模型有极好的灵活性和粒度，可以用服务身份来标识人类用户、单个工作负载或一组工作负载。在没有服务身份的平台上，Istio 可以使用其它可以对服务实例进行分组的身份，例如服务名称。 下面的列表展示了在不同平台上可以使用的服务身份： Kubernetes: Kubernetes service account GKE/GCE: GCP service account GCP: GCP service account AWS: AWS IAM user/role account 本地（非 Kubernetes）：用户帐户、自定义服务帐户、服务名称、Istio 服务帐户或 GCP 服务帐户。自定义服务帐户引用现有服务帐户，就像客户的身份目录管理的身份一样。 ","date":"2021-02-18","objectID":"/istio/:3:2","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"公钥基础设施 Identity and certificate management Istio PKI 使用 X.509 证书为每个工作负载都提供强大的身份标识。可以大规模进行自动化密钥和证书轮换，伴随每个 Envoy 代理都运行着一个 istio-agent 负责证书和密钥的供应。 Istio 供应身份是通过 secret discovery service（SDS）来实现的，具体流程如下： CA 提供 gRPC 服务以接受证书签名请求（CSRs）。 Envoy 通过 Envoy 秘密发现服务（SDS）API 发送证书和密钥请求。 在收到 SDS 请求后，istio-agent 创建私钥和 CSR，然后将 CSR 及其凭据发送到 Istio CA 进行签名。 CA 验证 CSR 中携带的凭据并签署 CSR 以生成证书。 Istio-agent 通过 Envoy SDS API 将私钥和从 Istio CA 收到的证书发送给 Envoy。 上述 CSR 过程会周期性地重复，以处理证书和密钥轮换。 ","date":"2021-02-18","objectID":"/istio/:3:3","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"认证 Authentication Istio 提供两种类型的认证： Peer authentication：用于服务到服务的认证，以验证进行连接的客户端。 为每个服务提供强大的身份，表示其角色，以实现跨群集和云的互操作性。 保护服务到服务的通信。 提供密钥管理系统，以自动进行密钥和证书的生成，分发和轮换。 Request authentication：用于最终用户认证，以验证附加到请求的凭据。 ORY Hydra Keycloak Auth0 Firebase Auth Google Auth 在所有情况下，Istio 都通过自定义 Kubernetes API 将认证策略存储在 Istio config store。 双向TLS认证 Mutual TLS authentication Istio 通过客户端和服务器端 PEPs 建立服务到服务的通信通道，PEPs 被实现为Envoy 代理。 当一个工作负载使用双向 TLS 认证向另一个工作负载发送请求时，该请求的处理方式如下： Istio 将出站流量从客户端重新路由到客户端的本地 sidecar Envoy。 客户端 Envoy 与服务器端 Envoy 开始双向 TLS 握手。在握手期间，客户端 Envoy 还做了安全命名检查，以验证服务器证书中显示的服务帐户是否被授权运行目标服务。 客户端 Envoy 和服务器端 Envoy 建立了一个双向的 TLS 连接，Istio 将流量从客户端 Envoy 转发到服务器端 Envoy。 授权后，服务器端 Envoy 通过本地 TCP 连接将流量转发到服务器服务。 宽容模式 Permissive mode Istio 双向 TLS 具有一个宽容模式，允许服务同时接受纯文本流量和双向 TLS 流量。这个功能极大的提升了双向 TLS 的入门体验。 安全命名 Secure naming 服务器身份被编码在证书里，但服务名称通过服务发现或 DNS 被检索。安全命名信息将服务器身份映射到服务名称。身份 A 到服务名称 B 的映射表示“授权 A 运行服务 B“。控制平面监视 apiserver，生成安全命名映射，并将其安全地分发到 PEPs。 假设运行服务 datastore 的合法服务器仅使用 infra-team 身份。恶意用户拥有 test-team 身份的证书和密钥。恶意用户打算模拟服务以检查从客户端发送的数据。恶意用户使用证书和 test-team 身份的密钥部署伪造服务器。假设恶意用户成功攻击了发现服务或 DNS，以将 datastore 服务名称映射到伪造服务器。 当客户端调用 datastore 服务时，它从服务器的证书中提取 test-team 身份，并用安全命名信息检查 test-team 是否被允许运行 datastore。客户端检测到 test-team 不允许运行 datastore 服务，认证失败。 安全命名能够防止 HTTPS 流量受到一般性网络劫持，除了 DNS 欺骗外，它还可以保护 TCP 流量免受一般网络劫持。如果攻击者劫持了 DNS 并修改了目的地的 IP 地址，它将无法用于 TCP 通信。这是因为 TCP 流量不包含主机名信息，我们只能依靠 IP 地址进行路由，而且甚至在客户端 Envoy 收到流量之前，也可能发生 DNS 劫持。 认证架构 Authentication architecture 您可以使用 peer 和 request 认证策略为在 Istio 网格中接收请求的工作负载指定认证要求。一有任何的策略变更，新策略都会转换为适当的配置，告知 PEP 如何执行所需的认证机制。 Istio 异步发送配置到目标端点。代理收到配置后，新的认证要求会立即生效。 Istio 将两种类型的身份验证以及凭证中的其他声明（如果适用）输出到授权。 认证策略 Authentication policies 认证策略是对服务收到的请求生效的。 apiVersion:\"security.istio.io/v1beta1\"kind:\"PeerAuthentication\"metadata:name:\"example-peer-policy\"namespace:\"foo\"spec:selector:matchLabels:app:reviewsmtls:mode:STRICT 策略存储 Policy storage Istio 将网格范围的策略存储在根命名空间。这些策略使用一个空的 selector 适用于网格中的所有工作负载。具有名称空间范围的策略存储在相应的名称空间中。它们仅适用于其命名空间内的工作负载。如果你配置了 selector 字段，则认证策略仅适用于与您配置的条件匹配的工作负载。 kind字段的两个值，PeerAuthentication和RequestAuthentication。 Selector 使用 selector 字段来指定该策略适用的工作负载的标签 如果您没有为 selector 字段提供值，则 Istio 会将策略与策略存储范围内的所有工作负载进行匹配。 因此，selector 字段可帮助您指定策略的范围： 网格范围策略：为根名称空间指定的策略，不带或带有空的 selector 字段。 命名空间范围的策略：为非root命名空间指定的策略，不带有或带有空的 selector 字段。 特定于工作负载的策略：在常规名称空间中定义的策略，带有非空 selector 字段。 只能有一个网格范围的 Peer 认证策略，每个命名空间也只能有一个命名空间范围的 Peer 认证策略。当您为同一网格或命名空间配置多个网格范围或命名空间范围的 Peer 认证策略时，Istio 会忽略较新的策略。当多个特定于工作负载的 Peer 认证策略匹配时，Istio 将选择最旧的策略。 Istio 按照以下顺序为每个工作负载应用最窄的匹配策略： 特定于工作负载的 命名空间范围 网格范围 Istio 可以将所有匹配的 request 认证策略组合起来，就像它们来自单个 request 认证策略一样。因此，您可以在网格或名称空间中配置多个网格范围或命名空间范围的策略。但是，避免使用多个网格范围或命名空间范围的 request 认证策略仍然是一个好的实践。 Peer Peer 认证策略指定 Istio 对目标工作负载实施的双向 TLS 模式。支持以下模式： PERMISSIVE：工作负载接受双向 TLS 和纯文本流量。此模式在迁移因为没有 sidecar 而无法使用双向 TLS 的工作负载的过程中非常有用。一旦工作负载完成 sidecar 注入的迁移，应将模式切换为 STRICT。 STRICT： 工作负载仅接收双向 TLS 流量。 DISABLE：禁用双向 TLS。 从安全角度来看，除非您提供自己的安全解决方案，否则请勿使用此模式。 如果未设置模式，将继承父作用域的模式。未设置模式的网格范围的 peer 认证策略默认使用 PERMISSIVE 模式。 下面的 peer 认证策略要求命名空间 foo 中的所有工作负载都使用双向 TLS： apiVersion:\"security.istio.io/v1beta1\"kind:\"PeerAuthentication\"metadata:name:\"example-policy\"namespace:\"foo\"spec:mtls:mode:STRICT 禁用特定工作负载： apiVersion:\"security.istio.io/v1beta1\"kind:\"PeerAuthentication\"metadata:name:\"example-workload-policy\"namespace:\"foo\"spec:selector:matchLabels:app:example-appportLevelMtls:80:mode:DISABLE Requests Request 认证策略指定验证 JSON Web Token（JWT）所需的值。 这些值包括： token 在请求中的位置 请求的 issuer 公共 JSON Web Key Set（JWKS） Istio 会根据 request 认证策略中的规则检查提供的令牌（如果已提供），并拒绝令牌无效的请求。当请求不带有令牌时，默认情况下将接受它们。要拒绝没有令牌的请求，请提供授权规则，该规则指定对特定操作（例如，路径或操作）的限制。 Principals 使用 peer 认证策略和双向 TLS 时，Istio 将身份从 peer 认证提取到 source.principal 中。同样，当您使用 request 认证策略时，Istio 会将 JWT 中的身份赋值给 request.auth.principal。 更新认证策略 Updating authentication policies 您可以随时更改认证策略，Istio 几乎实时将新策略推送到工作负载。但是，Istio 无法保证所有工作负载都同时收到新政策。 以下建议有助于避免在更新认证策略时造成干扰： 将 peer 认证策略的模式从 DISABLE 更改为 STRICT 时，请使用 PERMISSIVE 模式来过渡，反之亦然。当所有工作负载成功切换到所需模式时，您可以将策略应用于最终模式。您可以使用 Istio 遥测技术来验证工作负载已成功切换。 将 request 认证策略从一个 JWT 迁移到另一个 JWT 时，将新 JWT 的规则添加到该策略中，而不删除旧规则。这样，工作负载接受两种类型的 JWT，当所有","date":"2021-02-18","objectID":"/istio/:3:4","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"授权 Authorization Istio 的授权功能为网格中的工作负载提供网格、命名空间和工作负载级别的访问控制。 这种控制层级提供了以下优点： 工作负载间和最终用户到工作负载的授权。 一个简单的 API：它包括一个单独的并且很容易使用和维护的 AuthorizationPolicy CRD 灵活的语义：运维人员可以在 Istio 属性上定义自定义条件，并使用 DENY 和 ALLOW 动作。 高性能：Istio 授权是在 Envoy 本地强制执行的。 高兼容性：原生支持 HTTP、HTTPS 和 HTTP2，以及任意普通 TCP 协议。 授权架构 Authorization architecture 每个 Envoy 代理都运行一个授权引擎，该引擎在运行时授权请求。当请求到达代理时，授权引擎根据当前授权策略评估请求上下文，并返回授权结果 ALLOW 或 DENY。 隐式启用 Implicit enablement 您无需显式启用 Istio 的授权功能。只需将授权策略应用于工作负载即可实施访问控制。对于未应用授权策略的工作负载，Istio 不会执行访问控制，放行所有请求。 授权策略支持 ALLOW 和 DENY 动作。 拒绝策略优先于允许策略。如果将任何允许策略应用于工作负载，则默认情况下将拒绝对该工作负载的访问，除非策略中的规则明确允许。当您将多个授权策略应用于相同的工作负载时，Istio 会累加地应用它们。 授权策略 Authorization policies 要配置授权策略，请创建一个 AuthorizationPolicy 自定义资源。 一个授权策略包括选择器（selector），动作（action） 和一个规则（rules）列表： selector 字段指定策略的目标 action 字段指定允许还是拒绝请求 rules 指定何时触发动作 from 字段指定请求的来源 to 字段指定请求的操作 when 字段指定应用规则所需的条件 栗子： apiVersion:security.istio.io/v1beta1kind:AuthorizationPolicymetadata:name:httpbinnamespace:foospec:selector:matchLabels:app:httpbinversion:v1action:ALLOWrules:- from:- source:principals:[\"cluster.local/ns/default/sa/sleep\"]- source:namespaces:[\"dev\"]to:- operation:methods:[\"GET\"]when:- key:request.auth.claims[iss]values:[\"https://accounts.google.com\"] 下例显示了一个授权策略，如果请求来源不是命名空间 foo，请求将被拒绝。 apiVersion:security.istio.io/v1beta1kind:AuthorizationPolicymetadata:name:httpbin-denynamespace:foospec:selector:matchLabels:app:httpbinversion:v1action:DENYrules:- from:- source:notNamespaces:[\"foo\"] 拒绝策略优先于允许策略。如果请求同时匹配上允许策略和拒绝策略，请求将被拒绝。Istio 首先评估拒绝策略，以确保允许策略不能绕过拒绝策略。 策略目标 Policy Target 您可以通过 metadata/namespace 字段和可选的 selector 字段来指定策略的范围或目标。根命名空间的值是可配置的，默认值为 istio-system。 栗子: apiVersion:security.istio.io/v1beta1kind:AuthorizationPolicymetadata:name:allow-readnamespace:defaultspec:selector:matchLabels:app:productsaction:ALLOWrules:- to:- operation:methods:[\"GET\",\"HEAD\"] 值匹配 Value matching 授权策略中的大多数字段都支持以下所有匹配模式： 完全匹配 前缀匹配 后缀匹配 存在匹配 有一些例外，例如，以下字段仅支持完全匹配： when 部分下的 key 字段 source 部分下 的 ipBlocks to 部分下的 ports 字段 以下示例策略允许访问前缀为 /test/* 或后缀为 */info 的路径。 apiVersion:security.istio.io/v1beta1kind:AuthorizationPolicymetadata:name:testernamespace:defaultspec:selector:matchLabels:app:productsaction:ALLOWrules:- to:- operation:paths:[\"/test/*\",\"*/info\"] 排除匹配 Exclusion matching Istio 支持排除匹配。 以下示例：如果请求路径不是 /healthz，则要求从请求的 JWT 认证中导出的主体是有效的。 因此，该策略从 JWT 身份验证中排除对 /healthz 路径的请求： apiVersion:security.istio.io/v1beta1kind:AuthorizationPolicymetadata:name:disable-jwt-for-healthznamespace:defaultspec:selector:matchLabels:app:productsaction:ALLOWrules:- to:- operation:notPaths:[\"/healthz\"]from:- source:requestPrincipals:[\"*\"] 下面的示例拒绝到 /admin 路径且不带请求主体的请求： apiVersion:security.istio.io/v1beta1kind:AuthorizationPolicymetadata:name:enable-jwt-for-adminnamespace:defaultspec:selector:matchLabels:app:productsaction:DENYrules:- to:- operation:paths:[\"/admin\"]from:- source:notRequestPrincipals:[\"*\"] 全部允许和默认全部拒绝授权策略 Allow-all and default deny-all authorization policies 以下示例显示了一个简单的 allow-all 授权策略，该策略允许完全访问 default 命名空间中的所有工作负载。 apiVersion:security.istio.io/v1beta1kind:AuthorizationPolicymetadata:name:allow-allnamespace:defaultspec:action:ALLOWrules:- {} 以下示例显示了一个策略，该策略不允许任何对 admin 命名空间工作负载的访问。 apiVersion:security.istio.io/v1beta1kind:AuthorizationPolicymetadata:name:deny-allnamespace:adminspec:{} 自定义条件 Custom conditions 您还可以使用 when 部分指定其他条件。 apiVersion:security.istio.io/v1beta1kind:AuthorizationPolicymetadata:name:httpbinnamespace:foospec:selector:matchLabels:app:httpbinversion:v1action:ALLOWrules:- from:- source:principals:[\"cluster.local/ns/default/sa/sleep\"]to:- operation:methods:[\"GET\"]when:- key:request.headers[version]values:[\"v1\",\"v2\"] 认证与未认证身份 Authenticated and unauthenticated identity 如果要使工作负载可公开访问，则需要将 source 部分留空。这允许来自所有（经过认证和未经认证）的用户和工作负载的源。 apiVersion:security.istio.io/v1beta1kind:AuthorizationPolicymetadata:name:httpbinnamespace:foospec:selector:matchLabels:app:httpbinversion:v1action:ALLOWrules:- to:- operation:methods:[\"GET\",\"POST\"] 要仅允许经过认证的用户，请将 principal 设置为 *。 apiVersion:security.istio.io/v1beta1kind:AuthorizationPolicymetadata:na","date":"2021-02-18","objectID":"/istio/:3:5","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"可观察性 Observability Istio 为网格内所有的服务通信生成详细的遥测数据。这种遥测技术提供了服务行为的可观察性。通过 Istio，运维人员可以全面了解到受监控的服务如何与其他服务以及 Istio 组件进行交互。 Istio 生成以下类型的遥测数据，以提供对整个服务网格的可观察性： 指标(Metrics)。Istio 基于 4 个监控的黄金标识（延迟、流量、错误、饱和）生成了一系列服务指标。 分布式追踪(Distributed Traces)。Istio 为每个服务生成分布式追踪 span，运维人员可以理解网格内服务的依赖和调用流程。 访问日志(Access Logs)。当流量流入网格中的服务时，Istio 可以生成每个请求的完整记录，包括源和目标的元数据。 ","date":"2021-02-18","objectID":"/istio/:4:0","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"指标 Metrics Istio 为服务网格中所有出入的服务流量都生成了指标。除了监控网格中服务的行为外，监控网格本身的行为也很重要。Istio 组件可以导出自身内部行为的指标，以提供对网格控制平面的功能和健康情况的洞察能力。 代理级别指标 Proxy-level metrics Istio 指标收集从 sidecar 代理（Envoy）开始。每个代理为通过它的所有流量（入站和出站）生成一组丰富的指标。代理还提供关于它本身管理功能的详细统计信息，包括配置信息和健康信息。 服务级别指标 Service-level metrics Istio 还提供了一组用于监控服务通信的面向服务的指标。这些指标涵盖了四个基本的服务监控需求：延迟、流量、错误和饱和情况。Istio 带有一组默认的仪表板，用于监控基于这些指标的服务行为。 默认的 Istio 指标由 Istio 提供的配置集定义并默认导出到 Prometheus。 控制平面指标 Control plane metrics 每一个 Istio 的组件（Pilot、Galley、Mixer）都提供了对自身监控指标的集合。更多详情请参考各个组件的文档。 ","date":"2021-02-18","objectID":"/istio/:4:1","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"分布式追踪 Distributed traces 分布式追踪通过监控流经网格的单个请求，提供了一种监控和理解行为的方法。追踪使网格的运维人员能够理解服务的依赖关系以及在服务网格中的延迟源。 Istio 支持通过 Envoy 代理进行分布式追踪。代理自动为其应用程序生成追踪 span，只需要应用程序转发适当的请求上下文即可。 Istio 支持很多追踪系统，包括 Zipkin、Jaeger、LightStep、Datadog。 Istio 为一个请求生成的分布式追踪数据： ","date":"2021-02-18","objectID":"/istio/:4:2","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"访问日志 Access logs 访问日志提供了一种从单个工作负载实例的角度监控和理解行为的方法。 Istio 可以以一组可配置的格式集生成服务流量的访问日志。访问日志可以在本地生成，或者导出到自定义的后端基础设施。 ","date":"2021-02-18","objectID":"/istio/:4:3","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"扩展性 Extensibility WebAssembly 是一种沙盒技术，可以用于扩展 Istio 代理（Envoy）的能力。Proxy-Wasm 沙盒 API 取代了 Mixer 作为 Istio 主要的扩展机制。 WebAssembly 沙盒的目标： 效率(Efficiency) - 这是一种低延迟，低 CPU 和内存开销的扩展机制。 功能(Function) - 这是一种可以执行策略，收集遥测数据和执行有效荷载变更的扩展机制。 隔离(Isolation) - 一个插件中程序的错误或是崩溃不会影响其它插件。 配置(Configuration) - 插件使用与其它 Istio API 一致的 API 进行配置。可以动态的配置扩展。 运维(Operator) - 扩展可以以仅日志，故障打开或者故障关闭的方式进行访问和部署。 扩展开发者(Extension developer) - 可以用多种编程语言编写。 ","date":"2021-02-18","objectID":"/istio/:5:0","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"高级架构 Istio 扩展（Proxy-Wasm 插件）有几个组成部分： 过滤器服务提供商接口(Filter Service Provider Interface (SPI))， 用于为过滤器构建 Proxy-Wasm 插件。 沙盒 在 Envoy 中嵌入 V8 Wasm 运行时。 主机 API 用于处理请求头，尾和元数据。 调出 API 针对 gRPC 和 HTTP 请求。 统计和记录 API 用于度量统计和监控。 ","date":"2021-02-18","objectID":"/istio/:5:1","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"术语表 Glossary ADAPTERS 适配器（adapter）是 Istio 策略和遥测组件 Mixer 的插件, 可使其与一组开放式基础架构后端交互，这些后端可提供核心功能，例如日志记录、监控、配额、ACL 检查等等。运行时所使用的精确的适配器集合是通过配置确定的，并可以针对新的或定制的基础架构后端轻松扩展。 ANNOTATION 注释是指附加到 Kubernetes annotation 的资源。 ATTRIBUTE 属性控制着网格中服务运行时的行为，是一堆有名字的、有类型的元数据，它们描述了 ingress 和 egress 流量，以及这些流量所在的环境。 CLUSTER 集群是运行容器化应用程序的一组计算节点。 CONTROL PLANE 控制平面是一组系统服务，这些服务配置网格或者网格的子网来管理工作负载实例之间的通信。 CRDS 自定义资源定义 (CRD) 是默认的 Kubernetes API 扩展。 DATA PLANE 数据平面是网格的一部分，直接控制工作负载实例之间的通信。Istio 的数据平面使用智能 Envoy 代理部署成 sidecar 去调节和控制服务网格中发送和接受的流量。 DESTINATION 目标服务 (destination) 是 envoy 代表一个源服务 工作负载与之打交道的远程上游服务。这些上游服务可以有多个服务版本，envoy 根据路由选择对应的版本。 ENVOY Envoy 是在 Istio 里使用的高性能代理，用于为所有服务网格里的服务调度进出的流量。 FAILURE DOMAIN 故障域是计算环境中物理或者逻辑的一部分，当关键设备或服务遇到问题时，它也会受到负面影响。对于 Istio 部署而言，故障域可能包含平台中的多个可用性区域。 IDENTITY 身份是基本的安全基础结构概念。Istio 的身份模型是基于第一阶级的工作负载身份。在服务之间的通信开始时，双方使用身份信息交换证书来实现相互认证的目的。 客户端根据其安全的命名信息检查服务器的身份，以便确定服务器是否被授权运行服务。 服务器检查客户端的身份，以确定客户端可以访问的信息。服务器基于客户端的身份，来确定配置的策略。 通过使用身份，服务器可以审核访问信息的时间和特定客户端访问的信息内容。还可以根据客户使用的服务向他们收费，并拒绝任何未付款的客户访问服务。 ISTIOD istiod组件是控制平面二进制，它封装了Pilot, Citadel, Mixer, Galley。 MANAGED CONTROL PLANE 托管控制平面是一个为客户提供管理的控制平面。 托管控制平面降低了用户部署的复杂性，并通常保证一定水平的性能和可用性。 MESH FEDERATION 网格联邦是在网格之间公开服务的一种行为，并且能跨越网格边界进行通信。每一个网格或许会公开其一部分的服务，使一个或多个其他网格使用此公开的服务。 您可以使用网格联邦来启用网格之间的通信。 MICRO-SEGMENTATION 一种安全技术，可在云部署中创建安全区域，使组织能够将工作负载彼此隔离，并分别保证它们的安全。 MIXER Mixer 是 Istio 里的一个组件，它负责增强服务网格里的访问控制和使用策略。它还负责收集来自 envoy 和其他服务的遥测数据。 MIXER HANDLER Handler 相当于配置完备的 Mixer 适配器。在 Mixer 运行时，Mixer 将 instances 路由到一个或多个 handlers。 MIXER INSTANCE Mixer Instance 表示通过检查一组请求属性 ，并结合使用者提供的配置而生成的数据块。Mixer Instance 在随请求到达各种基础后端设施的途中，会被传递给各个处理程序。 MULTI-MESH 多个服务网格组成的部署模型。每个网格都有独立的命名管理和身份管理，但是您可以通过网格联邦来暴露 网格之间的服务, 最终构成一个多网格部署。 MULTI-CLUSTER 多个集群的网格组成 MUTUAL TLS AUTHENTICATION 双向 TLS 通过内置身份和凭证管理，提供强大的服务到服务身份验证。 OPERATOR 打包，部署和管理k8s应用程序的一种方法。 PILOT Pilot 是 Istio 里的一个组件，它控制 Envoy 代理，负责服务发现、负载均衡和路由分发。 PRIMARY CLUSTER 主集群是具有控制平面 的集群。 一个网格可以有一个以上的主集群，以用于 HA 或需要低延迟的场景。 主集群可以充当从集群的控制平面。 ROUTING RULES 您在虚拟服务中配置的路由规则，遵循服务网格定义了请求的路径。使用路由规则，您可以定义将寻址到虚拟服务主机的流量路由到指定目标的工作负载。 路由规则使您可以控制流量，以实现如 A/B 测试、金丝雀发布以及按百分比分配流量的分阶段发布等任务。 SECURE NAMING 提供一个 service name 到 workload instance principals 的映射，这个工作负载实例被授权运行一个 workload instances，实现一个 service。 SERVICE 使用服务名称标识一组具有关联行为的服务服务网格， 并使用这些名称应用 Istio 策略。 SERVICE CONSUMER 服务消费者是使用 service 的代理。 SERVICE ENDPOINT 一个 service 的网络可达表现形式。 SERVICE MESH 服务网格 （简称 网格 ）是一个可管理、可观测以及支持工作负载实例之间进行安全通信的基础设施层。 SERVICE OPERATOR 是在 service mesh 里管理 service 的代理，它们通过操纵配置状态并通过各种仪表板监视服务的运行状况来管理这些服务。 SERVICE PRODUCER 创建服务的 pilot-agent。 SERVICE REGISTRY Istio 维护了一个内部服务注册表 (service registry)，它包含在服务网格中运行的一组服务及其相应的服务 endpoints。Istio 使用服务注册表生成 Envoy 配置。 Istio 不提供服务发现，尽管大多数服务都是通过 Pilot adapter 自动加入到服务注册表里的，而且这反映了底层平台（Kubernetes、Consul、plain DNS）的已发现的服务。还有就是，可以使用 ServiceEntry 配置手动进行注册。 SERVICE VERSION 区分一系列服务，通常通过工作负载二进制文件的不同版本来帮助确定。在一些场景多服务版本是需要的，比如 A/B 测试和金丝雀发布。 SOURCE Source 是 Envoy 代理的下游客户端。 TLS ORIGINATION TLS源发生于一个被配置为接收内部未加密 HTTP 连接的 Istio 代理（sidecar 或 egress gateway）加密请求并使用简单或双向 TLS 将其转发至安全的 HTTPS 服务器时。这与 TLS 终止相反，后者发生于一个接受 TLS 连接的 ingress 代理解密 TLS 并将未加密的请求传递到网格内部的服务时。 TRUST DOMAIN 信任域对应于系统的信任根，并且是工作负载标识的一部分。 Istio 使用信任域在网格中创建所有身份。每个网格都有一个专用的信任域。 WORKLOAD WORKLOAD INSTANCE WORKLOAD INSTANCE PRINCIPAL 工作负载实例主体是工作负载实例的可验证权限。Istio 的服务到服务身份验证用于生成工作负载实例主体。 安装 Setup ","date":"2021-02-18","objectID":"/istio/:6:0","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"入门 Getting Started 本指南帮你快速评估 Istio。你需要有一个k8s集群。 按照以下步骤开始使用Istio: 下载并安装Istio 部署示例应用 对外开放应用 查看仪表盘 ","date":"2021-02-18","objectID":"/istio/:7:0","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"下载Istio 在github istio: https://github.com/istio/istio/releases 上下载对应发行版压缩包并解压。 ","date":"2021-02-18","objectID":"/istio/:7:1","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"安装Istio 对于本次安装，我们采用 demo 配置组合。 选择它是因为它包含了一组专为测试准备的功能集合，另外还有用于生产或性能测试的配置组合。 istioctl install --set profile=demo -y # 给命名空间添加标签，指示 Istio 在部署应用的时候，自动的注入 Envoy sidecar kubectl label namespace default istio-injection=enabled ","date":"2021-02-18","objectID":"/istio/:7:2","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"部署示例应用 kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml kubectl get services kubectl get pods kubectl exec \"$(kubectl get pod -l app=ratings -o jsonpath='{.items[0].metadata.name}')\" -c ratings -- curl -s productpage:9080/productpage | grep -o \"\u003ctitle\u003e.*\u003c/title\u003e\" ","date":"2021-02-18","objectID":"/istio/:7:3","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"开放外部访问 此时，BookInfo 应用已经部署，但还不能被外界访问。 要开放访问，你需要创建 Istio 入站网关（Ingress Gateway）, 它会在网格边缘把一个路径映射到路由。 kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml istioctl analyze # bookinfo-gateway.yamlapiVersion:networking.istio.io/v1alpha3kind:Gatewaymetadata:name:bookinfo-gatewayspec:selector:istio:ingressgateway# use istio default controllerservers:- port:number:80name:httpprotocol:HTTPhosts:- \"*\"---apiVersion:networking.istio.io/v1alpha3kind:VirtualServicemetadata:name:bookinfospec:hosts:- \"*\"gateways:- bookinfo-gatewayhttp:- match:- uri:exact:/productpage- uri:prefix:/static- uri:exact:/login- uri:exact:/logout- uri:prefix:/api/v1/productsroute:- destination:host:productpageport:number:9080 关于上面的ingressgateway，可访问nodeport地址，来验证应用的外部访问。 访问nodeport地址/productpage，查看效果。 ","date":"2021-02-18","objectID":"/istio/:7:4","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"查看仪表板 View the dashboard Istio 和几个遥测应用做了集成。 遥测能帮你了解服务网格的结构、展示网络的拓扑结构、分析网格的健康状态。 使用下面说明部署 Kiali 仪表板、 以及 Prometheus、 Grafana、 还有 Jaeger。 kubectl apply -f samples/addons kubectl rollout status deployment/kiali -n istio-system # 或者给这个svc创建一个外部访问内 istioctl dashboard kiali bookinfo的请求示例图 要在 Istio 中运行这一应用，无需对应用自身做出任何改变。 您只要简单的在 Istio 环境中对服务进行配置和运行，具体一点说就是把 Envoy sidecar 注入到每个服务之中。 所有的微服务都和 Envoy sidecar 集成在一起，被集成服务所有的出入流量都被 sidecar 所劫持，这样就为外部控制准备了所需的 Hook，然后就可以利用 Istio 控制平面为应用提供服务路由、遥测数据收集以及策略实施等功能。 任务 Tasks ","date":"2021-02-18","objectID":"/istio/:7:5","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"流量管理 Traffic Management 演示 Istio 的流量路由功能的任务。 ","date":"2021-02-18","objectID":"/istio/:8:0","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"请求路由 Request Routing 将请求动态路由到微服务的多个版本。 开始之前 安装Istio。安装Bookinfo示例应用。 关于 Isito Bookinfo示例包含四个独立的微服务，每个微服务有多个版本。 此任务的最初目标是应用将所有流量路由到微服务的v1的规则。稍后，您将应用规则根据 HTTP 请求 header 的值路由流量。 应用虚拟服务 Apply a virtual service 要仅路由到一个版本，请应用为微服务设置默认版本的 virtual service。在这种情况下，virtual service 将所有流量路由到每个微服务的 v1 版本。 如果您还没有应用 destination rule，请先应用默认目标规则 # 没有启用双向 TLS kubectl apply -f samples/bookinfo/networking/destination-rule-all.yaml kubectl get destinationrules # virtual-service-all-v1.yamlapiVersion:networking.istio.io/v1alpha3kind:VirtualServicemetadata:name:productpagespec:hosts:- productpagehttp:- route:- destination:host:productpagesubset:v1---apiVersion:networking.istio.io/v1alpha3kind:VirtualServicemetadata:name:reviewsspec:hosts:- reviewshttp:- route:- destination:host:reviewssubset:v1---apiVersion:networking.istio.io/v1alpha3kind:VirtualServicemetadata:name:ratingsspec:hosts:- ratingshttp:- route:- destination:host:ratingssubset:v1---apiVersion:networking.istio.io/v1alpha3kind:VirtualServicemetadata:name:detailsspec:hosts:- detailshttp:- route:- destination:host:detailssubset:v1--- kubectl apply -f samples/bookinfo/networking/virtual-service-all-v1.yaml kubectl get virtualservices -o yaml kubectl get destinationrules -o yaml 您已将 Istio 配置为路由到 Bookinfo 微服务的 v1 版本，最重要的是 reviews 服务的版本 1。 测试路由 Test the new routing configuration 您可以通过再次刷新 Bookinfo 应用程序的 /productpage 轻松测试新配置。它将把所有流量路由到版本1。 基于用户身份的路由 Route based on user identity 接下来，您将更改路由配置，以便将来自特定用户的所有流量路由到特定服务版本。在这，来自名为 Jason 的用户的所有流量将被路由到服务 reviews:v2。 请注意，Istio 对用户身份没有任何特殊的内置机制。事实上，productpage 服务在所有到 reviews 服务的 HTTP 请求中都增加了一个自定义的 end-user 请求头，从而达到了本例子的效果。 # virtual-service-reviews-test-v2.yamlapiVersion:networking.istio.io/v1alpha3kind:VirtualServicemetadata:name:reviewsspec:hosts:- reviewshttp:- match:- headers:end-user:exact:jasonroute:- destination:host:reviewssubset:v2- route:- destination:host:reviewssubset:v1 kubectl apply -f samples/bookinfo/networking/virtual-service-reviews-test-v2.yaml kubectl get virtualservice reviews -o yaml 现在访问/productpage，并以jason用户登录。你将看到不通的版本。以其他用户登录，刷新后，看看是不是又不一样了。 您已成功配置 Istio 以根据用户身份路由流量。 理解原理 Understanding what happened 在此任务中，您首先使用 Istio 将 100% 的请求流量都路由到了 Bookinfo 服务的 v1 版本。 然后设置了一条路由规则，它根据 productpage 服务发起的请求中的 end-user 自定义请求头内容，选择性地将特定的流量路由到了 reviews 服务的 v2 版本。 ","date":"2021-02-18","objectID":"/istio/:8:1","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"故障注入 Fault Injection 如何注入故障并测试应用程序的弹性。 开始之前 在前面的请求路由中，配置了如下请求流程： productpage → reviews:v2 → ratings (针对 jason 用户) productpage → reviews:v1 (其他用户) 注入http延迟故障 Injecting an HTTP delay fault 为了测试微服务应用程序 Bookinfo 的弹性，我们将为用户 jason 在 reviews v2 和 ratings 服务之间注入一个 7 秒的延迟。 这个测试将会发现一个故意引入 Bookinfo 应用程序中的 bug。 注意 reviews v2 服务对 ratings 服务的调用具有 10 秒的硬编码连接超时。 因此，尽管引入了7秒的延迟，我们仍然期望端到端的流程是没有任何错误的。 # 创建故障注入规则以延迟来自测试用户 jason 的流量 kubectl apply -f samples/bookinfo/networking/virtual-service-ratings-test-delay.yaml kubectl get virtualservice ratings -o yaml # virtual-service-ratings-test-delay.yamlapiVersion:networking.istio.io/v1alpha3kind:VirtualServicemetadata:name:ratingsspec:hosts:- ratingshttp:- match:- headers:end-user:exact:jasonfault:delay:percentage:value:100.0fixedDelay:7sroute:- destination:host:ratingssubset:v1- route:- destination:host:ratingssubset:v1 测试延迟 Testing the delay configuration 使用jason用户访问 /productpage页面。你期望 Bookinfo 主页在大约 7 秒钟加载完成并且没有错误。 但是，出现了一个问题：Reviews 部分显示了错误消息： Error fetching product reviews! Sorry, product reviews are currently unavailable for this book. 打开浏览器开发工具、网络，重新加载productpage页面，会看到页面加载实际上用了大约 6s(x-envoy-upstream-service-time: 6031)。 理解原理 Understanding what happened 你发现了一个 bug。微服务中有硬编码超时，导致 reviews 服务失败。 按照预期，我们引入的 7 秒延迟不会影响到 reviews 服务，因为 reviews 和 ratings 服务间的超时被硬编码为 10 秒。但是，在 productpage 和 reviews 服务之间也有一个 3 秒的硬编码的超时，再加 1 次重试，一共 6 秒。 结果，productpage 对 reviews 的调用在 6 秒后提前超时并抛出错误了。 这种类型的错误可能发生在典型的由不同的团队独立开发不同的微服务的企业应用程序中。 Istio 的故障注入规则可以帮助您识别此类异常，而不会影响最终用户。 请注意，此次故障注入限制为仅影响用户 jason。如果您以任何其他用户身份登录，则不会遇到任何延迟。 错误修复 Fixing the bug 这种问题通常会这么解决： 增加 productpage 与 reviews 服务之间的超时或降低 reviews 与 ratings 的超时 终止并重启修复后的微服务 确认 productpage 页面正常响应且没有任何错误 但是，reviews 服务的 v3 版本已经修复了这个问题。 reviews v3 服务已将 reviews 与 ratings 的超时时间从 10 秒降低为 2.5 秒，因此它可以兼容（小于）下游的 productpage 的请求。 如果您按照流量转移任务所述将所有流量转移到 reviews v3， 您可以尝试修改延迟规则为任何低于 2.5 秒的数值，例如 2 秒，然后确认端到端的流程没有任何错误。 注入HTTP中止 Injecting an HTTP abort fault 测试微服务弹性的另一种方法是引入 HTTP abort 故障。 这个任务将给 ratings 微服务为测试用户 jason 引入一个 HTTP abort。 在这种情况下，我们希望页面能够立即加载，同时显示 Ratings service is currently unavailable 这样的消息。 # 为用户 jason 创建一个发送 HTTP abort 的故障注入规则 kubectl apply -f samples/bookinfo/networking/virtual-service-ratings-test-abort.yaml kubectl get virtualservice ratings -o yaml # virtual-service-ratings-test-abort.yamlapiVersion:networking.istio.io/v1alpha3kind:VirtualServicemetadata:name:ratingsspec:hosts:- ratingshttp:- match:- headers:end-user:exact:jasonfault:abort:percentage:value:100.0httpStatus:500route:- destination:host:ratingssubset:v1- route:- destination:host:ratingssubset:v1 测试http中止 Testing the abort configuration 使用jason用户登录到productpage页面。 如果规则成功传播到所有的 pod，您应该能立即看到页面加载并看到 Ratings service is currently unavailable 消息。 如果您注销用户 jason 或在匿名窗口（或其他浏览器）中打开 Bookinfo 应用程序， 您将看到 productpage 为除 jason 以外的其他用户调用了 reviews v1（完全不调用 ratings）。 因此，您不会看到任何错误消息。 ","date":"2021-02-18","objectID":"/istio/:8:2","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"流量转移 Traffic Shifting 本任务将向您展示如何逐步将流量从一个版本的微服务迁移到另一个版本。例如，您可以将流量从旧版本迁移到新版本。 一个常见的用例是将流量从一个版本的微服务逐渐迁移到另一个版本。在 Istio 中，您可以通过配置一系列规则来实现此目标， 这些规则将一定百分比的流量路由到一个或另一个服务。 在本任务中，您将会把 50％ 的流量发送到 reviews v1，另外 50％ 的流量发送到 reviews v3。然后，再把 100％ 的流量发送到 reviews v3 来完成迁移。 基于权重的路由 Apply weight-based routing # 将所有流量路由到各个微服务的 v1 版本kubectl apply -f samples/bookinfo/networking/virtual-service-all-v1.yaml# 把 50% 的流量从 reviews v1 转移到 reviews v3kubectl apply -f samples/bookinfo/networking/virtual-service-reviews-50-v3.yamlkubectl get virtualservice reviews -o yaml # virtual-service-reviews-50-v3.yamlapiVersion:networking.istio.io/v1alpha3kind:VirtualServicemetadata:name:reviewsspec:hosts:- reviewshttp:- route:- destination:host:reviewssubset:v1weight:50- destination:host:reviewssubset:v3weight:50 刷新浏览器的productpage页面，大约有 50% 的几率会看到页面中出带 红色 星级的评价内容。这是因为 v3 版本的 reviews 访问了带星级评级的 ratings 服务，但 v1 版本却没有。 # 如果您认为 reviews v3 微服务已经稳定，你可以通过应用此 virtual service 规则将 100% 的流量路由到 reviews v3 kubectl apply -f samples/bookinfo/networking/virtual-service-reviews-v3.yaml 现在，当您刷新 productpage 时，您将始终看到带有 红色 星级评分的书评。 理解原理 在这项任务中，我们使用 Istio 的权重路由功能将流量从旧版本的 reviews 服务迁移到新版本。 请注意，这和使用容器编排平台的部署功能来进行版本迁移完全不同，后者使用了实例扩容来对流量进行管理。 使用 Istio，两个版本的 reviews 服务可以独立地进行扩容和缩容，而不会影响这两个服务版本之间的流量分发。 ","date":"2021-02-18","objectID":"/istio/:8:3","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["cncf"],"content":"TCP流量转移 TCP Traffic Shifting 本任务展示了如何逐步将 TCP 流量从微服务的一个版本迁移到另一个版本。例如，将 TCP 流量从旧版本迁移到新版本。 ","date":"2021-02-18","objectID":"/istio/:8:4","tags":["K8s","ServiceMesh","Microservice","微服务","服务网格"],"title":"Istio","uri":"/istio/"},{"categories":["devops"],"content":"参考: Flagger github: https://github.com/fluxcd/flagger Flagger docs: https://docs.flagger.app/ 介绍 Introduction Flagger是一个渐进式交付的k8s operator，可使用Istio, Linkerd, App Mesh, Nginx, Sgipper, Contour, Gloo, Traefik路由流量漂移(traffic shifting)，自动化进行金丝雀部署，Prometheus指标用于金丝雀分析。金丝雀分析可通过webhook扩展，用于运行系统集成/测试验收、负载测试，或其它自定义验证。 Flagger实现了一个控制循环(control loop)，逐渐向金丝雀转移流量，同时测量如HTTP请求成功率、请求平均持续时间、pod健康度等关键性能指标。基于对KPIs的分析，提升(promoted)或中止(aborted)金丝雀，分析结果发布到Slack等其它软件。 Flagger架构图： Flagger可以k8s CRD进行配置，并与任何用于k8s ci/cd 方案兼容。由于Flagger是声明性的，并对k8s events做出反应，它可与Flux CD或JenkinsX一起用于GitOps管道中。 Flagger是一个CNCF项目。 快速开始 Getting started 要开始使用Flagger，请选择一个受支持的路由提供商，并安装它(Helm/Kustmoze)。 安装Flagger之后，可从以下指导手册开始： Service mesh Istio Linkerd aws app mesh Ingress controller Contour Gloo Nginx ingress skipper ingress Traefik Hand-on Gitops Istio Linkerd aws app mesh 安装 Install ","date":"2021-01-14","objectID":"/flagger/:0:0","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"k8s Flagger Install on Kubernetes ","date":"2021-01-14","objectID":"/flagger/:1:0","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"先决条件 Prerequisites k8s v1.16+ ","date":"2021-01-14","objectID":"/flagger/:1:1","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"Helm安装Flagger Install Flagger with Helm 你可在任意namespace安装Flagger，只要它能够访问Prometheus。 # 添加helm 仓库 helm repo add flagger https://flagger.app # 安装Flagger Canary CRD kubectl apply -f https://raw.githubusercontent.com/fluxcd/flagger/main/artifacts/flagger/crd.yaml # Deploy Flagger for Istio # Flagger依赖Istio telemetry和Prometheus helm upgrade -i flagger flagger/flagger \\ --namespace=istio-system \\ --set crd.create=false \\ --set meshProvider=istio \\ --set metricsServer=http://prometheus:9090 对于Istio多集群共享控制面板，你可在每个远程集群上安装Flagger，并设置Istio控制面板host cluster kubeconfig: helm upgrade -i flagger flagger/flagger \\ --namespace=istio-system \\ --set crd.create=false \\ --set meshProvider=istio \\ --set metricsServer=http://istio-cluster-prometheus:9090 \\ --set istio.kubeconfig.secretName=istio-kubeconfig \\ --set istio.kubeconfig.key=kubeconfig 注意，Istio kubeconfig必须存储为k8s secret，其数据键名称为kubeconfig。关于如果配置Istio multi-cluster credential的详细信息，请参考Istio文档: https://istio.io/docs/setup/install/multicluster/shared-vpn/#credentials # Deploy Flagger for Linkerd helm upgrade -i flagger flagger/flagger \\ --namespace=linkerd \\ --set crd.create=false \\ --set meshProvider=linkerd \\ --set metricsServer=http://linkerd-prometheus:9090 # Deploy Flagger for App Mesh helm upgrade -i flagger flagger/flagger \\ --namespace=appmesh-system \\ --set crd.create=false \\ --set meshProvider=appmesh \\ --set metricsServer=http://appmesh-prometheus:9090 对于ingress controlles，安装指南如下： Contour Gloo Nginx Skipper Traefik ","date":"2021-01-14","objectID":"/flagger/:1:2","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"Helm安装Grafana Install Grafana with Helm Flagger使用Grafana来监测金丝雀分析。 # Deploy Grafana in the istio-system namespace helm upgrade -i flagger-grafana flagger/grafana \\ --namespace=istio-system \\ --set url=http://prometheus.istio-system:9090 \\ --set user=admin \\ --set password=change-me # 使用端口转发访问Grafana kubectl -n istio-system port-forward svc/flagger-grafana 3000:80 ","date":"2021-01-14","objectID":"/flagger/:1:3","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"Kustomize安装Flagger ","date":"2021-01-14","objectID":"/flagger/:1:4","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"gke istio ","date":"2021-01-14","objectID":"/flagger/:2:0","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"eks app mesh 使用 Usage ","date":"2021-01-14","objectID":"/flagger/:3:0","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"它如何工作 How it works Flagger可以配置使用名为canary的自定义资源来自动化k8s工作负载发布过程。 ","date":"2021-01-14","objectID":"/flagger/:4:0","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"Canary resource canary CRD定义了运行在k8s上的程序的发布过程，它是跨集群、服务网格、Ingress提供商可移植。 对一个名为podinfo的deployment，具有渐进式流量迁移的金丝雀发布(canary release)如下所定义。 apiVersion:flagger.app/v1beta1kind:Canarymetadata:name:podinfospec:targetRef:apiVersion:apps/v1kind:Deploymentname:podinfoservice:port:9898analysis:interval:1mthreshold:10maxWeight:50stepWeight:5metrics:- name:request-success-ratethresholdRange:min:99interval:1m- name:request-durationthresholdRange:max:500interval:1mwebhooks:- name:load-testurl:http://flagger-loadtester.test/metadata:cmd:\"hey -z 1m -q 10 -c 2 http://podinfo-canary.test:9898/\" 当部署一个应用的新版本时，Flagger逐渐地向金丝雀(canary)转移流量，同时测量请求成功率以及响应持续时间。你可以使用自定义指标扩展金丝雀分析，接受和负载测试来硬化应用发布过程的验证过程。 如果你在同一个集群内运行了多个服务网格(service mesh)或ingress controller，则可以使用spec.provider配置金丝雀来覆盖全局配置。 ","date":"2021-01-14","objectID":"/flagger/:4:1","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"Canary target 一个金丝雀资源可以目标到一个k8s deployment或daemonset。 k8s deployment示例: spec:progressDeadlineSeconds:60targetRef:apiVersion:apps/v1kind:Deploymentname:podinfoautoscalerRef:apiVersion:autoscaling/v2beta2kind:HorizontalPodAutoscalername:podinfo 根据上述配置，Flagger生成如下k8s对象: deployment/\u003ctargetRef.name\u003e-primary hpa/\u003cautoscalerRef.name\u003e-primary primary deployment被视为应用稳定版本，默认情况下所有流量都路由到此版本，并且target deployment将缩放为0。Flagger会检测targer deployment（包括secrets和configmaps）的更改，并在新版本替换为主版本(primary)之前执行金丝雀分析。 注意，target deployment必须具有这种格式的单个标签(single label): app: \u003cdeployment-name\u003e apiVersion:apps/v1kind:Deploymentmetadata:name:podinfospec:selector:matchLabels:app:podinfotemplate:metadata:labels:app:podinfo 除了app，Flagger支持name和app.kubernetes.io/name选择器(selector)。如果使用不同的惯例，你可以在Flagger deployment的容器参数下指定-selector-labels=my-app-label命令行标志，或在使用Helm安装Flagger时设置--set selectorLabels=my-app-label，来指定特定的标签。 如果target deployment使用了secrets或configmaps，Flagger将使用--primary后缀创建每个对象的副本，并将在primary deployment中引用这些对象。如果在configmap, secret中注释了flagger.app/config-tracking: disabled，Flagger将为primary deployment使用相同的对象，而不是做一个primary的副本。可在Flagger deployment的容器参数中使用-enable-config-tracking=false命令行标志，或在使用Helm安装Flagger时设置--set configTracking.enabled=false来全局禁用secrets/configmaps tracking。不过不建议全局禁用，建议使用注释(annotation)。 自动伸缩(autoscaler)引用是可选的，当指定时，在target和primary deployment在伸缩时，Flagger将暂停流量增加(traffic increase)。HPA可以帮助减少金丝雀分析期间的资源使用情况。 进度截止时间表示canary deployment在回滚之前进行的最大时间，默认为十分钟。 ","date":"2021-01-14","objectID":"/flagger/:4:2","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"Canary service 金丝雀资源决定了如何在集群内公开工作负载。金丝雀目标应该公开一个TCP端口，由Flagger去创建一个ClusterIP服务。 spec:service:name:podinfoport:9898portName:httptargetPort:9898portDiscovery:true 如果工作负载使用gRPC（默认是http），则portName应设置为grpc。 如果启用了端口发现(port discovery)，Flagger扫描目标工作负载并提取排除了canary service和service mesh sidecar端口的容器端口。生成CluterIP服务时会使用这些端口。 基于canary spec service，Flagger创建如下的k8s ClusterIP service: \u003cservice.name\u003e.\u003cnamespace\u003e.svc.cluster.local，selector app=\u003cname\u003e-primary \u003cservice.name\u003e-primary.\u003cnamespace\u003e.svc.cluster.local，selector app=\u003cname\u003e-primary \u003cservice.name\u003e-canary.\u003cnamespace\u003e.svc.cluster.local，selector app=\u003cname\u003e 这可确保流量到podinfo.test:9898将被路由到应用的最新稳定版本。podinfo-canary.test:9898这个地址仅在金丝雀分析期间可用，可用于符合测试或负载测试。 可以配置Flagger为service生成annotations和labels： spec:service:port:9898apex:annotations:test:\"test\"labels:test:\"test\"canary:annotations:test:\"test\"labels:test:\"test\"primary:annotations:test:\"test\"labels:test:\"test\" 除了端口映射和元数据，service spec可包含URI和重定向规则，超时和重试策略： spec:service:port:9898match:- uri:prefix:/rewrite:uri:/retries:attempts:3perTryTimeout:1stimeout:5s 当使用Istio时，你还可以指定HTTP headers, CORS, traffic policies, Istio gateway, hosts。Istio的路由配置请参考: https://docs.flagger.app/faq#istio-routing ","date":"2021-01-14","objectID":"/flagger/:4:3","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"Canary status 可使用kubectl来获取canary deployment的当前状态: kubectl get canaries --all-namespaces NAMESPACE NAME STATUS WEIGHT LASTTRANSITIONTIME test podinfo Progressing 15 2019-06-30T14:05:07Z prod frontend Succeeded 0 2019-06-30T16:15:07Z prod backend Failed 0 2019-06-30T17:05:07Z 状态条件反映了金丝雀分析的最后一个已知状态: kubectl -n test get canary/podinfo -oyaml | awk '/status/,0' 一个成功的rollout状态: status: canaryWeight: 0 failedChecks: 0 iterations: 0 lastAppliedSpec: \"14788816656920327485\" lastPromotedSpec: \"14788816656920327485\" conditions: - lastTransitionTime: \"2019-07-10T08:23:18Z\" lastUpdateTime: \"2019-07-10T08:23:18Z\" message: Canary analysis completed successfully, promotion finished. reason: Succeeded status: \"True\" type: Promoted CD样例: # update the container image kubectl set image deployment/podinfo podinfod=stefanprodan/podinfo:3.0.1 # wait for Flagger to detect the change ok=false until ${ok}; do kubectl get canary/podinfo | grep 'Progressing' \u0026\u0026 ok=true || ok=false sleep 5 done # wait for the canary analysis to finish kubectl wait canary/podinfo --for=condition=promoted --timeout=5m # check if the deployment was successful kubectl get canary/podinfo | grep Succeeded ","date":"2021-01-14","objectID":"/flagger/:4:4","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"Canary finalizers Flagger对金丝雀删除(canary deletion)的默认行为是 离开(leave)不受当前状态控制器拥有的资源。这简化了删除操作，避免了在资源最终确定期间可能的死锁。如果金丝雀被引入现有资源，他们将在初始化阶段变异(mutated)，并且不再反映它们的初始状态。如果删除时所需的功能是将资源还原到他们的初始阶段，则可以启动revertOnDeletion属性。 spec:revertOnDeletion:true 当一个删除操作提交到集群，Flagger经尝试恢复(revert)以下资源： canary target副本将更新到primary副本数 canary service选择器将被恢复 mesh/ingress 流量路由到target 推荐的方法是禁用金丝雀分析，将使用skipAnalysis属性，这限制了资源和解(reconciliation)的需求。当不再计划依赖Flagger部署管理时，应该启用revertOnDeletion属性。 ","date":"2021-01-14","objectID":"/flagger/:4:5","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"Canary analysis 金丝雀部署定义了： 部署策略的类型 验证金丝雀版本的指标 一致性测试、负载测试和手动门控的webhooks 告警设置 spec: analysis:# schedule interval (default 60s)interval:# max number of failed metric checks before rollbackthreshold:# max traffic percentage routed to canary# percentage (0-100)maxWeight:# canary increment step# percentage (0-100)stepWeight:# promotion increment step# percentage (0-100)stepWeightPromotion:# total number of iterations# used for A/B Testing and Blue/Greeniterations:# canary match conditions# used for A/B Testingmatch:- # HTTP header# key performance indicatorsmetrics:- # metric check# alertingalerts:- # alert provider# external checkswebhooks:- # hook 金丝雀分析定期运行，直到它达到最大流量权重或迭代次数。在每个运行时，Flagger调用webhook，检查指标，如果达到失败的检查阈值，则停止分析并回滚金丝雀。如果配置了告警，Flagger将发送分析结果。 ","date":"2021-01-14","objectID":"/flagger/:4:6","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"部署策略 Deployment Strategies: https://docs.flagger.app/usage/deployment-strategies Flagger可以为以下部署策略自动运行应用分析(application analysis)，提升(promotion)，回滚(rollback): 金丝雀发布(Canary Release, progressive traffic shifting): Istio, Linkerd, App Mesh, NGINX, Skipper, Contour, Gloo Edge, Traefik AB测试(A/B Testing, HTTP headers and cookies traffic routing): Istio, App Mesh, NGINX, Contour, Gloo Edge 蓝绿(Blue/Green, traffic switching): Kubernetes CNI, Istio, Linkerd, App Mesh, NGINX, Contour, Gloo Edge 蓝绿镜像(Blue/Green Mirroring, traffic shadowing): Istio 对于金丝雀发布和A/B测试，你应该使用7层流量管理方案，如service mesh或ingress controller。 对于蓝绿部署，不需要service mesh 或 ingress controller。 可通过改变以下对象来触发一个金丝雀分析： Deployment PodSpec (container image, command, ports, env, resources, etc) ConfigMaps mounted as volumes or mapped to environment variables Secrets mounted as volumes or mapped to environment variables ","date":"2021-01-14","objectID":"/flagger/:5:0","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"金丝雀发布 Canary Release Flagger实现了一个控制循环(control loop)，可以逐渐地将流量转移到金丝雀，同时测量关键性能指标（如http请求成功率，请求平均耗时，Pod健康状态…）。 Flagger金丝雀阶段： 金丝雀分析会定期运行，直到达到最大流量权重或检查失败。 spec: analysis:# schedule interval (default 60s)interval:1m# max number of failed metric checks before rollbackthreshold:10# max traffic percentage routed to canary# percentage (0-100)maxWeight:50# canary increment step# percentage (0-100)stepWeight:2# promotion increment step (default 100)# percentage (0-100)stepWeightPromotion:100# deploy straight to production without# the metrics and webhook checksskipAnalysis:false 以上分析，如果成功，将运行25分钟，每分钟验证HTTP指标和webhokk。 你可以使用以下供使确定验证和升级金丝雀部署所需的最短时间： interval * (maxWeight / stepWeight) # 上面 1 * ( 50 / 2) 当指标检测失败时，金丝雀回滚需要的时间： interval * threshold # 上面 1 * 10 当指定了stepWeightPromotion，promotion阶段发生在stages中，流量以逐步的方式路由回primary pod，主权重逐渐增加直到100%。 在紧急情况下，你可能希望提升分析阶段并直接应用变更到生产环境。你随时都可以设置spec.skipAnalysis: true。当启用了跳过分析，Flagger会检查金丝雀部署是否健康，并在不分析它的情况下提升它(promote)。如果正在进行分析，则Flagger回取消分析并运行提升(promotion)。 Gated canary promotion stages: 扫描金丝雀部署（scan for canary deployments） 检查主和金丝雀部署状态（check primary and canary deployment status） 如果正在进行滚动更新，则停止（halt advancement if a rolling update is underway） 如果pod不健康，则停止（halt advancement if pods are unhealthy） 确认部署并检查结果（call confirm-rollout webhooks and check results） 如果任意hook返回非http 2xx结果，则停止提升（halt advancement if any hook returns a non HTTP 2xx result） 预览部署并检查结果（call pre-rollout webhooks and check results） 如果任意hook返回非http 2xx结果，则停止提升 递增失败的检查计数器（increment the failed checks counter） 增加金丝雀流量权重（increase canary traffic weight percentage from 0% to 2% (step weight)） 调用推出并检查结果（call rollout webhooks and check results） 检查金丝雀HTTP请求成功率和延迟（call rollout webhooks and check results） 如果任意指标都在指定的阈值下，则停止提升（halt advancement if any metric is under the specified threshold） 递增失败的检查计数器 检查失败的检查的数量是否达到了阈值（check if the number of failed checks reached the threshold） 路由所有流量到主（route all traffic to primary） 将金丝雀部署缩减为0并标记为失败（scale to zero the canary deployment and mark it as failed） 调用推出后的钩子（call post-rollout webhooks） 发送分析结果（post the analysis result to Slack） 等待金丝雀部署更新或重新开始（wait for the canary deployment to be updated and start over） 增加金丝雀流量直到最大（increase canary traffic weight by 2% (step weight) till it reaches 50% (max weight) ） 如果任意狗子调用失败，则停止提升（halt advancement if any webhook call fails） 金丝雀请求成功率在阈值之下，则停止提升（halt advancement while canary request success rate is under the threshold） 金丝雀请求持续时间超过阈值，则停止提升（halt advancement while canary request duration P99 is over the threshold） 任意自定义指标检查失败，则停止提升（halt advancement while any custom metric check fails） 如果primary或金丝雀部署不健康，则停止提升（halt advancement if the primary or canary deployment becomes unhealthy ） 金丝雀部署正通过HPA进行伸缩，则停止提升（halt advancement while canary deployment is being scaled up/down by HPA） 调用确认提升钩子并检查结果（call confirm-promotion webhooks and check results） 如果任意hook返回非http 2xx结果，则停止提升 提升金丝雀为主（promote canary to primary） 将configmap和secret从金丝雀复制到主（copy ConfigMaps and Secrets from canary to primary） 复制金丝雀部署spec模板（copy canary deployment spec template over primary） 等待主滚动更新完成（wait for primary rolling update to finish） 如果pod不健康，则停止提升 路由所有流量到主（route all traffic to primary） 将金丝雀部署伸缩为0（scale to zero the canary deployment） 标记推出为完成（mark rollout as finished） 调用推出后钩子（call post-rollout webhooks） 发送金丝雀分析结果通知（send notification with the canary analysis result） 等待金丝雀部署更新并重新开始（wait for the canary deployment to be updated and start over） Rollout Weights 默认情况下，Flagger对提升使用线性权重值（开始值，步进值，最大权重）。 栗子: canary:analysis:promotion:maxWeight:50stepWeight:20 此配置执行分析，从20开始，每次递增20，直到权重到达50。 20 (20 : 80) 40 (40 : 60) 60 (60 : 40) promotion 要启用非线性提升，可以使用stepWeights参数（在金丝雀提升期间使用有序权重数组）。 栗子: canary: analysis: promotion: stepWeights: [1, 2, 10, 80] 此配置分析，从1开始，经过有序权重直到80。 1 (1 : 99) 2 (2 : 98) 10 (10 : 90) 80 (20 : 60) promotion ","date":"2021-01-14","objectID":"/flagger/:5:1","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"AB测试 A/B Testing 对于需要会话关联(session affinity)的前端应用，你应该使用HTTP headers或cookie匹配条件，以便在整个金丝雀分析期间，确保一组用户将保持同一应用版本。 你可以通过指定HTTP匹配条件和迭代次数来启用AB测试。如果Flagger发现HTTP匹配条件，它会忽略maxWeight和stepWeight设置。 Istio栗子： analysis:# schedule interval (default 60s)interval:1m# total number of iterationsiterations:10# max number of failed iterations before rollbackthreshold:2# canary match conditionmatch:- headers:x-canary:regex:\".*insider.*\"- headers:cookie:regex:\"^(.*?;)?(canary=always)(;.*)?$\" analysis:interval:1mthreshold:10iterations:2match:- headers:x-canary:exact:\"insider\"- headers:cookie:regex:\"^(.*?;)?(canary=always)(;.*)?$\"- sourceLabels:app.kubernetes.io/name:\"scheduler\" header key必须小写，并使用作为分隔符。header value是大小写敏感的。 exact: \"value\" for exact string match prefix: \"value\" for prefix-based match suffix: \"value\" for suffix-based match regex: \"value\" for RE2 style regex-based match 请注意，只有当网格网关包含在canary.service.gateways列表时，才适用sourceLabels匹配条件。 App Mesh栗子： analysis:interval:1mthreshold:10iterations:2match:- headers:user-agent:regex:\".*Chrome.*\" 注意，App Mesh支持单个条件。 轮廓栗子: analysis:interval:1mthreshold:10iterations:2match:- headers:user-agent:prefix:\"Chrome\" 请注意，contour不支持正则，你可以使用prefix, suffix, exact。 nginx栗子： analysis:interval:1mthreshold:10iterations:2match:- headers:x-canary:exact:\"insider\"- headers:cookie:exact:\"canary\" 请注意，nginx ingress controller仅支持cookies的精确匹配，其中值必须设置为always。从nginx ingress v0.31开始，header values支持正常匹配。 以上配置将会路由带有x-canary header或canary cookie的用户: curl -H 'X-Canary: insider' http://app.example.com curl -b 'canary=always' http://app.example.com ","date":"2021-01-14","objectID":"/flagger/:5:2","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"蓝绿部署 Blue/Green Deployments 对于未使用服务网格部署的应用，Flagger可使用k8s 四层网络的蓝绿格式的部署。使用Istio，你可以在蓝绿之间选择镜像流量。 你可以在analysis spec中使用iterations替换stepWeight/maxWeight来使用蓝绿部署策略： analysis:# schedule interval (default 60s)interval:1m# total number of iterationsiterations:10# max number of failed iterations before rollbackthreshold:2 上面的配置，Flagger将在canary pod上运行一致性和负载测试10分钟。如果指标分析成功，当金丝雀提升时，实时流量(live traffic)将从旧版本切换到新版本。 蓝绿部署策略支持多个服务网格提供商。 服务网格的蓝绿推出步骤（Blue/Green rollout steps for service mesh）： 检测新的修订（detect new revision (deployment spec, secrets or configmaps changes)） 扩展金丝雀（scale up the canary (green)） 运行一致性测试（run conformance tests for the canary pods） 每分钟为canary pods运行负载测试和指标检测（run load tests and metric checks for the canary pods every minute） 如果达到失败阈值，则中止金丝雀发布（abort the canary release if the failure threshold is reached） 路由流量到金丝雀（route traffic to canary） 提升主的canary spec（promote canary spec over primary (blue)） 等待主推出（wait for primary rollout） 路由流量到主（route traffic to primary） 缩小金丝雀（scale down canary） 分析完成后，在触发主(primary, blue)滚动更新之前，流量被路由到金丝雀(canary, green)，这确保了在k8s部署推出期间避免删除飞行中(in-flight)的请求，平滑过渡到新版本。 ","date":"2021-01-14","objectID":"/flagger/:5:3","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"流量镜像的蓝绿部署 Blue/Green with Traffic Mirroring 流量镜像是金丝雀（逐渐流量漂移）或蓝绿部署策略的前阶段(pre-stage)。流量镜像将复制每个入请求，将请求分别发送给主和金丝雀服务。来自主的响应将发送回用户，来自金丝雀的响应将被丢弃。两个请求都会收集指标，以便在金丝雀指标健康时，部署会继续进行。 镜像应该用于幂等的请求或能够进行两次处理（一次主，一次金丝雀）。读取是幂等的。在请求上使用镜像之前，请求可能写入，你应该考虑会发生什么，如果一个写重复并且由主和金丝雀处理。 要使用镜像，将spec.analysis.mirror设置为ftrue。 Istio栗子： analysis:# schedule interval (default 60s)interval:1m# total number of iterationsiterations:10# max number of failed iterations before rollbackthreshold:2# Traffic shadowing (compatible with Istio only)mirror:true# Weight of the traffic mirrored to your canary (defaults to 100%)mirrorWeight:100 服务网格的镜像推出步骤（Mirroring rollout steps for service mesh）： 检测新的改动（detect new revision (deployment spec, secrets or configmaps changes)） 伸展金丝雀（scale from zero the canary deployment） 等待HPA设置金丝雀最小副本数（wait for the HPA to set the canary minimum replicas） 检查金丝雀pod健康状态（check canary pods health） 运行验收测试（run the acceptance tests） 如果测试失败，则中止金丝雀发布（abort the canary release if tests fail） 启动负载测试（start the load tests） 从主镜像流量到金丝雀（mirror 100% of the traffic from primary to canary） 检查请求成功率和每分钟请求耗时（check request success rate and request duration every minute） 如果达到失败阈值，则中止金丝雀发布（abort the canary release if the failure threshold is reached） 如果达到迭代次数，则停止流量镜像（stop traffic mirroring after the number of iterations is reached） 路由实时流量到金丝雀pod（route live traffic to the canary pods） 提升金丝雀（promote the canary (update the primary secrets, configmaps and deployment spec)） 等待主推出完成（wait for the primary deployment rollout to finish） 等待HPA设置主的最小副本数（wait for the HPA to set the primary minimum replicas） 检查主pod健康状况（check primary pods health） 将实时流量切换回主（switch live traffic back to primary） 缩小金丝雀（scale to zero the canary） 发送金丝雀分析结果通知（send notification with the canary analysis result） ","date":"2021-01-14","objectID":"/flagger/:5:4","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"指标分析 Metrics Analysis 作为分析过程的一部分，Flagger可以根据应用特定指标验证其可用性、错误率、平均响应时间和任何其它目标级别的服务(SLOs, service level objectives)。如果在SLOs分期期间注意到性能下降，则发布将自动回滚以最小化影响用户。 ","date":"2021-01-14","objectID":"/flagger/:6:0","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"内置指标 Builtin metrics Flaggger有两个内置的指标检查：HTTP请求成功率和持续时间。 analysis:metrics:- name:request-success-rateinterval:1m# minimum req success rate (non 5xx responses)# percentage (0-100)thresholdRange:min:99- name:request-durationinterval:1m# maximum req duration P99# millisecondsthresholdRange:max:500 内置的检查指标支持每个service mesh、ingress controller，并可使用Prometheus进行查询。 ","date":"2021-01-14","objectID":"/flagger/:6:1","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"自定义指标 Custom metrics 金丝雀分析可以通过自定义检测指标进行扩展。使用MetricTemplate自定义资源，你可以配置Flagger连接到一个指标提供商（如Prometheus），并运行一个查询，它返回一个float64值。查询结果用于基于特定阈值范围来验证金丝雀。 apiVersion:flagger.app/v1beta1kind:MetricTemplatemetadata:name:my-metricspec:provider:type:# can be prometheus or datadogaddress:# API URLsecretRef:name:# name of the secret containing the API credentialsquery:# metric query 以下变量可用于查询模板： name (canary.metadata.name) namespace (canary.metadata.namespace) target (canary.spec.targetRef.name) service (canary.spec.service.name) ingress (canary.spec.ingresRef.name) interval (canary.spec.analysis.metrics[].interval) 金丝雀分析指标可以使用templateRef引用模板： analysis:metrics:- name:\"my metric\"templateRef:name:my-metric# namespace is optional# when not specified, the canary namespace will be usednamespace:flagger# accepted valuesthresholdRange:min:10max:1000# metric query time windowinterval:1m ","date":"2021-01-14","objectID":"/flagger/:6:2","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"Prometheus 你可以使用如Prometheus，并编写PromQL查询，来创建自定义检查指标目标。 Prometheus template栗子： apiVersion:flagger.app/v1beta1kind:MetricTemplatemetadata:name:not-found-percentagenamespace:istio-systemspec:provider:type:prometheusaddress:http://prometheus.istio-system:9090query:|100 - sum( rate( istio_requests_total{ reporter=\"destination\", destination_workload_namespace=\"{{ namespace }}\", destination_workload=\"{{ target }}\", response_code!=\"404\" }[{{ interval }}] ) ) / sum( rate( istio_requests_total{ reporter=\"destination\", destination_workload_namespace=\"{{ namespace }}\", destination_workload=\"{{ target }}\" }[{{ interval }}] ) ) * 100 在金丝雀分析中引用模板： analysis:metrics:- name:\"404s percentage\"templateRef:name:not-found-percentagenamespace:istio-systemthresholdRange:max:5interval:1m 上面的配置验证金丝雀，通过检查HTTP 404 req/sec 百分比是否低于5%。如果大于5%阈值，那么金丝雀失败。 Prometheus gRPC错误率栗子： apiVersion:flagger.app/v1beta1kind:MetricTemplatemetadata:name:grpc-error-rate-percentagenamespace:flaggerspec:provider:type:prometheusaddress:http://flagger-prometheus.flagger-system:9090query:|100 - sum( rate( grpc_server_handled_total{ grpc_code!=\"OK\", kubernetes_namespace=\"{{ namespace }}\", kubernetes_pod_name=~\"{{ target }}-[0-9a-zA-Z]+(-[0-9a-zA-Z]+)\" }[{{ interval }}] ) ) / sum( rate( grpc_server_started_total{ kubernetes_namespace=\"{{ namespace }}\", kubernetes_pod_name=~\"{{ target }}-[0-9a-zA-Z]+(-[0-9a-zA-Z]+)\" }[{{ interval }}] ) ) * 100 ","date":"2021-01-14","objectID":"/flagger/:6:3","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"Prometheus认证 Prometheus authentication 如果Prometheus启用了认证，你可以在相同的命名空间内创建一个包含认证信息的secret。 apiVersion:v1kind:Secretmetadata:name:prom-basic-authnamespace:flaggerdata:username:your-userpassword:your-password 在MetricTemplate中引用secret： apiVersion:flagger.app/v1beta1kind:MetricTemplatemetadata:name:my-metricnamespace:flaggerspec:provider:type:prometheusaddress:http://prometheus.monitoring:9090secretRef:name:prom-basic-auth ","date":"2021-01-14","objectID":"/flagger/:6:4","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"DataDdog ","date":"2021-01-14","objectID":"/flagger/:6:5","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"Amazon CloudWatch ","date":"2021-01-14","objectID":"/flagger/:6:6","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"New Relic ","date":"2021-01-14","objectID":"/flagger/:6:7","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"Webhooks url: https://docs.flagger.app/usage/webhooks 金丝雀分析可以用webhooks进行扩展延伸。如果金丝雀失败，Flagger会调用每个webhook url并检测响应状态码。 有几种类型的钩子： confirm-rollout：在扩展金丝雀部署之前执行，并可用于手动批准。推出是暂停的，直到钩子返回一个成功的HTTP状态码。 pre-rollout：在将流量路由到金丝雀之前执行。如果钩子失败，并且失败次数达到阈值，金丝雀进展是将暂停， 并回滚。 rollout：在指标检查之前在分析期间执行。如果失败，金丝雀进展将暂停并最终回滚。 confirm-promotion：在提升之前执行。金丝雀提升是暂停的，直到钩子返回HTTP 200。当提升暂停时，Flagger将继续运行指标检查和rollout钩子。 post-rollout：在金丝雀被提升或回滚之后执行。如果失败，则记录错误。 rollback：在金丝雀部署处于进度和等待状态时执行。这提供了在分析期间回滚或等待确认的能力。如果它返回一个成功的HTTP状态码，Flagger将停止分析并将金丝雀发布标记为失败。 event：在每次Flagger发出k8s事件时执行。配置后，在Flagger在金丝雀部署期间的每个动作都将通过HTTP POST作为JSON发送。 spec： analysis:webhooks:- name:\"start gate\"type:confirm-rollouturl:http://flagger-loadtester.test/gate/approve- name:\"helm test\"type:pre-rollouturl:http://flagger-helmtester.flagger/timeout:3mmetadata:type:\"helmv3\"cmd:\"test podinfo -n test\"- name:\"load test\"type:rollouturl:http://flagger-loadtester.test/timeout:15smetadata:cmd:\"hey -z 1m -q 5 -c 2 http://podinfo-canary.test:9898/\"- name:\"promotion gate\"type:confirm-promotionurl:http://flagger-loadtester.test/gate/approve- name:\"notify\"type:post-rollouturl:http://telegram.bot:8080/timeout:5smetadata:some:\"message\"- name:\"rollback gate\"type:rollbackurl:http://flagger-loadtester.test/rollback/check- name:\"send to Slack\"type:eventurl:http://event-recevier.notifications/slack webhook payload(http post)： {\"name\": \"podinfo\",\"namespace\": \"test\",\"phase\": \"Progressing\",\"metadata\": {\"test\": \"all\",\"token\": \"16688eb5e9f289f1991c\"}} 响应状态码： 200-202，通过增加流量权重来提升金丝雀 timeout或非2xx，停止提升并增加失败检查 在一个非2xx响应，Flagger将包含response body在失败检查日志和k8s事件中。 event payload(http post)： {\"name\": \"string (canary name)\",\"namespace\": \"string (canary namespace)\",\"phase\": \"string (canary phase)\",\"metadata\": {\"eventMessage\": \"string (canary event message)\",\"eventType\": \"string (canary event type)\",\"timestamp\": \"string (unix timestamp ms)\"}} 事件接收器可以根据接收阶段创建告警（可能的值：Initialized, Waiting, Progressing, Promoting, Finalising, Succeeded或Failed）。 ","date":"2021-01-14","objectID":"/flagger/:7:0","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"负载测试 Load Testing 对于未接收恒定流量的工作负载，Flagger可以使用webhook配置，即在调用时，为目标工作负载启动一个负载测试。如果工作负载在金丝雀分析期间没有接收任何流量，Flagger指标检查将失败（no values found for metric request-success-rate）。 Flagger的负载测试服务基于rakyll/hey，当配置为webhooks时会在分析期间生成流量。 # First you need to deploy the load test runner in a namespace with sidecar injection enabled kubectl apply -k https://github.com/fluxcd/flagger//kustomize/tester?ref=main # 或使用helm helm repo add flagger https://flagger.app helm upgrade -i flagger-loadtester flagger/loadtester \\ --namespace=test \\ --set cmd.timeout=1h # When deployed the load tester API will be available at http://flagger-loadtester.test/ 现在，你可以将webhook添加到金丝雀分析规范中： webhooks:- name:load-test-geturl:http://flagger-loadtester.test/timeout:5smetadata:type:cmdcmd:\"hey -z 1m -q 10 -c 2 http://podinfo-canary.test:9898/\"- name:load-test-posturl:http://flagger-loadtester.test/timeout:5smetadata:type:cmdcmd:\"hey -z 1m -q 10 -c 2 -m POST -d '{test: 2}' http://podinfo-canary.test:9898/echo\" 当金丝雀分析开始时，如果它们尚未运行，Flagger将调用webhook，负载测试器将在后台运行hey命令。这将确保在分析期间，podinfo-canary.test服务将收到稳定的GET和POST请求流。 对于gRPC服务，你可以使用bojand/ghz工具，它是一个类似于hey但用于gRPC测试的工具。 webhooks:- name:grpc-load-testurl:http://flagger-loadtester.test/timeout:5smetadata:type:cmdcmd:\"ghz -z 1m -q 10 -c 2 --insecure podinfo.test:9898\" ghz使用反射(reflection)来确定要调用哪种gRPC方法。如果你不希望为gRPC服务启用反射，你可以从grpc-proto library实现标准化的健康检查。要使用不带反射的健康检查架构，亦可以将参数传递给ghz： webhooks:- name:grpc-load-test-no-reflectionurl:http://flagger-loadtester.test/timeout:5smetadata:type:cmdcmd:\"ghz --insecure --proto=/tmp/ghz/health.proto --call=grpc.health.v1.Health/Check podinfo.test:9898\" 负载测试器可以运行任何命令，只要容器镜像中存在二进制文件即可。例如，如果你想用其它命令替代hey，你可以创建自己的Dockerfile和镜像： FROMweaveworks/flagger-loadtester:\u003cVER\u003eRUN curl -Lo /usr/local/bin/my-cli https://github.com/user/repo/releases/download/ver/my-cli \\ \u0026\u0026 chmod +x /usr/local/bin/my-cli ","date":"2021-01-14","objectID":"/flagger/:7:1","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"负载测试委托 Load Testing Delegation 负载测试器同样可以转发测试任务到外部工具，目前支持nGrinder。 ","date":"2021-01-14","objectID":"/flagger/:7:2","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"集成测试 Integration Testing Flagger附带的测试服务，当配置为webhook是，可以运行helm测试、Bash测试或Concord测试。 # 部署一个helm测试器 helm repo add flagger https://flagger.app helm upgrade -i flagger-helmtester flagger/loadtester \\ --namespace=kube-system \\ --set serviceAccountName=tiller # When deployed the Helm tester API will be available at http://flagger-helmtester.kube-system/ 现在，你可以向金丝雀分析规范中添加pre-rollout webhook： analysis:webhooks:- name:\"smoke test\"type:pre-rollouturl:http://flagger-helmtester.kube-system/timeout:3mmetadata:type:\"helm\"cmd:\"test {{ .Release.Name }} --cleanup\" 当金丝雀分析启动时，在路由流量到金丝雀之前，Flagger将调用pre-rollout webhook。如果helm测试失败，Flagger将重试直到到达分析阈值，并回滚金丝雀。 如果使用Helm v3，你必须在此命名空间创建专用的service account，并将命名空间添加到命令： analysis:webhooks:- name:\"smoke test\"type:pre-rollouturl:http://flagger-helmtester.kube-system/timeout:3mmetadata:type:\"helmv3\"cmd:\"test {{ .Release.Name }} --timeout 3m -n {{ .Release.Namespace }}\" 如果测试挂起或错误日志暗示权限不足，它可能与RBAC有关。 作为helm的替代方案，你可以使用Bash Automated Testing System来运行你的测试。 analysis:webhooks:- name:\"acceptance tests\"type:pre-rollouturl:http://flagger-batstester.default/timeout:5mmetadata:type:\"bash\"cmd:\"bats /tests/acceptance.bats\" 使用Bats测试，你应该创建一个ConfigMap，并将其挂载到测试器容器内。 你同样可以配置测试器来启动Concord程序： analysis:webhooks:- name:\"concord integration test\"type:pre-rollouturl:http://flagger-concordtester.default/timeout:60smetadata:type:\"concord\"org:\"your-concord-org\"project:\"your-concord-project\"repo:\"your-concord-repo\"entrypoint:\"your-concord-entrypoint\"apiKeyPath:\"/tmp/concord-api-key\"endpoint:\"https://canary-endpoint/\"pollInterval:\"5\"pollTimeout:\"60\" ","date":"2021-01-14","objectID":"/flagger/:7:3","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"手动门控 Manual Gating 对于手动批准(manual approval)金丝雀部署，你可以使用confirm-rollout和confirm-promotion webhooks。confirm rollout钩子在pre-rollout钩子之前执行。Flagger会中止金丝雀流量漂移并分析，直到confirm钩子返回HTTP 200。 对于手动回滚(manual rollback)金丝雀部署，你可以使用rollback webhook。此钩子将在分析和确认状态期间被调用。如果回滚钩子返回成功的HTTP状态码，Flagger将漂移所有流量回主实例(primary)并失败金丝雀。 使用Flagger测试器手动门控： # /gate/halt会返回http 403，因此会阻止推出analysis:webhooks:- name:\"gate\"type:confirm-rollouturl:http://flagger-loadtester.test/gate/halt 如果你启用了通知，如果金丝雀推出等待批准，Flagger将会给你推送消息。 # 启动金丝雀分析analysis:webhooks:- name:\"gate\"type:confirm-rollouturl:http://flagger-loadtester.test/gate/approve # 手动门控可通过Flagger测试器API驱动analysis:webhooks:- name:\"ask for confirmation\"type:confirm-rollouturl:http://flagger-loadtester.test/gate/check 默认情况下，门控是关闭的，你可以开启或恢复金丝雀推出： kubectl -n test exec -it flagger-loadtester-xxxx-xxxx sh curl -d '{\"name\": \"podinfo\",\"namespace\":\"test\"}' http://localhost:8080/gate/open 你可以在任意时间暂停推出： curl -d '{\"name\": \"podinfo\",\"namespace\":\"test\"}' http://localhost:8080/gate/close 如果一个金丝雀分析暂停，状态将改变为等待： kubectl get canary/podinfoNAME STATUS WEIGHTpodinfo Waiting 0 confirm-promotion钩子类型可用于手动批准金丝雀提升。当提升暂停时，Flagger将继续运行指标检查和负载测试。 analysis:webhooks:- name:\"promotion gate\"type:confirm-promotionurl:http://flagger-loadtester.test/gate/halt rollback钩子类型可用于手动回滚金丝雀提升。与门控一样，通过将回滚URL设置为/rollback/check，回滚可以被Flagger测试器API驱动 analysis:webhooks:- name:\"rollback\"type:rollbackurl:http://flagger-loadtester.test/rollback/check 默认情况下，回滚是关闭的。 # 你可以回滚一个金丝雀推出 kubectl -n test exec -it flagger-loadtester-xxxx-xxxx sh curl -d '{\"name\": \"podinfo\",\"namespace\":\"test\"}' http://localhost:8080/rollback/open # 你可以关闭回滚 curl -d '{\"name\": \"podinfo\",\"namespace\":\"test\"}' http://localhost:8080/rollback/close 如果你启用了通知，如果一个金丝雀已经回滚，Flagger会发送通知消息。 ","date":"2021-01-14","objectID":"/flagger/:7:4","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"告警 Alerting: https://docs.flagger.app/usage/alerting Flagger可配置来将告警发送到各种聊天平台。你可以在全局配置，也可以在金丝雀层面配置。 ","date":"2021-01-14","objectID":"/flagger/:8:0","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"全局配置 Global configuration 全局配置通知： # Slack全局配置 helm upgrade -i flagger flagger/flagger \\ --set slack.url=https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK \\ --set slack.channel=general \\ --set slack.user=flagger # Microsoft Teams全局配置 helm upgrade -i flagger flagger/flagger \\ --set msteams.url=https://outlook.office.com/webhook/YOUR/TEAMS/WEBHOOK ","date":"2021-01-14","objectID":"/flagger/:8:1","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"金丝雀层面配置 Canary configuration 全局配置通知不够细化，为了使告警更加灵活，可在金丝雀层面配置。 Slack栗子： apiVersion:flagger.app/v1beta1kind:AlertProvidermetadata:name:on-callnamespace:flaggerspec:type:slackchannel:on-call-alertsusername:flagger# webhook address (ignored if secretRef is specified)address:https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK# secret containing the webhook address (optional)secretRef:name:on-call-url---apiVersion:v1kind:Secretmetadata:name:on-call-urlnamespace:flaggerdata:address:\u003cencoded-url\u003e 金丝雀分析的告警列表： analysis:alerts:- name:\"on-call Slack\"severity:errorproviderRef:name:on-callnamespace:flagger- name:\"qa Discord\"severity:warnproviderRef:name:qa-discord- name:\"dev MS Teams\"severity:infoproviderRef:name:dev-msteams ","date":"2021-01-14","objectID":"/flagger/:8:2","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"AlertMnager Prometheus AlertMnager 当金丝雀部署失败时，你可以使用AlertManger来触发告警： - alert:canary_rollbackexpr:flagger_canary_status \u003e 1for:1mlabels:severity:warningannotations:summary:\"Canary failed\"description:\"Workload {{ $labels.name }} namespace {{ $labels.namespace }}\" ","date":"2021-01-14","objectID":"/flagger/:8:3","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"监控 Monitoring: https://docs.flagger.app/usage/monitoring ","date":"2021-01-14","objectID":"/flagger/:9:0","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"Grafana Flagger配有针对金丝雀分析的Grafana仪表盘。 # Install Grafana with Helm helm upgrade -i flagger-grafana flagger/grafana \\ --set url=http://prometheus:9090 ","date":"2021-01-14","objectID":"/flagger/:9:1","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"Logging 金丝雀错误和延迟尖峰被记录为k8s事件，并被Flagger以json格式记录： kubectl -n istio-system logs deployment/flagger --tail=100 | jq .msg Starting canary deployment for podinfo.test Advance podinfo.test canary weight 5 Advance podinfo.test canary weight 10 Advance podinfo.test canary weight 15 Advance podinfo.test canary weight 20 Advance podinfo.test canary weight 25 Advance podinfo.test canary weight 30 Advance podinfo.test canary weight 35 Halt podinfo.test advancement success rate 98.69% \u003c 99% Advance podinfo.test canary weight 40 Halt podinfo.test advancement request duration 1.515s \u003e 500ms Advance podinfo.test canary weight 45 Advance podinfo.test canary weight 50 Copying podinfo.test template spec to podinfo-primary.test Halt podinfo-primary.test advancement waiting for rollout to finish: 1 old replicas are pending termination Scaling down podinfo.test Promotion completed! podinfo.test ","date":"2021-01-14","objectID":"/flagger/:9:2","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"Event Webhook Flagger可以配置来发送event payloads到特定webhook： helm upgrade -i flagger flagger/flagger \\ --set eventWebhook=https://example.com/flagger-canary-event-webhook 栗子： { \"name\": \"podinfo\", \"namespace\": \"default\", \"phase\": \"Progressing\", \"metadata\": { \"eventMessage\": \"New revision detected! Scaling up podinfo.default\", \"eventType\": \"Normal\", \"timestamp\": \"1578607635167\" } } 在金丝雀层面，event webhook可被覆盖： analysis:webhooks:- name:\"send to Slack\"type:eventurl:http://event-recevier.notifications/slack ","date":"2021-01-14","objectID":"/flagger/:9:3","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"Metrics Flagger公开了可用于确定金丝雀分析状态和目标权重值的Prometheus metrics： # Flagger version and mesh provider gaugeflagger_info{version=\"0.10.0\", mesh_provider=\"istio\"} 1# Canaries total gaugeflagger_canary_total{namespace=\"test\"} 1# Canary promotion last known status gauge# 0 - running, 1 - successful, 2 - failedflagger_canary_status{name=\"podinfo\" namespace=\"test\"} 1# Canary traffic weight gaugeflagger_canary_weight{workload=\"podinfo-primary\" namespace=\"test\"} 95flagger_canary_weight{workload=\"podinfo\" namespace=\"test\"} 5# Seconds spent performing canary analysis histogramflagger_canary_duration_seconds_bucket{name=\"podinfo\",namespace=\"test\",le=\"10\"} 6flagger_canary_duration_seconds_bucket{name=\"podinfo\",namespace=\"test\",le=\"+Inf\"} 6flagger_canary_duration_seconds_sum{name=\"podinfo\",namespace=\"test\"} 17.3561329flagger_canary_duration_seconds_count{name=\"podinfo\",namespace=\"test\"} 6 教程 Tutorials ","date":"2021-01-14","objectID":"/flagger/:9:4","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"Isito金丝雀部署 Istio Canary Deployments: https://docs.flagger.app/tutorials/istio-progressive-delivery ","date":"2021-01-14","objectID":"/flagger/:10:0","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"Istio AB测试 Istio A/B Testing: https://docs.flagger.app/tutorials/istio-ab-testing ","date":"2021-01-14","objectID":"/flagger/:11:0","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"Nginx 金丝雀部署 NGINX Canary Deployments: https://docs.flagger.app/tutorials/nginx-progressive-delivery ","date":"2021-01-14","objectID":"/flagger/:12:0","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"蓝绿部署 Blue/Green Deployments: https://docs.flagger.app/tutorials/kubernetes-blue-green ","date":"2021-01-14","objectID":"/flagger/:13:0","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"使用Prometheus Operator的金丝雀分析 Canary analysis with Prometheus Operator: https://docs.flagger.app/tutorials/prometheus-operator ","date":"2021-01-14","objectID":"/flagger/:14:0","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"零停机时间部署 Zero downtime deployments: https://docs.flagger.app/tutorials/zero-downtime-deployments 如果你想最大限度地减少滚动更新(rolling updates)和缩小(downscaling)带来的影响，当处理高流量生产环境时，有下面一些事情你应该考虑。 ","date":"2021-01-14","objectID":"/flagger/:15:0","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"部署策略 Deployment strategy 在滚动更新期间限制不可用pod的数量： apiVersion:apps/v1kind:Deploymentspec:progressDeadlineSeconds:120strategy:type:RollingUpdaterollingUpdate:maxUnavailable:0 一个部署的默认的进度截止日期为十分钟。你应该考虑调整此值以使部署过程更快地失败。 ","date":"2021-01-14","objectID":"/flagger/:15:1","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"存活度健康检查 Liveness health check 你的应用程序应该公开一个http endpoint，让k8s能够调用它来检测应用是否转换为无法恢复的断开状态，并且需要重新启动。 livenessProbe:exec:command:- wget- --quiet- --tries=1- --timeout=4- --spider- http://localhost:8080/healthztimeoutSeconds:5initialDelaySeconds:5 ","date":"2021-01-14","objectID":"/flagger/:15:2","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"准备度健康检查 Readiness health check 你的应用程序应该公开一个http endpoint，让k8s可以调用它来确认应用是否准备好接收流量。 readinessProbe:exec:command:- wget- --quiet- --tries=1- --timeout=4- --spider- http://localhost:8080/readyztimeoutSeconds:5initialDelaySeconds:5periodSeconds:5 如果你的应用依赖于外部服务，在允许k8s路由流量到应用实例之前，你应该检查服务是否可用。请记住， envoy sidecar可以比应用慢得多启动。这意味着在应用程序开始时，你应该重试至少几秒钟任意外部连接。 ","date":"2021-01-14","objectID":"/flagger/:15:3","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"优雅地关闭 Graceful shutdown 在pod terminated(终止)之前，k8s发送SIGTERM信号到每个容器，并等待所有容器的一段时间(默认30s)来优雅地退出。如果你的应用不处理SIGTERM信号，或如果它不在宽限期内退出，k8s将杀死容器和任意正在处理的流量，这意味着你的应用处理将会失败。 apiVersion:apps/v1kind:Deploymentspec:template:spec:terminationGracePeriodSeconds:60containers:- name:applifecycle:preStop:exec:command:- sleep- \"10\" 你的应用应该具有延迟容器的关闭的preStop钩子。这将允许服务网格耗尽流量，并在应用不可用之前从所有其它envoy sidecar移除此pod。 ","date":"2021-01-14","objectID":"/flagger/:15:4","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"推迟envoy关闭 Delay Envoy shutdown 即使你的应用对SIGTERM信号做出反应并尝试完全在关闭之前完成请求，并不意味着响应会将结果返回给调用者。如果envoy sidecar在你的应用之前关闭，则调用者会收到503错误。 要缓解此问题，你可以将preStop钩子添加到Istio代理，并等待主应用程序在envoy之前退出。 #!/bin/bashset -eif ! pidof envoy \u0026\u003e/dev/null; thenexit 0fiif ! pidof pilot-agent \u0026\u003e/dev/null; thenexit 0fiwhile [ $(netstat -plunt | grep tcp | grep -v envoy | wc -l | xargs) -ne 0 ]; dosleep 1;doneexit 0 你必须使用上面的脚本构建你自己的envoy docker image，并使用preStop指令修改Istio来注入webhook。 ","date":"2021-01-14","objectID":"/flagger/:15:5","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"资源请求和限制 Resource requests and limits 如果你正在运行生产环境，则为所有工作负载设置CPU和MEM的请求和限制是必需的步骤。如果没有资源限制，由于CPU或MEM耗尽，你的节点可能会反应迟钝。如果没有资源请求，k8s scheduler将无法做出将pod调度到哪个节点的决定。 apiVersion:apps/v1kind:Deploymentspec:template:spec:containers:- name:appresources:limits:cpu:1000mmemory:1Girequests:cpu:100mmemory:128Mi 请注意，如果没有资源请求(requests)，hpa无法确定何时扩展你的应用程序。换句话来说，hpa是根据requests来进行伸缩的，而不是limits。 ","date":"2021-01-14","objectID":"/flagger/:15:6","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"自动伸缩 Autoscaling 生产环境应该能够处理突发流量(traffic burst)而不会影响服务质量(quality of service)。这可以通过k8s自动伸缩功能来实现。k8s的自动伸缩有亮哥维度：集群层面的节点伸缩和负载层面Pod数量自动伸缩。 apiVersion:autoscaling/v2beta2kind:HorizontalPodAutoscalerspec:scaleTargetRef:apiVersion:apps/v1kind:Deploymentname:appminReplicas:2maxReplicas:4metrics:- type:Resourceresource:name:cputargetAverageValue:900m- type:Resourceresource:name:memorytargetAverageValue:768Mi ","date":"2021-01-14","objectID":"/flagger/:15:7","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"ingress重试 Ingress retries 为了最大限度地减少缩小操作的影响，你可以利用Envoy retry功能。 apiVersion:flagger.app/v1beta1kind:Canaryspec:service:port:9898gateways:- public-gateway.istio-system.svc.cluster.localhosts:- app.example.comretries:attempts:10perTryTimeout:5sretryOn:\"gateway-error,connect-failure,refused-stream\" 当hpa缩小应用副本数是，用户可能会获取到503错误。上面的配置将使Envoy重试由于网关错误而失败的http请求。 ","date":"2021-01-14","objectID":"/flagger/:15:8","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["devops"],"content":"推出权重 Rollout Weights: https://docs.flagger.app/tutorials/rollout-weights ","date":"2021-01-14","objectID":"/flagger/:16:0","tags":["K8s","CNCF","DevOps","GitOps","Canary","ServiceMesh"],"title":"Flagger","uri":"/flagger/"},{"categories":["cncf"],"content":"参考： docs: https://docs.helm.sh/ github: https://github.com/helm 环境： el7x86_64 helm v3.3 \r\r \r\r概述 Helm是Kubernetes生态系统中的一个软件包管理工具，主要用来管理Charts，有点类似于Ubuntu中的apt或CentOS中的yum。由go编写，是Deis公司发起的一个开源工具，有助于简化部署和管理Kubernetes应用。 在Kubernetes中，应用管理是需求最多、挑战最大的领域。Helm项目提供了一个统一软件打包方式，支持版本控制，可以大大简化Kubernetes应用分发与部署中的复杂性。 Helm Chart是用来封装 Kubernetes原生应用程序的一系列YAML文件。可以在你部署应用的时候自定义应用程序的一些 Metadata，以便于应用程序的分发。 对于应用发布者而言，可以通过 Helm 打包应用、管理应用依赖关系、管理应用版本并发布应用到软件仓库。 对于使用者而言，使用 Helm 后不用需要编写复杂的应用部署文件，可以以简单的方式在 Kubernetes 上查找、安装、升级、回滚、卸载应用程序。 The package manager for Kubernetes. Helm is the best way to find, share, and use software built for Kubernetes. 术语 Glossary: https://helm.sh/docs/glossary/ Chart Helm包涵盖了将k8s资源安装到k8s集群所需的足够多的信息。 Charts包含了Chart.yaml文件核模板，默认值(values.yaml)，以及相关依赖。 Charts开发设计了良好定义的目录结构，并打包为chart archive。 Chart Archive Chart包是被tar和gzip压缩（可选签名）的chart。 Chart Dependency(Subcharts) Chart可以依赖于其它chart。依赖有两种方式： 软依赖(soft): 如果另一个chart没有在集群中安装，chart可能会无法使用 硬依赖(hard): chart包含它所依赖的chart。（在charts/目录中） 当一个chart打包(helm package)时，所有的依赖都会和它绑定。 Chart Version 每个chart都需要版本号。 Chart.yaml chart的信息说明被存储在一个特定文件(Chart.yaml)。每个chart都必须有这个文件。 helm Helm是k8s包管理器。作为一个操作系统包管理器，使其很容易在操作系统中安装工具。Helm使得k8s集群中安装应用和资源变得异常简单。 Helm Configuration Files Helm将配置文件存储在XDG目录中。helm第一次运行，会自动生成。 Kube Config(KUBECONFIG) helm客户端通过Kube config配置文件来理解k8s集群。默认$HOME/.kube/config。 Lint Helm代码规范，规范一个chart是去验证其遵照Helm chart的标准规范和要求。Helm提供了helm lint命令。 Provenance Helm chart可以由来源文件(provenance file)提供chart的出处以及它所包含的内容。 来源文件(.prov)是Helm安全的一部分。一个来源包含chart包文件的加密哈希值，Chart.yaml数据，一个签名块。当再加上一个钥匙链(keychain)时，可为chart用户提供以下能力： 验证chart被可信第三方签名 验证chart文件没有被篡改 验证chart的元数据内容(Chart.yaml) 快速匹配chart的数据来源 Release 发行版本。chart安装之后，Helm库会创建一个release来跟踪这个安装。 单个chart可以在同一个集群中安装多次，并能创建多个不同的版本。 Release Number/Version 单个版本号可以被升级多次。通过连续技术来跟踪升级发布版本。 Rollback 每一次发布会更新chart或者配置。当生成发布历史后，一次发布也可以被 rolled back 之前的发布版本号。回滚使用helm rollback命令。 重要的是, 每一次回滚版本会生成一个新的发布版本号。 操作 版本号 install release 1 upgrade release 2 upgrade release 3 rollback 1 release 4 (但使用release 1的配置) Helm Library(SDK) Helm库（或SDK）涉及到go代码，可以直接与k8s API服务交互进行安装、升级、查询 以及移除k8s资源。 Repository Helm chart可以被存储到专用的HTTP服务器上，称之为chart仓库。 Helm客户端可以指向零个或多个chart仓库。默认没有配置仓库，可使用helm repo add添加。 Values Values 提供了一种使用您自己的信息覆盖模板默认值的方式。 Helm Chart是参数化的, 这意味着chart开发者可以在安装时显式配置。比如说，chart可以暴露username字段， 允许为服务设置一个用户名。这些可暴露的变量在Helm用语中称为values。 Values可在helm install, helm upgrage时设置。也可以在values.yaml文件中设置。 介绍 Introduction: https://helm.sh/docs/intro/ ","date":"2020-09-21","objectID":"/helm/:0:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"快速入门 Quickstart: https://helm.sh/docs/intro/quickstart/ 如何快速安装核使用Helm。 ","date":"2020-09-21","objectID":"/helm/:1:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"先决条件 Prerequisites 使用Helm的前置条件： k8s集群 建议最新k8s稳定版 kubectl 安装的安全配置(如果有的话) 安装和配置Helm 注意Helm版本对应支持的k8s版本。 ","date":"2020-09-21","objectID":"/helm/:1:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"安装 Install: https://helm.sh/docs/intro/install/ 从源码、或二进制安装Helm CLI。 从Helm项目 From The Helm Project 从二进制包: 下载特定版本包: https://github.com/helm/helm/releases 解压 添加到PATH wget https://get.helm.sh/helm-v3.3.3-linux-amd64.tar.gz tar -zxvf helm-v3.3.3-linux-amd64.tar.gz mv helm /usr/local/bin/helm 从脚本: curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 chmod 700 get_helm.sh ./get_helm.sh 从源码 git clone https://github.com/helm/helm.git cd helm make ","date":"2020-09-21","objectID":"/helm/:1:2","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"初始化Helm chart Initialize a Helm Chart Repository Helm安装好之后，你可以添加一个chart仓库。 # 添加Helm官方仓库 helm repo add stable https://kubernetes-charts.storage.googleapis.com/ # 查看安装的charts列表 helm search repo stable NAME CHART VERSION APP VERSION DESCRIPTION stable/acs-engine-autoscaler 2.2.2 2.1.1 DEPRECATED Scales worker nodes within agent pools stable/aerospike 0.2.8 v4.5.0.5 A Helm chart for Aerospike in Kubernetes stable/airflow 4.1.0 1.10.4 Airflow is a platform to programmatically autho... stable/ambassador 4.1.0 0.81.0 A Helm chart for Datawire Ambassador ","date":"2020-09-21","objectID":"/helm/:1:3","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"安装Chart Install an Example Chart 可以通过helm install命令安装chart。 helm repo update # helm install，都会创建一个新的release # 所以一个chart在同一个集群里面可以被安装多次，每一个都可以被独立的管理和升级 helm install stable/mysql --generate-name NAME: mysql-1600679719 LAST DEPLOYED: Mon Sep 21 17:15:23 2020 NAMESPACE: default STATUS: deployed REVISION: 1 NOTES: MySQL can be accessed via port 3306 on the following DNS name from within your cluster: mysql-1600679719.default.svc.cluster.local To get your root password run: MYSQL_ROOT_PASSWORD=$(kubectl get secret --namespace default mysql-1600679719 -o jsonpath=\"{.data.mysql-root-password}\" | base64 --decode; echo) To connect to your database: 1. Run an Ubuntu pod that you can use as a client: kubectl run -i --tty ubuntu --image=ubuntu:16.04 --restart=Never -- bash -il 2. Install the mysql client: $ apt-get update \u0026\u0026 apt-get install mysql-client -y 3. Connect using the mysql cli, then provide your password: $ mysql -h mysql-1600679719 -p To connect to your database directly from outside the K8s cluster: MYSQL_HOST=127.0.0.1 MYSQL_PORT=3306 # Execute the following command to route the connection: kubectl port-forward svc/mysql-1600679719 3306 mysql -h ${MYSQL_HOST} -P${MYSQL_PORT} -u root -p${MYSQL_ROOT_PASSWORD} #查看此chart的基本信息 helm show chart stable/mysql helm show all stable/mysql ","date":"2020-09-21","objectID":"/helm/:1:4","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"Releases # 查看chart发行版 helm ls NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION mysql-1600679719 default 1 2020-09-21 17:15:23.169811348 +0800 CST deployed mysql-1.6.7 5.7.30 # 列出所有部署的发行 helm list ","date":"2020-09-21","objectID":"/helm/:1:5","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"卸载Release 使用helm uninstall命令卸载realease。 helm uninstall mysql-1600679719 release \"mysql-1600679719\" uninstalled 它会删除和该release相关的所有资源。使用--keep-history选项，Helm将保存release history。所以你可以审计集群历史甚至使用helm rollback回滚release。 主题 Topic Guides: https://helm.sh/docs/topics/ ","date":"2020-09-21","objectID":"/helm/:1:6","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"Charts Charts: https://helm.sh/docs/topics/charts/ Helm使用的包格式称为charts。chart就是一个描述k8s相关资源的文件集合。单个chart可以用来部署简单或复杂的服务。 Chart是作为特定目录布局的文件被创建，它们可以打包到要部署的版本存档中。 # 下载一个chart，但不安装 helm pull xxx ","date":"2020-09-21","objectID":"/helm/:2:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"文件结构 chart是一个组织在文件目录中的集合。目录名称就是chart名称(没有版本信息)。 示例: wordpress/ Chart.yaml # 包含了chart信息的YAML文件 LICENSE # 可选: 包含chart许可证的纯文本文件 README.md # 可选: 可读的README文件 values.yaml # chart 默认的配置值 values.schema.json # 可选: 一个使用JSON结构的values.yaml文件 charts/ # 包含chart依赖的其他chart crds/ # 自定义资源的定义 templates/ # 模板目录， 当和values 结合时，可生成有效的Kubernetes manifest文件 templates/NOTES.txt # 可选: 包含简要使用说明的纯文本文件 ","date":"2020-09-21","objectID":"/helm/:2:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"Chart.yaml Chart.yaml文件是chart必须的。包含以下字段。 apiVersion:chart API 版本 （必需）name:chart名称 （必需）version:语义化2 版本（必需）kubeVersion:兼容Kubernetes版本的语义化版本（可选）description:一句话对这个项目的描述（可选）type:chart类型 （可选）keywords:- 关于项目的一组关键字（可选）home:项目home页面的URL （可选）sources:- 项目源码的URL列表（可选）dependencies:# chart 必要条件列表 （可选）- name:chart名称 (nginx)version:chart版本 (\"1.2.3\")repository:仓库URL (\"https://example.com/charts\") 或别名 (\"@repo-name\")condition:（可选） 解析为布尔值的yaml路径，用于启用、禁用chart (e.g. subchart1.enabled )tags:# （可选）- 用于一次启用/禁用 一组chart的tagenabled:（可选） 决定是否加载chart的布尔值import-values:# （可选）- ImportValue 保存源值到导入父键的映射。每项可以是字符串或者一对子/父列表项alias:（可选） chart中使用的别名。当你要多次添加相同的chart时会很有用maintainers:# （可选）- name:维护者名字 （每个维护者都需要）email:维护者邮箱 （每个维护者可选）url:维护者URL （每个维护者可选）icon:用做icon的SVG或PNG图片URL （可选）appVersion:包含的应用版本（可选）。不需要是语义化的deprecated:不被推荐的chart （可选，布尔值）annotations:example:按名称输入的批注列表 （可选）. Chart和版本控制 每个chart都必须有版本号。版本必须遵循SemVer2标准。 # nginx chart的版本字段version: 1.2.3 # 按照名称设置为 nginx-1.2.3.tgz Chart.yaml文件中的version字段被很多Helm工具使用。当生成一个包时，helm package命令可以用Chart.yaml文件中找到的版本号作为包名的token。系统假设chart包名中的版本号可以与Chart.yaml文件中的版本号匹配。如果不满足这一假设会导致错误。 apiVersion字段 对于至少需要Helm3的chart，apiVersion字段应该是v2。 kubeVersion字段 可选的kubeVersion字段可以在支持的k8s版本上定义语义约束，Helm 在安装chart时会验证这个版本约束， 并在集群运行不支持的k8s版本时显示失败。 版本约束可以包含空格、比较操作符、逻辑操作符。 \u003e= 1.13.0 \u003c 1.15.0 \u003e= 1.13.0 \u003c 1.14.0 || \u003e= 1.14.1 \u003c 1.15.0 1.1 - 2.3.4 deprecated字段 在Chart仓库管理chart时，有时需要废弃一个chart。deprecated字段可用来标记已弃用的chart。如果latest版本被标记为已弃用，则所有的chart都会被认为是已弃用的。以后可以通过发布未标记为已弃用的新版本来重新使用chart名称。 kubernetes/charts项目遵循的弃用charts的流程为： 升级chart的Chart.yaml文件，将这个文件标记为已弃用，并更改版本 在chart仓库中发布新版的chart 从源仓库中移除这个chart type字段 type字段定义了chart的类型。有两种类型： application：默认类型，是可以完全操作的标准chart。 library：不能安装，提供针对chart构建的实用程序和功能。通常不包含任何资源对象。 应用类型chart 可以作为库类型chart使用。可以通过将类型设置为library来实现。 然后这个库就被渲染成了一个库类型chart，所有的实用程序和功能都可以使用。所有的资源对象不会被渲染。 ","date":"2020-09-21","objectID":"/helm/:2:2","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"许可证和描述 Chart LICENSE, README and NOTES Chart也可以包含描述安装、配置和使用的文件，以及chart许可证。 LICENSE是一个包含了chart license的纯文本文件。chart可以包含一个许可证，因为在模板里不只是配置，还可能有编码逻辑。如果需要，还可以为chart安装的应用程序提供单独的许可证。 README自述文件，一般包含： chart提供的应用或服务的描述 运行chart的先决条件或要求 values.yaml的可选项和默认值的描述 与chart的安装或配置相关的其它信息 chart也会包含一个简短的纯文本templates/NOTES.txt文件，这会在安装后及查看版本状态时打印出来。由于此文件是在运行helm install或helm status时打印到STDOUT的，因此建议保持内容简短，并指向自述文件以获取更多详细信息。 ","date":"2020-09-21","objectID":"/helm/:2:3","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"依赖 Chart Dependencies Helm中，chart可能会依赖其它任意个chart。这些依赖可使用dependencies字段(Chart.yaml)动态链接，或写入charts/目录。 dependencies字段 当前chart依赖的其它chart会在dependencies字段定义为一个列表。 dependencies:- name:apacheversion:1.2.3repository:https://example.com/charts- name:mysqlversion:3.2.1repository:https://another.example.com/charts 必须使用helm repo add在本地添加仓库。 一旦你定义好了依赖，运行helm dependency update就会使用你的依赖文件下载所有你指定的chart到你的charts/目录。 alias字段 为依赖chart添加一个别名，会使用别名作为新依赖chart的名称。 需要使用其他名称访问chart时可以使用alias。 dependencies: - name: subchart repository: http://localhost:10191 version: 0.1.0 alias: new-subchart-1 - name: subchart repository: http://localhost:10191 version: 0.1.0 alias: new-subchart-2 - name: subchart repository: http://localhost:10191 version: 0.1.0 tags和condition字段 dependencies:- name:subchart1repository:http://localhost:10191version:0.1.0condition:subchart1.enabled, global.subchart1.enabledtags:- front-end- subchart1- name:subchart2repository:http://localhost:10191version:0.1.0condition:subchart2.enabled,global.subchart2.enabledtags:- back-end- subchart2 #values.yamlsubchart1:enabled:truetags:front-end:falseback-end:true # 可以在CLI使用--set参数来设置标签和条件值 helm install --set tags.front-end=true --set subchart2.enabled=false 通过依赖导入sub values 在某些情况下，允许子chart的值作为公共默认传递到父chart中是值得的。 # parent's Chart.yaml filedependencies:- name:subchartrepository:http://localhost:10191version:0.1.0import-values:- data # child's values.yaml fileexports:data:myint:99 通过charts目录手动管理依赖 如果对依赖进行更多控制，通过将有依赖关系的chart复制到charts/目录中来显式表达这些依赖关系。 要将依赖放入charts/目录，使用helm pull命令。 ","date":"2020-09-21","objectID":"/helm/:2:4","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"Templates and Values Helm Chart模板是按照Go模板语言书写。让我想起了Django模板语言，Jinja2模板语言。 所有模板语言存放在chart的templates/目录下。当Helm渲染chart时，它会通过模板引擎遍历目录中的每个文件。 模板的Value通过两种方式提供： 通过values.yaml文件提供，此文件包含了默认值。 用户可以提供一个包含value的yaml文件，在helm install时使用它。 当用户提供自定义的value时，会覆盖values.yaml中的值。 模板文件示例 apiVersion: v1 kind: ReplicationController metadata: name: deis-database namespace: deis labels: app.kubernetes.io/managed-by: deis spec: replicas: 1 selector: app.kubernetes.io/name: deis-database template: metadata: labels: app.kubernetes.io/name: deis-database spec: serviceAccount: deis-database containers: - name: deis-database image: {{ .Values.imageRegistry }}/postgres:{{ .Values.dockerTag }} imagePullPolicy: {{ .Values.pullPolicy }} ports: - containerPort: 5432 env: - name: DATABASE_STORAGE value: {{ default \"minio\" .Values.storage }} 预定义的Values 以下值是预定义的，对每个模板都有效，并且可以被覆盖。和所有值一样，名称 区分大小写： Release.Name: 版本名称(非chart的) Release.Namespace: 发布的chart版本的命名空间 Release.Service: 组织版本的服务 Release.IsUpgrade: 如果当前操作是升级或回滚，设置为true Release.IsInstall: 如果当前操作是安装，设置为true Chart: Chart.yaml的内容。因此，chart的版本可以从Chart.Version获得， 并且维护者在Chart.Maintainers里 Files：chart中的包含了非特殊文件的类图对象 Capabilities: 包含了Kubernetes版本信息的类图对象 范围 Scope, Dependencies, and Values Values文件可以声明顶级chart的值，以及charts/目录中包含的其他任意chart。 全局Values Helm支持特殊的global值。 global:app:MyWordPress 这个值以.Values.global.app在所有chart中有效。 架构文件 有时候，chart容器可能想基于它们的values值定义一个结构，这可以在values.schema.json文件中定义一个架构实现。 示例： { \"$schema\": \"https://json-schema.org/draft-07/schema#\", \"properties\": { \"image\": { \"description\": \"Container Image\", \"properties\": { \"repo\": { \"type\": \"string\" }, \"tag\": { \"type\": \"string\" } }, \"type\": \"object\" }, \"name\": { \"description\": \"Service name\", \"type\": \"string\" }, \"port\": { \"description\": \"Port\", \"minimum\": 0, \"type\": \"integer\" }, \"protocol\": { \"type\": \"string\" } }, \"required\": [ \"protocol\", \"port\" ], \"title\": \"Values\", \"type\": \"object\" } 这个架构会应用values值并验证它。当执行以下任意命令时会进行验证： helm install, helm upgrage, helm lint, helm template。 ","date":"2020-09-21","objectID":"/helm/:2:5","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"用户自定义资源 Custom Resource Definitions k8s提供了一种声明k8s新类型对象的机制。使用CustomResourceDefinition（CRD），k8s开发者可以声明自定义资源类型。 Helm3中，CRD被视为一种特殊的对象。它们被安装在chart的其他部分之前，并受到一些限制。 CRD YAML文件应被放置在chart的crds/目录中。 多个CRD(用YAML的开始---和结束符...分隔)可以被放置在同一个文件中。Helm会尝试加载CRD目录中所有的文件到k8s。 当Helm安装新chart时，会上传CRD，暂停安装直到CRD可以被API服务使用，然后启动模板引擎， 渲染chart其他部分，并上传k8s。 CRD的限制 不像大部分k8s对象，CRD是全局安装的。因此Helm管理CRD时会采取非常谨慎的方式。 CRD受到以下限制： CRD从不重新安装。 如果Helm确定crds/目录中的CRD已经存在（忽略版本），Helm不会安装或升级。 CRD从不会在升级或回滚时安装。Helm只会在安装时创建CRD。 CRD从不会被删除。自动删除CRD会删除集群中所有命名空间中的所有CRD内容。因此Helm不会删除CRD。 希望升级或删除CRD的操作员应该谨慎地手动执行此操作。 ","date":"2020-09-21","objectID":"/helm/:2:6","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"管理chart Using Helm to Manage Charts helm工具有一些命令用来处理chart。 # 创建新chart helm create mychart # 打包 helm package mychart # 格式信息 helm lint mychart ","date":"2020-09-21","objectID":"/helm/:2:7","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"仓库 Chart Repositories 当helm用来管理本地chart目录时， 共享chart时，首选的机制就是使用chart仓库。 仓库的主要特征存在一个名为index.yaml的特殊文件，文件中包含仓库提供的包的完整列表， 以及允许检索和验证这些包的元数据。 在客户端，仓库使用helm repo命令管理。然而，Helm不提供上传chart到远程仓库的工具。 这是因为这样做会给执行服务器增加大量的必要条件，也就增加了设置仓库的障碍。 ","date":"2020-09-21","objectID":"/helm/:2:8","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"Starter Packs helm create命令可以附带一个可选的--starter选项指定一个starter chart。Starter就只是普通chart，但是被放置在$XDG_DATA_HOME/helm/starters。 ","date":"2020-09-21","objectID":"/helm/:2:9","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"Hooks Chart Hooks: https://helm.sh/docs/topics/charts_hooks/ Helm提供了一个hook机制，使chart开发者在发行版(release)生命周期的特定点进行干预。你可以使用hooks做以下事情： 安装过程中，在chart载入之前载入configmap或secret。 在安装一个新chart之前，执行一个作业(job)来备份数据库，然后执行第二个作业还原数据库。 在删除一个release之气，运行一个作业，在移除之前，来优雅地取出服务轮询。 hooks工作像常规模板，但它们有特殊的注释(写在annotations下)，因此helm可以不同地使用它们。本章节，我们将介绍hooks的基本使用模式。 annotations:\"helm.sh/hook\": post-install ","date":"2020-09-21","objectID":"/helm/:3:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"可用的hooks Annotation Value Description pre-install - 模板渲染之后执行，但在k8s创建任何资源之前 post-install - 所有资源载入k8s后执行 pre-delete - 在从k8s删除任意资源前，执行一个删除请求 post-delete - 在所有release的资源被删除后，执行一个删除请求 pre-upgrade - 在模板渲染后，执行一个升级请求，但在任意资源升级之前 post-upgrade - 在所有资源都升级后，执行一个升级 pre-rollback - 在模板渲染后，执行一个回滚请求，但在任意资源回滚前 post-rollback - 在所有资源都被修改后，执行一个回滚请求 test - 当heml test子命令调用时执行 ","date":"2020-09-21","objectID":"/helm/:3:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"测试 Chart Tests: https://helm.sh/docs/topics/chart_tests/ chart包含许多k8s资源和协同工作的组件。作为包作者，你可能想编写一个测试，来验证包安装时是否如预期那样工作。 helm chart中的测试位于templates/目录下，是一个作业(job)定义，指定一个容器运行特定的命令。容器成功退出(exit 0)，被认为测试成功。作业定义必须包含helm.sh/hook: test的注释。 示例测试： 验证values.yaml文件被正确配置 验证服务、负载均衡正常 等等 可在helm中运行预定义测试，在release上使用helm test \u003cRELEASE_NAME\u003e命令。对于包的使用者，这是一个检测release of chart工作正常的方式。 ","date":"2020-09-21","objectID":"/helm/:4:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"示例 Example Test helm repo add bitnami https://charts.bitnami.com/bitnami helm pull bitnami/wordpress --untar wordpress/ Chart.yaml README.md values.yaml charts/ templates/ templates/tests/test-mariadb-connection.yaml templates/tests/test-mariadb-connection.yaml的内容： {{- if .Values.mariadb.enabled }}apiVersion:v1kind:Podmetadata:name:\"{{ .Release.Name }}-credentials-test\"annotations:\"helm.sh/hook\": testspec:containers:- name:{{.Release.Name }}-credentials-testimage:{{template \"wordpress.image\" . }}imagePullPolicy:{{.Values.image.pullPolicy | quote }}{{- if .Values.securityContext.enabled }}securityContext:runAsUser:{{.Values.securityContext.runAsUser }}{{- end }}env:- name:MARIADB_HOSTvalue:{{template \"mariadb.fullname\" . }}- name:MARIADB_PORTvalue:\"3306\"- name:WORDPRESS_DATABASE_NAMEvalue:{{default \"\" .Values.mariadb.db.name | quote }}- name:WORDPRESS_DATABASE_USERvalue:{{default \"\" .Values.mariadb.db.user | quote }}- name:WORDPRESS_DATABASE_PASSWORDvalueFrom:secretKeyRef:name:{{template \"mariadb.fullname\" . }}key:mariadb-passwordcommand:- /bin/bash- -ec- |mysql --host=$MARIADB_HOST --port=$MARIADB_PORT --user=$WORDPRESS_DATABASE_USER --password=$WORDPRESS_DATABASE_PASSWORDrestartPolicy:Never{{- end }} 运行测试: helm install quirky-walrus wordpress --namespace default helm test quirky-walrus 注意： 你可以在templates/目录下定义许多测试 你可以嵌套你的测试\u003cchart-name\u003e/templates/tests/ 一个测试就是一个helm hook ","date":"2020-09-21","objectID":"/helm/:4:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"Library Library Charts: https://helm.sh/docs/topics/library_charts/ A library chart is a type of Helm chart，定义chart可通过helm模板在其它charts中共享。 ","date":"2020-09-21","objectID":"/helm/:5:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"完整性校验 Helm Provenance and Integrity: https://helm.sh/docs/topics/provenance/ helm有来源工具，帮助chart user验证包的来源和完整性。使用基于行业标准的PIK, GnuPG等备受推崇的包管理器，Helm 可以生成和验证签名文件。 # 生成 helm package --sign ... helm package --sign --key 'John Smith' --keyring path/to/keyring.secret mychart # 校验 helm install --verify helm verify mychart-0.1.0.tgz helm install --generate-name --verify mychart-0.1.0.tgz ","date":"2020-09-21","objectID":"/helm/:6:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"仓库 Chart Repository: https://helm.sh/docs/topics/chart_repository/ 官方的chart repo由Kubernetes Charts项目维护。欢迎各位参与。Helm也使得创建和运行自己的chart repo变得很容易。 ","date":"2020-09-21","objectID":"/helm/:7:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"创建仓库 Create a chart repository: https://helm.sh/docs/topics/chart_repository/ 一个chart repo是一个HTTP服务器，它容纳了一个index.yaml文件和一些包。当你准备好分享你的charts，方法是将它们上传到一个chart repository。你可以使用GCS, S3, GitHub Pages等来创建你自己的web服务器。 ","date":"2020-09-21","objectID":"/helm/:7:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"注册中心 Registries: https://helm.sh/docs/topics/registries/ Helm 3 支持OCI用于包分发。 Chart包可以通过基于OCI的注册中心存储和分发。 # 激活对OCI的支持 export HELM_EXPERIMENTAL_OCI=1 # 运行一个注册中心 docker run -dp 5000:5000 --restart=always --name registry registry # 认证 htpasswd -cB -b auth.htpasswd myuser mypass docker run -dp 5000:5000 --restart=always --name registry \\ -v $(pwd)/auth.htpasswd:/etc/docker/registry/auth.htpasswd \\ -e REGISTRY_AUTH=\"{htpasswd: {realm: localhost, path: /etc/docker/registry/auth.htpasswd}}\" \\ registry # 登录 helm registry login -u myuser localhost:5000 # 注销 helm registry logout localhost:5000 # 保存 helm chart save mychart/ localhost:5000/myrepo/mychart:2.7.0 # 查看 helm chart list # 导出 helm chart export localhost:5000/myrepo/mychart:2.7.0 # 推送到远程 helm chart push localhost:5000/myrepo/mychart:2.7.0 # 从缓存中移除 helm chart remove localhost:5000/myrepo/mychart:2.7.0 # 从远程拉取 helm chart pull localhost:5000/myrepo/mychart:2.7.0 使用上述命令存储的chart会被缓存到文件系统中。OCI 镜像设计规范 严格遵守文件系统布局的。如： tree ~/Library/Caches/helm/ └── registry ├── cache │ ├── blobs │ │ └── sha256 │ │ ├── 1b251d38cfe948dfc0a5745b7af5ca574ecb61e52aed10b19039db39af6e1617 │ │ ├── 31fb454efb3c69fafe53672598006790122269a1b3b458607dbe106aba7059ef │ │ └── 8ec7c0f2f6860037c19b54c3cfbab48d9b4b21b485a93d87b64690fdb68c2111 │ ├── index.json │ ├── ingest │ └── oci-layout └── config.json ","date":"2020-09-21","objectID":"/helm/:8:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"架构 Helm Architecture: https://helm.sh/docs/topics/architecture/ 介绍Helm在高级别的架构。 ","date":"2020-09-21","objectID":"/helm/:9:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"目的 The Purpose of Helm Helm是管理称为chart的k8s包的工具。Helm可以做以下事情： 从头开始创建一个新的charts packages charts为归档(tgz) chart文件 与chart repo交互，并存储在那 安装和卸载charts到k8s集群 管理已安装的charts的发行版 对于Helm，有三个重要的概念： chart是创建一个k8s应用实例所需的信息束 config包含配置信息，可以合并到package chart来创建一个可发行的对象 release是一个运行的chart实例，包含特定的配置 ","date":"2020-09-21","objectID":"/helm/:9:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"组件 Components Helm被实现为两个不同部分来执行： Helm CLI客户端，负责以下事情： 本地chart开发 管理repo 管理release 与Helm Library接口 发送chart安装 请求升级或卸载releases Helm Library提供了执行所有helm操作的逻辑。与k8s API接口交互，并提供以下功能： 组合chart和配置来构建一个release 安装chart到k8s，并提供release对象 通过与k8s交互，升级和卸载chart ","date":"2020-09-21","objectID":"/helm/:9:2","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"实现 Implementation Helm client和library由go编写。library使用k8s client与k8s集群通信。目前，library使用REST+JSON。它存储信息在k8s内的secrets里，不需要自己的数据库。配置文件以YAML编写。 ","date":"2020-09-21","objectID":"/helm/:9:3","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"高级技术 Advanced Helm Techniques: https://helm.sh/docs/topics/advanced/ ","date":"2020-09-21","objectID":"/helm/:10:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"后置渲染 Post Rendering ","date":"2020-09-21","objectID":"/helm/:10:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"GO SDK ","date":"2020-09-21","objectID":"/helm/:10:2","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"后端存储 Storage backends ","date":"2020-09-21","objectID":"/helm/:10:3","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"RBAC Role-based Access Control: https://helm.sh/docs/topics/rbac/ k8s rbac: https://kubernetes.io/docs/reference/access-authn-authz/rbac/ 介绍Helm如何与k8s RBAC进行交互。 在k8s中，授权角色给特定用户或应用的服务账号(service account)，以确保应用程序的操作在特定范围内。从k8s v1.6开始，RBAC默认启用。 使用RBAC，你可以： 授权特权操作给管理员 限制用户在特定命名空间/集群范围创建资源的能力 限制用户在特定命名空间/集群范围内查看资源的能力 ","date":"2020-09-21","objectID":"/helm/:11:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"管理用户账户 Managing user accounts 所有的k8s集群有两种类型的用户： service accounts managed by Kubernetes normal users 普通用户假定由外部进行管理，独立的服务。管理员分发私钥，用户存储密码，甚至是用户名密码列表这样的文件。在这方面，k8s不具有代表普通用户账户的对象。普通用户无法通过API调用被添加到集群。 相比之下，服务账号是由k8s API管理的用户。它们被绑定到特定的命名空间，通过API server自动创建，或通过API调用手动创建。服务账号绑定在一组凭据里，存储为secret，它被挂载到pod，允许集群内进程与k8s API进行交谈。 API请求被绑定到任何一个用户（普通用户、服务账号），或者被视为匿名请求。这意味着集群内或集群外的每一个进程，从工作站上输入kubectl的人类用户，到节点上的kubelets，到控制面板的成员，在进行请求API server时必须进行认证，或被视为匿名用户。 ","date":"2020-09-21","objectID":"/helm/:11:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"角色、集群角色、角色绑定、集群角色绑定 Roles, ClusterRoles, RoleBindings, and ClusterRoleBindings 在k8s中，用户账户和服务账户只能够根据授权访问来查看和修改资源。这种授权是通过使用角色(Roles)和角色绑定(RoleBindings)。角色和角色绑定被绑定到特定的命名空间，它通过角色提供授权，授予用户在此命名空间内查看或修改资源的能力。 在集群范围内，这些被称为集群角色(ClusterRoles)和集群角色绑定(ClusterRoleBindings)。授权用户集群角色，允许它们访问和修改整个集群的资源。这也需要查看和修改集群范围(命名空间，资源配额，节点)的资源。 集群角色可通过角色绑定的引用来绑定到特定的命名空间。admin, edit, view是最常使用的默认集群角色。 k8s有一些默认的集群角色可用，它们的本意是面向用户的角色。它们包含超级角色(cluster-admin)，和细粒度访问的角色(admin, edit, view)。 Default ClusterRole Default ClusterRoleBinding 描述 cluster-admin system:masters group 允许超级用户访问对任意资源执行任意动作。 admin None 允许管理员访问，在命名空间内使用角色绑定来授权。如读写命名空间内的大部分资源，包括在命名空间内创建角色和角色绑定的能力。但不允许对资源配额或命名空间进行写操作。 edit None 允许在命名空间内读取大多数对象的权限，不允许查看或修改角色和角色绑定 view None 允许在命名空间内查看大多数对象的权限。不允许查看角色和角色绑定。不允许查看secrets。 ","date":"2020-09-21","objectID":"/helm/:11:2","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"限制用户账户使用RBAC访问 Restricting a user account access using RBAC 现在让我们了解基于角色的访问控制的基础知识，让我们讨论管理员如何限制用户的访问范围。 示例：授予用户命名空间范围的读写权限 Grant a user read/write access to a particular namespace 要限制用户对特定命名空间的读写权限，可以使用edit或admin角色。 此外，你还可以使用cluster-admin来创建一个角色绑定。授予在命名空间范围内的cluster-admin来提供在此命名空间内完整控制资源的权限，包含命名空间自身。 # 创建ns kubectl create namespace foo #创建RoleBinding kubectl create rolebinding sam-edit --clusterrole edit \\ --user sam \\ --namespace foo 示例：授予用户集群范围的读写权限 Example: Grant a user read/write access at the cluster scope 如果用户希望安装chart，在集群范围内安装集群资源（ns, roles, crd…），它们将需要集群范围的写权限。要这样做，授予用户admin或cluster-admin角色权限。 kubectl create clusterrolebinding sam-view --clusterrole view \\ --user sam kubectl create clusterrolebinding sam-secret-reader --clusterrole secret-reader \\ --user sam 示例：授予用户命名空间范围的只读权限 Example: Grant a user read-only access to a particular namespace 你可能注意到了，没有查看secret的集群角色。view集群角色没有授予用户访问secret的权限。然而，Helm默认将release metadata存储为secret。 为了使用户运行helm list，它需要读取这些secrets。为此，我们将创建一个特殊的secret-reader集群角色。 # cluster-role-secret-reader.yamlapiVersion:rbac.authorization.k8s.io/v1kind:ClusterRolemetadata:name:secret-readerrules:- apiGroups:[\"\"]resources:[\"secrets\"]verbs:[\"get\",\"watch\",\"list\"] kubectl create -f clusterrole-secret-reader.yaml kubectl create namespace foo kubectl create rolebinding sam-view --clusterrole view \\ --user sam \\ --namespace foo kubectl create rolebinding sam-secret-reader --clusterrole secret-reader \\ --user sam \\ --namespace foo 示例：授予用户集群范围的只读权限 Example: Grant a user read-only access at the cluster scope 如果用户想运行helm l ist --all-namespaces命令，API需要用户拥有集群范围内的读权限。 kubectl create clusterrolebinding sam-view --clusterrole view \\ --user sam kubectl create clusterrolebinding sam-secret-reader --clusterrole secret-reader \\ --user sam ","date":"2020-09-21","objectID":"/helm/:11:3","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"插件 The Helm Plugins Guide: https://helm.sh/docs/topics/plugins/ Helm plugin是一个可通过helm CLI访问的工具，但不是内置的helm基础代码的一部分。 ","date":"2020-09-21","objectID":"/helm/:12:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"V2迁移到V3 Migrating Helm v2 to v3: https://helm.sh/docs/topics/v2_v3_migration/ ","date":"2020-09-21","objectID":"/helm/:13:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"弃用的k8s api Deprecated Kubernetes APIs: https://helm.sh/docs/topics/kubernetes_apis/ ","date":"2020-09-21","objectID":"/helm/:14:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"版本支持 Helm Version Support Policy: https://helm.sh/docs/topics/version_skew/ ","date":"2020-09-21","objectID":"/helm/:15:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"SQL存储后端的权限管理 Permissions management for SQL storage backend: https://helm.sh/docs/topics/permissions_sql_storage_backend/ 最佳实践 The Chart Best Practices Guide: https://helm.sh/docs/chart_best_practices/ 涵盖了Helm团队对创建chart的最佳做法。它侧重于chart应该如何构造。主要关注那些可能会公开部署的charts的最佳实践。 ","date":"2020-09-21","objectID":"/helm/:16:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"一般约定 General Conventions: https://helm.sh/docs/chart_best_practices/conventions/ ","date":"2020-09-21","objectID":"/helm/:17:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"chart名称 Chart Names chart名称必须是小写字母和数字，可用-隔开。 chart目录必须与chart名称相同。 # 示例 drupal nginx-lego aws-cluster-autoscaler nginx-lego nginx-lego/ ","date":"2020-09-21","objectID":"/helm/:17:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"版本号 Version Numbers 只要有可能，Helm使用SemVer2来表示版本号。请注意，Docker image tag并不一定遵循SemVer，注意。 ","date":"2020-09-21","objectID":"/helm/:17:2","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"格式化YAML Formatting YAML YAML应该使用两个空格（别使用tab）。 ","date":"2020-09-21","objectID":"/helm/:17:3","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"词 Usage of the Words Helm and Chart Helm词的一些约定： Helm指作为一个整体的项目 helm客户端CLI chart不需要大写，它不是专有名词 Chart.yaml需要大写，因为该文件名是大小写敏感的 ","date":"2020-09-21","objectID":"/helm/:17:4","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"值 Values: https://helm.sh/docs/chart_best_practices/values/ 提供给你如何组织和设计chart的values.yaml文件，并使用你的值。 ","date":"2020-09-21","objectID":"/helm/:18:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"命名约定 Naming Conventions 变量名必须小写字母开头，使用驼峰分开： chicken: true chickenNoodleSoup: true 请注意，所有Helm内置变量以大写字母开头，用户可以轻松区分开: .Release.Name .Capabilities.KubeVersion ","date":"2020-09-21","objectID":"/helm/:18:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"嵌套值 YAML是一种灵活的格式，值可以被深度嵌套。 server: name: nginx port: 80 {{ if .Values.server }} {{ default \"none\" .Values.server.name }} {{ end }} ","date":"2020-09-21","objectID":"/helm/:18:2","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"使类型清晰 Make Types Clear # YAM的类型强制规则有时是反直觉的。例如一下两者是不同的foo:falsefoo:\"false\"# 避免类型转化错误的最简单的方法是要明确字符串和隐含的一切。使用引号引用字符串# 要避免整数转换错误，将整数存储为字符串，使用以下方法来获取整数值{{int $value }}# 在大多数情况下，显式类型标签被尊重。如以下1234被当作字符串foo:!!string1234 ","date":"2020-09-21","objectID":"/helm/:18:3","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"考虑用户如何使用你的值 Consider How Users Will Use Your Values 值有三个来源： values.yaml文件 helm install -f或helm upgrade -f时指定的文件里 --set或--set-string选项指定 当设计值的组织结构时，用户是希望可通过-f或--set选项来覆盖它们。YAML建议写成映射(mapping)，便于替换--set servers.foo.port=80。 servers: foo: port: 80 bar: port: 81 ","date":"2020-09-21","objectID":"/helm/:18:4","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"values.yaml 每个在values.yaml中定义的属性应该被记录(documented)。文档字符串应该用它描述的属性的名称开始，然后给出至少一个单句描述。 # serverHost is the host name for the webserverserverHost:example# serverPort is the HTTP listener port for the webserverserverPort:9191 ","date":"2020-09-21","objectID":"/helm/:18:5","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"模板 Templates: https://helm.sh/docs/chart_best_practices/templates/ ","date":"2020-09-21","objectID":"/helm/:19:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"templates目录架构 Structure of templates/ templates/目录应该是如下结构： 模板文件是.yaml扩展的YAML输出。.tpl扩展可用于未经格式化的模板文件 模板文件名应使用虚线(example-configmap.yaml)，而不是驼峰 每个资源定义应该有自己的模板文件 模板文件应放映资源类型（如foo-pod.yaml, bar-svc.yaml） ","date":"2020-09-21","objectID":"/helm/:19:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"定义的模板的名称 Names of Defined Templates 定义的模板(模板文件内的{{ define }})是全局访问的。这意味着，chart和它的subchart可以访问所有{{ define }}创建的模板。这样我想起了Pythond的模板语言（Django模板语言，Jinja2等等）。 出于此原因，所有定义的模板名称都应该命名空间。 {{- define \"nginx.fullname\" }} {{/* ... */}} {{ end -}} It is highly recommended that new charts are created via helm create command as the template names are automatically defined as per this best practice. ","date":"2020-09-21","objectID":"/helm/:19:2","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"格式化模板 Formatting Templates 模板应该使用两个空格，而不是tab。花括号前后应该有空格。有适当的空格和缩进。 {{ .foo }} {{ print \"foo\" }} {{- print \"bar\" -}} {{ if $foo -}} {{- with .Bar }}Hello{{ end -}} {{- end -}} ","date":"2020-09-21","objectID":"/helm/:19:3","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"生成模板中的空格 Whitespace in Generated Templates 优选的是，保持在生成的模板中的空格数量降到最低。特别是，许多空行不应出现彼此相邻。但偶尔空行还是可以的。 # This is bestapiVersion:batch/v1kind:Jobmetadata:name:examplelabels:first:firstsecond:second# This is okayapiVersion:batch/v1kind:Jobmetadata:name:examplelabels:first:firstsecond:second ","date":"2020-09-21","objectID":"/helm/:19:4","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"注释 Comments (YAML Comments vs Template Comments) YAML文件注释和模板注释。当一个模板记录功能时，应该使用模板注释。当Helm用户通过查看注释调试时，在模板内应该使用YANML注释。 # yaml 注释 {{- /* 模板注释 */ -}} {{- /* mychart.shortname provides a 6 char truncated version of the release name. */ -}} {{ define \"mychart.shortname\" -}} {{ .Release.Name | trunc 6 }} {{- end -}} # This may cause problems if the value is more than 100Gi memory: {{ .Values.maxMem | quote }} ","date":"2020-09-21","objectID":"/helm/:19:5","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"在模板和模板输出中使用JSON Use of JSON in Templates and Template Output YAML是JSON的超集(superset)。在一些情况下，使用JSON语法可比其它YAML表示更具有可读性。 # 列表 # yaml arguments: - \"--dirname\" - \"/foo\" # json arguments: [\"--dirname\", \"/foo\"] ","date":"2020-09-21","objectID":"/helm/:19:6","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"依赖 Dependencies: https://helm.sh/docs/chart_best_practices/dependencies/ 介绍Chart.yaml内声明的dependencies的最佳实践。 ","date":"2020-09-21","objectID":"/helm/:20:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"版本 Versions 如果可能的化，使用版本范围，而不是某个确切的版本。建议使用补丁级别(patch-level)版本匹配: # \u003e= 1.2.3, \u003c 1.3.0 version: ~1.2.3 repo ruls，如果可能，使用HTTPS。文件URL(file://...)被认为是一个特殊，对由一个固定部署的流水线charts。 ","date":"2020-09-21","objectID":"/helm/:20:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"条件和标记 Conditions and Tags 条件或标记应被添加到任何依赖（可选的）。 # 条件的推荐格式 condition: somechart.enabled # 标记 tags: - webaccelerator ","date":"2020-09-21","objectID":"/helm/:20:2","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"标签和注释 Labels and Annotations: https://helm.sh/docs/chart_best_practices/labels/ 讨论chart中使用标签和注释的最佳实践。 ","date":"2020-09-21","objectID":"/helm/:21:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"标签还是注释 Is it a Label or an Annotation? 以下条件的元数据项应该为标签(label)： 它利用k8s来标识此资源 暴露给查询系统的目的是有用的 如果元数据的条目不用于查询，它应该设置为注释。Helm hooks总是注释。 ","date":"2020-09-21","objectID":"/helm/:21:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"标准的标签 Standard Labels 下表定义了Helm chart常用的标签。Helm自身从未要求特定的标签存在。REC的标签是建议的，并应该放置到全局一致性的chart。OPT的标签是可选的。 名称 状态 描述 app.kubernetes.io/name REC 这应该是app名称。通常使用{{ template \"name\" . }} 这由许多k8s manifests使用，不是Helm特定的 helm.sh/chart REC chart名称和版本: {{ .Chart.Name }}-{{ .Chart.Version }} app.kubernetes.io/managed-by REC 这应该始终设置为{{ .Release.Service }} app.kubernetes.io/instance REC 这应该为{{ .Release.Name }}，有助于在同意应用不同实例之间进行区分 app.kubernetes.io/version OPT 应用的版本设置为{{ .Chart.AppVersion }} app.kubernetes.io/component OPT This is a common label for marking the different roles that pieces may play in an application |app.kubernetes.io/part-of OPT 当多个charts或软件片一起使用来做一个应用 可在k8s 文档中，带有app.kubernetes.io前缀的文档中查看更多信息。 ","date":"2020-09-21","objectID":"/helm/:21:2","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"Pods和PodTemplates Pods and PodTemplates: https://helm.sh/docs/chart_best_practices/pods/ 以下资源列表使用PodTemplate： Deployment ReplicationController ReplicaSet DaemonSet StatefulSet ","date":"2020-09-21","objectID":"/helm/:22:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"镜像 Images 容器镜像应该使用确定的标记或镜像的SHA。但不应该使用latest, head, canary这样的标记。 镜像可以在values.yaml文件中定义，使其很容易替换镜像。 image: {{ .Values.redisImage | quote }} 镜像和标记可在values.yaml中被定义为分开的两个字段： image: \"{{ .Values.redisImage }}:{{ .Values.redisTag }}\" ","date":"2020-09-21","objectID":"/helm/:22:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"镜像拉取策略 ImagePullPolicy helm create默认在deployment.yaml中设置imagePullPolicy为IfNotPresent。 imagePullPolicy:{{.Values.image.pullPolicy }} # values.yamlimage:pullPolicy:IfNotPresent 同样，如果未设置impagePullPolicy，k8s默认会将其设置为IfNotPresent。如果想要修改此值，只需在values.yaml文件中更新此值。 ","date":"2020-09-21","objectID":"/helm/:22:2","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"PodTemplate应该声明选择器 PodTemplates Should Declare Selectors 所有的PodTemplate部分应该指定一个选择器。示例： selector:matchLabels:app.kubernetes.io/name:MyNametemplate:metadata:labels:app.kubernetes.io/name:MyName 这是一个很好的做法，因为它使set和pod相关联。 但是，这对于像Deployment这样的集更为重要。没有这一点，整个标签集(set of labels)用于选择匹配pod，如果你使用的标签发生改变（如版本或日期），这将打破匹配。 ","date":"2020-09-21","objectID":"/helm/:22:3","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"自定义资源的定义 Custom Resource Definitions 当使用自定义资源定义(CRDs)，区分两种不同的片是很重要的： 声明一个CRD(kind: CustomResourceDefinition) 然后资源使用CRD ","date":"2020-09-21","objectID":"/helm/:23:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"使用资源前安装CRD声明 Install a CRD Declaration Before Using the Resource Helm是尽可能优化地载入更多的资源到k8s中。按照设计，k8s可以采取一整套清单(manifests)，并带它们所有上线（这就是所谓的和解循环(reconciliation loop))）。 但是，CRDs有一些不同。对于CRD，在任意CRDs类型资源被使用之前，必须先注册声明。注册过程有时需要几秒。 方法1：让helm为你做此事 Method 1: Let helm Do It For You 随着Helm3的到来，出于更简单的方法，Helm移除了旧的crd-install hooks。这在是一个称为crds的新目录，在你创建的chart的此目录下保存你的CRDs。这些CRDs没有模板，但会在chart运行helm install时默认安装。如果CRD已存在，它会被跳过。你也可以通过传递--skip-crds选项来跳过CRD的安装。 一些注意事项: 目前不支持使用Helm更新或删除CRDs。这是一个经过反复讨论的明确的决定，由于存在非故意丢失数据的危险。此外，目前社区如何处理CRDs和它的生命周期没有共识，由于这种演变，Helm将添加对这些用例的支持。 helm install和helm upgrade的--dry-run选项暂不支持CRDs。Dry Run的目的是去验证chart的输出将实际地工作，如果发送到服务器。但CRDs可通过服务器行为的修改。Helm无法在dry run上安装CRD，因此发现客户端将不知道自定义资源(CR)，并验证将失败。你可以可选地移动CRDs到它们自己的chart，或使用helm template来代替。 围绕CRD支持的另一个重要的考虑点是如何处理模板的渲染(rendering of templates)。一个在Helm2中使用crd-install方法的明显的缺点是不能正确验证chart，由于改变API可用性（一个CRD被实际添加到另一个可用API到k8s集群）。如果一个chart安装了CRD，helm不再有一组API版本的有效集。这也是在移除从CRDs的模板支持的原因。随着安装CRD的新的crds方法，我们现在确保helm有关于当前集群状态的完整信息。 方法2：独立chart Separate Charts 另一种方法是，把CRD定义在一个chart中，然后把所有资源使用的该CRD放在另一个chart。 在此方法中，每个char都必须单独安装。然而，这个工作流程可能是集群操作器(cluster operators)（对集群拥有admin权限）使用。 ","date":"2020-09-21","objectID":"/helm/:23:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"RBAC Role-Based Access Control: https://helm.sh/docs/chart_best_practices/rbac/ RBAC资源有： ServiceAccount (namespaced) Role (namespaced) ClusterRole RoleBinding (namespaced) ClusterRoleBinding ","date":"2020-09-21","objectID":"/helm/:24:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"YAML配置 RBAC和ServiceAccount配置因该在单独的密钥里。它们是不同的东西。拆分这两个概念在YAML歧义消除它们，使之更清楚。 rbac:# Specifies whether RBAC resources should be createdcreate:trueserviceAccount:# Specifies whether a ServiceAccount should be createdcreate:true# The name of the ServiceAccount to use.# If not set and create is true, a name is generated using the fullname templatename: 多个服务账号可以扩展为更复杂的charts。 someComponent: serviceAccount: create: true name: anotherComponent: serviceAccount: create: true name: ","date":"2020-09-21","objectID":"/helm/:24:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"RBAC资源应该被默认创建 RBAC Resources Should be Created by Default rbac.create应该是一个布尔值，由RBAC资源来控制创建。默认应该为true。希望管理RBAC访问控制的用户可以将此设置为false。 ","date":"2020-09-21","objectID":"/helm/:24:2","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"使用RBAC资源 Using RBAC Resources serviceAccount.name应该被设置为由chart创建的访问控制资源使用的服务账号名称。如果serviceAccount.create为true，那么此名称的服务名称应该被创建。如果此名称未设置，则使用模板fullname来生成。如果为false，则它不应该被创建，但它应该与同样的资源相关联，以便创建后引用该手动创建RBAC资源正常工作。如果为false且没有指定名称，则使用默认的服务账号。 下面的助手模板应该用于服务账号： {{/*Create the name of the service account to use*/}}{{- define \"mychart.serviceAccountName\" -}}{{- if .Values.serviceAccount.create -}}{{default (include \"mychart.fullname\" .) .Values.serviceAccount.name }}{{- else -}}{{default \"default\" .Values.serviceAccount.name }}{{- end -}}{{- end -}} 模板 Chart Template: https://helm.sh/docs/chart_template_guide/ Helm‘s chart templates，重点介绍模板语言。让我想起的Django模板语言、Jinja2模板语言。 模板生成清单文件，这是k8s可理解的YAML格式的资源描述。本章重点介绍以下概念： Helm模板语言 Values使用 使用模板的技术 ","date":"2020-09-21","objectID":"/helm/:24:3","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"入门 Getting Started: https://helm.sh/docs/chart_template_guide/getting_started/ 创建一个chart并添加一个模板。 ","date":"2020-09-21","objectID":"/helm/:25:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"Charts mychart/ Chart.yaml values.yaml charts/ templates/ ... templates/目录存放模板文件。当Helm评估一个chart，它会发送所有模板目录中的文件到模板渲染引擎。然后，它收集模板的结果，并将它们发送到k8s。 values.yaml文件对模板也很重要。此文件包含了一个chart的默认值。默认值可通过命令行选项进行覆盖。 Chart.yaml文件包含对chart包的描述信息。你可在模板中访问它。charts/目录可能包含其它chats(称为subcharts)。 ","date":"2020-09-21","objectID":"/helm/:25:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"示例 A Starter Chart # 创建一个名为mychart的chart包 helm create mychart Creating mychart # 目录结构 tree ./mychart -L 2 ./mychart ├── charts ├── Chart.yaml ├── templates │ ├── deployment.yaml │ ├── _helpers.tpl #模板助手，你可以重新使用整个chart │ ├── hpa.yaml # │ ├── ingress.yaml │ ├── NOTES.txt #chart包的帮助文本(help text)，会在运行helm install显示 │ ├── serviceaccount.yaml │ ├── service.yaml │ └── tests └── values.yaml # 创建自己的模板 rm -rf mychart/templates/* 当编写生产环境的chart包时，有这些charts包的基础版本可能很有用。 ","date":"2020-09-21","objectID":"/helm/:25:2","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"第一个模板 A First Template 创建一个ConfigMap资源的模板。由于它是一个基本的资源，因此它为我们提供了一个很好的起点。 # mychart/templates/configmap.yamlapiVersion:v1kind:ConfigMapmetadata:name:mychart-configpmapdata:myvalue:\"Hello World\" 小技巧：模板名称不遵循严格的命名模式。然而，我们建议为YAML文件使用.yaml后缀，为模板助手使用.tpl后缀。 上述YAML文件是一个最基本的ConfigMap，最有最小的必要的字段。它会通过模板引擎进行发送。 一个普通的平YAML文件是蛮好的。当Helm读取此模板，它会简单地将文件原样发送给k8s。 在这个简单的例子中，我们现在有了一个可安装的chart包。安装一下： helm install full-coral mychart NAME: full-coral LAST DEPLOYED: Sun Sep 27 10:38:03 2020 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None helm ls NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION full-coral default 1 2020-09-27 10:38:03.546664865 +0800 CST deployed mychart-0.1.0 1.16.0 helm get manifest full-coral --- # Source: mychart/templates/configmap.yaml apiVersion: v1 kind: ConfigMap metadata: name: mychart-configmap data: myvalue: \"Hello World\" kubectl get configmap NAME DATA AGE mychart-configmap 1 9m47s # 卸载 helm uninstall full-coral 添加一个简单的模板调用 Adding a Simple Template Call 硬编码的name，通常被认为是不好的做法。每个发行版的名称应该是唯一的。因此，我们可能将生成一个名称字段来写入发行版名称。 注意，由于DNS系统的限制，name字段被限制为63字符。出于这个原因，发行版名称被限制为53字符。 apiVersion:v1kind:ConfigMapmetadata:name:{{.Release.Name }}-configmapdata:myvalue:\"Hello World\" # 模板指令放置于{{ xxx }} 块内 helm install clunky-serval mychart/ NAME: clunky-serval LAST DEPLOYED: Sun Sep 27 11:16:20 2020 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None helm get manifest clunky-serval --- # Source: mychart/templates/configmap.yaml apiVersion: v1 kind: ConfigMap metadata: name: clunky-serval-configmap data: myvalue: \"Hello World\" # 可使用--debug查看详情 # 下面将渲染模板，返回渲染输出，不会真正安装 helm install --debug --dry-run goodly-guppy ./mychart 使用--dry-run将更容易对代码进行测试，但它不会保证k8s会接受你生成的模板。 ","date":"2020-09-21","objectID":"/helm/:25:3","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"内置对象 Built-in Objects: https://helm.sh/docs/chart_template_guide/builtin_objects/ 对象动模板引擎传递到模板。你的代码可以传递对象范围（如with和range）。有一些方法可在模板中创建新的对象，如tuple函数。 对象可以很简单，它只有一个值。它们也可以包含其它对象或函数。如，Realease对象可包含几个对象（如Release.Name），Files对象有一些函数。 - `Release`对象 - `Release.Name` - `Release.Namespace` - `Release.IsUpgrade` - `Release.IsInstall` - `Release.Revision` - `Release.Service`：在Helm中，总是Helm - `Values`: `values.yaml`中传递给模板的值 - `Chart`: `Chart.yaml`文件内容 - `Files`: 访问chart包中非模板的文件 - `Files.Get`: 通过名称生成文件的函数 - `Files.GetBytes` - `Files.Glob`: 返回文件为列表的函数 - `Files.Lines`: 一行行读取文件的函数 - `Files.AsSecrets`: 返回文件内容为base64编码字符串的函数 - `Files.AsConfig`: 返回文件内容为YAML map的函数 - `Capabilities` - `Capabilities.APIVersions` - `Capabilities.APIVersions.Has $version` - `Capabilities.KubeVersion`, `Capabilities.KubeVersion.Version` - `Capabilities.KubeVersion.Major` - `Capabilities.KubeVersion.Minor` - `Template` - `Template.Name` - `Template.BasePath` 内置的值总以大写字母开头。这与go命名方式保持一致。 ","date":"2020-09-21","objectID":"/helm/:26:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"值文件 Values Files: https://helm.sh/docs/chart_template_guide/values_files/ Values是一个内置的对象。它提供了访问值并传递到chart包。值文件是平YAML文件。其内容来源于多个源： chart包中的values.yaml文件 如果是一个subchart包，则为parent chart包的values.yaml文件 通过helm install/upgrade的-f myvals.yaml传递值 通过helm install/upgrade的--set foo=bar选项传递值 # values.yamlfavoriteDrink:coffee# configmap.yamlapiVersion:v1kind:ConfigMapmetadata:name:{{.Release.Name }}-configmapdata:myvalue:\"Hello World\"drink:{{.Values.favoriteDrink }} # 渲染 helm install geared-marsupi ./mychart --dry-run --debug HOOKS: MANIFEST: --- # Source: mychart/templates/configmap.yaml apiVersion: v1 kind: ConfigMap metadata: name: geared-marsupi-configmap data: myvalue: \"Hello World\" drink: coffee # 通过命令行选项覆盖值 helm install solid-vulture ./mychart --dry-run --debug --set favoriteDrink=slurm HOOKS: MANIFEST: --- # Source: mychart/templates/configmap.yaml apiVersion: v1 kind: ConfigMap metadata: name: solid-vulture-configmap data: myvalue: \"Hello World\" drink: slurm 值文件也可以包含更多结构化的内容。 # values.yamlfavorite:drink:coffeefood:pizza# configmap.yamlapiVersion:v1kind:ConfigMapmetadata:name:{{.Release.Name }}-configmapdata:myvalue:\"Hello World\"drink:{{.Values.favorite.drink }}food:{{.Values.favorite.food }} 虽然结构化数据这种方式是可行的，但建议你保持值的浅度(shallow)，有利于平整。当看到subcharts包的值时，我们将看到值是如何使用树状结构命名的。 ","date":"2020-09-21","objectID":"/helm/:26:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"删除一个默认键 Deleting a default key 如果你需要从默认值删除一个键，你可以覆盖这个键的值为null，在这种情况下，Helm将从覆盖值得合并中移除这个键。 ","date":"2020-09-21","objectID":"/helm/:26:2","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"模板函数和管道 Template Functions and Pipelines: https://helm.sh/docs/chart_template_guide/functions_and_pipelines/ 到目前为止，我们以将看到如何将信息转换为模板。但这些信息放入未修改的模板。有时候，我们希望以一种更可用的方式来转换提供的数据。 在模板指令中调用quote函数： apiVersion:v1kind:ConfigMapmetadata:name:{{.Release.Name }}-configmapdata:myvalue:\"Hello World\"drink:{{quote .Values.favorite.drink }}food:{{quote .Values.favorite.food }} 模板函数使用funcationName arg1 arg2...语法。上面的quote .Values.favorite.drink调用quote函数并传递一个参数。 Helm有超过60个可用的函数。一些通过go模板语言定义。大多数是Sprig template library的一部分。 ","date":"2020-09-21","objectID":"/helm/:27:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"管道 pipelines(|) 模板语言的一个强大功能就是它的管道(|)。管道是让几件事情依序进行的有效方式。让我们使用管道重写上面的示例： apiVersion:v1kind:ConfigMapmetadata:name:{{.Release.Name }}-configmapdata:myvalue:\"Hello World\"drink:{{.Values.favorite.drink | quote }}food:{{.Values.favorite.food | quote }} 使用管道，我们可以将多个函数链接在一起： drink:{{.Values.favorite.drink | repeat 5 | quote }}food:{{.Values.favorite.food | upper | quote }}#drink: \"coffeecoffeecoffeecoffeecoffee\"#food: \"PIZZA\" ","date":"2020-09-21","objectID":"/helm/:27:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"default函数 default函数经常在模板中使用(default DEFAULT_VALUE GIVEN_VALUE)。此函数允许你指定一个默认值。有则替换它，无则使用默认值。 drink:{{.Values.favorite.drink | default \"tea\" | quote }} 在实际的chart包中，所有静态默认值都应该位于values.yaml中，而不应该使用default重复。然而，default命令对于不能在values.yaml中声明的值，是完美的计算值的方法。例如： drink:{{.Values.favorite.drink | default (printf \"%s-tea\" (include \"fullname\" .)) }} ","date":"2020-09-21","objectID":"/helm/:27:2","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"lookup函数 lookup函数可用于在正在运行的集群中查找资源。它查找apiVersion, kind, namespace, name到resource或resource list。 # apiVersion, kind, namespace, name都是string # name, namespace两个是可选的，可以为空进行传递 # 下列将会返回mynamespace对象的注释 (lookup \"v1\" \"Namespace\" \"\" \"mynamespace\").metadata.annotations # 当lookup返回一个列表(list)对象时，可以通过items字段访问列表对象 {{ range $index, $service := (lookup \"v1\" \"Service\" \"mynamespace\" \"\").items }} {{/* do something with each service */}} {{ end }} 当没有找到对象时，则返回一个空值。这可以用于检查对象是否存在。 lookup函数使用Helm现有的k8s连接配置来查询k8s。如果调用API server进行交互时返回错误，则Helm的模板处理将失败。 请记住，Helm是不应该在helm template或helm install|update|delete|rollback --dry-run期间连接到k8s API server，因此，lookup在此情况下将会获得一个空列表。 ","date":"2020-09-21","objectID":"/helm/:27:3","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"操作符 Operators are functions 对于模板，操作符(eq, ne, lt, gt, and, or等)都被实现为函数。在管道中，操作符可使用括号()进行分组。 ","date":"2020-09-21","objectID":"/helm/:27:4","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"函数列表 Template Function List: https://helm.sh/docs/chart_template_guide/function_list/ Helm包含很多模板函数，你可以在模板中使用它们。下面按照功能列出： Cryptographic and Security Date Dictionaries Encoding File Path Kubernetes and Chart Logic and Flow Control Lists Math Network Reflection Regular Expressions Semantic Versions String Type Conversion URL UUID ","date":"2020-09-21","objectID":"/helm/:28:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"流程控制 Flow Control: https://helm.sh/docs/chart_template_guide/control_structures/ 控制结构（在模板原语中称为行动）提供给模板作者，模板生成的控制流程的能力。Helm的模板语言提供了如下控制结构： if, else：创建条件块 with：指定一个范围 range： 提供一个类似的for循环 除此之外，它为声明和使用命名模板段提供了一些动作： define：在模板内声明一个新的命名模板 template：导入一个命名的模板 block：声明一个特殊的可填写的模板区域 这些都让我想起之前用Django模板语言写前端的时候，基本上一样的原理。 ","date":"2020-09-21","objectID":"/helm/:29:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"if和else if, else块示例： {{if PIPELINE }}# Do something{{else if OTHER PIPELINE }}# Do something else{{else }}# Default case{{end }} apiVersion:v1kind:ConfigMapmetadata:name:{{.Release.Name }}-configmapdata:myvalue:\"Hello World\"drink:{{.Values.favorite.drink | default \"tea\" | quote }}food:{{.Values.favorite.food | upper | quote }}{{if eq .Values.favorite.drink \"coffee\" }}mug: true{{ end }} ","date":"2020-09-21","objectID":"/helm/:29:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"控制空格 Controlling Whitespace 虽然我们看到了条件语句，我们也应该了解模板中的空格的控制方式。这主要是确保对于生成的YAML文件的缩进的正确性。 apiVersion:v1kind:ConfigMapmetadata:name:{{.Release.Name }}-configmapdata:myvalue:\"Hello World\"drink:{{.Values.favorite.drink | default \"tea\" | quote }}food:{{.Values.favorite.food | upper | quote }}{{if eq .Values.favorite.drink \"coffee\" }}mug:true{{end }} 生成的不正确的YAML格式： # Source: mychart/templates/configmap.yamlapiVersion:v1kind:ConfigMapmetadata:name:eyewitness-elk-configmapdata:myvalue:\"Hello World\"drink:\"coffee\"food:\"PIZZA\"mug:true mug被不正确地缩进。让我们修改模板： apiVersion:v1kind:ConfigMapmetadata:name:{{.Release.Name }}-configmapdata:myvalue:\"Hello World\"drink:{{.Values.favorite.drink | default \"tea\" | quote }}food:{{.Values.favorite.food | upper | quote }}{{if eq .Values.favorite.drink \"coffee\" }}mug:true{{end }} 这样生成的YAML是有效的，但显得很滑稽： # Source: mychart/templates/configmap.yamlapiVersion:v1kind:ConfigMapmetadata:name:telling-chimp-configmapdata:myvalue:\"Hello World\"drink:\"coffee\"food:\"PIZZA\"mug:true 请注意，在YAML文件中生成了几个空行。为什么？当模板引擎运行时，它将删除花括号里的内容，但它留下的剩余空格完全一样。 YAML对空白很在意，所以管理空白变得非常重要。幸运的是，Helm有一些工具来帮助我们。 # 首先，模板声明的花括号 {{ 可以使用特殊字符进行修改，来告诉模板引擎排列空白 {{- 表示空白应靠左(chomped left) -}} 表示空白应在右边消耗(right should be consumed) # 注意，换行也是空白（Newlines are whitespace) apiVersion:v1kind:ConfigMapmetadata:name:{{.Release.Name }}-configmapdata:myvalue:\"Hello World\"drink:{{.Values.favorite.drink | default \"tea\" | quote }}food:{{.Values.favorite.food | upper | quote }}{{- if eq .Values.favorite.drink \"coffee\" }}mug:true{{- end }} # Source: mychart/templates/configmap.yaml apiVersion: v1 kind: ConfigMap metadata: name: clunky-cat-configmap data: myvalue: \"Hello World\" drink: \"coffee\" food: \"PIZZA\" mug: true 小心使用排列修改器(chomping modifier)。很容易不小心做了下面的事情： food:{{.Values.favorite.food | upper | quote }}{{- if eq .Values.favorite.drink \"coffee\" -}}mug:true{{- end -}} 这会生成food: \"PIZZA\"mug:true这样，因为它消耗了两侧的换行。 # 最后，有时很容易告诉模板系统如何缩进，而不是试图掌握模板指令的空格。 # 出于此原因，你有时可能会发现使用 indent函数 处理缩进是很有用的 {{ indent 2 \"mug: true\" }} ","date":"2020-09-21","objectID":"/helm/:29:2","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"使用with修改范围 Modifying scope using with 另一个控制结构是with动作。这可以控制变量的范围，.是指的当前范围。因此，.Values告诉模板到当前范围下去寻找Values对象。 # with语法和if语句类似{{with PIPELINE }}# restricted scope{{end }} 范围可以被更改。with可以允许你将当前范围(.)设置为特定对象。例如，我们使用.Values.favorite工作。让我们在.Values.favorite范围来重写ConfigMap： apiVersion:v1kind:ConfigMapmetadata:name:{{.Release.Name }}-configmapdata:myvalue:\"Hello World\"{{- with .Values.favorite }}drink:{{.drink | default \"tea\" | quote }}food:{{.food | upper | quote }}{{- end }} # 注意，由于我们使用 with 将范围设置在了 .Values.favorite # 所以我们使用 .drink, .food。范围在 {{ end }} 后被还原 但这里有一个值得注意的问题！在限制的范围内，你将无法从父对象范围(.)访问其它对象。以下示例会失败： {{- with .Values.favorite }}drink:{{.drink | default \"tea\" | quote }}food:{{.food | upper | quote }}release:{{.Release.Name }}{{- end }}release-2:{{.Release.Name }} 由于Release.Name没有在限制的范围(.)内，会报错。但在限制的之外就没有问题。 或者，我们可以使用$符号从父范围访问Release.Name对象。$符号在开始执行时会映射到根范围内，在模板执行时也不会改变。示例如下： {{- with .Values.favorite }}drink:{{.drink | default \"tea\" | quote }}food:{{.food | upper | quote }}release:{{$.Release.Name }}{{- end }} 在了解range后，我们会看到模板变量，它提供了一个解决上述作用域问题的方法。 ","date":"2020-09-21","objectID":"/helm/:29:3","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"range循环 Looping with the range action 许多编程语言都是用for循环，在Helm模板语言中，它使用range操作符来实现迭代。 首先，让我们在values.yaml文件里添加一个列表。 favorite:drink:coffeefood:pizzapizzaToppings:- mushrooms- cheese- peppers- onions 在我们的ConfigMap中获取值里面的列表： apiVersion:v1kind:ConfigMapmetadata:name:{{.Release.Name }}-configmapdata:myvalue:\"Hello World\"{{- with .Values.favorite }}drink:{{.drink | default \"tea\" | quote }}food:{{.food | upper | quote }}{{- end }}toppings:|-{{- ranage .Values.pizzaToppings }} - {{ . | title | quote }} {{- end }} 我们可以使用$来访问父范围内的Values.pizzaToppings。$符号映射到根目录下，并在函数执行时不会改变。示例如下: apiVersion:v1kind:ConfigMapmetadata:name:{{.Release.Name }}-configmapdata:myvalue:\"Hello World\"{{- with $.Values.favorite }}drink:{{.drink | default \"tea\" | quote }}food:{{.food | upper | quote }}toppings:|-{{- range $.Values.pizzaToppings }} - {{ .| title | quote }} {{- end }}{{- end }} 渲染示例： # Source: mychart/templates/configmap.yamlapiVersion:v1kind:ConfigMapmetadata:name:edgy-dragonfly-configmapdata:myvalue:\"Hello World\"drink:\"coffee\"food:\"PIZZA\"toppings:|-- \"Mushrooms\" - \"Cheese\" - \"Peppers\" - \"Onions\" 符号|-声明一个多行字符串。因此，实际上我们的toppings不是一个YAML list，而是一个big string。我们为什么要这样做？因为在ConfigMaps data里的数据是由键值对(k/v)组成，其中键和值都是简单的字符串。要理解为什么这样的化，请查看k8s configmap文档。 YAML里的|-符号表示一个多行字符串(multi-line string)。这可以在文件中嵌入一大块数据。 Helm模板具有一个tuple函数，来使得操作更简单。让我想起了Python中的tuple数据类型。示例如下: sizes:|-{{- range ruple \"small\" \"medium\" \"large\"}} - {{ . }} {{- end }} 结果如下： sizes:|-- small - medium - large 除了list和tuple，range还可以迭代具有有键值对的map和dict。我们将在后面的章节中了解它们。 ","date":"2020-09-21","objectID":"/helm/:29:4","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"变量 Variables: https://helm.sh/docs/chart_template_guide/variables/ 我们可以在模板中使用变量。在Helm模板中，变量是其它对象的命名引用。 apiVersion:v1kind:ConfigMapmetadata:name:{{.Releae.Name }}-configmapdata:myvalue:\"Hello World\"{{- $relname := .Release.Name -}}{{- with .Values.favorite }}drink:{{.drink | default \"tea\" | quote }}food:{{.food | upper | quote }}release:{{$relname }}{{- end }} 在with块之前，我们赋值了一个变量。在with块内，$relname变量仍然指向版本名称。 在range循环中使用变量： toppings:|-{{- range $index, $topping := .Values.pizzaToppings }} {{ $index }}: {{ $topping }} {{- end } 渲染效果： toppings:|-0: mushrooms 1: cheese 2: peppers 3: onions 有一个变量($)它永远是全局的，此变量将永远指向根上下文(root context)。放你使用range循环，并且需要知道chart的版本名称时，这非常有用。示例如下： {{- range .Values.tlsSecrets }}apiVersion:v1kind:Secretmetadata:name:{{.name }}labels:# Many helm templates would use `.` below, but that will not work,# however `$` will work hereapp.kubernetes.io/name:{{template \"fullname\" $ }}# I cannot reference .Chart.Name, but I can do $.Chart.Namehelm.sh/chart:\"{{ $.Chart.Name }}-{{ $.Chart.Version }}\"app.kubernetes.io/instance:\"{{ $.Release.Name }}\"# Value from appVersion in Chart.yamlapp.kubernetes.io/version:\"{{ $.Chart.AppVersion }}\"app.kubernetes.io/managed-by:\"{{ $.Release.Service }}\"type:kubernetes.io/tlsdata:tls.crt:{{.certificate }}tls.key:{{.key }}---{{- end }} 到目前为止，我们已看到了只在一个文件中声明的模板。但是Helm模板语言的一个强大功能是声明多个模板和使用它们。我们将在后面的章节了解到。 ","date":"2020-09-21","objectID":"/helm/:30:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"命名模板 Named Templates: https://helm.sh/docs/chart_template_guide/named_templates/ 是时候使用多个模板了。本章中，我们将在一个文件中命名模板，然后在其它地方使用它们。这让我想起了Python写Web是的模板。命名模板（有时称为子模板）是在文件中定义的一个简单的模板。有两种方法来创建它，有几种不同的方法来使用它。 在流程控制(flow control)章节，我们介绍了define, template, block这三个声明和管理模板的动作。在本章中，我们将讨论这三种动作，并引入一种特殊目的的include函数。 命名模板的一个重要细节：模板名称是全局的。如果声明了两个相同名称的模板，whichever one is loaded last will be the one used. 由于subcharts中的模板与顶级模板一起编译，你应该小心命名。 # 一种流行的命名约定是使用chart名作为前缀： {{ define \"mychart.labels\" }} # 通过使用特定的chart名称作为前缀，我们可以避免相同模板名称所带来的冲突 ","date":"2020-09-21","objectID":"/helm/:31:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"下划线文件 Partials and _ files 目前为止，我们使用的一个文件中包含一个模板。但是Helm模板语言允许你创建命名嵌套模板，可通过名称在其它任何地方进行访问。 在我们开始编写这些模板之前，我们需要注意一下命名规范： templates/下的大多数文件被视为包含k8s manifests NOTES.txt是一个例外 以下划线(_)开头的文件被假定为不包含k8s manifests。这些文件不会被渲染为k8s对象定义，但可在任意chart templates中使用。 这些文件用来存储特定(partials)和助手(helpers)。实际上，当我们第一次创建mychart，我们会看到_helpers.tpl文件，此文件是默认的template partials。 ","date":"2020-09-21","objectID":"/helm/:31:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"声明和使用模板 Declaring and using templates with define and template。 define动作允许我们在一个模板文件中创建命名模板(named template)。语法如下: {{ define \"MY.NAME \"}}# body of template here {{ end }} 栗子： {{- define \"mychart.labels\" }}labels:generator:helmdata:{{now | htmlDate }}{{- end }}apiVersion:v1kind:ConfigMapmetadata:name:{{.Release.Name }}-configmap{{- template \"mychart.labels\" }}data:myvalue:\"Hello World\"{{- range $key, $va1 := .Values.favorite }}{{$key }}:{{$va1 | quote }}{{- end }} 渲染之后的效果： # Source: mychart/templates/configmap.yamlapiVersion:v1kind:ConfigMapmetadata:name:running-panda-configmaplabels:generator:helmdate:2016-11-02data:myvalue:\"Hello World\"drink:\"coffee\"food:\"pizza\" define仅定义，只有在模板中调用时才会产生输出。 按照惯例，Helm charts将这些模板放在partials文件中（通常是_helpers.tpl），如： {{/* Generate basic labels */}}{{- define \"mychart.labels\" }}labels: generator: helm date: {{ now | htmlDate }}{{- end }} # 按照管理，define函数 应该有一个简单的文档块 {{/*...*/}} # 如上。然后在其它模板文件中访问它。 ","date":"2020-09-21","objectID":"/helm/:31:2","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"设置模板范围 Setting the scope of a template 在上面定义的模板中，我们没有使用任何对象。让我们做些修改： {{/* Generate basic labels */}}{{- define \"mychart.labels\" }}labels: generator: helm data: {{ now | htmlData }}chart: {{ .Chart.Name }}version: {{ .Chart.Version }}{{- end }} 上面定义的名称和版本是动态的，会根据不同的模板生成不同的值。 之前的引用并没有床底范围，因此在模板内我们不能使用.来访问任何事物。现在我们对模板加上范围: apiVersion:v1kind:ConfigMapmetadata:name:{{.Release.Name }}-configmap{{- template \"mychart.labels\" . }} 注意上面在模板调用处使用的点(.)。我们可以非常容易地传递.Values或.Values.favorite或任何我们需要的范围。但是，我们需要的是顶级范围。 现在运行渲染(helm install --dry-run --debug plinking-anaco ./mychart)来预览下： # Source: mychart/templates/configmap.yamlapiVersion:v1kind:ConfigMapmetadata:name:plinking-anaco-configmaplabels:generator:helmdate:2016-11-02chart:mychartversion:0.1.0 ","date":"2020-09-21","objectID":"/helm/:31:3","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"include The include function 假设我们定义了如下一个简单模板： {{- define \"mychart.app\" -}}app_name: {{ .Chart.Name }}app_version: \"{{ .Chart.Version }}\" {{- end -}} 一个错误的栗子： apiVersion:v1kind:ConfigMapmetadata:name:{{.Release.Name }}-configmaplabels:{{template \"mychart.app\" . }}data:myvalue:\"Hello World\"{{- range $key, $val := .Values.favorite }}{{$key }}:{{$val | quote }}{{- end }}{{template \"mychart.app\" . }} 渲染的结果并不正确： # Source: mychart/templates/configmap.yamlapiVersion:v1kind:ConfigMapmetadata:name:measly-whippet-configmaplabels:app_name:mychartapp_version:\"0.1.0+1478129847\"data:myvalue:\"Hello World\"drink:\"coffee\"food:\"pizza\"app_name:mychartapp_version:\"0.1.0+1478129847\" Because the template that is substituted in has the text aligned to the right. Because template is an action, and not a function, there is no way to pass the output of a template call to other functions; the data is simply inserted inline. To work around this case, Helm provides an alternative to template that will import the contents of a template into the present pipeline where it can be passed along to other functions in the pipeline. 因为模板是靠右对齐的文本，因为template是一个动作，不是一个函数，因此无法传递调用其它函数的template的输出，数据被简单的插入内联。 现在我们需要使用ident来告诉模板正确的缩进，栗子： apiVersion:v1kind:ConfigMapmetadata:name:{{.Release.Name }}-configmaplabels:{{include \"mychart.app\" . | indent 4 }}data:myvalue:\"Hello World\"{{- range $key, $va1 := .Values.favorite }}{{$key }}:{{$val | quote }}{{- end }}{{include \"mychart.app\" . | indent 2 }} 正确的渲染结果： # Source: mychart/templates/configmap.yamlapiVersion:v1kind:ConfigMapmetadata:name:edgy-mole-configmaplabels:app_name:mychartapp_version:\"0.1.0+1478129987\"data:myvalue:\"Hello World\"drink:\"coffee\"food:\"pizza\"app_name:mychartapp_version:\"0.1.0+1478129987\" 在Helm template中使用include对template被认为更好，这使得输出格式可以为YAML文档更好地处理。 有时候，我们想要导入内容，但不作为模板。也就是逐字导入文件。我们可以通过.Files对象访问文件来实现这一目标。 ","date":"2020-09-21","objectID":"/helm/:31:4","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"在模板内访问文件 Accessing Files Inside Templates: https://helm.sh/docs/chart_template_guide/accessing_files/ Helm提供了.Files对象来访问文件。在开始模板示例之前，有些事需要注意下： 可以添加额外的文件到Helm chart。这些文件将被捆绑。要注意，charts必须小于1MB，因为k8s对象的存储限制。 某些文件无法通过.Files对象访问，通常出于安全原因 templates/目录内的文件无法访问 .helmignore中包含的文件无法访问 Charts不保留UNIX mode信息，当设计到.Files对象时，文件级别的权限对一个文件的可用性没有影响。 ","date":"2020-09-21","objectID":"/helm/:32:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"示例 Basic example 添加三个位于mychart/目录下的文件。 # config1.toml message = Hello from config 1 # config1.tom2 message = Hello from config 2 # config1.tom3 message = Goodbye from config 3 在模板中访问文件： apiVersion:v1kind:ConfigMapmetadata:name:{{.Release.Name }}-configmapdata:{{- $files := .Files }}{{- range tuple \"config1.tom1\" \"config2.toml\" \"config3.toml\" }}{{.}}:|-{{$files.Get .}}{{- end }} # 首先，创建了一个 $files变量 来保存.Files对象的引用 # 我们同样使用 tuple函数来创建循环的文件列表 # 接着打印每个文件名 {{ . }}: |- 后面接着文件内容 {{ $files.Get . }} 渲染效果示例： # Source: mychart/templates/configmap.yamlapiVersion:v1kind:ConfigMapmetadata:name:quieting-giraf-configmapdata:config1.toml:|-message = Hello from config 1config2.toml:|-message = This is config 2config3.toml:|-message = Goodbye from config 3 ","date":"2020-09-21","objectID":"/helm/:32:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"路径助手 Path helpers 使用文件时，对文件路径执行一些标准的操作是有用的。为了帮助处理，Helm从go path包中引入了许多函数供你使用: Base Dir Ext IsAbs Clean ","date":"2020-09-21","objectID":"/helm/:32:2","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"Glob模式 Glob patterns 随着你的chart包的增长，你会发现你有一个更大的需来组织你的文件，因此我们提供了Files.Glob(pattern string)方法，以帮助提取某些文件与glob patterns的所有灵活性。 .Glob返回一个Files类型，因此你可以在返回的对象上调用任意Files方法。 # 示例的目录结构 foo/: foo.txt foo.yaml bar/: bar.go bar.conf baz.yaml 使用Globs的多种选项： {{ $currentScope := .}} {{ range $path, $_ := .Files.Glob \"**.yaml\" }} {{- with $currentScope}} {{ .Files.Get $path }} {{- end }} {{ end }} 或者： {{ range $path, $_ := .Files.Glob \"**.yaml\" }} {{ $.Files.Get $path }} {{ end }} ","date":"2020-09-21","objectID":"/helm/:32:3","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"ConfigMap和Secrets的实用功能 ConfigMap and Secrets utility functions 将文件内容放置到K8s ConfigMap或Secrets中非常常见，然后在运行的时候挂载到容器。为了帮助实现此功能，我们在Files类型上提供了几种实用的方法： AsCoinfig AsSecrets 栗子： apiVersion:v1kind:ConfigMapmetadata:name:confdata:{{(.Files.Glob \"foo/*\").AsConfig | indent 2 }}---apiVersion:v1kind:Secretmetadata:name:very-secrettype:Opaquedata:{{(.Files.Glob \"bar/*\").AsSecrets | indent 2 }} ","date":"2020-09-21","objectID":"/helm/:32:4","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"编码 Encoding 你可以导入一个文件，并实用base64编码来确保成功传输： apiVersion:v1kind:Secretmetadata:name:{{.Release.Name }}-secrettype:Opaquedata:token:|-{{.Files.Get \"config1.toml\" | b64enc }} 渲染后的效果： # Source: mychart/templates/secret.yamlapiVersion:v1kind:Secretmetadata:name:lucky-turkey-secrettype:Opaquedata:token:|-bWVzc2FnZSA9IEhlbGxvIGZyb20gY29uZmlnIDEK ","date":"2020-09-21","objectID":"/helm/:32:5","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"行 Lines 有时候需要在模板中访问一个文件中的每行内容。我们为此提供了Lines方法。 示例： data:some-file.txt:{{range .Files.Lines \"foo/bar.txt\" }}{{. }}{{ end }} ","date":"2020-09-21","objectID":"/helm/:32:6","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"NOTES.txt Creating a NOTES.txt File: https://helm.sh/docs/chart_template_guide/notes_files/ 在helm install或helm upgrade结束，Helm可以为用户打印一块有用的信息。此信息使用模板且高度可定制。 要为你的chart包添加安装说明，简单地创建一个templates/NOTES.txt文件。此文件是纯文本文件，但它像作为模板一样处理，并可访问所有正常模板函数和对象。 NOTES.txt文件示例： Thank you for installing {{ .Chart.Name }} Your release is named {{ .Release.Name }} To learn more about the release, try: $ helm status {{ .Release.Name }} $ helm get all {{ .Release.Name }} 接下来运行： helm install rude-cardinal ./mychart RESOURCES: ==\u003e v1/Secret NAME TYPE DATA AGE rude-cardinal-secret Opaque 1 0s ==\u003e v1/ConfigMap NAME DATA AGE rude-cardinal-configmap 3 0s NOTES: Thank you for installing mychart. Your release is named rude-cardinal. To learn more about the release, try: $ helm status rude-cardinal $ helm get all rude-cardinal 强烈建议创建NOTES.txt文件，以帮助用户获得chart包的有用信息。 ","date":"2020-09-21","objectID":"/helm/:33:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"Subcharts Subcharts and Global Values: https://helm.sh/docs/chart_template_guide/subcharts_and_globals/ 之前我们只有一个chart，但charts可能会有依赖(dependencies)，称为subcharts。subcharts也有自己的值和模板。本章我们将会创建subchart，并看看我们可以从模板访问值的不同的方式。 subcharts的一些重要详情： 一个subchart被认为是独立的(stand-alone)，这意味着一个subchart不能明确依赖它的parent chart 出于此原因，subchart不能访问parent chart的值 parent chart可以覆盖subcharts的值 Helm有一个全局值(global values)的概念，这些全局值可被所有charts访问 ","date":"2020-09-21","objectID":"/helm/:34:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"创建一个subchart Creating a Subchart cd mychart/charts helm create mysubchart rm -rf mysubchart/templates/*.* ","date":"2020-09-21","objectID":"/helm/:34:1","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"对subchart添加值和模板 Adding Values and a Template to the Subchart 为subchart添加一个简单的值和模板： # values.yamldessert:cake apiVersion:v1kind:ConfigMapmetadata:name:{{.Release.Name }}-cfgmap2data:dessert:{{.Values.dessert }} 因为每个subchart都是独立的chart，我们可以测试mysubchart： helm install --generate-name --dry-run --debug mychart/charts/mysubchart SERVER: \"localhost:44134\" CHART PATH: /Users/mattbutcher/Code/Go/src/helm.sh/helm/_scratch/mychart/charts/mysubchart NAME: newbie-elk TARGET NAMESPACE: default CHART: mysubchart 0.1.0 MANIFEST: --- # Source: mysubchart/templates/configmap.yaml apiVersion: v1 kind: ConfigMap metadata: name: newbie-elk-cfgmap2 data: dessert: cake ","date":"2020-09-21","objectID":"/helm/:34:2","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"从parent chart覆盖值 现在，mychart是mysubchart的parent chart。因为mychart是parent chart，我们可以在mychart中指定配置，并将配置推送到mysubchart中。 # mychart/values.yamlfavorite:drink:coffeefood:pizzapizzaToppings:- mushrooms- cheese- peppers- onionsmysubchart:dessert:ice cream 我们在parent chart(mychart)的值文件里添加了mysubchart的值，mysubchart这部分值会发送到mysubchart包，这回覆盖mysubchart的值。 helm install --dry-run --debug mychart # Source: mychart/charts/mysubchart/templates/configmap.yaml apiVersion: v1 kind: ConfigMap metadata: name: unhinged-bee-cfgmap2 data: dessert: ice cream ","date":"2020-09-21","objectID":"/helm/:34:3","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"全局值 Global Chart Values 有时候你需要将值提供给所有模板，这可以使用全局值(global chart values)。全局值可被任意chart或subchart通过相同的名称来访问。全局需要明确地声明。 值数据类型保留在称为Values.global的区域，此区域可以设置全局值。 # mychart/values.yamlfavorite:drink:coffeefood:pizzapizzaToppings:- mushrooms- cheese- peppers- onionsmysubchart:dessert:ice creamglobal:salad:caesar # 任意chart和subchart都可以使用 {{ .Values.global.salad }} 来访问这个值# mychart/templates/configmap.yamlapiVersion:v1kind:ConfigMapmetadata:name:{{.Release.Name }}-configmapdata:salad:{{.Values.global.salad }} # mysubchart/templates/configmap.yamlapiVersion:v1kind:ConfigMapmetadata:name:{{.Release.Name }}-cfgmap2data:dessert:{{.Values.dessert }}salad:{{.Values.global.salad }} 渲染输出效果： # Source: mychart/templates/configmap.yamlapiVersion:v1kind:ConfigMapmetadata:name:silly-snake-configmapdata:salad:caesar---# Source: mychart/charts/mysubchart/templates/configmap.yamlapiVersion:v1kind:ConfigMapmetadata:name:silly-snake-cfgmap2data:dessert:ice creamsalad:caesar ","date":"2020-09-21","objectID":"/helm/:34:4","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"共享模板 Sharing Templates with Subcharts parent charts和subcharts可以共享模板。任意在chart中定义的block(块)都可以被其它charts所使用。 定义一个简单的模板栗子： {{- define \"labels\" }}from: mychart {{ end }} 尽管chart开发者可以在include和template之间选择，但使用include的优点是它可以动态引用模板： {{ include $mytemplate }} 上面间接引用$mytemplate。template函数，相反它只接受一个字符串。 ","date":"2020-09-21","objectID":"/helm/:34:5","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"避免使用块 Avoid Using Blocks go模板语言提供了一个block关键字，来允许开发者提供一个覆盖的默认实现。在Helm chart中，块(block)并不是覆盖的最佳工具，因为如果提供了相同块的多个实现，选择的那个是不可预测的。 建议使用include来代替。 ","date":"2020-09-21","objectID":"/helm/:34:6","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":".helmignore The .helmignore file: https://helm.sh/docs/chart_template_guide/helm_ignore_file/ .helmignore也就类似于.gitignore, .dockerignore，指定不需要包含在chart包中的文件。 如果此文件存在，helm package命令将忽略.helmignore里面匹配到的文件打包到应用的包里。 一个.helmignore文件的栗子： # comment # Match any file or path named .git .git # Match any text file *.txt # Match only directories named mydir mydir/ # Match only text files in the top-level directory /*.txt # Match only the file foo.txt in the top-level directory /foo.txt # Match any file named ab.txt, ac.txt, or ad.txt a[b-d].txt # Match any file under subdir matching temp* */temp* */*/temp* temp? ","date":"2020-09-21","objectID":"/helm/:35:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"模板调试 Debugging Templates: https://helm.sh/docs/chart_template_guide/debugging/ 有几个命令可帮助调试模板： helm lint: 验证chart最佳实践的工具 helm install --dry-run --debug或helm template --debug：渲染模板并返回k8s manifest文件 helm get manifest：查看安装了哪些模板 ","date":"2020-09-21","objectID":"/helm/:36:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["cncf"],"content":"YAML技巧 YAML Techniques: https://helm.sh/docs/chart_template_guide/yaml_techniques/ Helm命令 Helm Commands: https://helm.sh/docs/helm/ 社区指南 Community Guides: https://helm.sh/docs/community/ FAQ Frequently Asked Questions: https://helm.sh/docs/faq/ ","date":"2020-09-21","objectID":"/helm/:37:0","tags":["Helm","K8s","DevOps","CNCF"],"title":"Helm","uri":"/helm/"},{"categories":["programming"],"content":"参考: github: https://github.com/golang/go Docs: https://golang.org/doc/ awesome-go: https://github.com/avelino/awesome-go goreleaser: https://github.com/goreleaser/goreleaser/ go-demo: https://github.com/pibigstar/go-demo 版本: go v1.14 介绍 Go编程语言是一个开源项目，使开发人员更高效。 Go是传神，简洁，干净，高效的。它的并发机制(concurrency mechanisms)可充分利用多核和网络机器编写程序，它的新颖类型系统允许灵活和模块化结构。它是一个快速、静态类型、编译型语言，像一个动态类型、解释型语言。 安装 下载对应平台的二进制包，解压，添加路径。 测试安装: package main import \"fmt\" func main() { fmt.Printf(\"hello, world\\n\") } # 编译 go build hello.go # 执行 ./hello 安装其它版本: go get golang.org/dl/go1.10.7 go1.10.7 version 学习 ","date":"2020-07-22","objectID":"/go/:0:0","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"旅程 Tour: https://tour.go-zh.org/list 交互式地分三部分介绍Go： 基本语法和数据结构 方法和接口 并发原语(concurrency primitives) 可在线上或本地开启旅程： 线上: https://tour.golang.org/welcome/1 本地: go get golang.org/x/tour，会在go path的bin/tour。 sandbox.go测试程序显示时间： package main import ( \"fmt\" \"time\" ) func main() { fmt.Println(\"Welcomt to the playground!\") fmt.Println(\"The time is\", time.Now()) } ","date":"2020-07-22","objectID":"/go/:1:0","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"基础语法 学习go程序的基本结构。 包 每个go程序都是由包构成。程序从main包开始运行。 按照约定，包名与导入路径的最后一个元素一致。例如，math/rand包中的源码均以package rand语句开始。 // package.go package main // 导入两个包 import ( \"fmt\" \"math/rand\" ) func main() { fmt.Println(\"My favorite number is\", rand.Intn(10)) } 导入 使用圆括号进行分组导入，也可以编写多个导入语句。分组导入语句是更好的形式。 // 分组导入 import ( \"fmt\" \"math\" ) // 单独导入 import \"fmt\" import \"math\" 导出名 在Go中，如果一个名字以大写字母，那么它就是已导出的。 在导入一个包时，你只能引用其中已导出的名字。任何未导出的名字在该包外均无法访问。 // exporter-nams.go package main import ( \"fmt\" \"math\" ) func main() { fmt.Println(math.pi) //fmt.Println(math.Pi) } 运行math.pi会报错 ./prog.go:9:14: cannot refer to unexported name math.pi ./prog.go:9:14: undefined: math.pi 运行math.Pi 3.141592653589793 函数 函数可以没有参数或接受多个参数。注意类型在变量名之后。 // functions.go package main import \"fmt\" func add(x int, y int) int { return x + y } // 省略模式: x, y int func main() { fmt.Println(add(42, 13)) } 多值返回 函数可以返回任意数量的返回值。 // multiple-results.go import \"fmt\" func swap(x, y string) (string, string) { return y, x } func main() { a, b := swap(\"hello\", \"world\") fmt.Println(a, b) } 命名返回值 go的返回值可被命名，它们会被视作定义在函数顶部的变量。返回值的名称应当具有一定的意义。 没有参数的return语句返回已命名的返回值，也就是直接返回。直接返回语句应当仅在短函数中，在长函数中会影响代码的可读性。 // name-result.go package main import \"fmt\" func split(sum int) (x, y int) { x = sum * 4 / 9 y = sum -x return } func main() { fmt.Println(split(17)) } 变量 var语句用于声明一个变量列表。 // variables.go package main import \"fmt\" var c, python, java bool func main() { var i int fmt.Println(i, c, python, java) } 变量初始化 变量声明可以包含初始值。 如果初始化值已存在，则可以省略类型，变量会从初始值中获得类型。 // var-ini.go package main impoort \"fmt\" var i, j, int = 1, 2 func main() { var c, python, java = true, false, \"no!\" fmt.Println(i, j, c, python, java) } 短变量声明 在函数中，简洁赋值语句:=可在类型明确的地方代替var声明。 函数外的每个语句都必须以关键字(var, func…)开始，因此:=结构不能在函数外使用。 // short-var-declarations.go package main() import \"fmt\" func main() { var i, j int = 1, 2 k := 3 c, python, java := true, false, \"no!\" fmt.Println(i, j, k, c, python, java) } 数据类型 go的基本类型有： bool string int, int8, int16, int32, int64 uint, uint8, uint16, uint32, uint64, uintptr byte(uint8的别名) rune(int32的别名，表示一个unicode码点) float32, float64 complex64, complex128 int, uint 和 uintptr 在 32 位系统上通常为 32 位宽，在 64 位系统上则为 64 位宽。 当你需要一个整数值时应使用 int 类型，除非你有特殊的理由使用固定大小或无符号的整数类型。 // basic-types.go package main import ( \"fmt\" \"math/cmplx\" ) var ( ToBe bool = false MaxInt uint64 = 1\u003c\u003c64 - 1 x complex128 = cmplx.Sqrt(-5 ++ 12i) ) func main() { fmt.Printf(\"Type: %T Value: %v\\n\", ToBe, ToBe) fmt.Printf(\"Type: %T Value: %v\\n\", MaxInt, MaxInt) fmt.Printf(\"Type: %T Value: %v\", z, z) } 零值 没有明确初始值的变量声明会被赋予它们的零值。 零值是: 数值类型为 0 布尔类型为 false 字符串为空字符串 // zero.go package main import \"fmt\" func main() { var i int var f float64 var b bool var s string fmt.Printf(\"%v %v %v %q\\n\", i, f, b, s) } 类型转换 T(v)将v转换为T类型。 // type-conversions.go package main import ( \"fmt\" \"math\" ) func main() { var x, y int = 3, 4 var f float64 = math.Sqrt(float64(x*x + y*y)) var z unit = unit(f) fmt.Println(x, y, z) } 类型推导 在声明一个变量而不指定其类型时，变量的类型由右值推导而出。 // type-inference.go package main import \"fmt\" func main() { v := 42 // int fmt.Printf(\"v is of type %T\\n\", v) } 常量 常量的声明与变量类似，只不过使用const关键字。 常量可以是字符、字符串、布尔值、数值。 常量不能用:=语法声明。 // constants.go package main import \"fmt\" const Pi = 3.14 func main() { const World = \"世界\" fmt.Println(\"Hello\", World) fmt.Println(\"Happy\", Pi, \"Day\") const Truth = true fmt.Println(\"Go rules?\" Truth) } 数值常量 数值常量是高精度的值。一个未指定类型的常量由上下文来决定其类型。 // nemeric-constants.go package main import \"fmt\" const ( // 将1左移100位来创建一个非常大的数字，即这个数的二进制是1后面跟着100个0 Big = 1 \u003c\u003c 100 // 再往右移99位，即Small = 1 \u003c\u003c 1，或Small = 2 Small = Big \u003e\u003e 99 ) func needInt(x int) int { return x*10 + 1} func needFloat(x float64) float64 {return x * 0.1} func main() { fmt.Println(needInt(Small)) fmt.Println(needFloat(Small)) fmt.Println(needFloat(Big)) } ","date":"2020-07-22","objectID":"/go/:1:1","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"流程控制 flowcontrol: https://tour.go-zh.org/flowcontrol 学习如何使用条件、循环、分支和推迟语句来控制代码的流程。 for go只有一种循环结构: for循环。它由三部分组成： 初始化语句： 在第一次迭代前执行 条件表达式：在每次迭代前求值 后置语句： 在每次迭代的结尾执行 初始化语句和后置语句是可选的。 初始化语句通常为一句短变量声明，该变量声明仅在for语句的作用域中可见。一旦条件表达式的布尔值为false，循环迭代就会终止。 // for.go package main import \"fmt\" func main() { sum := 0 for i := 0; i \u003c 10; i++ { sum += i } fmt.Println(sum) } // for-continued.go package main import \"fmt\" func main() { sum := 1 for ; sum \u003c 1000; { sum += sum } fmt.Println(sum) } for是while go的for就是while。 // for-is-while.go package main import \"fmt\" func main() { sum := 1 for sum \u003c 1000 { sum += sum } fmt.Println(sum) } 无限循环 如果省略循环条件，该循环就不会结束，因此无限循环可以写的很紧凑。 // forever.go package main func main() { for {} } if // if.go package main import ( \"fmt\" \"math\" ) func sqrt(x float64) string { if x \u003c 0 { return sqrt(-x) + \"i\" } return fmt.Sprint(math.Sqrt(x)) } func main() { fmt.Println(sqrt(2), sqrt(-4)) } 简短的if if语句可在条件表达式前执行一个简单的语句。该语句声明的变量作用域仅在if之内。 // if-short.go package main import ( \"fmt\" \"math\" ) func pow(x, n, lim float64) float64 { if v := math.Pow(x, n); v \u003c lim { return v } return lim } func main() { fmt.Println( pow(3, 2, 10), pow(3, 3, 20), ) } else // else.go package main import ( \"fmt\" \"math\" ) func pow(x, n, lim float64) float64 { if v := math.Pow(x, n); v \u003c lim { return v } else { fmt.Printf(\"%g \u003e= %g\\n\", v, lim) } return lim } func main() { fmt.Println( pow(3, 2, 10), pow(3, 3, 20), ) } switch switch是一连串的if-else语句的简单写法。它运行第一个值等于条件表达式的case语句。 // switch.go package main import ( \"fmt\" \"runtime\" ) func main() { fmt.Print(\"Go runs on \") switch os := runtime.GOOS; os { case \"darwin\": fmt.Println(\"OS X.\") case \"linux\": fmt.Println(\"Linux.\") default: fmt.Printf(\"%s. \\n\", os) } } switch的case语句从上到下依次执行，知道匹配成功时停止。 // switch-order.go package main import ( \"fmt\" \"time\" ) func main() { fmt.Println(\"When's Saturday?\") today := time.NOw().Weekday() switch time.Saturday { case today + 0: fmt.Println(\"Today.\") case today + 1: fmt.Println(\"Tomorrow.\") case today + 2: fmt.Println(\"In two days.\") default: fmt.Println(\"Too far away.\") } } 没有条件的switch同switch true一样。这种形式能将一长串if-then-else写得更加清晰。 // switch-no-condition.go package main import ( \"fmt\" \"time\" ) func main() { t := Now() switch { case t.Hour() \u003c 12: fmt.Pringln(\"Good morning!\") case t.Hour() \u003c 17: fmt.Println(\"Good afternoon.\") default: fmt.Println(\"Good evening.\") } } defer defer语句会将函数推迟到外层函数返回之后执行。 推迟调用的函数其参数会立即求值，但直到外层函数返回前该函数都不会被调用。 // defer.go package main import \"fmt\" func main() { defer fmt.Println(\"world\") fmt.Pringln(\"hello\") } 推迟的函数调用会被压入一个栈中。当外层函数返回时，被推迟的函数会按照后进先出的顺序调用。 // defer-multi.go package main import \"fmt\" func main() { fmt.Pringln(\"counting\") for i := 0; i \u003c 10; i++ { defer fmt.Pringln(i) } fmt.Println(\"done\") } ","date":"2020-07-22","objectID":"/go/:1:2","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"更多类型 学习如何基于现有类型定义新的类型，包含结构体、数组、切片和映射。 指针 go拥有指针。指针保存了值的内存地址。类型*T是指向T类型值的指针。其零值位nil。\u0026操作符会生成一个指向其操作数的指针。*操作符表示指针指向的底层值。这也就是常说的间接引用和重定向。 与C不同，go没有指针运算。 // pointers.go package main import \"fmt\" func main() { i, j := 42, 2701 p := \u0026i // 指向i fmt.Pringln(*p) // 通过指针读取i的值 *p = 21 // 通过指针设置i的值 fmt.Pringln(i) p = \u0026j *p = *p /37 fmt.Pringln(j) } 结构体 一个结构体(struct)就是一组字段(field)。 // structs.go package main import \"fmt\" type Vertex struct { X int Y int } func main() { fmt.Println(Vertex{1, 2}) } 结构体字段使用点号来访问。 // struct-fields.go package main import \"fmt\" type Vertex struct { X int Y int } func main() { v := Vertex{1, 2} v.X = 4 fmt.Println(v.X) } 结构体字段可以通过结构体指针来访问。 如果有一个指向结构体的指针P，那么可通过(*p).X来访问其字段X。不过这样写太啰嗦，可隐式间接引用，直接写p.X。 // struct-pointers.go package main import \"fmt\" type Vertex struct { X int Y int } func main() { v := Vertex{1, 2} p := \u0026v // 指针 p.X = 1e9 fmt.Println(v) } 结构体文法通过直接列出字段的值来新分配一个结构体。 // struct-literals.go package main import \"fmt\" type Vertex struct { X, Y int } var ( v1 = Vertex{1, 2} // 创建一个Vertex类型的结构体 v2 = Vertex{X: 1} // Y:0被隐式地赋予 v3 = Vertex{} // X:0 Y:0 p = \u0026Vertex{1, 2} // 创建一个*Vertex类型的结构体(指针) ) func main() { fmt.Println(v1, p, v2, v3) } 数组 类型[n]T表示拥有n个T类型的值的数组。 数组的长度是其类型的一部分，因此数组不能改变大小。 // array.go package main import \"fmt\" func main() { var a [2]string a[0] = “Hello\" a[1] = \"World\" fmt.Pringln(a[0], a[1]) fmt.Println(a) primes := [6]int{2, 3, 5, 7, 11, 13} fmt.Println(primes) } 切片 每个数组大小都是固定的，而切片则为数组元素提供动态大小的、灵活的视角。在实践中，切片比数组更常用。 类型[]T表示一个元素类型为T的切片。 // slices.go package main import \"fmt\" func main() { primes := [6]int{2, 3, 5, 7, 11, 13} var s []int = primes[1:4] fmt.Println(s) } 切片并不存储任何数据，它只是描述了底层数组中的一段。更改切片的元素会修改其底层数组中对应的元素。与它共享底层数组的切片都会观测到这些修改。 // slices-pointers.go package main import \"fmt\" func main() { names := [4]string{\"John\", \"Paul\", \"George\", \"Ringo\",} fmt.Println(names) a := names[0:2] b := names[1:3] fmt.Pringln(a, b) b[0] = \"XXX\" fmt.Pringln(a, b) fmt.Pringln(names) } 切片文法类似于没有长度的数组文法。 // slice-literals.go package main import \"fmt\" func main() { q := []int{2, 3, 5, 7, 11, 13} // 创建一个数组，并构建一个引用数组的切片 fmt.Pringln(q) r := []bool{true, false, true, true, false, true} fmt.Pringln(r) s := []struct { i int b bool } { {2, true}, {3, false}, {5, true}, {7, true}, {11, false}, {13, true}, } fmt.Pringln(s) } 在进行切片时，你可以利用它的默认行为来忽略上下界。 切片拥有长度和容量。切片的长度就是它所包含的元素个数。切片的容量从第一个元素开始数，到元素末尾的个数。 可通过len()和cap()来获取。 // slice-len-cap.go package main import \"fmt\" func main() { s := []int{2, 3, 5, 7, 11, 13} printSlice(s) // 截取切片使其长度为0 s = s[:0] printSlice(s) // 扩展长度 s = s[:4] printSlice(s) // 舍弃前两个值 s = s[2:] printSlice(s) } func printSlice(s []int) { fmt.Printf(\"len=%d cap=%d %v\\n\", len(s), cap(s), s) } 切片的零值nil。nil切片的长度和容量为0且没有底层数组。 // nil-slices.go package main import \"fmt\" func main() { var s []int fmt.Println(s, len(s), cap(s)) if s == nil { fmt.Pringln(\"nil!\") } } 切片可以使用内建函数make来创建，这也是创建动态数组的方式。make函数会分配一个元素为零值的数组并返回一个引用了它的切片。 // making-slices.go package main import \"fmt\" func main() { a := make([]int, 5) PrintSlice(\"a\", a) b := make([]int, 0, 5) printSlice(\"b\", b) c := b[:2] printSlice(\"c\", c) d := c[2:5] printSlice(\"d\", d) } func printSlice(s string, x []int) { fmt.Printf(\"%s lend=%d cap=%d %v\\n\", s, len(x), cap(x), x) } 切片可包含任何类型，甚至包括其他切片。 // slices-of-slices.go package main import ( \"fmt\" \"STRINGS\" ) func main() { // 创建一个井字板 board := [][]string{ []string{\"_\", \"_\", \"_\"}, []string{\"_\", \"_\", \"_\"}, []string{\"_\", \"_\", \"_\"}, } // 两个玩家轮流打上 x和o board[0][0] = \"X\" board[2][2] = \"O\" board[1][2] = \"X\" board[1][0] = \"O\" board[0][2] = \"X\" for i := 0; i \u003c len(board); i++ { fmt.Printf(\"%s\\n\", strings.Join(board[i], \" \")) } } 向切片追加新的元素是常用的操作，为此go提供了内建的append函数。 // append.go package main import \"fmt\" func main() { var s []int printSlice(s) // 添加一个空切片 s = append(s, 0) printSlice(s) s = append(s, 1) printSlice(s) // 一次性添加多个元素 s = append(s, 2, 3, 4) printSlice(s) } func printSlice(s []int) { fmt.Printf(\"len=%d cap=%d %v\\n\", len(s), cap(s), s) } range for循环的range形式可以遍历切片或映射。 // range.go package main import \"fmt\" var pow = []int{1, 2, 4, ","date":"2020-07-22","objectID":"/go/:1:3","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"方法和接口 docs: https://tour.go-zh.org/methods/1 包含方法和接口，可以用这种构造来定义对象及其行为。 方法 go没有类。 不过你可以为结构体类型定义方法。方法就是一类带特殊的接收者参数的函数。方法接收者在它自己的参数列表内，位于func关键字和方法名之间。 // methods.go package main import ( \"fmt\" \"math\" ) type Vertex struct { X, Y float64 } // Abs方法拥有一个名为v，类型为Vertex的接收者 func (v Vertex) Abs() float64 { return math.Sqrt(v.X*v.X + v.Y*v.Y) } func main() { v := Vertex{3, 4} fmt.Println(v.Abs()) } 方法只是个带接收者参数的函数。 // metheods-funcs.go package main import ( \"fmt\" \"math\" ) type Vertex struct { X, Y float } func Abs(v Vertex) float64 { return math.Sqrt(v.X*v.X + v.Y*v.Y) } func main() { v := Vertex(3, 4) fmt.Println(Abs(v)) } 也可以为非结构体类型声明方法。接收者的类型定义和方法声明必须在同一包内，不能为内建类型声明方法。 // methods-continued.go package main import ( \"fmt\" \"math\" ) type MyFloat float64 func (f MyFloat) Abs() float64 { if f \u003c 0 { return float64(-f) } return float64(f) } func main() { f := MyFloat(-math.Sqrt2) fmt.Println(f.Abs()) } 指针接收者 可以为指针接收者声明方法。 // methods-pointers.go package main import ( \"fmt\" \"math\" ) type Vertex struct { X, Y float64 } func (v, Vertex) Abs() float64 { return math.Sqrt(v.X*v.X + v.Y*v.Y) } func (v *Vertex) Scale(f float64) { v.X = v.X * f v.Y = v.Y * f } func main() { v := Vertex{3, 4} v.Scale(10) fmt.Println(v.Abs()) } 指针与函数 // methods-pointers-explained.go package main import ( \"fmt\" \"math\" ) type Vertex struct { X, Y float64 } func Abs(v Vertex) float64 { return math.Sqrt(v.X*v.X + v.Y*v.Y) } func Scale(v *Vertex, f float64) { v.X = v.X * f x.Y = x.Y * f } func main() { v := Vertex{3, 4} Scale(\u0026v, 10) fmt.Println(Abs(v)) } 方法与指针重定向 // indirection.go package main import \"fmt\" type Vertex struct { X, Y float64 } func (v *Vertex) Scale(f float64) { v.X = v.X * f x.Y = v.Y * f } func ScaleFunc(v *Vertex, f float64) { v.X = V.X * f v.Y = v.Y * f } func main() { v := Vertex{3, 4} v.Scale(2) ScaleFunc(\u0026v, 10) p := \u0026Vertex{4, 3} p.Scale(3) ScaleFunc(p, 8) fmt.Println(v, p) } // indirection-values.go package main import ( \"fmt\" \"math\" ) type Vertex struct { X, Y float64 } func (v Vertex) Abs() float64 { return math.Sqrt(v.X*v.X + v.Y*v.Y) } func AbsFunc(v Vertex) float64 { return math.Sqrt(v.X*v.X + v.Y*v.Y) } func main() { v := Vertex{3, 4} fmt.Println(v.Abs()) fmt.Println(AbsFunc(v)) p := \u0026Vertex{4, 3} fmt.Println(p.Abs()) fmt.Println(AbsFunc(*p)) } 选择值或指针作为接收者 使用指针接收者的原因有二： 方法能够修改其接收者指向的值 可以避免在每次调用方法时复制该值。若值的类型为大型结构体时，这样做会更加高效 // methods-pointer-receivers.go package main import ( \"fmt\" \"math\" ) type Vertex struct { X, Y float64 } func (v *Vertex) Scale(f float64) { v.X = v.X * f v.Y = v.Y * f } func (v *Vertex) Abs() float64 { return math.Sqrt(v.X*v.X + v.Y*v.Y) } func main() { v := \u0026Vertex{3, 4} fmt.Printf(\"Before scaling: %+v, Abs: %v\\n\", v, v.Abs()) v.Scale(5) fmt.Printf(\"After scaling: %+v, Abs: %v\\n\", v, v.Abs()) } 接口 接口类型是由一组方法签名定义的集合。接口类型的变量可以保存任何实现了这些方法的值。 类型通过实现一个接口的所有方法来实现该接口。既然无需专门显式声明，也就没有implements关键字。隐式接口从接口的实现中解耦了定义，这样接口的实现可以出现在任何包中，无需提前准备。因此，也就无需在每一个实现上增加新的接口名称，这样同时也鼓励了明确的接口定义。 // interfaces-implicitly.go package main import \"fmt\" type I interface { M() } type T struct { S string } // 此方法表示类型T实现了接口I，但我们无需显式声明 func (t T) M() { fmt.Println(t.S) } func main() { var i I = T{\"Hello\"} i.M() } 接口也是值。它们可以像其它值一样传递。接口值可以用作函数的参数或返回值。 在内部，接口值可以看做包含值和具体类型的元组：(value, type)。接口值保存了一个具体底层类型的具体值。接口值调用方法时会执行其底层类型的同名方法。 // interface-values.go package main import ( \"fmt\" \"math\" ) type I interface { M() } type T struct { S string } func (t *T) M() { fmt.Println(t.S) } type F float64 func (f F) M() { fmt.Println(f) } func main() { var i I i = \u0026T[\"Hello\"] describe(i) i.M() i = F(math.Pi) describe(i) i.M() } func describe(i I) { fmt.Printf(\"(%v, %T)\\n\", i, i) } 底层值为nil的接口值。 即便接口内的具体值为nil， 方法仍然会被nil接收者调用。注意，保存了nil具体值的接口其自身并不为nil。 // interface-values-nil.go package main import \"fmt\" type I interface { M() } type T struct { S tring } func (t *T) M() { if t == nil { fmt.Println(\"\u003cnil\u003e\") return } fmt.Println(t.S) } func main() { var i I var t *T i = t describe(i) i.M() i = \u0026T{\"hello\"} describe(i) i.M() } func describe(i I) { fmt.Printf(\"(%v, %T)\\n\", i, i) } nil接口值","date":"2020-07-22","objectID":"/go/:1:4","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"并发 doc: https://tour.go-zh.org/concurrency/1 作为语言的核心部分，go提供了并发的特性。这一部分概览了goroutine和channel，以及如何使用它们来实现不同的并发模式。 goroutine go程(goroutine)是由go运行时管理的轻量级线程。 go f(x, y, z) # 会启动一个新的goroutine并执行 f(x, y, z) # f, x, y, z的求值发生在goroutine中 # 而f的执行发生在新的goroutine中 goroutine在相同的地址空间中运行，因此在访问共享的内存时必须进行同步。 // goroutines.go package main import ( \"fmt\" \"time\" ) func say(s string) { for i := 0; i \u003c 5; i++ { time.Sleep(100 * time.Millisecond) fmt.Println(s) } } func main() { go say(\"world\") sqy(\"hello\") } 信道 信道是带有类型的管道，通过它用信道操作符\u003c-来发送或接收值。 // 信道在使用前必须创建 ch := make(chan int) // 箭头就是数据流的方向 ch \u003c- v // 将v发送至信道ch v := \u003c-ch // 从ch接收值并赋予v // channels.go package main import \"fmt\" func sum(s []int, c chan int) { sum := 0 for _, v := range s { sum += v } c \u003c- sum // 将和送入c } func main() { s := []int{7, 2, 8, -9, 4, 0} c := make(chan int) go sum(s[:len(s)/2], c) go sum(s[len(s)/2:], c) x, y := \u003c-c, \u003c-c // 从c中接收 fmt.Println(x, y, x+y) } 带缓冲的信道 将缓冲长度作为第二个参数提供给make来初始化一个带缓冲的信道，仅当信道的缓冲区填满后，向其发送数据时才会阻塞。当缓冲区为空时，接受方会阻塞。 // buffered-channels.go package main import \"fmt\" func main() { ch := make(chan int, 2) ch \u003c- 1 ch \u003c- 2 // ch \u003c- 3 填满缓冲区 fmt.Println(\u003c-ch) fmt.Println(\u003c-ch) } close 发送者可通过close关闭一个信道来表示没有需要发送的值。接收者可以通过为接收表达式分配第二个参数来测试信道是否被关闭。 只有发送者才能关闭信道，而接收者不能。向一个已经关闭的信道发送数据会引发程序恐慌(panic)。信道与文件不同，通常情况下不需要关闭它们。只有在必须告诉接收者不再有需要发送的值时才有必要关闭，例如终止一个range循环。 // 若没有值可接收且信道已关闭，在执行完后,ok会被设置为false v, ok := \u003c-ch // 循环for i := range c会不断从信道接收值，直到它关闭 // range-and-close.go package main import ( \"fmt\" ) func fibonacci(n int, c chan int) { x, y := 0, 1 for i := 0; i \u003c n; i++ { c \u003c- x x, y = y, x+y } close(c) } func main() { c := make(chan int, 10) go fibonacci(cap(c), c) for i := range c { fmt.Println(i) } } select select语句使一个go routine可以等待多个通信操作。 它会阻塞到某个分支可以继续执行为止，这时就会执行该分支。当多个分支都准备好时会随机选择一个执行。 // select.go package main import \"fmt\" func fibonacci(c, quit chan int) { x, y := 0, 1 for { select { case c \u003c- x: x, y = y, x+y case \u003c-quit: fmt.Println(\"quit\") return } } } func main() { c := make(chan int) quit := make(chan int) go func() { for i := 0; i \u003c 10; i++ { fmt.Println(\u003c-c) } quit \u003c- 0 }() fibonacci(c, quit) } 当select中的其它分支都没有转杯好时，default分支就会执行。 // default-selection.go package main import ( \"fmt\" \"time\" ) func main() { tick := time.Tick(100 * time.Millisecond) boom := time.After(500 * time.Millisecond) for { select { case \u003c-tick: fmt.Println(\"tick.\") case \u003c-boom: fmt.Println(\"BOOM!\") return default: fmt.Println(\" .\") time.Sleep(50 * time.Millisecond) } } } 互斥锁 信道非常适合在各个Go routine间进行通信。但如果并不需要通信，只想保证每次只有一个go routine能够访问一个共享的变量，从而避免冲突。 这里面涉及的概念就做互斥(mutual exclusion)，通常使用互斥锁(Mutex)这一数据结构来提供这种机制。go标准库提供了sync.Mutex互斥锁及其两个方法: Lock, Unlock。 // mutex-counter.go package main import ( \"fmt\" \"sync\" \"time\" ) // SafeCounter 的并发使用是安全的 type SafeCounter struct { v map[string]int mux sync.Mutex } // Inc 增加给定 key 的计数器的值 func (c *SafeCounter) Inc(key string) { c.mux.Lock() // Lock 之后同一时刻只有一个 go routine 能访问c.v c.v[key]++ c.mux.Unlocak } // Value 返回给定key的计数器的当前值 func (c *SafeCounter) Value(key string) int { c.mux.Lock() // Lock之后同一时刻只有一个 go routine 能访问c.v defer c.mux.Unlock() return c.v[key] } func main() { c := SafeCounter{v: make(map[string]int)} for i := 0; i \u003c 1000; i++ { go c.Inc(\"somekey\") } time.Sleep(time.Second) fmt.Println(c.Value(\"somekey\")) } ","date":"2020-07-22","objectID":"/go/:1:5","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"如何编写go代码 doc: https://golang.org/doc/code.html ","date":"2020-07-22","objectID":"/go/:2:0","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"介绍 本文介绍如何开发一个模块内的一组简单的go包集合，并使用go工具，以标准的方式去fetch, build, install go modules, packages, commands。 注意: 本文使用go v1.13+，并且没有设置GO111MODULE环境变量。 ","date":"2020-07-22","objectID":"/go/:2:1","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"代码组织 go程序被组织到包。包是编译在同一目录中的源文件的集合。定义在一个源文件中的函数、类型、变量、常量对同一个包中的其它源文件可见。 一个仓库(repo)包含一个或多个模块。模块是发布到一起关联go包的集合。一个go仓库通常只包含一个模块，位于该库的根目录。go.mod文件声明了模块路径，该模块内所有包的导入路径前缀。该模块包含了go.mod文件此目录及其子目录的包。 注意，在你可以构建之前，你并不需要将代码发布到远程仓库。一个模块可以定义在本地而不属于一个仓库。然而，如果你某天希望发布你的代码，那么组织你的代码是一个很好的习惯。 每个模块的路径不仅作为其包的导入路径前缀，也预示着go命令在哪里下载它。例如，要下载golang.org/x/tools模块，go命令会通过协商表示https://golang.org/x/tools。 导入路径是用来导入包的字符串。一个包的导入路径是它和模块内子目录的加入模块的路径。例如，模块github.com/google/go-cmp在cmp/目录下包含一个包，这个包的导入路径是github.com/google/go-cmp/cmp。标准库中的包没有模块路径前缀。 ","date":"2020-07-22","objectID":"/go/:2:2","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"第一个程序 要编译和运行一个简单的程序，首先要选择一个模块路径（如example.com/user/hello）并创建一个go.mod文件来声明它。 make hello cd hello go mod init example.com/user/hello go: creating new go.mod: module example.com/user/hello cat go.mod module example.com/user/hello go 1.14 go源文件的第一个语句必须是包名(package name)。可执行命令必须使用package main。 // hello.go package main import \"fmt\" func main() { fmt.Println(\"Hello, world.\") } 现在你可以使用go工具来构建和安装程序。 go install example/user/hello 此命令构建hello命令，产生一个可执行二进制文件，安装此二进制到$HOME/go/bin/hello。 安装目录由GOPATH和GOBIN环境变量控制。如果GOBIN有设置，则安装到它这个目录。如果GOPATH有设置，二进制被安装到$GOPATH/bin/下。否则，二进制文件被安装到默认$GOPATH/bin目录下。 可以使用go env命令来设置和取消环境变量: # 设置 go env -w GOBIN=/somewhere/else/bin # 取消 go env -u GOBIN 像go install这样的命令应用在包含当前工作目录的模块上下文内。如果当前工作目录不在example.com/user/hell模块内，则go install命令可能会失败。 为了方便，如果没有给定其它路径，go命令接收相对于当前工作目录的路径，默认为包的当前路径。因此，在当前工作目录下，下面的命令是等效的： go install example.com/user/hello go install . go install 接下来，让我们运行此程序以确保它工作。 export PATH=$PATH:$(dirname $(go list -f '{{.Target}}' .)) hello Hello, world 如果你在使用版本控制，那现在是初始化仓库，添加文件并提交你的第一个变化的好时机。这一步是可选的，你不需要使用版本控制编写go代码。 go init git add go.mod hello.go git commit -m \"initial commit\" go命令通过请求HTTPS URL和从HTML响应中读取元数据来定位仓库包含的模块路径(go help importpath)。许多托管服务已经提供了包含go代码的元数据，使你的模块对其他人可用的最简单的方法通常是——使模块路径匹配仓库URL。 从你的模块导入包 Importing packages from your module 让我们编写一个morestrings包，并从hello程序来使用它。首先，为包创建一个目录$HOME/hello/morestrings，并在目录下编写reverse.go源文件。 // Package morestrings implements additional functions to manipulate UTF-8 // encoded strings, beyond what is provided in the standard \"strings\" package. package morestrings // ReverseRunes returns its argument string reversed rune-wise left to right. func ReverseRunes(s string) string { r := []rune(s) for i, j := 0, len(r)-1; i \u003c len(r)/2; i, j = i+1, j-1 { r[i], r[j] = r[j], r[i] } return string(r) } 测试并使用go build来编译包： cd hello/morestrings go build 这不会生成一个输出文件。相反，它在本地构建缓存(local build cache)中保存编译包(compiled package)。 在确认了morestrings包构建之后，让我们修改hello.go来使用morestrings包: package main import ( \"fmt\" \"example.com/usr/hello/morestrings\" ) func main() { fmt.Println(morestrings.ReverseRunes(\"!oG ,0lleH\")) } // install hello go install example.com/user/hello hello Hello, Go! 从远程模块导入包 Importing packages from remote modules 导入路径可以描述如何使用版本控制获得源代码。go工具使用该属性从远程仓库自动获取包。比如，在程序中使用github.com/google/go-cmp/cmp： package main import ( \"fmt\" \"example.com/user/hello/morestrings\" \"github.com/google/go-cmp/cmp\" ) func main() { fmt.Println(morestrings.ReverseRunes(\"!oG ,olleH\")) fmt.Println(cmp.Diff(\"Hello World\", \"Hello Go\")) } 当你运行go install, go build, go run这些命令时，go命令会自动下载远程模块并在go.mod文件中记录版本。 $ go install example.com/user/hello go: finding module for package github.com/google/go-cmp/cmp go: downloading github.com/google/go-cmp v0.4.0 go: found github.com/google/go-cmp/cmp in github.com/google/go-cmp v0.4.0 $ hello Hello, Go! string( - \"Hello World\", + \"Hello Go\", ) $ cat go.mod module example.com/user/hello go 1.14 require github.com/google/go-cmp v0.4.0 $ 模块依赖关系自动下载到$GOPATH/pkg/mod目录。一个模块的特定版本的下载内容，要求该版本与所有其它模块之间共享，因此go命令标记目录和文件为只读。 # 删除所有下载的模块 go clean --modcache ","date":"2020-07-22","objectID":"/go/:2:3","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"测试 go有一个轻量测试框架go test命令和testing包。 你可以通过创建一个以_test.go名称结尾的文件来编写一个测试，此测试文件包含以func (t *testing.T)签名的TestXXX函数。测试框架运行每个这样的函数，如果此函数调用一个失败的函数（如t.Error或t.Fail），则测试被认为失败。 通过创建包含以下代码的morestrings/reverse_test.go文件，对morestrings包添加一个测试。 package main import \"test\" func TestReverseRunes(t *testing.T) { cases := []struct { in, want string }{ {\"Hello, world\", \"dlrow ,olleH\"}, {\"Hello, 世界\", \"界世 ,olleH\"}, {\"\", \"\"}, } for _, c := range cases { got := ReverseRunes(c.in) if got != c.want { t.Errorf(\"ReverseRunes(%q) == %q, want %q, c.in, got, c.want\") } } } 接着使用go test运行测试: $ go test PASS ok example.com/user/morestrings 0.165s $ # 帮助 go help test ","date":"2020-07-22","objectID":"/go/:2:4","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"ide和插件 doc: https://golang.org/doc/editors.html vim-go: https://github.com/fatih/vim-go Visual Studio Code: https://marketplace.visualstudio.com/items?itemName=golang.Go 我是用的k-vim已经添加了vim-go，只需要将let g:bundle_groups=中添加golang即可。 ","date":"2020-07-22","objectID":"/go/:3:0","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"高效go编程 Effective Go: https://golang.org/doc/effective_go.html ","date":"2020-07-22","objectID":"/go/:4:0","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"介绍 Go是一门新语言。要把go写好，了解其性质和惯用语法是很重要的。同样重要的是要知道在go中程序所建立的约定。如命名、格式、项目建设等，让你写的程序会很容易为其他go程序员所理解。 此文档对编写清晰、惯用的go代码给出了一些技巧。 ","date":"2020-07-22","objectID":"/go/:4:1","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"示例 go package sources 不仅作为核心库，而且为如何使用语言做了示例。 ","date":"2020-07-22","objectID":"/go/:4:2","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"格式化 格式问题最具争议，但却始终没有形成统一的定论。若所有人都遵循相同的编码风格，在这类问题上浪费的时间将会更少。 在go中我们另辟蹊跷，让机器来处理大部分的格式问题。gofmt程序将go程序安装标准风格 进行缩进、对齐，保留注释并在需要时重新格式化。 举例来说，你无需花时间将结构体中的字段对其，gofmt将会为你代劳。 type T struct { name string // 对象名 value int // 对象值 } gofmt会将它按列对齐： type T struct { name string // 对象名 value int // 对象值 } 标准包中的所有go代码都已经用gofmt格式化过了。一些关于格式化的细节： 缩进(Indentation) 使用制表符tab，gofmt也默认使用它。在你认为有必要的时候使用空格符(space)。 行长度(Line length) go对行长度没有限制。如果一行实在太长，可以拆行并插入适当的tab缩进。 括号(Parentheses) 比起C和Java，Go所需的括号更少。控制结构(if, for, switch)在语法上并不需要圆括号。此外，操作符优先级处理变得更加简洁： x\u003c\u003c8 + y\u003c\u003c16 ","date":"2020-07-22","objectID":"/go/:4:3","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"注释 go提供了C风格的块注释(/* */)和c++风格的行注释(//)。 godoc既是一个程序，又是一个Web服务器，它对go源码进行处理，并提取包中的文档内容。出现在顶级声明之前，且与该声明之间没有空行的注释，将与该声明一起被提取出来，作为该条目的说明文档。让我想起了Python的文档字符串(docstring)。 每个包都应包含一个包说明(package comment)——即放置在包子句前的一个块注释。对于包含多个文件的包，包注释只需出现在其中的任一文件中即可。包注释应在整体上对该包进行介绍，并提供包的相关信息。 /* regexp 包为正则表达式实现了一个简单的库。 它接受的正则表达式语法为： 正则： 串联 { '|' 串联} 串联： { 闭包 } 闭包： 条目 [ '*' | '+' | '?' ] 条目： '^' '$' '.' 字符 '[' [ '^' ] 字符遍历 ']' '(' 正则表达式 ')' */ package regexp 如果包比较简单，包说明可以简洁些： // Package path implements utility routines for // manipulating slash-separated filename paths. 注释无需额外的格式化。godoc会像gofmt一样处理好一切。注释是不会被解析的纯文本，因此特定的格式不会被渲染。godoc是否会重新格式化注释取决于上下文，因此必须确保它看起来清晰易辨：使用正确的拼写、标点、句子结构以及折叠长行等。 在包中，任何顶级声明前的注释都作为该声明的文档说明。每个可导出名称的程序(首字母大写)都有该用文档说明。这让我想起了Python的类。 文档注释最好是完整的句子，这样它才能适应各种自动化的展示。 第一句应当以被声明的东西开头，并且是单句的摘要。 // Compile parses a regular expression and returns, if successful, // a Regexp that can be used to match against text. func Compile(str string) (*Regexp, error) { 若注释总是以名称开头，godoc的输出就能通过grep变得更加有用。 go doc -all regexp | grep -i parse go的声明语法允许成组声明。单个文档注释应介绍一组相关的常量或变量。 由于是整体声明，这种注释往往较为笼统。 // Error codes returned by failures to parse an expression. var ( ErrInternal = errors.New(\"regexp: internal error\") ErrUnmatchedLpar = errors.New(\"regexp: unmatched '('\") ErrUnmatchedRpar = errors.New(\"regexp: unmatched ')'\") ... ) 即便是对于私有名称，也可通过成组声明来表明各项间的关系，例如某一组由互斥体保护的变量。 var ( countLock sync.Mutex inputCount uint32 outputCount uint32 errorCount uint32 ) ","date":"2020-07-22","objectID":"/go/:4:4","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"命名 names 命名在编程语言中很重要！ 包名 package names 当一个包被导入后，包名就会成为内容的访问器。 import \"bytes 包的名称应该简洁明了以便于理解。按照惯例，包应当以小写的单个单词来命名，且不应该使用下划线或驼峰记法(mixedCaps)。包名是就是导入时所需的默认名称，它并不需要在所有源码中保持唯一，即使在少数发生冲突的情况下，也可为导入的包选择一个别名来局部使用。无论如何，通过文件名来判定使用的包，基本不会产生混淆。 另一个约定就是包名应为其源码目录的基本名称。在src/encoding/base64中的包应作为encoding/base64导入，其包名为base64，而非encoding_base64或encodingBase64。 包的导入者可通过包名来引用其内容，因此包中的可导出名称可以此来避免冲突。请勿使用import .记法，它可以简化必须在被测试包外运行的测试， 除此之外应尽量避免使用。 另一个简短的例子是once.Do，once.Do(setup)表述足够清晰， 使用once.DoOrWaitUntilDone(setup)完全就是画蛇添足。 长命名并不会使其更具可读性。一份有用的说明文档通常比额外的长名更有价值。 获取器 Getters Go并不对获取器（getter）和设置器（setter）提供自动支持。 你应当自己提供获取器和设置器，通常很值得这样做，但若要将 Get 放到获取器的名字中，既不符合习惯，也没有必要。 owner := obj.Owner() if owner != user { obj.SetOwner(user) } 接口名 Interface names 按照约定，只包含一个方法的接口应当以该方法的名称加上-er后缀来命名，如Reader、Writer、 Formatter、CloseNotifier等。 驼峰记法 MixedCaps 最后，go中约定使用MexedCaps或mixedCaps而不是下划线来编写多个词的名字。 ","date":"2020-07-22","objectID":"/go/:4:5","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"分号 Semicolons 和C一样，Go的正式语法使用分号(;)来结束语句。但和C不同的是，这些分号不会出现在源码中。取而代之，词法分析器会使用一条简单的规则来自动插入分号，因此大部分输入文本是自由的。 若在新行前的最后一个标记为一个标识符(包括int, float64)，数值或字符串常量的基本字面或以下标记之一: break continue fallthrough return ++ -- ) } 词法分析器将始终在该标记后面插入一个分号。这可以概括为：如果新行前的标记为语句的末尾，则插入一个分号。 分号也可以在关闭括号之前直接省略，因此一个语句像如下这样，不需要分号。 go func() { for { dst \u003c- \u003c-src } }() 通常go程序只在诸如for循环子句这样的地方使用分号。如果在一行中写多个语句，也需要使用分号分隔。 无论如何，你都不应该将控制结构(if, for, switch, select)的左括号放到下一行。你应该这样写： if i \u003c f() { g() } 而不是这样： if i \u003c f() // wrong! { // wrong! g() } ","date":"2020-07-22","objectID":"/go/:4:6","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"控制结构 Control structures go的控制结构与C有许多相似之处，但其不同才是独到之处。go不使用do或while循环，只有一个更通用的for；switch要更灵活些；if和switch像for一样接受一个可选的初始化语句；break和continue语句有一个可选的标签来确定那些break或continue；此外，还有一个包含类型选择和多路通信复用器的新控制结构——select。它们的语法也有些许不同，没有圆括号，主体必须始终使用大括号括住。 if if x \u003e 0 { return y } 由于if和switch可接收初始化语句，因此用它们来设置局部变量很常见。 if err := file.Chmod(0644); err != nil { log.Print(err) return err } 重新声明和重新赋值 Redeclaration and reassignment f, err := os.Open(name) d, err := f.Stat() 满足下列条件时，已被声明的变量可出现在:=声明中： 本次声明与已声明的变量出于同一作用域（若变量已在外层作用域中声明过，则此次声明会创建一个新的变量§） 在初始化中与其类型相应的值才能赋予变量，且在此次声明中至少另有一个变量是新声明的 for go的for循环统一了for和while。它有三种形式，但只有一种需要分号。 // Like a C for for init; condition; post { } // Like a C while for condition { } // Like a C for(;;) for { } 简短的声明使得更容易在循环中声明下标变量： sum := 0 for i := 0; i \u003c 10; i++ { sum += i } 若你想遍历数组、切片、字符串、映射，或从信道中读取消息，range子句能够帮你轻松实现循环。 for key, value := range oldMap { newMap[key] = value } // 只需要遍历下标，去掉第二个 for key := range m { if key.expired() { delete(m, key) } } // 只需要值，使用空白标识符(_)来丢弃下标 sum := 0 for _, value := range array { sum += value } switch go的switch比C更通用。其表达式无需为常量或整数，case语句会自上而下逐一进行求值直到匹配为止。如果switch后面没有表达式，它将匹配true。因此，我们可以将if-else-if-else链写成一个switch，这也更符合go的风格。 func unhex(c byte) byte { switch { case '0' \u003c= c \u0026\u0026 c \u003c= '9': return c - '0' case 'a' \u003c= c \u0026\u0026 c \u003c= 'f': return c - 'a' + 10 case 'A' \u003c= c \u0026\u0026 c \u003c= 'F': return c - 'A' + 10 } return 0 } switch并不会自动下溯，但case可通过逗号分隔来列举相同的处理条件。 func shouldEscape(c byte) bool { switch c { case ' ', '?', '\u0026', '=', '#', '+', '%': return true } return false } break语句可以使switch提前终止。不仅是switch，有时候也需要打破层层的循环。在go中，只需将标签(label)放置到循环外，然后break到标签。下例展示了两者的用法： Loop: for n := 0; n \u003c len(src); n += size { switch { case src[n] \u003c sizeOne: if validateOnly { break } size = 1 update(src[n]) case src[n] \u003c sizeTwo: if n+1 \u003e= len(src) { err = errShortInput break Loop } if validateOnly { break } size = 2 update(src[n] + src[n+1]\u003c\u003cshift) } } 当然，continue语句也能接受一个可选的标签，不过它只能应用在循环中。 作为这一节的结束，下例使用两个switch语句对字节切片进行比较： // Compare returns an integer comparing the two byte slices, // lexicographically. // The result will be 0 if a == b, -1 if a \u003c b, and +1 if a \u003e b func Compare(a, b []byte) int { for i := 0; i \u003c len(a) \u0026\u0026 i \u003c len(b); i++ { switch { case a[i] \u003e b[i]: return 1 case a[i] \u003c b[i]: return -1 } } switch { case len(a) \u003e len(b): return 1 case len(a) \u003c len(b): return -1 } return 0 } 类型选择 type switch switch也可用于判断接口变量的动态类型。如type switch通过括号中的关键字type使用类型断言。若switch在表达式中声明了一个变量，那么该变量的每个子句中都将有该变量对应的类型。 var t interface{} t = functionOfSomeType() switch t := t.(type) { default: fmt.Printf(\"unexpected type %T\\n\", t) // %T prints whatever type t has case bool: fmt.Printf(\"boolean %t\\n\", t) // t has type bool case int: fmt.Printf(\"integer %d\\n\", t) // t has type int case *bool: fmt.Printf(\"pointer to boolean %t\\n\", *t) // t has type *bool case *int: fmt.Printf(\"pointer to integer %d\\n\", *t) // t has type *int } ","date":"2020-07-22","objectID":"/go/:4:7","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"函数 function 多值返回 multiple return values 以下简单的函数可从字节数组中的特定位置获取其值，并返回该数值和下一个位置。 func nextInt(b []byte, i int) (int, int) { for ; i \u003c len(b) \u0026\u0026 !isDigit(b[i]); i++ { } x := 0 for ; i \u003c len(b) \u0026\u0026 isDigit(b[i]); i++ { x = x*10 + int(b[i]) - '0' } return x, i } 获取多值： for i := 0; i \u003c len(b); { x, i = nextInt(b, i) fmt.Println(x) } 命名结果形参 Named result parameters go函数的返回值(return)或结果(result)行参可被命名，并作为常规变量使用。就像传入的形参一样。命名后，一旦该函数开始执行，它们就会被初始化为与其类型相应的零值；若该函数执行了一条不带参数的return语句，则结果形参的当前值将作为返回值。 此名称不是强制性的，但它们能使代码更加简洁明了：它们就是文档。如果我们命名了nextInt的结果，那么它返回的int就值如其意了： func nextInt(b []byte, pos int) (value, nextPos int) { 由于被命名的结果已经初始化，且已经关联至无参数的返回，它们就能让代码简单而清晰。 func ReadFull(r Reader, buf []byte) (n int, err error) { for len(buf) \u003e 0 \u0026\u0026 err == nil { var nr int nr, err = r.Read(buf) n += nr buf = buf[nr:] } return } Defer go的defer语句用于预设一个函数调用(即推迟执行函数(deferred function))，该函数会在执行defer的函数返回之前立即执行。它显得非比寻常， 但却是处理一些事情的有效方式，例如无论以何种路径返回，都必须释放资源的函数。 典型的例子就是解锁互斥和关闭文件。 // Contents returns the file's contents as a string. func Contents(filename string) (string, error) { f, err := os.Open(filename) if err != nil { return \"\", err } defer f.Close() // f.Close will run when we're finished. var result []byte buf := make([]byte, 100) for { n, err := f.Read(buf[0:]) result = append(result, buf[0:n]...) // append is discussed later. if err != nil { if err == io.EOF { break } return \"\", err // f will be closed if we return here. } } return string(result), nil // f will be closed if we return here. } 推迟如Close之类的函数调用有两个好处。第一， 它能确保你不会忘记关闭文件。如果你以后又为该函数添加了新的返回路径时，这种情况往往就会发生。第二，它意味着关闭离打开很近， 这总比将它放在函数结尾处要清晰明了。 推迟函数（如果函数是一个方法则还包括接收者）的实参在推迟执行时就会求值，而不是在调用执行时才求值。这样不仅无需担心变量值在函数执行时被改变， 同时还意味着单个已推迟的调用可推迟多个函数的执行。一个简单的例子： for i := 0; i \u003c 5; i++ { defer fmt.Printf(\"%d \", i) } 被推迟的函数会按照**后见先出(LIFO)**的顺序执行，因此上述返回为4 3 2 1 0。一个更具实际意义的例子，让程序跟踪函数的运行： func trace(s string) { fmt.Println(\"entering:\", s) } func untrace(s string) { fmt.Println(\"leaving:\", s) } // Use them like this: func a() { trace(\"a\") defer untrace(\"a\") // do something.... fmt.Println(\"---\") } 输出结果如下： entering: a --- leaving: a 我们可以充分利用这个特点，即被推迟函数的实参在defer执行时才会求值。跟踪go程可针对反跟踪go程设置实参。 func trace(s string) string { fmt.Println(\"entering:\", s) return s } func un(s string) { fmt.Println(\"leaving:\", s) } func a() { defer un(trace(\"a\")) fmt.Println(\"in a\") } func b() { defer un(trace(\"b\")) fmt.Println(\"in b\") a() } func main() { b() } 输出如下： entering: b in b entering: a in a leaving: a leaving: b ","date":"2020-07-22","objectID":"/go/:4:8","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"数据 Data new go有两种分配原语，即内建函数new和make。new用来分配内存，但与其它同名函数不同，它不会初始化内存，只会将内存置零(zero)。new(T)会为类型T的新项分配已置零的内存控制，并返回它的地址，也即是类型*T的值。用go的术语，它返回一个指针，该指针指向新分配的类型为T的零值。 既然new返回的内存已置零，那么当你设计数据结构时，每种类型的零值就不必进一步初始化，这意味着该数据结构的使用者只需用new创建一个新的对象就能正常工作。 零值属性有各种好处，考虑以下声明： type SyncedBuffer struct { lock sync.Mutex buffer bytes.Buffer } SyncedBuffer类型的值也是在声明时就分配好内存就绪了。后续代码中， p和v无需进一步处理即可正确工作。 p := new(SyncedBuffer) // type *SyncedBuffer var v SyncedBuffer // type SyncedBuffer 构造函数与复合字面 Constructors and composite literals 有时零值还不够好，这时就需要一个初始化构造函数。 func NewFile(fd int, name string) *File { if fd \u003c 0 { return nil } f := new(File) f.fd = fd f.name = name f.dirinfo = nil f.nepipe = 0 return f } 这里显得代码过于冗长。我们可通过复合字面来简化它， 该表达式在每次求值时都会创建新的实例。 func NewFile(fd int, name string) *File { if fd \u003c 0 { return nil } f := File{fd, name, nil, 0} return \u0026f } 请注意，返回一个局部变量的地址完全没有问题，这点与C不同。该局部变量对应的数据 在函数返回后依然有效。实际上，每当获取一个复合字面的地址时，都将为一个新的实例分配内存， 因此我们可以将上面的最后两行代码合并： return \u0026File{fd, name, nil, 0} 复合字面的字段必须按顺序全部列出。但如果以k:v对的形式明确地标出元素，初始化字段时就可以按任何顺序出现，未给出的字段值将赋予零值。 因此，我们可以用如下形式： return \u0026File{fd: fd, name: name} make 再回到内存分配上来。不同于new，make只用于创建切片、映射和信道，并返回类型为T的一个已初始化的值。出现这种差异的原因在于，这三种类型本质上为引用数据类型，它们在使用前必须初始化。对于切片、映射和信道，make用于初始化其内部的数据结构并准备好将要使用的值。 // ew([]int) 会返回一个指向新分配的，已置零的切片结构， 即一个指向 nil 切片值的指针 // 会分配一个具有100个int的数组空间，接着创建一个长度为10， 容量为100并指向该数组中前10个元素的切片结构 make([]int, 10, 100) new和make的区别： var p *[]int = new([]int) // allocates slice structure; *p == nil; rarely useful var v []int = make([]int, 100) // the slice v now refers to a new array of 100 ints // Unnecessarily complex: var p *[]int = new([]int) *p = make([]int, 100, 100) // Idiomatic: v := make([]int, 100) 请记住，make只适用于映射、切片和信道且不返回指针。若要获得明确的指针， 请使用new分配内存。 Arrays 在详细规划内存布局时，数组非常有用，有时还能避免过多的内存分配，但它们主要用作切片的构件。 Go中数组： 数组是值。将一个数组赋予另一个数组会复制其所有元素。 若将某个数组传入某个函数，它将接收到该数组的一份副本而非指针。 数组的大小是其类型的一部分。类型[10]int和[20]int是不同的。 数组为值的属性很有用，但代价高昂。若你想要C那样的行为和效率，你可以传递一个指向该数组的指针。但这并不是Go的习惯用法，切片才是。 func Sum(a *[3]float64) (sum float64) { for _, v := range *a { sum += v } return } array := [...]float64{7.0, 8.5, 9.1} x := Sum(\u0026array) // Note the explicit address-of operator Slices 切片通过对数组进行封装，为数据序列提供了更通用、强大而方便的接口。 除了矩阵变换这类需要明确维度的情况外，Go中的大部分数组编程都是通过切片来完成的。 切片保存了对底层数组的引用，若你将某个切片赋予另一个切片，它们会引用同一个数组。只要切片不超出底层数组的限制，它的长度就是可变的。尽管append可修改切片的元素，但切片自身（其运行时数据结构包含指针、长度和容量）是通过值传递的。 二维切片 Two-dimensional slices Go的数组和切片都是一维的。要创建等价的二维数组或切片，就必须定义一个数组的数组， 或切片的切片。像下面这样： type Transform [3][3]float64 // A 3x3 array, really an array of arrays. type LinesOfText [][]byte // A slice of byte slices. Maps 映射是方便而强大的内建数据结构，它可以关联不同类型的值。其键可以是任何相等性操作符支持的类型， 如整数、浮点数、复数、字符串、指针、接口（只要其动态类型支持相等性判断）、结构以及数组。 切片不能用作映射键，因为它们的相等性还未定义。与切片一样，映射也是引用类型。 若将映射传入函数中，并更改了该映射的内容，则此修改对调用者同样可见。 var timeZone = map[string]int{ \"UTC\": 0*60*60, \"EST\": -5*60*60, \"CST\": -6*60*60, \"MST\": -7*60*60, \"PST\": -8*60*60, } 赋值和获取映射值的语法类似于数组，不同的是映射的索引不必为整数： offset := timeZone[\"EST\"] 有时你需要区分某项是不存在还是其值为零值。可以使用多重赋值的形式来分辨这种情况。 var seconds int var ok bool seconds, ok = timeZone[tz] 若仅需判断映射中是否存在某项而不关心实际的值，可使用空白标识符(_)来代替该值的一般变量。 _, present := timeZone[tz] 要删除映射中的某项，可使用内建函数 delete，它以映射及要被删除的键为实参。 即便对应的键不在该映射中，此操作也是安全的。 delete(timeZone, \"PDT\") // Now on Standard Time Printing Go采用的格式化打印风格和C的printf族类似，但却更加丰富而通用。这些函数位于fmt包中，且函数名首字母均为大写：如fmt.Printf、fmt.Fprintf，fmt.Sprintf等。 fmt.Printf(\"Hello %d\\n\", 23) fmt.Fprint(os.Stdout, \"Hello \", 23, \"\\n\") fmt.Println(\"Hello\", 23) fmt.Println(fmt.Sprint(\"Hello \", 23)) append 内建函数append像这个： func append(slice []T, elements ...T) []T ","date":"2020-07-22","objectID":"/go/:4:9","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"初始化 Initialization 尽管从表面上看，Go的初始化过程与C或C++并不算太大，但它确实更为强大。 在初始化过程中，不仅可以构建复杂的结构，还能正确处理不同包对象间的初始化顺序。 常量 Constants Go中的常量就是不变量。它们在编译时创建，即便它们可能是函数中定义的局部变量。 常量只能是数字、字符（符文）、字符串或布尔值。由于编译时的限制， 定义它们的表达式必须也是可被编译器求值的常量表达式。 变量 变量的初始化与常量类似，但其初始值也可以是在运行时才被计算的一般表达式。 var ( home = os.Getenv(\"HOME\") user = os.Getenv(\"USER\") gopath = os.Getenv(\"GOPATH\") ) init The init function 最后，每个源文件都可以通过定义自己的无参数init函数来设置一些必要的状态。而它的结束就意味着初始化结束： 只有该包中的所有变量声明都通过它们的初始化器求值后init才会被调用， 而那些init只有在所有已导入的包都被初始化后才会被求值。 除了那些不能被表示成声明的初始化外，init 函数还常被用在程序真正开始执行前，检验或校正程序的状态。 Besides initializations that cannot be expressed as declarations, a common use of init functions is to verify or repair correctness of the program state before real execution begins. func init() { if user == \"\" { log.Fatal(\"$USER not set\") } if home == \"\" { home = \"/home/\" + user } if gopath == \"\" { gopath = home + \"/go\" } // gopath may be overridden by --gopath flag on command line. flag.StringVar(\u0026gopath, \"gopath\", gopath, \"override default GOPATH\") } ","date":"2020-07-22","objectID":"/go/:4:10","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"方法 Methods 指针与值 Pointers vs. Values 以指针或值为接收者的区别在于：值方法可通过指针和值调用， 而指针方法只能通过指针来调用。 ","date":"2020-07-22","objectID":"/go/:4:11","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"接口和其它类型 Interfaces Go中的接口为指定对象的行为提供了一种方法：如果某样东西可以完成这个， 那么它就可以用在这里。 每种类型都能实现多个接口。 类型转换 Conversions 接口转换与类型断言 Interface conversions and type assertions 类型选择是类型转换的一种形式：它接受一个接口，在选择中根据其判断选择对应的情况， 并在某种意义上将其转换为该种类型。 type Stringer interface { String() string } var value interface{} // Value provided by caller. switch str := value.(type) { case string: return str case Stringer: return str.String() } 类型断言接受一个接口值， 并从中提取指定的明确类型的值。 通用性 Generality 若某种现有的类型仅实现了一个接口，且除此之外并无可导出的方法，则该类型本身就无需导出。 仅导出该接口能让我们更专注于其行为而非实现，其它属性不同的实现则能镜像该原始类型的行为。 这也能够避免为每个通用接口的实例重复编写文档。 在这种情况下，构造函数应当返回一个接口值而非实现的类型。 接口和方法 Interfaces and methods 由于几乎任何类型都能添加方法，因此几乎任何类型都能满足一个接口。 // 一个很直观的例子就是 http 包中定义的 Handler 接口。任何实现了 Handler 的对象都能够处理HTTP请求 type Handler interface { ServeHTTP(ResponseWriter, *Request) } ","date":"2020-07-22","objectID":"/go/:4:12","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"空白标识符 The blank identifier 空白标识符(_)可被赋予或声明为任何类型的任何值，而其值会被无害地丢弃。它有点像Unix中的/dev/null文件：它表示只写的值，在需要变量但不需要实际值的地方用作占位符。 多重赋值中的空白标识符 The blank identifier in multiple assignment for range循环中对空表标识符的用法是一种具体情况，更一般的情况即为多重赋值。 if _, err := os.Stat(path); os.IsNotExist(err) { fmt.Printf(\"%s does not exist\\n\", path) } 未使用的导入和变量 Unused imports and variables 若导入某个包或声明某个变量而不使用它就会产生错误。未使用的包会让程序膨胀并拖慢编译速度， 而已初始化但未使用的变量不仅会浪费计算能力，还有可能暗藏着更大的Bug。 要让编译器停止关于未使用导入的抱怨，需要空白标识符来引用已导入包中的符号。 package main import ( \"fmt\" \"io\" \"log\" \"os\" ) var _ = fmt.Printf // For debugging; delete when done. var _ io.Reader // For debugging; delete when done. func main() { fd, err := os.Open(\"test.go\") if err != nil { log.Fatal(err) } // TODO: use fd. _ = fd } 为副作用而导入 Import for side effect 有时导入某个包只是为了其副作用， 而没有任何明确的使用。只为了其副作用来导入该包， 只需将包重命名为空白标识符： import _ \"net/http/pprof\" 这种导入格式能明确表示该包是为其副作用而导入的，因为没有其它使用该包的可能： 在此文件中，它没有名字。（若它有名字而我们没有使用，编译器就会拒绝该程序。） 接口检查 Interface checks 一个类型无需显式地声明它实现了某个接口。取而代之，该类型只要实现了某个接口的方法， 其实就实现了该接口。在实践中，大部分接口转换都是静态的，因此会在编译时检测。 若只需要判断某个类型是否是实现了某个接口，而不需要实际使用接口本身 （可能是错误检查部分），就使用空白标识符来忽略类型断言的值： if _, ok := val.(json.Marshaler); ok { fmt.Printf(\"value %v of type %T implements json.Marshaler\\n\", val, val) } 在这种结构中出现空白标识符，即表示该声明的存在只是为了类型检查。 不过请不要为满足接口就将它用于任何类型。作为约定， 仅当代码中不存在静态类型转换时才能这种声明，毕竟这是种罕见的情况。 ","date":"2020-07-22","objectID":"/go/:4:13","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"内嵌 Embedding Go并不提供典型的，类型驱动的子类化概念，但通过将类型内嵌到结构体或接口中， 它就能借鉴部分实现。 ","date":"2020-07-22","objectID":"/go/:4:14","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"并发 Concurrency 通过通信共享内存 Share by communicating 并发编程是个很大的话题。这里只讨论一些go特有的东西。 在并发编程中，为实现对共享变量的正确访问需要精确的控制，这在多数环境下都很困难。 Go语言另辟蹊径，它将共享的值通过信道传递，实际上，多个独立执行的线程从不会主动共享。 在任意给定的时间点，只有一个Go程能够访问该值。数据竞争从设计上就被杜绝了。 为了提倡这种思考方式，我们将它简化为一句口号： 不要通过共享内存来通信，而应通过通信来共享内存(Do not communicate by sharing memory; instead, share memory by communicating)。 这种方法意义深远。例如，引用计数通过为整数变量添加互斥锁来很好地实现。 但作为一种高级方法，通过信道来控制访问能够让你写出更简洁，正确的程序。 go程 Goroutines 称它为GO程是因为现有的术语——线程(threads), 协程(coroutines), 进程(process)无法准确表达它的含义。Go程具有简单的模型：它是与其它Go程并发运行在同一地址空间的函数。它是轻量级的， 所有小号几乎就只有栈空间的分配。而且栈最开始是非常小的，所以它们很廉价， 仅在需要时才会随着堆空间的分配（和释放）而变化。 Go程在多线程操作系统上可实现多路复用，因此若一个线程阻塞，比如说等待I/O， 那么其它的线程就会运行。Go程的设计隐藏了线程创建和管理的诸多复杂性。 // 在函数或方法前添加go关键字能够在新的Go程中调用它。当调用完成后， 该Go程也会安静地退出 // 效果有点像Unix Shell中的 \u0026 符号，它能让命令在后台运行 go list.Sort() // run list.Sort concurrently; don't wait for it. 函数字面在Go程调用中非常有用。 func Announce(message string, delay time.Duration) { go func() { time.Sleep(delay) fmt.Println(message) }() // Note the parentheses - must call the function. } 在Go中，函数字面都是闭包(closures)：其实现在保证了函数内引用变量的生命周期与函数的活动时间相同。这些函数没什么实用性，因为它们没有实现完成时的信号处理。因此，我们需要信道。 信道 Channels 信道与映射一样，也需要通过make来分配内存，其结果充当了对底层数据结构的引用。若提供了一个可选的整数形参，它就会为该信道设置缓冲区大小。默认值是零，表示不带缓冲(unbuffered)的或同步(synchronous)的信道。 ci := make(chan int) // unbuffered channel of integers cj := make(chan int, 0) // unbuffered channel of integers cs := make(chan *os.File, 100) // buffered channel of pointers to Files 无缓冲信道在通信时会同步交换数据，它能确保（goroutine）计算处于确定状态。 信道有很多惯用方法。 c := make(chan int) // Allocate a channel. // Start the sort in a goroutine; when it completes, signal on the channel. go func() { list.Sort() c \u003c- 1 // Send a signal; value does not matter. }() doSomethingForAWhile() \u003c-c // Wait for sort to finish; discard sent value. 接收者在收到数据前会一直阻塞。若信道是不带缓冲的，那么在接收者收到值前， 发送者会一直阻塞；若信道是带缓冲的，则发送者仅在值被复制到缓冲区前阻塞； 若缓冲区已满，发送者会一直等待直到某个接收者取出一个值为止。 带缓冲的信道可被用作信号量，例如限制吞吐量。 回到编写服务器的一般问题上来。另一种管理资源的好方法就是启动固定数量的handleGo程，一起从请求信道中读取数据。Go程的数量限制了同时调用process的数量。Serve同样会接收一个通知退出的信道， 在启动所有Go程后，它将阻塞并暂停从信道中接收消息。 func handle(queue chan *Request) { for r := range queue { process(r) } } func Serve(clientRequests chan *Request, quit chan bool) { // Start handlers for i := 0; i \u003c MaxOutstanding; i++ { go handle(clientRequests) } \u003c-quit // Wait to be told to exit. } 信道中的信道 Channels of channels Go最重要的特性就是信道是一等值，它可以被分配并像其它值到处传递。 这种特性通常被用来实现安全(safe)、并行(parallel)的多路分解(demultiplexing)。 并行化 Parallelization 这些设计的另一个应用是在多CPU核心上实现并行计算。如果计算过程能够被分为几块 可独立执行的过程，它就可以在每块计算结束时向信道发送信号，从而实现并行处理。 const numCPU = 4 // number of CPU cores func (v Vector) DoAll(u Vector) { c := make(chan int, numCPU) // Buffering optional but sensible. for i := 0; i \u003c numCPU; i++ { go v.DoSome(i*len(v)/numCPU, (i+1)*len(v)/numCPU, u, c) } // Drain the channel. for i := 0; i \u003c numCPU; i++ { \u003c-c // wait for one task to complete } // All done. } 目前Go运行时的实现默认并不会并行执行代码，它只为用户层代码提供单一的处理核心。 任意数量的Go程都可能在系统调用中被阻塞，而在任意时刻默认只有一个会执行用户层代码。 它应当变得更智能，而且它将来肯定会变得更智能。但现在，若你希望CPU并行执行， 就必须告诉运行时你希望同时有多少Go程能执行代码。除了为CPU数量创建一个创建，还有两种方法： // 1 var numCPU = runtime.NumCPU() // 2 var numCPU = runtime.GOMAXPROCS(0) 注意不要混淆并发(concurrency)和并行(parallelism)的概念。并发是用可独立执行的组件构造程序的方法， 而并行则是为了效率在多CPU上平行地进行计算。 尽管Go的并发特性能够让某些问题更易构造成并行计算， 但Go仍然是种并发而非并行的语言，且Go的模型并不适合所有的并行问题。 泄露的缓冲区 A leaky buffer 并发编程的工具甚至能很容易地表达非并发的思想。 这里有个提取自RPC包的例子。 客户端Go程从某些来源，可能是网络中循环接收数据。为避免分配和释放缓冲区， 它保存了一个空闲链表，使用一个带缓冲信道表示。若信道为空，就会分配新的缓冲区。 一旦消息缓冲区就绪，它将通过serverChan被发送到服务器。 var freeList = make(chan *Buffer, 100) var serverChan = make(chan *Buffer) func client() { for { var b *Buffer // Grab a buffer if available; allocate if not. select { case b = \u003c-freeList: // Got one; nothing more to do. default: // None free, so allocate a new one. b = new(Buffer) } load(b) // Read next message from the net. serverChan \u003c- b // Send to server. } } 服务器从客户端循环接收每个消息，处理它们，并将缓冲区返回给空闲列表。 func server() { for { b := \u003c-serverChan // Wait for work. process(b) // Reuse buffer if there's room. select { case freeList \u003c- b: // Buffer on free list; nothing more to do. default: // Free list full, just carry on. } } } 客户端试图从freeList中获取缓冲区；若没有缓冲区可用","date":"2020-07-22","objectID":"/go/:4:15","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"错误 error 库例程通常需要向调用者返回某种类型的错误提示。之前提到过，Go语言的多值返回特性， 使得它在返回常规的值时，还能轻松地返回详细的错误描述。 按照约定，错误的类型通常为error，这是一个内建的简单接口。 type error interface { Error() string } 库的编写者通过更丰富的底层模型可以轻松实现这个接口，这样不仅能看见错误， 还能提供一些上下文。 // PathError records an error and the operation and // file path that caused it. type PathError struct { Op string // \"open\", \"unlink\", etc. Path string // The associated file. Err error // Returned by the system call. } func (e *PathError) Error() string { return e.Op + \" \" + e.Path + \": \" + e.Err.Error() } // 生成的错误信息例子 // open /etc/passwx: no such file or directory 错误字符串应尽可能地指明它们的来源，例如产生该错误的包名前缀。若调用者关心错误的完整细节，可使用类型选择或者类型断言来查看特定错误，并抽取其细节。 Panic 向调用者报告错误的一般方式就是将error作为额外的值返回。但如果错误时不可恢复的呢？有时程序就是不能继续运行。为此，我们提供了内建的panic函数，它会产生一个运行时错误并终止程序。该函数接受一个任意类型的实参（一般为字符串），并在程序终止时打印。 它还能表明发生了意料之外的事情，比如从无限循环中退出了。 // A toy implementation of cube root using Newton's method. func CubeRoot(x float64) float64 { z := x/3 // Arbitrary initial value for i := 0; i \u003c 1e6; i++ { prevz := z z -= (z*z*z-x) / (3*z*z) if veryClose(z, prevz) { return z } } // A million iterations has not converged; something is wrong. panic(fmt.Sprintf(\"CubeRoot(%g) did not converge\", x)) } 实际的库函数应避免panic。若问题可以被屏蔽或解决， 最好就是让程序继续运行而不是终止整个程序。 Recover 当panic被调用后，程序将立刻终止当前函数的执行，并开始回溯Go程的栈，运行任何被推迟的函数。 若回溯到达Go程栈的顶端，程序就会终止。不过我们可以用内建的recover函数来重新或来取回Go程的控制权限并使其恢复正常执行。 调用recover将停止回溯过程，并返回传入panic的实参。 由于在回溯时只有被推迟函数中的代码在运行，因此recover只能在被推迟的函数中才有效。 recover的一个应用就是在服务器中终止失败的Go程而无需杀死其它正在执行的Go程。 func server(workChan \u003c-chan *Work) { for work := range workChan { go safelyDo(work) } } func safelyDo(work *Work) { defer func() { if err := recover(); err != nil { log.Println(\"work failed:\", err) } }() do(work) } 在此例中，若do(work)触发了Panic，其结果就会被记录， 而该Go程会被干净利落地结束，不会干扰到其它Go程。我们无需在推迟的闭包中做任何事情， recover会处理好这一切。 通过恰当地使用恢复模式，do函数（及其调用的任何代码）可通过调用 panic 来避免更坏的结果。我们可以利用这种思想来简化复杂软件中的错误处理。 让我们看看regexp包的理想化版本，它会以局部的错误类型调用 panic 来报告解析错误。以下是一个error类型的 Error方法和一个Compile函数的定义： // Error is the type of a parse error; it satisfies the error interface. type Error string func (e Error) Error() string { return string(e) } // error is a method of *Regexp that reports parsing errors by // panicking with an Error. func (regexp *Regexp) error(err string) { panic(Error(err)) } // Compile returns a parsed representation of the regular expression. func Compile(str string) (regexp *Regexp, err error) { regexp = new(Regexp) // doParse will panic if there is a parse error. defer func() { if e := recover(); e != nil { regexp = nil // Clear return value. err = e.(Error) // Will re-panic if not a parse error. } }() return regexp.doParse(str), nil } 顺便一提，这种重新触发Panic的惯用法会在产生实际错误时改变Panic的值。 然而，不管是原始的还是新的错误都会在崩溃报告中显示，因此问题的根源仍然是可见的。 这种简单的重新触发Panic的模型已经够用了，毕竟他只是一次崩溃。 但若你只想显示原始的值，也可以多写一点代码来过滤掉不需要的问题，然后用原始值再次触发Panic。 ","date":"2020-07-22","objectID":"/go/:4:16","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"A web server 让我们以一个完整的Go程序作为结束吧，一个Web服务器。该程序其实只是个Web服务器的重用。 package main import ( \"flag\" \"html/template\" \"log\" \"net/http\" ) var addr = flag.String(\"addr\", \":1718\", \"http service address\") // Q=17, R=18 var templ = template.Must(template.New(\"qr\").Parse(templateStr)) func main() { flag.Parse() http.Handle(\"/\", http.HandlerFunc(QR)) err := http.ListenAndServe(*addr, nil) if err != nil { log.Fatal(\"ListenAndServe:\", err) } } func QR(w http.ResponseWriter, req *http.Request) { templ.Execute(w, req.FormValue(\"s\")) } const templateStr = ` \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eQR Link Generator\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e {{if.}}\u003cimg src=\"http://chart.apis.google.com/chart?chs=300x300\u0026cht=qr\u0026choe=UTF-8\u0026chl={{.}}\" /\u003e \u003cbr\u003e {{.}}\u003cbr\u003e \u003cbr\u003e {{end}}\u003cform action=\"/\" name=f method=\"GET\"\u003e \u003cinput maxLength=1024 size=70 name=s value=\"\" title=\"Text to QR Encode\"\u003e \u003cinput type=submit value=\"Show QR\" name=qr\u003e \u003c/form\u003e \u003c/body\u003e \u003c/html\u003e ` Go语言强大到能让很多事情以短小精悍的方式解决。 ","date":"2020-07-22","objectID":"/go/:4:17","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"调试 Diagnostics: https://golang.org/doc/diagnostics.html 总结工具和方法来诊断Go程序 ","date":"2020-07-22","objectID":"/go/:5:0","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"介绍 Go生态提供了一套API和工具来诊断go程序的逻辑和性能问题。本章总结了可用的工具，帮助用户去选择正确的工具来解决问题。 调试方案可分为一下几组： Profiling： 分析工具分析go程序的复杂性和成本，如内存使用和调用函数的频率，以确定go程序的昂贵的部分； Tracing： 追踪是分析整个延迟和调用或用户请求的生命周期的一种方法； Debugging： 调试可以让我们暂停go程序，检查并执行。程序的状态和流程可通过调试进行验证； Runtime statistics and events： 收集和分析运行时状态和事件，提供go程序运行状态的高度概括。 ","date":"2020-07-22","objectID":"/go/:5:1","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"分析 Profiling 对于识别昂贵的或频繁调用的代码部分，分析很有用。go runtime通过pprof可视化工具以格式化形式提供了分析数据。可通过go test或net/http/pprof包来收集分析数据。用户需要在代码顶级路径使用pprof工具来收集分析路径。 由runtime/pprof包预分析： cpu: cpu porfile，报告程序花费的CPU时间。 heap： heap profile，报告内存分配样本，监控当前和历史的内存使用，并检查内存泄漏。 threadcreate： thread profile，报告程序的操作系统的线程创建部分。 goroutine： goroutine profile，报告当前所有goroutine的栈追踪(stack trace)。 block： block profile，报告goroutine在哪里等待同步原语(synchronization primitives)阻塞。此功能默认关闭，使用runtime.SetBlockProfileRate开启。 mutex： mutex profile，报告锁的争用情况。当你认为由于互斥锁争用，CPU没有得到充分利用时，使用此功能。此功能默认关闭，使用runtime.SetMutexProfileFraction启用。 ","date":"2020-07-22","objectID":"/go/:5:2","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"追踪 Tracing 追踪是一种来分析整个调用链的生命周期的延迟的方法。go提供了golang.org/x/net/trace包作为每个go节点的最小化追踪后端，并使用一个简单的面板来提供一个小型的仪器库。go还提供了一个可执行的追踪程序在内部追踪运行时事件。 追踪使我们能够： 在go程序内工具和分析应用延迟。 衡量一个长链调用的特定调用的开销。 计算使用率和性能优化。 go的生态提供了多种追踪库。 ","date":"2020-07-22","objectID":"/go/:5:3","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"调试 Debugging 调试是识别一个程序行为不端的过程。调试器让我们了解程序的执行流程和当前状态。有几种调试风格，本章节将仅聚焦于一个调试器附加到一个程序和核心转储(core dump)调试。 go用户大多使用以下调试器： (Delve)[https://github.com/go-delve/delve]： Delve是一个go lang调试器。它支持go runtime和内建类型。它正努力成为一个go程序的全功能可靠的调试器。 (GDB)[https://golang.org/doc/gdb]： go通过标准的go编译器和Gccgo提供了GDB支持。尽管GDB可以用来调试go程序，但这不理想，可能导致混乱。 ","date":"2020-07-22","objectID":"/go/:5:4","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"运行时统计数据和事件 Runtime statistics and events 运行时(runtime)提供了统计信息和内部事件的报告，为用户在运行时级别诊断性能和利用率的问题。 用户可以监控这些数据，以便于更好地了解go程序的总体运行状况和性能。一些常用的监控统计数据和状态： runtime.ReadMemStats： 报告与堆分配(heap allocation)和垃圾回收(garbage collection)相关的指标。内存统计数据对监控进程消耗了多少内存资源是有用的，进程是否能很好地利用内存，并捕捉到内存泄漏。 debug.ReadGCStats： 阅读关于垃圾回收的统计数据。查看多少资源都花在了垃圾回收阶段也是很有用的。它还报告垃圾回收暂停和暂停事件百分数的时间线。 debug.Stack： 返回当前的栈追踪。栈追踪对于查看有多少goroutine正在运行，它们在做什么，它们是否阻塞很有用。 debug.WriteHeapDump： 中止所有goroutine的执行，并允许转存(dump)堆(heap)到文件。一个堆转存是go程序在特定时间内存的快照。它包含所有分配的对象，以及goroutine, finalizers… runtime.NumGoroutine： 返回当前的goroutine数量。该值可以被监测、以了解是否有足够的goroutine被利用，或检测goroutine泄漏。 执行追踪 Execution tracer go使用runtime execution tracer来捕获广泛的运行时事件。调度、系统调用、垃圾回收、堆大小和其它收集的事件。执行追踪器是一个检测延迟和使用率问题的工具。你可以检查CPU如何利用，网络或系统调用时，抢占对goroutine的原因。 追踪器对这些有用： 理解你的goroutine如何执行 理解一些核心(core)的运行时事件，如垃圾回收 确定不佳的并行执行 然而，它不是很大用于识别热点（如分析内存溢出或CPU使用的原因）。使用分析工具而不是先定位它们。 详细信息查看go tool trace，来收集和分析运行时追踪。 GODEBUG 如果GODEBUG环境变量相应地设置，运行时也会发出事件和信息。 GODEBUG=gctrace=1： 在每个收集中打印垃圾回收器事件，汇总内存收集量和停顿的长度。 GODEBUG=schedtrace=X： 每个x毫秒打印调度事件。 GODEBUG环境变量可用于在标准库和运行时中禁用指令集扩展。 GODEBUG=cpu.all=off： 禁止使用所有可选的扩展指令集。 GODEBUG=cpu.extension=off： 禁止从指定的指令集扩展中使用指令。 ","date":"2020-07-22","objectID":"/go/:5:5","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"FAQ docs: https://golang.org/doc/faq 有关go的常见问答。 ","date":"2020-07-22","objectID":"/go/:6:0","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"Go wiki docs: https://github.com/golang/go/wiki 由GO社区维护的wiki。 参考 References ","date":"2020-07-22","objectID":"/go/:7:0","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"包 Package Documentation: https://golang.org/pkg/ Go标准库文档。 ","date":"2020-07-22","objectID":"/go/:8:0","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"命令 Command Documentation: https://golang.org/doc/cmd Go工具文档。 ","date":"2020-07-22","objectID":"/go/:9:0","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"语言规范 Language Specification: https://golang.org/ref/spec 官方Go语言规范。 ","date":"2020-07-22","objectID":"/go/:10:0","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"内存模型 The Go Memory Model: https://golang.org/ref/mem \r\r \r\r一些工具 ","date":"2020-07-22","objectID":"/go/:11:0","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"goreleaser goreleaser是用于Go项目的发布自动化工具。目标是简化构建、发版和发布步骤，同时为所有步骤提供适当的自定义选项。 goreleaser运行主要有以下四个步骤： defaulting：为每个步骤配置明智的默认值 building：构建二进制，归档，打包，docker镜像… publishing：发布版本到SCM, Docker仓库，存储… announcing：声明你的发布 \r\r","date":"2020-07-22","objectID":"/go/:12:0","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"CI \r\r","date":"2020-07-22","objectID":"/go/:12:1","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"常用命令 goreleaser的一些常用命令。 # Generates a .goreleaser.yaml file goreleaser init # Checks if configuration is valid goreleaser check # Builds the current project goreleaser build # Generate the autocompletion script for the specified shell goreleaser completion # Releases the current project goreleaser release \r\r","date":"2020-07-22","objectID":"/go/:12:2","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"配置详解 关于.goreleaser.yaml配置文件的详细介绍。 # SCM(software configuration management)软件配置管理# github, gitlab, gitea的token# env_filesenv_files:github_token:/path/to/my/github_tokenenv_files:gilab_token:/path/to/my/gitlab_tokenenv_files:gitea_token:~/.path/to/my/gitea_token# Basics# includesincludes:- from_file:path:./config/goreleaser.yaml- from_url:url:https://raw.githubusercontent.com/goreleaser/goreleaser/main/.goreleaser.yaml- from_url:url:caarlos0/goreleaserfiles/main/packages.yml# the https://raw.githubusercontent.com/ prefix may be ommited- from_url:url:https://api.mycompany.com/configs/goreleaser.yamlheaders:# header values are expanded in case they are environment variablesx-api-token:\"${MYCOMPANY_TOKEN}\"# name template# 包含很多内置变量: .ProjectName, .Version, .Tag, .Branch, .ShortCommit...# 与go相关的： .Os(GOOS), .Arch(GOARCH), .Arm(GOARM)...# enviroment variables# 全局环境变量# .goreleaser.yamlenv:- GO111MODULE=on- FOO={{ .Env.FOOBAR }}- ENV_WITH_DEFAULT={{ if index .Env \"ENV_WITH_DEFAULT\" }}{{ .Env.ENV_WITH_DEFAULT }}{{ else }}default_value{{ end }}# global hooksbefore:hooks:- make clean- go generate ./...- go mod tidy- touch {{ .Env.FILE_TO_TOUCH }}# dist folder# 默认在./dist目录下创建工件# 可修改dist:another-folder-that-is-not-dist# project name# 项目名称project_name:myproject# Build# buildsbuilds:# You can have multiple builds defined as a yaml list-# ID of the build.# Defaults to the project name.id:\"my-build\"# Path to project's (sub)directory containing Go code.# This is the working directory for the Go build command(s).# Default is `.`.dir:go# Path to main.go file or main package.# Notice: when used with `gomod.proxy`, this must be a package.## Default is `.`.main:./cmd/my-app# Binary name.# Can be a path (e.g. `bin/app`) to wrap the binary in a directory.# Default is the name of the project directory.binary:program# Custom flags templates.# Default is empty.flags:- -tags=dev- -v# Custom asmflags templates.# Default is empty.asmflags:- -D mysymbol- all=-trimpath={{.Env.GOPATH}}# Custom gcflags templates.# Default is empty.gcflags:- all=-trimpath={{.Env.GOPATH}}- ./dontoptimizeme=-N# Custom ldflags templates.# Default is `-s -w -X main.version={{.Version}} -X main.commit={{.Commit}} -X main.date={{.Date}} -X main.builtBy=goreleaser`.ldflags:- -s -w -X main.build={{.Version}}- ./usemsan=-msan# Custom build tags templates.# Default is empty.tags:- osusergo- netgo- static_build- feature# Custom environment variables to be set during the builds.# Default is empty.env:- CGO_ENABLED=0# GOOS list to build for.# For more info refer to: https://golang.org/doc/install/source#environment# Defaults are darwin and linux.goos:- freebsd- windows# GOARCH to build for.# For more info refer to: https://golang.org/doc/install/source#environment# Defaults are 386, amd64 and arm64.goarch:- amd64- arm- arm64# GOARM to build for when GOARCH is arm.# For more info refer to: https://golang.org/doc/install/source#environment# Default is only 6.goarm:- 6- 7# GOMIPS and GOMIPS64 to build when GOARCH is mips, mips64, mipsle or mips64le.# For more info refer to: https://golang.org/doc/install/source#environment# Default is only hardfloat.gomips:- hardfloat- softfloat# List of combinations of GOOS + GOARCH + GOARM to ignore.# Default is empty.ignore:- goos:darwingoarch:386- goos:linuxgoarch:armgoarm:7- goarm:mips64gomips:hardfloat# Optionally override the matrix generation and specify only the final list of targets.# Format is `{goos}_{goarch}` with optionally a suffix with `_{goarm}` or `_{gomips}`.# This overrides `goos`, `goarch`, `goarm`, `gomips` and `ignores`.targets:- linux_amd64- darwin_arm64- linux_arm_6# Set a specific go binary to use when building. It is safe to ignore# this option in most cases.# Default is \"go\"gobinary:\"go1.13.4\"# Set the modified timestamp on the output binary, typically# you would do this to ensure a build was reproducible. Pass# empty string to skip modifying the output.# Default is empty string.mod_timestamp:'{{ .CommitTimestamp }}'# Hooks can be used","date":"2020-07-22","objectID":"/go/:12:3","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"golangci-lint golangci-ling github: https://github.com/golangci/golangci-lint golangci-lint是一个用于go项目的静态检查工具。 \r\r","date":"2020-07-22","objectID":"/go/:13:0","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"go-demo 这个项目go-demo写了很多go实例代码，可以看看。 ","date":"2020-07-22","objectID":"/go/:14:0","tags":["go","golang"],"title":"Go","uri":"/go/"},{"categories":["programming"],"content":"参考: wiki: https://zh.wikipedia.org/zh-cn/JavaScript W3school: https://www.w3school.com.cn/js/index.asp 廖雪峰：https://www.liaoxuefeng.com/wiki/1022910821149312 \r环境： ELRH7x86_64 \r\r \r\r简介 Introduction JavaScript(JS)是一种解释型的高级编程语言。JavaScript是一门基于原型、函数先行的语言，是一门多范式的语言，它支持面向对象编程，命令式编程，以及函数式编程。它提供语法来操控文本、数组、日期以及正则表达式等，不支持I/O，比如网络、存储和图形等，但这些都可以由它的宿主环境提供支持。它已经由ECMA（欧洲电脑制造商协会）通过ECMAScript实现语言的标准化。它被世界上的绝大多数网站所使用，也被世界主流浏览器（Chrome、IE、Firefox、Safari、Opera）支持。 虽然JavaScript与Java这门语言不管是在名字上，或是在语法上都有很多相似性，但这两门编程语言从设计之初就有很大的不同。为什么起名叫JavaScript？原因是当时Java语言非常红火，所以网景公司希望借Java的名气来推广，但事实上JavaScript除了语法上有点像Java，其他部分基本上没啥关系。 JavaScript是世界上最流行的脚本语言，因为你在电脑、手机、平板上浏览的所有的网页，以及无数基于HTML5的手机App，交互逻辑都是由JavaScript驱动的。随着HTML5在PC和移动端越来越流行，JavaScript变得更加重要了。并且，新兴的Node.js把JavaScript引入到了服务器端，JavaScript已经变成了全能型选手。 \r\r","date":"2020-03-16","objectID":"/javascript/:0:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"ECMAScript 为了让JavaScript成为全球标准，几个公司联合ECMA（European Computer Manufacturers Association）组织定制了JavaScript语言的标准，被称为ECMAScript标准。 所以简单说来就是，ECMAScript是一种语言标准，而JavaScript是网景公司对ECMAScript标准的一种实现。 JavaScript的标准是ECMAScript 。ECMAScript第一版标准发布于1997年。 那为什么不直接把JavaScript定为标准呢？因为JavaScript是网景的注册商标。 \r\r \r\r快速入门 JavaScript代码可以直接嵌在网页的任何地方，不过通常我们都把JS代码放到\u003chead\u003e中。由\u003cscript\u003e...\u003c/script\u003e包含的代码就是JS代码，它将直接被浏览器执行。 \u003chtml\u003e \u003chead\u003e \u003cscript\u003e alert(\"hello, world\"); \u003c/script\u003e \u003c/head\u003e \u003c/html\u003e 第二种方法是把JavaScript放到单独的.js文件，然后在HTML中通过\u003cscript src=\"...\"\u003e\u003c/script\u003e来引入。 \u003chtml\u003e \u003chead\u003e \u003cscript src=\"/static/js/hello.js\"\u003e\u003c/script\u003e \u003c/head\u003e \u003c/html\u003e 将JS代码放入单独的文件中更有利于维护代码，并且多个页面可以复用。 在同一个页面中引入多个JS文件（或编写多个JS代码），浏览器将按照顺序依次执行。 有时会看到\u003cscript\u003e有一个type属性。但其实这是没有必要的，以你为默认的type就是javascript，所以不必显式指定。 \u003cscript type=\"text/javascript\"\u003e ... \u003c/script\u003e console.log()代替alert()的好处是可以避免弹出烦人的对话框。 // 在chrome中console中查看 var x = 100; console.log(x) \r\r","date":"2020-03-16","objectID":"/javascript/:1:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"如何运行JS 要让浏览器运行JavaScript，必须先有一个HTML页面，在HTML页面中引入JavaScript。然后，然浏览器加载该HTML页面，就可以执行JavaScript代码。 \r\r","date":"2020-03-16","objectID":"/javascript/:2:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"基本语法 每个语句以分号;结束，语句块使用花括号{}。 // 不建议一行写多个语句 var x = 1; var y = 2; /* 缩进不是JS语法要求所必须，但有助于我们理解代码层次。 缩进通常是4个空格 */ if (x \u003e y) { x = y; } \r\r","date":"2020-03-16","objectID":"/javascript/:3:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"数据类型 数字(Number) 字符串(String) 布尔(Bool) 空(Null) 未定义(Undefined) Symbol: 独一无二的值 数组(Array) 对象(Object) 函数(Function) JS不区分整数和浮点数，统一用Number表示。 NaN这个特殊的数字与所有其它值都不相等，包括它自己。 字符串以单引号或双引号括起来的任意文本。可通过转义字符()进行转义。 布尔值只有true和false两种值。 null表示一个空值，如Python的None。undefined表示未定义。大多数情况下，我们都应该使用null，undefined仅仅在判断函数参数是否传递的情况下有用。 ''表示长度为0的字符串。 数组使用[]表示，元素间用逗号,分隔。类似于Python的List，包括所索引、切片等操作。 对象是一组由键值组成的无序集合。类似于Python的Dictionary。 var person = { name: 'A', age: 20, tags: ['js', 'html', 'css'], hasCar: true, zipCode: null } \r\r","date":"2020-03-16","objectID":"/javascript/:4:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"Map和Set JavaScript的默认对象表示方式{}可以视为其他语言中的Map或Dictionary的数据结构，即一组键值对。但是JavaScript的对象有个小问题，就是键必须是字符串。但实际上Number或者其他数据类型作为键也是非常合理的。 为了解决这个问题，最新的ES6规范引入了新的数据类型Map。 // Map var m = new Map([['A': 90], ['b': 80]]); m.get('A'); m.set('A', 99); m.has('B'); m.delete('B'); Set和Map类似，也是一组Key的集合，但不存储Value。没有重复的键。 // Set var s1 = new Set(); var s2 = new Set([1, 2, 3, 1, 4, 'A']) s2.add(4) s2.delete('A') \r\r","date":"2020-03-16","objectID":"/javascript/:4:1","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"动态类型 JavaScript拥有动态类型，这意味着相同的变量可哦你工作不同的类型。 var x; // x为unfefined var x = 5; // x为数字 var x = \"John\"; // x为字符串 \r\r","date":"2020-03-16","objectID":"/javascript/:4:2","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"运算符 \u0026\u0026 || ! \u003e, \u003c \u003e=, \u003c= ==: 会自动转换数据类型再比较 ===: 不会自动转换数据类型，如果数据类型不一致，返回false；如果一致，再比较 由于JS这个设计缺陷，不要使用==，始终坚持使用===。 \r\r\r","date":"2020-03-16","objectID":"/javascript/:4:3","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"变量 变量在JavaScript中就是用一个变量名表示，变量名是大小写英文、数字、$和_的组合，且不能用数字开头。变量名也不能是JavaScript的关键字。变量名也可以用中文。 // 注意，只能用var申明一次 var a = 123; a = 'ABC'; /* 变量本身类型不固定的语言称为动态语言 与之相反的是静态语言，在定义变量时必须指定变量类型，如果类型不匹配，则会报错 动态语言更灵活 */ 可使用关键字new来声明变量类型: var name = new String; var x = new Number; var y = new Boolean; var z = new Array; var o = new Object; \r\r","date":"2020-03-16","objectID":"/javascript/:5:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"严格模式 JavaScript在设计之初，为了便于学习，并不强制要求使用var声明变量。这个设计错误带来了严重的后果：如果一个变量没有通过var申明就被使用，那么该变量就自动被申明为全局变量。 // i现在是全局变量 i = 10; 在同一个页面的不同的JavaScript文件中，如果都不用var申明，恰好都使用了变量i，将造成变量i互相影响，产生难以调试的错误结果。 使用var申明的变量则不是全局变量，它的范围被限制在该变量被申明的函数体内，同名变量在不同的函数体内互不冲突。 为了修补JavaScript这一严重设计缺陷，ECMA在后续规范中推出了严格(strict)模式，在strict模式下运行的JavaScript代码，强制通过var申明变量，未使用var申明变量就使用的，将导致运行错误。 不用var申明的变量会被视为全局变量，为了避免这一缺陷，所有的JavaScript代码都应该使用strict模式。我们在后面编写的JavaScript代码将全部采用strict模式。 启用strict模式的方法是在JavaScript代码的第一行写上：'use strict'; \r\r\r","date":"2020-03-16","objectID":"/javascript/:5:1","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"条件判断 if () { xxx; } else { xxxx; } if (condition) { xx; } else if (conditon) { xxx; } else { xxxx; } 栗子： 'use strict'; var age = 20; if (age\u003e=18) { console.log('adult'); } else if (age \u003c 6) { console.log('kid'); } else { console.log('teenager'); } JavaScript把null, undefined, 0, NaN, ''视为fasle，其它一概视为true。 栗子： 'use strict'; // 类似于alert的弹窗输入 var height = parseFloat(prompt('请输入身高(m):')); var weight = parseFloat(prompt('请输入体重(kg):')); var bmi = weight / height*height; console.log(bmi); if (bmi \u003c 18.5) { console.log(\"过轻\"); } else if (25 \u003e bmi \u003e= 18.5) { console.log(\"正常\"); } else if (32 \u003e bmi \u003e= 25) { console.log(\"过重\"); } else { console.log(\"肥胖\"); } \r\r","date":"2020-03-16","objectID":"/javascript/:6:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"循环 for while do...while // for var x = 0; var i; for (i=1; i\u003c=100; i++) { x = x + i; } console.log(x) // for 索引 var arr = ['0', '1', '2']; var i, x; for (i=0; i\u003carr.length; i++) { x = arr[i]; console.log(x); } // \u003efor in for (var i in arr) { console.log(i); console.log(a[i]); } // while var x = 0; var n = 99; while (n \u003e 0) { x = x + n; n = n -2; } console.log(x) // do...while var n = 0; do { n = n + 1; } while (n \u003c 100); // \u003e哈哈 console.log(n); \r\r\r","date":"2020-03-16","objectID":"/javascript/:7:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"iterable 遍历Array可以采用下标循环，遍历Map和Set就无法使用下标。为了统一集合类型，ES6标志引入了新的iterable类型，Array, Map, Set都属于iterable类型。 具有iterable类型的集合可以通过新的for...of循环来遍历。 var a = ['A', 'B', 'C']; var s = new Set(['A', 'B', 'C']); var m = new Map([[1, 'x'], [2, 'y'], [3, 'z']]); for (var x of a) { // 遍历Array console.log(x); } for (var x of s) { // 遍历Set console.log(x); } for (var x of m) { // 遍历Map console.log(x[0] + '=' + x[1]); } \r\r \r\r函数 Function 借助抽象，我们才能不关心底层的具体计算过程，而直接在更高的层次上思考问题。写计算机程序也是一样，函数就是最基本的一种代码抽象的方式。 \r\r","date":"2020-03-16","objectID":"/javascript/:8:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"函数定义 JavaScript中，定义函数的方式如下： function abs(x) { if (x \u003e= 0) { return x; } else { return -x; } } // 匿名函数 // 注意赋值语句结束需要; var abs = function (x) { if (x \u003e= 0) { return x; } else { return -x; } }; // 调用函数 abs(10); /* 由于JS允许传入任意个参数而不影响调用， 因此传入的参数比定义的参数多也没有问题。 虽然函数内部并不需要这些参数。 */ abs(10, 'haha', null); JS还有一个免费赠送的关键字arguments，它只在函数内部起作用，并且永远指向当前函数的调用者传入的所有参数。 实际上arguments最常用于判断传入参数的个数。 function abs() { if (arguments.length === 0) { return 0; } var x = arguments[0]; return x \u003e= 0 ? x : -x : } ES6标准引入了rest参数。 function foo(a, b, ...rest) { console.log(a); console.log(b); console.log(rest); } foo(1, 2, 3, 4); // 1 // 2 // Array [3, 4] foo(1); // 1 // undefined // Array [] \r\r\r","date":"2020-03-16","objectID":"/javascript/:9:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"变量作用域 在JavaScript中，用var申明的变量实际上是有作用域的。 如果一个变量在函数体内部申明，则该变量的作用域为整个函数体，在函数体外不可引用该变量。 \r\r","date":"2020-03-16","objectID":"/javascript/:10:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"变量提升 虽然JavaScript的函数有一个变量提升的特点，它会先扫描整个函数体的语句，把所有申明的变量提升到函数顶部。但我们在函数内部定义变量时，请在函数内部首先申明所有变量。 \r\r","date":"2020-03-16","objectID":"/javascript/:10:1","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"全局作用域 不在任何函数内定义的变量就具有全局作用域。实际上，JavaScript默认有一个全局对象window，全局作用域实际上被绑定到window的一个属性。 var course = 'JavaScript'; alert(course); alert(window.course); 这说明JavaScript实际上只有一个全局作用域。任何变量（函数也视为变量），如果没有在当前函数作用域中找到，就会继续往上查找，最后如果在全局作用域中也没有找到，则报ReferenceError错误。 \r\r","date":"2020-03-16","objectID":"/javascript/:10:2","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"命名空间 全局变量会绑定到window上，不同的JavaScript文件如果使用了相同的全局变量，或者定义了相同名字的顶层函数，都会造成命名冲突，并且很难被发现。 减少冲突的一个方法是把自己的所有变量和函数全部绑定到一个全局变量中。例如： // 唯一的全局变量MYAPP var MYAPP = {}; MYAPP.name = 'myapp'; MYAPP.version = 1.0; MYAPP.foo = function () { return 'foo'; }; 把自己的代码全部放入唯一的命名空间MYAPP中，会大大减少全局变量冲突的可能。 许多著名的JS库都是这么做的：jQuery, YUI等等。 \r\r","date":"2020-03-16","objectID":"/javascript/:10:3","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"局部作用域 由于JavaScript的变量作用域实际上是函数内部，我们在for循环等语句块中是无法定义具有局部作用域的变量的。 为了解决块级作用域，ES6引入了新的关键字let，用let替代var可以申明一个块级作用域的变量。 \r\r","date":"2020-03-16","objectID":"/javascript/:10:4","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"常量 由于var和let申明的是变量，如果要申明一个常量，在ES6之前是不行的，我们通常用全部大写的变量来表示这是一个常量，不要修改它的值。 var PI = 3.14; ES6标准引入了新的关键字const来定义常量，const和let都具有块级作用域。 const PI = 3.14; PI = 3; // TypeError: Assignment to constant variable. \r\r\r","date":"2020-03-16","objectID":"/javascript/:10:5","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"解构赋值 从ES6开始，JavaScript引入了解构赋值，可以同时对一组变量进行赋值。 使用解构赋值可以减少代码量，但是，需要在支持ES6解构赋值特性的现代浏览器中才能正常运行。 \r\r\r","date":"2020-03-16","objectID":"/javascript/:11:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"方法 在一个对象中绑定函数，称为这个对象的方法。 var xiaoming = { name: 'Ming', birth: 1990, age: function () { var y = new Date().getFullYear(); return y - this.birth; } }; 注意，有一个this关键字。在一个方法内部，this是一个特殊变量，它始终指向当前对象，也就是xiaoming这个变量。 我们可以控制this的指向。要确定函数的this指向哪个对象，可以用函数本身的apply方法，它接收两个参数，第一个参数就是需要绑定的this变量，第二个参数是Array，表示函数本身的参数。 另一个与apply()类似的方法是call()，唯一区别是： apply()把参数打包成Array再传入； call()把参数按顺序传入。 栗子： // Math.max(3, 5, 4) Math.max.apply(null, [3, 5, 4]); Math.max.call(null, 3, 5, 4); 对普通函数调用，我们通常把this绑定为null。 \r\r","date":"2020-03-16","objectID":"/javascript/:12:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"装饰器 利用apply()，我们还可以动态改变函数的行为。 JavaScript的所有对象都是动态的，即使内置的函数，我们也可以重新指向新的函数。 \r\r\r","date":"2020-03-16","objectID":"/javascript/:12:1","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"高阶函数 一个函数就可以接收另一个函数作为参数，这种函数就称之为高阶函数(Higher order function)。 function add(x, y, f) { return (f(x) + f(y)); } add(-5, 6, Math.abs) \r\r","date":"2020-03-16","objectID":"/javascript/:13:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"map/reduce map()方法定义在JS的Array中。 function pow(x) { return (x * x); } var arr = [1, 2, 3]; var results = arr.map(pow); // [1, 4, 9] reduce()把结果继续和序列的下一个元素做累积计算。 var arr = [1, 4, 5, 7]; arr.reduce(function (x, y) { return (x + y); }); // 17 \r\r","date":"2020-03-16","objectID":"/javascript/:13:1","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"filter filter()它用于把Array的某些元素过滤掉，然后返回剩下的元素。 // 保留奇数 var arr = [1, 2, 3, 4, 5]; var r = arr.filter(function (x){ return (x % 2 !== 0); }); \r\r","date":"2020-03-16","objectID":"/javascript/:13:2","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"sort JavaScript的Array的sort()方法就是用于排序的，但它默认把所有元素先转换为String再排序，如果不知道这个，那么用它直接对数字排序会栽进坑里。 \r\r","date":"2020-03-16","objectID":"/javascript/:13:3","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"其它高阶函数 Array对象还提供了许多非常实用的高阶函数： every(): 判断数组的所有元素是否满足测试条件 find(): 查找符合条件的第一个元素，如果找到了，返回这个元素；否则，返回undefined findIndex(): 它返回查找元素的索引 forEach: 把每个元素依次作用于传入的函数，但不会返回新的数组。常用于遍历数组 \r\r\r","date":"2020-03-16","objectID":"/javascript/:13:4","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"闭包 闭包是一种保护私有变量的机制，在函数执行时形成私有的作用域，保护里面的私有变量不受外界干扰。直观的说就是形成一个不销毁的栈环境。 \r\r\r","date":"2020-03-16","objectID":"/javascript/:14:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"箭头函数 ES6新增了一种新的函数：箭头函数(Arrow Function)。 感觉有点类似于Python的lambda。 // arrow function x =\u003e x * x // 相当于 function (x) { return x * x; } 其它用法: // 两个参数 (x, y) =\u003e (x * x) + (y * y) // 无参数 () =\u003e 3.14 // 可变参数 (x, y, ...rest) =\u003e { xxx; } // 返回对象 x =\u003e ({foo: x}) \r\r\r","date":"2020-03-16","objectID":"/javascript/:15:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"生成器 **生成器(generator)**是ES6标准引入的新的数据类型。一个生成器看上去像一个函数，但可以返回多次。 同样类似于Python的生成器，还记得next和yield吗？哈哈。 // generator 斐波那契数列 function* fib(max) { var t, a = 0, b = 1, n = 0; while (n \u003c max) { //\u003ehaha yield a; [a, b] = [b, a+b]; n++; } return; } 直接调用生成器和调用函数不一样，仅仅是创建了一个生成器对象，还没有去执行它。 // 第一种方法：不断调用生成器对象的next()方法，需要判断是否done var f = fib(5); f.next(); f.next(); ... f.next() // 第二种方法：for ... of循环迭代生成器对象 for (var x of fib(10)) { console.log(x); } \r\r \r\r标准对象 在JavaScript的世界里，一切都是对象。但某些对象还是和其它对象不一样。 // typeof 获取对象类型 typeof 123; // 'number' typeof null; // 'object' typeof []; // 'object' JS还提供了包装对象，熟悉Java的小伙伴肯定很清楚int和Integer这种暧昧关系。 虽然包装对象看上去和原来的值一摸一样，但是它们的类型已经变为object了。所以，闲的蛋疼也不要使用包装对象。 // 包装对象用 new 创建 var n = new Number(123); var b = new Boolean(true); typeof new Number(123); // 'object' new Number(123) === 123; // false \r\r","date":"2020-03-16","objectID":"/javascript/:16:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"Date 在JavaScript中，Date对象用来表示日期和时间。 注意，当前时间是浏览器从本机操作系统获取的时间，所以不一定准确，因为用户可以把当前时间设定为任何值。 JavaScript的Date对象月份值从0开始，牢记0=1月，1=2月，2=3月，……，11=12月。 var now = new Date(); now; // Wed Jun 24 2015 19:49:22 GMT+0800 (CST) now.getFullYear(); // 2015, 年份 now.getMonth(); // 5, 月份，注意月份范围是0~11，5表示六月 now.getDate(); // 24, 表示24号 now.getDay(); // 3, 表示星期三 now.getHours(); // 19, 24小时制 now.getMinutes(); // 49, 分钟 now.getSeconds(); // 22, 秒 now.getMilliseconds(); // 875, 毫秒数 now.getTime(); // 1435146562875, 以number形式表示的时间戳 // 创建一个日期对象 var d = new Date(2015, 5, 19, 20, 15, 30, 123); d; // Fri Jun 19 2015 20:15:30 GMT+0800 (CST) // 或ISO 8601格式 var d = Date.parse('2015-06-24T19:49:22.875+08:00'); d; // 1435146562875 // 或时间戳 var d = new Date(1435146562875); d; // Wed Jun 24 2015 19:49:22 GMT+0800 (CST) d.getMonth(); // 5 时区 Date对象表示的时间总是按浏览器所在的时区显示，不过我们既可以显示本地时间，也可以显示调整后的UTC时间。 var d = new Date(1435146562875); d.toLocaleString(); // '2015/6/24 下午7:49:22'，本地时间（北京时区+8:00），显示的字符串与操作系统设定的格式有关 d.toUTCString(); // 'Wed, 24 Jun 2015 11:49:22 GMT'，UTC时间，与本地时间相差8小时 \r\r","date":"2020-03-16","objectID":"/javascript/:17:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"RegExp 强大的正则表达式！ 了解了基本的RE知识，我们就可以在JavaScript中使用正则表达式了。JS有两种方式创建一个正则表达式： /正则表达式/ new RegExp('正则表达式')，创建一个RegExp对象 var re1 = /ABC\\-001/; var re2 = new RegExp('ABC\\\\-001'); // 使用了转义字符 // 测试正则 var re = /^$d{3}\\-\\d{3, 8}$/; re.test('010-12345'); // true 切分字符串 用正则表达式切分字符串比用固定的字符更灵活。 'a b c'.split(' '); // ['a', 'b', '', '', 'c'] 'a b c'.split(/\\s+/); // ['a', 'b', 'c'] 分组 除了简单地判断是否匹配之外，正则表达式还有提取子串的强大功能。用()表示的就是要提取的分组（Group）。 如果正则表达式中定义了组，就可以在RegExp对象上用exec()方法提取出子串来。 var re = /^(\\d{3})-(\\d{3,8})$/; re.exec('010-12345'); // ['010-12345', '010', '12345'] re.exec('010 12345'); // null 贪婪匹配 需要特别指出的是，正则匹配默认是贪婪匹配，也就是匹配尽可能多的字符。 // 贪婪匹配 var re = /^(\\d+)(0*)$/; re.exec('102300'); // ['102300', '102300', ''] // 非贪婪匹配 var re = /^(\\d+?)(0*)$/; re.exec('102300'); // ['102300', '1023', '00'] 全局搜索 JavaScript的正则表达式还有几个特殊的标志，最常用的是g，表示全局匹配。 var r1 = /test/g; // 等价于: var r2 = new RegExp('test', 'g'); \r\r","date":"2020-03-16","objectID":"/javascript/:18:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"JSON JSON是JavaScript Object Notation的缩写，它是一种轻量级的数据交换格式。 在JSON出现之前，大家一直用XML来传递数据。因为XML是一种纯文本格式，所以它适合在网络上交换数据。XML本身不算复杂，但是，加上DTD、XSD、XPath、XSLT等一大堆复杂的规范以后，任何正常的软件开发人员碰到XML都会感觉头大了，最后大家发现，即使你努力钻研几个月，也未必搞得清楚XML的规范。 JSON实际上是JavaScript的一个子集。在JSON中，一共就这么几种数据类型： number boolean string null array object JSON还定死了字符集必须是UTF-8，表示多语言就没有问题了。为了统一解析，JSON的字符串规定必须用双引号\"\"，Object的键也必须用双引号\"\"。 由于JSON非常简单，很快就风靡Web世界，并且成为ECMA标准。几乎所有编程语言都有解析JSON的库，而在JavaScript中，我们可以直接使用JSON，因为JavaScript内置了JSON的解析。 把任何JavaScript对象变成JSON，就是把这个对象序列化成一个JSON格式的字符串，这样才能够通过网络传递给其他计算机。 如果我们收到一个JSON格式的字符串，只需要把它反序列化成一个JavaScript对象，就可以在JavaScript中直接使用这个对象了。 序列化 // JavaScript object to JSON var xiaoming = { name: 'xiaoming', age: 14, gender: true, height: 1.65, grade: null, skills: ['JS', 'Java', 'Python'] }; var s = JSON.stringift(xiaoming); console.log(s); 反序列化 // JSON to JavaScript object JSON.parse('{\"name\":\"小明\",\"age\":14}'); // Object {name: '小明', age: 14} \r\r \r\r面向对象编程 JavaScript的面向对象编程和大多数其他语言如Java、C#的面向对象编程都不太一样。面向对象的两个基本概念： 类：类是对象的模板 实例：根据类创建的对象 所以，类和实例是大多数面向对象编程语言的基本概念。 不过，在JavaScript中，这个概念需要改一改。JavaScript不区分类和实例的概念，而是通过原型（prototype）来实现面向对象编程。 JavaScript没有类的概念，所有对象都是实例。所谓继承关系不过是把一个对象的原型指向另一个对象而已。 \r\r","date":"2020-03-16","objectID":"/javascript/:19:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"创建对象 JavaScript对每个创建的对象都会设置一个原型，指向它的原型对象。 当我们用obj.xxx访问一个对象的属性时，JavaScript引擎先在当前对象上查找该属性，如果没有找到，就到其原型对象上找，如果还没有找到，就一直上溯到Object.prototype对象，最后，如果还没有找到，就只能返回undefined。 // 创建Array对象 var arr = [1, 2, 3]; // 原型链 arr ----\u003e Array.prototype ----\u003e Object.prototype ----\u003e null 构造函数 JavaScript还可以用一种构造函数的方法来创建对象。 // 定义一个构造函数 function Student(name) { this.name = name; this.hello = function () { alert('Hello, ' + this.name + '!'); } } // 这确实是一个普通函数，但在JavaScript中，可以用关键字new来调用这个函数，并返回一个对象 // 写了new， 它就变成了一个构造函数 var xiaoming = new Student('小明'); xiaoming.name; xiaoming.hello(); // xiaoming的原型链 xiaoming ----\u003e Student.prototype ----\u003e Object.prototype ----\u003e null 要让创建的对象共享一个函数，根据对象的属性查找规则，我们只需要把此函数移动到这些对象的原型上就可以了，也就是xxx.prototype: function Student(name) { this.name = name; } Student.prototype.hello = function() { alert('Hello, ' + this.name + '!'); } 为了区分普通函数和构造函数，按照约定，构造函数首字母应当大写，而普通函数首字母应当小写。 \r\r","date":"2020-03-16","objectID":"/javascript/:20:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"原型继承 在传统的基于类的语言中，继承的本质是扩展一个已有的类(class)，并生成新的子类(subclass)。 但是，由于JavaScript采用原型继承，我们无法直接扩展一个类，因为根本不存在类。 JavaScript的原型继承方式是： 定义新的构造函数，并在内部用call()调用希望继承的构造函数，并绑定this 借助中间函数F实现原型继承，最好通过封装的inherits函数完成 继续在新的构造函数的原型上定义新方法 function Student(props) { this.name = props.name || 'Unnamed'; } Student.prototype.hello = function () { alert('Hello, ' + this.name + '!'); } // PrimaryStudent构造函数: function PrimaryStudent(props) { Student.call(this, props); this.grade = props.grade || 1; } // 空函数F: function F() { } // 把F的原型指向Student.prototype: F.prototype = Student.prototype; // 把PrimaryStudent的原型指向一个新的F对象，F对象的原型正好指向Student.prototype: PrimaryStudent.prototype = new F(); // 把PrimaryStudent原型的构造函数修复为PrimaryStudent: PrimaryStudent.prototype.constructor = PrimaryStudent; // 继续在PrimaryStudent原型（就是new F()对象）上定义方法： PrimaryStudent.prototype.getGrade = function () { return this.grade; }; // 创建xiaoming: var xiaoming = new PrimaryStudent({ name: '小明', grade: 2 }); xiaoming.name; // '小明' xiaoming.grade; // 2 // 验证原型: xiaoming.__proto__ === PrimaryStudent.prototype; // true xiaoming.__proto__.__proto__ === Student.prototype; // true // 验证继承关系: xiaoming instanceof PrimaryStudent; // true xiaoming instanceof Student; // true ","date":"2020-03-16","objectID":"/javascript/:21:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"class继承 JavaScript的对象模型是基于原型实现的，特点是简单，缺点是理解起来比传统的类－实例模型要困难，最大的缺点是继承的实现需要编写大量代码，并且需要正确实现原型链。 但有更简单的写法。在ES6标准中，新的关键字class正式被引入到JavaScript中。它的目的就是让定义类更简单。 // class的定义包含了构造函数constructor class Student { constructor(name) { this.name = name; } hello() { alert('Hello, ' + this.name + '!'); } } // 创建对象 var xiaoming = new Student('小明'); xiaoming.hello(); 用class定义对象的另一个巨大好处是继承更方便了。不需要写大量的中间对象，直接通过extends来实现： class PrimaryStudent extends Student { constructor(name, grade) { super(name); // 记得用super调用父类的构造方法! this.grade = grade; } myGrade() { alert('I am at grade ' + this.grade); } } 要注意浏览器是不是支持ES6的class。 \r\r \r\r浏览器 由于JavaScript的出现就是为了能在浏览器中运行，所以，浏览器自然是JavaScript开发者必须要关注的。 目前，主流浏览器分这几种： IE 6-11：从IE 10开始支持ES6； Chrome：Google出品的基于Webkit内核，内置非常强悍的JS引擎——V8。支持ES6； Safari：Mac自带的基于Webkit内核，支持ES6； Firefox：Mozilla研制的Gecko内核和JS引擎OdinMonkey。支持ES6； 移动设备(IOS/Android)：支持ES6 不同的浏览器对JavaScript支持的差异主要是，有些API的接口不一样，比如AJAX，File接口。对于ES6标准，不同的浏览器对各个特性支持也不一样。 在编写JavaScript的时候，就要充分考虑到浏览器的差异，尽量让同一份JavaScript代码能运行在不同的浏览器中。 \r\r","date":"2020-03-16","objectID":"/javascript/:22:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"浏览器对象 JavaScript可以获取浏览器提供的很多对象，并进行操作。 \r","date":"2020-03-16","objectID":"/javascript/:23:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"window window对象不但充当全局作用域，而且表示浏览器窗口。属性： innerWidth：浏览器窗口的内部宽度 innerHeight：内部高度 outerWidth: 浏览器窗口整个宽度 outerHeight: 整个高度 内部宽高是指除去菜单栏、工具栏、边框等占位元素后，用于显示网页的净宽高。 // 可以调整浏览器窗口大小，进行测试 cosole.log('window inner size: ' + window.innerWidth + 'x' + window.innerHeight); \r\r","date":"2020-03-16","objectID":"/javascript/:23:1","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"navigator navigator表示浏览器的信息，最常用的属性包括： appName：浏览器名称； appVersion：浏览器版本； language：浏览器设置的语言； platform：操作系统类型； userAgent：浏览器设置的User-Agent字符； 请注意，navigator的信息可以轻易的被用户修改。 console.log('appName = ' + navigator.appName); console.log('appVersion = ' + navigator.appVersion); console.log('language = ' + navigator.language); console.log('platform = ' + navigator.platform); console.log('userAgent = ' + navigator.userAgent); \r\r","date":"2020-03-16","objectID":"/javascript/:23:2","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"screen screen对象表示屏幕的信息，常用的属性有： width：屏幕宽度(px)； height：屏幕高度(px)； colorDepth：颜色位数； console.log('Screen size = ' + screen.width + ' x ' + screen.height); \r\r","date":"2020-03-16","objectID":"/javascript/:23:3","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"location location对象表示当前页面的URL信息。 href：完整的URL protocol：协议 host: 主机名 port：端口 pathname： 路径 search： 参数 hash： assign()：加载一个新页面 reload()：重载当前页面 if (confirm('重新加载当前页' + location.href + '?')) { location.reload(); } else { location.assign('/'); // 设置一个新的URL地址 } \r\r","date":"2020-03-16","objectID":"/javascript/:23:4","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"document document对象表示当前页面。由于HTML在浏览器中以DOM形式表示为树形结构，document对象就是整个DOM树的根节点。 title getElementById()：按id获得一个DOM节点； getElementsByTagName()：按tag获得一个DOM节点； getElementsByClassName() cookie：为了确保安全，服务器端在设置Cookie时，应该始终坚持使用httpOnly； // document.title属性从HTML文档中\u003ctitle\u003exxx\u003c/title\u003e读取，但可以动态改变 document.title = 'DOM title'; \r\r","date":"2020-03-16","objectID":"/javascript/:23:5","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"history history保存了浏览器的历史记录，JavaScript可以调用history()对象的back()或forward()。 这个对象属于历史遗留问题，任何情况，你都不应该使用history这个对象。 \r\r\r","date":"2020-03-16","objectID":"/javascript/:23:6","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"DOM DOM(文档对象模型, document object model)，是W3C(万维网联盟)的标准。它定义了访问HTML和XML文档的标准。 由于HTML文档被浏览器解析后就是一棵DOM树，要改变HTML的结构，就需要通过JavaScript来操作DOM。 DOM节点有几个操作： 更新 遍历 添加 删除 在操作一个DOM节点前，我们需要通过各种方式先拿到这个DOM节点。常用的方法： document.getElementById()：由于ID在HTML文档中是唯一的，所以可以直接定位唯一的一个DOM节点。 document.getElementsByTagName()：返回一组DOM节点 document.getElementsByClassName()：要精确地选择DOM，可以先定位父节点，再从父节点开始选择，以缩小范围 document.querySelector() document.queryAelectorAll() \r\r","date":"2020-03-16","objectID":"/javascript/:24:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"更新DOM 拿到DOM节点后，我们可以对它进行更新。可以直接修改节点文本，方法有两种： 一种是修改innerHTML属性，这个方式非常强大，不但可以修改一个DOM节点的文本内容，还可以直接通过HTML片段修改DOM节点内部的子树。 用innerHTML时要注意，是否需要写入HTML。如果写入的字符串是通过网络拿到了，要注意对字符编码来避免XSS攻击。 // 获取\u003cp id=\"p-id\"\u003e...\u003c/p\u003e var p = document.getElementById('p-id'); // 设置文本为abc: p.innerHTML = 'ABC'; // \u003cp id=\"p-id\"\u003eABC\u003c/p\u003e // 设置HTML: p.innerHTML = 'ABC \u003cspan style=\"color:red\"\u003eRED\u003c/span\u003e XYZ'; // \u003cp\u003e...\u003c/p\u003e的内部结构已修改 第二种是修改innerText或textContent属性，这样可以自动对字符串进行HTML编码，保证无法设置任何HTML标签。 // 获取\u003cp id=\"p-id\"\u003e...\u003c/p\u003e var p = document.getElementById('p-id'); // 设置文本: p.innerText = '\u003cscript\u003ealert(\"Hi\")\u003c/script\u003e'; // HTML被自动编码，无法设置一个\u003cscript\u003e节点: // \u003cp id=\"p-id\"\u003e\u0026lt;script\u0026gt;alert(\"Hi\")\u0026lt;/script\u0026gt;\u003c/p\u003e 两者的区别在于读取属性时，innerText不返回隐藏元素的文本，而textContent返回所有文本。因为CSS允许font-size这样的名称，但它并非JavaScript有效的属性名，所以需要在JavaScript中改写为驼峰式命名fontSize。 修改CSS也是经常需要的操作。DOM节点的style属性对应所有的CSS，可以直接获取或设置。 // 获取\u003cp id=\"p-id\"\u003e...\u003c/p\u003e var p = document.getElementById('p-id'); // 设置CSS: p.style.color = '#ff0000'; p.style.fontSize = '20px'; p.style.paddingTop = '2em'; \r\r","date":"2020-03-16","objectID":"/javascript/:24:1","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"插入DOM 如果DOM节点是空的，那么，直接使用innerHTML = \u003cx\u003eaaa\u003c/x\u003e就可以修改DOM节点的内容，相当于插入了新的DOM节点。 如果DOM节点不是空，则不能这样做。有两个新办法。 一个是使用appendChild：把一个子节点添加到父节点的最后一个子节点。 var js = document.getElementById('js'), list = document.getElementById('list); list.append(js); // 更多的时候，我们会从零创建一个新的节点，然后插入到指定位置 var list = document.getElementById('list'), haskell = document.createElement('p'); haskell.id = 'haskell'; haskell.innerText = 'Haskell'; list.appendChild(haskell); 动态创建一个节点，然后田间道DOM树中，可以实现很多功能。 var d = document.createElement('style'); d.setAttribute('type', 'text/css'); d.innerHTML = 'p {color: red}'; document.getElementsByTagName('head')[0].appendChild(d); 这个栗子更改了颜色。可在浏览器的console上执行来看效果。 insertBefore 使用parentElement.insertBefore(newElement, referenceElement);，子节点会插入到referenceElement之前。 var list = document.getElementById('list'), ref = document.getElementById('python'), haskell = document.createElement('p'); haskell.id = 'haskell'; haskell.innerText = 'Haskell'; list.insertBefore(haskell, ref); 可见，使用insertBefore重要的是拿到一个参考子节点的引用。很多时候，需要循环一个父节点的所有字节嗲，可以通过children属性实现： var i, c, list = document.getElementById('list'); for (i = 0; i \u003c list.children.length; i++) { //\u003ehaha c = list.children[i]; } \r\r","date":"2020-03-16","objectID":"/javascript/:24:2","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"删除DOM 要删除一个节点，首先要获得该节点本身以及它的父节点。然后，调用父节点的removeChild把自己删掉。 // 拿到待删除节点: var self = document.getElementById('to-be-removed'); // 拿到父节点: var parent = self.parentElement; // 删除: var removed = parent.removeChild(self); removed === self; // true 注意，删除后的节点虽不在文档树中，但其实它还在内存中，可以随时在此被添加到别的位置。 当你遍历一个父节点的子节点并进行删除操作时，要注意，children属性是一个只读属性，并且它在子节点变化时会实时更新。因此，删除多个节点时，要注意children属性时刻都在变化。 \r\r\r","date":"2020-03-16","objectID":"/javascript/:24:3","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"操作表单 用JavaScript操作表单和操作DOM是类似的，因为表单本身也是DOM树。 不过，表单的输入框、下拉框等可以接收用户输入，所以用JavaScript来操作表单，可以获得用户输入的内容，或者对一个输入框设置新的内容。 HTML表单的输入控件主要有以下几种： 文本框：\u003cinput type=\"text\"\u003e; 口令框：\u003cinput type=\"password\"\u003e; 单选框：\u003cinput type=\"radio\"\u003e; 复选框：\u003cinput type=\"checkbox\"\u003e; 下拉框：\u003cselect\u003e; 隐藏文本，用户不可见，但表单提交时会把隐藏文本发送到服务器: input type=\"hidden\"\u003e。 \r\r","date":"2020-03-16","objectID":"/javascript/:25:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"获取值 如果我们获取了一个\u003cinput\u003e节点的引用，就可以调用value获得对应的用户输入值。 // \u003cinput type=\"text\" id=\"email\"\u003e var input = document.getElementById('email'); input.value; // '用户输入的值' 这种方式可以用于text, password, hidden, select。但是，对于单选框和复选框，value属性返回的永远是HTML预设的值，而我们需要获得的实际是用户是否勾上了选项，所以应该用checked判断。 // \u003clabel\u003e\u003cinput type=\"radio\" name=\"weekday\" id=\"monday\" value=\"1\"\u003e Monday\u003c/label\u003e // \u003clabel\u003e\u003cinput type=\"radio\" name=\"weekday\" id=\"tuesday\" value=\"2\"\u003e Tuesday\u003c/label\u003e var mon = document.getElementById('monday'); var tue = document.getElementById('tuesday'); mon.value; // '1' tue.value; // '2' mon.checked; // true或者false tue.checked; // true或者false \r\r","date":"2020-03-16","objectID":"/javascript/:25:1","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"设置值 对于text, password, hidden, select，直接设置value就可以。对于单/复选框，设置checked为true或false即可。 // \u003cinput type=\"text\" id=\"email\"\u003e var input = document.getElementById('email'); input.value = 'test@example.com'; // 文本框的内容已更新 \r\r","date":"2020-03-16","objectID":"/javascript/:25:2","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"HTML5控件 HTML5新增了大量标准空间，常用的包括date, datetime, datetime-local, color…，它们都使用\u003cinput\u003e标签。 不支持HTML5的浏览器无法识别新的控件，会把它们当做type=\"text\"来显示。支持HTML5的浏览器将获得格式化的字符串。 \r\r","date":"2020-03-16","objectID":"/javascript/:25:3","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"提交表单 最后，JavaScript可以以两种方式来处理表单的提交（AJAX方式在后面介绍）。 一是通过\u003cform\u003e元素的submit()方法提交一个表单。这种方式的缺点是扰乱了浏览器对form的正常提交。 \u003c!-- html --\u003e \u003cform id=\"test-form\"\u003e \u003cinput type=\"text\" name=\"test\"\u003e \u003cbutton type=\"button\" onclick=\"doSubmitForm()\"\u003eSubmit\u003c/button\u003e \u003c/form\u003e \u003cscript\u003e function doSubmitForm() { var form = document.getElementById('test-form'); // 可在此修改form的input // 提交form form.submit(); } \u003c/script\u003e 第二种方式是响应\u003cform\u003e本身的onsubmit事件，在提交form时作修改： \u003c!-- html --\u003e \u003cform id=\"test-form\" onsubmit=\"return checkForm()\"\u003e \u003cinput type=\"text\" name=\"test\"\u003e \u003cbutton type=\"submit\"\u003eSubmit\u003c/button\u003e \u003c/form\u003e \u003cscript\u003e function checkForm() { var form = document.getElementById('test-id'); return true; } \u003c/script\u003e 注意要return true来告诉浏览器继续提交，如果return false，浏览器将不会继续提交form，这种情况通常对应用户输入有误，提示用户错误信息后终止提交form。 在检查和修改\u003cinput\u003e时，要充分利用\u003cinput type=\"hidden\"\u003e来传递数据。例如，很多登录表单希望用户输入的口令（出于安全考虑）在提交表单时不传输明文口令，而是口令的MD5。 \u003c!-- html --\u003e \u003cform id=\"login-form\" method=\"post\" onsubmit=\"return checkForm()\"\u003e \u003cinput type=\"text\" id=\"username\" name=\"username\"\u003e \u003cinput type=\"password\" id=\"password\" name=\"password\"\u003e \u003cbutton type=\"submit\"\u003eSubmit\u003c/button\u003e \u003c/form\u003e \u003cscript\u003e function checkForm() { var pwd = document.getElementById('password'); // to MD5 pwd.value = toMD5(pwd.value); return true; } \u003c/script\u003e 这样做看上去没问题，但用户输入了口令提交时，口令框突然会从几个*变为32个**（MD5有32个字符）。若不想改变用户的输入，可利用\u003cinput type=\"hidden\"\u003e实现： \u003c!-- HTML --\u003e \u003cform id=\"login-form\" method=\"post\" onsubmit=\"return checkForm()\"\u003e \u003cinput type=\"text\" id=\"username\" name=\"username\"\u003e \u003cinput type=\"password\" id=\"input-password\"\u003e \u003cinput type=\"hidden\" id=\"md5-password\" name=\"password\"\u003e \u003cbutton type=\"submit\"\u003eSubmit\u003c/button\u003e \u003c/form\u003e \u003cscript\u003e function checkForm() { var input_pwd = document.getElementById('input-password'); var md5_pwd = document.getElementById('md5-password'); // 把用户输入的明文变为MD5: md5_pwd.value = toMD5(input_pwd.value); // 继续下一步: return true; } \u003c/script\u003e 没有name属性的\u003cinput\u003e的数据不会被提交。 \r\r\r","date":"2020-03-16","objectID":"/javascript/:25:4","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"操作文件 在HTML表单中，可以上传文件的唯一控件就是\u003cinput type=\"file\"\u003e。 注意：当一个表单包含\u003cinput type=\"file\"\u003e时，表单的enctype必须指定为multipart/form-data，method必须指定为post，浏览器才能正确编码并以multipart/form-data格式发送表单的数据。 处于安全考虑，浏览器只允许用户点击\u003cinput type=\"file\"\u003e来选择本地文件，用JavaScript对\u003cinput type=\"file\"\u003e的value赋值是没有任何效果的。当用户选择了上传某个文件后，JavaScript也无法获得该文件的真实路径。 通常，上传的文件都由后台服务器处理，JavaScript可以在提交表单时对文件的扩展名做检查，以便防止用户上传无效格式的文件。 var f = document.getElementById('file-upload'); var filename = f.value; if(!filename || !(filename.endsWith('.jpg')) || filename.endsWith('.png') || filename.endsWith('.gif')) { alert(\"Can only upload image file.\"); return false; } File API 由于JavaScript对用户上传的文件操作非常有限，尤其是无法读取文件内容，使得很多需要操作文件的网页不得不用Flash这样的第三方插件来实现。 随着HTML5的普及，新增的File API允许JavaScript读取文件内容，获得更多的文件信息。HTML5的File API提供了File和FileReader两个主要对象，可以获得文件信息并读取文件。 回调 在JavaScript中，浏览器的JavaScript执行引擎在执行JavaScript代码时，总是以单线程模式执行，也就是说，任何时候，JavaScript代码都不可能同时有多于1个线程在执行。 你可能会问，单线程模式执行的JavaScript，如何处理多任务？在JavaScript中，执行多任务实际上都是异步调用。因为是异步操作，所以我们在JavaScript代码中就不知道什么时候操作结束，因此需要先设置一个回调函数： reader.onload = function(e) { // 操作完成后，自动调用此函数 }; \r\r\r","date":"2020-03-16","objectID":"/javascript/:26:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"AJAX AJAX(Asynchronous JavaScript and XML)不是JavaScript的规范，意思是用JavaScript执行异步网络请求。 如果仔细观察一个Form的提交，你就会发现，一旦用户点击Submit按钮，表单开始提交，浏览器就会刷新页面，然后在新页面里告诉你操作是成功了还是失败了。如果不幸由于网络太慢或者其他原因，就会得到一个404页面。 这就是Web的运作原理：一次HTTP请求对应一个页面。 如果要让用户留在当前页面中，同时发出新的HTTP请求，就必须用JavaScript发送这个新请求，接收到数据后，再用JavaScript更新页面，这样一来，用户就感觉自己仍然停留在当前页面，但是数据却可以不断地更新。 最早大规模使用AJAX的就是Gmail，Gmail的页面在首次加载后，剩下的所有数据都依赖于AJAX来更新。 用JavaScript写一个完整的AJAX代码并不复杂，但是需要注意：AJAX请求是异步执行的，也就是说，要通过回调函数获得响应。 // 在现代浏览器上写AJAX主要依靠XMLHttpRequest对象 function success(text) { var textarea = document.getElementById('response-text'); textarea.value = text; } function fail(code) { var textarea = document.getElementById('response-text'); textarea.value = 'Error code: ' + code; } var request = new XMLHttpRequest(); // 新建XMLHttpRequest对象 request.onreadystatechange = function () { // 状态发生变化时，函数被回调 if (rquest.readyState === 4) { // 判断相应结果 if (request.status === 200) { return success(request.responseText); } else { return fail(request.status); } } else { // HTTP请求还在继续 } } // 发送请求 request.open('GET', '/api/categories'); request.send(); alert('请求已发送，请等待响应...'); 安全限制 上面代码的URL使用的是相对路径。如果你把它改为http://xxx.com/，再运行，肯定会报错。在console里，还可以看到错误信息。 这是因为浏览器的同源策略导致的。默认情况下，JavaScript在发送AJAX请求时，URL的域名必须和当前页面完全一致。 那是不是JavaScript无法请求外域（其它网站）的URL了呢？方法还是有的： 一是通过Flash插件发送HTTP请求，这种方式可以绕过浏览器的安全限制，但必须安装Flash，并且跟Flash交互。不过Flash用起来麻烦，而且现在用得也越来越少了。 二是通过在同源域名下架设一个代理服务器来转发，JavaScript负责把请求发送到代理服务器。代理服务器再把结果返回，这样就遵守了浏览器的同源策略。这种方式麻烦之处在于需要服务器端额外做开发。 三是JSONP。它有个限制，只能用GET请求，并且要求返回JavaScript。这种方式跨域实际上是利用了浏览器允许跨域引用JavaScript资源。 CORS 如果浏览器支持HTML5，那么就可以一劳永逸地使用新的跨域策略：CORS(Cross-Origin Resource Sharing)，它是HTML5规范定义的如何跨域访问资源。 了解CORS前，我们先搞明白概念。Origin表示本域，也就是浏览器当前页面的域。当JavaScript向外域发起请求后，浏览器收到响应后，首先检查Access-Control-Allow-Origin是否包含本域，如果是，则此次跨域请求成功，如果不是，则请求失败，JavaScript将无法获取到响应的任何数据。 可见，跨域能否成功，取决于对方服务器是否愿意给你设置一个正确的Access-Control-Allow-Origin，决定权始终在对方手中。 \r\r\r","date":"2020-03-16","objectID":"/javascript/:27:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"Promise 在JavaScript的世界中，所有代码都是单线程执行的。由于这个缺陷，导致JavaScript的所有网络操作，浏览器事件，都必须是异步执行。 异步执行可以用回调函数实现： function callback() { console.log('Done'); } console.log(\"before setTimeout()\"); setTimeout(callback, 1000); // 1s后调用callback console.log(\"after setTimeout()\"); 可见，异步操作会在将来某个时间点触发一个函数调用。 Promise有各种开源实现，在ES6中被统一规范，由浏览器直接支持。 Promise最大的好处是在异步执行的流程中，把执行代码和处理结果的代码清洗地分离。 Promise还可以做更多的事情，比如，有若干个异步任务，需要先做任务1，如果成功后再做任务2，任何任务失败则不再继续并执行错误处理函数。 要串行执行这样的异步任务，不用Promise需要些一层一层的嵌套代码。 // job 1, 2, 3都是Promise对象 job1.then(job2).then(job3).catch(handleError); 除了串行执行若干异步任务外，Promise还可以并行执行异步任务。 如果我们组合使用Promise，就可以把很多异步任务以并行和串行的方式组合起来执行。 \r\r\r","date":"2020-03-16","objectID":"/javascript/:28:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"Canvas Canvas是HTML5新增的组件，它就像一块幕布，可以用JavaScript在上面绘制各种图标、动画等。没有Canvas的年代，绘图只能借助Flash插件实现，页面不得不用JavaScript和Flash进行交互。有了Canvas，我们就再也不需要Flash了，直接使用JavaScript完成绘制。 一个Canvas定义了一个指定尺寸的矩形框，在这个范围内我们可以随意绘制： \u003ccanvas id=\"test-canvas\" width=\"300\" height=\"200\"\u003e\u003c/canvas\u003e 绘制形状 我们可以在Canvas上绘制各种形状。在绘制前，我们需要了解以下Canvas的坐标系统。Canvas的坐标以左上角为原点，水平向右为X轴，垂直向下为Y轴，以像素为单位，所以每个点都是非负整数。 绘制文本 绘制文本就是在指定的位置输出文本，可以设置文本的字体、样式、阴影等，与CSS完全一致。 Canvas除了能绘制基本的形状和文本，还可以实现动画、缩放、各种滤镜和像素转换等高级操作。如果要实现非常复杂的操作，考虑以下优化方案： 通过创建一个不可见的Canvas来绘图，然后将最终绘制结果复制到页面的可见Canvas中； 尽量使用整数坐标而不是浮点数； 可以创建多个重叠的Canvas绘制不同的层，而不是在一个Canvas中绘制非常复杂的图； 背景图片如果不变可以直接用\u003cimg\u003e标签并放到最底层。 \r\r \r\rJQuery 你可能听说过jQuery，它名字起得很土，但却是JavaScript世界中使用最广泛的一个库。 江湖传言，全世界大约有80~90%的网站直接或间接地使用了jQuery。鉴于它如此流行，又如此好用，所以每一个入门JavaScript的前端工程师都应该了解和学习它。 JQuery的理念是Write Less, Do More，让你写更少的代码，完成更多的工作。 JQuery能帮助解决一些很重要的问题： 消除浏览器差异 简洁的操作DOM的方法：写$('#test')肯定比document.getElementById('test')来的简洁 轻松实现动画、修改CSS等各种操作。 JQuery版本 JQuery有1.x和2.x两个主要版本，区别在于2.x移除了对古老的IE6、7、8的支持，因此2.x的代码更精简。 JQuery只是一个jquery-xxx.js文件，但你会看到有compressed（已压缩）和uncompressed（未压缩）两种版本，使用时完全一样，但如果你想深入研究jQuery源码，那就用uncompressed版本。 使用JQuery 使用JQuery只需要在页面的\u003chead\u003e引入JQuery文件即可： \u003chtml\u003e \u003chead\u003e \u003cscript src=\"code.jquery.com/jquery-2.1.4.min.js\"\u003e\u003c/script\u003e \u003c/head\u003e \u003cbody\u003e ... \u003c/body\u003e \u003c/html\u003e $符号 $符号是著名的JQuery符号。实际上，Jquery把所有功能全部封装在一个全局变量JQuery中，而$也是一个合法的变量名，它是JQuery的别名。 window.jQuery; // jQuery(selector, context) window.$; // jQuery(selector, context) $ === jQuery; // true typeof($); // 'function' $本质上是一个函数，但函数也是对象。于是$除了可以直接调用外，也可以有很多其它属性。 注意：你看到的$函数名可能不是JQuery(selector, context)，因为很多JavaScript压缩工具可以对函数名和参数改名，所以压缩过的JQuery源码$函数可能变成a(b, c)。 绝大多数时候，我们都直接用$。但是，如果$这个变量不幸地被占用了，而且还不能改，那我们只能让JQuery把$变量交出来，然后就只能使用JQuery这个变量。 $; // jQuery(selector, context) jQuery.noConflict(); $; // undefined jQuery; // jQuery(selector, context) 这种黑魔法的原理是JQuery在占用$之前，现在内部保存了原来的$，调用JQuery.noConflict()时会把原来保存的变量还原。 \r\r","date":"2020-03-16","objectID":"/javascript/:29:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"选择器 选择器是JQuery的核心，一个选择器写出来大概是这样：$('#dom-id')。 为什么JQuery要发明选择器？来回顾一下DOM操作中经常使用的代码： // 按ID查找 var a = document.getElementById('dom-id'); // 按tag查找 var divs = document.getElementsByTagName('div'); 这些代码实在太过繁琐。并且在层级关系中，很多时候需要递归查找所有子节点。 JQuery的选择器就是帮助我们快速定位到一个或多个DOM节点。 按id查找 var div = $('#abc'); // 如果不存在，则返回 [] 它返回JQuery对象。JQuery对象类似数组，它的每个元素都是一个引用了DOM节点的对象。 JQuery的选择器不会返回undefined或null，这样的好处是不必在下一行判断if (div === undefined)。 // JQuery对象和DOM对象直接可以互相转化 var div = $('#abc'); //JQuery对象 var divDom = div.get(0); // 假设存在div，获取第1个DOM元素 var another = $(divDom); // 重新把DOM包装为JQuery对象 通常情况下你不需要获取DOM对象，直接使用jQuery对象更加方便。如果你拿到了一个DOM对象，那可以简单地调用$(aDomObject)把它变成jQuery对象，这样就可以方便地使用jQuery的API了。 \r按tag查找 var ps = $('p'); // 返回所有\u003cp\u003e节点 ps.length; // 数一数页面有多少个\u003cp\u003e节点 \r按class查找 var a = $('.red'); // 所有节点包含`class=\"red\"`都将返回 // 多个class var a = $('.red.green'); // 注意没有空格！ 按属性查找 var email= $('[name=email]'); // 找出所有name属性为email的DOM // 还可使用前缀/后缀查找 var icons = $('[name^=icon]'); // 找出所有name属性以icon开头的DOM var names = $('[name$=with]'); // 找出所有name属性以with结尾的DOM 组合查找 组合查找就是把上述简单选择器组合起来使用。 var emailInput = $('input[name=email]'); // tag and class var tr = $('tr.red'); // 找出\u003ctr class='red ...'\u003e...\u003c/tr\u003e 多项选择器 多项选择器就是把多个选择器用逗号,组合起来： $('p,div'); // 把\u003cp\u003e和\u003cdiv\u003e都选出来 $('p.red, p.green'); \r\r","date":"2020-03-16","objectID":"/javascript/:30:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"层级选择器 除了基本的选择器外，jQuery的层级选择器更加灵活，也更强大。因为DOM的结构就是层级结构，所以我们经常要根据层级关系进行选择。 层级选择器(Descendant Selector) 如果两个DOM元素具有层级关系，就可以用$('ancestor descendant')来选择，层级之间用空格隔开。 $('ul.lang li.lang-javascript'); $('div.testing li.lang-python'); 这种层级选择器相比单个的选择器好处在于，它缩小了选择范围，因为首先要定位父节点，才能选择相应的子节点，这样避免了页面其他不相关的元素。 子选择器(Child Selector) 子选择器$('parent\u003echild')是限定了父子关系的层级选择器。 $('ul.lang\u003eli.lang-javascript'); 过滤器(Filter) 过滤器一般不单独使用，它通常附加在选择器上，帮助我们更精确地定位元素。 $('ul.lang li'); $('ul.lang li:first-child'); $('ul.lang li:nth-child(2)'); 表单相关 针对表单元素，jQuery还有一组特殊的选择器: :input，可选择input, textarea, select, button :file，可选择\u003cinput type=\"file\"\u003e，和input[type=file]一样 :checkbox :radio :focus :checked :enabled :disabled \r\r","date":"2020-03-16","objectID":"/javascript/:30:1","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"查找和过滤 通常情况下选择器可以直接定位到我们想要的元素，但是，当我们拿到一个jQuery对象后，还可以以这个对象为基准，进行查找和过滤。 // find()查找 var ul = $('ul.lang'); // 获得\u003cul\u003e var dy = ul.find('.dy'); // 获得JavaScript, Python, Scheme var swf = ul.find('#swift'); // 获得Swift var hsk = ul.find('[name=haskell]'); // 获得Haskell // 要从当前节点开始向上查找，使用parent()方法 var swf = $('#swift'); // 获得Swift var parent = swf.parent(); // 获得Swift的上层节点\u003cul\u003e var a = swf.parent('.red'); // 获得Swift的上层节点\u003cul\u003e，同时传入过滤条件。如果ul不符合条件，返回空jQuery对象 // 对于位于同一层级的节点，可以通过next()和prev() var swift = $('#swift'); swift.next(); // Scheme swift.next('[name=haskell]'); // 空的jQuery对象，因为Swift的下一个元素Scheme不符合条件[name=haskell] swift.prev(); // Python swift.prev('.dy'); // Python，因为Python同时符合过滤器条件.dy // filter()方法可以过滤不符合选择器条件的节点 var langs = $('ul.lang li'); // 拿到JavaScript, Python, Swift, Scheme和Haskell var a = langs.filter('.dy'); // 拿到JavaScript, Python, Scheme \r\r\r","date":"2020-03-16","objectID":"/javascript/:30:2","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"操作DOM jQuery的选择器很强大，用起来又简单又灵活，但是搞了这么久，我拿到了jQuery对象，到底要干什么？ 当然是操作对应的DOM节点啦！ 回顾一下修改DOM的CSS、文本、设置HTML有多么麻烦，而且有的浏览器只有innerHTML，有的浏览器支持innerText，有了jQuery对象，不需要考虑浏览器差异了，全部统一操作！ 修改Text和HTML jQuery对象的text()和html()方法分别获取节点的文本和原始HTML文本。 // 获取 $('#ul li[name=book]').text(); $('#ul li[name=book]').html(); // 修改 var j1 = $('#test-ul li.js'); var j2 = $('#test-ul li[name=book]'); j1.html('\u003cspan style=\"color: red\"\u003eJavaScript\u003c/span\u003e'); j2.text('JavaScript \u0026 ECMAScript'); 修改CSS // css('name', 'value') var div = $('#test-div'); div.css('color'); // '#000033', 获取CSS属性 div.css('color', '#336699'); // 设置CSS属性 div.css('color', ''); // 清除CSS属性 显示和隐藏DOM 考虑到显示和隐藏DOM元素使用非常普遍，jQuery直接提供show()和hide()方法。 注意，隐藏DOM节点并未改变DOM树的结构，它只影响DOM节点的显示。这和删除DOM节点是不同的。 var a = $('a[target=_blank]'); a.hide(); // 隐藏 a.show(); // 显示 获取DOM信息 利用jQuery对象的若干方法，我们直接可以获取DOM的许多信息，而无需针对不同浏览器编写特定代码。 width() height() attr()：获取或修改属性 removeAttr() prop() … $(window).width(); $(window).height(); var div = $('#test-div'); div.width(400); div.height('200px'); div.attr('name'); div.attr('name', 'Hello'); div.removeAttr('name'); 操作表单 对于表单元素，jQuery对象统一提供val()方法获取和设置对应的value属性。一个val()就统一了各种输入框的取值和赋值的问题。 var input = $('#input'), select = $('#select'), textarea = $('#textarea'); input.val(); input.val('xxx@example.com'); \r\r","date":"2020-03-16","objectID":"/javascript/:31:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"修改DOM结构 有了jQuery，我们就专注于操作jQuery对象本身，底层的DOM操作由jQuery完成就可以了，这样一来，修改DOM也大大简化了。 添加DOM 除了html()这种暴力方法外，还可以用append()方法。append()把DOM添加到最后，prepend()则把DOM添加到最前。 var ul = $('#test-div\u003eul'); ul.append('\u003cli\u003e\u003cspan\u003exxx\u003c/span\u003e\u003c/li\u003e'); 除了接受字符串，append()还可以传入原始的DOM对象、jQuery对象和函数对象。 // 创建DOM对象: var ps = document.createElement('li'); ps.innerHTML = '\u003cspan\u003ePascal\u003c/span\u003e'; // 添加DOM对象: ul.append(ps); // 添加jQuery对象: ul.append($('#scheme')); // 添加函数对象: ul.append(function (index, html) { return '\u003cli\u003e\u003cspan\u003eLanguage - ' + index + '\u003c/span\u003e\u003c/li\u003e'; }); 同级节点可以用after()或者before()方法。 删除节点 要删除DOM节点，拿到jQuery对象后直接调用remove()方法就可以了。如果jQuery对象包含若干DOM节点，实际上可以一次删除多个DOM节点。 \r\r\r","date":"2020-03-16","objectID":"/javascript/:31:1","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"事件 因为JavaScript在浏览器中以单线程模式运行，页面加载后，一旦页面上所有的JavaScript代码被执行完后，就只能依赖触发事件来执行JavaScript代码。 浏览器在接收到用户的鼠标或键盘输入后，会自动在对应的DOM节点上触发相应的事件。如果该节点已经绑定了对应的JavaScript处理函数，该函数就会自动调用。由于不同的浏览器绑定事件的代码都不太一样，所以用jQuery来写代码，就屏蔽了不同浏览器的差异，我们总是编写相同的代码。 // 栗子：点击超链接弹出提示框，用jQuery绑定一个click事件 var a = $('#test-link'); a.on('click', function () { alert('Hello!';) }); // on方法用来绑定一个事件，需要传入事件名称和对应的处理函数 // 一种更简化的写法 a.click(function () { alert('Hello!'); }); jQuery能够绑定的事件主要有： 鼠标事件 click：鼠标单击时触发； dblclick：鼠标双击时触发； mouseenter：鼠标进入时触发； mouseleave：鼠标移出时触发； mousemove：鼠标在DOM内部移动时触发； hover：鼠标进入和退出时触发两个函数（相当于mouseenter+mouseleave）。 键盘事件：仅作用在当前焦点的DOM上 keydown：键盘按下时触发； keyup：键盘松开时触发； keypress：按一次键后触发。 其它事件 focus：当DOM获得焦点时触发； blur：当DOM失去焦点时触发； change：当input, select, textarea的内容改变时触发； submit：当form提交时触发； ready：当页面被载入并且DOM树完成初始化后触发。 取消绑定 一个已被绑定的事件可以解除绑定，通过off('click', function)实现。 function hello() { alert('hello!'); } a.click(hello); // 绑定事件 // 10秒钟后解除绑定: setTimeout(function () { a.off('click', hello); }, 10000); 需要特别注意，以下这种写法无效： / 绑定事件: a.click(function () { alert('hello!'); }); // 解除绑定: a.off('click', function () { alert('hello!'); }); 这是因为两个匿名函数虽然长得一模一样，但是它们是两个不同的函数对象，off('click', function () {...})无法移除已绑定的第一个匿名函数。 为了实现移除效果，可以使用off('click')一次性移除已绑定的click事件的所有处理函数。 同理，无参数调用off()一次性移除已绑定的所有类型的事件处理函数。 事件触发条件 一个需要注意的问题是，事件的触发总是由用户操作引发的。 浏览器安全限制 在浏览器中，有些JavaScript代码只有在用户触发下才能执行。 // 如window.open()函数 // 无法弹出新窗口，将被浏览器屏蔽: $(function () { window.open('/'); }); \r\r\r","date":"2020-03-16","objectID":"/javascript/:32:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"动画 用JavaScript实现动画，原理非常简单：我们只需要以固定的时间间隔（例如，0.1秒），每次把DOM元素的CSS样式修改一点（例如，高宽各增加10%），看起来就像动画了。 但是要用JavaScript手动实现动画效果，需要编写非常复杂的代码。如果想要把动画效果用函数封装起来便于复用，那考虑的事情就更多了。 使用jQuery实现动画，代码就非常简单了。 jQuery内置的几种动画样式 show()：显示DOM元素，从左上角展开； hiden()：隐藏DOM元素，从左上角收缩； sideUp()：在垂直方向展开； sideDown()：在垂直反向收缩； fadeIn()：动画效果淡入； fadeOut()：动画效果淡出。 var div = $('#test-show-hide'); div.hide(3000); // 在3秒钟内逐渐消失 var div = $('#test-show-hide'); div.show('slow'); // 在0.6秒钟内逐渐显示 var div = $('#test-slide'); div.slideUp(3000); // 在3秒钟内逐渐向上消失 var div = $('#test-fade'); div.fadeOut('slow'); // 在0.6秒内淡出 自定义动画 使用animate()可实现任意动画效果，需要传入的参数就是DOM元素最终的CSS状态和时间，jQuery在时间段内不断调整CSS直到达到设定的值。 var div = $('#test-animate'); div.animate({ opacity: 0.25, width: '256px', height: '256px' }, 3000, function () { console.log('动画已结束'); // 恢复至初始状态: $(this).css('opacity', '1.0').css('width', '128px').css('height', '128px'); }); 串行动画 jQuery的动画效果还可以串行执行，通过delay()方法还可以实现暂停，这样我们可以实现更复杂的动画效果。 var div = $('#test-animates'); // 动画效果：slideDown - 暂停 - 放大 - 暂停 - 缩小 div.slideDown(2000) .delay(1000) .animate({ width: '256px', height: '256px' }, 2000) .delay(1000) .animate({ width: '128px', height: '128px' }, 2000); } \r\r\r","date":"2020-03-16","objectID":"/javascript/:33:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"AJAX jQuery在全局对象jQuery(也就是$)绑定了ajax()函数，可以处理AJAX请求。ajax(url, settings)常用的选项如下： async：是否异步执行AJAX请求，默认true，千万不要指定为false； method：缺省为GET； content type：发送POST请求的格式，默认为application/x-www-form-urlencoded; charset=UTF-8，也可指定为text/plain, application/json； data：发送的数据，可以是字符串、数组、对象； headers：发送的额外HTTP头，必须是一个对象； dataType：接收的数据格式，可指定为html, xml, json, text等。 get 对常用的AJAX操作，jQuery提供了一些辅助方法。由于GET请求最常见，所以jQuery提供了get()方法。 var jqxhr = $.get('/path/to/resource', { name: 'xxx', check: 1 }); // 实际URL：/path/to/resource?name=Bob%20Lee\u0026check=1 post 与get类似，但传入的第二个参数默认被序列化为application/x-www-form-urlencoded。 var jqxhr = $.post('/path/to/resource', { name: 'Bob Lee', check: 1 }); // 实际构造数据：name=Bob%20Lee\u0026check=1 getJSON 由于json越来越普遍，所以jQuery也提供了getJSON()方法来快速通过GET获取一个json对象。 var jqxhr = $.getJSON('/path/to/resource', { name: 'Bob Lee', check: 1 }).done(function (data) { // data已经被解析为JSON对象了 }); 安全限制 jQuery的AJAX完全封装的是JavaScript的AJAX操作，所以它的安全限制和前面讲的用JavaScript写AJAX完全一样。 \r\r\r","date":"2020-03-16","objectID":"/javascript/:34:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"扩展 当我们使用jQuery对象的方法时，由于jQuery对象可以操作一组DOM，而且支持链式操作，所以用起来非常方便。但是jQuery内置的方法永远不可能满足所有的需求。 我们可以扩展jQuery来实现自定义方法。我们可以扩展jQuery来实现自定义方法。 ","date":"2020-03-16","objectID":"/javascript/:35:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"编写jQuery插件 给jQuery对象绑定一个新方法是通过扩展$.fn对象实现的。 $.fn.highlight1 = function () { // this已绑定为当前jQuery对象，所以函数内部代码可以正常调用所有jQuery对象的方法 this.css('backgroundColor', '#fffceb').css('color', '#d85030'); return this; // 因为jQuery对象支持链式操作，我们自己写的扩展方法也要能继续链式下去 } // 可以给方法加个参数，让用户自己把参数用对象传进去 $.fn.highlight2 = function (options) { // 要考虑到各种情况: // options为undefined // options只有部分key var bgcolor = options \u0026\u0026 options.backgroundColor || '#fffceb'; var color = options \u0026\u0026 options.color || '#d85030'; this.css('backgroundColor', bgcolor).css('color', color); return this; } 另一种方法是使用jQuery提供的辅助方法$.extend(target, obj1, obj2, ...)，它把多个对象的属性合并到第一个target对象中，遇到同名属性，总是使用靠后的对象的值，也就是越往后优先级越高。 紧接着用户对highlight2()提出了意见：每次调用都需要传入自定义的设置，能不能让我自己设定一个缺省值，以后的调用统一使用无参数的highlight2()？也就是说，我们设定的默认值应该能允许用户修改。那默认值放哪比较合适？放全局变量肯定不合适，最佳地点是$.fn.highlight2这个函数对象本身。 $.fn.highlight = function (options) { // 合并默认值和用户设定值: var opts = $.extend({}, $.fn.highlight.defaults, options); this.css('backgroundColor', opts.backgroundColor).css('color', opts.color); return this; } // 设定默认值: $.fn.highlight.defaults = { color: '#d85030', backgroundColor: '#fff8de' } 最终，我们得出编写一个jQuery插件的原则： 给$.fn绑定函数，实现插件的代码逻辑； 插件函数最后要return this;以支持链式调用； 插件函数要有默认值，绑定在$.fn.\u003cpluginName\u003e.defaults上； 用户在调用时可传入设定值以便覆盖默认值。 \r\r","date":"2020-03-16","objectID":"/javascript/:35:1","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"针对特定元素的扩展 我们还知道jQuery对象的有些方法只能作用在特定的DOM元素上，比如submit()方法只能针对form。如果我们编写的扩展只能针对某些类型的DOM元素，应该怎么写？ 还记得jQuery的选择器支持filter()方法来过滤吗？我们可以借助这个方法来实现针对特定元素的扩展。 \r\r \r\r错误处理 错误分两种： 一种是程序逻辑写的不对，导致代码执行异常； 一种是执行过程中，程序可能遇到无法预测的异常情况而报错。 错误处理是程序设计时必须要考虑的问题。 // 类似于Python的try try { ... } catch (e) { ... } finally { ... } 错误类型 JavaScript有一个标准的Error对象表示错误，还有从Error派生的TypeError, FeferenceError等错误对象。 try { ... } catch (e) { if (e instanceof TypeError) { alert('Type error!'); } else if (e instanceof Error) { alert(e.message); } else { alert('Error: ' + e); } } 抛出错误 程序也可以主动抛出一个错误，让执行流程直接跳转到catch块。抛出错误使用throw语句。 \r\r","date":"2020-03-16","objectID":"/javascript/:35:2","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"错误传播 如果代码发生了错误，有没有被try...catch捕获，那么程序执行流程会跳转到哪呢？ 如果在一个函数内部发生了错误，它自身没有捕获，错误就会被抛到外层调用函数，如果外层函数也没有捕获，该错误会一直沿着函数调用链向上抛出，直到被JavaScript引擎捕获，代码终止执行。 \r\r","date":"2020-03-16","objectID":"/javascript/:36:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"异步错误处理 编写JavaScript代码时，我们要时刻牢记，JavaScript引擎是一个事件驱动的执行引擎，代码总是以单线程执行，而回调函数的执行需要等到下一个满足条件的事件出现后，才会被执行。 所以，涉及到异步代码，无法在调用时捕获，原因就是在捕获的当时，回调函数并未执行。类似的，当我们处理一个事件时，在绑定事件的代码处，无法捕获事件处理函数的错误。 \r\r \r\runderscore 正如jQuery统一了不同浏览器之间的DOM操作的差异，让我们可以简单地对DOM进行操作，underscore则提供了一套完善的函数式编程的接口，让我们更方便地在JavaScript中实现函数式编程。 jQuery在加载时，会把自身绑定到唯一的全局变量$上，underscore与其类似，会把自身绑定到唯一的全局变量_上，这也是为啥它的名字叫underscore的原因。 \r\r \r\rNode.js 从本章开始，我们就正式开启JavaScript的后端开发之旅。 Node.js是目前非常火热的技术，但是它的诞生经历却很奇特。 Google认为要运行现代Web应用，浏览器必须有一个性能非常强劲的JavaScript引擎，于是Google自己开发了一个高性能JavaScript引擎，名字叫V8，以BSD许可证开源。 话说有个叫Ryan Dahl的歪果仁，他的工作是用C/C++写高性能Web服务。对于高性能，异步IO、事件驱动是基本原则，但是用C/C++写就太痛苦了。于是这位仁兄开始设想用高级语言开发Web服务。他评估了很多种高级语言，发现很多语言虽然同时提供了同步IO和异步IO，但是开发人员一旦用了同步IO，他们就再也懒得写异步IO了，所以，最终，Ryan瞄向了JavaScript。 因为JavaScript是单线程执行，根本不能进行同步IO操作，所以，JavaScript的这一缺陷导致了它只能使用异步IO。 选定了开发语言，还要有运行时引擎。这位仁兄曾考虑过自己写一个，不过明智地放弃了，因为V8就是开源的JavaScript引擎。让Google投资去优化V8，咱只负责改造一下拿来用，还不用付钱，这个买卖很划算。 于是在2009年，Ryan正式推出了基于JavaScript语言和V8引擎的开源Web服务器项目，命名为Node.js。虽然名字很土，但是，Node第一次把JavaScript带入到后端服务器开发，加上世界上已经有无数的JavaScript开发人员，所以Node一下子就火了起来。 在Node上运行的JavaScript相比其他后端开发语言有何优势？最大的优势是借助JavaScript天生的事件驱动机制加V8高性能引擎，使编写高性能Web服务轻而易举。 其次，JavaScript语言本身是完善的函数式语言，在前端开发时，开发人员往往写得比较随意，让人感觉JavaScript就是个“玩具语言”。但是，在Node环境下，通过模块化的JavaScript代码，加上函数式编程，并且无需考虑浏览器兼容性问题，直接使用最新的ECMAScript 6标准，可以完全满足工程上的需求。 Node.js是一个开源和跨平台的JavaScript runtime environment。 \r\r","date":"2020-03-16","objectID":"/javascript/:37:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"安装Node.js和npm 由于Node.js平台是在后端运行JavaScript代码，所以需要在本机按照Node环境。 \r\r","date":"2020-03-16","objectID":"/javascript/:38:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"安装Node.js 详情请看官网文档。 \r\r","date":"2020-03-16","objectID":"/javascript/:38:1","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"npm npm is the standard package manager for Node.js. npm其实是Node.js的包管理工具。 为啥我们需要一个包管理工具呢？因为我们在Node.js上开发时，会用到很多别人写的JavaScript代码。如果我们要使用别人写的某个包，每次都根据名称搜索一下官方网站，下载代码，解压，再使用，非常繁琐。于是一个集中管理的工具应运而生：大家都把自己开发的模块打包后放到npm官网上，如果要使用，直接通过npm安装就可以直接用，不用管代码存在哪，应该从哪下载。 更重要的是，如果我们要使用模块A，而模块A又依赖于模块B，模块B又依赖于模块X和模块Y，npm可以根据依赖关系，把所有依赖的包都下载下来并管理起来。否则，靠我们自己手动管理，肯定既麻烦又容易出错。 讲了这么多，npm究竟在哪？其实npm已经在Node.js安装的时候顺带装好了。 \r\r","date":"2020-03-16","objectID":"/javascript/:38:2","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"第一个Node程序 在前面的章节中，编写的JavaScript代码都是在浏览器中运行的，因此，我们可以直接在浏览器中敲代码，然后直接运行。 从本章开始，我们编写的JavaScript代码将不能在浏览器环境中执行了，而是在Node环境中执行。 'use strics'; console.log('Hello, world.') 执行: node hello.js # Hello, world. 严格模式 在服务器环境下，如果有很多JavaScript文件，每个文件都写上'use strict';很麻烦。我们可以给Nodejs传递一个参数，让Node直接为所有js文件开启严格模式： node --use_strict \r\r\r","date":"2020-03-16","objectID":"/javascript/:39:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"模块 为了编写可维护的代码，我们把很多函数分组，分别放到不同的文件里，这样，每个文件包含的代码就相对较少，很多编程语言都采用这种组织代码的方式。在Node环境中，一个.js文件就称之为一个模块（module）。 使用模块有什么好处？最大的好处是大大提高了代码的可维护性。其次，编写代码不必从零开始。当一个模块编写完毕，就可以被其他地方引用。我们在编写程序的时候，也经常引用其他模块，包括Node内置的模块和来自第三方的模块。 'use strict'; var s = 'Hello'; function greet(name) { console.log(s + ', ' + name + '!'); } // 把函数greet作为模块的输出暴露出去，这样其他模块就可以使用greet函数了 module.exports = greet; // 使用模块 // 使用require引入模块，请注意路径 var greet = require('./hello'); var s = 'Michael'; greet(s); CommonJS规范 这种模块加载机制被称为CommonJS规范。在这个规范下，每个.js文件都是一个模块，它们内部各自使用的变量名和函数名都互不冲突。 一个模块想要对外暴露变量（函数也是变量），可以用module.exports = variable;，一个模块要引用其他模块暴露的变量，用var ref = require('module_name');就拿到了引用模块的变量。 \r\r\r","date":"2020-03-16","objectID":"/javascript/:40:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["programming"],"content":"基本模块","date":"2020-03-16","objectID":"/javascript/:41:0","tags":["JavaScript","Web","JS"],"title":"JavaScript","uri":"/javascript/"},{"categories":["DevOps"],"content":"参考: Ansible docs: https://docs.ansible.com 环境: RHELx86_64 Ansible v2.9 \r\r \r\r介绍 About Ansible: https://docs.ansible.com/ansible/latest/index.html Ansible是一个IT自动化工具。它可以配置系统，部署软件和编排更先进的IT任务。Ansible的主要目标是简单和易于使用。它也专注于安全性和可靠性。 Ansible以无代理(agent-less)方式管理机器。Ansible是分散的，它依赖于现有操作系统的平局来控制访问到远程主机。如果需要，Ansible可以很容易地使用Kerberos, LDAP等集中认证管理系统连接。 \r\r \r\r词汇表 Glossary Action 动作(action)是任务的一部分，用于指定要运行的模块和传递给该模块的参数。每个任务只能有一个动作，但也可能有其它参数。 Ad Hoc 指使用/usr/bin/ansible运行Ansible执行一些快速命令，而不是编排语言，即/usr/bin/ansible-play-book。ad hoc命令的示例可能是重新启动基础结构中的50台计算机。你可以通过编写playbook来完成你可以做的任何事情，而playbook也可以将许多其它操作粘合在一起。 Async 指配置为在后台运行而不是等待完成的任务。如果你的进程时间长度超过了SSH超时时间，那么以异步(async)模式启动该任务是有意义的。异步模式可以每隔很多秒轮询完成，或者可配置为’fire and forget'，在这种情况下，Ansible甚至不会再次检查任务，它将开始并继续进行未来的步骤。异步模式使用/usr/bin/ansible和/usr/bin/ansible-playbook。 Callback Plugin 指一些用户编写的代码，可拦截Ansible的结构并对它们执行某些操作。GitHub中提供的一些示例执行自定义日志记录，发送电子邮件… Check Mode 值运行带有--check选项的Ansible，它不会对远程系统进行任何更改，但仅输出在没有此标志的情况下运行时才有可能发生的更改。 Connection Plugin 默认情况下，Ansible通过pluggable libraries与远程计算机通信。Ansible支持原生OpenSSH或称为paramiko的Python实现。如果您使用的是最新版本，则首选OpenSSH，并启用Kerberos和jump host等功能。还有其它连接类型，如accelerate模式，必须通过一种基于SSH的连接类型进行引导，但速度非常快，而本地模式则作用于本地系统。用户还可以编写自己的连接插件。 Conditionals 条件是一个表达式，其计算结果为true或false，用于决定给定任务是否在给定计算机上执行。 Declarative 实现使用最终状态描述的任务的方法，而不是实现该状态所需的步骤序列的描述。对于真实世界的栗子，任务的声明规范将是: “put me in California”。根据你当前的位置，前往加州的步骤顺序可能会有所不同，如果你已在加州，则根本不需要做任何事情。Ansible的资源是声明性的；它确定了实现最终状态所需的步骤。它还可让你知道是否需要采取任何步骤才能到达最终状态。 Diff Mode 将--diff标志传递给Ansible，以显示支持它的模块。 Executor Ansible的核心软件组件，它是/usr/bin/ansible背后的力量——并且对应于剧本中每个任务的调用。 Facts 事实是发现的有关远程节点的事情。通过在远程节点上执行内部设置模块来运行，Ansible会自动发现事实。 Filter Plugin 这允许创建新的Jinja2过滤器，这只适用于知道Jinja2过滤器的人。 Fork Ansible并行地与远程节点通信，并且可通过传递--forks或编辑配置文件中的默认值来设置并行级别。 Gather Facts (Boolean) 有时，当运行多重playbook时，如果不需要利用任何这些值，则希望有一些不打扰事实计算的playbook。 Globbing 通配符是一种选择大量主机，或它们所在组的名称的方法 Group 一组主机 Group Vars 这是将提供给指定组的变量，尤其是复杂的数据结构，这样这些变量就不必嵌入到库存文件或playbook中。 Handlers 处理程序就像Ansible playbook中的常规任务，但只有在任务包含notify指定并且还指示它已更改某些内容时才会运行。 Host 主机是Ansible管理的远程机器。 Host Specifier Ansible中的每个play都将一系列任务映射到一组系统。每个play中的hosts:指令通常称为主机说明符。它可以选择一个或多个系统，一个或多个组，甚至一个组中的一些主机，而不是另一个组中的主机。 Host Vars 主机变量类似与组变量。 Idempotency 如果执行一次的结果与在没有任何干预动作的情况下重复执行它的结果完全相同，则操作是幂等的。 Includes playbook文件可以包括其它play list，任务列表可以外部化其它文件中的任务列表，类似于处理程序。 Inventory 用于描述Ansible中的主机和组的文件。 Inventory Script 一个程序，用于查找主机，主机的组关系以及外部资源的变量信息——无论是SQL数据库，CMDB方案，还是LDAP等。 Jinja2 Jinja2是Ansible模板模块的首选语言。它是一种非常简单的Python模板语言，可读且易于编写。 JSON Ansible使用JSON从远程模块返回数据。这允许用任何语言编写。 Lazy Evaluation 通常，Ansible会在最后一秒评估playbook内容中的任何变量。 Library Ansible的模块集合。 Limit Groups 通过将--limit somegroup传递给Ansible或ansible-playbook可以限制主机的子集。 Local Action 针对远程计算机的playbook中的本地活动指令意味着给定的步骤实际上将在本地计算机上发生，但是可以传入变量{{ansible_hostname}}以引用该步骤中引用的远程主机名。 Local Connection 通过在playbook中使用connection: local，或将-c local传递给/usr/bin/ansible，这表明我们正在管理本地主机而不是远程主机。 Lookup Plugin 查找插件是一种从外部获取数据到Ansible的方法。 Loops 通常，Ansible不是一种编程语言。它更喜欢声明性，尽管循环这样的各种结构允许对列表中的多个项重复特定任务。 Modules 模块是Ansible发送到远程机器的工作单元。 Multi-Tier IT系统不是一次管理一个系统的概念，而是通过明确定义的订单中多个系统和系统组之间的交互。 Notify 任务注册更改事件并通知处理程序任务需要在play结束时运行另一个操作的行为。 Orchestration 许多软件自动化系统使用这个词来表示不同的东西。Ansible使用它作为编排的指挥。 paramiko 默认情况下，Ansible通过SSH管理机器。Ansible默认使用的库是一个名为paramiko的Python驱动库。 Playbooks playbook是Ansible编排，配置，管理或部署系统的语言。它被称为剧本，部分原因在于它是一种运动类比，并且使用它们应该很有趣。 Plays A playbook is a list of plays。剧本最小是由主机说明符选择的一组主机之间的映射，以及在这些主机上运行定义这些系统将执行的角色的任务。 Pull Mode 默认情况下，Ansible以push模式运行，这使得它可以在与每个系统进行通信时进行非常精细的控制。当你希望在特定计划时间点检查节点时，可以使用pull模式。 Push Mode Register Variable 在Ansible中运行任何任务的结果可以存储在变量中，以便在模板或条件语句中使用。 Resource Model Ansible模块在资源方面起作用。 Roles 角色是Ansible的组织单位。 Rolling Update 一次解决组中的多个节点的行为，以避免一次更新所有节点并使系统脱机。 Sudo SSH (Native) Tags Ansible允许使用任意关键字标记剧本中的资源，然后仅运行与这些关键字对应的剧本部分。 Task 任务将操作(模块及其参数)与名称和可选的其他关键字(如循环指令)组合在一起。 Templates Ansible可以轻松地将文件传输到远程系统，但通常需要在其它文件中替换变量。 Transport Ansible使用term:连接插件来定以可用传输的类型。 When 一个可选的条件语句。 Vars (Variables) 与事实相反，变量是值的名称(int, bool, string)或复杂的数据(dict, hash, lists)。它是声明的东西，而不是从远程系统获取的东西。 YAML Ansible不想强迫人们编写程序代码来自动化基础设施，因此使用YAML来定义剧本配置语言和变量文件。 \r\r \r\r安装指南 Installtion Gu","date":"2019-12-26","objectID":"/ansible/:0:0","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"安装Ansible Installing Ansible: https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html Ansible是一个默认通过SSH协议管理机器的无代理(agentless)的自动化工具。一旦安装，Ansible不添加数据库，并且不需要启动守护进程。你只需要在一台机器上安装它，它可以从该中心点管理远程所有机器。 \r","date":"2019-12-26","objectID":"/ansible/:1:0","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"先决条件 Prerequisite 在控制节点上安装Ansible，然后使用SSH(默认)与管理的节点通信。 控制节点的依赖 Control node requirements 目前，Ansible可以从任何安装了Python2.7或Python3.5+的机器上运行。不支持Windows。 被管理节点的依赖 Managed node requirements 在被管理的节点上，你需要一种方法来通信（通常是SSH）。 \r\r","date":"2019-12-26","objectID":"/ansible/:1:1","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"选择版本 Selecting an Ansible version to install 选择自己需要的Ansible版本进行安装，可选择一下几种方式： 使用操作系统包管理器进行安装 使用pip进行安装 使用源码进行安装 \r\r","date":"2019-12-26","objectID":"/ansible/:1:2","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"在RHEL上安装 Installing Ansible on RHEL, CentOS, or Fedora yum search ansible sudo yum install ansible \r\r","date":"2019-12-26","objectID":"/ansible/:1:3","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"使用pip安装 Installing Ansible with pip 使用Python的包管理工具pip来安装Ansible。 # env # python -m virtualenv ansible # source ansible/bin/activate pip install --user ansible pip install --user paramiko \r\r","date":"2019-12-26","objectID":"/ansible/:1:4","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"Ansible command shell completion Ansible 2.9的命令行工具由称为argcomplete的依赖提供。 sudo yum install epel-release sudo yum install python-argcomplete # pip # pip install argcomplete 配置argcomplete 有两种方式来配置Ansible的命令行工具argcomplete： 全局(Globally) # Global completion requires bash 4.2. sudo activate-global-python-argcomplete 每个命令(Per command) # If you do not have bash 4.2, you must register each script independently. # 可将这些写入.profile里 eval $(register-python-argcomplete ansible) eval $(register-python-argcomplete ansible-config) eval $(register-python-argcomplete ansible-console) eval $(register-python-argcomplete ansible-doc) eval $(register-python-argcomplete ansible-galaxy) eval $(register-python-argcomplete ansible-inventory) eval $(register-python-argcomplete ansible-playbook) eval $(register-python-argcomplete ansible-pull) eval $(register-python-argcomplete ansible-vault) \r\r\r","date":"2019-12-26","objectID":"/ansible/:1:5","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"配置Ansible Configuring Ansible: https://docs.ansible.com/ansible/latest/installation_guide/intro_configuration.html ","date":"2019-12-26","objectID":"/ansible/:2:0","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"配置文件 Configuration file Ansible将按照一下顺序搜索配置文件： ANSIBLE_CONFIG环境变量 ansible.cfg当前目录 ~/.ansible.cfg /etc/ansible/ansible.cfg Ansible配置参考 \r\r \r\rAnsible移植指南 Ansible Porting Guides: https://docs.ansible.com/ansible/latest/porting_guides/porting_guides.html \r\r \r\r用户指南 User Guide: https://docs.ansible.com/ansible/latest/user_guide/index.html 本指南介绍如何使用Ansible工作，包括CLI, invetory, playbooks。 \r\r","date":"2019-12-26","objectID":"/ansible/:2:1","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"Quickstart Ansible Quickstart Guide: https://docs.ansible.com/ansible/latest/user_guide/quickstart.html \r\r","date":"2019-12-26","objectID":"/ansible/:3:0","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"概念 Ansible concepts: https://docs.ansible.com/ansible/latest/user_guide/basic_concepts.html Controle node：按照Ansible的任意机器。Windows机器无法作为控制节点。可以有多个控制节点。 Managed nodes：使用Ansible管理的网络设备。通常称为主机，Ansible未安装在管理节点上。 Inventory：一组管理节点的列表。清单文件有时称为主机文件(hostfile)。 Modules：Ansible执行代码单元。Ansible模块列表 Tasks：Ansible中的动作单元。可使用ad-hoc命令执行单一任务一次。 Playbooks：任务的有序列表。可按照顺序反复执行这些任务。剧本可以包含变量和任务。它以YAML格式编写。 \r\r","date":"2019-12-26","objectID":"/ansible/:4:0","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"入门 Getting Started: https://docs.ansible.com/ansible/latest/user_guide/intro_getting_started.html 一个基本的Ansible命令或playbooks： 从清单中选择机器来执行 连接到这些机器（通常是SSH） 复制一个或多个模块到远程机器，并执行 Ansible可以做很多事。一旦你理解了Ansible是如何工作的，你可以阅读有关的ad-hoc命令的详细信息，使用清单组织你的基础架构，并利用Ansible强大的playbooks。 \r\r","date":"2019-12-26","objectID":"/ansible/:5:0","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"从清单选择机器 Ansible从你的清单中读取管理的机器的信息。虽然你可以通过IP地址和ad-hoc命令，你也需要清单来增加Ansible的灵活性和重复性。 # 创建一个基本的清单 # 在此文件中添加远程系统 vim /etc/ansible/hosts 192.0.2.50 aserver.example.org bserver.example.org 也可以使用别名(aliases)，主机变量(host vars)，组变量(group vars)。 \r","date":"2019-12-26","objectID":"/ansible/:5:1","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"连接到远程节点 Ansible与远程机器通过SSH协议进行通信。默认情况下，Ansible使用原生的OpenSSH连接到远程机器。 确认用户名可使用SSH进行连接。如有必要，将SSH公钥添加到系统的authorized_keys文件。 ","date":"2019-12-26","objectID":"/ansible/:5:2","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"复制和执行模块 一旦建立连接，Ansible传输你的命令或剧本需要的模块到远程机器。 # 运行第一个ansible命令 ansible all -m ping # 运行一个节点上的命令 ansible all -a \"/bin/echo hell\" ","date":"2019-12-26","objectID":"/ansible/:5:3","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"如何构建清单 How to build your inventory: https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html Ansible对多个被管理的节点使用被称为清单的列表或组列表。一旦清单定义，你可以选择主机或组来运行。 清单的默认位置是/etc/ansible/hosts。可以通过-i选项来指定不同的清单文件。也可以同时使用多个清单文件。从动态或云拉取清单。 ","date":"2019-12-26","objectID":"/ansible/:6:0","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"清单基本 formats, hosts, groups。 清单文件有多种形式。最常用的是INI和YAML。 # INI格式 mail.example.com # 组名 [webservers] a.example.com b.example.com [dbserver] db1.example.com db2.example.com db3.example.com # YAML格式all:hosts:mail.example.com:children:webserver:hosts:a.example.com:b.example.com:dbservers:hosts:db1.example.com:db2.example.com:db3.example.com: 默认组(default groups)，有两个默认组。 all：包含每个主机 ungrouped：all中没有组的主机 在多个组中的主机(Hosts in multiple groups)。 all:hosts:mail.example:children:webservers:hosts:f.example.com:b.example.com:dbservers:hosts:one.example.com:two.example.com:east:hosts:f.example.com:one.example.com:west:hosts:b.example.com:two.example.com:prod:children:east:test:hosts:b.example.com: 添加主机范围(Adding ranges of hosts)。如果有很多主机有一个类似的模式，可将其添加为一个范围，而不是单独列出每个主机名。 ...webservers:hosts:www[01:20].example.com:dbservers:hosts:db-[a:f].example.com ","date":"2019-12-26","objectID":"/ansible/:6:1","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"添加变量到清单 Adding variables to inventory 可以在清单中存储涉及到特定主机或组的变量值。 \r\r","date":"2019-12-26","objectID":"/ansible/:6:2","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"主机变量 Assigning a variable to one machine: host variables atlanta:hosts1:http_port:80maxRequestPerChild:808hosts2:http_port:303maxRequestPerChild:909 清单别名(Inventory aliases)。在清单中定义别名： ...hosts:jumper:ansible_port:5555ansible_host:192.0.2.50 \r\r","date":"2019-12-26","objectID":"/ansible/:6:3","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"组变量 Assigning a variable to many machines: group variables 在一组的主机中共享变量值。 atlanta:hosts:hosts1:host2:vars:ntp_server:ntp.atlanta.example.comproxy:proxy.atlanta.example.com 继承变量值(Inheriting variable values: group variables for groups of groups)。可使用children:(yaml)来构建组的组，同样，可使用vars:来构建组变量的组变量。 all:children:usa:children:southeast:children:atlanta:hosts:hosts1:hosts2:raleigh:hosts:hosts2:hosts3:vars:some_server:foo.southeast.example.comhalon_system_timeout:30self_destruct_countdown:60escape_pods:2northeast:norethwest:southwest: 子组有几个属性的注意事项： 子组成员的任何主机自动成为父组的成员 子组的变量的优先级高于(覆盖)父组的变量 组可以有多个父亲和孩子 主机可以在多个组，但只会有一台主机实例，合并来自多个组的数据 \r\r","date":"2019-12-26","objectID":"/ansible/:6:4","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"组织主机和组变量 Organizing host and group variables 尽管你可以将变量存储在清单文件，但存储独立的主机和组变量可以帮助您更轻松地阻止你的变量值。主机和组变量文件必须使用YAML语法。 Ansible通过搜索清单文件或剧本文件的路径来载入主机和组变量文件。 \r\r","date":"2019-12-26","objectID":"/ansible/:6:5","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"变量如何合并 How variables are merged 默认情况下，在play运行前变量被合并到特定的主机。这使Ansible集中在主机和任务，因此组并没有真正生存在清单和主机匹配之外。Ansible覆盖变量的顺序： all group parent group child group host 默认情况下Ansible在相同的父/子级按字母顺序合并组，并在最后一组加载覆盖前面的组。你可以通过设置组变量ansible_group_priority来改变同级组合并顺序的行为。数字越大，优先级就越高。默认值是1。 # testvar == aa_group:testvar:aansible_group_priority:10b_group:testvar:b \r\r","date":"2019-12-26","objectID":"/ansible/:6:6","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"使用多个清单源 Using multiple inventory sources 可通过在命令行中或配置ANSIBLE_INVENTORY通过给定多个清单参数在同一时间目标多个清单源（目录，动态清单脚本，清单插件…）。 # target 2 sourcesansible-playbook get_logs.yml -i staging -i production 以一个目录组合多个清单源(Aggregating inventory sources with a directory) 还可以通过一个目录下结合多个清单源和原类型来创建清单。这对于动静结合主机和管理它们为一体化清单很有用。 inventory/openstack.yml # configure inventory plugin to get hosts from Openstack clouddynamic-inventory.py # add additional hosts with dynamic inventory scriptstatic-inventory # add static hosts and groupsgroup_vars/all.yml # assign variables to all hosts # target inventory ansible-playbook example.yml -i inventory \r\r","date":"2019-12-26","objectID":"/ansible/:6:7","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"清单参数 Connecting to hosts: behavioral inventory parameters 以下变量控制与远程主机如何与Ansible相互作用。 \r\r","date":"2019-12-26","objectID":"/ansible/:6:8","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"清单配置样例 Inventory setup examples 每个环境一个清单(One inventory per environment) 通过功能分组(Group by function) 通过地址分组(Group by location) # Example: One inventory per environment # inventory_test [dbservers] db01.test.example.com db02.test.example.com # Example: Group by function- hosts:dbserverstasks:- name:allow access from 10.0.0.1iptables:chain:INPUTjump:ACCEPTsource:10.0.0.1 # Example: Group by location [dc1] db01.test.example.com app01.test.example.com \r\r\r","date":"2019-12-26","objectID":"/ansible/:6:9","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"动态清单 Working with dynamic inventory: https://docs.ansible.com/ansible/latest/user_guide/intro_dynamic_inventory.html \r","date":"2019-12-26","objectID":"/ansible/:7:0","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"cobbler \r\r","date":"2019-12-26","objectID":"/ansible/:7:1","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"AWS ec2 \r\r","date":"2019-12-26","objectID":"/ansible/:7:2","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"OpenStack \r\r","date":"2019-12-26","objectID":"/ansible/:7:3","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"其它清单脚本 Other inventory scripts \r\r\r","date":"2019-12-26","objectID":"/ansible/:7:4","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"模式 Patterns: targeting hosts and groups: https://docs.ansible.com/ansible/latest/user_guide/intro_patterns.html 当你通过ad-hoc或playbook执行Ansible时，你必须选择要对哪些节点或组执行。模式可以让你针对清单中的特定主机或组执行。一个Ansible Pattern可以指定单个主机、IP地址、清单组、一组组、所有主机…模式非常灵活，可以排除需要的主机子集、使用通配符、正则表达式…Ansible将在包含在模式上的所有清单主机上执行。 \r","date":"2019-12-26","objectID":"/ansible/:8:0","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"模式使用 Using patterns # ad-hoc # ansible {pattern} -m {module_name} -a \"{module_options}\" ansible webservers -m service -a \"name=httpd state=restarted\" # palybook- name:{play_name}hosts:{pattern}- name:restart webservershosts:webservers \r\r","date":"2019-12-26","objectID":"/ansible/:8:1","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"常见模式 Common patterns 描述 模式 目标 All hosts all(*) - One host host1 - Multiple hosts host1:host2(host1,host2) - One group g1 - Multiple groups g1:g2 all hosts in g1 and g2 Excluding groups g1:!g2 all hosts in g1 except those in g2 Intersection of groups g1:\u0026g2 g1和g2的交集 \r\r","date":"2019-12-26","objectID":"/ansible/:8:2","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"模式的局限性 Limitations of patterns 模式依赖于清单。如果主机或组不在清单中，则不能使用模式来目标它。如果模式中包含清单中不存在的IP地址或主机名，会报错。模式必须匹配清单语法。 \r\r","date":"2019-12-26","objectID":"/ansible/:8:3","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"高级的模式选项 Advanced pattern options 常用的模式将满足你的大部分需求，但Ansible提供了几种方法来定义你需要定位(target)的主机和组。 在模式中使用环境变量 Using variables in patterns # playbook webservers:!{{ excluded }}:\u0026{{ required }} 在模式中使用组位置 Using group position in patterns [g1] aa bb cc g1[0] g1[-1] g1[0:2] g1[1:] 在模式中使用正则 Using regexes in patterns 以~符号开始使用模式的正则: ~(web|db).*\\.example\\.com \r\r","date":"2019-12-26","objectID":"/ansible/:8:4","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"playbook标志 Patterns and ansible-playbook flags 可以使用命令行选项改变playbook中定义的行为。 ansible-playbook site.yml --limit datacenter2 \r\r\r","date":"2019-12-26","objectID":"/ansible/:8:5","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"ad-hoc Introduction to ad-hoc commands: https://docs.ansible.com/ansible/latest/user_guide/intro_adhoc.html 一个Ansible的ad-hoc命令使用ansible命令行工具在一个或多个管理节点上执行单一任务。ad-hoc命令是快速和容易的，但却无法重复使用。那么为什么首先学习ad-hoc命令呢？它表明Ansible的简单和功能。在这学的内容可直接到playbook里。在执行前，请先阅读构建清单。 ansible命令行实用程序的默认模块是command module。 如果像重复一个命令，可使用playbook中的template module。 \r","date":"2019-12-26","objectID":"/ansible/:9:0","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"为什么使用它 Why use ad-hoc commands? ad-hoc命令针对的是很少会重复的任务。 # 栗子 ansible [pattern] -m [module] -a \"[module options]\" \r\r","date":"2019-12-26","objectID":"/ansible/:9:1","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"用例 Use cases for ad-hoc tasks ad-hoc任务可用来重启服务器、复制文件、管理包和用户…可在ad-hoc任务中使用任意Ansible模块。Ad-hoc tasks与playbooks类似，使用一个声明模型，计算并执行以达到规定的最终状态所需的操作。 重启服务器 ad-hoc任务调用命令模块。在执行前，确保清单和SSH。 # rebooting servers ansible host1 -a \"/sbin/reboot\" # 默认是5并发进程 ansible host1 -a \"/sbin/reboot\" -f 10 # ansible将默认为你的用户账户 ansible host1 -a \"/sbin/reboot\" -f 10 -u username # 重启服务器可能需要特权提升，如从user到root ansible host1 -a \"/sbin/reboot\" -f 10 -u username --become [--ask-become-pass] # 使用不同的模块 ansible host1 -m shell -a 'echo ${TERM}' 文件管理 ad-hoc可利用Ansible和scp的力量，并行传输文件到多台机器。 # 复制文件 ansible atlanta -m copy -a \"src=/etc/hosts dest=/tmp/hosts\" # file模块属主和权限，创建目录，递归删除 ansible webservers -m file -a \"dest=/srv/foo/b.txt mode=600 owner=mdehaan group=mdehaan\" ansible webservers -m file -a \"dest=/path/to/c mode=755 owner=mdehaan group=mdehaan state=directory\" ansible webservers -m file -a \"dest=/path/to/c state=absent\" 包管理 使用ad-hoc任务使用包管理模块（如yum），来安装、升级、移除包。 Ansible有许多平台的许多包管理工具的模块，详情请看文档。 # 安装了包不更新 ansible webservers -m yum -a \"name=acme state=present\" # 特定包版本 ansible webservers -m yum -a \"name=acme-1.5 state=present\" # 确认包是最新版 ansible webservers -m yum -a \"name=acme state=latest\" # 确保未安装 ansible webservers -m yum -a \"name=acme state=absent\" 管理用户和组 使用ad-hoc任务在管理的节点上创建、管理、移除用户账户。 ansible all -m user -a \"name=foo password={crypted password here}\" ansible all -m user -a \"name=foo state=absent\" 服务管理 # 确保服务已启动 ansible webservers -m service -a \"name=httpd state=started\" # 重启服务 ansible webservers -m service -a \"name=httpd state=restarted\" # 确保服务已停止 ansible webservers -m service -a \"name=httpd state=stopped\" 收集事实 事实代表发现关于系统的变量。 # 查看所有facts ansible all -m setup \r\r\r","date":"2019-12-26","objectID":"/ansible/:9:2","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"连接方法和详情 Connection methods and details: https://docs.ansible.com/ansible/latest/user_guide/connection_details.html \r","date":"2019-12-26","objectID":"/ansible/:10:0","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"ControlPersist和paramiko 默认情况下，Ansible使用原生的OpenSSH，因为它支持ControlPersist（一个性能特点），Kerberos，和~/.ssh/config中的配置。如果你的控制机使用的旧版本OpenSSH不支持ControlPersist，Ansible将回退到称为paramiko的一个Python实现的OpenSSH。 \r\r","date":"2019-12-26","objectID":"/ansible/:10:1","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"ssh-key配置 SSH key setup 默认情况下，Ansible假定您使用SSH keys连接到远程主机。推荐使用key，但可使用--ask-pass选项来使用密码。使用--ask-become-pass选项来使用特权提升。 # 建立ssh agent来避免输入密码 ssh-agent bash ssh-add ~/.ssh/id_rsa \r\r","date":"2019-12-26","objectID":"/ansible/:10:2","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"本地运行 Running against localhost ansible localhost -m ping -e 'ansible_python_interpreter=\"/usr/bin/env python\"' \r\r","date":"2019-12-26","objectID":"/ansible/:10:3","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"主机密钥检查 Host key checking Ansible默认启用主机密钥检查。如果主机重装并在known_hosts中有不同的密钥，这将导致一个错误消息，知道纠正。 可在/etc/ansible/ansible.cfg或~/.ansible.cfg中禁用它: [defaults] host_key_checking = False 或设置环境变量: export ANSIBLE_HOST_KEY_CHECKING=False \r\r","date":"2019-12-26","objectID":"/ansible/:10:4","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"其它连接方法 Other connection methods 除了SSH之外，Ansible还可以使用许多连接方法。 \r\r\r","date":"2019-12-26","objectID":"/ansible/:10:5","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"命令行工具 Working with command line tools: https://docs.ansible.com/ansible/latest/user_guide/command_line_tools.html 大多数用户对ansible和ansilbe-playbook比较熟悉，但它们不是Ansible提供的唯一实用工具。下面是完整的Ansible使用工具列表。 ansible: 在一组主机上定义和运行一个单任务playbook ansible-config: 查看Ansible配置信息 ansible-console: REPL控制台执行Ansible任务 ansible-doc: 插件文档工具 ansible-galaxy: 执行各种角色并收集相关的操作 ansible-invotory: 显示或转配置清单 ansible-playbook: 运行Ansible playbook ansible-pull: 从仓库拉playbook并为本地主机执行 ansible-valut: Ansible数据文件的加解密工具 \r\r\r","date":"2019-12-26","objectID":"/ansible/:11:0","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"playbook Working With Playbooks: https://docs.ansible.com/ansible/latest/user_guide/playbooks.html Playbooks是Ansible的配置(configuration)、部署(deployment)和编排(orchestration)语言。它可以描述你希望你的远程系统强制执行的策略，或在IT流程的步骤。 在最基本的级别上，playbook可以被用来管理部署的配置到远程机器。在更高级的，它们可以序列进行涉及多层(mulit-tier)的滚动更新和回滚，并可以委托操作其它主机，与监控服务器进行交互和负载均衡。它有很多功能和信息，详情看文档。 playbook被设计为人类可读的和基于文本语言开发。有多种方式来组织playbook和它包含的文件。 你应该看一看Example Playbooks，并与playbook文档一起阅读。这些说明的最佳实践，以及如何把众多的各种概念混合在一起。 \r","date":"2019-12-26","objectID":"/ansible/:12:0","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"介绍 Intro to Playbooks: https://docs.ansible.com/ansible/latest/user_guide/playbooks_intro.html playbook是比在ad-hoc任务执行模式下的一个完全不同的使用ansible的方式，并且特别强大。 简单来说，Playbook是一个非常基础的用于配置管理和多机部署系统，不同于任何已存在的，并且非常适合部署复杂的应用程序。 playbook可以声明配置，但它也可以通过编排任意手动排序进程的步骤，尽管不同的步骤必须来回在特定命令的机器之间。它可以同步(synchronously)或异步(asynchronously)发射任务。 虽然你为ad-hoc任务运行主要的/usr/bin/ansible程序，playbook更可能被保持在原控制和用于推送配置或保证远程系统上的配置。palybook example中有许多栗子，建议去看一看。 \rplaybook language playbook以YAML语法格式表示，故意不设计成一种编程语言或脚本，而是过程或配置的模型。 每个playbooks由列表中的play组成。play的目标是映射一组主机到一些良好定义的角色(roles)，由ansible调用任务来表示。通过多个paly组成playbook，有可能协调多机部署，在某个组的所有机器上运行某些步骤…你可以由相当多的影响你的系统做不同事情的paly。 # 仅包含一个paly的`verigy-apache.yml`的playbook的栗子---- hosts:webservervars:http_port:80max_clients:200remote_user:roottasks:- name:ensure apache is at the latest versionyum:name:httpdstate:latest- name:write the apache config filetemplate:src:/srv/httpd.j2dest:/etc/httpd.confnotify:- restart apache- name:ensure apache is runningservice:name:httpdstate:startedhandlers:- name:restart apacheservice:name:httpdstate:restarted # 包含多个play的栗子---- hosts:webserversremote_user:roottasks:- name:ensure apache is at the lastest versionyum:name:httpdstate:latest- name:write the apache config filetemplate:src:/srv/httpd.j2dest:/etc/httpd.conf- hosts:databasesremote_user:roottasks:- name:ensure pgsql is at the latest versionyum:name:postgresqlstate:latest- name:ensure that postgresql is startedservice:name:postgresqlstate:started \r\r基本 Basics 主机和用户 Hosts and Users 对于playbook中的每个play，你可以选择哪些机器在你的基础设施到目标，什么远程用户完成这些步骤。 # hosts行是一个或多个主机或组的模式，以冒号分隔---- hosts:webserversremote_user:roottasks:- name:testping:remote_user:username# 远程用户可在每个用户中定义 # 特权提升---- hosts:webserversremote_user:usernamebecome:yes # 也可在每个paly中使用become---- hosts:g1remote_user:uernametasks:- service:name:nginxstate:startedbecome:yesbecome_method:sudo # 权限提升为特定用户---- hosts:g1remote_user:usernamebecome:yesbecome_user:postgres # 控制运行顺序，默认是清单里面的顺序---- hosts:allorder:sortedgather_facts:Falsetasks:- debug:var:inventory_hostname 任务列表 Tasks list 每个play包含任务列表。任务在移动到下一个任务之前执行，一次一个，由模式匹配的所有主机。理解在一个play中，所用主机都将得到同样的任务指令是很重要的。这是play映射选择主机到任务的目的。 当运行playbook时，它从上到下运行，失败任务的主机被从playbook轮转中取出。如果事情失败，只是纠正playbook文件，然后重新运行。 每个任务的目标是执行带有特定参数的模块，变量可以在参数中传给模块。 # 一个任务的基本栗子tasks:- name:make sure apache is runningservice:name:httpdstate:started # command, shell模块tasks:- name:enable selinuxcommand:/sbin/setenfore 1tasks:- name:run this command and ignore the resultshell:/usr/bin/somecommand || /bin/true tasks:- name:create a virtual host file for {{ vhost}}template:src:somefile.j2dest:/etc/httpd/conf.d/{{ vhost}} \r\raction shorthand # Ansible prefers listing modules like this:template:src:template/foo.j2dest:/etc/foo.conf 早期版本使用以下格式，仍旧有效: action: template src=templates/foo.j2 dest=/etc/foo.conf \r\rHandlers Handlers: Running Operations On Change 如前所述，当远程系统上做了改变时模块应该是幂等的和可以中继(relay)。playbook认识到了这一点，并有一个基本的事件系统用于应对改变。 这些play中的notify行动在任务的每个末尾块触发，即使被多个不同任务通知也只能被触发一次。 例如，多个资源可能表明Apache需要重启，因为配置文件发生了更改，但Apache将跳跃一次，以避免不必要的重启。 # 当一个文件的内容更改时（仅此文件），重启两个服务的栗子- name:template configuration filetemplate:src:template.j2dest:/etc/foo.confnotify:- restart memcached- restart apache 在任务的notify中列出的事情的部分被称为处理程序(handlers)。 处理程序是任务列表，与常规的任务没什么区别，由一个全局唯一的名称进行引用，并通过通知程序(notifier)进行通知。如果没有事情通知一个处理程序，它将不会运行。不管有多少任务通知处理程序，它只能运行一次，在一个特定paly中的所有任务完成之后。 # handlers sectionhandlers:- name:restart memcachedservice:name:memcachedstate:restarted- name:restart apachedservice:name:apachestate:restarted 你可能想让Ansible handlers使用变量。如果handlers name使用的变量不可用，则整个paly将失败。取而代之的是，在handlers的任务参数中使用变量。 tasks:- name:Set host variables based on distributioninclude_vars:\"{{ ansible_facts.distribution}}.yml\"handlers:- name:restart web serviceservice:name:\"{{ web_service_name | default('httpd') }}\"state:restarted Ansible 2.2，handlers可以监听(listen)通用话题(generic topics)，任务可以通知这些话题。以下这种使用使它更容易触发多个处理程序。它还从名称解耦处理程序，使得在playbook和roles之间更容易共享处理程序。（特别是当使用像Galaxy的第三方角色时） handlers:- name:restart memcachedservice:name:memcachedstate:restartedlisten:\"restart web service\"- n","date":"2019-12-26","objectID":"/ansible/:12:1","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"可重复使用的playbook Creating Reusable Playbooks: https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse.html 虽然可以在一个非常大的文件里编写playbook，最终你会想重新使用文件和整理东西。在Ansible中，有三种方式可以做到这一点： includes imports roles includes和imports允许用户将大型playbook分解为小型文件，可跨多个parent playbook或设置多次在相同的playbook里。 roles允许不仅仅是任务可以打包在一起，可以包括变量(variables)，处理程序(handlers)，甚至模块(modules)和其它插件(plugins)。不同于includes和imports，roles也可上传并经由Ansible Galaxy共享。 including和importing Including and Importing: https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_includes.html include和import语句相似，但Ansible执行引擎处理它们却非常不同。 import*语句在playbook被解析的时候进行预处理(pre-processed)。 include*语句在playbook的执行过程中遇到才处理。 include和import语句可以在任意深度使用。 在一个master playbook内包含playbook： - import_playbook:a.yml- import_playbook:b.yml 每个playbook中列出的plays和tasks将以列出的顺序 执行，就好像它们已经在这里直接定义。 大型任务划分成不同的文件是组织复杂任务或重用它们的一种好方式。一个任务文件只包含简单的任务列表： - name:aaacommand:/bin/aaa- name:bbbcommand:/bin/bbb 可以使用import_tasks或include_tasks来执行在主任务列表中的文件的任务： tasks:- import_tasks:aaa_tasks.yml# or- include_tasks:aaa_tasks.yml 你也可以传递变量到imports和includes： tasks:- import_tasks:aaa.yamlvars:user:aaa- import_tasks:aaa.ymlvars:user:bbb- import_tasks:aaa.ymlvars:user:ccc include和import同样可以用于handlers:部分。栗子： # more_handlers.yml- name:restart apacheservice:name:apachestate:restarted handlers:- include_tasks:more_handlers.yml# or- import_tasks:more_handlers.yml Roles roles: https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_roles.html 角色(role)是基于已知的文件架构自动加载某些变量文件、任务和处理程序的方式。按角色分组的内容还可以方便地与其他用户共享。 角色目录结构 Role Directory Structure 栗子： site.ymlwebservers.ymlfooservers.ymlroles/common/tasks/handlers/files/templates/vars/defaults/meta/webservers/tasks/defaults/meta/ 角色在特定目录名下期待文件。角色必须包括这些目录中的至少一个，但它是完全没排除任何未使用。在使用时，每个目录必须包含一个main.yml文件，其中包含的相关内容： tasks：包含由角色执行的主任务列表 handlers：包含可通过此角色甚至此角色外的任何地方使用的处理程序 defaults：角色的默认变量 vars：角色的其它变量 files：通过此角色可以部署的文件 templates：通过此角色可以部署的模板 meta：为角色定义的元数据 其它YAML文件可能包含在特定目录。栗子： # roles/example/tasks/main.yml- name:added in 2.4, previously you used includeimport_tasks:redhat.ymlwhen:ansible_facts['os_family']|lower == 'redhat'import_tasks:debian.ymlwhen:ansible_facts['os_family']|lower == 'debian' # roles/example/tasks/redhat.yml- yum:name:\"httpd\"state:present # roles/example/tasks/debian.yml- pat:name:\"apache2\"state:present 角色还可以包含模块和其它插件类型。 角色使用 使用角色的原始的方式是在play中通过roles:： ---- hosts:webserversroles:- common- webservers 这将为每个角色(x)指定以下行为： 如果roles/x/tasks/main.yml存在，其中列出的任务将被添加到play； 如果roles/x/handlers/main.yml存在，其中列出的处理程序将被添加到play； 如果roles/x/vars/main.yml存在，其中列出的变量将被添加到play； 如果roles/x/defaults/main.yml存在，其中列出的变量将被添加到play； 如果roles/x/meta/main.yml存在，其中列出的任何角色的依赖都将被添加到角色列表； 角色中的任意copy, script, template, include tasks，可在roles/x/{files,templates,tasks}/dir进行引用，而不必关心它们的相对或绝对路径。 当以这种方式使用时，playbook的执行顺序如下： play中定义的任意pre_tasks 任意处理程序触发到目前为止将会运行 在roles中列出的每个角色将依次执行。在角色meta/main.yml中定义的任意角色依赖将首先运行，受标签过滤和条件 play中定义的任意tasks 任意处理程序触发到目前为止将会运行 play中定义的任意post_tasks 任意处理程序触发到目前为止将会运行 可使用import_role或include_role在其它任务中使用角色： ---- hosts:webserverstasks:- debug:msg:\"before we run our role\"- import_role:name:example- include_role:name:example- debug:msg:\"after we ran our role\" 当角色在原始方式中定义，它们被视为静态导入和在playbook解析时进行处理。 角色的名称可是很简单，也可以是一个完全合格的路径： ---- hosts:webserversroles:- role:'/path/to/roles/common' 角色可以接受其它关键字： ---- hosts:webserverstasks:- include_role:name:foo_app_instancewhen:\"ansible_facts['os_family'] == 'RedHat'\"vars:dir:'/opt/a'app_port:5000tags:- aaa- bbb 角色副本和扩展 Role Duplication and Execution Ansible只允许一个角色执行一次，即使多次定义： ---- hosts:webserversroles:- foo- foo 上面给出的foo角色仅将运行一次。为了使角色多次运行，有两种选择： 每个角色传递不同的参数 添加allow_duplicates: true到meta/main.yml文件 # playbook.yml---- hosts:webserversroles:- foo- foo# roles/foo/meta/main.yml---allow_duplicates:true 角色默认变量 Role Default Variables 角色的默认变量允许你为角色设定默认变量。在角色目录中添加defaults/main.yml文件。这些变量具有最低优先级，可以轻易被覆盖。 角色依赖 Role Dependencies 角色依赖让你在其它角色使用角色时自动拉取。角色依赖存储在角色目录的meta/main.yml文件。此文件应包含角色和参数列表在指定角色之前插入： # orles/myapp/meta/main.yml---dependencies:- role:commonvars:come_parameter:3- role:apach","date":"2019-12-26","objectID":"/ansible/:12:2","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"使用变量 Using Variables: https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html Ansible中使用变量可以更好地帮助处理各系统之间的差异。 创建有效的变量名 Creating valid variable names 有效的变量名是很重要的。变量名应该是字母 、数字和下划线，且总是以字母开头。 YAML也支持映射键值对的字典： foo:field1:onefield2:two 你可以使用中括号或点来引用特定字段的值: foo['field1'] foo.field2 请注意，如果使用点来引用，它们属性和Python字典的方法相冲突可能会导致一些问题。如果你使用的键开始和结束有两个下划线，或它们是已知的公共属性，则你应该使用中括号来代替点使用。 # 公共属性 add, append, count, decode... 在清单中定义变量 Defining variables in inventory 通常，你需要为单独的主机或组设置变量。你可以在清单文件(如hosts)中定义所需的变量： west:host1:port:80maxRequest:808 east:hosts:host1:xxhost2:xxxvars:port:80 在playbook中定义变量 Defining variables in a playbook 你可以直接在playbook中定义变量： - hosts:xxxvars:port:80 在文件和角色中定义变量 Defining variables in included files and roles - hosts:xxxroles:- role:testvars:dir:'/opt/a'- role:test2vars:dir:'/opt/b' 在Jinja2中使用变量 Using variables with Jinja2 一旦你定义了变量，便可以在Jinja2的模板系统中引用它： Ma amp goes to {{ max_amp_value }} 使用Jinja2过滤器转换变量 Transforming variables with Jinja2 filters Jinja2 filters 让你在模板表达式内转换变量的值。如capitalize大写过滤器，to_yaml和to_json过滤器来转换成对应格式。 Jinja2包含了许多内置过滤器： https://jinja.palletsprojects.com/en/2.11.x/templates/#builtin-filters Ansible也支持许多过滤器： https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#playbooks-filters YAML疑难杂症 Hey wait, a YAML gotcha YAML语法要求，如果你使用{{ foo }}值引用整行，它要确保你不是想开始一个YAML字典。所以记得使用双引号。 # wrong...vars:path:{{dir }}/22# rightvars:path:\"{{ dir }}/22\" 系统facts中的变量 Variables discovered from systems: Facts facts是从远程系统获得的信息。你可以从ansible_facts变量中找到。 # 查看facts ansible hostname -m setup - debug:var:ansible_facts {{ ansible_facts['devices']['xvda']['model']}} 禁用facts 如果你不需要fact数据，你可以禁用它。 - hosts:xxxgather_facts:no Local facts(facts.d) facts通常都是由Ansible setup模块自动发现。用户也可以编写自定义的facts模块，请参考API指南。但是，如果你想要一个简单的方法来使用用户提供的数据，而不需要写一个facts模块。 facts.d是一种可让用户控制它们的系统是如果管理的某些方面的机制。 如果远程管理系统有/etc/ansible/facts.d目录，该目录中的所有.fact文件（JSON, INI…）。可使用fact_path paly 关键字作为可选目录。 注册变量 Registering variables 另一个主要使用的变量是正在运行一个命令和将此命令的返回的结果注册为一个变量，供其它地方使用。 - hosts:xxxtasks:- shell:/usr/bin/fooregister:foo_resultignore_errors:True- shell:/usr/bin/barwhen:foo_result.rc == 5 访问复杂的变量数据 Accessing complex variable data 有些提供的facts，如网络信息，包含了复杂的嵌套结构。取值会稍微麻烦一些： {{ ansible_facts['eth0']['ipv4']['address']}} # or {{ ansible_facts.eth0.ipv4.address }} # 访问数组的第一个元素 {{ foo[0] }} 使用magic变量访问其它主机的信息 Accessing information about other hosts with magic variables 无论你是否定义变量，你也可以利用特殊的Ansible变量访问有关主机的信息，包括magic, facts, connection变量。magic变量名称被保留，所以不要使用这些名称来设置变量。enviroment变量也同样被保留。 最常使用的魔术变量有：hostvars, groups, group_names, inventory_hostname。 host_vars允许你访问其它主机的变量，包括该主机的facts。你可以在playbook中的任意一点访问主机变量。即使你在playbook中并没有连接到此主机，你仍可以得到变量。 groups是清单中所有组的列表。这可以用于枚举组内的所有主机。 group_names是所有组中当前主机的列表或数组。 inventory_hostname是清单主机文件中配置的主机名。使用inventory_hostname_short获取更简短的信息。 ansible_play_hosts是当前play中仍然活跃的主机列表。 ansible_play_batch是当前批量paly上可用的主机名列表。 ansible_playbook_python是python执行调用ansible命令行工具的路径。 role_path返回当前角色的路径名。这仅在角色里工作。 {{ hostvars['test.example.com']['ansible_facts']['distribution'] }} {% for host in groups['app_servers'] %} {{ hostvars[host]['ansible_facts']['eth0']['ipv4']['address'] }} {% endfor %} {% if 'webserver' in group_names %} # xxx {% endif %} 在文件中定义变量 Defining variables in files 让playbook使用版本控制是很好的想法，但你可能希望让playbook 源公开化，但同时又保证一定的重要的私有变量。 你可以通过一个外部变量文件来这么做： ---- hosts:all...vars:color:bluevars_files:- /vars/external_vars.yml # external_vars.ymluser:xxpassword:xxxx 这消除了分享playbook但避免分享数据的风险。 在命令行上传递参数 Passing variables on the command line 可在命令行上使用--extra-vars参数来设置变量： # k:v格式 ansible-playbook release.yml --extra-vars \"version=1.23.45 other_variable=foo\" # json格式 ansible-playbook arcade.yml --extra-vars '{\"pacman\":\"mrs\",\"ghosts\":[\"inky\",\"pinky\",\"clyde\",\"sue\"]}' # 文件 ansible-playbook release.yml --extra-vars \"@some_file.json\" 变量的优先级：我应该把变量放在哪 Variable precedence: Where should I put a variable? 同一名称的变量如果在多个地方被定义，则它们会以特定的顺序发生覆盖，所需需要知道Ansible变量的优先级，以及它们的放置位置。下面是从小到大的优先级： command line values role defaults inventory file or script group vars inventory group_vars/all","date":"2019-12-26","objectID":"/ansible/:12:3","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"Jinja2模板 Templating (Jinja2): https://docs.ansible.com/ansible/latest/user_guide/playbooks_templating.html Ansible使用Jinja2模板化来实现动态表达式和访问变量。Ansilbe大大扩展的filters和tests数量，以及新增了一个插件类型：lookups。 请注意，所有模板发生在Ansible控制器上，在任务发送和执行在目标主机之前。 Filters Filters: https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html Tests Tests: https://docs.ansible.com/ansible/latest/user_guide/playbooks_tests.html Jinja中的测试是评估模板表达式并返回True或False。许多内置测试: https://jinja.palletsprojects.com/en/2.11.x/templates/#builtin-tests 测试器和过滤器的主要区别是测试用于比较，而过滤去用于数据操作。测试同样可以在列表处理器中使用，如map()和select()在列表中选择项。 与所有模板一样，测试始终在Ansible控制器上执行，而不是任务的目标主机。除了这些Jinja2的测试，Ansible支持用户轻松创建自己的测试。 Lookups Lookups: https://docs.ansible.com/ansible/latest/user_guide/playbooks_lookups.html 查找插件允许访问外部数据源。与所有模板一样，这些插件在Ansible控制器上进行评估，并且可以包括读取文件系统、对外联络网络数据存储和服务。这些数据使用Ansible标准模板系统提供。 注意 查找发生在本地主机，而不是远程主机； 它们在包含role或play的目录内执行，而不是与执行脚本的目录执行本地任务； 可以传递wantlist=True给lookups来使用Jinja2中的for循环； 查找是一个高级的功能，你应该对Ansible有足够的了解。 Python版本和模板 Python Version and Templating: https://docs.ansible.com/ansible/latest/user_guide/playbooks_python_version.html Jinja2模板利用Python数据类型和标准函数。这使得可对数据进行丰富的操作。然而，这也意味着潜在的Python的某些细节对模板编写者可见。由于Ansible playbook使用Jinja2用于模板与变量，这意味着playbook作者需要了解这些细节。 除了这些，请注意在Python2和Python3上运行Ansible的不同。 ","date":"2019-12-26","objectID":"/ansible/:12:4","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"条件语句 Conditionals: https://docs.ansible.com/ansible/latest/user_guide/playbooks_conditionals.html 经常的一个play的结果可能依赖于一个变量的值，或之前的任务的结果。在某些情况下，变量的值可能依赖于其它变量。本主题介绍如何在playbook中使用条件语句。 When语句 The When Statement 有时你会想在某个特定主机上跳过特定的步骤。 在Ansible中使用when子句很容易达到，它不包含Jinja2中的双花括号表达式。它非常简单： tasks:- name:\"shut down CentOS 6 systems\"command:/sbin/shutdown -t nowwhen:- ansible_facts['distribution'] == \"CentOS\"- ansible_facts['distribution_major_version'] == \"6\" 许多Jinja2的测试器和过滤器都可在when子句中使用，其中某些是由Ansible单独提供的。 tasks:- command:/bin/falseregister:resultignore_errors:True- command:/bin/somethingwhen:result is failed# In older versions of ansible use ``success``, now both are valid but succeeded uses the correct tense.- command:/bin/something_elsewhen:result is succeeded- command:/bin/still/something_elsewhen:result is skipped tasks:- shell:echo \"This certainly is epic!\"when:epic or monumental|bool tasks:- shell:echo \"I've got '{{ foo }}' and am not afraid to use it!\"when:foo is defined- fail:msg=\"Bailing out. this play requires 'bar'\"when:bar is undefined 循环和条件 Loops and Conditionals when和loops结合使用，请注意when语句是根据每个项分别处理。 tasks:- command:echo {{ item }}loop:[0,2,4,6,8,10]when:item \u003e 5 在自定义facts中载入 Loading in Custom Facts 如果你想提供自己的facts也很简单。要运行它们，只需要在任务顶部调用你自己定义的模块，这里返回的变量将能访问未来的任务： tasks:- name:gather site specific fact dataaction:site_facts- command:/usr/bin/thingywhen:my_custom_fact_just_retrieved_from_the_remote_system == '1234' Applying when to roles,imports,and includes 在roles, imports, includes中使用when语句： - hosts:webserversroles:- role:debian_stock_configwhen:ansible_facts['os_family'] == 'Debian' 有条件的导入 Conditional Imports 一个剧本适用于多个平台和操作系统是很好的栗子。 ---- hosts:allremote_user:rootvars_files:- \"vars/common.yml\"- [\"vars/{{ ansible_facts['os_family'] }}.yml\",\"vars/os_defaults.yml\"]tasks:- name:make sure apache is startedservice:name={{ apache }} state=started 基于变量来选择文件和模板 Selecting Files And Templates Based On Variables 基于不同的系统来生成不同的配置文件： - name:template a filetemplate:src:\"{{ item }}\"dest:/etc/myapp/foo.confloop:\"{{ query('first_found', { 'files': myfiles, 'paths': mypaths}) }}\"vars:myfiles:- \"{{ansible_facts['distribution']}}.conf\"- default.confmypaths:['search_location_one/somedir/','/opt/other_location/somedir/'] 注册变量 Register Variables 存储一个给定命令的结果，以便后面来访问它，在playbook中可能很有用。 注意： 即使当一个任务由于条件语句跳过，注册也会发生。 register关键字决定将结果保存哪个变量。 - name:check registered variable for emptinesshosts:alltasks:- name:list contents of directorycommand:ls mydirregister:contents- name:check contents for emptinessdebug:msg:\"Directory is empty\"when:contents.stdout == \"\" 常用facts Commonly Used Facts ansible_facts[‘distribution’] ansible_facts[‘distribution_major_version’] ansible_facts[‘os_family’] ","date":"2019-12-26","objectID":"/ansible/:12:5","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"循环 Loops: https://docs.ansible.com/ansible/latest/user_guide/playbooks_loops.html 常见的Ansible循环包括改变多个文件/目录的权限、创建多个用户、重复轮询…Ansible提供了两个关键字来创建循环： loop with_\u003clookup\u003e 注意： We added loop in Ansible 2.5. It is not yet a full replacement for with_\u003clookup\u003e, but we recommend it for most use cases. We have not deprecated the use of with_\u003clookup\u003e We are looking to improve loop syntax 两者比较 Comparing loop and with_* with_\u003clookup\u003e关键字依赖于Lookup插件，即便items也是查找； loop关键字等于with_list，它是简单循环的最佳选择； loop关键字不接受字符串作为输入； 一般来说，任何在Migrating from with_X to loop中使用with_*可以更新为使用loop； 当更改with_items为loop时请小心，with_items执行单级的。你需要在loop中使用flatten(1)。栗子如下： with_items:- 1- [2,3]- 4# you would needloop:\"{{ [1, [2,3] ,4] | flatten(1) }}\" 标准循环 Standard loops 遍历一个简单列表 Iterating over a simple list - name:add several usersuser:name:\"{{ item }}\"state:presentgroups:\"wheel\"loop:- testuser1- testuser2 遍历一个散列列表 Iterating over a list of hashes - name:add several usersuser:name:\"{{ item.name }}\"state:presentgroups:\"{{ item.groups }}\"loop:- {name: 'testuser1', groups:'wheel'}- {name: 'testuser2', groups:'root'} 遍历一个字典 Iterating over a dictionary 使用dict2items字典过滤器来遍历字典： - name:create a tag dictionary of non-empty tagsset_fact:tags_dict:\"{{ (tags_dict|default({}))|combine({item.key: item.value}) }}\"loop:\"{{ tags|dict2items }}\"vars:tags:Environment:devApplication:paymentAnother:\"{{ doesnotexist|default() }}\"when:item.value != \"\" 循环与注册变量 Registering variables with a loop 你可以将循环的输出注册为变量： - shell:\"echo {{ item }}\"loop:- \"one\"- \"two\"register:echo 复杂循环 Complex loops 遍历嵌套的列表 Iterating over nested lists 你可以使用Jinja2的表达式来遍历复杂的列表： - name:give users access to multiple databasesmysql_user:name:\"{{ item[0] }}\"priv:\"{{ item[1] }}.*:ALL\"append_privs:yespassword:\"foo\"loop:\"{{ ['alice', 'bob'] |product(['clientdb', 'employeedb', 'providerdb'])|list }}\" 重试任务直到满足条件 Retrying a task until a condition is met 可以使用until关键字来重试任务直到满足特定条件： - shell:/usr/bin/fooregister:resultuntil:result.stdout.find(\"all systems go\") != -1retries:5delay:10 循环清单 Looping over inventory 遍历资产清单： # show all the hosts in the inventory- debug:msg:\"{{ item }}\"loop:\"{{ groups['all'] }}\"# show all the hosts in the current play- debug:msg:\"{{ item }}\"loop:\"{{ ansible_play_batch }}\"# show all the hosts in the inventory- debug:msg:\"{{ item }}\"loop:\"{{ query('inventory_hostnames', 'all') }}\"# show all the hosts matching the pattern, ie all but the group www- debug:msg:\"{{ item }}\"loop:\"{{ query('inventory_hostnames', 'all:!www') }}\" query与lookup loop关键字需要一个列表作为输入，但是lookup关键字默认返回逗号分隔的值的字符串。 # same thingloop:\"{{ query('inventory_hostnames', 'all') }}\"loop:\"{{ lookup('inventory_hostnames', 'all', wantlist=True) }}\" 循环控制 Adding controls to loops loop_control关键字让你可以以有效的方式管理自己的循环。 限制循环输出 Limiting loop output with label 当遍历复杂的数据结构，你的任务的控制台输出可能是巨大的。为了限制显示的输出，在loop_control中使用label。 # 此任务输出仅显示每项的name字段- name:create serversdigital_ocean:name:\"{{ item.name }}\"state:presentloop:- name:server1disks:3gbram:15Gbnetwork:nic01:100Gbnic02:10Gb...loop_control:label:\"{{ item.name }}\" 暂停循环 Pausing within a loop 要控制每个项的执行之间的时间(seconds)，在loop_control中使用pause。 # main.yml- name:create servers, pause 3s before creating nextdigital_ocean:name:\"{{ item }}\"state:presentloop:- server1- server2loop_control:pause:3 追踪流程 Tracking progress through a loop with index_var 要追踪你在循环的位置，在loop_control中使用index_var。 - name:count our fruitdebug:msg:\"{{ item }} with index {{ my_idx }}\"loop:- apple- banana- pearloop_control:index_var:my_idx inner and outer variable names Defining inner and outer variable names with loop_var 可使用include_tasks嵌套两个循环任务。然而，默认情况下Ansible为每个循环item设置循环变量。This means the inner, nested loop will overwrite the value of item from the outer loop.你可以在loop_control中使用loop_var来为每个循环指定变量名。 - include_tasks:inner.ymlloop:- 1- 2- 3loop_control:loop_var:outer_item# inner.yml- debug:msg:\"outer item={{ outer_item }} inner item={{ item }}\"loop:- a- b- c 扩展的循环变量 Extended loop variables 在循环控制中使用extended选项来获取扩展的循环信息： loop_control:extended:yes Variable Description ansible_loop.allitems T","date":"2019-12-26","objectID":"/ansible/:12:6","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"Block Blocks: https://docs.ansible.com/ansible/latest/user_guide/playbooks_blocks.html 块允许任务的逻辑分组，并在play中错误处理。大多数可以适用于单任务的也可适用于块(block)，这使得它很容易设置数据或常见指令到任务。这并不意味着该指令影响块自身，而是有一个块包围的任务继承。 tasks:- name:Install, configure, and start Apacheblock:- name:install httpd and memcachedyum:name:- httpd- memcachedstate:present- name:apply the foo config templatetemplate:src:templates/src.j2dest:/etc/foo.conf- name:start service bar and enable itservice:name:barstate:startedenabled:Truewhen:ansible_facts['distribution'] == 'CentOS'become:truebecome_user:rootignore_errors:yes 在上面的栗子中，块中3个任务中的每一个附加在when条件后，在任务上下文评估之后都将执行。 块中的任务名在Ansible 2.3时可用。建议在所有任务中使用名称，无论是块还是其它地方。 块错误处理 Blocks error handling 块同样介绍了类似于大多数编程语言的异常处理的错误处理的方法。块仅处理任务的失败(failed)状态。一个糟糕的任务定义或主机不可达不是rescuable错误。 # block error handling exampletasks:- name:Handle the errorblock:- debug:msg:'I execute normally'- name:i force a failurecommand:/bin/false- debug:msg:'I never execute, due to the above task failing, :-('rescue:- debug:msg:'I caught an error, can do stuff here to fix it, :-)' always部分，无论什么任务状态都将会运行。 - name:Always do Xblock:- debug:msg:'I execute normally'- name:i force a failurecommand:/bin/false- debug:msg:'I never execute :-('always:- debug:msg:\"This always executes, :-)\" ","date":"2019-12-26","objectID":"/ansible/:12:7","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"高级的playbook功能 Advanced Playbooks Features: https://docs.ansible.com/ansible/latest/user_guide/playbooks_special_topics.html 下面有许多playbook功能不需要每个人都去学习，但可以为特定应用提供有用的功能。浏览这些话题，因为你可能找有一些有用的技巧。 特权晋升 异步操作和轮询 Asynchronous Actions and Polling: https://docs.ansible.com/ansible/latest/user_guide/playbooks_async.html 默认情况下，playbook块中的任务，直到任务在每个节点上完成后连接才会断开。这可能不总是可取的，或者你需要运行超过ssh timeout的操作。 限时后台操作(Time-limited background operations) 你可以在后台运行长时间运行的操作，之后再检查它们的状态。例如，异步地在后台执行long_running_operation： # -B 超时时间， -p 轮询数 ansible all -B 3600 -P 0 -a \"/usr/bin/long_running_operation --do-stuff\" # async_status模块 检查状态 ansible web1.example.com -m async_status -a \"jid=488359678239.2844\" 轮询模式是智能的，所以在轮询将在任意机器上开始之前所有的工作都将启动。如果想要所有工作快速开始，请确保使用足够高的--forks。在超时之后，远程节点上的进程将会被终止。 通常，你只需在后台长时间运行shell命令或软件更新。后台复制模块不会进行文件传输。 为了避免阻塞或超时问题，你可以使用异步模式来一次运行你的所有任务，并轮询直到它们完成。 异步模式的行为依赖于poll值。 Avoid connection timeouts: poll \u003e 0 当poll是正值，playbook仍然会阻塞任务直到它完成、失败或超时。 要异步启动任务，请指定其最大运行实践和要轮询状态的频率。如果未指定poll，则默认由DEFAULT_POLL_INTERVAL设置。 ---- hosts:allremote_user:roottasks:- name:simulate long running op (15 sec), wait for up to 45 sec, poll every 5 seccommand:/bin/sleep 15async:45poll:5 Concurrent tasks: poll=0 当poll为0时，Ansible将启动任务，并立即移动到下一个而不必等待结果。 从序列试图这点是异步编程：任务现在可以同时运行。playbook将结束而不检查异步返回。异步任务将执行根据async的值，直到它们完成、失败或超时。 ---- hosts:allremote_user:roottasks:- name:simulate long running op, allow to run for 45 sec, fire and forgetcommand:/bin/sleep 15async:45poll:0 检查模式 Check Mode: https://docs.ansible.com/ansible/latest/user_guide/playbooks_checkmode.html Debugger Playbook Debugger Ansible包含了debugger作为策略插件的一部分。此调试器允许你调试任务。你可以在任务的上下文中访问所有的调试器的功能，以帮助解决失败的问题。 有多种方式来调用调试器。 使用debugger关键字(Using the debugger keyword) 可在提供name属性的块中使用debugger关键字，如paly, role, block, task。debugger关键字接受下列值： always: 总是调用调试器 never: 绝不调用调试器 on_failed: 任务失败才调用调试器 on_skipped: 任务跳过才调用调试器 全局配置： # on a task- name:execute a commandcommand:falsedebugger:on_failed # on a play- name:playhosts:alldebugger:on_skippedtasks:- name:Execute a commandcommand:truewhen:False 在特定层级上： - name:Playhosts:alldebugger:nevertasks:- name:Execute a commandcommand:falsedebugger:on_failed 配置或环境变量(Configuration or environment variable) # ansible.cfg [defaults] enable_task_debugger = True # environment variable ANSIBLE_ENABLE_TASK_DEBUGGER=True ansible-playbook -i hosts site.yml 策略(As a Strategy) 要使用debug策略，改变strategy属性： - hosts:teststrategy:debugtasks:... # ansible.cfg [defaults] strategy = debug # environment variable ANSIBLE_STRATEGY=debug 可用命令(Available Commands) 打印值： [192.0.2.10] TASK: install package (debug)\u003e p task TASK: install package [192.0.2.10] TASK: install package (debug)\u003e p task.args {u'name': u'{{ pkg_name }}'} [192.0.2.10] TASK: install package (debug)\u003e p task_vars {u'ansible_all_ipv4_addresses': [u'192.0.2.10'], u'ansible_architecture': u'x86_64', ... } [192.0.2.10] TASK: install package (debug)\u003e p task_vars['pkg_name'] u'bash' [192.0.2.10] TASK: install package (debug)\u003e p host 192.0.2.10 [192.0.2.10] TASK: install package (debug)\u003e p result._result {'_ansible_no_log': False, 'changed': False, u'failed': True, ... u'msg': u\"No package matching 'not_exist' is available\"} 滚动升级 Delegation, Rolling Updates, and Local Actions: https://docs.ansible.com/ansible/latest/user_guide/playbooks_delegation.html 设置环境 Setting the Environment: https://docs.ansible.com/ansible/latest/user_guide/playbooks_environment.html environment关键字可以允许你为远程目标主机设置环境变量。例如，需要为http请求设置一个代理。获取其它工具需要的环境变量。 - hosts:allremote_user:roottasks:- name:Install cobblerpackage:name:cobblerstate:presentenvironment:http_proxy:http://proxy.example.com:8080 也可以存储在一个变量里： - hosts:allremote_user:root# here we make a variable named \"proxy_env\" that is a dictionaryvars:proxy_env:http_proxy:http://proxy.example.com:8080tasks:- name:Install cobblerpackage:name:cobblerstate:presentenvironment:\"{{ proxy_env }}\" 特定语言版本管理器 Working With Language-Specific Version Managers 一些特定语言版本管理器(如nvm)要求，而这些工具在使用中都要求环境变量。挡手动使用这些工具，通常需要在配置文件中添加一些环境变量，在Ansible中，你可使用enviroment代替： --- ### A playbook de","date":"2019-12-26","objectID":"/ansible/:12:8","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"控制playbook执行 Controlling playbook execution: strategies and more: https://docs.ansible.com/ansible/latest/user_guide/playbooks_strategies.html 默认情况下，Ansible在使用5forks任意主机上开始下一个任务之前在所有被play影响的主机上运行每个任务。如果你想要改变此默认的行为，你可以使用不同的策略插件，改变fork数，或应用几个play级别的关键字（如serial）。 选择策略 Selecting a strategy linear strategy: https://docs.ansible.com/ansible/latest/plugins/strategy/linear.html#linear-strategy debug strategy: https://docs.ansible.com/ansible/latest/plugins/strategy/debug.html#debug-strategy free strategy: https://docs.ansible.com/ansible/latest/plugins/strategy/free.html#free-strategy - hosts:allstrategy:freetasks:... 设置fork数 Setting the number of forks # ansible.cfg [defaults] forks = 30 # or cli ansible-playbook -f 30 my_playbook.ym 使用关键字控制执行 Using keywords to control execution play level的关键字会影响paly的执行。 最常见的是serial，还有throttle, ignore_errors, ignore_unreachable, any_errors_fatal。 ","date":"2019-12-26","objectID":"/ansible/:12:9","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"最佳实践 Best Practices: https://docs.ansible.com/ansible/latest/user_guide/playbooks_best_practices.html 使用Ansible和playbooks的一些技巧。 你可以在ansible-examples仓库中找到最佳用法。 内容组织 Content Organization 下面将介绍组织Playbook内容的多种方式。你的ansible的使用应该适合你的需求，因此你可以按需组合各种方法。 组织ansible playbook内容的一个关键方式是role。你应该理解它。 目录布局 Directory Layout 栗子： staging # inventory file for staging environmentgroup_vars/group1.yml # here we assign variables to particular groupsgroup2.ymlhost_vars/hostname1.yml # here we assign variables to particular systemshostname2.ymllibrary/ # if any custom modules, put them here (optional)module_utils/ # if any custom module_utils to support modules, put them here (optional)filter_plugins/ # if any custom filter plugins, put them here (optional)site.yml # master playbookwebservers.yml # playbook for webserver tierdbservers.yml # playbook for dbserver tierroles/common/ # this hierarchy represents a \"role\"tasks/ #main.yml # \u003c-- tasks file can include smaller files if warrantedhandlers/ #main.yml # \u003c-- handlers filetemplates/ # \u003c-- files for use with the template resourcentp.conf.j2 # \u003c------- templates end in .j2files/ #bar.txt # \u003c-- files for use with the copy resourcefoo.sh # \u003c-- script files for use with the script resourcevars/ #main.yml # \u003c-- variables associated with this roledefaults/ #main.yml # \u003c-- default lower priority variables for this rolemeta/ #main.yml # \u003c-- role dependencieslibrary/ # roles can also include custom modulesmodule_utils/ # roles can also include custom module_utilslookup_plugins/ # or other types of plugins, like lookup in this casewebtier/ # same kind of structure as \"common\" was above, done for the webtier rolemonitoring/ # \"\"fooapp/ # \"\" 可选的目录布局 Alternative Directory Layout 此布局为大型环境提供了更多灵活性，栗子： inventories/production/hosts # inventory file for production serversgroup_vars/group1.yml # here we assign variables to particular groupsgroup2.ymlhost_vars/hostname1.yml # here we assign variables to particular systemshostname2.ymlstaging/hosts # inventory file for staging environmentgroup_vars/group1.yml # here we assign variables to particular groupsgroup2.ymlhost_vars/stagehost1.yml # here we assign variables to particular systemsstagehost2.ymllibrary/module_utils/filter_plugins/site.ymlwebservers.ymldbservers.ymlroles/common/webtier/monitoring/fooapp/ 使用云动态资产 Use Dynamic Inventory With Clouds 如果你使用云服务提供商，你不应该在静态文件中管理你的资产。请参考Working with dynamic inventory 如何区分测试与生产 How to Differentiate Staging vs Production 如果管理静态清单，经常会问到如何区分不同类型的环境。下面的例子提供了一个好方法。分组的类似方法可以适用动态清单。 # file: production [atlanta_webservers] www-atl-1.example.com www-atl-2.example.com [boston_webservers] www-bos-1.example.com www-bos-2.example.com [atlanta_dbservers] db-atl-1.example.com db-atl-2.example.com [boston_dbservers] db-bos-1.example.com # webservers in all geos [webservers:children] atlanta_webservers boston_webservers # dbservers in all geos [dbservers:children] atlanta_dbservers boston_dbservers # everything in the atlanta geo [atlanta:children] atlanta_webservers atlanta_dbservers # everything in the boston geo [boston:children] boston_webservers boston_dbservers 组和主机变量 Group And Host Variables ---# file: group_vars/atlantantp:ntp-atlanta.example.combackup:backup-atlanta.example.com ---# file: group_vars/webserversapacheMaxRequestsPerChild:3000apacheMaxClients:900 ---# file: group_vars/allntp:ntp-boston.example.combackup:backup-boston.example.com 顶级playbook通过角色分离 Top Level Playbooks Are Separated By Role ---# file: site.yml- import_playbook:webservers.yml- import_playbook:dbservers.yml ---# file: webservers.yml- hosts:webserversroles:- common- webtier 这里，我们可以选择运行site.yml来配置我们的整个基础架构，或者通过运行webservers.yml来只运行一个子集。类似于下面： ansible-playbook site.yml --limit webserversansible-playbook webservers.yml 角色的任务和处理程序组织 Task And Handler Organization For A Role 下面解释一个NTP任务是如何工作： # file: roles/common/tasks/main.yml- name:be sure ntp is installedyum:name:ntpstate:presenttags:ntp- name:be sure ntp is configuredtemplate:src:ntp.conf.j2dest:/etc/ntp.confnotify:-","date":"2019-12-26","objectID":"/ansible/:12:10","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"持续交付和滚动更新 Playbook Example: Continuous Delivery and Rolling Upgrades: https://docs.ansible.com/ansible/latest/user_guide/guide_rolling_upgrade.html 什么是持续交付 What is continuous delivery Continuous delivery(CD)是指经常更新你的软件应用程序。 ","date":"2019-12-26","objectID":"/ansible/:12:11","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"特权晋升 Understanding privilege escalation: become: https://docs.ansible.com/ansible/latest/user_guide/become.html Ansible使用现有的权限升级系统来执行具有root或其它权限的任务。此功能允许你成为(become)其它用户，与登录到远程机器不同，我们称之为become。become关键字利用现有的权限提升工具（如sudo, su, pfexec, doas, pbrun, dzdo, ksu, runas）。 ","date":"2019-12-26","objectID":"/ansible/:13:0","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"使用 你可以在任务、连接变量、命令行等控制become的使用。如果你以多种方式设置了特权提升，请注意优先级。 所有become plugins完整的列表: https://docs.ansible.com/ansible/latest/plugins/become.html#become-plugin-list become 你可在play或task层设置become指令。你可以设置连接变量，从不同主机之间覆盖它们。 # 激活特权提升become:yes# 默认rootbecome_user:xxx# 参考become plugins，可在ansible.cfg中配置。默认sudobecome_method:sudo# 为role或task执行特定标志become_flags:xxx 栗子： - name: Ensure the httpd is running become: yes service: name: httpd state: started - name: Run a command as the apache user command: somecommand become: yes become_user: apache - name: Run a command as nobody command: somecommand become: yes become_method: su become_user: nobody become_flags: '-s /bin/sh' 连接变量 Become connection variables 你可以定义不同的选型来管理node或group。你可以在资产中定义这些变量，或将其作为正常的变量使用。 ansible_become ansible_become_method ansible_become_user ansible_become_password # 栗子 webserver ansible_user=manager ansible_become=yes 命令行选项 --ask-become-pass, -K --become, -b --become-method=BECOME_METHOD --become-user=BECOME_USER ","date":"2019-12-26","objectID":"/ansible/:13:1","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"风险和局限性 Risks and limitations of become 虽然权限提升是很直观的，但它如何工作也有一些限制。用户应该知道这些，以避免意外。 成为一个非特权用户的风险 Risks of becoming an unprivileged user Ansible模块由第一个参数带入模块文件，然后将其复制到远程主机，最后在远程机器上执行它。 如果模块文件不使用become，当become_ueer为root时，或当远程机器被设置为root时，一切都好。在这些情况下，Ansible创建具有只允许由所述用户和root读取，或只允许由所述非特权用户切换到读取权限模块文件。 然而，当连接用户和become_user都不是特权用户，模块文件被写入需要由Ansible设置为用户可读。在这种情况下，Ansible使得模块文件世界可读的Ansible模块执行的持续时间。一旦模块执行完毕，Ansible删除临时文件。 不是所有连接插件都支持 Not supported by all connection plugins 特权升级方法也必须由连接使用的插件支持。 每个主机只能启用一个方法 Only one method may be enabled per host 特权提升必须通用 Privilege escalation must be general 你不能限制权限提升某些命令的权限。 ","date":"2019-12-26","objectID":"/ansible/:13:2","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"Vault Ansible Vault: https://docs.ansible.com/ansible/latest/user_guide/vault.html Ansible Vault是Ansible的一个功能，可以让你在加密的文件中保存敏感数据（如密码、密钥），而不是像普通文本或playbooks或roles中。这些vault文件可以分布或放置在版本控制中。 要启用此功能，使用命令行选型-ansible-vault，和--vault-password-file。 ","date":"2019-12-26","objectID":"/ansible/:14:0","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"Modules Ansible Modules: https://docs.ansible.com/ansible/latest/user_guide/modules.html Ansible包含了大量的模块(module library)，可以直接在远程主机或通过playbook执行。 用户也可以编写自己的模块。这些模块可以控制系统资源（服务、包、文件…），或执行系统命令。 ","date":"2019-12-26","objectID":"/ansible/:15:0","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"模块介绍 Introduction to modules: https://docs.ansible.com/ansible/latest/user_guide/modules_intro.html # adhoc ansible webservers -m service -a \"name=httpd state=started\" # playbook- name:restart webserverservice:name:httpdstate:restarted ","date":"2019-12-26","objectID":"/ansible/:15:1","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"返回值 Return Values: https://docs.ansible.com/ansible/latest/reference_appendices/common_return_values.html Ansible模块通常正常返回一个可以注册为一个变量的数据结构，或直接看到由ansible程序输出。每个模块都可选的记录自己唯一的返回值。 本章节包含的返回值适用于所有模块。 Common backup_file changed failed invocation msg rc results skipped stderr stderr_lines stdout stdout_lines Internal use ansible_facts exception warning deprecations ","date":"2019-12-26","objectID":"/ansible/:15:2","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"模块索引 Module Index: https://docs.ansible.com/ansible/latest/modules/modules_by_category.html ","date":"2019-12-26","objectID":"/ansible/:15:3","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"插件 Working With Plugins: https://docs.ansible.com/ansible/latest/plugins/plugins.html 插件是一段代码，可以扩充Ansible的核心功能。Ansible使用插件架构，以实现丰富的、灵活的、可扩展的功能集。 Ansible附带了一些方便的插件，你也可以很容易地编写自己的插件。 ","date":"2019-12-26","objectID":"/ansible/:16:0","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["DevOps"],"content":"collections collections: https://docs.ansible.com/ansible/latest/user_guide/collections_using.html Collections是Ansible的内容分发格式，可以包括playbooks, roles, modules, plugins。你可以通过Ansible Galaxy安装和使用collections。 开发指南 Developer Guide: https://docs.ansible.com/ansible/latest/dev_guide/index.html Ansible Galaxy Ansible Galaxy: https://docs.ansible.com/ansible/latest/galaxy/user_guide.html Ansible Galaxy是一个查找、分享、下载社区开发的roles的网站。 ","date":"2019-12-26","objectID":"/ansible/:17:0","tags":["Ansible","Automation","DevOps"],"title":"Ansible","uri":"/ansible/"},{"categories":["backend"],"content":"环境: Tornado: v5.1 Python: v3.6 参考: Docs: https://www.tornadoweb.org/en/branch5.1/ \r\r \r\r用户指南 \r","date":"2019-10-14","objectID":"/tornado/:0:0","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"介绍 Tornado是一个Python Web框架和异步(asynchronous)网络库。通过使用非阻塞(non-blocking)网络I/O，Tornado可以扩展到上万个连接，因此非常适合长轮询(long polling)、WebSocket需要长期连接到的每个用户的应用程序。 Tornado大致可以分为四个主要组件: Web框架：包含RequestHandler，它的子类用于创建web应用，并支持各种类。 HTTP的Client和Server的实现：HTTPServer和AsyncHTTPClient。 异步网络库(IOLoop和IOStream)，用于HTTP组件的构建块，并且还可实现其它协议。 协程库(tornado.gen)，允许异步代码写的更直接而不用链式回调(chaining callbacks)的方式。 Tornado web框架和HTTP server一起为WSGI提供了一个全栈(full-stack)式选择。为了充分利用Tornado的特性，你需要一起使用Tornado Web框架和HTTP Server。 \r\r\r","date":"2019-10-14","objectID":"/tornado/:1:0","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"异步和非阻塞I/O 实时(real-time) Web功能需要为每个用户提供一个长时间空闲(mostly-idle)的长连接。在传统的同步(synchronous) web server，这意味着为每个用户提供一个线程(thread)，这是非常昂贵的。 要尽可能减少并发连接(concurrent connections)的开销，Tornado使用一个单线程事件循环。这意味着所有应用程序代码都应该是异步非阻塞的，因为在同一时间只有一个操作是活跃的。 异步和非阻塞这两个术语是非常相关的，并经常交换使用，但它们不是完全相同的事情。 \r","date":"2019-10-14","objectID":"/tornado/:2:0","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"阻塞 一个函数在等待某些事情的返回的时候会被阻塞(block)。函数阻塞的原因有很多，如：网络IO、磁盘IO、互斥锁…事实上，每个函数在运行和使用CPU的时候或多或少会被阻塞。 一个函数可以在某些方面阻塞，在另外一些方面不阻塞。在Tornado下，我们通常讨论网络IO阻塞，尽管各种阻塞也被最小化。 \r\r","date":"2019-10-14","objectID":"/tornado/:2:1","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"异步 异步(asynchronous)函数在完成之前返回，在应用中触发下一个动作之前通常会在后台执行一些工作（和正常的同步函数在返回之前就执行完所有的事情不同）。这里列举了几种风格的异步接口： 回调参数 返回一个占位符 传送给一个队列 回调注册表 \r\r","date":"2019-10-14","objectID":"/tornado/:2:2","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"栗子 一个同步(synchronous)函数的栗子: from tornado.httpclient import HTTPClient def synchronous_fetch(url): http_client = HTTPClient() response = http_client.fetch(url) return response.body 一个异步(asynchronous)重写的函数: from tornado.httpclient import AsyncHTTPClient async def asynchronous_fetch(url): http_client = AsyncHTTPClient() response = await http_client.fetch(url) return response.body 协程(coroutines)有点不可思议，但它们在内如是这样的: from tornado.concurrent import Future def async_fetch_manual(url): http_client = AsyncHTTPClient() my_future = Future() fetch_future = http_client.fetch(url) def on_fetch(f): my_future.set_result(f.result().body) fetch_future.add_done_callback(on_fetch) return my_future 任何可用协程做的都可传递到回调(callback)对象周围，但协程提供了一个重要的简化让你以相同的方式组织你的代码。这对于错误处理(error handling)尤其重要，在协程预期的tyr/except块工作，这是难以实现的回调。 在Tornado中，协程(Coroutines)是推荐的编写异步代码的方式。协程使用Python的await或yield关键字来暂停(suspend)和恢复(resume)来代替回调链。 协程几乎与同步(synchronous)代码一样简单，但不带线程(thread)的开销。它们使得并发(concurrency)更简单。 栗子: async def fetch_coroutine(url): http_client = AsyncHTTPClient() response = await http_client.fetch(url) return response.body ","date":"2019-10-14","objectID":"/tornado/:2:3","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"原生与装饰的协程 Native vs decorated coroutines Python 3.5介绍了async和await关键字。 只要可能，原生协程是推荐的形式。仅需要与旧版本的Python兼容时使用装饰的协程。Tornado文档中一般会使用原生形式。 这两种形式之间的转换一般是简单的: # Decorated # Normal function declaration # with decorator @gen.coroutine def a(): # 'yield' all async funcs b = yield c() # 'return' and 'yield' # cannot be mixed in # Python 2, so raise a # special execption raise gen.Return(b) # Native # 'async def' keywords async def a(): # 'await' all async funcs b = await c() # return normally return b 两种协程形式的不同: 原生协程通常更快 原生协程可以使用async for和async with语句，这使得一些模式更简单 除非await和yield它们，原生协程不会运行所有。装饰的协程一经调用就运行在后台(background)。请注意，这两种协程使用await或yield都很重要，以便任何异常都有地方可去 装饰的协程有与concurrent.futures包额外的集成，允许直接yielded executor.submit的结果。对于原生协程，使用IOLoop.run_in_executor代替 通过生成一个列表或字典，装饰的协程支持一些速记。在原生协程中使用tornado.gen.multi 装饰的协程可以支持与其它软件包的整合。要在原生协程中访问此功能，使用tornado.gen.convert_yielded 装饰的协程总是返回一个Future对象。原生协程返回一个awaitable对象 ","date":"2019-10-14","objectID":"/tornado/:2:4","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"如何工作 本节介绍装饰的协程的操作。原生协程在概念上相似，但多了几分复杂。因为与Python runtime额外集成。 包含yield的函数是一个生成器(generator)。所有的生成器都是异步的，调用它们时返回一个生成器对象，而不是运行到完成。@gen.coroutine装饰器(decorator)通过yield表达式与生成器进行通信，通过协程调用返回一个Future。 一个协程装饰器的内循环的简单栗子: # Simplified inner loop of tornado.gen.Runner def run(self): # send(x) makes the current yield return x # It returns when the next yield is reached future = self.gen.send(self.next) def callback(f): self.next = f.result() self.run() future.add_done_callback(callback) 装饰器从生成器接收一个Future，等待(不会阻塞)选择那些完成的Future，解包Future并将结果发送回生成器的yield表达式。大多数异步代码不直接接触Future类，除了由一个异步函数立即传递Future到yield表达式。 ","date":"2019-10-14","objectID":"/tornado/:2:5","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"如何调用协程 协程在正常方式下不抛出异常：它们抛出的任何异常都将在awaitable对象直到它被yielded。这意味着以正确的方式调用协程是重要的，或者可能有被你忽略的错误。 async def divide(x, y): return x / y def bad_call(): # This should raise a ZeroDivisionError, but it won't because # the coroutine is called incorrectly. divide(1, 0) 在几乎所有情况下，调用协程的任何函数都必须是一个协程本身，并在调用中使用await和yield关键字。当你重写superclass中定义的方法时，查看文档看协程是否被允许。 async def good_call(): # await will unwrap the object returned by divide() and raise the exception. await divide(1, 0) 有时，你可能想fire and forget协程，而无需等待其结果。在这种情况下，推荐使用IOLoop.spawn_callback，这使得IOLoop负责调用。如果失败，IOLoop将记录stack trace。 # The IOLoop will catch the exception and print a stack trace in the logs. # Note that this doesn't look like a normal call, since we pass the function object to be called by the IOLoop. IOLoop.current().spawn_callback(divide, 1, 0) 函数使用@gen.coroutin在这种方式下建议使用IOLoop.spawn_callback，但它需要函数使用async def。 最后，在程序的顶层，如果IOLoop尚未运行，就可以启动IOLoop，运行协程，然后用IOLoop.run_sync方法停止IOLoop。这经常用来启动一个面向批处理程序的main()函数。 # run_sync() doesn't take arguments, so we must wrap the call in lambda. IOLoop.current().run_sync(lambda: divide(1, 0)) ","date":"2019-10-14","objectID":"/tornado/:2:6","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"协程模式 Coroutine patterns 调用阻塞函数 Calling blocking functions 从协程调用阻塞函数最简单的方式是使用IOLoop.run_in_executor，它返回与协程兼容的Future: async def call_blocking(): await IOLoop.current().run_in_executor(None, blocking_func, args) Parallelism multi函数接收列表和字典，其值是Futures，并等待所有并行(parallel)的Futures: from tornado.gen import multi async def paraller_fetch(url1, url2): resp1, resp2 = await multi([http_client.fetch(url1), http_client.fetch(url2)]) async def paraller_fetch_many(urls): responses = await multi (http_client.fetch(url) for url in urls) # responses is a list of HTTPResponses in the same order async def parallel_fetch_dict(urls): responses = await multi({url: http_client.fetch(url) for url in urls}) # responses is a dict {url: HTTPResponse} 在装饰的协程，可yield列表或字典: @gen.coroutine def aprallel_fetch_decorated(url1, url2): resp1, resp2 = yield [http_client.fetch(url1), http_client.fetch(url2)] Interleaving 有时保存Future是有用的而不立即yielding，因此你可以在等待之前启动其它操作。 from tornado.gen import convert_yielded async def get(self): # convert_yielded() starts the native coroutine in the background. # This is equivalent to asyncio.ensure_future() (both work in Tornado). fetch_future = convert_yielded(self.fetch_next_chunk()) while True: chunk = yield fetch_future if chunk is None: break self.write(chunk) fetch_future = convert_yielded(self.fetch_next_chunk()) yield self.flush() 这是一个比较容易做装饰的协程，因为它们在调用时立即启动: @gen.coroutine def get(self): fetch_future = self.fetch_next_chunk() if chunk is None: break self.write(chunk) fetch_future = self.fetch_next_chunk() yiield self.flush() Looping 在原生协程，可使用async for。在不同版本的Python中，looping is tricky with coroutines，因为没有办法获得对for或while循环的每次迭代结果的yield。你需要从访问结果分隔循环条件。 import motor db = motor.MotorClient().test @gen.coroutine def loop_example(collection): cursor = db.collection.find() while (yield cursor.fetch_next): doc = cursor.netx_object() 在后台运行 Running in the background PeriodicCallback通常不与协程使用。相反，协程可以包含While True:循环并使用tornado.gen.sleep: async def minute_loop(): while True: await do_something() await gen.sleep(60) # Coroutines that loop forever are generally started with spawn_callback(). IOLoop.current().spawn_callback(minute_loop) 有时，一个更复杂的循环可能是可取的。例如，前一个循环每60+N秒运行，N是do_something的运行时间。要准确每60秒运行，使用上面的interleaving模式: async def minute_loop2() while True: nxt = gen.sleep(60) # Start the clock. await do_something() # Run while the clock is ticking. await nxt # Wait for the timer to run out. ","date":"2019-10-14","objectID":"/tornado/:2:7","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"Queue Queue example - a concurrent web spider Tornado的tornado.queues模块实现了协程异步 生产者(producer)/消费者(consumer)模式，类似于由Python标准库的queue模块为线程(thread)实现的模式。 yields Queue.get协程暂停直到队列中有项。如果队列设置了最大大小集(yield Queue.put)协程暂停，直到有另一个项。 Queue维护未完成的任务计数，从0开始。put递增计数，task_done递减它。 web-spider栗子，队列开始仅包含base_url。当worker获取它解析的链接和队列放出新的页面，然后调用task_done递减计数。最终，worker取出其url没有过的页面，也没有留在队列中工作。因此，worker调用task_done递减计数器归零。主协程，它等待join，取消暂停和完成。 import time from datatime import timedelta from html.parser import HTMLParser from ulllib.parse import urljoin, urldefrag from tornado import gen, httpclient, ioloop, queues base_url = 'http://www.tornadoweb.org/en/stable/' concurrency = 10 async def get_links_from_url(url): \"\"\"Download the page at `url` and parse it for links. Returned links have had the fragment after `#` removed, and have been made bsolute so, e.g. the URL 'gen.html#tornado.gen.coroutine' becomes 'http://www.tornadoweb.org/en/stable/gen.html'. \"\"\" response = await httpclient.AsyncHTTPClient().fetch(url) print('fetched %s' % url) html = response.body.decode('errors='ignore') return [urljoin(url, remove_fragment(new_url)) for new_url in get_links(html)] def remove_fragment(url): pure_url, frag = urldefrag(url) return pure_url def get_links(html): class URLSeeker(HTMLParser): def __init__(self): HTMLParser.__init__(self) self.urls = [] sef handle_starttag(self, tag, attrs): href = dict(attrs).get('href') if href and tag == 'a': self.urls.append(href) url_seeker = URLSeeker() url_seeker.feed(html) return url_seeker.urls async def main(): q = queues.Queue() start = time.time() fetching, fetched = set(), set() async def fetch_url(currrent_url): if current_url in fetching: return print('fetching %s' % current_url) fetching.add(current_url) urls = await get_links_from_url(current_url) fetched.add(current_url) for new_url in urls: # Only follow links beneath the base URL if new_url.startswith(base_url): await q.put(new_url) async def worker(): async for url in q: if url in None: return try: await fetch_url(url) except Exception as e: print('Exception: %s%s' % (e, url)) finally: q.task_done() await q.put(base_url) # Start workers, then wait for the work queue to be empty. workers = gen.multi([worker() for _ in range(concurrency)]) await q.join(timeout=timedelta(seconds=300)) assert fetching == fetched print('Done in %dseconds, fetched %sURLs.' % ( time.time() - start, len(fetched))) # Signal all the workers to exit. for _ in range(concurrency): await q.put(None) await workers if __name__ == '__main__': io_loop = ioloop.IOLoop.current() io_loop.run_sync(main) ","date":"2019-10-14","objectID":"/tornado/:3:0","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"Tornado web程序结构 Structure of a Tornado web application 一个Tornado web程序通常由一个或多个RequestHandler子类组成，Application对象是哪些路由进入的请求的处理程序(handler)，main()函数来启动server。 一个最小化的hello world栗子: import tornado.ioloop import tornado.web class MainHandler(tornado.web.RequestHandler): def get(self): self.write(\"Hello, world\") def make_app(): return tornado.web.Application([ (r\"/\", MainHandler), ]) if __name__ == \"__main__\": app = make_app() app.listen(8888) tornado.ioloop.IOLoop.current().start() ","date":"2019-10-14","objectID":"/tornado/:4:0","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"Application对象 Application对象是负责全局配置，包括映射请求到处理程序(handler)的路由表。 路由表是URLSpec对象的列表(或元组)，其中每一个包含(至少)一个正则表达式和一个处理类(handler class)。顺序匹配，第一匹配规则被使用。如果正则表达式中包含捕获组，这些组的路径参数将被传递给处理程序(handler)的HTTP方法。如果字典作为URLSpec的第三个参数传递，它提供将初始化参数传递给RequestHandler.initialize。最后，URLSpec可以有一个名称，这将允许它与RequestHandler.reverse_url使用。 栗子: # / URL 映射到 MainHandler # /story/后跟数字 映射到 StoryHandler，数字(作为字符串)被传递给StoryHandler.get class MainHandler(RequestHandler): def get(self): self.write('\u003ca href=\"%s\"\u003e link to story 1\u003c/a\u003e' % self.reverse_url(\"story\", \"1\")) class StoryHandler(RequestHandler): def initialize(self, db): self.db = db def get(self, story_id): self.write(\"this is story %s\" % story_id) app = Application([ url(r\"/\", MainHandler), url(r\"/story/([0-9]+)\", StoryHandler, dict(db=db), name=\"story\") ]) Application构造器采用许多关键字参数，可用于定制应用程序的行为和启用可选功能。查看Application.settings获取完整列表。 ","date":"2019-10-14","objectID":"/tornado/:4:1","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"RequestHandler子类 Subclassing RequestHandler 大部分Tornado Web应用程序的工作是RequestHandler子类完成的。主入口点的处理程序子类(handler subclass)是正在处理的HTTP方法(get(), post())的方法命名。例如，每个handler可以定义这些方法中的一种或多种，以处理不同的HTTP动作。如上所述，这些方法将于对应于匹配的路由规则的捕获组参数来调用。 在处理程序内部，调用如RequestHandler.render或RequestHandler.write来产生响应(response)。render()通过名称加载一个模板，并与给定的参数来渲染它。write()被用于非基于模板(non-template-based)输出。它接受字符串，字节和字典(字典被编码为json)。 ReqestHandler中的许多方法都设计在子类中重写(overridden)，并在整个application中使用。这是常见的定义BaseHandler类，覆盖方法如write_error, get_current_user，并为你所有指定的handler继承BaseHandler而不是RequestHandler。 ","date":"2019-10-14","objectID":"/tornado/:4:2","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"处理请求输入 Handling request input request handler可以访问表示与self.quest获取当前请求的对象。查看HTTPServerRequest类来获取完整的列表。 通过HTML表单中使用的格式请求的数据将为你解析，并在如get_query_argument和get_body_argument方法中可用。 class MyFormHandler(tornado.web.RequestHandler): def get(self): self.write('\u003chtml\u003e\u003cbody\u003e\u003cform action=\"/myform\" method=\"POST\"\u003e' '\u003cinput type=\"text\" name=\"message\"\u003e' '\u003cinput type=\"submit\" value=\"Submit\"\u003e' '\u003c/form\u003e\u003c/body\u003e\u003c/html\u003e') def post(self): self.set_header(\"Conten-Type\", \"text/plain\") self.write(\"You wrote\" + self.get_body_argument) 由于HTML表单的编码是模糊的，以元素中的一个参数是否为单一值(single value)或一个列表，RequestHandler有独特的方法，以允许application表明它是否期望一个列表。对于列表，使用get_query_arguments和get_body_arguments来代替它们的singular counterparts。 通过表单上传的文件在self.request.files可用，它映射名称(html input type=\"file\"元素)到一个文件列表。每个文件是{\"filename\":..., \"content_type\":..., \"body\":...}格式的字典。files对象仅表示文件是否以一种form wrapper上传(如multipart/form-data 内容类型)。如果不使用这种格式，原始上传数据在self.request.body可用。默认情况下上传的文件在内存中完全缓冲(fully buffered)。如果你要处理的文件太大，但想在内存中舒适保存，可参考stream_request_body类装饰器。 由于HTML格式编码的怪癖，Tornado并不试图统一参数和其它输入类型的形式。特别是，我们不解析JSON请求主体。Applicaton希望使用JSON而不是form-encoding可以覆盖prepare来解析它们的请求: def prepare(self): if self.request.headers.get(\"Content-Type\", \"\").startswith('\"application/json\"'): self.json_args = json.loads(self.request.body) else: self.json_args = None ","date":"2019-10-14","objectID":"/tornado/:4:3","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"重写RequestHandler方法 Overriding RequestHandler methods 除了get(), post()…，在RequestHandler某些其它方法被设计成在必要时由子类重写。在每次请求，调用以下顺序进行: 在每个请求上，一个新的RequestHandler对象被创建 initialize()被调用，从Application配置的初始化参数。初始化通常应该只保存传入成员变量的参数，不产生任何输出或调用(如send_error) prepare()被调用。这是最有用的，由所有handler subclass共享的基类，作为prepare被无论哪个HTTP方法所调用。prepare可产生输出，如果它调用finish或redirect，这里处理停止 当其中一个HTTP方法被调用时: get(), post(), put()。如果URL正则中包含捕获组(capturing group)，它们将被作为参数传递给该方法 当请求完成后，调用on_finish()。对于大多数handler这个在get()返回后立即调用。在调用finish()之后使用tornado.web.asynchronous装饰器来装饰handler 在RequestHandler文档中，所有的方法都设计来可重写。一些最常用的重写方法: writre_error: 输出HTML错误页面 on_connection_close: 当客户端断开连接时调用。应用可选择检测此情况并停止进一步的处理。注意，不能保证一个关闭的连接能够被及时发现 get_current_user get_user_locale: 返回当前用户的Locale对象 set_default_headers: 用于在响应中设置其它header ","date":"2019-10-14","objectID":"/tornado/:4:4","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"错误处理 Error Handling 如果handler抛出一个异常，Tornado将调用RequestHandler.write_error来生成一个错误页。tornado.web.HTTPError可用来生成一个特定状态码。所有其它异常返回500状态。 debug模式下的默认错误页面包含一个stack trace和对错误的一行说明。要生成自定义错误页，重写RequestHandler.write_error。可通过如write和render方法来产生输出。如果错误是由异常导致的，一个exc_info将作为一个关键字参数传递。 也可通过调用set_status产生与常规处理方法write_error生成的错误页面，编写一个响应，并返回。特殊异常tornado.web.Finish可抛出终止处理而不调用write_error在简单返回不方便时。 对于404错误，使用default_handler_class应用设置(Application setting)。此处理程序应重写prepare，而不是像get()方法更具体的方法，所以它与任何HTTP方法工作。如上所述应该产生错误页面: 要么抛出HTTPError(404)和重写write_error，或调用self.set_status(404)和直接在prepare()中产生响应。 ","date":"2019-10-14","objectID":"/tornado/:4:5","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"重定向 Redirection Tornado中有两种主要的方式重定向请求: RequestHandler.redirect和RedirectHandler。 可在RequestHandler方法中使用self.redirect()来重定向到别处。这有一个permanent的可选参数，可用它来表示永久的重定向。permanent的默认值为False，其产生一个302 Found HTTP响应码，适合像POST请求成功之后使用。如果permanent为true， 则使用301 Moved Permanently HTTP响应码，其用于重定向到一个规范友好的URL。 RedirectHandler让你直接在Application路由表中配置重定向，栗子: app = tornado.web.Application([ url(r\"/app\", tornado.web.RedirectHandler, dict(url=\"http://xxx.com\")), ]) RedirectHandler同样支持正则表达式取代。栗子: app = tornado.web.Application([ url(r\"/photos/(.*)\", MyPhotoHandler), url(r\"/pictures/(.*)\", tornado.web.RedirectHandler, dict(url=r\"/photo/{0})), ]) 不像RequestHandler.redirect，RedirectHandler默认使用永久重定向。这因为路由表在运行时不发生变化，被认定为时永久性的，而在处理中发现重定向可能改变其它逻辑的结果。要使用RedirectHandler发送一个临时的重定向，将permanent=False添加到RedirectHandler初始化参数。 ","date":"2019-10-14","objectID":"/tornado/:4:6","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"异步处理程序 Asynchronous handlers 某些处理方法(如prepare()和HTTP的get(), post()…)可能会被重写为协程，使处理程序异步。 Tornado同样支持使用tornado.web.asynchronous装饰器异步处理的回调风格，但这种风格已经过时，将在Tornado6中一处。新的应用应该使用协程来代替它。 使用协程的一个简单处理程序的栗子: class MainHandler(tornado.web.RequestHandler): async def get(self): http = tornado.httpclient.AsyncHTTPClient() response = await http.fetch(\"http://friendfeed-api.com/v2/feed/bret\") json = tornado.escape.json_decode(response.body) self.write(\"Fetched \" + str(len(json[\"entries\"])) + \" entries \" \"from the FriendFeed API\") 更多高级的异步的栗子，查考文档。 ","date":"2019-10-14","objectID":"/tornado/:4:7","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"模板和UI Templates and UI Tornado包含了一个简单、快速、灵活的模板语言。想想Django和Jinja2。 Tornado还可与任何其它Python模板语言使用，虽然没有规定集成这些系统到RequestHandler.render里。简单地渲染模板为字符串，并将其传递到RequestHandler.write。 ","date":"2019-10-14","objectID":"/tornado/:5:0","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"配置模板 Configuring templates 默认情况下，Tornado在引用它的.py文件中的同一目录下查找模板文件。要把模板文件放在不同的目录中，使用template_path应用设置。如果你有不同的模板路径用于不同的处理程序，请重写RequestHandler.get_template_path。 要从非文件系统位置载入模板，子类tornado.template.BaseLoader将在模板并传递一个实例作为template_loader应用设置。 默认缓存编译的模板。要关闭这个缓存和重新加载模板，使用compiled_template_cache=False或debug=True应用设置。 ","date":"2019-10-14","objectID":"/tornado/:5:1","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"模板语法 Template syntax Tornado模板仅仅是HTML(或其它基于文本的格式)与Python控制序列和嵌入在标记内的表达式，想想Django模板和Jinja2。 表达式可以是任意Python表达式，包括函数调用。模板代码在包括以下对象和函数的命名空间执行(请注意，以下列表适用于使用RequestHandler.render和render_string渲染模板。如果你直接使用在RequestHandler外的tornado.template模块，那么许多内容是不存在的。) escape: tornado.escape.xhtml_escape的别名 xhtml_escape: tornado.escape.xhtml_escape的别名 url_escape: tornado.escape.url_escape的别名 json_encode: tornado.escape.json_encode的别名 squeeze: tornado.escape.squeeze的别名 linkify: tornado.escape.linkify的别名 datetime: Python的datetime模块 handler: 目前的RequestHandler对象 request: handler.request的别名 current_user: handler.current_user的别名 locale: handler.locale的别名 _: handler.locale.translate的别名 static_url: handler.static_url的别名 xsrf_form_html: handler.xsrf_form_html的别名 reverse_url: Application.reverse_url的别名 所有条目从应用的ui_methods和ui_modules 任何关键字参数传递给render或render_string 当你在构建一个真正的应用时，你会想要使用Tornado模板的所用功能，尤其是模板继承。阅读tornado.template部分了解详细信息。 引擎盖下，Tornado模板直接转换为Python。模板中的表达式是逐字复制到Python函数中。我们不设法防止模板语言的任何东西。最后，如果你写的模板表达式内随机的东西，当你执行模板可能会获得随机的Python错误。 所有的模板输出默认被转义(escape)，使用tornado.escape.xhtml_escape函数。这个行为可通过全局地传递autoescape=None给应用或tornado.template.Loader构造器，对于模板文件指示{% autoescape None%}或通过{% raw ... %}代替{{ ... }}。此外，在每一个可选择转义函数名的地方，可用None代替。 虽然Tornado的自动转义为避免XSS漏洞有帮助，但它并不是在所有情况下都有效。例如在JS或CSS表达式的某些地方，可能需要额外的转义。此外，必须小心地使用HTML双引号\"和xhtml_escape，可能包含不受信任的内容，或者必须为属性使用单独地转义函数。 ","date":"2019-10-14","objectID":"/tornado/:5:2","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"UI模块 UI modules Tornado支持UI模块，可以很容易地在你的应用中支持标准的、可重用的UI组件。UI模块都喜欢特殊的函数调用来渲染网页和组件，它们可以包装自己的CSS和JS。 例如，如果要实现一个博客，你想拥有的博客条目同时出现在博客主页和每个博客页面上，你可以编写一个Entry模块在两个页面上渲染它们。首先，为你的UI模块创建一个Python模块: # uimodules.py class Entry(tonado.web.UIModule): def render(self, entry, show_commnets=False): return self.render_string(\"module-entry.html, entry=entry, show_comments=show_comments\") 在应用中设置ui_modules告诉Tornado使用uimodules.py: from . import uimodules class HomeHandler(tornado.web.RequestHandler): def get(self): entries = self.db.query(\"SELECT * FROM entries ORDER BY date DESC\") self.render(\"home.html\", entries=entries) class EntryHander(tornado.web.ReqestHandler): def get(self, entry_id): entry = self.db.get(\"SELECT * FROM entries WHERE id = %s, entry_id\") if not entry: raise tornado.web.HTTPError(404) self.render(\"entry.html\", entry=entry) settings = { \"ui_modules\": uimodules, } application = tornado.web.Application([ (r\"/\", HomeHandler), (r\"/entry/([0-9])\", EntryHandler), ], **settings) 在模板内，你可以使用{% module %}调用模块，例如在home.html中调用Entry模块: {% for entry in entries%} {% module Entry(entry) %} {% end %} entry.html中: {% module Entry(entry, show_comments=True) %} 模块可以通过重写embedded_css, embedded_javascript, javascript_files或css_files方法来包含自定义的CSS和JS函数: class Entry(tornado.web.UIModule): def embedded_css(self): return \".entry { margin-bottom: 1em; }\" def render(self, entry, show_comments=False): return self.render_string(\"module-entry\", show_comments=show_comments) 模块CSS和JS将包含一次，不管一个页面中这个模块使用了多少次。CSS总是包含在页面的\u003chead\u003e，JS总是包含在\u003c/body\u003e标记之前在页面的页面结束标记。 当不需要附加的Python代码，模板文件本身可以用作一个模块。例如，前面的栗子可以改写在module-entry.html模块: {{ set_resources(embedded_css=\".entry { margin-bottom: 1em; }\") }} \u003c!-- more template html... --\u003e 经修订的模板模块将与下栗被调用: {% module Template(\"module-entry.html\", show_comments=True) %} 该set_resources功能尽在通过 {% module Template(...) %} 调用模板。不同于 {% include %}， 模板模块具有从它们的包含模板的独特命名空间——它们只能看到全局模板命名空间和自己的关键字参数。 ","date":"2019-10-14","objectID":"/tornado/:5:3","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"认证和安全 Authentication and security ","date":"2019-10-14","objectID":"/tornado/:6:0","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"Cookie和secure cookies 可以使用set_cookie方法在用户浏览器中设置cookie: class MainHandler(tornado.web.ReqestHandler): def get(self): if not self.get_cookie(\"mycookie\"): self.set_cookie(\"mycookie\", \"myvalue\") self.write(\"Your cookie was not set yet!\") else: self.write(\"Your cookie was set!\") cookie是不安全的，可以很容易地被客户修改。如果你需要设置cookie，请确定当前登录的用户，你需要签属(signed)你的cookie来防止伪造。Tornado支持使用set_secure_cookie和get_secure_cookie方法来签属(sign)cookie。要使用这些方法，你需要在创建应用时指定一个名为cookie_secret的密钥键。你可以在应用中设置关键字参数来传递给应用。 application = tornado.web.Application([ (r\"/\", MainHandler), ], cookie_secret=\"__TODO:_GENERATE_YOUR_OWN_RANDOM_VALUE_HERE__\") 签属的cookie含有时间戳和HMAC签名的cookie编码值。如果cookie是旧的，或者签名不匹配，get_secure_cookie将会返回None就像没有设置cookie那样。上面栗子的安全版本: class MainHandler(tornado.web.RequestHandler): def get(self): if not self.get_secure_cookie(\"mycookie\"): self.set_secure_cookie(\"mycookie\", \"myvalue\") self.write(\"Your cookie was not set yet!\") else: self.write(\"Your cookie was set!\") Tornado的secure cookie保证完整性，但不保密。也就是说，cookie不能被修改，但可以被用户看到。cookie_secret是一个对称密钥并且必须保密——得到这个值的人都可以制作自己的签名的cookie。 默认情况下，Tornado的cookie在30天后过期。可对set_secure_cookie使用expires_days参数和max_age_days来修改。 Tornado同样支持多个签名密钥来启用签名轮询。cookie_secret必须与整数密钥版本作为关键字和相应的secret作为字典的值。将当前使用的签名密钥必须在应用中设置为key_version，但在字典的所有其它键都允许cookie签名认证，如果设置在cookie中的是正确的密钥版本。要更新cookie，可通过查询get_secure_cookie_key_version获取当前的签名密钥版本。 ","date":"2019-10-14","objectID":"/tornado/:6:1","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"用户认证 User authentication 当前已认证的用户在每个request handler中可使用self.current_user，在每个模板中为current_user。默认情况下，current_user为None。 要在应用中执行用户身份认证，需要在request handler中重写get_current_user以基于cookie的值确定当前用户。下面是一个让用户登录到应用，简单地指定一个昵称，然后将其保存到cookie中: class BaseHandler(tornado.web.RequestHandler): def get_current_user(self): return self.get_secure_cookie(\"user\") class MainHandler(BaseHandler): def get(self): if not self.current_user: self.redirect(\"/login\") return name = tornado.escape.xhtml_escape(self.current_user) self.write(\"Hello, \" + name) class LoginHandler(BaseHandler): def get(self): self.write('\u003chtml\u003e\u003cbody\u003e\u003cform action=\"/login\" method=\"post\"\u003e' 'Name: \u003cinput type=\"text\" name=\"name\"\u003e' '\u003cinput type=\"submit\" value=\"Sign in\"\u003e' '\u003c/form\u003e\u003c/body\u003e\u003c/html\u003e') def post(self): self.set_secure_cookie(\"user\", self.get_argument(\"name\")) self.redirect(\"/\") application = tornado.web.Application([ (r\"/\", MainHandler), (r\"/login\", LoginHandler), ], cookie_secret=\"__TODO:_GENERATE_YOUR_OWN_RANDOM_VALUE_HERE__\") 你可以要求用户在使用tornado.web.authenticated Python装饰器处登录。如果请求的方法带有此装饰器，并且用户没有登录，则他们将被重定向到login_url或其它设置。重写上面的栗子: class MainHandler(BaseHandler): @tornado.web.authenticated def get(self): name = tornado.escaple.xhtml_escape(self.current_user) self.write(\"Hello, \" + name) settings = { \"cookie_secret\": \"__TODO:_GENERATE_YOUR_OWN_RANDOM_VALUE_HERE__\", \"login_url\":\"/login\", } application = tornado.web.Application([ (r\"/\", MainHandler), (r\"/login\", LoginHandler), ], **settings) 如果你使用authenticate装饰器装饰一个post()方法，并且用户没有登录，则Server会返回403响应。@authenticated装饰器简单来说就是if not self.current_user: self.redirect()的快捷键，并且可能不适用于非基于浏览器的登录方案。 ","date":"2019-10-14","objectID":"/tornado/:6:2","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"第三方认证 Third party authentication tornado.auth模块实现了许多受欢迎的网站上提供的认证(authentication)和授权(authorization)协议，包括Google, FaceBook, Twitter… 下面是一个使用谷歌认证的示例，存储Google credential到cookie以便后续访问使用: class GoogleOAuth2LoginHandler(tornado.web.RequestHandler, tornado.auth.GoogleOAuth2Mixin): async def get(self): if self.get_argument('code', False): user = await self.get_authenticated_user( redirect_uri=\"http://your.site.com/auth/google\", code=self.get_argument('code')) # Save the user with e.g. set_secure_cookie else: await self.authorize_redirect( redirect_uri='http://your.site.com/auth/google', client_id=self.setting['google_oauth']['key'], scope=['profile', 'email'], response_type='code', extra_params={'approval_prompt': 'auto'}) 更多详细内容，请参考tornado.auth文档。 ","date":"2019-10-14","objectID":"/tornado/:6:3","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"跨站请求伪造保护 Cross-site request forgery protection 跨站请求伪造(Cross-site request forgery, XSRF)，是Web应用的一个常见的问题。 防止XSRF普遍接受的解决方案是每个用户的cookie使用不可预测的值，此值包含网站上每个表单提交的额外参数。如果表单提交的cookie和值不匹配，则请求可能是伪造的。 Tornado内置了XSRF保护。要在你的站点中包含它，启用应用scrf_cookies设置: settings = { \"cookie_secret\": \"__TODO:_GENERATE_YOUR_OWN_RANDOM_VALUE_HERE__\", \"login_url\": \"/login\", \"xsrf_cookies\": True } application = tornado.web.Application([ (r\"/\", MainHandler), (r\"/login\", LoginHandler), ], **settings) 如果设置了xsrf_cookies，Tornado Web Application将为所有用户设置_xsrf cookie，并拒绝没有包含正确的_xsrf值的所有POST, PUT, DELETE请求。如果你打开了此设置，你需要一切形式的POST提交中包含此字段。你可以使用特殊的UIModule vsrf_form_html()，在所有模板中可用: \u003cform action=\"/new_message\" method=\"post\"\u003e {% module xsrf_form_html() %} \u003cinput type=\"text\" name=\"message\"/\u003e \u003cinput type=\"submit\" value=\"Post\"/\u003e \u003c/form\u003e 如果你提交AJAX POST请求，你还需要构造JS来包括每个请求的_xsfr值。所有包含_xsrf请求AJAX POST的JQuery函数: function getCookie(name) { var r = document.cookie.match(\"\\\\b\" + name + \"=([^;]*)\\\\b\"); return r ? r[1] : undefined; } jQuery.postJSON = function(url, args, callback) { args._xsrf = getCookie(\"_xsrf\"); $.ajax({url: url, data: $.param(args), dataType: \"text\", type: \"POST\", success: function(response) { callback(eval(\"(\" + response + \")\")); }}); }; 对于PUT和DELETE请求，XSRF token可能会通过HTTP X-XSRFToken Header进行传递。使用xsrf_form_html时，XSRF cookie被正常设置，但是在不使用任何形式的纯JS应用中，可能需要手动访问self.xsrf_token。 如果你需要在每个handler中自定义XSRF行为，你可以重写RequestHandler.check_xsrf_cookie()。例如，如果你有一个不使用cookie的API，你可能希望通过使check_xsrf_cookie什么也不做来禁用XSRF保护。然而，如果你支持基于cookie和非基于cookie的认证，只要求当前请求使用cookie认证XSRF保护是重要的。 ","date":"2019-10-14","objectID":"/tornado/:6:4","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"DNS重新绑定 DNS Rebinding DNS重新绑定是一种攻击，可以绕过同源策略，并允许外部站点访问内部网络的资源。使用TLS的应用不容易受到这种攻击。没有使用TLS的应用依赖网络层的访问控制，应警惕通过验证的HTTP Header的Host被DNS重新绑定。This means passing a restrictive hostname pattern to either a HostMatches router or the first argument of Application.add_handlers: # BAD: uses a default host pattern of r'.*' app = Application([('/foo', FooHandler)]) # GOOD: only matches localhost or its ip address. app = Application() app.add_handlers(r'(localhost|127\\.0\\.0\\.1)', [('/foo', FooHandler)]) # GOOD: same as previous example using tornado.routing. app = Application([ (HostMatches(r'(localhost|127\\.0\\.0\\.1)'), [('/foo', FooHandler)]), ]) 此外，应用的default_host参数，和DefaultHostMatches路由器不能在应用中使用，这可能受到DNS重新绑定，因为它有一个通配符主模式类似的效果。 ","date":"2019-10-14","objectID":"/tornado/:6:5","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"运行和部署 Running and deploying 自从Tornado提供了自己的HTTPServer，运行和部署它便和其它Python Web框架有点不同。不同于配置WSGI，你只需要写一个main()函数来启动Server: def main(): app = make_app() app.listen(8888) IOLoop.current().start() if __name__ == '__main__': main() 请注意，这可能需要增加每个进程可打开的文件数(open files)，可能修改ulimit限制。 ","date":"2019-10-14","objectID":"/tornado/:7:0","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"进程和端口 Processes and ports 由于Python的GIL(Global Interpreter Lock)，有必要运行多个Python进程，以充分利用多CPU机器。通常，最好为每个CPU运行一个进程。 Tornado包含了一个内置的多进程模式，一次可启动多个进程。这需要稍微修改以下启动方式: def main(): app = make_app() server = tornado.httpserver.HTTPServer(app) server.bind(8888) server.start(0) # forks one process per cpu IOLoop.current().start() 这是启动多个进程，并让它们使用相同的端口最简单的方法，虽然它有一定的局限性。首先，每个子进程都会有自己的IOLoop，因此在fork前没有事物触及IOLoop示例是很重要的。第二，在这个模型中很难做到零停机更新(zero-downtime updates)。最后，由于所有的进程共享同一端口更难以单独监控。 对于更复杂的部署，建议单独启动进程，并监听不同的端口。supervisord是一个好办法。当每个进程使用了不同的端口，通常需要一个外部的负载均衡器(如HAProxy, Nginx)以单独的访问地址提供给访问者。 ","date":"2019-10-14","objectID":"/tornado/:7:1","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"运行在负载均衡器后 Running behind a load balancer 当运行在如Nginx这样的负载均衡器之后，建议传递xheaders=True给HTTPServer构造器。这将告诉Tornado使用X-Real-IP用户Header，来获取用户IP地址，而不是负载均衡器的IP地址。 一个栗子: user nginx; worker_processes 1; error_log /var/log/nginx/error.log; pid /var/run/nginx.pid; events { worker_connections 1024; use epoll; } http { # Enumerate all the Tornado servers here upstream frontends { server 127.0.0.1:8000; server 127.0.0.1:8001; server 127.0.0.1:8002; server 127.0.0.1:8003; } include /etc/nginx/mime.types; default_type application/octet-stream; access_log /var/log/nginx/access.log; keepalive_timeout 65; proxy_read_timeout 200; sendfile on; tcp_nopush on; tcp_nodelay on; gzip on; gzip_min_length 1000; gzip_proxied any; gzip_types text/plain text/html text/css text/xml application/x-javascript application/xml application/atom+xml text/javascript; # Only retry if there was a communication error, not a timeout # on the Tornado server (to avoid propagating \"queries of death\" # to all frontends) proxy_next_upstream error; server { listen 80; # Allow file uploads client_max_body_size 50M; location ^~ /static/ { root /var/www; if ($query_string) { expires max; } } location = /favicon.ico { rewrite (.*) /static/favicon.ico; } location = /robots.txt { rewrite (.*) /static/robots.txt; } location / { proxy_pass_header Server; proxy_set_header Host $http_host; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_pass http://frontends; } } } ","date":"2019-10-14","objectID":"/tornado/:7:2","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"静态文件和侵略性的文件缓存 Static files and aggressive file caching 你可以通过在应用中指定static_path来设置Tornaodo提供静态文件: settings = { \"static_path\": os.path.join(os.path.dirname(__file__), \"static\"), \"cookie_secret\": \"__TODO:_GENERATE_YOUR_OWN_RANDOM_VALUE_HERE__\", \"login_url\": \"/login\", \"xsrf_cookies\": True, } application = tornado.web.Application([ (r\"/\", MainHandler), (r\"/login\", LoginHandler), (r\"/(apple-touch-icon\\.png)\", tornado.web.StaticFileHandler, dict(path=settings['static_path'])), ], **settings) 此设置会自动设置以/static/的所有请求到静态目录，如http://localhost:8888/static/foo.png将从指定的静态目录提供静态文件。同样还有/robots.txt和/favicon.ico，即便它们并未以/static/为前缀。 在上面的设置，我们已明确的配置Tornado从StaticFileHandler提供apple-touch-icon.png。 要提高性能，通常是浏览器缓存静态资源，因此浏览器将不会发送不必要的If-Modified-Since或Etag请求，这可能会阻止页面的渲染。Tornado支持这一开箱即用的静态内容版本。 要使用此功能，在你的模板中使用static_url方法，而不是在你的HTML中直接输入静态文件: \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eFriendFeed - {{ _(\"Home\") }}\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cdiv\u003e\u003cimg src=\"{{ static_url(\"images/logo.png\") }}\"/\u003e\u003c/div\u003e \u003c/body\u003e \u003c/html\u003e static_url()函数会将相对路径转换为如/static/images/logo.png?v=aae54这样的URI。v参数是logo.png的哈希内容，它的存在使得Tornado Server发送cache header到用户浏览器，这将使浏览器无限期缓存内容。 由于v参数使基于文件的内容，如果你更新文件并重启Server，它将发送一个新的v值，因此用户浏览器会自动获取新的文件。如果文件的内容没有改变，浏览器将继续使用本地缓存的副本而没有检查Server上的更新，显著提供渲染性能。 在生产环境，你可能希望从像Nginx这样更优化的静态文件服务器提供静态文件。你可以配置几乎所有的Web Server识别由static_url使用的标签，并设置相应的cache header。 栗子: location /static/ { root /var/friendfeed/static; if ($query_string) { expires max; } } ","date":"2019-10-14","objectID":"/tornado/:7:3","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"Debug模式和自动重载 Debug mode and automatic reloading 如果将debug=True传递给Application构造器，应用将运行在debug/development模式下。在此模式下，一些便于开发调试的功能将被启用: autoreload=True：应用会监视更改的源文件并在发生变化时自动重载。这样减少了在开发过程中手动重启服务。然后，某些错误可能导致无法启动。 compiled_template_cache=False：模板不会被缓存。 static_hash_cache=False：静态文件哈希值(由static_url函数使用)将不会被缓存。 serve_traceback=True：当RequestHandler中的异常没有被捕获，将会生成一个包含stack trace的错误页面。 自动重载模式不兼容HTTPserver的多进程模式。如果你正在使用自动重载模式，你不要给HTTPServer.start一个或多于一个参数(或调用tornado.process.fork_processes)。 调式模式的自动重载功能是可用作为tornado.autoreload独立(standalone)模块。这两个可以组合使用，以提供对语法错误的额外稳健：在应用中设置autoreload=True来在运行时检测改变，并使用python -m tornado.autoreload myserver.py启动来在启动时捕获任意语法错误或其它错误。 重载将失去任何Python解释器命令行参数(如-u)，因为它使用sys.executable和sys.argv来重新执行Python。此外，修改这些变量将导致重载行为不正确。 ","date":"2019-10-14","objectID":"/tornado/:7:4","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["backend"],"content":"WSGI Tornado通常是为了独立运行，而不用WSGI容器。然而，在一些环境中（如Google App Engine），只允许WSGI，应用程序无法运行自己的Server。在这种情况下，Tornado支持操作的限制模式，不支持异步操作，但允许在只有WSGI环境的Tornado功能的子集。未在WSIG模式允许的功能包括协程、@asynchronous装饰器，AsyncHTTPclient、auth模块和WebSockets。 你可以使用tornado.wsgi.WSGIAdapter将一个Tornado Application转换为WSGI application。 栗子: import tornado.web import tornado.wsgi class MainHandler(tornado.web.RequestHandler): def get(self): self.write('Hello, world') tornado_app = tornado.web.Application([ (r\"/\", MainHandler), ]) application = tornado.wsgi.WSGIAdapter(tornado_app) ","date":"2019-10-14","objectID":"/tornado/:7:5","tags":["Python","Web","Tornado","DevOps"],"title":"Tornado","uri":"/tornado/"},{"categories":["frontend"],"content":"参考: Head First HTML and CSS w3cSchool \r\r \r\r认识HTML HTML(Hyper Text Markup Language)超文本标记语言，创建结构。 HTML会告诉浏览器文档的结构，标题放在哪、段落放在哪、哪些文本需要强调… CSS(Cascading Style Sheets)层叠样式表，创建样式。 与试图使用一种语言兼顾这两方面的工作相比，实际上学习两种语言让它们各司其职反而更容易。 首部(head): 包含了web页面的有关信息 页面元素(body): 包含web页面的所有内容和结构 元素(element): 开始标记+内容+结束标记（如element=\u003c\u003e+content+\u003c/\u003e），某些例外 属性(attribute): 如type=\"text/css\"，能提供元素的一些额外信息 \u003cStyle\u003e元素放在HTML首部 \u003c!--index.html--\u003e \u003c!DOCTYPE html\u003e \u003chtml lang='en'\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eStarbuzz Coffee\u003c/title\u003e \u003cstyle type=\"text/css\"\u003e body { background-color:skyblue; margin-left: 20%; margin-right: 20%; border: 2px dotted black; padding: 10px 10px 10px 10px; font-family: sans-serif; } \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eStarbuzz Coffee Beverages\u003c/h1\u003e \u003ch2\u003eHouse Blend\u003c/h2\u003e \u003cp\u003eABC\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e \r\r \r\r深入了解超文本 想从一个页面链接到另一个页面，使用\u003ca\u003e元素。 \u003ca\u003e元素的href属性制订了链接的目标文件。 文字和图像都可以用作链接的标签。 单击一个链接时，浏览器会加载href属性中指定的Web页面。 可以链接到相同文件夹中的文件，也可以链接到其它文件夹的文件。 请注意相对路径和绝对路径。 为网站选择的文件名和文件夹不要有空格。 \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eAAA\u003c/title\u003e \u003cstyle type=\"text/css\"\u003e body { margin-left:20%; margin-right:20; } \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1 id=\"top\"\u003eWelcome\u003c/h1\u003e \u003cimg src=\"images/aaa.jpg\"\u003e \u003ca href=\"aaa/aaa.html\" title=\"aaa\" target=\"_blank\"\u003e \u003ch2\u003eaaa\u003c/h2\u003e \u003c/a\u003e \u003cp\u003e abcd \u003cem\u003eaaa\u003c/em\u003e \u003c/p\u003e \u003ca href='#top'\u003e\u003ch3\u003e返回TOP\u003c/h3\u003e\u003c/a\u003e \u003c/body\u003e \u003c/html\u003e \r\r \r\r构建模块 开始输入内容之前要规划好Web页面的结构。首先画出一个草图，然后创建一个略图，最后再写出HTML。 规划页面时，首先设计大的块元素，然后用内联(inline)元素完善。 记住，要尽可能使用元素来告诉浏览器你的内容的含义。 一定要使用与内容含义最接近的元素。例如，如果需要一个列表，就不要使用段落元素。 \u003cp\u003e, \u003cblockquote\u003e, \u003col\u003e, \u003cul\u003e, \u003cli\u003e都是块元素。它们单独显示，与内容前后分别有一个换行(默认的)。 \u003cq\u003e, \u003cem\u003e是内联元素。这些元素中的内容与其包含元素的其余内容放在一起。 需要插入自己的换行时，可以使用\u003cbr\u003e元素，它是一个void元素。 void元素没有内容，只有一个标记组成。 空元素没有内容。不过它有开始和结束标记。 嵌套元素是指完全包含在另一个元素中的元素。如果元素能正确地嵌套，所有标记都能正确匹配。 要结合两个元素建立一个HTML列表，可以使用\u003col\u003e和\u003cli\u003e，也可以使用\u003cul\u003e和\u003cli\u003e。 要对HTML内容中的特殊字符使用字符实体(character entity)，如\u003c符号使用\u0026lt。 \r元素大杂烩(elements) \u003ca\u003e # 建立链接 \u003cp\u003e # 段落 \u003cq\u003e # 短引用 \u003cblockquote\u003e # 长引用 \u003ccode\u003e # 显示代码 \u003cem\u003e # 斜体 \u003ctime\u003e # 告诉浏览器此内容是时间 \u003cul\u003e # 无序列表 \u003col\u003e # 有序列表 \u003cli\u003e # 列表 \u003cstrong\u003e # 强调文本 \u003cpre\u003e # 浏览器按照你输入的格式显示文本 \u003cbr\u003e # 换行 \u003cimg\u003e # 图像 \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003e333\u003c/title\u003e \u003cstyle type=\"text/css\"\u003e body { margin-left: 20%; margin-right: 20%; } q, blockquote, ol, ul { font-size: x-large; } \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003e333\u003c/h1\u003e \u003cp\u003e333\u003c/p\u003e \u003ch2\u003e333\u003c/h2\u003e \u003cimg src=\"../images/333.png\"\u003e \u003cp\u003e 333333333333: \u003col\u003e \u003cli\u003e3\u003c/li\u003e \u003cli\u003e33\u003c/li\u003e \u003cli\u003e333\u003c/li\u003e \u003c/ol\u003e \u003cp\u003e 3333 \u003cblockquote\u003e 3\u003cbr\u003e 33\u003cbr\u003e 333\u003cbr\u003e \u003c/blockquote\u003e 333 \u003c/p\u003e \u003ch2\u003e333\u003c/h2\u003e \u003cp\u003e 333: \u003cul\u003e \u003cli\u003e3\u003c/li\u003e \u003cli\u003e33\u003c/li\u003e \u003cli\u003e333\u003c/li\u003e \u003cul\u003e 333 \u003c/p\u003e \u003c/body\u003e \u003c/html\u003e \r\r \r\r连接起来 要把网站发布到Web上，通常最好的方法就是找一家公司来托管你的Web页面。 域名(domain)是一个唯一的名字，如aaa.com，用来唯一标识网站。 托管公司可能会为你的域创建一个或多个Web服务器，通常为www。 URL是统一资源定位符或Web地址，可用来标识Web上的任何资源。 定性的URL是由一个协议、一个网站名和资源的一个绝对路径组成。 HTTP是一个请求和响应协议，用来在Web服务器和浏览器之间传送Web页面。 浏览器使用file:///协议从你的计算机读取页面。 index.html和default.html都是默认页面，如果指定一个目录而没有指定文件名，则Web服务器会查找一个默认页面返回到浏览器。 \u003ca\u003e元素的href属性中可以使用相对路径或URL来链接其它web页面。对于你的网站中的其它页面，最好使用相对路径，对外部链接才使用URL。 可以用id属性在页面中创建一个目标（如\u003ch1 id=\"top\"\u003e），使用#后面加一个目标id（如\u003ca href=\"#top\"\u003e），可以链接到页面中的那个位置。 为了便于访问，可以在\u003ca\u003e元素中使用title属性提供链接的一个描述。 使用target属性在另一个窗口中打开链接。对于不同设备和浏览器，target属性可能会有问题。 \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003e444\u003c/title\u003e \u003cstyle type=\"text/css\"\u003e body { margin-left: 20%; margin-right: 20%; } \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1 id=\"top\"\u003e444\u003c/h1\u003e \u003cimg src=\"images/444.jpg\" width=\"800\" height=\"400\"\u003e \u003ca href=\"about/444.html\" title=\"444\" taget=\"_blank\"\u003e \u003ch2\u003e4444\u003c/h2\u003e \u003c/a\u003e \u003cp\u003e 4 \u003cem\u003e44\u003c/em\u003e 444 \u003c/p\u003e \u003ca href=\"#top\"\u003e \u003ch3\u003eTop\u003c/h3\u003e\u003c/a\u003e \u003c/body\u003e \u003c/html\u003e \r\r \r\r为页面添加图像 使用\u003cimg\u003e元素在web页面中添加图像。\u003cimg\u003e元素是一个内联元素，这说明浏览器不会在图像前后插入一个换行。 浏览器对\u003cimg\u003e元素的处理与其它HTML元素稍有不同。读取HTML页面之后，浏览器会从Web服务器获取各个图像并显示。 如果web页面上有多个大图像，则可以通过创建图像的缩略图使web页面更可用，下载也更快。缩略图是一些小图像（大图像的缩小版本），用户单击这些缩略图时可以看到原来的大图像。 要利用src属性指定图像文件的位置。可以在src属性中使用相对路径包含自己网站中的图像，或者可使用URL包含其它网站的图像。 alt属性是对图像的一个有意义的描述，在一些浏览器中，如果无法找到图像，就会显示这个描述。 对于浏览器来说，太大的图像会使web页面很难用，而且下载和显示都很慢。 图像可以用作指向其它web页面的链接。 JPEG、PNG和GIF是web浏览器广泛支持的3中图像格式 JPEG格式最适合保存照片和其他复杂图像 GIF或PNG格式最适合保存Logo和其他包含单色、线条或文本的简单图形 JPEG图像可以按不同的质量(quality）压缩，所以可以很好地权衡图像","date":"2019-10-11","objectID":"/htmlcss/:0:0","tags":["frontend","html","css"],"title":"HTML和CSS","uri":"/htmlcss/"},{"categories":["backend"],"content":"参考: docs: https://docs.djangoproject.com/zh-hans/2.1/topics/ 版本: Django Version: v2.1 \r\r \r\r使用Django docs: https://docs.djangoproject.com/zh-hans/2.1/topics/ \r\r安装Django \r\r \r\r模型和数据库 docs: https://docs.djangoproject.com/zh-hans/2.1/topics/db/ 模型是你的数据唯一而且准确的信息来源。它包含你正在存储的数据的重要字段和行为。一般来说，每一个模型都映射一个数据库表。 \r","date":"2019-09-25","objectID":"/django/:0:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"模型 docs: https://docs.djangoproject.com/zh-hans/2.1/topics/db/models/ 基础: 每个模型都是一个Python类(继承django.db.models.Model) 模型类的每个属性都相当于一个数据库的字段 \r","date":"2019-09-25","objectID":"/django/:1:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"快速上手 这个样例模型定义了一个Person, 其拥有first_name和last_name: from django import models class Person(models.Model): first_name = models.CharField(max_length=30) last_name = models.CharField(max_length=30) first_name和last_name是模型的字段。每个字段都被指定为一个类属性，并且每个属性映射为一个数据库列。 上面的Person会创建一个如下的数据库表: CREATETABLEmyapp_person(\"id\"serialNOTNULLPRIMARYKEY,\"first_name\"varchar(30)NOTNULL,\"last_name\"varchar(30)NOTNULL); 说明: 表名myapp_person是自动从模型元数据中派生出来，但可以被改写 id字段会被自动添加，也可被改写 这是使用默认的PostgreSQL语法，数据库引擎可在settings中配置 \r\r","date":"2019-09-25","objectID":"/django/:1:1","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"使用模型 一旦定义了模型，需要告诉Django使用这些模型。需要修改setting文件中的INSTALLED_APPS, 这个设置中添加包含你models.py文件的模块的名字。 # 例如，模型位于项目中的myapp.models中 # 包结构使用 manage.py startapp 创建 INSTALLED_APPS = [ ... 'myapp', ... ] 当你在配置中添加新应用的时候，请务必运行manage.py migrate \u003cmigrate\u003e，此外你也可以先使用manage.py makemigrations先进行迁移。 \r\r\r","date":"2019-09-25","objectID":"/django/:1:2","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"进行查询 docs: https://docs.djangoproject.com/zh-hans/2.1/topics/db/queries/ 一旦创建了数据模型，Django会自动地给你一个数据库抽象API——让你可创建、检索、更新和删除对象。 from django.db import models class Blog(models.Model): name = models.CharField(max_length=1000) tagline = models.TextField() def __str__(self): return self.name class Author(models.Model): name = models.CharField(max_length=1200) email = models.EmailField() def __str__(self): return self.name class Entry(models.Model): blog = models.ForeignKey(Blog, on_delete=models.CASCADE) headline = models.CharField(max_length=255) body_text = models.TextField() pub_date = models.DateField() authors = models.MangToManyField(Author) n_comments = models.IntegerField() n_pingbacks = models.IntegerField() def __str__(self): return self.headline \r","date":"2019-09-25","objectID":"/django/:2:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"创建对象 为了表示在Python对象数据库表中的数据，Django使用一个直观的系统: 一个模型类表示一个数据库表 类实例表示数据库中的表中的特定记录 要创建一个对象，使用关键字参数模型类的实例化，然后调用save()将它保存到数据库中。 # 例子 from blog.models import Blog b = Blog(name='xxx', tagline='xxxx') b.save() \r\r","date":"2019-09-25","objectID":"/django/:2:1","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"将更改保存到对象 使用save()将更改保存到一个对象中已有的数据库。 b5.name = 'New b5' b5.save() # 这执行幕后的UPDATE SQL语句 \r\r","date":"2019-09-25","objectID":"/django/:2:2","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"检索对象 要检索数据库对象，通过在模型类上Manager构建一个QuerySet。 QuerySet代表从数据库的对象集合。它可以有0, 1, n个过滤器。在SQL方面，一个QuerySet相当于SELECT语句，而过滤器相当于WHERE, LIMIT。 通过使用Manager模型获取QuerySet。每个模型至少有一个Manager，这就是所谓的默认objects。直接通过模型类访问: Blog.objects b = Blog(name='xxx', tagline='Bar') b.objects ... 检索所有对象； 使用过滤器检索特定对象； \r\r","date":"2019-09-25","objectID":"/django/:2:3","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"比较对象 \r\r","date":"2019-09-25","objectID":"/django/:2:4","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"删除对象 \r\r","date":"2019-09-25","objectID":"/django/:2:5","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"更新对象 \r\r","date":"2019-09-25","objectID":"/django/:2:6","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"关联对象 \r\r","date":"2019-09-25","objectID":"/django/:2:7","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"回落的原生SQL 如果你发现自己使用Django 数据库映射器写一个SQL查询太复杂，你可以手边编写SQL fall back。 \r\r\r","date":"2019-09-25","objectID":"/django/:2:8","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"聚合 docs: https://docs.djangoproject.com/zh-hans/2.1/topics/db/aggregation/ 有时候要获取的值需要根据一组对象聚合后才能得到。 \r\r","date":"2019-09-25","objectID":"/django/:3:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"搜索 docs: https://docs.djangoproject.com/zh-hans/2.1/topics/db/search/ Web应用的一个常见任务就是寻找与用户输入数据库中的某些数据。 \r\r \r\r处理HTTP请求 docs: https://docs.djangoproject.com/zh-hans/2.1/topics/http/ \r","date":"2019-09-25","objectID":"/django/:4:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"URL调度器 docs: https://docs.djangoproject.com/zh-hans/2.1/topics/http/urls/ 对于高质量的Web应用来说，使用简洁、优雅的URL模式是一个非常值得重视的世界。Django允许你自由滴设计你的URL，不受框架束缚。 \r","date":"2019-09-25","objectID":"/django/:5:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"概况 为了给一个应用设计URL，你需要创建一个Python模块，通常被称为URLconf。这个模块是纯粹的Python代码，包含URL模式(简单的正则)到Python函数(视图)的简单映射。 映射可长可短，随便你。它可以引用其它映射。而且，因为它是纯粹的Python代码，它可以动态构造。 \r\r","date":"2019-09-25","objectID":"/django/:5:1","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"Django如何处理一个请求 当一个用户请求Django站点的一个页面，下面是Django系统决定执行哪个Python代码使用的算法: Django确定 root URLconf 模块的使用。通常，这个setting中ROOT_URLCONF的值，但如果传入HttpRequest对象具有URL配置属性(由中间件设置)，它的值将代替ROOT_URLCONF。 Django载入 Python 模块并查找 urlpatterns变量。这应该是是一个 Python List。 Django依次匹配每个URL模式，在与请求的URL匹配的第一个模式停下来。 一旦URL模式匹配，Django导入并调用给定的视图——这是一个简单的Python函数(或基于类的视图)。该类会传递如下参数: 4.1 一个HttpRequest实例 4.2 如果匹配的URL模式没有返回命名组，则从正则匹配作为位置参数 4.3 关键字参数是由通过路径表达式匹配的任何命名的部分，通过在任选关键字参数kwargs指定的任何参数重写django.urls.path()或django.urls.re_path() 如果每个URL模式匹配，或者一个异常在此过程中的任何点被抛出，则Django调用适当的错误处理视图。 \r\r","date":"2019-09-25","objectID":"/django/:5:2","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"栗子 一个简单的URLconf: from django.urls import path from . import views utlpatterns = [ path('articles/2003/', views.special_case_2003), path('articles/\u003cint:year\u003e/', views.year_archive), path('articles/\u003cint:year\u003e/\u003cint:month\u003e/', views.month_archive), path('articles/\u003cint:year\u003e/\u003cint:month\u003e/\u003cslug:slug\u003e/', view.article_detail) ] 注意: 为了捕获从URL中的值，使用尖括号\u003c\u003e 捕获的值可任选地包括一个转换器类型。如，使用\u003cint: name\u003e来捕获整数参数。如果不包含一个转换器，则为任意string。排除/字符，被匹配。 没有必要添加开始的斜线/，因为每个URL都有。如articles而不是/articles。 一些请求栗子: 一个请求/articles/2005/03/将匹配李彪中的第三项。Django将调用函数view.mouth_archive(request, year=2005, month=3)。 /articles/2003/将匹配第一个模式，而不是第二个。Django将调用函数views.special_case_2003(request) /articles/2003将不会匹配这些模式，因为每个模式都要求URL以斜线/结束 /articles/2003/building-a-django-site/讲匹配最后一个模式。Django将调用函数view.article_detail(request, year=2003, month=3, slug=\"building-a-django-site\") \r\r","date":"2019-09-25","objectID":"/django/:5:3","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"path转换器 下面的路径转换器默认可用: str: 匹配任意非空字符串，不包括路径分隔符/。如果表达式中不包含转换器，这是默认值。 int: 匹配零个或多个正整数，返回一个int。 slug: 匹配任何由ASCII字母、数字、连字符、下划线组成的slug字符串。 uuid: 匹配一个格式化的UUID。为了防止映射到同一页面的多个网址，必须包含字符，必须小写。(如075194d3-6885-417e-a8a8-6c931e272f00)，返回一个UUID实例。 path: 匹配任意费控字符串，包含路径分隔符/。这允许你来匹配一个完整的URL路径. \r\r","date":"2019-09-25","objectID":"/django/:5:4","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"注册自定义路径转换器 对于更复杂的匹配要求，可以定义自己的路径转换器。 \r\r","date":"2019-09-25","objectID":"/django/:5:5","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"使用正则表达式 如果路径和转换器的语法不够定义你的URL模式，你也可以使用正则表达式。要做到这一点，使用re_path()来代替path()。 在Python的正则表达式中，正则表达式组名语法是(?P\u003cname\u003epattern)，name是组名和pattern相匹配。 将之前的URLconf使用正则表达式改写: from django.urls import path, re_path from . import views urlpatterns = [ path('articles/2003/', views.special_case_2003), re_path(r'^articles/(?P\u003cyear\u003e[0-9]{4}/$', views.year_archive)), re_path(r'^articles/(?P\u003cyear\u003e[0-9]{4})/(?P\u003cmonth\u003e[0-9]{2})/$', views.month_archive), re_path(r'^articles/(?P\u003cyear\u003e[0-9]{4})/(?P\u003cmonth\u003e[0-9]{2})/(?P\u003cslug\u003e[\\w-]+)/$', views.article_detail), ] 使用未命名的正则表达式组 嵌套的参数 # 正则表达式允许嵌套参数 from django.urls import re_path urlpatterns = [ re_path(r'^blog/(page-(\\d+)/)?$', blog_articles), # bad re_path(r'^comments/(?:page-(?P\u003cpage_number\u003e\\d+)/)?$', comments), # good ] \r\r","date":"2019-09-25","objectID":"/django/:5:6","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"URLconf在什么上查找 请求的URL被看成是一个普通的Python字符串，URLconf在其上查找并匹配。进行匹配时将不包括GET或POST请求方式的参数以及域名。 例如，https://www.example.com/myapp/请求中，URLconf将查找myapp/。在https://www.example.com/myapp/?page=3请求中，URLconf仍将查找myapp/。 URLconf不检查使用了哪种请求方法。换句话讲，所有的请求方法——无论是POST, GET, HEAD…，都将路由到相同的函数。 \r\r","date":"2019-09-25","objectID":"/django/:5:7","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"指定视图参数的默认值 有一个方便的小技巧是指定视图参数的默认值。 # URLconf from django.urls import path from . import views utlpatterns = [ path('blog/', views.page), path('blog/page\u003cint:num\u003e', views.page), ] # View def page(request, num=1): ... \r\r","date":"2019-09-25","objectID":"/django/:5:8","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"错误处理 当Django找不到请求的URL匹配，或将引发异常，Django调用错误处理视图。 这些情况发生时使用的视图通过4个变量指定。它们的默认值应该能满足大部分项目，但也可给他们赋值以进一步自定义。 handler400: django.conf.urls.handler400 handler403: django.conf.urls.handler403 handler404: django.conf.urls.handler404 handler500: django.conf.urls.handler500 \r\r","date":"2019-09-25","objectID":"/django/:5:9","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"包含其它的URLconfs 在任何时候，你的urlpatterns都可以include其它URLconf模块。这实际上将一部分URL放置于其它URL下面。 from django.urls import include, path urlpatterns = [ ... path('community/', include('abc.urls')), ] 当Django遇到include()，它砍掉任何匹配到该点和该URL的一部分发送所述剩余的字符串所包含的URL配置用于进一步的处理。 from django.urls import include, path from app.main import view as main_views from credit import views as credit_views extra_patterns = [ path('reports/', credit_views.report), path('reports/\u003cint:id\u003e/', credit_views.report), path('charge/', credit_views.charge), ] urlpatterns = [ path('', main_views.homepage), path('help/', include('apps.help.urls')), path('credit/', include(extra_patterns)), ] 这个栗子中，/credit/reports/ URL将被credit_views.report()这个Django视图处理。 这种方法可以用来去除URLconf中的冗余，其中某个模式前缀被重复使用。如: from django.urls import path from . import views urlpatterns = [ path('\u003cpage_slug\u003e-\u003cpage_id\u003e/history/', views.history), path('\u003cpage_slug\u003e-\u003cpage_id\u003e/edit/', views.edit), path('\u003cpage_slug\u003e-\u003cpage_id\u003e/discuss/', views.discuss), path('\u003cpage_slug\u003e-\u003cpage_id\u003e/permissions/', views.permissions), ] # 改进它 urlpatterns = [ path('\u003cpage_slug\u003e-\u003cpage_id\u003e/', include([ path('history/', views.history), path('edit/', views.edit), path('discuss/', views.disscuss), path('permissions/', views.permissions), ])), ] 捕获的参数 被包含的URLconf会收到来自父URLconf捕获的任何参数: # settings/urls/main.py from django.urls import include, path urlpatterns = [ path('\u003cusername\u003e/blog/', include('foo.urls.blog')), ] # foo/urls/blog.py from django.urls import path from . import views urlpatterns = [ path('', views.blog.index), path('archive/', views.blog.archive), ] 在上面的栗子中，捕获的username变量将被如期传递给include()执行的URLconf。 \r\r","date":"2019-09-25","objectID":"/django/:5:10","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"传递额外选项到视图函数 URLconfs有一个hooks，可以传递额外的参数给视图函数，作为Python字典。 The path() function can take an optional third argument which should be a dictionary of extra keyword arguments to pass to the view function. from django.urls import path from . import views urlpatterns = [ path('blog/\u003cint:year\u003e/', views.year_archive, {'foo': 'bar'}), ] # In this example, for a request to /blog/2005/, Django will call views.year_archive(request, year=2005, foo='bar'). 传递额外选项到include() # main.py from django.urls import include, path urlpatterns = [ path('blog/', include('inner'), {'blog_id': 3}), ] # inner.py from django.urls import path from mysite import views urlpatterns = [ path('archive/', views.archive), path('about/', views.about), ] \r\r","date":"2019-09-25","objectID":"/django/:5:11","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"URLs的反向解析 Django项目工作时的一个常见需要是获得 URLs 它们的最终形式或用于在生成的内容中嵌入的 URL 的可能性为在服务器上的导航流处理测(重定向)。 强烈希望避免硬编码(hard-coding)这些URLs（费力，不可扩展且容易出错）。同样危险的是ad-hoc机制，以产生平行于所述 URLconf 描述的设计，这可能导致生成的 URLs 随着时间的推移而变得陈旧。 换句话说，需要一个 DRY 机制。在其它优点将允许 URL 设计的进化，而不必去复习所有项目的源代码来查找和替换过时的URLs。 Django提供了一个解决方案，以使 URL 映射器 是 URL 设计的唯一仓库。用你的 URL 喂养它，那么它可以在两个方向上使用: 与 user/browser 请求的 URL 开始，它调用正确的Django视图提供任意参数给需要从URL提取它的值。 与标识对应的Django视图将被传递给它的参数的值开始，获得相关的URL。 第一个前面讨论过，第二个是所谓的 URL 的反向解析、URL 反向匹配、 URL 反向查找或 URL 反转。 Django提供了用于执行 URL 反向，匹配不同层 URLs 的需要: Template: 使用url template tag Python code: 使用 reverse() 函数 在相关的Django模型实例的URL处理更高级别的代码: get_absolute_url()方法 就是给这个path取个名字，通过名字去找路径。即使修改了路径，只要名字没有修改，在其它部分里使用path名字的部分就不需要修改。 from django.urls import path from . import views urlpatterns = [ ... path('articles/\u003cint:year\u003e/', views.year_archive, name='news-year-archive'), ] 你可通过使用这些模板代码获得: \u003ca href=\"{% url 'news-year-archive' 2012 %}\"\u003e {# Or with the year in a template context variable: #} \u003cul\u003e {% for yearvar in year_list %} \u003cli\u003e\u003ca href=\"{% url 'new-year-archive' yearvar %}\"\u003e{{ yearvar }} Archive\u003c/a\u003e\u003c/li\u003e {% end for %} \u003c/ul\u003e Or in Python Code: from django.http import HttpResponseRedirect from django.urls import reverse def redirect_to_year(request): # ... year = 2006 # ... return HttpResponseRedirect(reverse('news-year-archive', args=(year,))) \r\r","date":"2019-09-25","objectID":"/django/:5:12","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"命名URL模式 要执行URL反向，你需要使用命名的URL模式(named URL patterns)。这个名称可以包含任何你喜欢的字符，而不仅限于Python names。 选择不太可能与其它应用程序名称相冲突的名字。如果你调用URL pattern comment 和其它应用程序做同样的事，URL reverse()查找取决于哪个模式是最后在项目的 urlpattens 的列表中。 为你的URL名称放一个前缀，后去可以从应用程序的名称派生，这样降低了冲突的可能。 \r\r","date":"2019-09-25","objectID":"/django/:5:13","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"URL命名空间 URL命名空间允许你唯一地反转 named URL patterns，即使不同的应用程序使用相同的URL名称。 一个URL命名空间有两个部分，两个都是字符串: application namespace instance namespace 命名空间URL使用特定的:操作符。 命名空间同样可以嵌套。命名的URL sports:polls:index ，会在顶级命名空间sports中定义的polls的命名空间中，寻找名为index的一个模式。 反向命名空间URLs 当给定一个命名空间URL（如polls:index）来解析时，Django将分割名称为几个部分，然后尝试一下查找: 首先，Django查找 应用程序命名空间（如polls)，这将产生应用程序的实例列表。 如果有定义当前应用程序，Django查找并返回该实例的URL解析。 如果没有当前应用程序，Django查找默认应用程序实例。 如果没有默认的应用程序实例，Django会挑选最后部署的应用的实例。 如果提供的命名空间无法匹配步骤1中的应用程序命名空间，Django会尝试将此命名空间直接作为实例命名空间查找。 # urls.py from django.urls import include, path urlpatterns = [ path('author-polls/', include('polls.urls', namespace='author-polls')), path('publisher-polls/', include('polls.urls', namespace='publisher-polls')), ] # polls/urls.py from django.urls import path from . import views app_name = 'polls' urlpatterns = [ path('', views.IndexView.as_view(), name='index'), path('\u003cint:pk\u003e/', views.DetailView.as_view(), name='detail') ] 使用此设置，可能进行下面这些查找: 如果其中一个实例就是当前这个，如果我们在实例 author-polls 渲染详情页面，polls:index 将解析到 author-polls 实例页面。即两个都会导致 /author-polls/。 在 class-based view 的方法中: reverse('polls:index', current_app=self.request.resolver_match.namespace) 在 模板中: {% url 'polls:index' %} 如果没有当前实例，xxxx author-polls:index将总是解析到author-polls实例的index页面。 URL命名空间和included URLconfs included URLconfs的应用程序命名空间可通过两种方式指定： 首先，你可在 included URLconf 中设置一个 app_name 属性，它与 urlpatterns 属性同级。 # polls/urls.py from django.urls import path form . import views app_name = 'polls' urlpatterns = [ path('', views.IndexView.as_view(), name='index'), ... ] # urls.py from django.urls import include, path urlpatterns = [ path('polls/', include('polls.urls')) ] \r\r\r","date":"2019-09-25","objectID":"/django/:5:14","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"编写视图 docs: https://docs.djangoproject.com/zh-hans/2.1/topics/http/views/ 视图函数，或 view short，是一个简单的Python函数——接收一个Web request，并返回一个Web response。这个response可以是HTML内容的Web页面，重定向，404错误，XML文档或图像…视图本身包含任意的逻辑是必要的返回响应。此代码可以选择你想要的任何地方，只要它是你的Python路径。对于将代码放在何处，默认的约定是把视图放在views.py文件中。 \r","date":"2019-09-25","objectID":"/django/:6:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"一个简单的视图 一个简单的视图，返回当期的日期和时间: from django.http import HttpResponse import datetime def current_datetime(request): now = datetime.datetime.now() html = \"\u003chtml\u003e\u003cbody\u003eIt is now %s.\u003c/body\u003e\u003c/html\u003e\" % now return HttpResponse(html) 让我们看看这个代码: 首先，我们从django.http模块导入了HttpResponse类，datetime库 接下来，我们定义了一个名为current_datetime的函数。这是视图函数，每个视图函数都接收一个HttpRequest对象作为第一个参数，通常称为请求request。 注意，视图函数的名称并不重要，它并没有以某种方式按顺序命名的Django来识别它。我们在这里调用current_datetime，因为这个名字清楚地表明它做什么。 此视图返回一个包含生成的响应的HttpResponse对象。每个视图函数负责返回HttpResponse对象。 Django’s Time Zone Django includes a TIME_ZONE setting that defaults to America/Chicago. This probably isn’t where you live, so you might want to change it in your settings file. \r\r","date":"2019-09-25","objectID":"/django/:6:1","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"映射URLs到视图 因此，要回顾一下，这个视图函数返回一个HTML页面，其中包括当前的日期和时间。要显示此视图的特定URL，你需要创建一个URLconf。 \r\r","date":"2019-09-25","objectID":"/django/:6:2","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"返回错误 在Django中返回HTTP error codes很容易。存在其它常见的HTTP状态码的HttpResponse子类(subclasses)。可在文档中找到所有可用的子类。 from django.http import HttpResponse, HttpResponseNotFound def my_view(request): # ... if foo: return HttpResponseNotFound('\u003ch1\u003ePage not found\u003c/h1\u003e') else: return HttpResponse('\u003ch1\u003ePage was found\u003c/h1\u003e') 没有对每个可能的HTTP响应码一个专门的子类，由于HttpResponse文档中，还可通过HTTP状态码到构造函数的HttpResponse创建你喜欢的任何状态码: from django.http import HttpResponse def my_view(request): return HttpResponse(status=201) 由于404错误是目前最常见的HTTP错误，处理它有简单的方法。 The Http404 exception class django.http.Http404 当你返回一个如HttpResponseNotFound的错误，你负责定义产生的错误页面的HTML: from django.http import Http404 from django.shortcuts import render from polls.models import Poll def detail(request, poll_id): try: p = Poll.objects.get(pk=poll_id) except Poll.DoesNotExist: raise Http404(\"Poll does not exist\") return render(request, 'polls/detail.html', {'poll': p}) 当Django返回一个404时，为了显示自定义的HTML，你可以创建一个名为 404.html的模板并放在模板树顶层。 \r\r","date":"2019-09-25","objectID":"/django/:6:3","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"自定义错误视图 Django的默认错误应该能满足大多数情况，但你也可以自定义行为。 # page_not_found()视图会被 handler404覆盖 handler404 = 'mysite.views.my_custom_page_not_found_view' # server_error()视图会被handler500覆盖 handler500 = 'mysite.views.my_custom_error_view' # permission_denied()视图会被handler403覆盖 handler403 = 'mysite.views.my_custom_permission_denied_view' # bad_request()会被handler400覆盖 handler400 = 'mysite.views.my_custom_bad_request_view' 参见 Use the CSRF_FAILURE_VIEW setting to override the CSRF error view. 测试自定义错误视图 为了测试自定义错误处理程序的响应，提高在测试视图中的相应的异常: from django.core.exceptions import PermissionDenied from django.http import HttpResponse from django.test import SimpleTestCase, override_settings from django.urls import path def response_error_handler(request, exception=None): return HttpResponse('Error handler content', status=403) def permission_denied_view(request): raise PermissionDenied urlpatterns = [ path('403/', permission_denied_view), ] handler403 = response_error_handler # ROOT_URLCONF must specify the module that contains handler403 = ... @override_settins(ROOT_URLCONF=__name__) class CustomErrorHandlerTests(SimpleTestCase): def test_handler_renders_template_response(self): response = self.client.get('/403/') # Make assertions on the response here. For example: self.assertContains(response, 'Error handler content', status_code=403) \r\r\r","date":"2019-09-25","objectID":"/django/:6:4","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"视图装饰器 docs: https://docs.djangoproject.com/zh-hans/2.1/topics/http/decorators/ Django提供了可应用于视图，以支持各种HTTP特征的几个装饰器(decorators)。 \r","date":"2019-09-25","objectID":"/django/:7:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"允许HTTP方法 django.views.decorators.http中的装饰器可用于限制访问基于请求方法的视图。如果条件不具备装饰器会返回django.http.HttpResponseNotAllowed。 require_http_methods(request_method_list) from django.views.decorators.http import require_http_methods @require_http_methods([\"GET\", \"POST\"]) def my_view(request): # I can assume now that only GET or POST requests make it this far pass require_GET()：装饰器要求视图只接受GET方法 require_POST()：装饰器要求视图只接受POST方法 require_safe()：装饰器要求视图只接受GET和HEAD方法。这些方法通常被认为是安全的的。 \r\r","date":"2019-09-25","objectID":"/django/:7:1","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"条件视图处理 装饰器django.views.decorators.http可用来控制特定视图的缓存行为。 condition(etag_func=None, last_modified_func=None) etag(etag_func) last_modified(last_modified_func) 这些装饰器可用来生成ETag和Last-Modified headers。 \r\r","date":"2019-09-25","objectID":"/django/:7:2","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"GZip压缩 装饰器django.views.decorators.gzip在每个视图上控制内容压缩。 gzip_page()：如果浏览器允许使用gzip压缩，这个装饰器压缩内容。 \r\r","date":"2019-09-25","objectID":"/django/:7:3","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"Vary Headers 装饰器django.views.decorators.vary可用于根据特定请求头来控制缓存。 vary_on_cookie(func) vary_on_headers(*headers) \r\r","date":"2019-09-25","objectID":"/django/:7:4","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"缓存 装饰器django.views.decorators.chache控制服务器和客户端的缓存。 cache_control(**kwargs)：此装饰器加入所有的关键字参数给它修补响应的Cache-Control头 never_cache(view_func)： 此装饰器添加Cache-Control: max-age=0, no-cache, no-store, must-revalidate头为响应指示页面不该被缓存。 \r\r\r","date":"2019-09-25","objectID":"/django/:7:5","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"文件上传 docs: https://docs.djangoproject.com/zh-hans/2.1/topics/http/file-uploads/ Django处理文件上传时，文件最终会位于attr:request.FILES\u003cdjango.http.HttpRequest.FILES\u003e \r\r\r","date":"2019-09-25","objectID":"/django/:8:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"快捷函数 docs: https://docs.djangoproject.com/zh-hans/2.1/topics/http/shortcuts/ 包django.shortcuts收集助手函数或跨堆积MVC的类。换句话说，为了方便起见，这些函数/类引入受控耦合。 \r","date":"2019-09-25","objectID":"/django/:9:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"render() `render(request, template_name, context=None, content_type=None, status=None, using=None)：将给定的模板与给定的上下文字典组合在一起，并以渲染的文本返回一个HttpResponse对象。 # 必选参数 request: 用于生成此响应的请求对象 template_name: 要使用的模板名称 # 可选参数 context: 要添加到模板上下文的值的字典 content_type 用于结果文档的MIME类型默认行为 status: 响应的状态码，默认200 using: 用于加载模板的模板引擎 栗子: from django.shortcuts import render def my_view(request): # view code here return render(request, 'myapp/index.html', {'foo': 'bar'}, content_type='application/xhtml+xml') 此栗子相当于: from django.http import HttpResponse from django.template import loader def my_view(request): # view code here... t = loader.get_template('myapp/index.html') c = {'foo': 'bar'} return HttpResponse(t.render(c, request), content_type'application/xhtml+xml) \r\r","date":"2019-09-25","objectID":"/django/:9:1","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"redirect() redirect(to, permanent=False, *args, **kwargs) # 将一个HttpResponseRedirect返回传递到参数的适当URL - A model: the model's get_absolute_url() function will be called. - A view name, possibly with arguments: reverse() will be used to reverse-resolve the name. - An absolute or relative URL, which will be used as-is for the redirect location. By default issues a temporary redirect; pass permanent=True to issue a permanent redirect. 栗子: 你可以在多种方式中使用redirect()函数。 # By passing some object; that object's get_absolute_url() method will be called to figure out the redirect URL from django.shortcuts import redirect def my_view(request): ... obj = MyModel.objects.get(...) return redirect(obj) # By passing the name of a view and optionally some positional or keyword arguments; the URL will be reverse resolved using the reverse() method def my_view(request): ... return ridirect('some-view-name', foo='bar') # By passing a hardcoded URL to redirect to def my_view(request): ... return redirect('/some/url/') # This also works with full URLs def my_view(request): ... return redirect('https://example.com/') # 默认情况下，redirect()返回一个临时重定向。设置parmanent=True修改为永久 def my_view(request): ... obj = MyModel.objects.get(...) return redirect(obj, permanent=True) \r\r","date":"2019-09-25","objectID":"/django/:9:2","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"get_object_or_404() get_object_or_404(klass, *args, **kwargs) # Calls get() on a given model manager, but it raises Http404 instead of the model's DoesNotExist exception. # 必选参数 klass # A Model class, a Manager, or a QuerySet instance from which to get the object. **kwargs # Lookup parameters, which should be in the format accepted by get() and filter(). 栗子: from django.shortcuts import get_object_or_404 def my_view(reqeust): obj = get_object_or_404(MyModel, pk=1) # 此栗相当于 from django.http import Http404 def my_view(request): try: obj = MyModel.objects.get(pk=1) execpt MyModel.DoesNotExist： raise Http404(\"No MyModel matches the given query.\") \r\r","date":"2019-09-25","objectID":"/django/:9:3","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"get_list_or_404() get_list_or_404(lkass, *args, **kwargs) # Returns the result of filter() on a given model manager cast to a list, raising Http404 if the resulting list is empty. # 必选参数 klass # A Model, Manager or QuerySet instance from which to get the list. **kwargs # Lookup parameters, which should be in the format accepted by get() and filter(). 栗子: # Get all published objects from MyModel from django.shortcuts import get_list_or_404 def my_view(request): my_objects = get_list_or_404(MyModel, published=True) # 此栗子相当于 from django.http import Http404 def my_view(reqeust): my_objects = list(MyModel.objects.filter(published=True)) if not my_objects: raise Http404(\"No MyModel matches the given query.\") \r\r\r","date":"2019-09-25","objectID":"/django/:9:4","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"通用视图 docs: https://docs.djangoproject.com/zh-hans/2.1/topics/http/generic-views/ docs: https://docs.djangoproject.com/zh-hans/2.1/ref/class-based-views/ \r","date":"2019-09-25","objectID":"/django/:10:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"基本视图与通用视图 Base class-based views 可以被认为是父视图，其可以通过本身被使用，或者从继承。它们可能不提供所有项目所需要的功能，在这种情况下，有混入其中的扩至基视图可以做。 Django generic views are built off of those base views，被开发作为一个快捷功能，用于公共使用模式（如显示对象的详细信息）。They take certain common idioms and patterns found in view development and abstract them so that you can quickly write common views of data without having to repeat yourself. 大多数的通用视图需要QuerySet键——它是一个QuerySet实例。 \r\r\r","date":"2019-09-25","objectID":"/django/:10:1","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"中间件 docs: https://docs.djangoproject.com/zh-hans/2.1/topics/http/middleware/ 内检中间件: https://docs.djangoproject.com/zh-hans/2.1/ref/middleware/ 中间件是Django 请求/响应 处理的钩子框架。它是一个轻量级的、低级的插件系统，用于全局改变Django的输入或输出。 每个中间件组件负责做一些特定的功能。如Django的一个中间件组件AuthenticationMiddleware，它使用会话将用于与请求关联起来。 文档中解释了中间件是如何工作的，如何激活中间件，如何编写自己的中间件。Django具有一些内置的中间件，你可以直接使用它们。 \r\r\r","date":"2019-09-25","objectID":"/django/:11:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"如何使用会话 sessions: https://docs.djangoproject.com/zh-hans/2.1/topics/http/sessions/ Django是支持匿名会话的。会话框架允许你基于每个站点访问者存储和检索任意数据。它在服务端存储数据并提供cookie的发送和接收。 Cookie包含会话ID，而不是数据本身。 \r","date":"2019-09-25","objectID":"/django/:12:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"打开会话 会话通过配置一个中间件(django.contrib.sessions.middleware.SessionMiddleware)实现。 \r\r \r\r使用表单 docs: https://docs.djangoproject.com/zh-hans/2.1/topics/forms/ 介绍Web表单的基本内容以及它们在Django中是如何处理的。 除非搭建的网站和应用只发布内容而不接收访问者的输入，否则你就需要理解和使用表单。 Django提供了一系列的工具和库来帮助构建表单来接收网站访问者的输入，然后处理以及响应这些输入。 \r","date":"2019-09-25","objectID":"/django/:12:1","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"HTML表单 在HTML中，表单是在\u003cform\u003e...\u003c/form\u003e中的一些元素，它允许访客做一些类似输入文档、选择选项、操作对象或空间等动作，然后发送这些信息到服务端。 一些表单界面元素(文本框或复选框)非常简单并内置在HTML中。其它会复杂些，如弹出日期选择、允许你移动滑块或操作控件，一般通过使用JavaScript，CSS以及HTML表单中的\u003cinput\u003e元素来实现这些效果。 表单必须指定两样东西: 何地: 负责响应用户输入数据的URL地址 如何: 数据如何请求使用的HTTP方法 例如，Django admin登录表单包含了一些\u003cinput\u003e元素： 用户名用type=\"text\"，密码用type=\"password\"，登录按钮用type=\"submit\"。 它还包含一些用户看不到的隐藏文本字段，Django用它们来决定下一步行为。 它还告诉浏览器表单数据应该发往\u003cform\u003e的action属性指定的URL——`/admin/`，并且应该使用method属性指定的HTTP方法——post。 当\u003cinput type=\"submit\" value=\"Log in\"\u003e元素被触发的时候，数据会发送到`/admin/`。 \rGET和POST 处理表单时只会用到GET和POST两种方法。 Django的登录表单使用POST方法传输数据，在这个方法中浏览器会封装表单数据，为了传输会进行编码，然后发送到服务端并接收它的响应。 相比之下，GET方法将提交的数据捆绑到一个字符串中，并用它来组成一个URL。该URL包含了数据要发送的地址以及一些键值对应的数据。如https://docs.djangoproject.com/search/?q=forms\u0026release=1 任何可用于更改系统状态的请求都应该使用POST。 GET方法也不适合密码表单，因为密码会出现在URL中，也是也会出现在浏览器的历史记录以及服务器的日志中，而且都是以纯文本都形式。它也不适合处理大量的数据或者二进制数据。在Web应用的管理表单中使用GET请求具有安全隐患：攻击者很容易通过模拟请求来访问系统的敏感数据。POST方法通过与其它像CSRF这样的保护措施配合使用，能对访问提供更多控制。 \r\r","date":"2019-09-25","objectID":"/django/:13:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"Django在表单中的角色 处理表单是一件挺复杂的事情。许多不同的数据可能在一张表单中准备显示，渲染成HTML，使用方便的界面进行编辑，传到服务器，验证和清理数据，然后保存或跳过进行下一步处理。 Django会处理设计表单的三个不同部分: 准备并重组数据，以便下一步的渲染 为数据创建HTML表单 接收并处理客户端提交的表单和数据 你可以手动编写代码来实现，但Django可以帮你完成所有这些工作。 \r\r","date":"2019-09-25","objectID":"/django/:14:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"Django中的表单 Web应用中所说的表单，可能指的是HTML \u003cform\u003e，或者是生成了它的Django Form，再或者是提交时返回的结构化数据，亦或是这些端到端作业的合集。 Django的Form类 Django表单系统的核心组件是Form类。它与Django模型描述对象的逻辑结构、行为以及它呈现给我们内容的形式的方式大致相同，Form类描述一张表单并决定它如何工作及呈现。 类似于模型类的字段映射到数据库字段的方式，表单类的字段会映射到HTML表单的\u003cinput\u003e元素。ModelForm通过Form映射模型类的字段到HTML表单的\u003cinput\u003e元素。 表单字段本身也是类，他们管理表单数据并在提交表单时执行验证。DateField和FileField处理的数据类型差别很大，所以必须用来处理不同的字段。 在浏览器中，表单字段以HTML控件的形式展示给我们。每个字段类型都有与之相匹配的控件类，但必要时可以覆盖。 实例化、处理和渲染表单 在Django中渲染一个对象的时候，我们通常： 在视图中获取它 将它传递给模板上下文 使用模板变量将它扩展为HTML标记 在模板中渲染表单几乎与渲染任何其他类型的对象的一样，但是存在一些关键性的差异。 如果模型实例不包含数据，在模板中对它做任何处理几乎没什么用。但完全有理由用来渲染一张空表单——当我们希望用户来填充的时候就会这么做。 所以当我们在视图中处理模型实例时，我们一般从数据库中获取它。当我们处理表单时，我们一般在视图中实例化它。 当我们实例化表单时，我们可以选择让它为空或者对它预先填充： 来自已经保存的模型实例的数据 从其它来源获取的数据 从前面一个HTML表单提交过来的数据 \r\r","date":"2019-09-25","objectID":"/django/:15:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"构建一张表单 需要完成的工作 假设你希望在你的网站上创建一张简易的表单，来获取用户的名字： \u003cform action=\"/your-name/\" method=\"post\"\u003e \u003clabel for=\"your_name\"\u003eYour name: \u003c/label\u003e \u003cinput id=\"your_name\" type=\"text\" name=\"your_name\" value=\"{{ current_name }}\"\u003e \u003cinput type=\"submit\" value=\"OK\"\u003e \u003c/form\u003e 这告诉浏览器将表单数据返回给URL /your-name/，并使用POST方法。它将显示一个标签为\"Your name:“的文本字段，以及一个\"OK\"按钮。如果模板上下文包含一个current_name变量，它会被预填充到your_name字段。 你需要一个视图来渲染这个包含HTML表单的模板，并能适当提供current_name字段。 提交表单时，发送给服务器的POST请求将包含表单数据。 现在，你还需要一个与该/your-name/ URL相对应的视图，该视图将在请求中找到相应的键值对，然后对其进行处理。 在Django中构建一张表单 Form类 # forms.py from django import forms class NameForm(forms.Form): your_name = forms.CharField(label='Your name', max_length=100) # Form表单实例有一个`is_valid()`方法，它运行所有的字段验证。当此方法被调用时，如果所有字段包含有效数据，它将会： # - 返回True # - 将表单数据放到它的cleaned_data属性中 这样整个表单在第一次渲染时，会显示如下: \u003clable for=\"your_name\"\u003eYour name: \u003c/label\u003e \u003cinput id=\"your_name\" type=\"text\" name=\"your_name\" maxlength=\"100\" required\u003e 注意它没有包含\u003cform\u003e标签和提交按钮。我们必须在模板中提供。 视图 发回Django网站的表单数据由视图来处理，一般和发布这个表单用的是同一个视图。这允许我们重用一些相同的逻辑。 为了处理表单，我们需要将它实例化到我们希望发布的URL的对应的视图中： # views.py from django.http import HttpResponseRedirect from django.shortcuts import render from .forms import NameForm def get_name(request): # if this is a POST request we need to process the form data if request.method == 'POST': # create a form instance and populate it with data from the request form = NameForm(request.POST) # check whether it's valid if form.is_valid(): # process the data in form.cleaned_data as required # ... # redirect to a new URL return HttpResponseRedirect('/thanks/') else: form = NameForm() return render(request, 'name.html', {'form': form}) 如果我们访问这个视图用的是GET请求，它会创建一个空的表单实例并将其放置在模板上下文中进行渲染。 如果表单提交用的是POST请求，那么该视图再次创建一个表单实例并使用请求中的数据填充它。form=NameForm(request.POST)，这叫绑定数据到表单。 调用表单的is_valid()方法，如果不为True，就带着表单返回到模板。这次表单不在为空，所以HTML表单将用之前提交的数据进行填充，放到可以根据需要进行编辑和修正的位置。 如果is_valid()为True，我们就能在cleaned_data属性中找到所有通过验证的表单数据。我们可以发送一个HTTP重定向告诉浏览器下一步去向之前用这些数据更新数据库或做其它处理。 模板 没有必要在模板name.html中做过多的操作。举个栗子: \u003cform action=\"/your-name/\" method=\"post\"\u003e {% csrf_token %} {{ form }} \u003cinput type=\"submit\" value=\"Submit\"\u003e \u003c/form\u003e 所有的表单字段机器属性都将通过Django模板语言从 {{ form }} 中被解包成HTML标记。 表格和跨站请求伪造保护 Django自带一个简单易用的跨站请求伪造保护。当通过POST方法提交一张启用了CSRF防护的表单时，你必须使用上例中这样的模板标签 csrf_token。但是，由于CSRF防护在模板中没有与表单直接绑定，因此这个标签在本页文档之后的示例中都将被忽略。 现在我们有了一个可以工作的Web表单，它通过一张Django Form描述，由一个视图来处理并渲染成一个HTML \u003cform\u003e。 \r\r","date":"2019-09-25","objectID":"/django/:16:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"详解Django的Form类 所有表单都作为django.forms.Form或者django.forms.ModelForm的子类来创建。 如果你的表单是要直接用来添加或编辑Django模型，用ModelForm，可以省时省力省代码，因为它会根据Model类构建一张对应字段及其属性的表单。 绑定和未绑定的表单实例 bound和unbound forms之间的区别非常重要： 未绑定的表单没有与其关联的数据。当渲染给用户时，它会是空的或者包含默认值。 绑定的表单拥有已提交的数据，因此可用来判断数据是否合法。 表单的is_bound属性将告诉你一张表单是否具有绑定的数据。 字段详解 栗子: # forms.py from django import forms class ContactForm(forms.Form): subject = forms.CharField(max_length=100) message = forms.CharField(widget=forms.Textarea) sender = forms.EmailField() cc_myself = forms.BooleanField(required=False) 控件 每个表单字段都有一个相对应的控件类，这个控件类又有对应的HTML表单控件，比如\u003cinput type=\"text\"\u003e。 字段数据 无论用表单提交了什么数据，一旦通过调用is_valid()验证成功，已验证的表单数据将被放到form.cleaned_data字典中。这里的数据已经很好的为你转化为Python类型。如cc_myself会被转化成一个布尔值。同样的，字段 IntegerField 和 FloatField 的值分别会被转化为Python的 int 和 float 类型。 栗子: # views.py from django.core.mail import send_mail if form.is_valid(): subjetct = form.cleaned_data['subject'] message = form.cleaned_data['message'] sender = form.cleaned_data['sender'] cc_myself = form.cleaned_data['cc_myself'] recipients = ['info@example.com'] if cc_myself: recipients.append(sender) send_mail(subject, message, sender, recipients) return HttpResponseRedirect('/thanks/') \r\r","date":"2019-09-25","objectID":"/django/:17:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"使用表达模板 你只需要将表单实例放到模板的上下文中即可。 表单渲染选项 额外表单模板标签 不要忘记，一张表单的输出不包含外层\u003cform\u003e标签以及submit控件。这些必须由你自己提供。 对于\u003clabel\u003e, \u003cinput\u003e对，还有其它输出选项： {{ form.as_table }}将渲染它们作为表格包裹在\u003ctr\u003e标记中 {{ form.as_p }}将渲染它们包裹在\u003cp\u003e标记中 {{ form.as_ul }}将渲染它们包裹在\u003cli\u003e标记中 注意，你必须自己提供外层的\u003ctable\u003e或\u003cul\u003e元素。 \r\r \r\r模板 templates: https://docs.djangoproject.com/zh-hans/2.1/topics/templates/ 作为一个Web框架，Django需要一种动态生成HTML的便捷方法。最常用的方法依赖于模板。模板包含所需HTML输出的静态部分以及描述动态内容将被插入的一些特殊语法。 Django项目可以配置一个或多个模板引擎（或者不使用模板引擎）。Django后端内置一个自己的模板系统，创造性地称为Django Template Language(DTL)。后端也可以使用第三方提供的其它可用的模板语言。 Django template language是Django自己的模板系统。这是一个很好的模板库，即使它是相当僵硬和使用时带有它自己特质。如果你没有紧迫的理由需要去选择另一个后端，则应该使用DTL。 Django定义了一个标准的API，用于加载和渲染模板，而不用考虑后端的模板系统。加载包括查找给定标识符的模板并对其进行预处理，通常将其编译的结果保存在内存中。渲染工具将上下文数据插入模板并返回结果字符串。 \r","date":"2019-09-25","objectID":"/django/:18:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"模板引擎的支持 TEMPLATES = [ { 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [], 'APP_DIRS': True, 'OPTIONS': { # ... some options here ... }, }, ] # BACKEND: 实现Django模板后台API，内建后台有: # - django.template.backends.django.DjangoTemplates # - django.template.backends.jinja2.Jinja2 # DIRS: 定义一个目录列表，其中模板引擎应该寻找的源文件 # APP_DIRS: 告诉引擎是否应该在安装的应用内寻找模板 \r\r \r\rDjango Template Language 参考: https://docs.djangoproject.com/zh-hans/2.1/topics/templates/ https://docs.djangoproject.com/zh-hans/2.1/ref/templates/language/ Django模板引擎提供了一种强大的mini-language，用于定义应用程序的面向用户层，鼓励应用程序和表示逻辑的清晰分离。任何了解HTML的人都可以维护模板，不需要Python的知识。 Django模板语言其实和Jinja2类似，只不过Jinja2更自由些。 \r","date":"2019-09-25","objectID":"/django/:19:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"Django模板语言 本文档解释了Django模板系统的语言语法。 Django的模板语言只在功能和易用性之间取得平衡。它旨在让那些习惯使用HTML的人感到舒服。如果你对其它模板语言(Smart, Jinja2)有任何接触，那么您应该对Django的模板感到宾至如归。 哲学 Django模板系统不仅仅是嵌入到HTML中的Python。模板系统用于表示，而不是程序逻辑。 Django模板系统提供的tags功能与某些编程结构类似——if标签用于布尔测试，for标签用于循环…但这些并不是简单地作为相应的Python代码执行，并且模板系统不会执行任意Python表达式。 \r\r","date":"2019-09-25","objectID":"/django/:20:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"模板 Templates 一个模板是一个简单的文本文件。它可以生成任何基于文本的格式(HTML, XML, CSV…)。 模板包含变量(variables)，这些变量在评估模板时将替换为值，而变量则包含控制模板逻辑的标签(tags)。 下面是一个最小的模板示例，每个元素将在后面解释。 {% extends \"base_generic.html\" %} {% block title %}{{ section.title }}{% endblock %} {% block content %} \u003ch1\u003e{{ section.title }}\u003c/h1\u003e {% for story in story_list %} \u003ch2\u003e \u003ca href=\"{{ story.get_absolute_url }}\"\u003e {{ story.headline|upper }} \u003c/a\u003e \u003c/h2\u003e \u003cp\u003e{{ story.tease|truncatewords:\"100\" }}\u003c/p\u003e {% endfor %} {% endblock %} 为什么使用基于文本而不是基于XML的模板？我们希望Django的模板语言不仅可用于XML/HTML模板。在互联网上，我们将其用于电子邮件、JS和CSV。你可将模板语言用于任何基于文本的格式。 让人类编辑XML是虐待狂! \r\r","date":"2019-09-25","objectID":"/django/:21:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"变量 Variables 变量像这样: {{ variable }}。当模板引擎遇到变量时，它会计算该变量并将其替换为结果。变量名由字母、数字和下划线组成，但不能以下划线开头。点(.)也出现在变量部分，尽管它具有特殊含义。重要的是，变量名称中不能包含空格或标点符号。 从技术上来说，当模板系统遇到一个点时，它会按照一下顺序尝试查找: 字典 属性或方法 数字索引 在上面的例子中，{{ section.title }}将替换为section对象的title属性。 如果使用不存在的 变量，模板系统将插入srting_if_invalid选项的值，默认情况下设置为空''。 请注意，模板表达式{{ foo.bar }}中的bar将被解释为文字字符串，而不使用变量bar的值(如果上下文中存在)。 可能无法访问以下划线开头的变量属性，因为它们通常被视为私有。 \r\r","date":"2019-09-25","objectID":"/django/:22:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"过滤器 Filters 你可使用过滤器(filters)修改要显示的变量。 过滤器像这样: {{ name|lower }}。这会在通过小写过滤器后显示变量的值，后者将文本转换为小写。使用管道(|)应用过滤器。 过滤器可以链接，一个过滤器的输出应用于下一个过滤器。{{ text|escape|linebreaks }}。{{ text|escape|linebreaks }}是转义文本内容，然后将换行符转换为\u003cp\u003e标签的常用习惯写法。 一些过滤会使用参数，过滤器参数如下所示: {{ bio|truncatewords:30 }}，这将显示变量bio的前30个单词。 过滤参数包含的空格必须使用引号引用，如: {{ list|join:\", \" }}。 Django提供了大约60个内置模板过滤器。可在built-in filter reference查看全部。 以下是一些常用的模板过滤器: default 如果变量为false或者为空，使用给定的默认值。 {{ value|default:\"nothing\" }} length 返回值得长度，使用与strings和lists。 {{ value|length }} filesizeformat 将值格式化为人类可读的文件大小(12KB, 2MB…) {{ value|filesizeformat }} 当然，你可以创建自己的自定义模板过滤器。 \r\r","date":"2019-09-25","objectID":"/django/:23:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"标记 Tags 标记像这样: {% tag %}。标签比变量更复杂：有些在输出中创建文本，有些通过执行循环或逻辑来控制流，有些则将外部信息加载到模板中以供以后的变量使用。 有些标签需要开始和结束标记: {% tag %}…{% endtag %}。 Django附带了大约24个内置模板标签。可查看build-in tag reference。 下面是一些常用的标记: for 循环遍历数组中的每个项。 \u003cul\u003e {% for athlete in athlete_list %} \u003cli\u003e{{ athlete.name }}\u003c/li\u003e {% end for %} \u003c/ul\u003e if, elif, else {% if athlete_list %} Number of athletes: {{ athlete_list|length }} {% elif athlete_in_locker_room_list %} Athletes should be out of the locker room soon! {% else %} No athletes. {% enfif %} 可在if标记中使用过滤器和操作符: {% if athlete_list|length \u003e 1 %} Team: {% for athlete in athlete_list %} ... {% endfor %} {% else %} Athlete: {{ athlete_list.0.name }} {% endif %} block, extends 设置模板继承template inheritance，这是一种在模板中减少样板(boilerplate)的强大方法。 你可以创建自己的自定义模板标记。 \r\r","date":"2019-09-25","objectID":"/django/:24:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"注释 Comments 注释的语法为: {# #}。 例如，此模板将呈现为hello: {# greeting #}hello。 \r\r","date":"2019-09-25","objectID":"/django/:25:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"模板继承 Templates inheritance Django模板引擎最强大，也是最复杂的就是模板继承。模板继承允许你构建一个基础骨架模型，其中包含站点的所有常用元素(elements)，并定义子模块可以覆盖的块(block)。 理解模板继承的栗子(base.html): \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003clink rel=\"stylesheet\" href=\"style.css\"\u003e \u003ctitle\u003e{% block title %}My amazing site{% endblock %}\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cdiv id=\"sidebar\"\u003e {% block sidebar %} \u003cul\u003e \u003cli\u003e\u003ca href=\"/\"\u003eHome\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"/blog/\"\u003eBlog\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e {% endblock %} \u003c/div\u003e \u003cdiv id=\"content\"\u003e {% block content %}{% endblock %} \u003c/div\u003e \u003c/body\u003e \u003c/html\u003e 定义了一个简单的HTML框架文档，你可将其用于简单的双列页面。子模板的工作是用内容填充空块(empty block)。 在此示例中，块标记(block)定义了子模块可以填充的三个块。所有块标记的作用是告诉模板引擎子模块可以覆盖模板的这些部分。 子模板栗子: {% extends \"base.html\" %} {% block title %}My amazing blog{% endblock %} {% block content %} {% for entry in blog_entries %} \u003ch2\u003e{{ entry.title }}\u003c/h2\u003e \u003cp\u003e{{ entry.body }}\u003c/p\u003e {% endfor %} {% endblock %} 扩展标记(extends)是这里的关键。它告诉模板引擎改模板扩展另一个模板。当模板系统评估此模板时，它首先找到父模板。 此时，模板引擎会注意到base.html中的三个块标记，并将这些块替换为子模板的内容。输出可能如下: \u003c!DOCTYPE html\u003e \u003chtml lange=\"en\"\u003e \u003chead\u003e \u003clink rel=\"stylesheet\" href=\"style.css\"\u003e \u003ctitle\u003eMy amazing blog\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cdiv id=\"sidebar\"\u003e \u003cul\u003e \u003cli\u003e\u003ca href=\"/\"\u003eHome\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"/blog/\"\u003eBlog\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e \u003cdiv id=\"content\"\u003e \u003ch2\u003eEntry one\u003c/h2\u003e \u003cp\u003eThis is my first entry.\u003c/p\u003e \u003ch2\u003eEntry two\u003c/h2\u003e \u003cp\u003eThis is my second entry.\u003c/p\u003e \u003c/div\u003e \u003c/body\u003e \u003c/html\u003e 请注意，由于子模块未定义sidebar块，因此将使用父模板中的值。 你可以根据需要使用尽可能多的继承级别。使用继承的一种常见方法是以下三级(three-level)方法: 创建base.html基础模板，其中包含网站的主要外观 为网站的每个部分(section)创建一个base_SECTIONNAME.html模板，这些模板都扩展基础模板，并包含特定于部分的样式设计 为每种类型的页面创建单独的模板，这些模板扩展了相应部分的模板 这种方法可以最大化代码重用，并且可以轻松地将项目添加到共享内容区域。 以下是使用继承的一些技巧与提示: 如果在模板中使用{% extends %}，则它必须是该模板中的第一个模板标记。否则，模板继承不起作用。 基础模板中的{% block %}标记越多越好。请记住，子模块不必定义所有父块，因此你可在多个块中填写合理的默认值，然后仅定义需要的块。 如果在许多模板中复制了内容，则可能意味着你应该将内容移动到父模板中的{% block %}。 如果需要从父模板获取块的内容，{{ block.super }}变量将起作用。如果要添加到父模块的内容而不是完全覆盖它，这将非常有用。 使用模板标记as语法在{% block %}块之外创建的变量不能在块内使用。 {% trans \"Title\" as title %} {% block conten %}{{ title }}{% endblock %} 为了提高可读性，可选择为{% endblock %}标记指定名称。在较大的模板中，此技术可帮助查看正在关闭的块标记。 {% block content %} ... {% endblock conten %} 最后，请注意，你无法在同一模板中定义多个名称相同的块标记。 \r\r","date":"2019-09-25","objectID":"/django/:26:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"自动HTML转义 Automatic HTML escaping 当从模板生成HTML时，变量将始终存在影响生成的HTML的字符的风险。 考虑这个模板片段: Hello {{ name }} 首先，这似乎是一种显示用户名的无害方式。但考虑如果用户输入其名称会发生什么: \u003cscript\u003ealert('hello')\u003c/script\u003e 使用此名称值，模板将呈现为: Hello, \u003cscript\u003ealert('hello')\u003c/script\u003e 这意味着浏览器会弹出一个JS警告框！ 类似地，如果名称包含\u003c符号: \u003cb\u003eusername 这将导致像这样的渲染模板: Hello, \u003cb\u003eusername 反过来，这将导致网页的其余部分被加粗。 显然，用户提交的数据不应盲目信任并直接插入到你的网页中，因为恶意用户可能会利用这种漏洞来做坏事。此类安全漏洞称为跨站点脚本(XSS, cross site scripting)攻击。 要避免此问题，有两种选择: 一，可以确保通过转义过滤器运行每个不受信任的变量，该过滤器可将可能有害的HTML字符转换为无害的HTML字符。这是Django最初几年的默认解决方案，但问题在于它让你有责任确保你逃避一切。 二，可利用Django的自动HTML转义功能。 默认情况下，Django中的每个模板都会自动转义每个变量标记的输出。具体来说，这五个字符被转义: \u003c被转换为\u0026lt; \u003e被转换为\u0026gt; '被转换为\u0026#39; \"被转换为\u0026quot; \u0026被转换为\u0026amp; 同样，我们强调默认情况下已启用此行为。如果你正在使用Django的模板系统，那么你将受到保护。 \r\r","date":"2019-09-25","objectID":"/django/:27:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"如何关闭 如果不想自动转义数据，则可通过多种方式将其关闭。 单独的变量(individual bariables) 使用safe过滤器。 This will be escaped: {{ data }} This will not be escaped: {{ data|safe }} 模板块(template block) 将模板包装在autoescape标记中。它将on或off作为其参数。 {% autoescape off %} Hello {{ name }} {% endautoescape %} \r\r","date":"2019-09-25","objectID":"/django/:27:1","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"字符串文字和自动转义 String literals and automatic escaping 如前面所说，过滤参数可以是字符串: {{ data|default:\"This is a string literal.\" }} \r\r","date":"2019-09-25","objectID":"/django/:27:2","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"访问方法调用 Accessing method calls Most method calls attached to objects are also available from within templates. 这意味着，模板必须比类属性和从视图中传递的变量获得更多的访问。 {% for comment in task.comment_set.all %} {{ comment }} {% endfor %} 你可以轻松访问你明确对自己的模型定义的方法: # models.py class Task(models.Model): def foo(self): return \"bar\" {{ task.foo }} \r\r","date":"2019-09-25","objectID":"/django/:28:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"自定义tag和filter库 某些应用程序提供了自定义的标签和过滤器库。要访问这些模板，确保应用在INSTALLED_APPS中，然后在模板中使用load标记. {% load humanize %} {{ 45000|intcomma }} load标记载入humanize标记库，然后就可以使用intcomma过滤器。 load标记可载入多个: {% load humanize i18n %} \r\r \r\r基于类的视图 class-based-views: https://docs.djangoproject.com/zh-hans/2.1/topics/class-based-views/ 视图是可调用的，能接受用户的请求并返回响应。视图远不止是个函数，Django提供了一些可用作视图的类的示例，允许你通过继承和复用构建自己的视图并且复用这些代码。 \r","date":"2019-09-25","objectID":"/django/:29:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"基于类的视图 intro: https://docs.djangoproject.com/zh-hans/2.1/topics/class-based-views/intro/ 基于类的视图提供了实现视图作为Python对象来替代函数。相比基于函数的视图，它们不取代基于函数的视图，但有一定的差异和优势： Organization of code related to specific HTTP methods (GET, POST, etc.) can be addressed by separate methods instead of conditional branching. Object oriented techniques such as mixins (multiple inheritance) can be used to factor code into reusable components. \r\r\r","date":"2019-09-25","objectID":"/django/:30:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"内置的基于类的通用视图 Built-in class-based generic views: https://docs.djangoproject.com/zh-hans/2.1/topics/class-based-views/generic-display/ 编写Web应用程序可以是单调的，因为我们一次又一次地重复某些模式。Django视图带走一些在模型和模板层千篇一律的单调，但Web开发者也在视图层级遇到了这些无聊的单调。 Django的通用视图被开发来缓解此问题。他们采取的在视图中开发和抽象的发现，让你能快速地编写普通视图，而无需编写大量代码。 我们我们可以发现一些常见的任务，比如显示对象的列表，并编写任何对象列表的代码。然后有问题的模型可以作为一个额外的参数传递到URLconf。 Django自带的通用视图能做到以下几点： 为单个对象显示列表和详细页面。如果我们创建一个应用程序来管理会议，那么TalkListView和RegisteredUserListView就应是列表视图的栗子。一个单一的talk page是我们成detail view的例子。 在基于日期(year/month/day)归档页的对象，associated detail, and “latest” pages 允许用户创建、更新和删除对象——是否授权 总之，这些视图提供了方便的接口来执行最常见的任务，以帮助开发者解决遇到的问题。 \r\r\r","date":"2019-09-25","objectID":"/django/:31:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"基类视图和表单处理 Form handling with class-based views: https://docs.djangoproject.com/zh-hans/2.1/topics/class-based-views/generic-editing/ 表单处理通常有3条路径： Initial GET (blank or prepopulated form) POST with invalid data (typically redisplay form with errors) POST with valid data (process the data and typically redirect) 实现此常常导致自己有大量重复的样板代码。为了帮助避免此情况，Django提供的通用基于类视图的集合来处理表单处理。 \r\r\r","date":"2019-09-25","objectID":"/django/:32:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"基类视图混入 Using mixins with class-based views: https://docs.djangoproject.com/zh-hans/2.1/topics/class-based-views/mixins/ 警告 这是一个高级的话题。 Django内置的基类视图提供了许多功能，但其中某些你可能要分开使用。例如，你可能想编写一个视图，来渲染模板生成HTTP response，但是你不能使用TemplateView。或许你需要渲染仅POST模板，GET是另外一回事。虽然你可直接使用TemplateResponse，这将有可能导致重复的代码。 出于这个原因，Django还提供了许多离散功能的混入。模板渲染，例如，被封装在TemplateResponseMixin。 \r\r\r","date":"2019-09-25","objectID":"/django/:33:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"例子 Django提供了适合广泛应用的基视图类。所有视图从View class继承，它处理链接到URLs的视图，HTTP方法调度等简单功能的视图继承。RedirectView是一个简单的HTTP重定向，并且TemplateView扩展基类使其也呈现渲染的模板。 \r\r\r","date":"2019-09-25","objectID":"/django/:34:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"简单使用 使用通用视图组件但的方法是直接在URLconf中创建它们。如果你只改变一个基类视图的几个简单属性，你可以简单地将它们传递到as_view()方法来调用自身： from django.urls import path from django.views.generic import TemplateView urlpatterns = [ path('about/', TemplateView.as_view(template_name=\"about.html\")), ] 传递给as_view()的任何参数将覆盖在类中设置的属性。在此例中，在TemplateView设置template_name。类似的覆盖模式可用于RedirectView的url属性。 \r\r\r","date":"2019-09-25","objectID":"/django/:35:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"子类通用视图 第二种，更强大的方式去使用通用视图是从现有视图继承和在子类中提供新值或方法覆盖属性或方法。 # some_app/views.py from django.views.generic import TemplateView class AboutView(TemplateView): template_name = \"about.html\" # urls.py from django.urls import path from some_app.views import AboutView urlpatterns = [ path('aboug/', AboutView.as_view()), ] \r","date":"2019-09-25","objectID":"/django/:36:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"支持其它HTTP方法 from django.urls import path from books.views import BookListView urlpatterns = [ path('books/', BookListView.as_view()), ] from django.http import HttpResponse from django.views.generic import ListView from books.models import Book class BookListView(ListView): model = Book def head(self, *args, **kwargs): last_book = self.get_queryset().latest('publication_date') response = HttpResponse('') # RFC 1123 date format response['Last-Modified'] = last_book.publication_date.strftime('%a, %d%b %Y %H:%M:%S GMT') return response \r\r \r\r迁移 Migrations: https://docs.djangoproject.com/zh-hans/2.1/topics/migrations/ 迁移是将你对模型的改变传播到你的数据库架构的Django方法。它被设计的目的主要是自动，但你需要知道什么时候才能迁移。当运行它们，你可能会遇到常见的问题。 \r","date":"2019-09-25","objectID":"/django/:36:1","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"命令 与迁移和Django处理数据库交互的几个命令： migrate：负责applying和unapplying migrations makemigrations: 负责创建一个基于你对你的模型所做的更改的新的迁移 sqlmigrate: 显示一个迁移的SQL语句 showmigrations: 列出项目迁移及其状态 你应该考虑迁移为你的数据库模式的版本控制系统。makemigrations是负责包装你的模型改变为个体迁移文件——类似于提交(commit)。migrate是负责应用(applying)你的数据库。 每个应用程序的迁移文件位于该应用程序内部的migrations目录，设计于commit和sidtributed，他是代码库的一部分。你应该在你的开发机上运行它们一次，然后在你同事的机器上运行相同的迁移，并最终在生产机上运行。 \r\r\r","date":"2019-09-25","objectID":"/django/:37:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"后端支持 迁移支持Django的所有后端。 PostgreSQL MySQL SQLite \r\r\r","date":"2019-09-25","objectID":"/django/:38:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"工作流 迁移的工作很简单。修改模型，然后运行makemigrations: python manage.py makemigrations 你的模型将被扫描，并且与当前包含在迁移文件的版本进行比较，然后一组新的迁移会被写出来。请务必阅读makemigrations的输出，它并不完美，对于复杂的变化可能无法检测到你所期望的那样。 一旦有了新的迁移文件，你应该把它们应用到你的数据库，以确保它们达到预期效果: python manage.py migrate Operations to perform: Apply all migrations: books Running migrations: Rendering model states... DONE Applying books.0003_auto... OK 一旦迁移已应用，提交迁移和模型改变到你的版本控制系统作为一个单个提交(singel commit)。这样，当其他开发者check out代码时，他们将同时获得模型的改变并在同一时间执行迁移。 你可以为迁移取一个有意义的名称: python manage.py makemigrations --name changed_my_model your_app_label \r","date":"2019-09-25","objectID":"/django/:39:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"版本控制 由于迁移是存储在版本控制中，你会偶尔遇到你和另一个开发人员在同一个应用上都有提交一个迁移，导致两个开发人员的迁移有相同迁移编号。 别担心，这些数字编号只是在开发者那里参考，Django只关注每个迁移有一个不同的名称。迁移指定它们依赖于哪些迁移——包括同一应用前面的迁移。 发生这些情况时，Django会提示你，给你一些选项。 \r\r\r","date":"2019-09-25","objectID":"/django/:39:1","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"依赖 虽然迁移的每个程序，通过你的模型隐含的表和关系太复杂，无法在同一时间仅一个程序创建。 当你依赖别的东西来运行迁移，所产生的迁移将包含在迁移的依赖上。 在限制单一应用的依赖行为为影响大部分迁移操作。限制到一个单一应用(makemigrations or migrate)是尽力的承诺，而不是保证。需要任何其它程序使用，以获得正确的依赖。 \r\r\r","date":"2019-09-25","objectID":"/django/:40:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"迁移文件 迁移存储为磁盘上的格式，这里成为迁移文件(migration file)。这些文件实际上是商定布局和声明样式的普通的Python文件。 一个基本的迁移文件: from django.db import migrations, models class Migration(migrations.Migration): dependencies = [('migrations', '0001_initial')] operations = [ migrations.DeleteModel('Tribble'), migrations.AddField('Author', 'rating', models.IntegerField(default=0)), ] \r\r\r","date":"2019-09-25","objectID":"/django/:41:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"向应用添加迁移 向新应用添加迁移很简单，一旦你做了一些改动，只需运行makemigrations。 如果你的应用已经有模型和数据库表，并且没有迁移。你需要转化它使用迁移，一个例子: python manage.py makemigrations your_app_label 这将为你的应用执行一个新的初始迁移。现在，执行python manage.py migrate --fake-initial，Django会检测你有一个初始迁移，它想创建的表已经存在，并将标识这些迁移为已经应用。 注意，这仅适用于给定的两件事： 你创建了表但没有改变你的模型。 你没有手动编辑你的数据库——Django将无法检测到与模型不匹配的数据库，你只得到迁移错误时尝试修改这些表。 \r\r\r","date":"2019-09-25","objectID":"/django/:42:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"历史模型 当运行迁移时，Django是从存储在迁移文件中的模型的历史版本进行工作。 \r\r\r","date":"2019-09-25","objectID":"/django/:43:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["backend"],"content":"数据迁移 与改变数据库模式一样，你也可以使用迁移数据库本身的数据。这通常称为数据迁移，最好把它写成单独地迁移，刚在模型架构迁移的旁边。 Djaong不能为你自动生成数据迁移。 首先，生成一个空的迁移文件: python manage.py makemigrations --empty yourappname 接着，打开此文件: # Generated by Django A.B on YYYY-MM-DD HH:MM from django.db import migrations class Migration(migrations.Migration): dependencies = [ ('yourappname', '0001_initial'), ] operations = [ ] \r\r \r\r管理文件 Managing files: https://docs.djangoproject.com/zh-hans/2.1/topics/files/ 此文档描述那些由用户上传的Django的文件的访问API。 \r\r \r\r测试 Testing in Django: https://docs.djangoproject.com/zh-hans/2.1/topics/testing/ \r\r \r\r用户认证 Django Auth: https://docs.djangoproject.com/zh-hans/2.1/topics/auth/ Django自带了一个用户认证系统。它处理用户账户、组、权限和基于cookie的用户会话。这一部分文档介绍了如何实现开箱即用。 \r\r \r\r缓存框架 Cache framework: https://docs.djangoproject.com/zh-hans/2.1/topics/cache/ \r\r \r\r条件视图处理 Conditional view processing: https://docs.djangoproject.com/zh-hans/2.1/topics/conditional-view-processing/ \r\r \r\r加密签名 Cryptographic signing: https://docs.djangoproject.com/zh-hans/2.1/topics/signing/ 发送邮件 Sending email: https://docs.djangoproject.com/zh-hans/2.1/topics/email/ \r\r \r\r国际化和本地化 i18n: https://docs.djangoproject.com/zh-hans/2.1/topics/i18n/ \r\r \r\r日志 Logging: https://docs.djangoproject.com/zh-hans/2.1/topics/logging/ Django使用Python内置的logging模块处理系统日志。 \r\r \r\r分页 Pagination: https://docs.djangoproject.com/zh-hans/2.1/topics/pagination/ Django提供了一些类来帮助你管理分页数据——跨页分割(Previous/Next)。它们位于django/core/paginator.py。 \r\r \r\r安全 Security: https://docs.djangoproject.com/zh-hans/2.1/topics/security/ Django的安全功能的概述。 \r\r \r\r性能和优化 本文档概述了一些技术和工具，这些技术和工具可以帮助您更有效地运行Django代码——更快，并且使用更少的系统资源。 \r\r \r\r序列化Django对象 Serialization: https://docs.djangoproject.com/zh-hans/2.1/topics/serialization/ Django的序列化框架提供了translating Django Model成其它格式的机制。 \r\r \r\r设置 Settings: https://docs.djangoproject.com/zh-hans/2.1/topics/settings/ Django的settings文件包含Django应用的所有配置项。 \r\r \r","date":"2019-09-25","objectID":"/django/:44:0","tags":["django","python"],"title":"Django","uri":"/django/"},{"categories":["Automotive"],"content":"参考: GT赛车 《Beyond The Apex》 \r\r\r\r序 最近在PS4上购置了GTSport赛车游戏，刷知乎的时候看到GT赛车附赠了有关于汽车知识的书籍 《Beyond The Apex》 。出于好奇，在网上下载了这两本书的PDF版本，来帮助我学习相关汽车知识。谢谢网友对书籍的分享！ \r\r \r\r汽车工程 Engineering for Automotive \r","date":"2019-07-16","objectID":"/beyondtheapex/:0:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"汽车的工学 一般人与专业技师对汽车的印象，之所以会有这么大的差异，决定性的因素就在于是否拥有工学的基础知识。因此，接下来我们将解说专业汽车技师拥有的工学基础知识，希望能尽可能填补两者之间的落差。 第一节： 将介绍基本的机械力学，力、力矩、能量等概念，并导入振动的理论。力、力矩、能量是所有工学的基础。 第二节： 将介绍车辆运动力学与悬吊系统的调校。 第三节： 将介绍汽车引擎的基础知识——热力学与统计力学。 第四节： 将介绍空气力学。 第五届： 将介绍流体力学(CFD)。 本书中介绍的工学理论，对于专业的汽车技师来说，都是最基础的内容。不过，对于一般人来说可能比较陌生，要从头看到尾也有点困难。出现这种情况时，请先选择自己感兴趣的部分阅读即可。 \r","date":"2019-07-16","objectID":"/beyondtheapex/:1:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"力、力量与振动 \r","date":"2019-07-16","objectID":"/beyondtheapex/:2:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"力与力矩的概念 行驶中的车辆，有各种力与力矩在作用。理解对车子产生作用的力与力矩，就是理解汽车原理的第一步。 力的定义 轮胎、悬吊系统、引擎……，汽车在行驶时，会有各种力发生于这些部分。这些作用力都是由不同的现象所引发，在直觉上或许会认为其种类也各不同。不过，从物理学角度而言，这些力全部都可以用$$F=ma$$（力量=质量x加速度），这个简单公式来代表，在本质上完全相同。 所谓力，就是改变物理的速度或运动方向的作用。反过来说，如果物理正在加速或加速，就一定有力在作用。例如，轮胎与地面之间产生的摩擦力可以改变汽车这个拥有质量的物体的运动方向或速度。避震器的阻尼力具有降低车体与轮胎振动速度的功效。 力矩的定义 若在行驶过程中转动方向盘，轮胎会产生与行驶方向垂直的力，车身的方向因而改变。车身会以为轮胎的作用力，而进行偏航运动。这种让有体积的物体出现旋转运动的作用，就称为力矩。所谓力矩，是因与旋转轴的举例，加重作用力力道的力量，以数学公式表示，就是$$M=LxF$$(力矩=旋转轴的距离x力)。 若将车子的重心位置设定于旋转轴，则前轮产生的力矩大小，就等于从重心至前轮的距离x前轮产生的横向作用力。当然，在转向时，后轮也可以发挥从重心至后轮的距离x后轮产生的横向作用力的力矩，让车子朝与前轮力矩相反的方向旋转。 让我们以实际的过弯来思考一下上述的情况。转动方向盘时，前轮的力矩会变大，因而开始转向。而到了弯道定点附近，前后轮的力矩达到平衡；过了顶点之后将方向盘回正，则后轮的力矩会变大，并完成转向。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:2:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"能量的概念 了解能量守恒定律。 \r能量守恒定律 关于汽车的物理现象，可细分为力学现象、热现象、电气现象、磁力现象、化学现象……。例如，在燃油引擎的气缸当中，燃油点火爆炸时，气缸内的温度上升、活塞会被推下。此时，气缸内部发生了化学现象、热现象与力学现象。这些物理现象的种类虽然不同，但在这些 现象之间，则有一种与力迥异的共通效应，那就是能量。能量可在不同的物理现象之间相互转换，而其总量在转换前与转换后会维持恒定、不会改变。这就是所谓的能量守恒定律。 刹车是将力学能量转换为热能量的行为。 \r引擎气缸内的能量守恒 若从能量的角度，观察发生于燃油引擎气缸内的物理现象，可说是气缸内的化学能量被转换成为热能与力学能量。换言之，燃油引擎可说是从化学能量当中，颉取出对人有帮助的力学能量的装置。此时，能量守恒会确保经过转换的化学能量的量与新生成的热能量与力学能量的总和相等。而引擎将化学能量转换为对人有帮助的力学能量的比率，称为引擎效率。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:2:2","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"振动的机制 振动现象的根源是物体的质量与弹性。 \r从力学角度看振动 为了让内容更容易理解，在此用独立的砝码与弹簧来说明（我们将可产生振动现象的对象统称为振动系统）。 从能量的角度看振动 振动也可以从前文提到的能量守恒定律来观察。若从能量的角度观察振动，则振动可说是由伸缩带动的砝码的运动能量，与弹簧的弹性能量之间的交互作用。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:2:3","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"共振现象 共振是指对来自外部的激励无抵抗的状态。 考量悬吊系统与引擎的振动时，必须特别注意的是共振的现象。共振必须尽可能避免。若无法避免时，也必须尽可能降低其影响。 自由振动与固有振动数 试着拉动前面的振动系统，然后放手让它自由震动，这种状态叫做自由振动。不久后砝码与弹簧会以某个特定的频率振动。无论一开始用什么方式拉扯，最终都会以一定的振动数振动。这个振动数，是仅有弹簧的弹性与砝码的质量决定的固有振动频率，因此称为固有振动数。固有振动数是振动系统进行自发性振动的频率，在以这个频率振动时，弹簧的弹力与砝码的惯性力会随时保持平衡，能量也自然会重复交互作用。 强制振动与共振 接下来试着用手强制让前文中使用弹簧与砝码伸缩，这种状态称为强制振动。用与固有振动数不同的振动数，让弹簧与砝码伸缩时，手应该会感受到阻力。让振动系统振动时，若将固有振动数视为自然的振动频率，则对于这个振动系统而言，其它的振动数都是不自然的频率。无论从外部施加何种振动，振动系统都会尝试以对自己最自然的频率来振动，因而会感受到阻力。 如果我们让这种砝码与弹簧用固有振动数来伸缩，结果又会如何？由于此时的振动对于该振动系统来说属于自然的振动数，因此不会感到阻力。不仅如此，振动的幅度反而会配合施加的外力而逐渐增大。因为振动系统对于来自外部的激励，不仅没有抵抗，而且会将其能量完全吸收。若持续以固有振动数对其施加振动则振幅会增加到无限大。 如上所述，若以振动系统本身自发振动时的振动频率，从外部强制让它振动，则振动的振幅将会持续增大，这种现象称为共振，而此时的频率称为共振频率。 以悬吊系统为例，共振将会导致接地性与乘坐的舒适度降低；而引擎出现共振，更会导致引擎本身的损坏。因此必须极力避免共振现象发生。防止共振导致损坏的方式之一，就是配置避震器。避震器可以吸收来自砝码与弹簧振动的能量，并将之转换成热能，是放到外部。因此即使产生共振，若阻尼力可却是发挥作用，就可以房子机械损坏。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:2:4","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"阻尼力的作用 振动的状态会因阻尼力而变化。 阻尼比不同的自由振动 振动衰减的情况，回音避震器阻尼力的大小而出现差异。而表示避震器阻尼力的大小，对于质量与弹簧弹力的效果有多大影响的量化指标，就是阻尼比。 当阻尼比大于1时，表示阻尼力强过质量与弹簧，因此振动系统的运动会朝向非振动收敛。这种状态称为过阻尼(over damping)。在过阻尼的状态下，振幅会随着之间而减少、逐渐趋近于零，属于无周期运动。 而阻尼比小于1时，则阻尼力会弱于质量与弹簧的效应，振幅会随着时间减少、而振动周期则会逐渐拉长。这种状态称为阻尼不足(underdamping)。 当阻尼比等于1时，则是振动或不振动的临界状态，这种状态称为临界阻尼(criticaldamping)。 当阻尼比为0时，不会产生阻尼力，也就是避震器不会发生作用的状态，因此振幅也不会衰减。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:2:5","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"相位差 相位差就是振动的节奏的差异。 汽车通过路面的起伏时，起伏会被悬吊系统缩小，再传导至车体。在这种情况下，通常车体的振幅会比路面的起伏更为平稳。换言之，车体的振幅会先被悬吊系统缩小之后，再传导至车体。由此可知，车体振幅的响应能被缩减到何种程度，应是最重要的着眼点。要讨论振动时，对于入力能以多快的速度回应，这一点也非常重要。 振动的节奏之差异 要评估一个振动系统，对于人力会以多快的速度回应时，使用的基准就是相位差。 用固有振动数(共振频率)以外的振动数，轻质针对弹簧与砝码进行激励时，为何手会感受到阻力？手的振动节奏与振动系统的自然节奏不同所致。这种节奏上的差异，就是施加振动的方向与砝码惯性力的方向之差异。这种运动的节奏差异，就叫相位差。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:2:6","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"频率响应 应用于悬吊系统与车辆运动的解析。 频率响应与波德图 将振幅、相位差等振动系统对于激励频率(激励振动数)的回应，称为频率响应。 在分析汽车的振动现象时，通常会解析其频率响应。而解析频率响应时最常使用的，就是名为波德图的图标。 透过波德图了解阻尼系统的振动 还是使用前面的振动模型，从静止状态逐步提升激励的振动数(频率)。频率极低时的振幅比为1，换句话说，也就是激励的振幅与响应的振幅相同。不过，之后若逐步提升频率，振幅比也会随之变大，这表示响应的振幅比受入力影响而逐渐变大。而达到某一频率时，振幅比会达到最大，这就是所谓的共振。而此时的频率就是共振频率。如果再进一步提升频率，则振幅比会变小、并逐渐趋近于0.换言之，激励的振动数越高，响应的振幅也会随之逐渐趋近于0。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:2:7","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"发生于悬吊系统的振动 多自由读之振动。 悬吊系统的振动特性 汽车的悬吊系统有各种机构，但本质上是由质量与弹簧以及避震器组成的振动系统。车体与车辆之间的弹簧与避震器代表悬吊系统；车轮与路面之间的弹簧与避震器则代表轮胎弹性与阻尼。 \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:2:8","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"车辆的运动性能 \r","date":"2019-07-16","objectID":"/beyondtheapex/:3:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"轮胎的力学 理解轮胎产生的力。 转弯力 让物体滑动或扭转变形的力，称为剪应力；而物体对剪应力产生抵抗的特性，则称为剪弹性。若剪应力对轮胎朝横向作用，轮胎就会朝横向变形。不过，此时轮胎也会产生于剪应力对抗的力，尝试恢复原状。事实上，轮胎就是用抗拒让自身变形的作用力的方式，来产生车子的加速、减速、转向时所需的力。 从图中可以了解，轮胎的旋转面与车子的行进方向之间是有差异的。换言之，轮胎的力，是通过一边旋转、一边横向变形所产生。在此将旋转面如行进方向形成搞得角度，称为滑移角；而与行进方向垂直产生的力，则称为转弯力。车子之所以可以转向，就是因为轮胎可以产生如上述所述的转弯力。 一般来说，若剪弹性较大，即使滑移角相同，也会产生较大的转弯力。不过，当剪弹性过大时，些微的滑移角就可能导致摩擦饱和，使路感与车手的感觉不合；相反，如果剪弹性太弱，则会过度变形，而让车手感到不安。 转弯力与滑移角的关系 在滑移角较小的范围内，转弯力会呈直线增加；而当滑移角大到一定程度时，转弯力则会达到饱和。这种转弯力的变化比率，称为转向功率。只需些微的滑移角变化，便可产生较大转弯力的轮胎，其转向功率也比较大。 胎压与转向功率 一般来说，在胎压较低的范围内，胎压增加时，轮胎的剪弹性会提升，转向功率也会变大。不过胎压的上升，却会导致与路面的接地面积减少。换言之，接地面积与剪弹性，是针对胎压产生的相反效果。当垂直载重较小时，胎压增加造成接地面积较少的效果，会比剪弹性增加的影响更大，因此转向功率会降低。为了将转向功率提升到极限，最重要的是考量轮胎的特性与车重，在各项要素之间取得平衡。 伴随驱动与制动的轮胎横向力 从上方观察汽车时，与轮胎旋转面方向垂直产生的抓地力，称为横向力。理解横向力在驱动或制动时会产生何种变化，是非常重要的一点。踩下油门或刹车时，轮胎的抓地力被用于驱动力或制动力，所以即使在相同的滑移角下，横向力仍然会减少。赛车会随着车手的操控，而频繁进行制动与驱动，因此斜向的摩擦力，容易影响单圈时间。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:3:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"车子的稳态定圆回转 车子的转向由前后轮的力矩之平衡决定。 转向特性的定义 以一定的转向角与速度行驶的车辆，会维持特定的旋转半径画圆，这称为定圆回转(steady state cornering)。研究进行稳态定圆回转的车辆，将有助于理解车辆运动的基本特性。 假设有一台以特定速度进行稳态定圆回转的车子，我们从此状态慢慢提升其速度。若速度提升时，前轮产生的的力矩变小，则其旋转半径将会随着速度的提升而扩大，若要持续稳态定圆回转，就必须增加转向角。相较于此，若前轮的力矩变大，则旋转半径会随着速度的提升而变小，因此必须缩小转向角。 转向特性： 转向角不足的特性，称为转向不足(US)； 转向角过大的特性，称为转向过度(OS)； 旋转半径与速度的增减无关、维持一定数值，称为转向适中(NS). 必须注意的是，转向过度的车辆，在特定速度下旋转半径会变为0，也就代表车子会陷入打滑的状态。而达到打滑状态的速度，则称为稳定极限速度(stability limit speed)。 转向特性与滑移角的关系 前后轮的滑移角β前轮、β后轮与转向特性之间的关系十分有趣。 若β前轮\u003eβ后轮，则为US； 若β前轮=β后轮，则为NS； 若β前轮\u003cβ后轮，则为OS。 这种关系，与是否有转弯力以外的横向力作用于前后轮无关，也与转弯力是否和轮胎的横向力成比例无关，而是在进行稳态定远回转的车辆，以几何学来决定的关系。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:3:2","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"车辆对转向角变化之回应 车辆的运动只是一种振动现象。 转弯的机制 当转向角发生变化时，车辆会如何回应？ 偏航运动并不是在转动反向盘后立即发生，而会因车辆的惯性与轮胎的作用力发生的关系，而有短暂的时间差(相位差)存在。 转向平衡与车子的回应 车子对于车手操控的变化之回应，会受到转向特性与车速很大的影响。 US的车辆在达到一定速度后，会产生振动，但不久后就会收敛、并趋于稳态。 NS的车辆则不会产生振动，维持稳定的状态。 OS的车辆若行驶速度超过稳定极限速度，车子的回应将不会振动而出现发散，因而陷入打滑。 将振动理论适用于车辆运动 事实上，如果用阻尼比或振动频率(固有振动数)等特定的抽象概念，来观察物体的运动，可发现由质量、弹簧与避震器构成的振动系统与车辆的运动，两者完全没有差异，都可视为一个振动系统。换言之，车辆的运动只不过是一种振动现象。 US的车辆偏航阻尼的阻尼比低于1，因此会以振动方式回应。 OS的车辆偏航阻尼的阻尼比在1以上，所以其回应为非振动性。 NS的车辆则位于US与OS的分解处，也就是偏航阻尼的阻尼比为1的临界状态，其回应也属于非振动性。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:3:3","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"车辆对周期性操控的回应 以波德图了解车辆的特性。 对于转向特性与周期性操控的回应 车辆的运动只不过是一种振动现象。而接下来，则将利用振动理论检视在一定的车速下，反复转动与回正方向盘（进行周期性操控）时，若改变操控的速度（操控频率），车辆将会如何回应，今儿厘清在不同转向特性下的车辆特性。 当操控的频率极低时，不论在OS、NS、US任一特性下，振幅比都会与稳态定圆回转的偏航角速度大致相同。相反，当操控频率提升时，US的车辆会在特定频率达到高峰、振幅比也会变大；而NS与OS的车辆不会出现高峰，振幅比也会随着操控频率的增加而减少。 观察期相位图，可以发现随着操控频率的提升，不论在哪一种转向特性下，相位的延迟都会变大，但US的车辆相位延迟最小。换言之，越是转向不足的车辆，对于操控的回应就会越快。 看波德图时应留意的重点 以偏航角速度的频率为例： 1是极低频率的振幅比。这个数值与稳态定圆回转时的数值大致相同； 2是振幅比峰值的高度。US越强的车辆，偏航阻尼越小、共振则会越大，因此振幅比峰值会比较高；不过在NS与OS的车辆上，则不会出现高峰； 3是共振频率。共振频率越高，回应性愈佳，车手在操控时的路感也会愈明确； 4是相位的延迟。相位的延迟越大，针对转向角的偏航角速度发生的时间也会愈慢。因此，想要确保良好的转向特性，就必须开发出相位延迟较小的车辆。换言之，也就是US的车辆。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:3:4","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"车体的滚转与运动 将滚转运动活用于转向特性的调整。 转向中的车子，车体回想外侧滚转。实际上车辆的特性，会因为是否将滚转运动列入考量而出现差异。 相对于载重的转弯力变化 即使施加于车体的载重达到2倍，转弯力也不会增为2倍。这是因为随着载重的提升，转弯力的增幅会逐渐钝化（呈饱和曲线）。车辆转向时，会产生从内轮至外轮的移动载重。不过由于上述原因，左右转弯力的和，会比不考量移动载重的情况减少。换言之，转向造成的移动载重愈大，左右转弯力的和也会减少的多。 前后移动载重不同时的转向特性 轮胎转弯力的产生，会针对垂直载重以趋向饱和的方式变化，因此当前后的移动载重量因滚转运动而出现差异，转向特性也会随之变化。 如果是前轮的移动载重量\u003e后轮的移动载重，则转向特性回潮US方向变化； 相反，若是前轮的移动载重量\u003c后轮的移动载重，则转向特性会朝OS方向变化。 左右的移动载重量，会由于滚转运动相关的外力作用和与其相斥的车辆滚转刚性之作用的平衡关系来决定。此一关系主要是由前后的滚转中心的高低、前后的滚转刚性比，以及前轮的滚转中心的高低、前后的滚转刚性比，以及前后的轮距宽度来决定。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:3:5","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"簧上质量与簧下质量的振动 悬吊系统调校的振动特性。 车辆的上下振动，是会影响乘坐舒适度与轮胎接地性的重要问题。车体振动太大，会降低舒适度，更可能对接地面形成干扰、导致轮胎失去抓地力，因此必须仔细调校弹簧与避震器。 振动模式 簧上质量是指被悬吊系统支撑的质量；簧下质量是指位于悬吊系统与轮胎之间的质量。在此一次介绍簧上质量的弹跳振动(bounce vibration)、颠簸振动(pitching vibration)、簧下质量的上下振动。 为了便于理解，使用下图所示的模型来进行说明。 因悬吊系统调校而产生的振动模式变化 车体的共振，会导致轮胎的接地性与乘坐舒适度恶化，必须尽可能避免。此外，簧上质量的振动还会影响车体的空气力学性能（特别是对赛车而言，是一项十分重要的问题）。 簧上质量与簧下质量的上下振动，具有以下性质。若能充分理解，对于悬吊系统的调校应该有很大的帮助： 增加避震器的阻尼力，对于降低簧上质量在共振频率附近的振动十分有效，但在共振点意外的范围，反而会使振动增加； 提升避震器的阻尼力，簧上质量的共振频率也会略微提升； 变更簧上质量或弹簧的弹性，则簧上共振会大幅变化，但簧下共振则不太会变化； 变更簧下质量或轮胎的纵向刚性，则簧下共振会答复变化，但簧上的振动则不会有太大改变。 抑制颠簸运动 车辆直线前进时，从路面传导至后轮的人力，在时间上会出现轴距÷车速的延迟。若将后轮的簧上共振频率设定得比前轮略高，则后轮振动的收敛会追上前轮振动的收敛，可以抑制车辆的颠簸运动。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:3:6","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"何为运动性能优良的车子 车辆运动性的关键在于后轮。 偏航角速度的共振频率与转向特性 一般来说，车辆偏航角速度的共振频率越高，车辆的运动性能也就越利落敏捷。要提升偏航角速度的共振频率，可以通过提升后轮的转向功率、降低车子重量，或缩减偏航惯性半径等方式达成。 后轮抓地力的大小，对于车辆的运动性能十分重要。所以在调校悬吊系统时，除了要确保后轮的抓地力之外，也必须配合悬吊系统，将前后轮的抓地力最佳化。这是提升车辆运动性能时的基本概念。 车辆回应性的分类范例 \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:3:7","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"引擎与效率 \r","date":"2019-07-16","objectID":"/beyondtheapex/:4:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"温度与压力 温度与压力其实都是分子的运动。 热、温度与压力其实是由分子的运动造成的现象。问了正确理解引擎等机械的效率与能量损耗，以及将于后文中说明的空气力学（流体力学），在此最好先能掌握温度、压力相关的分子运动原理。 在密闭空间中不规则飞舞的分子样貌 请各位想象一下被密封在特定容器中的气体。以宏观角度来看，这个容器中的气体，在温度与压力都维持在均衡的状态，这种状态称为平衡状态。 不过，如果站在可观测分子动态的微观角度，观察容器内部的状态，则可以看到无数的气体分子在其中不规则地随意飞舞。有的分子以非常缓慢的速度飞舞，有的则以非常快的速度飞舞。而且分子之间会互相撞击，有时还会撞到容器的内壁，因而改变了速度。 所谓温度，是每个分子的平均运动能量 在容器中，有无数个速度各不相同的分子存在，若从能量的角度观察，即可说是容器中存在有无数个运动能量各不相同的气体分子。事实上，所谓温度，就是指每个不规则飞舞的分子平均运动能量的对应量。 若以数学方式描述，则可写成：每个分子的平均运动能量=3/2kT。（T为绝对温度、k为波茨曼常数(Boltzmann constant，也就是气体的温度、密度、压力、量及种类无关的比例常数)）。在这个公式中，力学量——每个分子的平均运动能量；热能量——温度。波茨曼常数才是扮演连结力学量与热能量的重要角色。 压力为四处飞舞的分子撞击力的平均值 气体的分子会不断撞击到容器的内部，它们有些速度快、有些速度慢；有些是垂直撞击、有些则是斜向撞击，所以每个分子的撞击力道也不相同。 不过，我们观察的所谓压力，其实是四处飞舞的无数分子，在不规则运动下的撞击力的平均值。在此要特别说明的是，在平衡状态下，上述分子撞击力的平均值，从任何一个方向测量都会得到相同的数值，不会因为量测的方向不同，压力就不同。换言之，容器中无无数的气体分子，虽然是以完全不规则的方式飞舞，但若以宏观的角度观察，撞击力其实是被平均分配至每一个方向。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:4:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"何为理想的热机 Heat Engine 完全不会产生无谓热能移动的卡诺循环(Carnot Cycle) 引擎，是可从热能量当中，以对人有助益的形式擷取出力学能量的机器。不过其效率到底是如何决定？在历史上，为了探索这个问题，而实际踏出一大步的，就是法国的卡洛。19世纪初期，卡洛以非常巧妙的论述，阐明了何为效率最高的热机，以及其效率的决定方式。他所提出的结论，成为之后开发热机时的重要指标。 卡诺留意到的两个事实 卡诺在考量何谓理想的热机时，留意到两个热能的性质。 第一，是热机在作功时，必须要有温差存在。如果没有温差，就不会发生热能的移动，也就无法让热机运作。不过，若热机内有撷取功时不需要的温度差异在，热能就只会因温差而移动，称为完全不会作功的无效率热移动。因此卡诺认为，在作功时，不靠温差进行热移动的，才是理想的热机。 第二，则是只要物体的体积或形状出现变化，即使没有温差、也可以进行热移动，这种现象称为等温变化(Isothermal change)。卡诺认为，如果能妥善运用等温变化，应该可以在不引发因温差而产生的热移动的情况下，便将功撷取出来。卡诺以上述假设为前提进行实验，并构思出不会因温差而产生无谓热移动的划时代热循环。 卡诺循环 为了明确凸显热的本质，卡诺设想出以高温与低温的热库(heat reservoir)，以及由空气充满的汽缸与活塞构成的空气引擎。下图是卡诺所设想出的热循环图： 让汽缸接触高温的热库，让热能从热库移动至汽缸内的空气，使空气膨胀。不过，由于不能在此步骤中产生温差，必须确保空气与热库的温度相同。此外，空气本身的温度也必须平均一致，不能有不均匀的情况。想要达到上述条件，必须让空气非常缓慢地逐渐膨胀。而这种以一定的温度让气体膨胀或压缩的现象，就是所谓的等温变化。 必须依照上述方式膨胀的汽缸，与低温的热库接触，但此时不可避免地会产生温差。卡诺因而利用了名为**绝热变化(adiabatic change)**的现象，也就是即使没有热能移动。若压缩气体、温度就会上升；相反，即使没有热能移动，若让气体膨胀，温度就会下降的现象。换言之，卡诺发现，只要让因高温热库而膨胀的气体，再因为绝热变化而膨胀，在没有热能移动的情况下，将气体的温度降低即可。要注意的是，在这个过程中，必须以非常缓慢的速度，让活塞动作才行。 当空气的温度下降到与低温的热库相同时，让汽缸与低温热库接触，就可让气体中的热能移动至低温的热库，同事压缩气体。如同先前说明过的，此时当然也不能有温差，所以必须以等温变化慢慢地让热能移动。 等温变化结束后，则开始利用绝热变化压缩空气，将温度提升上去。等到将空气压缩到与高温热库相同的温度时，在进行步骤1的等温膨胀，重复相同的过程。 如上所述，高温热库的等温膨胀-绝热膨胀让温度下降-低温热库的等温压缩-绝热压缩让温度上升，这4个过程进行一轮之后，汽缸的空气会恢复到与一开始完全相同的状态，在没有无谓的热移动的情况下，将热转换为工。由于以上热循环是卡诺构思开发，因此成为卡诺循环。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:4:2","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"卡诺的结论 以令人惊叹的方式将热能抽象化 卡诺循环的理论效率 经过以上说明，卡诺循环是可以达到热机最高效率的热循环。不过，卡诺的卓越之处，在于用巧妙的论述，以理论证明了由他所构思的热循环，也就是在汽缸内有温差的物体完全不会互相接触的热循环，就是最理想的热机，不会再有效率更好的热机。 更令人惊叹的是，卡诺下了一个结论——那就是这个热循环的理论效率，仅取决于高温热库与低温热库的温度。他虽然没有将这套理论定型化，不过之后英国的William Thomson将它整理、归纳为一下数学公式: $$卡诺循环的理论效率=1-\\frac{低温热库的绝对温度}{高温热库的绝对温度}$$ 将热机终极完美地抽象化 卡诺循环的理论效应，仅仅取决于热库的温度——这个由卡诺导出的结论，还证明了一项划时代的事实。那就是卡诺循环的理论效率，与热机的制作方式无关，仅仅取决于自然本身的性质。 他的理论当中，完全没有不必要的成份，也完全没有遗漏不可或缺的部分，堪称是终极完美的抽象化。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:4:3","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"汽车引擎的理论效率 何谓奥图循环、狄赛尔循环的理论效率。 奥图循环的理论效率 在了解了何谓理想的热机之后，让我们来看看一般的汽车引擎。 目前的燃油引擎，事宜Nikolaus August Otto构思出的四衝程循环——**奥图循环(otto cycle)**为基础。奥图循环包括以下四个过程：1，绝热压缩；2，定容加热；3，绝热膨胀；4，定容冷却。 定容加热、定容冷却，是指在不改变汽缸容积的情况下，将汽缸内的工作物质加热或冷却的作用。‘ 与卡诺循环相同，我们准备由高温与低温热库驱动的空气引擎，以非常缓慢的速度让活塞动作，就可以了解奥图循环是如何达到最高的效率。不过，在奥图循环中2和4的定容过程一定会产生温差，因为如果没有温差，从高温热库至空气的热移动，或是从空气至低热库的热移动就不会发生。因此，奥图循环的理论效率会低于卡诺循环，其差距就是上述温差导致热移动部分。 奥图循环的理论效率，可用以下的公式表示: $$奥图循环的理论效率=1-\\frac{1}{压缩比^{比热比-1}}$$ 狄赛尔循环的理论效率 **狄赛尔循环(Diesel cycle)**是由Rudolf Christian Karl Diesel构思出的柴油引擎热循环。狄赛尔循环主要包括一下四个过程：1，绝热压缩；2，定压加热；3，绝热膨胀；4，定容冷却。 这里所谓的定压加热，是指在不改变空气压力的情况下，将汽缸内的工作物质加热之作用。 迪赛尔循环的理论效率公式为：$$狄赛尔循环的理论效率=1-\\frac{1}{压缩比^{比热比-1}}\\frac{燃料喷射的截止比^{比热比-1}}{比热比(燃料喷射的截止比-1)}$$ 卡诺循环、奥图循环、狄赛尔循环，不论采用哪一种循环，都无法制作出可实际达成理论效率的热机。因为非常缓慢的活塞运动，根本就不具有实质上的利用价值。此外，活塞与汽缸无法完全绝热，不仅会因为温差而产生无谓的热移动，活塞与汽缸之间的摩擦，也不可能完全消除。不过厘清理论效率，可以突显热机的本质，为工程师提供重要的指标。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:4:4","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"可逆変化与不可逆变化 自然的变化具有方向。 有一个重要的自然法则，会发生能量的损耗问题。请注意。 自然是从秩序朝向无秩序变化 准备高温与低温气体的两个容器。让温度不同的两个容器接触，热会从高温的容器朝向低温的容器移动。保持这一状态，不久后两个容器的温度将会相同，热将不再移动，进入平衡状态。若以微观的角度观察，最初高温的容器中，会有比较多激烈的分子；而低温的容器中，则较少激烈飞舞的分子。而在让容器互相接触时，高温容器内的分子的运动能量会朝向低温容器移动，低温容器内的分子的运动能量因而增加。等到两个容器内的分子平均运动能量（也就是温度）相等时，运动能量（热能量）的移动就会停止。 从无秩序朝向秩序的变化不会发生 接下来再从另一个角度观察。一开始，高运动能量的分子与低运动能量的分子，分处于不同的容器当中，可以明确区别出高温容器内的分子运动与低温容器内的分子运动。换句话说，容器内有可供判别两者差异的秩序存在，而可供区别其差异的资讯，就存在该项秩序当中。不过，达到平衡状态之后，可供判别两者间差异的资讯就会消失，进入所谓无秩序的状态。 事实上，上述从有秩序的状态朝向无秩序的状态之变化，对于自然界而言是十分自然的变化；相较于此，从无秩序朝向有秩序的变化，则不会自然发生。举例来说，让高温的容器与低温的容器接触时，高温的容器会冷却、低温的容器则会加温，这对于自然界而言是十分自然的变化。相较于此，让两个温度不同的容器接触时，高温容器的温度进一步提升，而低温容器的温度反而下降，这种现象绝不会发生。 像这种不论用何种方式，都不可能将现有状态恢复到与原本完全相同的状态的变化，就称为不可逆变化；而可以复原的变化，则称为可逆变化。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:4:5","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"尝试让热机逆向运转 可逆循环与不可逆循环的差异。 到底实际上引擎为何无法达到理论效率？在可达到理论效率的热循环中，必须让活塞以非常缓慢的速度动作。 卡诺循环的逆向运转是可逆的 在此，将卡诺循环以1-2-3-4的顺序运作的情况称为顺向运转；而以4-3-2-1的顺序运行的情况称为逆向运转。 让卡诺循环进行顺向运转，让特定量的热从高温热库移动至低温热库，并将过程中产生的功存储起来。接下来再用存储的功，让卡诺循环逆向运转，使在顺向运转中移动的热，从低温热库移动至高温热库，恢复与原本完全相同的状态，不会剩下任何东西。换句话说，也就是将卡诺循环顺向运转产生的功存储起来，再用存储的功进行逆向运转，恢复到与原本完全相同的状态。之所以能做到，是因为在卡诺循环的过程中，完全没有物体相互接触，因而完全不会发生无谓的热移动。换言之，卡诺循环的所有过程都属于可逆变化，所以才能进行可逆的你想运转。 汽车引擎的逆向运转是不可逆的 如果换成奥图循环或狄赛尔循环，有会如何？在此同样让上述循环顺向运转，将过程中产生的功存储起来，再用存储的功进行逆向运转。结果发现即使将在顺向运转中存储的功完全耗尽，也只能让一部分的热复原，无法让所有的热从低温热库移动至高温热库。 原因是它们两者的定容过程中，必然会出现温差。无论如何都会产生无谓的热移动。因此我们可以说奥图循环和狄赛尔循环是不可逆的。而这代表了一个非常重要的观念，那就是热机无法进行可逆的逆向运动，其实也就证明了在该循环中，有发生无法产生工的无谓热移动。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:4:6","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"能量的损耗 能量的损耗其实就是不可逆变化。 在说明热机的理论效率时，我们多次强调了必须让活塞以非常缓慢的速度运动，其原因就是为了不要引起不可逆变化。因为不可逆变化，其实就是能量损耗的真面目。 引擎的能量损耗 如果在热机的运转过程中，包含了可归为不可逆变化的现象，则该现象就属于前文提到的无法作功的热移动，也就代表可使用的功会减少。 实际上引擎是通过在汽缸内引发燃烧的化学变化来产生热能，并以该能量让活塞运动、从而产生功。此时产生的热会造成温差，引起无谓的热移动。而汽缸与活塞之间也会产生摩擦，导致声音与扰流。此外，燃油的化学变化也属于不可逆变化。这些现象一旦发生，就绝对无法向影片的你想播放一样，恢复到与发生前完全相同的状态，因此属于不可逆变化。换言之，也就是无法作功的无谓热移动。 机械的能量损耗 先前探讨的对象都仅限于热机，而事实上机器装置的能量损耗，全部都是因不可逆变化而产生。反过来说，效率高的机器，可以说是在运作时尽可能减少不可逆变化的机器。因此，想要制作出效率高的机器，重要的关键之一，就在于理解何种现象属于不可逆变化，并极可能减少该现象的发生。 阿特金森循环是与奥图循环相同的热循环，一般来说，其机制是通过将奥图循环的膨胀行程延长，来产生更多的功。 \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:4:7","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"空气力学 \r","date":"2019-07-16","objectID":"/beyondtheapex/:5:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"白努利定律 思考流体的压力与速度的关系。 汽车的空气力学特性，对于耗油量、加速性能与行驶稳定性等，都有很大的影响。特别是赛车，其空气力学特性，对于车辆整体运动性能的贡献占有很大的比例。 因此，接下来就要解说作为汽车空气力学解析与设计基础的空气力学理论。 有流体流动时的分子运动 当有气流时，能量均分定理就无法成立。在气流当中，会有较多的分子运动能量被分配至流动的方向，而与气流不同方向的运动能量则会因而减少。如果在气流中量测压力，则在流动方向测到的压力会长高，在与流动垂直的方向量测到的压力则会最低。 在此要注意的是，在流动变化的前与后，分子运动能量的总和是不会改变的。 有流动时的分子运动 由白努利(Daniel Bernoulli)提出的白努利定律，代表当分子的能量分配因流速的变化而改变时，流速与压力的关系。 白努利定律的数学公式如下（P代表压力，ρ为流体的密度、V则是流速）：$$P_0=P_1+\\frac{1}{2}ρV_1^2=P_2+\\frac{1}{2}ρV_2^2$$ 升力发生的机制 接下来就用白努利定律，来说明翼型(airfoil)产生升力的机制。下图以流线代表翼型周围流场的示意图。所谓流线，是指以流体的速度向量为切线的曲线，也就是流动的路线。从流线的定义可以了解，气流不会横向穿过流线，换言之，被相同的流线上下包夹的区域，无论在哪个位置的流量都相同，这一点请留意。此外，流体存在的场域，称为流场(flow field)。 从下图的流场中可以了解，在翼型的前方，流线为等间隔，但在翼型的上表面，流线的间隔则会变窄。由于气流不会横向穿越流线，所以在翼型的上表面，实际上流路是被缩减的。尽管如此，由于被相同流线包夹的流路，其流量不会出现变化，所以在流路被缩减的翼型上表面，压力会与流速的平方成反比例降低。相反地，若翼型小表面的流线间隔变宽，则流速会下降、压力则会上升。而在此过程中产生的上表面压力与下表面压力的差，就是所谓的升力。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:5:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"流体的运动法则 流体的运动方程式代表的意义。 尤拉方程式 第一个导出流体运动方程式的，就是将白努利定律正确地以公式描述的尤拉。对于流体力学的进步而言，其重要性远超过白努利定律。因为若能解出气运动方程式，就可以计算出流场的状态。这个由尤拉导出的运动方程式，名为尤拉方程式(Euler equations)。 左边代表流体流动（加速）的效果；而右边则称为压力项，代表压力的梯度。总括来说，尤拉方程式描述的就是流体会沿着压力梯度流动。 压力梯度与流经该流场的流体之间的关系，可说是和斜面与滚过斜面的球的关系相同。这里的斜面相当于压力梯度，而球则相当于流体。举例来说，在斜面坡度较陡的地方，球会加速；而在斜面坡度方向相反时，则会减速。同样，流体在压力梯度高的地方会加速，与压力梯度方向相反时，则会减速。 那维尔-史托克方程式 尤拉方程式，虽然已数学方式描述了流体的速度与压力的关系，但并不包括流体实际上具有的黏滞性之效果。而将黏滞性效果列入考量的运动方程式，是在19世纪由Navier与Stokes导出的那维尔-史托克方程式(navier-stoker equations)。 左边是流体流动（加速）的效果；右边第一项为压力项，表示压力的梯度；右边第二项，则称为黏滞性项或扩散项，代表黏滞的特性。 尤拉方程式与那维尔-史托克方程式，到目前为止都还没有通解，所以只能直接适用于非常特殊的流体。在此情况下，要从这些方程式了解一般的流场，目前只能利用电脑以数值方式求解。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:5:2","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"涡线与不连续面 回避流体运动方程式的策略。 尤拉方程式和那维尔-史托克方程式，都是可以正确描述流体运动的方程式，不过由于在数学上的难度过高，几乎无法适用于实际的流体，在发展上也出现瓶颈。在此情况下，因而出现了不仰赖上述方程式，来解析流体的动向。接下来就为各位介绍达朗伯特矛盾，与突破此一矛盾的尝试。 达朗伯特矛盾 达朗伯特(Jean Le Rondd’Alembert)，尝试以理论求出放置于恒定流中的圆柱的阻力（与流体的速度平行且逆向产生的力），结果他解出的阻力为0. 当然，在实际的流动中，阻力不会是0.尽管如此，在他的计算当中完全找不出错误，无论是由谁重新计算几次，得出的阻力都还是0，结果并没有改变。这成为了之后160年间流体力学上的重大问题，因此也被称为达朗伯特矛盾。 如果具备现代的知识，就可以了解他的计算本身完全没有错误，只是没有考量到流体的黏滞性，所以当然会导出阻力为0的结果。如果不考量黏滞性的恒定流，则圆柱前后的气流会对称，压力也会在圆柱前后形成对称，圆柱周围的压力会互相抵消，结果造成阻力成为0。 当时还没有那维尔-史托克方程式，对于黏滞性效果的处理方式，也不甚了解。一直到1904年德国物理学家Ludwig Prandtl提出边界层的概念之后，才完全解决了达朗特矛盾。 涡线与不连续面的概念 不直接针对流体的运动方程式求解，而是以数学的方式处理流体运动、开创出新境界的，就是德国的Hermann Von Helmholtz。他进一步扩展涡旋的概念，并提出新的流体概念。 Helmholtz导入涡线与涡层的概念后，让长达一世纪不得其解的朗伯特矛盾，突然豁然开朗。根据达朗伯特矛盾，平板的抗力应为0。不过，若假设没有不连续面从平板的前缘与后缘延伸，便可将平板的背面视为流速较低的范围，实际上达朗伯特矛盾便不再存在。虽然因为他们过度高估了平板背后的压力，结果并没有成功试算出阻力，不过计算阻力的努力确实是朝正确的方向迈进。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:5:3","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"库塔-贾可斯基定律 升力的循环理论。 Kirchhoff与Reyleigh，假设不连续面是由物体的锐角部分所形成。不过，这种不连续面，会发生与物体表面的任何位置，所以也可以说物体表面是由涡层所覆盖。事实上，这种想法与升力理论中的升力之循环理论密切相关。 库塔-贾可斯基定律 由于物体表面的流速，会因为黏滞性而产生很大的变化，所以从物体表面的任何位置都会产生涡线，并成为覆盖物体的涡层。此时，覆盖物体的涡层整体的强度，便称为循环。如此一来，我们就可以将物体周围的气流，分离成均匀流与循环流两种（循环的定义，是指沿着任意的平曲线，将流速线积分后得出的量）。 假设有均匀流与循环流存在，来思考一下将两者重叠的流体。由于在循环流的上方，其流动方向与均匀流一致，所以上方的流速会增加。而在循环流的下方，均匀流与循环流朝反方向流动，若将两者重叠，流速将会降低。结果依据白努利定律，循环流上方压力会下降，下方压力则会上升，所以会产生向上的升力。 上述的流场正与翼型周围的流场类似，在翼型的上表面，流速变快、压力降低；而在翼型的下表面，则是流速变慢、压力上升。事实上，我们同样可以将翼型周围的流场，当作是均匀流与循环流的重叠流场来处理若能得出循环，就可用以下方式计算出升力：$$升力=流体的密度×均匀流的速度×涡漩的循环(L=\\rho V \\Gamma)$$ 库塔条件 依据库塔-贾可斯基定律，若能解出物体周围的循环，就可以算出作用于该物体的升力。不过，要将该定律适用于翼型时，有一点必须特别注意，那就是基本上流体的方程式，是根据流动是平滑的这个前提导出。而对于尖锐或不连续的流动，通常必须另行考虑。 以翼型为例，翼型的后缘形状是尖的，因此在尖翼的后缘有一项限制，那就是无法满足翼型上表面的气流与下表面的气流会在翼型的后缘平顺汇进这个条件，库塔-贾可斯基定律就无法适用于机翼。而这个上表面与下表面的气流，会在翼的后缘平顺汇进的条件，就称为库塔条件。必须先满足库塔条件，才能决定循环，也才能用数学公式算出升力。 要补充的是，如果针对气流在翼加上攻角，则攻角愈大、要满足的库塔条件时所需的循环也会变大。因此攻角愈大、循环也会自然随之变大，结果也就会产生较大的升力。这就是将攻角加大、升力也会随之提升的机制。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:5:4","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"普朗特的边界层理论 摩擦的影响局限于物体的表面附近。 Kirchhoff与Reyleigh计算阻力的尝试虽然失败，但已向成功迈进了一大步。接下来便介绍普朗特(Ludwig Prandtl)提出，最终解决了达朗伯特矛盾的边界层理论。 普朗特的边界层理论 想要估算阻力，除了压力之外，如何处理摩擦力也十分重要。而在处理摩擦力时，必须先了解物体表面的气流流动的情况。 率先提出边界层的概念，就是普朗特。他指出受到黏滞性的影响，物体表面的流速会变成0，而摩擦的影响，则仅局限于物体表面的邻近区域，而在其外部，气流基本上不会收到黏滞性的影响，可将该气流视为非黏滞性流体。而这个位于邻近物体表面、会受到黏滞性影响的范围，目前称为边界层。 普朗特于1904年发表名为《具有极低黏滞性的流体之运动》的论文，并在这篇仅有8页的论文中，首都提出边界层的概念。他指出那维尔-史托克方程式简化的边界层方程式。此外，利用他的边界层理论，在某种程度上也可以预测流体剥离的位置。 就这样，边界层理论完全解决了达朗伯特矛盾的问题。普朗特于1904年发表的这篇论文，为流体力学开创了新的发展，因而被视为流体力学史上最重要的论文。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:5:5","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"普朗特的升力线理论 发生于有限翼的翼尖涡流问题。 Kutta和Joukowski催生了升力的循环理论，并得以正确计算出二维气流中的升力。不过一般来说，翼周围的气流都是三维的，无法直接使用二维流体的翼型理论。在此情况下，就必须构建出翼在三维流场中的升力理论。 有限翼展翼周围的气流情况 翼型也可以说是拥有无限长翼展的翼。这种无限翼展翼，在翼展任何一个位置的循环大小都相同，升力也维持一定，因此无限翼展翼可以直接使用库塔-贾可斯基定律。 不过，实际上翼的翼展是有限的。所以在翼尖，气流会从压力较高的下表面流动至压力较低的上表面，其压力分布会与无限翼展不同。愈靠近翼尖，升力会变得愈小。此外，从翼尖的高压侧转入低压侧的气流会形成纵向涡旋，并朝向背风面流动。这种以翼尖为起点产生的涡旋，称为翼尖流。 普朗特的升力线理论 普朗特提出的有限翼展翼升力理论，成功的赋予了Lanchester建构的模型非常相似，不过普朗特成功赋予了该理论严密的数学描述，这是Lanchester没有做到的。 普朗特构思出的模型，是沿着翼展方向在翼面配置由无数个无限弱的涡线组成的涡线束，而每条涡线均朝着背风面玩去流动。这个无限弱的涡线，就称为升力线。 利用普朗特的升力线理论，可以算出有限翼可产生的升力与力矩。此外，普朗特也证明了由翼尖涡流诱发的下洗(downwash)气流造成的阻力，也就是诱导阻力的存在，并以理论阐明了翼展愈大的翼，其诱导阻力就会愈小。 \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:5:6","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"计算流体力学 \r","date":"2019-07-16","objectID":"/beyondtheapex/:6:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"CFD的世界 CFD是一个被离散化的世界。 随着电脑的普及，利用电脑求出流体方程式数值解答的手法持续发展。而这也是Computational Fluid Dynamics(计算流体力学、数值流体力学)，也就是统称为CFD的学问。目前CFD已成为研发汽车时不可或缺的工具，但一般人对于其机制都不甚了解。所以接下来就简单介绍一下与CFD有关的理论概念。 近似 真实的世界是类比，换言之，也就是平滑而连续的，无论在何时取出任何一个空间的一点，里面都包含了某些物理的资讯。相较于此，电脑是数位的，只能处理不连续的分散数值，也只能保存有限的资讯。因此CFD也只能将原本平滑连续的时间与空间分割，当成不连续的物体来处理。尽管如此，在CFD的世界当中，仍希望能尽量呈现出与真实世界接近的平滑类比世界，所以会通过模型化，来补足电脑没有的资讯。 那么，应通过何种方式，来补足资讯欠缺的部分？答案其实很简单，只要用直线将电脑的资讯连结起来，将资讯欠缺的部分视为直线变化；或是用曲线进行模型化，将资讯欠缺的部分，以曲线变化的方式来补足即可。这种精确来说与原本的资讯有差异，却是在不减损原本资讯的性质下，进行单纯化的作业，称为近似。而通过此一过程所得出的与原本数值非常接近的数值，则称为近似值。在CFD当中，将上述的近似手法，称为数值法(scheme)。 Lax等价定理 只要近似值与真值之间的误差够小，在实用上就不会有问题。因此，对于解析气流的人来说，无意义的极小数值可以忽略，而通过模拟得出的结果误差，只要小于必要的精度，以专业的术语来说，只要模拟的计算结果向真值收敛即可。 接下来介绍一个重要的定理，那就是由Peter David Lax证明的Lax等价定理。这个定理的内容是**会趋于收敛的唯一数值法，就是稳定且相容的数值法。**换言之，所谓的Lax等价定理，可以说就是指稳定性+相容性=收敛性的关系。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:6:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"有限体积法 运用最广泛的流体模拟方式。 有限体积法的概念 有限体积法主要是针对被分割的个别空间元素，留意其流入量与流出量的平衡（如1秒后容器中的水量=原本的水量+流入量-流出量）。在实际的流体模拟中，处理流体的量之外，对于压力与流速等物理量，也是用同样的方式计算。 数值通量 接下来让我们按照实际的CFD，更具体地观察有限体积法的基本概念。如下图，将空间细细分割，如此分割出来的空间，称为网格(grid)。让我们思考一下流经这些网格的流体。 首先，假设我们知道每个网格在特定时刻拥有的物理量，然后再根据这些资讯，以单位时间的流出量与流入量，来预测未来每个网格中的物理量——这就是以有限体积法模拟流体的方式。 上述流入量与流出量，必须由操作CFD的人，根据当下的物理量之分布，用某种方式来推测出最合理的数值。换句话说，决定这些量的方式，有可供选择的空间，因此单位时间的流入流出量，无法定义为单值。向这种有人为选择空间的单位时间流入流出的物理量，称为数值通量，而数值通量的精度，会大幅左右计算结果的精度。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:6:2","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"数值法的特征 单调性与高精度无法兼顾。 数值通量的精度，会因为采用的数值法而出现差异，当然也会影响到模拟的精度。若采用了不适当的数值法，则误差将随着计算你的进行而持续扩大，计算甚至可能发散。 一街精度的数值法 一阶精度的数值法，优点在于可维持单调性，但缺点则是得出的解容易扩散。 高阶精度的数值法 采用高精度数值法得出的解，精度通常较高。不过，愈是高阶，就代表须从更多的网格中取得更多的物理量来进行计算，计算量势必会大增。此外，采用高阶精度数值法得出的解，在部分情况下会出现振荡，反而会导致精度下降，这也是其缺点之一。 戈多诺夫定理 数值法无法兼顾高精度与解的单调性（解不会出现振荡），这一点已经过数学上的验证，也就是所谓的戈多诺夫(Godunov)定理。根据戈多诺夫定理，可同时满足高精度与解不会出现振荡的数值法并不存在，无论如何费心，都无法制作出两全其美的高阶精度数值法。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:6:3","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"一阶与高阶精度的并存 设法让一阶精度与高阶精度并存。 TVD法 只要配合气流的性质，妥善运用不同数值法各自的优点，应该就能得出良好的计算结果。基于这种想法而实际开发出来的，就是名为TVD的数值法。 TVD是一阶精度与高阶精度的混合数值法，特别注重于避免增加解整体的变动。它可以自行判断气流变化的激烈程度，大部分的气流以高阶精度进行计算，而气流急剧变化的部分，则切换为一阶精度，以维持其单调性。 TVD法不会像高阶精度的数值法般出现预测过度(overshoot)或预测不足(undershoot)的振荡。此外，TVD法也比一阶精度数值法更能控制解的扩散。而且不论与一阶或高阶的数值法相较，TVD法得出的解都更接近真值。 不过，TVD法必须有判定流场变化的作业程序，因此多少会消耗额外的计算时间。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:6:4","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"如何解析紊流 设法降低庞大的计算量。 解析涡旋 汽车行驶时，其周围会发生紊流。紊流是由大大小小的空气涡旋构成。无论其结构有多单纯，要计算一个涡旋，至少需要9个网格。如果要直接计算车子周围所有的涡旋，所需的网格数量将会及其庞大，这应该很容易可以想象。 紊流模型 在进行研究分析时，通常会将以上述成果为基础的紊流模型导入CFD，放弃解析构成紊流的大大小小的所有涡旋，而仅计算具有特征的部分，以缩减庞大的计算量。接下来就简单介绍一下目前应用最为广泛的RANS与LES这两种紊流模型。 RANS(Reynolds Averaged Navier-Stokes) RANS，是将紊流的流速，分成平均流速与其中的变动成份之紊流模型。由RANS的计算量相对较少，所以是应用最为广泛的紊流模型。不过，它无法正确重现非恒定的气流，所以有较难正确估算剥离等的缺点。 LES(Large Eddy Simulation) 在紊流当中，拥有支配性影响力的是大型的涡旋：小型涡旋对于整体流场的影响则相对较弱。而放弃直接解析小型涡旋，只计算大型涡旋，并将小型涡旋模型化的方式，就是所谓的LES。与RANS相较，LES能够以非常高的精度重现流场，但计算量也远超RANS。 \r\r \r\r汽车结构 Mechanism \r","date":"2019-07-16","objectID":"/beyondtheapex/:6:5","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"车的基本要件 车身骨架和基本结构的皮遏制称作车子的基本性能，从设计初期阶段便已决定，无法轻易更动。这是一辆车的潜能，会大幅影响它的三大性能： 行进、过弯、停止，同时也是用来判断一辆车的行进性能的重要基准。有关基本性能的部分，大多难以通过改装加一弥补，医药一点点规格上的差异，便足以影响上路时表现的优劣。 \r","date":"2019-07-16","objectID":"/beyondtheapex/:7:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"车身尺寸 轴距(wheel base) 从车身侧边看去，自前轮中心起到后轮中心为止的长度就叫做轴距。 这项特性主要影响车子行进间的安全性。轴距越长越不容易受到路面的高低起伏和横风的影响，在直线行进时具有较高的安定性。一般而言，虽然轴距较短会降低车辆稳定性，但是当方向盘转向时，反应会变得较为敏锐，并可更灵活地过弯。就乘客的感受来说，长轴距可提供舒适的感受。 外悬(Overhang) 从前轮中心至前保险杠前端的距离称为前悬(front overhang)，从后轮中心到后保险杠末端的距离称为后悬(behind overhang)。 如果有重物位于这个部位，将使得车的偏向惯性力矩（妨碍转向的力量）变大，降低车子的运动性能。因此从结构上来看，重量应尽量设置在轴距内侧较为理想。这一点对于引擎这类重型机具而言更是格外重要。另外，必须保留一定以上的外悬长度，才能处理空力的问题。 \r 轮距(tread) 左右轮间的距离称为轮距。放宽轮距则可降低车身假想重心的高度。 一般而言，轮距越宽，过弯时轮胎的抓地力效果越大。因此，若放大驱动轮的轮距，便有利于将汽车的马力传到到地面。在比赛用车种上，常会将前后轮改装成不同轮距，以改变操控感。另一方面，若轮距相较于轴距在比例上显得极度狭窄，则虽然可以得到快速的操纵反应，却也较容易使车子时区稳定性。 车高(height) 指从路面至车身最高处的高度。 车高越低，则因为重心降低，可以抑制过弯时的晃动（车身横向的倾斜），提升回转反应速度。另一方面，降低车高将会影响车内的舒适性，切回造成难以确保悬吊行程的状况，是的行经赛道路石等处时，发生触底（避震行程完全用尽）的原因。 车重(weight) 这是左右汽车运动性能的重要因素。 车重越轻，引擎负担也会降低，在动力性能面较占优势，且因降低了对刹车曹成的负担，得以提升制动力。另外，更因省去了惯性造成的浪费，让过弯变得更加轻快，好处不胜枚举。 将车重除以最高输出功率的值称为重量马力比。这个值越小，包括出弯后起步在内的加速性将更敏锐，车子行驶起来也更加灵活，且在降低燃料消耗率方面也极具效果。因此从环保性能的角度来看，车重轻量化业已成为开发新车时的重要主题。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:7:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"重量平衡与驱动方式 驱动方式和车身尺寸同样属于基本的规格。驱动方式视引擎安装位置、驱动轮位置而定。一般分为：FF、FR、MR、RR等种类。决定将车身上最重的零件——引擎安装在哪里？又要让它驱动哪个轮胎，是决定车身重量平衡的重大因素。 一台重量平衡良好的车，可以让引擎动力有效地传导到驱动轮上，对于起步/加速性能都有帮助；刹车时不容易让车身受惯性影响而向前倾，并可以更有效地发挥刹车性能。 重量平衡影响最大的是过弯。由于过弯时离心力会使得车子变得不稳定，因此重量分配不当的车子，在车身过弯离心力增加的情况下，更容易发生打滑等风险。 基本上，车身重量分配的理想值为前后、左右各为50比50。将引擎安置在车身前部，驱动后轮的FR式配置较易实现上述50比50的比例。另一方面，将引擎和驱动机组集中在车身前方的FF（以及4WD）式配置，则较易呈现中心在前的倾向。引擎和驱动机组集中在车身后方的RR式配置，则较易呈中心在后的倾向。因此，部分FF配置的车种为了改善重量分配的问题，会可以将横向安置为主流的引擎，改为纵向方式安置。 \r驱动方式的种类： FR(Front engine Rear drive) 引擎安置于车厢前方，并驱动后轮的配置。 最易实现前后重量50:50的理想数据。除了具备优异的操作感受外，由于操舵轮和驱动轮的分离设计，因此不需要特别去习惯操舵感觉，则是它的另一优点。然而，随着路面状况不同，这种配置也会发生难以获得驱动力的情形。 FF(front engine front drive) 集中在前方的引擎驱动配置。 由于结构上将沉重的引擎和变速器都收纳在引擎盖当中，因此，虽然可提供更宽广的车厢空间，却无可避免地将使重量集中于车体前方。又因为前轮必须同时扮演了驱动和操舵轮两种角色，以致在过弯时，车胎的抓地力必须兼顾维持直进与转向两个部分。正因如此，这样的配置通常不太适合大马力的车种使用。 MR(Mid engine rear drive) 引擎装在车身中央来驱动后轮，也称为中置引擎(middle-ship)配置。 通过将引擎安装在车身中央附近、缩短引擎与车辆重心距离的方式，让车辆发挥锐利的过弯性能。且无论在加速或减速时，前后轮都能发挥最大的抓地力。这种配置对于车子行驶最为有利，是纯跑车、赛车常见的固定配置。 RR(rear engine rear drive) 引擎安装在比后轮更后的后悬部位来驱动后轮。 这样的做法会导致车辆重心偏后。然而，由于引擎和变速器的重量将后轮牢牢地压在路面上，因此反而容易取得驱动力，今儿获得更优秀的加速性能。但相反，由于前轮缺少负重，因此在过弯初期容易发生转向不足的问题。又因为后轮负重较重，因此在后胎超过负荷时，会产生激烈的打滑现象，想要从这样的状况中恢复正常，需要极高的驾驶技巧。 4WD(four wheel drive) 通过前后左右四个轮胎进行驱动。 这种配置架构除了增加车辆总重量的小缺点以外，可以说是姿势和起步与加速的驱动配置。然而，高度的稳定性却也意味着不容易过弯。 \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:7:2","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"车的心脏 在组成汽车的零件中，引擎扮演着最重要的角色。能够正确掌握引擎的原理，搭配上正确的操作，才能百分百发挥出车子的性能。 \r","date":"2019-07-16","objectID":"/beyondtheapex/:8:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"构造与原理 几乎所有的燃油引擎车都搭载4衝程的往复式设计。往复式引擎当中配有汽缸，靠着汽缸中的活塞往返运动来产生动力。而所谓的4衝程设计，便是因具采用了进气-压缩-燃烧-排气等4到反复程序设计而命名。 首先，在活塞到达汽缸上死点前，进气门便会打开，而在活塞达到死点后开始下降，因此会自动开启的进气门吸入空气与汽油的混合气体。当活塞降至最下方，进气衝程即告结束，进入压缩衝程。此时，在所有气门都已关上的气缸当中，活塞开始加压前述混合气体。 当压缩混合气体的活塞抵达稍微超过顶点的位置时，火星塞即会进行点火，于是便告进入燃烧衝程。此时汽油引擎的气缸内部甚至可以达到摄氏2000度以及200个大气压力。这样高温高压的能量会将活塞往下推，并推动曲轴以产生回转的动力。 活塞抵达下端后，排气门便会打开，展开排气衝程。在此衝程中，与其说是活塞把气体推排出去，不如说是这些排出气体因本身夹带了高温、高压动力，自动地从排气门喷出。排气后， 顶点的进气门有会打开，于是再度回到进气衝程。 4衝程引擎即使在怠速状况下1分钟，也会执行数百次这4道步骤，在全力运转的状况下能够以1分钟数千次的速度转动曲轴，以持续产生动能。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:8:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"气缸配置的种类 直列型(in-line engine) 将复数汽缸配置成一列的设计。 所有的汽缸均共享一根曲轴，可让气缸体机组成为整体化结构，因此有着结构简单、且较能降低重量的优点。然而，若汽缸数量越多，则本体长度也会随之增加，同事会影响空间上的运用。 V型(V engine) 将汽缸左右交互配置呈V字型。 这种配置可以缩短曲轴的长度，优点是在多汽缸的情况下，也能有效缩小引擎本身的体积。且无论汽缸数量有多少都不易震动，而较短的汽缸区块和曲轴长度，同时可让结构更为坚固。 水平对向型(flat engine) 将汽缸左右交互进行水平配置的型式。 各汽缸以曲轴为中心左右对置，且对向的活塞呈现左右对称的动作。就好像拳击场上两名选手交互打出的拳击一般，因此也被称为拳击手(boxer)引擎。另外，由于引擎高度较低，因此也有这适合低重心化的优点。 W型(W engine) 原本是指1根曲轴对应3列气缸呈扇状安置的引擎设计，不过，现在也可用来称呼结合了2组狭角V型引擎的机组。这种配置的宽度大于V型引擎，但是在汽缸数超过12颗以上的多汽缸架构下，此种配置可以缩短曲轴长度（即引擎全长），并带来更大的好处。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:8:2","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"气门驱动方式 4衝程引擎当中，有着在进气衝程中开启以自外部引入混合气体的进气门，以及在排气衝程中开启以将燃烧气体送出外部的排气门。气门设置在汽缸盖的位置，负责在适当的时机阻隔/连接燃烧室与外界。 现代引擎一般选在将凸轮轴设在引擎的上半部，以更加正确地驱动气门。关于气门的数量，目前几乎都采用2个进气门、2个出气门，共计4气门的设计。不过，今后为了追求在低转速领域的燃烧效率，像进气门、排气门各1的2气门设计，仍很有可能重新面世。 另外，近来潮流倾向于采用可变气门正时系统。原本在低转速和高转速领域间转换时，气门开闭正时也必须随之变更。然而，之后已进步到可随着引擎回转连续不间断地变换气门开闭正时和扬程深度。而自BMW推出可变气门扬程系统后，市面上一系列最新的可变气门结构，更能在不通过节流阀的情况下调整输出功率，这项进展得以进一步地提升效率。 气门驱动方式的种类： DOHC(double over head camshaft) DOHC(双凸轮轴)，使用两根凸轮轴分别驱动进气与排气门的设计。此设计减轻了凸轮轴的负担，不仅能更加确实地执行开关气门的动作，同时可以降低气门结构附近的往复运动质量（即惯性），以获得高转速表现。该配置也容易取得高输出功率，因此今日几乎所有的高性能引擎，都采用这种设计。 SOHC(single over head camshaft) 在汽缸盖上设置1根凸轮轴的方式就称为SOHC(单凸轮轴)。依照燃烧室的形状不同，又可区分为凸轮轴直接驱动气门，或由凸轮轴通过一种像跷跷板的零件锁臂(locker arm)驱动气门。它拥有更可靠的气门运作表现，且可获得更高的转速。 OHV(over head value) OHV(顶置气门式)。顾名思义，气门机组设于汽缸盖上方。它与SOHC、DOHC引擎之间的差别，在于凸轮轴不是位于顶部，而是在汽缸旁，并从这个位置通过一种叫做推杆的长棒和锁臂来驱动气门。虽然此中结构较为简单、且便于维修，不过，在高速运转的状态下却缺乏可靠性，也因此通常不适合被赋予大功率输出。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:8:3","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"转子引擎 **转子引擎(rotary engine)**基本上也和往复式引擎一样，通过反复进气、压缩并燃烧、最后排除废气的过程来取得运转能力。然而在这样的过程中，转子引擎所用的原理却和往复式引擎完全不同。 在转子引擎当中有著名为转子室的茧形空间，完全取代了汽缸的功能。三角形的转子就安置在这个空间当中。在转子于其中进行偏心旋转时，转子和转子室之间的空间大小会有所变化，在此进行压缩-燃烧-排气过程。 一般引擎之中通常拥有复数组的活塞反复运动，因此不仅难以控制作用力，同时也成为振动与噪音的起因。然而，由于转子引擎利用了旋转运动的原理，因此运转起来较为平稳顺畅。又因为不具备气门机组，所有有着零件总数大幅减少的优点。不过，随着往复式引擎近年逐步地趋向轻量化，相较之下，此优点并不显得格外突出，然而不可否认的，这种引擎整体而言是较为小巧的。 转子引擎进气与排气的时机，取决于设置于转子室壁面与侧面的气埠（混合气体的通道）的形状而定。调节转子引擎的进气/排气时机，基本上便是通过改变气埠的位置和形状来进行。又由于回转引擎中不具备排气门，而是让排气动能直接自排气埠排出，因此非常适合搭配涡轮增压器。 另一方面，转子引擎普遍被认为在节省燃料费用方面的表现不如往复式引擎。这是因为转子引擎的燃烧室容积与表面积比例相对较大，容易让热能散失，因此导致转换成回转动能的比例较低。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:8:4","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"增压器 若能让引擎吸入越多空气，便能提升越多马力。因此增加功率最简单的作法，便是从提升排气量着手。 然而有种东西可以不必提升排气量，便可获得相同的效果，那就是增压器(compressor)。这种装置可以大略分为机械增压器(supercharger)和涡轮增压器(turbocharger)。不过，大致上都是将空气压进引擎中（称为加压），以达到与提升排气量相同的效果。 加压空气时的压力称为增压，提升此压力，便能得到更大的输出功率。 大气压为1气压时，记为1bar或$$1kg/cm^2$$。因此，若过增压为1bar连同大气压在内合计有2bar的压力，意味着会迫使2倍的空气进入引擎当中。 增压器的缺点在于随着增压提升，燃烧能量亦会提高，但同时却也会对引擎造成较大的损伤，例如偶发性的异常燃烧现象等。因此，装有增压器的引擎当中，大多会同时补强引擎内部零件的强度，或是降低压缩比例，以减少发生异常燃烧的次数。 另外，空气经压缩之后将会夹带热能，使得密度降低，尤其在高负荷运作的条件或夏季时会特别显著，而此时点火亦无法得到巨大的爆发力（马力输出功率）据说进气温度每上升1度，便会损失1ps。因此，通过装设中冷器来降低压缩空气的温度，已被车坛视为常识。 由于增压器使用排气端的废气来推动增压器，因此在产生增压之前会出现一段延迟时间。另一方面，使用引擎曲轴作为动力来源的机械增压器虽然无此烦恼，但却会丧失些许引擎本身的功率输出。 近来颉取两种增压器的长处：在低转速领域使用机械增压，但到了高转速领域该用涡轮增压的新引擎设计，开始受到业界注目。 机械增压器(supercharger) 自引擎曲轴通过皮带来驱动增压器(compressor)，并将空气压缩后供给引擎的装置，便称为机械增压器。 由于增压器的动力来自于曲轴运转，因此和涡轮增压器相比，具备在低回转领域有着极大的增压效果、加速反应灵敏等优点，并且相当适合搭配自动变速器。 图为鲁式(Rootsblower)机械增压器，其它还有李式(Lysholm)双螺管机械增压器、涡卷式(Scroll)等不同种类。 涡轮增压器(turbocharger) Turob意即涡轮机，通常是指利用通过排气管所排出的排气压力，来推动涡轮云总的增压器。 由于使用排气动能作为动力，因此没有像机械增压器那样，会发生在高转速领域损失驱动力的缺点。但相对来说，由于排气的动能较低，在低转速领域不足以转动涡轮，就算想要开始加速，也必须等待涡轮转速升高。这就是所谓涡轮增压延迟现象的成因。为了克服此问题，技术人员想出了各种不同的系统架构，现在也仍不断地改进当中。目前欧洲地区仍持续推出可提升油耗表现的小型化涡轮引擎。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:8:5","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"混合驱动系统 混合驱动系统的目的在于并用引擎与马达以降低燃料消耗率。日本走在这个领域的前端，所开发出来的混合驱动车种清一色都是所谓的环保车，不过随着欧洲的车厂也开始研究，也许有朝一日这种系统会成为核心设计。 这种系统的弱点，在于引擎怠速和起步时的效率较差。不过，马达即使在零转速的情况下也能发挥最大扭力，且效率亦高，可以有效弥补引擎不擅长的低回转领域。而在速度上升之后，引擎运转的效率也随之提高，而相对低马达的输出效率则会下降。因此为了让两种机组都能在各自擅长的领域有所发挥，以充分提升能源的使用效率，混合驱动车便应运而生了。 车上同时装载马达和电池的优点，在于可以回收能源再利用。这样的机制称为回生，在未踩油门/刹车时，会运用轮胎的转动能量带动发电机为电池充电，而这些存下来的电能，则可于再度驱动马达时使用。原本刹车产生的热能只能任其丧失，如今却能够回收成电能并再度利用。 本系统的另一个优点，在于马达可以弥补引擎的性能，发挥近似于增压器的功能。欧洲车厂制作混合驱动车时，大多着眼于此。它们推出的这类车种，在设计上大多不使用增压器，改采用电动马达来呈现大排气量车种的驾驶感。 混合驱动系统种类 串联式(series hybrid) 并联式(parallel hybrid) 串并联混合式(series-parallel hybrid) \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:8:6","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"车子性能的关键字 车辆的规格表上通常列出了许多数值与专有名词。必须充分掌握这些资料的意思以及解读方式，才能了解车子的引擎性能，并且推敲出车子锁蕴含的潜能。 马力(horsepower) 最能直截了当地表现出引擎性能的数值，便是以ps为单位的马力。1马力代表能将75KG重的物体在1s内举起1公尺的工作效率。 也就是说，1台100马力的引擎可以将1T中的物体在1s内举起7.5公尺。马力是由扭力x引擎转速求得，所以即使引擎的排气量小，只要转速高，一样能够发挥出输出功率。顺便说一句，国际通用规格使用kW来换算马力（1ps:0.735kW）。 扭力(torque) 用来表示回转力的数值称为扭力。 将长1公尺的扳手，对于位于1公尺源的螺帽施加1KG的力使其旋转时的回转力写做1kg-m。就引擎而言，扭力通常用来表示曲轴所拥有的回转力。扭力几乎等同于燃烧能，以自然进气引擎而言，大致上可以得到等同于排气量的扭力。 一辆车的扭力越强，表示维持引擎回转的力道越强，如此一来我们便能说，这对驾驶人而言是一辆好驾驭的车子。 排气量/汽缸数(displacement/cylinder) 从排气量可以得知引擎能够吸入多少混合气体。这在往复式引擎来说，即活塞运动中往返的圆柱体积x汽缸数。 当引擎排气量越大，获得的输出功率也越大。然而若单个汽缸的容积过大，相对也会妨碍到运转。未解决此问题，一般采用的方法是增加汽缸的数目，来降低每个汽缸所需的容积。若汽缸数目增加，曲轴每回转1次在汽缸中的引爆次数也会随之增加，因此有着令引擎回转更加顺畅的效果。 一般而言，一个汽缸的排气量以350-600cc较为理想，然而多汽缸引擎的成本非常高。因此，实际装载的汽缸数目大多依据车身尺寸和车款价位而定。 缸径衝程比(bore stroke ratio) 将汽缸内的衝程除以缸径所得到的值就叫做缸径衝程比。 当此值小于1时，称为短衝程引擎；大于1时，称为长衝程引擎；等于1时，称为方型引擎。缸径衝程比会影响引擎的特性，一般来说，长衝程引擎在低中转速领域较容易产出扭力，但在高转速领域却不太能发挥功率；短衝程则相反。 顺便说一句，当活塞运动到气缸内的最上部时称为上死点；降至最底部时称为下死点。 压缩比(compression ratio) 所谓压缩比是用来表示引擎将吸入的混合气体压缩至多少程度的数值。引擎的功率将大幅受此压缩比左右。 将活塞被推至最下方时汽缸中呈现的最大容量(汽缸总容量)，除以活塞推至最高处时汽缸中呈现的最小容量(燃烧室容量)，即可求得此比例。所谓汽缸总容量，则是将活塞运动中上下往返的**圆柱体积(排气量)**再加上燃烧室容量。 以一个2000cc的4汽缸引擎为例，1个汽缸的排气量=汽缸容量(500cc)。假设燃烧室容量为50cc，则将总容量500cc+50cc=550cc处理燃烧室容量50cc，可得知压缩比为11。 通常，自然进气式汽油引擎的压缩比大多设定在9-11之间，超过10的即可视为该引擎的排气量做了较高输出功率设定。若是装有增压器的引擎，一般则倾向于7-9之间。 \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:8:7","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"将动力转化为速度的驱动装置 为了有效地引出引擎功率并转化成速度，必须拥有适切的齿轮和驱动力配置。因此驱动系统的零件会大幅左右引擎效率。 \r","date":"2019-07-16","objectID":"/beyondtheapex/:9:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"变速器 引擎每分钟可以达到数百甚至数千转，这样的速度如果直接用来转动轮胎则嫌太快，因此我们需要靠着变速器(transmission)，通过搭配**齿轮(gear)**以依照状况自引擎取出所需的速度与动力。 让我们回顾一下齿轮的原理。如果将某个此轮搭配上比它大的齿轮，那么虽然大齿轮的转速不如原本那么快，但却可以增大运作的力道；如果搭配的是比较小的齿轮，则虽然较小的齿轮转速较快，但相对取得的动力也比较有限。 变速器靠的便是这样的原理。车子需要最大动力的时间点起步时，相反地，再告诉状况下维持固定速度行进时，则只需要少许动力即可。 因此在起步时让引擎搭配能产生较大扭力的大此轮（较大的减速比），才能确实地让车子往前推进。 大齿轮虽然对于扭力有倍力的效果，但是转速较慢。这解释了为什么在打1档时，就算把引擎转速踩到极限，车辆的时速也只能达到数十公里左右。因此在变速器中北邮复数此轮，以逐渐缩小搭配齿轮（降低减速比）的方式，让使用者可以因应行进情况，自由地操纵车子的速度和动力。 实际上在汽车当中，是靠着引擎正后方的变速器，以及驱动轮前方的最终传动齿轮两者间的搭配组合，调整出齿轮比例。变更此一齿轮比例，便能大幅影响车子的行进特性。特别是在赛道奔走时，为顺应赛道特性选择合适的齿轮搭配，往往是缩短时间记录的重要关键。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:9:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"终传齿轮 介于引擎和驱动轮间，在驱动机组中做最后一道减速步骤的此轮装置，就叫做终传齿轮。从整体驱动机组的角度来看，他和变速器有着相互补强的关系，也可以把它看做是将引擎的转速再减速过一次之后，才传给轮胎的装置。在纵向配置引擎的车种中，最终传动齿轮则还肩负著将动力传导的方向转换90度的责任。 由最终传动齿轮独立在变速器之外，因此比较便于拆装更换。换言之，当我们想要大幅变更车子的特性时，最终传动齿轮便是必须考量的重要因素之一。一般而言，若重视车子的运动性能，只需要调高最终传动齿轮齿轮比，就能提升车子的加速能力（到达极限会降低）。相反，若以降低燃料消耗为目标，则只需降低齿轮比，便可收到降低引擎转速的功效。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:9:2","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"双踏板式变速器的种类 AT(Automatic transmission) 自动变速器。 利用扭力变换器（流体离合器）调整引擎断断续续输出的动力，能够顺应车速和引擎转速，自动切换成适当的变速比率，而在内部则配有行星齿轮，通过油压进行控制。虽然优点在于能够顺畅地进行变速，然而却也会因为使用油压带来打滑或浪费功率的问题，在油耗上比较不理想。 CVT(Continuously variable transmission) 无段自动变速器或连续可变变速器。 不像一般变速器通过切换齿轮达到变速效果，这种变速器通过变化金属带和链条等连接成的2组滑车和滚轮的直径，来连续地变换变速比。这种变速器在变速时不会产生震动，且在各种行进状况下，都能选择效率最佳的引擎回转域来行进。 DCT(Dual clutch transmission) 双离合变速器是将手排变速器的操作以2具离合器加以自动化之后的产物。 通过将奇数档分在不同轴上，以双离合器分别瞬时切换，在变速性能上可以超越手排变速器。在自动变速器当中，受限于行星齿轮的回转性能，引擎的最高转速也受到限制。然而，双离合变速器却能够搭配高转速的引擎。正因如此，跑车以至于环保车种都能有效地发挥此种变速器的性能。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:9:3","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"差速齿轮 对于左右两侧都有驱动轮的车种而言，差速齿轮是不可或缺的零件。虽然这在完全直线行进时派不上用场，但是会在过弯时发挥重要的功能。 过弯时，弯道外侧轮胎行走的距离比起内侧轮胎要来的长，这就是所谓的内轮差。如果不顺应这样的差异，对内/外胎设定不同的回转圈数，那么内侧轮胎将会卡住，车子根本无法转弯。能够吸收这种差异的，便是这里要介绍的差速齿轮。差速齿轮通常和终传齿轮整合为一，装置与左右驱动轮之间。 平时在车子直线前进时，主动此轮会配合终传四轮旋转与边此轮周围绕行，以将引擎动力传导至边齿轮。此时分配给左右驱动轮的扭力是相同的。 而当开始过弯进入回转状态时，位于弯道内侧的轮胎将产生阻力，而这样的阻力会通过传动轴传至内轮的边齿轮。此时，原本只会绕着齿轮周围公转的主动齿轮会同时展开自转，以调整外侧轮胎和内侧轮胎之间的回转差。 如此一来，分配引擎动力时，将只传给产生阻力的弯道内侧较少的动力，而给外轮胎更多的动力，以弥补两者之间的回转差。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:9:4","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"限滑差速器 前面介绍了差速齿轮在弯道的作用，不过这种机组在结构上存在著弱点：在装置了差速齿轮的驱动轮之中，只要有一个轮胎离开地面，就无法将驱动力传导给其它驱动轮。这是因为此时离开地面的轮胎将会空转，而差速齿轮则视图修正空转胎的回转差，将驱动力全部传给这个轮胎。路上常可以看到卡在泥泞或雪地上的车子，大多是因为差速齿轮的这种特性造成的。 因此，当左右驱动轮之间的回转差大于某个范围时，能够限制差速齿轮功能的，便是所谓的LSD(限滑差速器)。 LSD的原理，是借由装上能够限制两侧边此轮转速差的装置，达到确实将驱动力分配各两轮的目的。具体的方式可以细分为多板离合器式、电子控制式、以及通过齿轮咬合和转轴方向产生的摩擦力，所作动的粘性耦合式等设计。 LSD机制运用在跑车车种上时，与其说是为了从泥泞中爬出来，不如说是为了确保驱动力并提升操控性。 LSD的种类： 扭力感应式(torque sensing type) 采用特殊齿轮组合的方式。当左右驱动轮间产生扭力差时，便会增加齿轮的齿面阻力，以限制差速效果。由于这样的差速限制力相当大，运用在像赛道上行进这类对车子负担较重的场面特别有效；切实际产生限制差速效果的反应时间也相当迅速。此类除多踏板离合器式之外，还有扭力感应式、螺旋齿轮式等。 回转感应式(revolution sensing type) 不限制差速齿轮运作，而是利用高粘度矽油的方式。除了最具代表性，利用油类剪阻力（物质内部抗形变的阻力）的粘性耦合式之外，还有利用油类通过孔穴式。和扭力感应式相较之下，此类的差速限制力比较和缓，反应速度也比较迟，但是相对的也比较适合用在低摩擦系数的路面上。 动态控制式(active control type) 就是电子控制式。由电脑通过收集自各种感应器的资讯，主动地进行差速限制。通常用在越野赛车等竞技车种当中。一般都用于世界越野锦标赛(WRC. \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:9:5","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"支持汽车行进的骨架 车身结构对行进性能造成的影响大于引擎和变速器，操控性优良与否也取决于此，可说是一辆车的基础，也是最根本的部分。 \r","date":"2019-07-16","objectID":"/beyondtheapex/:10:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"车身应具备的性能 能与车身、引擎、以及悬吊并列足以左右车子个性的要素，则是一辆车的骨干。一般来说，我们要求车身必需兼具刚性与强度，还得同事追求轻巧。这里所说的刚性简单来说便是不易变形的程度，而强度则是不易损坏的程度。 上述特征中，刚性对行驶性能造成的影响特别大。当一辆车通过凹凸路面，或处在过弯等对车身造成负担的状况下时，若车身仍不会轻易变形，则可以说这辆车刚性高。 就算车身变形了，只要能够瞬间恢复原状，悬吊便可以正确地运作，也能提升轮胎接地性。车身刚性够高，动力便容易传达到路面，车子行进更加安定，也较容易驾驶。 加诸于车身的冲击力并没有固定的模式；有些缓慢的到来，也有突然发生的。而在车辆的产品型号上有着弯曲刚性和扭曲刚性这类标示，这些大多是针对缓慢到来的冲击力而言的刚度。然而，真正具备高刚性的车身，即使受到剧烈摇晃这类瞬间的冲击力，也必须能够承受。 另一方面，所谓的强度即硬度或坚固的程度。强度过低时，发生冲撞时对车身的伤害较大。然而，若因此便让车子具备有如坦克车般的强度，则虽然让车身毫发无损，但激烈的冲击力却会相对加诸在乘客身上。 一辆车的车身，必须将刚性和强度的平衡追求到及完善的境界。如果只是要单纯地提升刚性和轻度，有许多简单的补强方法。然而，却无可避免地会让车身变重。 框架式车身(frame body) 也称为非承载式车身或车身与车架分离式结构。 这种结构是将引擎和变速器、悬吊等装置在固定的车架上之后，再架设上理你性制作的车身。除了梯型式，还有背骨式、周长式、平台式等。而其中又以梯型式较能压低制造成本，同时又能确保强度，所以许多越野车种喜欢采用。 车体式车身(monocoque body) 车架和车身一体成形，是现代车身结构的主流。整个车体的强度来自于车身板件等多项结构零件，有如蛋壳般地支撑了车身的整体强度，不仅轻巧且也具备了高刚性。这种架构的另一个优点在于可以降低底盘高度，而在发生冲撞时也易于吸收能量。由于引擎和悬吊直接安装在车身上，使得过去这样的架构在乘坐舒适性和噪音抑制方面，一直比不上框架车身。然而，随着悬吊不断演进及组装技术提升，这些缺点已成为过去式。 \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:10:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"用来降低车速的热交换器 减速就是将车子行进的动能转化为热能。除了让车子停下的功率理所当然地必须大于引擎功率外，对于过热问题也必须做好万全的处置，因此这是车上最重要的零件。 \r","date":"2019-07-16","objectID":"/beyondtheapex/:11:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"结构与原理 汽车的刹车，说穿了就是将动能转换为热能，以降低车速的装置。这种装置也有固定车身、防止静态状态下的车子产生移动的功能。 组成刹车的基本原件为接受驾驶员命令的操作装置、传导操作力的液压回路，以及最重要的制动装置。近来的刹车系统则还会在液压回路中额外加装能够放大操作力的倍力装置，以及能够防止轮胎锁死的ABS系统。 刹车踏板和制动装置之间通过液压回路相连。由于液压回路仰仗帕斯卡原理运作，因此啥词踏板前端连接著一个大剖面积的刹车总泵。这个刹车总泵中产生的压力在放大过后，再传导给刹车来令和蹄片。刹车来令和蹄片是摩擦介质，将它们压在刹车碟盘或刹车鼓上之后，才能将动能转换成热能，以降低车速。 流动在液压回路当中的并不是一般油类，而是专用的刹车液。针对刹车时的热能，刹车液必须具备不易沸腾的特性，也因此主要依沸点分为几种不同种类。 随着高速道路的逐渐普及，小客车主流的前刹车设计，已由鼓刹转为碟刹。碟式刹车主要是通过在刹车卡钳当中的刹车来令片从两侧家住刹车碟盘，已发挥制动力。 碟式刹车(disc type) 通过从两侧来令片家住转动的金属制圆盘（刹车碟盘）产生摩擦力，以发挥刹车效果。最大的优点在于包括刹车碟盘在内，几乎所有的结构零件都露出在外，所以通风性、散热性十分优秀，不容易过热。另一个优点在于当水附著在刹车碟盘上的时候，可以靠著碟盘本身的旋转将其挥散，因此不至于使摩擦系数降至过低。不过，这种刹车虽然易于通过调整脚踩刹车踏板的力道来微调制动力，然而，自身却没有产生倍力效果，以至于如果停车时的制动维持力不如鼓式刹车。 鼓式刹车(drum type) 这种刹车系统，乃是将刹车蹄片由内侧压在和轮圈一起转动的圆筒型刹车鼓上来取得制动力。由于散热性不佳，比碟刹更容易发生过热的情形，且若刹车内部进水，需要一段时间才能恢复摩擦力。不过在制动时，刹车蹄片会自动朝向咬住刹车鼓的运动方向，因此可以发挥极大的制动力（这称为自我倍力作用）。在小客车上 ，通常装载刹车负荷较小的后轮为多，而在大型车中则会把它装载后轮碟刹的内侧，作为驻车用的刹车。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:11:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"摩擦热引起的刹车问题 过温衰退现象(fade) 当过度使用刹车时，造成制动力急速下降的现象。具体而言，这样的现象时因为用作摩擦截止的来令片和刹车皮过热后产生气体，而这些气体在刹车碟和鼓之间发挥了近似于润滑剂的作用，导致摩擦系数降低。 气阻(vapor lock) 过热的来令片和刹车皮上的热能使得刹车液沸腾，使得刹车油管内产生气泡的现象。此时即使踩刹车踏板也无法将正规的压力送出刹车液，最糟的状况下甚至无法取得制动力。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:11:2","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"刹车碟盘的种类 实心碟盘(solid disc) 仅使用一面碟盘，是最基本的结构种类设计。虽然散热效果不如通风式刹车，不过由于制造成本地，所以用于许多轻型汽车的前刹，或者在4轮碟刹系统中负责制动时符合较小的后刹。比起通风式刹车碟，此类设计对摩擦热承受度较强，并以散热效果高的钢铁材质为主流。 通气式碟盘(ventilated disk) 结合两面刹车碟盘，并在其中设置多个散热孔。原本是为了赛车所开发、运用，不过现在许多客车也采用此种刹车碟盘。由于和实心碟盘相较之下，碟面温度大概降低了30%，因此可以进一步提升耐热性（以及防止过温衰退），并延长来令片的寿命。缺点在于碟身较厚导致重量较重。 更加进化的通气式通气式刹车碟： 针孔式碟盘(pinhole type) 一般用来指在通风式刹车碟盘的摩擦面上打更多的洞，以提高散热性、冷却效率的刹车碟盘。而这种也叫做攒孔刹车碟(drilled disc)的碟盘设计，同时频繁使用在赛车和高性能跑车上。这些洞孔对于排除制动时产生的摩擦粉也很有效。而另一种在表面上挖满槽的画线式碟刹(slit disc)，在设计上也是出于同样目的。 螺翼式碟盘(spiral fin type) 在贴合的2面刹车碟盘内侧将散热排成螺旋状。翼片的形状是经过解析刹车碟盘内气流数据之后做出最佳化的设计，可以伴随着车辆转动有效地排除摩擦热。除了常用在高性能跑车以外，也会用在车重较重的大马力车种上。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:11:3","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"刹车卡钳 浮动式刹车卡钳(floating type) 这是在刹车卡钳内部只有单边具有将刹车来令片推出的刹车活塞的型式，因此也叫单活塞式。承受来自于刹车踏板油压的活塞只存在于机组的一侧，对面的来令片则靠反作用力压制住刹车碟盘。在这种刹车卡钳当中，与刹车碟的解除位置是常时在调整的，且左右两侧来令片之间不存在著时间差的变化，每次都能得到同样的刹车感。由于这种刹车卡钳本身体积较小，重量也较轻，因此可以顺应高温扭曲变形的碟刹做出应变。虽然在赛道等连续行驶的状况下会导致效果降低，但是从性能上来看，在一般使用情况下丝毫没有问题。 对向活塞式刹车卡钳(opposite piston type) 左右皆装有刹车活塞，从两侧将来令片夹上刹车碟盘的型式。由于这种结构体积较大，必须选用吕质刹车卡钳，因此仅以维持刹车卡钳的刚度。用在赛道等跑车的行驶条件下十分有效，单向有发挥原本的性能，如果不一并把刹车碟盘改装成浮动式，碟盘会因为热变形而倾斜，导致来令片无法确实著力。随着刹车碟盘直径逐渐变大，市面上也有不少采用4活塞设置6活塞这类复数刹车活塞、以及来令片总面积较大的车种。从吕质轮圈的空隙间能窥见的大型对向活塞，可说是一台高性能车的有利表征。 \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:11:4","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"控制车身动态的缓冲装置 伸缩乍看之下是种简单的运作原理，然而车上要是没有悬吊，不仅无法正确操作，甚至无法正常行驶。 \r","date":"2019-07-16","objectID":"/beyondtheapex/:12:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"构造与原理 从结构上来看，悬吊位于车身和轮胎间，一边支撑着车身，一面吸收来自轮胎的冲击力。这重要的机制大幅影响着车子行进间的操纵稳定性。 悬吊可以大略分为左/右轮动态会影响到另一轮的固定式悬吊，以及左右轮个别作动的独立式悬吊。而这两类悬吊又各自有几种具代表性的形式，如固定式车轴式、吊环式、扭力梁式等。而独立式则有支架式或双叉骨式等等。 悬吊本身由弹簧、减震筒、连杆支臂等结构组成。弹簧能够缓和来自 路面的冲击力，减震筒则是可以抑制弹簧的弹跳，提升搭乘的舒适感与稳定性。连杆支臂则用在限制轮胎的动态，让轮胎能以最佳的方式与地面接触。悬吊还有另一个重大的用途，是通过弹簧的反作用力将轮胎压在地面，以稳定轮胎位置。 弹簧(spring) 除了具备先一步吸收加诸于行进间车身的冲击力、缓和震动的功能之外，还有维持固定车高的功能，是会影响操控性、方向盘性能、动作稳定性的重要因素。因此我们可以说，就算只调整弹簧设定，也足以让车子的个性不大相同。而一般除了金属制的线圈弹簧以外，还包括利用空气压力的气压式悬吊。 减震筒(shock absorbers) 线圈状的弹簧在承受负重时，虽然可以通过伸缩原理加以缓冲，然而光是如此却无法消弭上下的运动量。而抑制这样的动态便需要减震筒（也称阻尼装置）的责任。一般常见的减震筒种类是仰赖活塞在密封于筒内的油类和气体中上下运动时遭遇的抵抗力来运作，可通过慢慢伸缩、慢慢恢复的动态，来缓和弹簧激烈的上下运动。因此减震筒和弹簧同样左右着车子的操作性和稳定性。 悬吊臂(suspension arm) 这是控制轮圈动态的零件，也称为控制臂。这种零件借由安装在车身与轮轴之间，可以依照各种不同的形状分为A臂和I臂等不同种类。基本上使用压合钢板，不过有时也会使用强度更加的锻造制品。在双A臂式悬吊这种上下成对的悬吊组当中，上方称为上臂，下方称为下臂。 稳定杆(stabilizer) 利用扭杆弹簧的扭曲来抑制车身晃动的安定装置，也称为防倾杆。两端安装于悬吊的下臂上，只会在左右车轮动态相異时作动。例如在过弯时，外侧车轮下沉，内侧车轮将会拉高，此时稳定杆就能控制左右车轮成为相同的动态，让行车姿势更安定。也有人会可以利用稳定杆的这种效果，调校成可以用来应变转向不足、转向过度的设定。 悬吊衬套(suspension bush) 用于构成悬吊的金属制连杆和悬吊臂等的结合部位，或是装著于车身部位的缓冲材质。如果衬套硬度不足，将会因过弯等情况下庞大的负重而变形，使得悬吊产生不必要的动作，影响车子的操作性和稳定性。因此，衬套的材料一般都选用冲击吸收性佳的橡胶材质，不过在竞技用车种当中，为了减少不必要的动作，较常改用鱼眼(pillow ball)这种金属球面轴承。衬套是能够引导出弹簧和避震装置性能的重要零件。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:12:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"悬吊的种类 虽然各种不同的悬吊同样具有保持车高、介绍行进间的负重和冲击的功能，不过彼此间的性能和特性却是各不相同的。这些性能与特性的差异，会影响到过弯、行驶性能、与安全息息相关的操控性能、以及乘客乘坐时的舒适性。 悬吊正日新月异地进步，目前已发展出了许多不同种类。虽然结构复杂并非就等同于具备了高性能，但是为了实现理想的悬吊能够瞬间追踪路面的凹凸起伏，保持轮胎能够维持在正确的接地状态的目标，目前各方专家仍在持续努力研究改进的技术和手法。 固定式(rigid axle) 所谓固定式悬吊，即通过车轴连接左右轮和轮圈的结构。由于轮胎的动作将会传达给另一侧的轮胎，因此容易降低接地性。且因轴梁和轴殻本身重量也重，在比较簧下重量时便较为吃亏。不过一你诶这种结构成本低、且强度优异，尝尝用在低价位的后轮驱动车种中作为后悬吊。 独立悬架式(independent system) 能够让左右车轮独立上下运动，在应付凹凸起伏路面方面的表现亮眼。特别是在后轮驱动车种中，可以有效地将动力传导给左右车轮。除此之外，还能减轻运作部位的重量。能够兼顾操控稳定性和乘坐舒适性的特点也让人激赏。 常见于跑车款中的独立式悬吊： 支柱式悬吊(macpherson strut) 基本上是由弹簧和避震装置以及下臂组成的简单结构。strut的意思是承受作用力的支柱，在此指的是减震筒与弹簧装置。减震筒的上端通过缓冲橡胶支撑车身，下部则由下臂支撑。不了零件数量少，得以控制重量之外，也因为易于确保衝程距离，可吸收较大范围来自路面的震动。 双A臂悬吊(double wishbone) 由上下成对的悬吊臂悬架起车轮的结构。使用双悬吊臂，而因为V字型排列的悬吊臂就像鸡的锁骨的形状，因此便以之命名。随着悬吊臂形状和配置位置不同，可以比较自由地控制加速/减速时车子的姿势和车轮矫正的变化。另外也因为这种悬吊便于追求高刚性，所以常用在重视操作性和稳定性的跑车当中。然而，相对的也因为零件数量较多且结构复杂，需要较大的安装控件。 多连杆式悬吊(multi link) 虽然这属于双A臂式悬吊的进化形，不过相较于双A臂式悬吊仅由上下2根悬吊臂组成，这种悬吊则由3-5根的连杆来决定车轴的位置。由于各悬吊臂互相分离，配置的自由度极高，方便进行更细腻的调校。并且在由数根悬吊臂共同支撑的情况下，可以严密地监控悬吊系统几何的变化，轮胎接地性亦佳。在高性能的FF驱动车种一季大马力的后轮驱动车种当中，常以此为后悬吊，以维持在高速领域的动态稳定性和确保马力。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:12:2","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"车辆矫正 如果你身边的家具或椅子上装有移动的车辆，请稍微留意一下。从正上方俯瞰，便会发现车轮的中心轴与它被装在家具上的轴心位置并未对齐。在移动家具和椅子时，车轮之所以不会乱摆，而能朝着固定的方向前进，这是多亏了这样的位置差。 另一方面，假设我们把轮胎拆下来，任其在地面上滚动，那么躲过滚动时轮胎的接地面紧密地沿着地面，轮胎便会直线前进；然而若转动时只使用到一部分的接地面，就会发现轮胎会朝着特定的方向转弯。 这说明了当轮胎固定在车身上时，只要给予各种不同的角度，便能让轮胎在适合车子的运动条件下运作。这就是所谓的车轮矫正(whell alignment)（悬吊系统几何）。 行驶-过弯-停止的基本原则建立在4轮矫正处于正确地装置状况下，这道决定轮胎位置的手续将可引导出轮胎的性能，设置发挥决定车子特性的效果。 具体而言，车轮校正的代表性因素共有如下所列4项： 从车身上方俯瞰时轮胎的角度————束角； 从车身侧边看去时悬吊的倾斜角度————倾斜角； 从车身正面看过去时轮胎的扁平度————外倾角； 车身正面看过去时轮胎的扁平度————外倾角。 这些角度都必须以0.1mm或0.1度的精确度加以管控，只要有些许的误差，便会影响车子的直进性能，或让操作感觉起来有异。因此，务必谨记这些因素会对车造成的影响。 束角(toe angle) 自车身上方俯瞰时，左右轮朝外侧展开的角度。当轮胎朝向行进方向的外侧展开时，称为外束角(toe-out)，而朝内侧收敛时，称为内束角(toe-in)。此角度会大幅影响直进性，设定角度过大时将会使轮胎产生偏磨损。 后倾角(caster-angle) 从旁看向车轮时前悬吊的倾斜角度。这个角度除了有抑制轮圈横向震动的效果之外，还具有自校准扭力(self-aligning-torque)，打方向盘是会尝试着将轮圈转回直进状态的作用力的功用。如果左右轮的此角度不同，则车子会偏向角度较大的那一侧，导致在制动时无法操作方向盘的现象。 外倾角(camber-angle) 从车子正面看去，轮胎下册变宽的状况较做负外倾，而上侧变窄的状况则称为正外倾。在正常状态下，为了防止负重时轮胎呈外八字行，因此会实现设定为上方较开的角度。 内倾角(king-pin-angle) 从正面看向轮胎时，固定轮圈轴心的倾斜角。这个角度基本上用来输入自路面的作用力，以防止方向盘失去控制。主要影响车子的直进性、操作方向盘时的复元力（自校准扭力）、方向盘操舵力。 \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:12:3","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"汽车与路面的交会点 TIRES 引擎动力经由传动系统和悬吊，最后通过轮胎传到地面。无论是什么车种，行驶时都无法超越轮胎所能负荷的性能。 \r","date":"2019-07-16","objectID":"/beyondtheapex/:13:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"高性能轮胎的条件 轮胎的功能主要分为4项： 支撑车身重量的负重支撑功能； 缓和来自路面冲击力的缓冲功能 开始行进与停止的制动/驱动功能； 安定地在直线与弯道上行进的路线维持功能。 改装轮胎时，必须在确保上述4项功能之间取得平衡后，才能按照各种轮胎不同的性能与特性进行调校。 就重视行驶功能的跑车轮胎而言，如果提升制动/驱动功能和路线维持功能，也就是有关开始、行进与停止的项目，显得格外重要。具体的做法是提升接触地面的橡胶的抓地力，并且提高刚度以抑制轮胎负重时的变形程度。如此一来，以过弯时为例，就可以让车子对方向盘操作的反应变得更敏锐，大幅提升回转速度。 当然，高抓地力的轮胎也有其缺点。这种轮胎虽然在过弯时负荷极限较高，但是一旦超过了极限就会变得难以控制，因此需要箱单的驾驶技巧。另外，这种轮胎也会增加多悬吊与车身的负荷，打破抓地力的均衡，使得过弯中的翻滚量变大。这意味着要使用这种轮胎，车子也必须有足以支撑的负荷的能力。而且由于轮胎与路面的摩擦力较大，使得磨损迅速，会使得搭乘感受恶化，噪音也大。 在泾滑路面上行进时，刻在轮胎接地面的满纹将会大幅左右其性能。这些满纹的目的在于排除存在于轮胎与路面间的水分，然而排水性能和接地面的刚度之间却有着相对的关系。在跑车轮胎中，两者间的平衡特别难以取舍。 汽车无法超越轮胎所能负荷的性能行驶，因此必须具备相关知识，才能选出符合自己的驾驶风格的轮胎。 胎面胶料(tread compound) 用于接地面的橡胶。高性能轮胎使用抓地力强的软质橡胶，由于与路面摩擦力大，磨损迅速。而另一方面，一般车种使用的则比较表示耐磨损性，选择的硬质胶料就仅有一般水准的抓地性能。另外，虽然橡胶在未升温到某种程度时呈现坚硬的状态，不易发挥原本的抓地力，然而过热时也会使抓地力降低。 胎面花纹(tread pattern) 即雕刻在接地面上的纹路。主要目的在于（随着转动）将路面的水排出去。许多汽车为了提高排水效果，还会特别采用具备指定方向性纹路的轮胎。另一方面，由于胎纹是造成接地面刚性降低的主要原因，所以高性能轮胎通常会省去细微的纹路，全部采用较粗的胎纹。而有些轮胎甚至会使用左右非对称的纹路，减少在过弯时会被强力地压在地面外侧部分的胎纹以提高胎面刚度，并将较多的胎纹设置在内侧以改善排水性。 胎身刚性(casing rigid) 轮胎的横剖面有胎面、胎臂、各胎体层组成有如一容器状，而这种结构的刚度就称做胎身刚性。来自路面加诸于胎面的力将会传达到各部位，最后由胎圈底部承受。也就是说，在加速/减速、过弯这些对轮胎造成庞大负荷的场合，为了不使轮胎发生不必要的扭曲，重要的是提升轮胎整体的刚性（胎身刚性）。然而，刚度越高，虽然能提升车子的运动性能，却会损及搭乘时的舒适度感。这也是为什么调校轮胎时，必须考虑其扮演的角色和使用目的。 \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:13:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"以吕制为主流的轮圈 WHEELS 簧下重量每轻1KG，收到的效果是簧上重量轻量化的15倍。 想要彻底在起步、加速、制动、过弯发挥出完整性能，绝对少不了选用轻巧的轮圈。 ","date":"2019-07-16","objectID":"/beyondtheapex/:14:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"簧下重量 吕制轮圈装饰性意义虽强，但一方面也仍对形式心梗造成不小的影响。 车子需要最多动力的时机在于起步时。想要让车子由静止状态稍稍开始移动，需要极大的动能。如果轮圈较重，则不易使其转动；所以轮圈越轻，便只需少量的动能(引擎马力)便可让它转动起来。 因此这项条件就称为簧下重量，会大幅影响车的运动性能。轮圈和轮胎越轻，不仅起步、加速性能会提升，制动时也容易停止轮胎的转动(刹车较为有效)。另外，悬吊的运作也更加流畅，路面运动表现和搭乘舒适感也都会获得改善，更能节省燃料费用。 目前成为主流的吕制轮圈，在优良的导热性、热容量以至于排除刹车热的效率方面的表现都十分出色，而且比起铁材料，耐腐蚀性更是优异。 而在更换轮圈时，要特别注意尺寸变大导致重量增加。特别是尺寸大幅提升时，通常也会使得簧下重量大幅增加。因此必须审慎考虑扁平轮胎所带来的好处，以及随之增加的重量所带来的坏处。 结构： 单片式(one piece) 轮框部位和轮盘部位一体成形，是最基本的结构。由于在制作上于锻造后进行切削加工，因此尺寸精确度极高。虽然在设计上自由度较小，不过因为零件数量少，重量较双片式和三片式来得轻，在重量平衡方面表现也相当优异。 双片式(two pieces) 分别制作轮盘部位和轮框部位，使用螺丝和螺帽，或用焊接方式连接两者的结构。这种作法允许在轮盘和轮框分别采用不同的材质（镁、铝、钛…）和制造方法（锻造、铸造），因此在调整偏距值和设计轮盘的自由度上较高。 三片式(tree pieces) 焊接起表面的轮框部位和内侧的轮框部位，再用穿孔螺栓组装轮盘部位的结构。具有双片式的特征与优点，但在重量上较为不利，因此许多重视时尚设计感的轮圈都采用此结构。 制法： 铸造(casting) 将高温融化的铝液注入模具中使其成型的制法。用在双片式和三片式轮圈当中，可以提高轮盘部位的设计自由度。反过来说却也因此必须为了维持强度而增加厚度，使得原本该材质相较于钢铁材质在重量面的优势变得比较不明显。由于制作成本低，是为目前铝制轮圈的主流方法。 锻造(die casting) 用数千吨的高压压缩金属块（令金属分子重新排列），使其变成高韧性、高硬度的材质。由于成品强度由于铸造，所以可以牺牲厚度换取亲量化。然而却也因为高硬度的特质，使得成品虽然抗拉力机枪，但是对扭曲变形力的承受力却较为脆弱，且制作成本较高，设计上限制也多。在材料方面不至于铝制，在赛车和部分跑车当中，设置还可以看到选择了比铝还轻的镁制轮圈。 \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:14:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"对车身作用的空气力 AERODYNAMICS 车身设计的影响力足以全盘改变汽车的高速性能。从极速、稳定性以至于经济性能都与此息息相关。现在讨论车子时，空气力学已是无法忽略的一大主题。 \r","date":"2019-07-16","objectID":"/beyondtheapex/:15:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"空气阻力与异力 在高速行进间，空气阻力将发挥极大的影响力。这道肉眼看不见的空气墙，在车速越快时，会夺走越多车子的行进动力。 空气阻力所造成的影响大约从时速80公里以上便开始无法忽视，之后更随速度提升等比放大。也就是说当速度提升为2倍，阻力便成为4倍；速度提高3倍则阻力可达9倍。虽然实际上还必须将轮胎的转动阻力等因素考虑进去，不过，当引擎马力无法冲破这道空气墙时，那就是这辆车的极速。因此对重视极速与高速性能的带车与跑车而言，如何减低空气阻力的重要性自然不在话下。就连对以讲求节省燃料费用为诉求的车种来说也不容小觑。 车高较低的阻力较小，而车身外型则以能够顺畅地将行进气流送往后方的流线型与楔形较为吃香。还有一种去除车身表面多余的凹凸起伏（齐平表面处理），同样是可以降低空气阻力的设计。 仍需留意的是，空气阻力较小的车身，从侧面看去通常会呈现像是飞机主翼的形状。在这样的车身上，流动在上方的空气快于下方的空气，导致产生让车身往上方浮起的作用力（昇力的问题），然而要抑制昇力却又必须增加空气阻力。因此，如何在空气阻力和昇力之间取得平衡点，便是开发车子时的重要关键。 另外，在高速行进间会打乱车子直线行进的横风，也是无法忽视的重要因素。在空气力学方面，必须考虑进包含空气阻力、昇力以及偏向力矩各种条件在内的整体平衡。 正面投影面积(frontal area) 从车身正面望去时的车身剪影。此面积越广，必须承受越多的行进风阻，阻力也就越大。跑车之所以将车身压低，就是为了尽量缩小正面投影面积。因此箱型车或小货车在这方面必然较为不利。 Cd值-风阻系数(constant drag) 这是用来表示当风吹在某个物体上时，气流流动的顺畅程度的系数。实际上在行进间会造成问题的空气阻力，就是一次空气阻力系数乘上正面投影面积所得。因此即使跑车的Cd系数高，只要正面投影面积小，承受的空气阻力便小，而向房车这类车种可说刚好相反。 CL值-昇力系数 这是用来表示高速行进间的行进风产生的让车身上浮的作用力的系数。而相反地，将车身往下压的作用力则称为下压力或负昇力。想要获得下压力，必须增加空气阻力，因此为求稳定车子的动态，必须将车身前后的下压力调整到最佳平衡。 CYM值—偏向力矩系数(constant yawing moment) 行进间所承受的风力不仅限于前方。当风力来自各种方向时，产生在车身中心轴周边，视图使其回转向的作用力=妨碍直线前进性能的力就称为偏向力矩。CYM值小的车种比较耐横风，而一般来说重心高度较高的高车身车种在此方面较为吃亏。 \r\r \r\r改装汽车 Tuning and Settings \r","date":"2019-07-16","objectID":"/beyondtheapex/:15:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"提升引擎的战斗力 一味提升引擎马力，只会让车子更难驾驭，无助于让它奔驰得更加快速。因此必须先看准了追求的目标为何，如何炒理想迈进，才能做出符合车子用途或赛道条件的完美调校。 \r","date":"2019-07-16","objectID":"/beyondtheapex/:16:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"微调 更换引擎电脑与改善排气系统的效率，可以说是为了提升引擎基本体力而做的处理。这些处理会成为之后针对引擎本体进行机械调校、加装增压器等正式调校工程的基础。虽然这些处理无法大幅提升马力，但效果却会展现在转速提升速度变得更敏锐、油门反应速度更快等，让驾驶员操作起来更舒适。另外，这些调校对于引擎造成的负担较小，且具有在高负荷运作下保护引擎的效果，可以带来提升引擎耐久度的好处。 电脑(computer) 通常是改写存有控制引擎的相关资讯的ROM中的资料，也称为记忆体调校。当提升增压器的增压质、更换进排气系统的零件以及对引擎本体做过变更之后，就有必要进行记忆体调校。 火星塞(spark plug) 想要对燃烧室内的混合气体点火使其正常引爆，需要产生强力的火花。即使是一般引擎，如果持续使用一般火星塞在高负荷下运转，便会导致过度燃烧。特别是在通过调校提升过马力的引擎当中，爆炸力增强将使燃烧室温度上升，导致变得容易发生异常燃烧现象(pre-ignition，也称预燃)。因此必须提高火星塞的耐热度，选择高价的火星塞。 空气滤清器(air cleaner) 空气滤清器能够去除引擎进气中含带的灰尘与异物。一般款式的阻力较大，会对马力输出造成不利影响，因此更换成阻力较小的竞赛用款式较为理想。这样带来的效果与其说是提升马力，不如说是会提升高转速领域的引擎反应速度和加速时加速性能方面的表现。同时，吸气音也可变得更大声。 排气系统(exhausut system) 降低排气阻力能够使引擎转速上升的速度、踩踏板时的油门反应速度变得更加敏锐。此调校对于利用排气动能驱动涡轮增压引擎来说效果尤其显著，甚至只靠着调校消音器便能提升1-2成马力。不过，在更换零件后引擎的扭力特性也会随之变化，因此动手调校引擎前应该要根据调校目的，预先设想调整后想得到的特性。 机油(engine oil) 高马力引擎内部各处都必须承受极大的压力，因此也必须使用高性能机油。机油除了润滑之外，还负有冷却、保持气密性等功用，因此若发生油膜破裂等情况，将引发缩缸导致马力降低。而在高速运转的金属零件之间，如果来不及润滑，很容易便会烧毁。另外，在选择机油时，影响摩擦损耗的黏度也是重要条件之一。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:16:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"检修 在以量产为目的的引擎当中，一般状况下的运作精确度可能未臻完美，导致无法发挥原本应有的马力。要改善这种状况，可以通过把引擎全面拆解为零件，重新加以精密组装，以压榨出引擎的所有性能。这是称为**检修(overhaul)**的作业步骤，若同时配合调整各零件之间的平衡与轻量化，可以收到更显著的效果。若调校条件对于排气量没有特别限制，借此机会同时提升引擎汽缸本身的容量，可望更有效率、更合理地提升马力和扭力。 提升排气量(scale up) 这是在对引擎本身进行调校时，可以最确定收到最高的效果的工程。让引擎燃烧更大量的混合气体，便可得到更大的马力。 在做法上则可分为削薄汽缸内径，该用大口径活塞的扩大缸径式，或是更换曲轴与连杆等零件以增加活塞衝程的衝动式两种。虽然同样是增加排气量，但两者在特性上相当不同。前者适合增进提升转速以取得马力，后者适合用以提升中低转速领域的扭力。最近的引擎由于普遍经过轻量化处理，汽缸体的零件厚度变得较薄，因此想要大幅地提升内径更加困难了。 调整平衡(balancing) 在一般状态下，每个汽缸的活塞和连杆之间都存在着些微的重量误差。而曲轴的旋转平衡若不佳，则会产生阻力，成为损失马力的主要原因。因此，调整平衡所要做的就是分解引擎，并精密地测量、同一每个零件的重量，以及修正旋转平衡来确保引擎运转顺畅，并有效率地引导马力。如果只靠加工零件无法达到上述目的时，甚至必须更换全新的零件。对于参加无法大幅改造引擎的统一规格赛的赛车而言，调整平衡可说是必备的已向调校作业。 轻量化(lightweighting) 惯性会出现在以超高速运转的引擎零件上，造成摩擦损耗而折损马力。能够解决这个问题的便是轻量化处理。基本上，轻量化必须与调整平衡作业同时运行，不过，若过度轻量化削薄零件的厚度，将会发生耐久性发面的问题。 强化(build up) 在大幅调校引擎之后，随着燃烧力变大，会对各部位零件造成庞大的负担，甚至有造成损坏之处。为此，虽然提升零件强度势在必行，然而在另一个方面，也不能忽略要保持轻盈的原则。经常被用来解决这个难题的，是以钛合金为首的各种新材质，以及用锻造工法制造的强化零件。它们具备一般零件难以相比的轻巧度，且能兼顾强度与刚度。在赛车用火调校过的引擎当中，使用铝制锻造活塞、钛合金值连杆等零件，已成为标准。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:16:2","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"高转速化 由于马力=扭力x转速，所以想要提升马力，可说如何提升引擎转速。这个调校工程主要是和汽缸盖有关，关键在于提升高转速领域的进排气效率。主流做法是更换为凸轮运作角度更大的高角度轮轴，同时补强凸轮周围的结构。这样的处理可以收到与扩大进排气门相同效果，能够在高转速领域带来压倒性的马力。 气埠(port) 进气/排气埠分别是混合气体与燃烧后废气的通道。理想状况下，这个部分应该尽可能接近光滑；然而基于成本考量，在一般引擎中很少会讲究到这个部分，因此往往会对进排气造成阻力。造成问题的主要是铸造制品表面特有的粗燥起伏、与气流通道的尺寸大小或变形等。因此，有必要把气埠研磨成有如镜面般光滑，让进排气变得更顺畅。研磨气埠即可改善高速运转时的操驾感，然而若没针对汽缸整体同时进行更换凸轮、研磨汽缸表面等调校，则难以收到原本的功效。 气门(value) 在研磨气埠以及更换凸轮的同时，建议同时考虑扩大气门。扩大进气门的开口面积，可以增加进气量，提升填充效率。当然，气门尺寸越大便会越笨重(惯性作用力越强)，因此大多会选择以质轻的钛材料制造，来解决此问题。 气门弹簧 为了防止引擎在高转速运作时，气门弹簧发生异常震动，也就是所谓的激振（凸轮的运作跟不上弹簧伸缩速度的状态）想象，势必得要补强弹簧。在搭配高角度凸轮轴时更是如此，否则要是持续使用一般弹簧，将无法承受增加的气门扬程量，最糟糕的情况将会使得弹簧紧靠上凸轮导致锁死，或者让气门与活塞互相接触。但是若搭配国语强力的弹簧，又会造成引擎的阻力，或是加速气门周边磨损，因此必须特别注意。 凸轮轴(camshaft) 凸轮轴时负责开关进排气门的轴，而所谓的高角度凸轮轴=高扬程图轮轴，则是指高凸轮的抬举部分，以延长气门开启时间的凸轮轴款式。选用这种凸轮轴，可收到和扩大进排气们相同的功效。这虽然会降低在低中速领域的扭力，但是却能大幅提升高转速领域的马力。虽然无法否认这是种极端的特性，不过确实是在提升自然进气引擎的马力时最基本的调校手法。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:16:3","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"高压缩化 在引擎当中，当活塞上推以压缩混合气体的力道越强，燃烧力也就越强，进而能引出更强大的马力和扭力。针对这个部分所做的调校，主要以汽缸盖的燃烧室容量设计为重点。不过要是过度提升压缩比，除了会造成引擎运转时的阻力，也可能导致异常燃烧。因此在调校时，也必须调整燃料、延迟点火正时、换成冷式火星塞、补强活塞和连杆等部分，以对抗更强的爆炸力。 活塞(piston) 在提高压缩比时，最具代表的调校手法便是更换成高压缩比活塞。不过，在压缩比提高后，混合气体的温度、燃烧温度都会变高，容易发生引擎爆震现象，所以必须采取改善混合气体动线等相关措施加以因应。 燃烧室 在针对燃烧室所作的加工方面，比较简便的做法是把它修整成排气和点火效率优良的棱顶形状，但以因提高压缩比例预防异常燃烧所做压缩涡流加工为主流。这种加工方式是削薄燃烧室内压力变高的挤流区，稍微降低一些压缩比。但是在进行压缩涡流加工之后，各个燃烧室的容量将会出现差异，所以必须精密地重测各燃烧室容量。 汽缸盖(sylinder head) 以0.1mm的细小单位研磨汽缸盖的底面，这种手法称为盖面研磨。基本上这么做的目的在于减少燃烧室容量以提高压缩比例。盖面研磨的另一种用途，在于用来修正当引擎在过度严苛的热能条件下运作时，发生在汽缸体和汽缸盖之间的变形现象。 汽缸床垫片(head gasket) 结余汽缸盖与汽缸体之间，用以保持气密性，防止压缩气体外漏的金属板，就叫汽缸床垫片。将这块金属板磨得比一般状况下更薄，也能收到与盖面研磨相同的效果——即减少燃烧室容量以提高压缩比。最近常见通过选用热传导率高、强度优异的不锈钢作为汽缸床垫片的材质，以同时达到防止压缩气体外泄和调节压缩比的目的。 涡轮增压(turbo boosting pressure) 显示涡轮增压器能够吸入多少空气、并加以压缩的数值，即称为增压值。这个值以压力的单位kg/cm²加以表记，愈高表示能够引出愈大的马力。然而，在吸入大量空气的同时，也必须要提供足够的燃料与之搭配，因此需要借由电脑调节燃料供给，并更换能够喷出大量燃料的喷油嘴等零件。而引擎内部也必须具备足够的强度以承受增加后的爆炸力。 高流量涡轮(high flow turbine) 扩大用来压缩进气的压缩机轮部分，以争取更多风量的涡轮。基本上都采分解一般涡轮，只更换其中的压缩机轮部分的做法。由于涡轮经过削减处理惯性重量减轻，因此擅长于快速地发挥增压效果。这种做法几乎不需要牺牲引擎反应速度，便能提高马力。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:16:4","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"增压器 只需要提升增压和加大增压器自身的大小，便可发挥提升排气量相同的效果。如果搭配机械调校一起实施，则可望更加显著地提升马力。然而增压器加诸于引擎的负担甚至大过自然进气式，因此必须做出相对的因应措施。在自然进气引擎当中，提升马力的关键在于提高压缩比，不过，在使用增压器的引擎当中，反而得要降低压缩比，才能防止异常燃烧、或增加的爆炸力造成零件损坏。若使用的是涡轮增压器，泽荣旗产生动力迟滞现象，为了避免使引擎反应速度季度恶化，还得特别下工夫加以处理。 大容量涡轮(big turbine) 由于涡轮的大小决定了它的极限功率，所以这种调校手法就是直接将它更换成更大容量的涡轮。虽然可以飞跃性地提升马力，然而，却相对地因为要转动更大的涡轮，将使得引擎反应速度变得较为迟钝。除此之外，除非具备足以产生大量排气动能的排气量、或引擎本身具有足够的潜藏性能，否则这样的调校手法会使得地转速领域的扭力降低，并且只有在高转速领域才能得到增压下过。这样会让车子变得难以驾驭，是进行此种调校手法前应要事先考虑的部分。 中冷器(inter cooler) 能够冷却受涡轮增压器压缩而变得高温的空气，以提高引擎填充效率，进而提升马力的套件，便是所谓的中冷器。这种装置在市售车种当中亦属必备，尺寸越大、冷却效果也越强。不过如果因此装上过大的中冷器，会让压缩空气停驻于内部的时间变长，导致增压下降。这种现象叫做压力损失，依据条件不同，可能成为让增压值下降10%-20%的肇因。 机械增压器(super charger) 机械增压器和涡轮增压器同样采用将压缩空气压入引擎当中获得马力的设计原理。也就是说，在使用机械增压器时，只要提升增压值，同样可以提升更多的马力。机械增压器和涡轮增压器一样，都只要用螺丝便能装置在自然进气引擎上，可以轻易地大幅提升马力。由于结构上的设计，不易在踩踏油门时产生动力迟滞的状况，所以在技术赛道上非常占优势。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:16:5","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"转子引擎 调校转子引擎的重点在于提升进气效率，也就是如何扩大进气埠，将更多的混合气体送入燃烧室。这和在往复式引擎当中改用高角度凸轮轴得到的效果类似。不过值得注意的是，在转子引擎上扩大与移设气埠后得到的效果较大，同时车辆特性改变也较明显。在转子引擎上同时调校气埠和涡轮增压器，两相搭配之下可望引出跟多引擎的潜藏性能。 调校平衡(balancing) 转子引擎的结构比起往复式引擎相对简单，零件数目也比较少。因此，只要提升各零件的精确度，仔细地加以组装，便能够引导出引擎的潜藏性能，而改装重点则在于叫做sealset的作业。这是讲相当于往复式引擎活塞运动的三角气封加以重新组装，让它们具备相同的间隙。借此可以让转子室中的转子在保持着正确压缩比下，以极度顺畅地方式回转。反过来说，若气封发生问题，将造成马力降低，最糟糕的情况下将会导致烧毁。 侧边气埠(side port) 通过扩大设置在殻体侧边的进气埠口径，可以比平常更早开始吸入混合气体，进而提升马力。这种做法可以获得与在往复式引擎上该用高角度凸轮轴同样的效果。 桥状气埠(bridge port) 这是调校侧边气埠的手法之一。由于好像在磨削过的气埠间架起了桥梁一般，因而获得此名称。之所以在2道气埠开口之前设置桥状的通道，是因为要预留在气埠扩大到接近极限时，供三角气封通过动线范围。 外环气埠(peripheral port) 以特殊接著剂将通常位于普通引擎殻体侧边的进气埠塞住后，再将它移至转子室上部的做法。由于这可以让混合气体直接送入转子室内，因此优点是在高回转领域可以引出强大的马力。然而，另一方面却会失去在一般配置下，依据低回转/高回转区隔不同的混合气体进气方式以确保常用转速领域下扭力的功能，今儿使得引擎特性走向极端，变成在高回转领域能够发挥压倒性的马力，但低回转领域却几乎无法产生扭力。 组合式气埠(combination port) 结合了侧置气埠和外环气埠的调校手法。采用序列式控制，让低转速领域当中只有侧置气埠作动，而高转速当中只有外环气埠会运作，兼具了双发的优点。 \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:16:6","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"调校驱动系统 驱动系统负责将引擎效能转化为速度。除了必须具备良好的效率，将马力尽可能原封不动地传导至路面，害的要具备能够确实承受高功率的强度。 ","date":"2019-07-16","objectID":"/beyondtheapex/:17:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"终传齿轮比 想要将引擎动力按照重视速度、或重视加速的需求加以分配，可以通过改变终传齿轮的齿轮比来进行，亦即改变动力系统的终传比。特别是针对终传比进行低速档化，将可以更容易地引出拥有高转速、高马力效能的极端引擎特性，并可显著提升加速性能。 引导出引擎的性能。 高速档化(high geared) 这种手法可以提升在低引擎转速下的车速，因此在重视极速的情况下较为有利。另外，对于降低燃耗也很有效果。然而反过来说，想要提升引擎转速取得马力或扭力带时，将会产生时间延迟，所以不可否认地在加速上确实较为缓慢。在出了狭窄弯道后重新加速之类的情况下，将会因不易引出有效的马力与扭力，导致难以获得充分的加速力。 低速档化(low geared) 这种手法即使在3速和4速这类较高的档位下仍能轻易保持高转速，所以虽然会牺牲极速，但却能有效地引导出马力和扭力、提升加速性能。而在过弯时也能充分发挥引擎性能，使车子能在出弯时重新加速，因此十分适合用在以狭窄弯道为主的技术赛道。不过，随着引擎对油门操作的加速反应更加灵敏，必须留意转速提升过快的情况。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:17:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"变速齿轮比 一般而言，针对变速器所做的调校，主要指的是将齿轮进行密齿比化（让相邻齿轮的比率更为接近），方能够比较容易地维持有效的马力带。这样做虽然能大幅提升加速性能，但根据与终传齿轮之间的搭配方式的不同，可能容易发生转速过快、需要频繁地换挡的情况。 密齿轮比(close ratio) 调校手排变速器的各齿轮比，使其具有相近比率后，这样的变速器通常就称为横向变速器。当比率愈接近时，在切入高档次时引擎转速下降幅度愈少，可以更有效率地引出马力。用此方法再搭配高角度凸轮轴的助力下，可以说是特别适合用在马力带狭窄的自然进气引擎的此轮配置。通常要采用此方法时，会顺应赛道结构等情况，搭配终传比一起进行设定。 疏齿轮比(wige ratio) 和高速档化一样，一般市售车款重视降低燃耗，因此会为了抑制转速而刻意地将各档齿轮比设定得比较大。在如此设定下，即便是切入高档位，引擎马力却仍旧只能和缓地传导至地面，也等于是牺牲了车辆的加速性能。不过，通常不会将1到5档，甚至包括6档在内的所有档位都改为疏齿轮比设定。比较常见的做法是将用于起步、加速的1、2档设定为密齿轮比，在3档以上设定为远齿轮比，再顺应引擎特性和赛道配置，来选择搭配较密或较疏的此轮比率设定。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:17:2","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"离合器 减少驱动力损失，提高引擎反应速度。 想要将调校过后所增加的马力，尽可能地在未经损失的情况下传导给变速器，并确实执行换挡，则必须要补强离合器。离合器只要稍微打滑，便会导致车辆的加速性能下降。因此，合理的做法是配合马力/扭力提升的比率，提高离合器片的摩擦力与离合器压板的压著力。 离合器片与离合器压板(disc cover) 要想补强离合器，最传统的做法是将离合器片与离合器更换成强化过的款式。通过提高离合器片的摩擦力和离合器压板的压著力，可以更确实地将引擎马力传导给变速器。这些是引擎马力提升过后必备的零件，在家时跑车等严苛的离合器操作条件下，也不会产生反应变慢的情况。另外，离合器片目前以摩擦系数高，耐磨损性优异的金属制碟片为主流。 多片式离合器(multi plate) 相对于一般的离合器采单片式，补强过的离合器大多配有复数碟片，以扩大摩擦面积与加大压著力，来提升引擎马力的传导效率。多片式离合器从双片式到四片式都有，而增加的摩擦力大小与碟片数量成正比，摩擦力愈大便适用于马力愈高的引擎。此举虽然会提升动力系统的反应速度和耐久性，但在操作上却会产生缺点。如需更重的踏力，以及更细微的离合器接合动作等。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:17:3","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"飞轮和传动轴 想要提升引擎提高回转的速度、反应速度以及加速性能，将驱动系统加以轻量化可以带来相当大的效果。然而极度轻量化的飞轮，在爬坡时将难以产生足够的扭力，因此为了补强该特性，需要特别加以调校。 轻量化飞轮(lightweight flywheel) 装置在曲轴后端(离合器前方)的滑车称为飞轮，主要用途在于抑制引擎回转的落差。飞轮重量越重，回转起来越顺畅。然而飞轮的种类却会对追求速度方面带来负面影响，因此加以轻量化才是理想做法。虽然如此一来会让飞轮回转的顺畅度受到影响，也会使引擎扭力减少，但相对的却能使得转速提升速度和引擎反应更加敏锐。 领量化传动轴(lightweight propeller shaft) 介于变速器和差速齿轮之间，传导引擎马力的传动轴在经过轻量化之后，也能带来提升引擎反应速度和加速性能的好处。轻量化传动轴的材质主要为碳纤维和强化塑胶(FRP)，重量约只有一般款式的一般。减轻重量固然重要，不过是否保持正确的回转平衡则同样不容忽视。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:17:4","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"限滑差速器 将动力确实地传导至路面。 想要追求快速过弯的目的，绝对少不了能将引擎马力确实传达给路面的限滑差速器(LSD)。而在各类限滑差速器当中，能够发挥最大差速限制能力的，是利用多片式离合器产生压著力的机械式限滑差速器。这种限滑差速器最大的优点，在于能够自由设定开始生效、乃至生效为止的引擎反应速度。换言之，它能够配合驱动系统配置等车辆特性，驾驶风格与赛道配置，取得最适切的驱动力。然而，在发挥极大的差速限制力的同时，对于内部零件的负担也会增加，所以更要确实做好更换机油、全面检修等定期保养措施。 锁定比(lock ratio) 锁定比是用来显示LSD功效的数值。0%时为使用一般差速齿轮时的状况，而100%则表示差速器锁死。此数值越高，表示差速限制力越大。但一般来说并不是锁定比愈高愈好，理想值和驱动方式、车高和轮距等，都有很大的关联性，也会因为希望将车子调教成何种特性而有所不同。如果锁定比设定超出了理想值，则会在入弯初期呈现强烈的转向不足特性，并显著地影响过弯性能。一般来说，车辆在锁定比设定为约50%左右的情况下最容易操控，同时也能得到充分的差速限制效果，不过，仍有必要通过反复的测试，从错误中找出最合适的数值。 介入扭力(initial torque) 介入扭力指的是差速齿轮箱内部压制碟片的压力。提高或降低此压力，可以变更LSD达到锁死前的时间。提高介入扭力，可以让对油门操作的反应速度变快，转瞬间便能使LSD锁死；降低介入扭力，则能使LSD平缓地达到锁死，乘驾感较为舒适。在调校汽车性能的过程当中，提高扭力是基本需求。不过，若因此而使得转向性降低、或在FF式驱动车种中造成扭力转向增强等缺点，也同样不容忽视。附带一提，近来在低扭力领域当中，能够发挥极高差速限制效果的车种，有愈渐增加的趋势。 机械式LSD的种类 1WAY 只有在踩踏油门时运作的LSD。由于不会在放开油门时运作，所以可以运用一般差速齿轮所具备的内轮差修正功能，更加顺畅地攻略弯道。这种LSD特别适合用在转向不足现象较强的FF式驱动车种上，不过会使得册子在踩踏/放开油门的情况下动态出现显著差异。 2WAY 在踩踏/放开油门两种情况下都会生效的LSD。在初期会发生较强的转向不足现象，不过，由于在减速时能够确保车身动态稳定，让人可以放心地攻略弯道。引擎反应速度也极为优异，让驾驶员可以积极地踩踏油门过弯。 1.5WAY 具有1WAY和2WAY双方特性的LSD。除了能够保持在加速方向的LSD效果，也能抑制LSD在减速方向的效果，同事也考虑到了在攻略弯道途中转向的容易性。可称得上是不会让驾驶人感受到车子的特殊习性，且能够应付各种状况的LSD。 \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:17:5","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"为车瘦身 轻巧、高刚性的车身，是高速奔驰的基本要件。无论提升了多少引擎马力，若搭配的是笨重脆弱的车身，还是难以发挥速度。 \r","date":"2019-07-16","objectID":"/beyondtheapex/:18:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"高刚性/轻量化 为了将车子的运动性能提升至极限，无可避免地一定得对车身做轻量化以及高刚性化的调校。车身轻量化不仅对提升加速性能而言十分重要，也对改善刹车和过弯性能有很大的影响。另外，为了确保悬吊在高负荷状态下能够正确运作，同时兼顾轮胎的接地性，高刚性化同样是不可或缺的步骤。为了让驾驶员能够瞬间掌握车辆动态，采取正确的操作，也绝对需要一具不易变形的坚固车身。附带一提，在路面阻力系数极低，且有著来自纵横两方向的强力G力的纽堡林赛道，若尘神未具备坚实刚性，很可能连一圈都没办法顺利跑完。 拉杆(tower bar) 连接悬吊和车体相连部位（轮胎室上端）左右两侧的长棒叫做拉杆。车子装上拉杆之后，将能提升车身前部的刚性，并使悬吊能够正确运作。对于方向盘操作的反应也会更加锐利。基本上，拉杆应该在针对减震筒、弹簧、襯套等悬吊系统进行调校时一并装上。一般来说，拉杆通常只装在车身前方，不过若只考量到提升刚度的需求，最理想的做法是在车身前后都装上拉杆。 点焊(spot welding) 车身是用冲压过的金属板件接合起来所制成的。在所有接合手法中，最具代表性的就是每个固定的间隔设一个点建议焊接，称之为点焊。不过，由于市售车种为了讲求生产效率，必须尽可能减少焊接部位，所以容造成车体刚性不足的问题，因此，增加焊接部位的强化手法，就称为增加焊点。这能让车身板件间的接合部位更加坚固，可望大幅提升车体刚性，此外，由于不用增加新的零件即可执行，所以也不需要担心会导致车身变重。 获得正确的操纵性。 防滚笼(roll cage) 防滚笼原本的功用在于保护驾驶员不受变形的车身伤害，但在提高车身刚性时，它也能发挥很大的效果。不过先决条件时这款防滚笼和车顶与车柱之间必须毫无缝隙，稳固且确实地焊接在车身上的设计，而不是只通过螺丝固定的款式。另外，若能尽可能增加支撑点，并架设成有如立体攀爬架的状态，则可提升更多的刚性。 底架(member brace) 底架是看完去和变形的金属制长棒，在强化车舱地板下部刚性的同时，也能通过连接车身底座，限制悬索的多余动态，已完全发挥悬吊的性能。换句话说，就像拉杆从引擎盖内部支撑悬吊和车身一样，底架则是从车身下部支撑着。和栏杆并用不仅效果更佳，还能进一步地提升车身动态的稳定性。 轻量化(lightweighting) 想要提升车子的加速/减速/转向等所有行驶性能，最有效的调校手法莫过于减轻车体重量。在做法上，依照轻量化程度的不同，从最基本的省略空调等行车舒适设备和隔音材质，乃至于将车身板件换成轻质量的铝制或碳纤维制材质都有。或者更讲究一点，还得将车殻本身改为碳纤维材质，并把车架换成铝制。不过，为了在保持均衡的状况下提升行驶性能，轻量化与高刚性化因该要同时进行。另外，若能一并考虑重心高度(低重心)，并主要针对车体的上部进行轻量化，效果会较为显著，效率也跟高。 \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:18:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"增强制动力 调校刹车应该和提升马力同步进行考量。唯有具备足够的制动力，驾驶员才能放心踩油门。调校刹车时不仅得要强化制动力，对于热能也要有万全之策。 \r","date":"2019-07-16","objectID":"/beyondtheapex/:19:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"强化制动力/耐过温衰退性 一辆调校过引擎、提升了绝对速度的车子，相对的也会需要更强大的制动力，以及更高的耐过温衰退性能。最基本的做法是更换来令片，而若要追求极致，则得将整套刹车系统换成大排气量赛车专用的套件。根据调校的需求层级不同，有许多的手法可供选择。不过，即使是赛车用的零件，也未必在各种用途上都能发挥完备的性能，还是应该要按照使用目的来选择零件。一味地加大刹车碟和卡钳的尺寸，可是会增加簧下重量，妨碍车辆运动性能。虽说刹车性能的铁则是必须高于引擎马力，但若因此就在轻量级的车种上装置大容量的系统，则明显大材小用了，极有可能会破坏车辆行驶时的整体平衡。 来令(pad) 刹车来令是在强化刹车时最基本的零件，会大幅影响制动力与耐过温衰退性。来令种类繁多，从街道用到竞赛用都有，然而在如此多样化的选择当中，适温(能够发挥最大制动力的温度)和耐热温度都各有不同，如果不能按照使用目前的选择最合适的种类，则很有可能效果不如预期，甚至对行驶造成不良影响。当然，跟一般的来令片比起来，特殊的来令片磨损较快，对刹车碟的伤害性也较高，为了确保制动力的平衡，通常会前后一起更换。 刹车油(fluid) 用在油压式刹车当中的作用油。为防止气阻现象，竞赛用的刹车油沸点必须在200度以上，但如此一来却也会使得吸湿性极高而容易裂化。 刹车油的DOT级数越高，沸点也就越高，干同事也更容易因吸收湿气而裂化(沸点下降)。因此，竞赛专用的DOT5刹车油，在使用时必须以很短的周期频繁更换。需要特别留意的是，DOT值越大，并不表示制动力本身也跟着提升。 提升刹车的整体性能。 刹车油管(hoos) 刹车油管是刹车油的通道，一般为橡胶材质。因此在紧急刹车等油压升高的状况下，刹车油管将会膨胀，使得刹车踏感变得暧昧不扎实。能够排除这种现象的便是称为不锈钢網的刹车油管。这种刹车油管当中在铁氟龙油管外部披上网状的不锈钢，使其在保有和橡胶同等的柔软性之下，又能防止膨胀。这在竞赛用车种当中是必备的补强零件，并能经常维持直接而正确的刹车踏感。 刹车碟盘 在提高制动力的手法当中，最有效的的便是提升刹车面积，也就是加大碟盘直径以产生更大的摩擦热。然而，换用铸铁制的大直径刹车碟盘同事却会使得簧下重量增加，降低车子的行驶性能。因此，最近市面上开始出现以陶瓷或碳纤维为主要材质的轻量化刹车碟。刹车碟盘是随着使用逐渐磨损的耗材，想要得到应有的制动力，就得定期更换或者研磨。 刹车卡钳(caliper) 对刹车卡钳本身进行的调校手法之一，是干脆升级整个刹车系统。一般而言是将卡钳更换成能够将两侧来令片推夹刹车碟的对向活塞式设计，让刹车来令能够确实紧压刹车碟。而从许多市场车款也采用6活塞式刹车来看，课件活塞数目愈多，愈有助于同一队来令表面施加的压力，达到提升制动力的效果。另外，在对向活塞式刹车系统中，刹车卡钳本体可采一体成型，固定在车体上无需移动，这种配置当中刹车卡钳的刚性高，即使在严苛的使用条件下也能发挥稳定的刹车性能。 \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:19:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"补强车底结构 补强车底结构是重要的调校工程，可以在严苛的行驶条件下稳定车辆的动态，带来正确的操控性。这道步骤的效果足以使得车辆特性大幅转变。 \r","date":"2019-07-16","objectID":"/beyondtheapex/:20:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"变更驾驶特性 在竞赛行驶目的下对悬吊所做的调校，通常意味着为追求速度而牺牲部分乘驾的舒适感。如果只会跑在像赛车跑道那种平坦的路面上，那么车高愈地，将使重心下降，车辆的动态便会愈安定。而悬吊越硬，就越能减少加速、减速、与转向时不必要的动态，让操控性更锐利。当然，实际上若悬吊完全不发挥功用，则重心便不会移动，让车辆的操控性变得极为糟糕，因此，在调硬悬吊阻尼时，应确保在能够运用重心移动的范围之内，并考量前后左右的均衡才是上策。随着车辆特性和路面状况不同，有时为了提升轮胎的抓地力，会刻意地调软悬吊。 弹簧(spring) 除了最基本的利用重心化来提高运行性能之外，同时是抑制过弯时的车身晃动、起步/加速时的后沉现象等，用以稳定车辆动态上所不可或缺的零件。 车高可调试悬吊(height adjust suspension) 拥有了可任意伸缩弹簧长度的车高调整功能，有些还同时具备可调整阻尼衰减的减震筒。各两件搭配的方式种类繁多，可以因应行驶情境做出细微的调整。调整车高的方式则可分为螺丝式、C环式、托架式等。 减震筒(damper) 通过赋予比一般减震筒更大的阻尼硬度，以确保在承受巨大负荷的高速行驶状况下，仍能维持车辆动态的稳定性，并提高操控性。更换与调校减震筒应该要与弹簧同时进行。 随心所以掌握操纵性能。 平衡杆(stabilizer) 通过调高比例，可以进一步提升平衡杆原本具备在过弯时抑制车身晃动的效果。若仅调高前方的比例，则可以使车子呈现出转向不足的特性，仅调高后方的比例，则会呈现出转向过度的特性。 悬吊襯套(bush) 通过强化装在避震装置和悬吊环等零件与车身相连处、以及各连杆的连接部位的缓冲材质（襯套），可以抑制悬吊的多余动态，给予驾驶员直线性的操盘反应与操控性。悬吊襯套的材质以橡胶或聚氨脂等树脂类为主，也有在可活动部位使用金属球（一般称为鱼眼）的种类。 \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:20:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"轮胎的高性能化 高性能轮胎的抓地力虽高，但是超出极限时却也极难控制，可说是有利有弊。因此在选择轮胎时，必须审慎考虑车子特性和动力间的平衡。 胎面加宽(width up) 加大胎面宽度能增加接地面积，则抓地性能自然会提升。不过轮胎的抓地力不仅来自于和地面的摩擦，同时也会因为轮胎的负重而大幅变化。例如，在车重较轻的车子上装上胎面极宽的轮胎时，因对轮胎施加的负重不足而导致无法获得高抓地力，也不是什么稀奇的事。而若是在马力不足的车种上装上尺寸过大的轮胎时，常会因轮胎的抓地力吃掉马力，反而使得车速变慢。因此，配合车重与引擎马力选择适当的轮胎相当重要。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:21:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"提升抓地力/轮胎刚性 高性能轮胎的要件是抓地力与刚性。将这两项条件追求到极致的境界的，是竞赛专用的光滑胎。这种轮胎的接地面胶料会因为摩擦热而融化，让车胎与路面紧密接触，而为了确保地面的刚性，这种轮胎上没有任何胎纹。这样的作法同样可以套用在公路胎上，凡是强调高性能的轮胎，无一例外会选用软质的胎面胶料，并且具备满较浅的粗胎纹。不过，为了确保在湿滑路面上的排水功能，胎面上势必还是得保留胎纹，且胎纹愈多、愈深，排水功能愈强。对轮胎而言，行驶性能和应付湿滑路面的性能时两种相斥的性能，如果将其中的平衡调整到极致境界也是一大学问。 紧紧地抓住地面。 升级轮圈尺寸(inch up) 所谓inch up，指藉由降低轮胎的扁平率（轮胎宽度相对于高度所占百分比），而在不需要变更轮胎外径的前提下，加大轮圈尺寸的手法，但这种手法未必等同于加宽轮胎宽度。主要的有点事当胎肩宽度（高度）变窄时，会减轻轮胎的过弯或刹车时的横向变形程度。这也可说是藉由提升刚性来改善操作方向盘的反应速度与操纵性。然而，极端的inch up将会因轮圈尺寸加大，导致簧下重量增加而显著折损运动性能。附带一提，竞赛用车种当中，inch up本来不低在于藉由扩大轮圈直径，以装载更大容量的刹车系统。 胎面胶料(compound) 用在轮胎接地部位的橡胶材质称为胎面胶料，对于轮胎抓地力有决定性的影响力。重视抓地力的高性能轮胎会使用容易紧贴于路面的软质胶料，特别是赛车胎的表面会因为与路面抹茶生热而融化，利用融化后的黏性牢牢地抓住地面。然而软质胶料虽然能够产生极高的抓地力，但相对地磨损也快。硬质胶料则具有完全相反的特性。选择轮胎时，应该对此基本特性有充分认识。另外，轮胎会随着时间经过而硬化，使得抓地力从全新品的状态开始逐渐劣化。越是软质的胎面胶料，这样的倾向越明显。 胎纹(groove) 刻在轮胎接地面上的满槽称为胎纹，具有在潮湿路面上排水，以保持接地面与路面间的抓地力的功能。另一方面，在干燥路面上进行过弯、刹车或加速等增加轮胎超负荷的动作时，胎纹只会带来使轮胎横向变形等坏处而已。最明显地说明了此一事实的，是赛道用的光滑胎上完全没有任何胎纹。而在试车会与假日车赛中使用的准赛车胎上，为了确保接地面的刚性，仅在胎面上刻上浅浅的、最低限度的胎纹。 \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:21:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"提升空气性能 为了提升高速领域的行驶性能，空气调校不可或缺。反过来说，如果这方面的调校稍有失误，则只会带来不好的影响。想要得到预期的效果，调校必须及其精密。 化解风阻并加以活用。 \r","date":"2019-07-16","objectID":"/beyondtheapex/:22:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"空力调校 一般而言，安装空力套件大多是为了装饰目的。不过对正式地进行大幅调校的车而言，这道步骤发挥了非常重要的功能。空力调校的主要目的是降低在高速领域使车速变慢的风阻、抑制让车身浮起的升力，以提高行驶性能。其中，安装空力套件后产生将车体向下压的作用力（下压力），是提高车身动作稳定性、强化轮胎抓地力时不可或缺的力量，对于提升操纵性有很大的贡献。不过，进行空力调校时，必须注意与包含悬吊在内的车辆整体之间的平衡性，若空力调校不当，往往反而使得行驶性能恶化。 前扰流器(front spoiler) 加装前扰流器的目的在于抑制流入车身下方的空气，以降低升力。不过，在一些稀有的案例当中，帮车子装上外型未充分改装的空力套件，又将是离地高度降低以放低重心之后，加压过的气流不断流入空间变窄的车身下方，反而在车身前方产生升力，造成和原本预期的完全相反的效果。这在最糟糕的情况下，甚至会让车子失去控制。 后扰流器(rear spoiler) 这种空力套件的功用在于优化后保险杠的形状，以抑制车身后方产生的涡流，引导气流更顺畅地通过车身。有的后扰流器和后保险杠一体成型，也有一部分装设在保险杠下方。一般而言前者称为后保险杠扰流器(rear bumper spoiler)，后者则称为下扰流器(under spoiler)或后裙(rear skirt)。 尾翼(rear wing spoiler) 装置在车身后方上部，除了具有引导气流顺畅地通过车身的整流效果，还能抑制产生于车身后方的涡流。扰流尾翼的形状和能够产生升力的飞机主翼恰恰相反，因此尺寸越大，能够产生越大的下压力，并可借此提高后胎的抓地力。 侧扰流器(side spoiler) 也称做侧扰流裙(side skirt)、侧扰流梯(side step)，装置在车身两侧下方（侧油封附近），具有减低车体两侧风阻的效果。 扰流尾翼(rear diffuser) 这种整流板的作用是有效率地将车身下方的气流自后保险杠下导出，以产生负压进而获得下压力。扰流尾翼是赛车必备的零件，车身下方和路面间的间隔越窄，则效果越显著。 \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:22:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"根据汽车特性改变设定 改装一辆汽车必须根据车辆本身的特性来进行合适的设定与调校。每一辆车不同之处、驱动方式可能对于操控与车辆动态造成最大的影响，在改装前了解不同驱动方式的差异是相当重要的。 \r","date":"2019-07-16","objectID":"/beyondtheapex/:23:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"驱动方式 车辆的驱动方式，指的是引擎位置——整车最重的地方，以及连接驱动轮的部分。不同的驱动方式拥有不同的优点与缺点，即使在高度改装的性能车上，操控特性与车身反应都无法不受到驱动方式的影响。改变车辆的驱动方式相当困难，但依旧可能藉由结构变动与调校，来改善驱动方式先天上的差异。最佳的改装与调校，就是要能在既有的驱动方式、悬吊、空力效应方面，提供比量产车更为优异的特性。 FR前置引擎后轮驱动 假设车辆的配重均衡的话，一辆FR(前置后驱)的汽车，可以提供顶尖的弯道表现与稳定性。如果想要提高车速，提升后轮循跡性，让车辆在加速过程中不发生后轮偏移的情况也是一种方法。另外针对非驱动轮的前轮，可以调整为转向不足的特性，有助于让整体转向特性趋于均衡，这尤其在车辆减速时可以让驾驶人更容易控制方向。 FF前置引擎前轮驱动 在一辆FF前置引擎前轮驱动的汽车上，尽管转向与驱动轮均在前轮，但也不能完全忘记后轮的反应。。在高速赛道的情况下，后轮需要更高的稳定性，降低在极端的情况下，后轮因为重量较低而产生偏移的几率，而车辆的调校必须让驾驶人松开油门后，让后轮回到可控制的反应范围内，并且协助前轮望准确的转向方向去，FF前置引擎前轮驱动车，可利用单向限制差速器，并且仅与车辆加速时作动提升车辆循跡性。 MR中置引擎后轮驱动 让引擎位于车辆的中心，可以提供车辆优异的加速与减速性能。但是在经过调校的情况下，若车头的负载较轻也可能让车辆出现转向不足的状况，车身后半部的偏移速度也会较快。所以当进行改装时，重点应该放在车辆入弯时容易操作的特性，之后才是车辆出弯时的循跡性，此外车辆的前方与后方的下压力也应该注意平衡。 RR后置引擎后轮驱动 将引擎放置在后轮上，并且采用后轮来驱动，这样的驱动方式，基本上会让车头更轻也可能出现明显的转向不足，但若在弯道操控时逼近极限，车尾可能出现钟摆效应，进而使整车出现瞬间转向过度的情况，通常改善的方式，是提升对于入弯时的控制能力，让车辆的转向趋于中性。 4WD四轮驱动 在各种不同的四轮驱动方式上，可能让车辆出现的过弯特性截然不同，但一般而言，让一辆车四轮驱动转弯更不容易，所以在设定方面往往都将焦点放在入弯控制的能力，通常会在前轴采用单向限滑差速器，并且在后轮导入双向限滑差速器，来解决先天上的问题。 \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:23:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"逐项基本设定 仅单纯地装置高性能组件，并无法让车变快，性能设定必须考虑到整车的均衡性表现，这样才能够发挥车辆各部分性能提升后的潜力。 \r","date":"2019-07-16","objectID":"/beyondtheapex/:24:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"悬吊 \r车辆高度/弹簧系数 改变车身反应。 假设路况够好，车辆的重心降低，将让整车的稳定性明显提升，这会降低车辆加速或减速时的车身俯仰程度，藉由改变悬吊行程的长度，影响前后轮的高度，也会影响到提升整体性能。 举例来说，若让前悬吊明显低于后悬吊，弯道上产生的进入制动会令前轮贴紧路面，使进弯的动作更顺畅。在FF前置引擎前轮驱动汽车上，可藉由提升加速来抑制车头俯仰程度，来改变车辆入弯的特性。 弹簧系数同样对于车辆的反应影响甚大，理论上悬吊设定更硬会提升过弯性能，但也不永远总是这样。较硬的悬吊可以让车辆在入弯时降低车头俯仰的幅度与车身的晃动，但是若降低悬吊高度太多，也可能会影响到车辆入弯时接触地面的面积与悬吊几何，结果影响到车辆的循跡状况，所以弹簧系数适当与否对于车辆入弯或出弯的表现影响甚大。 弹簧系数也将对操控表现影响极大，提升弹簧系数可能导致转向不足，而且也可能提升后轮转向过度的几率，有时藉由调整阻尼系数，也可以补偿原有的特性。 \r\r阻尼系数 控制弹簧的压缩比。 若增加负载的压力，避震器会控制悬吊弹簧扩张，而执行这项任务的应力，便被称为阻尼系数，通常这股力量减震筒内所封存的气体压力进行活塞运动来决定，阻尼系数愈高，表示弹簧的活动速度反应会变快，若被压缩地位置愈地，或是活动行程加长，避震器的反应会较为和缓。 阻尼系数的设定独立施力，让车身反应与操控更精确，假设阻尼系数利用弹簧压缩，也会影响悬吊系统的反应时间、车身晃动与俯仰角度，也可以让车轮尽速脱离不均衡的状态，另外一方面，提升阻尼系数，也可以降低前悬吊在短时间内的反应幅度，维持车轮与地面的接触面积。 操控特性同样也可藉由改变阻尼系数的压缩或延伸还加以改变，也可以影响前后轮的反应状况，若藉由减少对前悬吊的压缩来改变阻尼系数，车辆大部分的重量将向前移，导致转向不足。 降低后轴弹簧反应的阻尼系数改变，则可能让车身重心后移，提升转向过度的几率，这必须藉由事先的调校与设定才能改变车身的反应。 \r\r轮胎定位/外倾角 最普遍的轮胎定位设置，就是轮胎外倾角的调整，负外倾角所指的是胎面与地面接触的面积，大于轮胎上半部；而正外倾角的状况正好相反，主要是轮胎轴心与铅直中央夹角向轮胎外侧扩大。 当车辆转弯时，离心力会导致车辆往弯道的外侧倾斜，假设在车辆转弯时出现负外倾角，表示转弯时轮胎胎面与地面接触面积较大，也代表可以提供较佳循跡表现，所以一般来说提升外倾角，指的就是造成负外倾角效应。 然而，负外倾角在车辆直线行进时还是有缺点，由于直进时轮胎并未与地面保持垂直，所以可能会造成车轮在此时接地面积比转弯时小，也代表影响到循跡表现，进而对操控产生不利的影响，同时行进时轮胎的滚动阻抗会予以提升，直接影响到车辆的加速性表现，更甚者会让同样的速度情况下，车辆需要更长的距离与更强大的制动力才能刹车，进行极端的调整前要注意上列的利与弊。 当采用负外倾角定位时，最重要的就是考量到车身前后配重，对于弯道操控与车身反应造成的影响，若车头负载较重，前轮负外倾角应该要增加，而且后轮外倾角则应该减少，这样可以降低转向不足的风险。 正外倾角几乎很少用到，因为会降低轮胎的抓地力，而且会容易让车身反应过于灵敏。 \r\r轮胎定位/束角 束角主要是当由上俯视轮胎时，与车辆前进方向之间所产生的夹角，束角的重要性，在于其在维持车辆稳定性方面，扮演十分吃重的角色，而且在轮胎左右对调时也将产生戏剧性的影响。 当内束角时，代表着由上方俯视车轮，车辆的方向呈现八字的状态，反之亦然，当前后轮均设定为内束角时，代表着会在转弯时造成较为明显的转向不足状态，若后轮为外束角时，代表着前轮呈现内八、后轮呈现外八字的状态，这时候则较为容易造成转向过度。 束角的状态与轴距、轮距、外倾角以及动力输出等因素都有关联，其中一个因素变化，都可能导致束角产生的差距，将对于车辆在过弯状态下的转向特性产生改变，所以也影响驾驶人在弯道操控的掌握程度，通常在轮胎定位时会先调整或校正正前束角，之后才决定后束角的修正状况。 \r\r平衡杆/增加刚性 平衡杆的本身就是拖拽臂结构中，连结下控制臂与左右两侧悬吊机构的部分。 拖拽臂本身是运用扭曲力道所造成的阻力来运作的金属杆，主要作用为降低车身晃动状态，让轮胎的胎面可以保持与路面接触面积较大的相对稳定状态，并且提升车身抗扭曲性表现，而平衡杠同样也具备安定车身反应的功能。 当调整平衡杆系数时，别让弹簧系数高于悬吊的弹性系数相对来说十分重要。 假如平衡杆强度愈高，悬吊弹簧会因此无法应付其所需要处理的状态，会让重量所产生的应力向轮胎外侧方向移动，导致内侧的悬吊组件举起平衡杆而丧失循跡性。 这当然可能在调校前后平衡杆时繁盛，但这些调整方式主要是藉由调整悬吊的弹簧系数或是阻尼系数来大城其目标，提升平衡杆的刚性当然也可能达到同样的效果，但相对来说这一部分的调校，应该是完成其他部分的调整之后，才需要在最后检视时处理的程序。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:24:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"驱动系统(限滑差速器) 初期的扭力输出，决定了限滑差速器的介入的时机，若扭力输出较大，限滑差速器就愈容易做动，而且也让弯道加速过程更容易进行，反之，扭力输出较低，限滑差速器就较不容易作动与介入。 一般而言，提升初步扭力输出能强化车辆驱动配置的特征，然而过度转向在这样的处理方式下，却更容易在高速过弯时产生，而且前轮也可能因为驱动轮扭力输出过大，而产生较为明显的转向不足现象。 所以初步扭力输出比例的调整，将可能影响到驾驶人希望车辆对于弯道反应的速度与幅度。 另一种调整，也可以藉由限滑差速器介入的时机与力道，来调整加速或减速时的扭力输出力道，加速设定将使得加速器与动作过程中反应更为强烈，而且驱动系统也会传送更多引擎输出的力道至驱动轮，这可以让入弯时驱动轮藉由取得更多的扭力，更容易入弯而达成提升过弯速度的能力。 然而，这也可能影响到驾驶人的弯道操控乐趣，因为让车辆更容易克服弯道，而降低驾驶技术对于训练弯道过弯的能力。 减速过程中对于限滑差速器的设定，也将影响到弯道中减速之后车辆的反应。限滑差速器在减速过程中作动的反应提升，将可能增加弯道减速过程中刹车系统的作用力，这可能让驾驶人在入弯时用更快的速度进入弯道，因为驾驶人可以在任何情况下对于刹车力道有更高程度的掌握，然而此设定会使过弯难度提升，虽然是适用于驾驶技术较优异之职业或半专业驾驶者，但也是解决初期转向不足的必备技术。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:24:2","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"驱动配置(齿轮比) 利用密齿比维持动力输出 为了应付各种赛道状况，由于蜿蜒的赛道具备更多的弯道，也充满各种加速直线道，为了让爱车引擎可以在这样复杂状况下适应反应，改变动力系统输出的比例便显得相当重要。这通常包括改变变速系统的终传比愈齿轮比。 当驾驶在较高比例的低速加速道与弯道上时，驾驶人的焦点将放在提升出弯速度，而非提升整体行车速度。变速系统在这种情况下，必须持续地在各档位、各种速度下维持相近的齿轮比，让驾驶人可以随时掌握动力系统较高的扭力输出状态，这样的设定就被称为密齿比。 另一方面，若是驾驶在直线加速道比例较高的赛道上，就需要针对五档或六档来提升高速反应，即所谓较疏的齿轮比设定。 最高档位的齿轮比会决定变速系统的做动方式，假设最高档位齿轮比被提升，这将提升车辆的最终速度时所具备的加速力道，当开始调整齿比时，应该调整的是最高档位的终传比，这样才能让车辆在直线加速道时，于最高档位获得较高比例的动力输出以提升最终速度。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:24:3","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"空力效应(下压力) 提升高速反应 当实行高速驾驶时，驾驶不可忽视气流对于车身产生的影响程度，空力效应主要对于车身造成二种影响：空气阻力将限制车辆的速度， 另外也可能在高速时抬升车身，进而影响到车辆行驶的速度。所以维持空力效应的均衡，将让车辆在高速行驶时更为顺利而且稳定。 此外，在高速行驶时所谓的下压力，也对于车辆行驶的稳定性造成相当重要的影响。下压力提升可以让车辆在高速行驶的情况下，提升车轮与地面接触的面积，也有利于提升车辆各轮的循跡性与稳定性。 尽管下压力可能压制最终速度，但是在高速过弯时却有助提升车辆的动态稳定性，所以减少下压力，会降低车辆过弯的速度，但却可以容许车辆在直线高速道时维持较快的车速。 下压力也可能受到赛道路线形状的影响，但若出现在起步时却不见得有利于车辆加速。最理想的状态，是提供车辆在不同的行驶状态下可以提供当时最适切的下压气流力道，在小排量动力的车辆上，通常藉由降低下压力来提升最终速度。 利用车身前后不同的下压力改变，可以用来提升车辆高速过弯时的操控表现，提升车身前端的下压力将增加车轮的抓地力，并且提升转向过度特性，相反地增加车身后半部的下压力，将较容易导致转向不足。各种不同的调整，将让车辆在高速赛道中拥有不同的反应特性。 \r\r\r","date":"2019-07-16","objectID":"/beyondtheapex/:24:4","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"依照目的状况进行设定 针对特性的赛道或路况进行跳帧，其实是为了替身整体驾驶技巧，以及对于车辆各种状况下反应的掌握。反应速度较快的悬吊与驱动模式，将可以让车辆在赛道上产生令人难以想象的改变。 \r","date":"2019-07-16","objectID":"/beyondtheapex/:25:0","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"高速赛道 提升极速 在高速赛道上，理想的车辆设定，将让赛车可以在高速弯道中维持较高的行驶速度。悬吊系统避震器必须较为强固，而且保持车身高度较低。然而，若车身高度太低，则也会影响到悬吊弹簧的作动效率，悬吊系统会难以吸收车轮与地面接触所传处的震动，减低悬吊系统原本带给车辆的优点。 若使用较为硬的悬吊设定，降低防倾杆的刚性表现，将会让轮胎因为车身小幅度的滚动效应而提升抓地力，但另外一方面，若使用较软的悬吊设定，在崎岖不平的路面上，悬吊系统与避震器也会有较大的作来吸收来自路面的震动，这是因为平衡杆可以补偿悬吊系统弹簧能力的不足。当然，轮胎定位也十分重要，提升后轮的束角，也是提升车身稳定性的方法。当驾驶在高速赛道上，降低车辆在全力刹车时对于悬吊系统与避震器的负担，却也同样重要，因为这样可以维持车辆的反应与结构耐久程度。 至于变速系统的齿轮比，其调校也是为了同样的目的：维持车辆动力系统，在较宽阔的高扭力输出范围，以提供随时都可以拥有强大的加速力道，藉由调整最终传比的设定，也可以让车辆及时在最高档位具备较强的扭力输出表现，当然提升下压力，也可以提升车辆在高速行驶时的稳定性，进而在高速赛道上追求更高的行驶速度，但必须避免在弯道与刹车时丧失稳定性。 建议悬吊设定 依照车辆特性不同亦有可能有所差异。 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:25:1","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"技术赛道 让动力更有效率地传达至路面 所谓技术型赛道，通常代表着赛道上不满高难度的玩到，所以调校的目标将是让车身反应更为灵敏，而且让车辆在弯道时因为传输所丧失的动力比例降到最低，首先针对赛道状况设定适当的车身高度相当重要，当然也必须维持最佳的贴地性，但同时又必须考量悬吊系统与避震器，可以在任何状况下动作良好。 在这样的情况下，若是后轮驱动车辆，建议前轮弹簧应该调软，后轴弹簧应该调硬，以提升车辆过弯性能，另外在轮胎定位的部分，前路你应该增加束角角度，这样可以提升驾驶掌握车辆入弯时的反应，但也必须注意到车辆在过顶点后出弯的车身反应，负外倾角也可以适当地运用，但也同时必须考量到弯道行车与刹车时车辆的循跡性。 变速系统应该提供较为紧密的齿轮比，让车辆随时可以维持较高的扭力输出，而且终传比例应该调低。 若引擎调校的宜，那应该维持各种转速领域下可以输出的最大扭力，以便于车辆在各种状况下都可以获得最大的加速力道，空力效应中的下压力，作用于前后轴都应该维持在较强大的状况，已提供车辆在连续过弯之后拥有较佳的稳定性。 建议悬吊设定 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:25:2","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"转向不足之对策 了解为何车辆无法转弯 一开始为了定义何时开始出现转向不足，车辆何时开始转弯、靠近顶点，或是何时开始加速出弯都是关键。 假设转向不足在车辆入弯时发生，前轮抓地力必须尽可能增加。这可能藉由调软前轴悬吊弹簧以及增加避震器内部的延伸量，以及减少对弹簧的压缩量来增加对于轮胎的负载量，进而达成提升前轮抓地力的目标。 各项与悬吊系统相关的变数，包含限滑差速器也同样可以让车辆，在这一个阶段出现转向不足，降低限滑差速器锁定的比例，或是限缩的扭力输出比例，也可予以纠正。 如果是FR车辆使用双向限滑差速器（系统会视驾驶人踩踏油门踏板与否决定限缩输出比例），试着在车辆减速时，使用单向凡是控制限滑差速器。在车辆高速过弯时，提升前轴的下压力提升前轮抓地力，也可以达成同样的效果。 若转向不足发生于车辆接近顶点，应该予以负增加外倾角，让前轮确认可在此时增加对于地面的抓地力，或是降低后轮束角也可以协助平衡前后轮的抓地力提升前轮距同样也可能达成效果。 若转向不足发生于后轮驱动车准备加速出弯时，降低前轴车身高度则可以抵销其作用力，或是提升悬吊阻尼系数，促使避震器提升前轴行程，或压缩避震器行程也可以达成，若发生在FF前置引擎前轮驱动车上，提升限滑差速器的作用效果也同样可以解决此问题。 建议悬吊设定 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:25:3","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"转向过度之对策 后轮驱动车固有的麻烦 FF车与四驱车很少苦于转向过度。这个问题几乎否发生在后轮驱动车上。 如果以甩尾驾驶为主并注重操控性，前后轴的悬吊系统都必须强化到足以控制因为转向过度导致的偏滑或可能失控，然而在小场地的竞赛中，则需要计算维持循跡性的各项因素，才能顺利地让车辆前进。 大部分发生转向过度的原因是因为后驱车，在加速过程中发生了后轮失去循跡性的状况，这将让传输的动力浪费在加速过程中发生的车辆打滑现象。 弹簧与阻尼系数也可以藉由调校以降低转向过度，后悬吊应该调软，而避震器的阻尼系数应该降低压缩比例，并且提升延展性，这同样可以降低后平衡杆的刚性，增加转向内侧车轮往往行进方向移动。若可能的话，增加后轮距也是个方法。若前悬吊过软的话，后轴的负重比例可能向前移动，所以前悬吊应该强化来提升后轮的抓地力。 若车辆皮质后扰流，可增加其角度，以提升车身后半部的下压力效应，但这也同时表示车辆可能必须牺牲最高车速。 建议悬吊设定 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:25:4","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"湿滑路况 重视轮胎表现 就像你可以想象的，在雨天时道路的摩擦力都已经降低了，当然轮胎的抓地力也会大受影响。在此就来看看有哪些设定在这样的路况下必须改变，让车辆可以充分地在湿滑路况发挥作用。 包括弹簧系数、下压力与平衡杆的强度，都应该尽可能在干燥时事先降低，在部分的情况下，后平衡杆还必须完全拆除。过硬的悬吊可能让车辆更不容易掌握抓地力，当路况相当湿滑，车辆不容易维持抓地力时，悬吊设定愈软愈好。 外倾角应该在还处于干燥的情况下略为增加，确定轮胎在路面湿滑的情况下，无论是加速或减速时都可以维持与路面最大的接触面积，当然车辆的空力套件也必须予以调整，前后下压力都应该增加，以尽可能地提升前后轮的抓地力。 另外要降低气候对于汽车的负面影响，还有一个方法就是调整轮胎，若在大雨的情况下提升轮胎的负载，可以提升车轮的抓地力，相反的在雨小时，降低轮胎可以提升性能表现，随时注意并且调整前后胎压，在面对湿滑路面或大小雨气候时，都是调校过程中的优先考量。 若可能提升动力调校的话，应该重视的是中低回转域的扭力输出表现，而非一味追求高速表现，而仰赖电子辅助系统的协助，在恶劣的湿滑路况下，更容易发现电子控制刹车系统的效果。 建议悬吊设定 \r\r","date":"2019-07-16","objectID":"/beyondtheapex/:25:5","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["Automotive"],"content":"砂砾路面 增加控制 当车辆必须在砂砾路面行驶时，针对车辆各部分的调校应该赋予最大的弹性，因为在这类路面上有太多难以预料的变化。可能在环境细微的变化，都必须针对车辆进行些许的调整，才能够让车辆顺利脱困并且降低应付路况所浪费的动力输出比例。 此外，在车辆加速的过程中，可能因此又随时改变了车轮与地面的抓地力，进而影响到循跡性，这也是砂砾路面随时可能变化的原因之一，所以对于车辆的调校与改变各项设定，在行驶砂砾路面时尤其重要。 针对砂砾路面进行的调校中，必须注意的另外一个重点是当松开油门踏板之后，车辆所产生的反应，包括所产生的各种转向特性，这有被称为转向过度的调校，主要是为了要控制加速时的转向特性，这可能藉由使用双向限滑差速器或是调整前后刹车力道的均衡来达成。 转向不足或过度同样可能发生在砂砾路面或柏油路面上，车身高度调整要视路面情况而定，尽管降低有其益处，但必须考量到在这类砂砾路面上，降低车身高度，会对底盘相关零件与结构造成的危机与损伤，当然在这样多变的情况下，车身空力效应依旧扮演重要角色，引擎的调校重点并不在于最高输出，而是可以在各种情况下保持最佳反应。 建议悬吊设定 \r\r– \r\r赛道","date":"2019-07-16","objectID":"/beyondtheapex/:25:6","tags":["PS4","PlayStation","Game","Automotive","GT"],"title":"Beyond The Apex","uri":"/beyondtheapex/"},{"categories":["middleware"],"content":"参考: 维基百科 ZooKeeper: https://zookeeper.apache.org/ Docs: https://zookeeper.apache.org/doc/ 环境: RHEL7x86_64 ZooKeeper v3.5 \r\r \r\r介绍 ZooKeeper: Because Coordinating Distributed Systems is a Zoo. Apache ZooKeeper 是Apache软件基金会的一个软件项目，它为大型分布式计算提供开源的分布式配置服务、同步服务和命名注册，实现高度可靠的分布式协调。ZooKeeper曾经是Hadoop的一个子项目，但现在是一个独立的顶级项目。 ZooKeeper 是一种集中式服务，用于维护配置信息(conf info)，命名(naming)，分布式同步(distributed synchronization)，组服务(group service)。所有这些类型的服务都以分布式应用程序的某种形式应用。每次实施它们都需要做很多工作来修复不可避免的错误和竞争条件。由于难以实现这些类型的服务，应用程序最初通常会吝啬它们，这使得它们在变化的情况下变得脆弱并且难以管理。即使正确完成，这些服务的不同实现也会在部署应用程序时导致管理复杂性。 ZooKeeper的架构通过冗余服务实现高可用性。因此，如果第一次无应答，客户端就可以询问另一台ZooKeeper主机。ZooKeeper节点将它们的数据存储于一个分层的命名空间，非常类似于一个文件系统或一个前缀树结构。客户端可以在节点读写，从而以这种方式拥有一个共享的配置服务。更新是全序的。 \r","date":"2019-03-15","objectID":"/zookeeper/:0:0","tags":["Apache","ZooKeeper","DataAnalysis"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["middleware"],"content":"概述 ZooKeeper: A Distributed Coordination Service for Distributed Applications ZooKeeper 是一种用于分布式应用程序的分布式开源协调(coordination)服务。它被设计为易于编程，并使用在熟悉的文件系统目录树结构之后设计的数据模型。它在Java中运行，并具有Java和C的绑定。 众所周知，协调服务很难做到。他们特别容易出现竞赛条件(race conditions)和死锁(deadlock)。ZooKeeper背后的动机是减轻分布式应用程序从头开始实施协调服务的责任。 \r","date":"2019-03-15","objectID":"/zookeeper/:1:0","tags":["Apache","ZooKeeper","DataAnalysis"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["middleware"],"content":"设计目标 Design Goals ZooKeeper is simple ZooKeeper允许分布式进程通过 共享的层级命名空间(shared hierarchal namespace) 相互协调，该命名空间的组织方式与标准文件系统类似。命名空间由 数据寄存器(data registers) 组成——在ZooKeeper用语中被称为 znodes，这些与文件和目录类似。与专为存储而设计的典型文件系统不同，ZooKeeper数据保存在内存中，这意味着ZooKeeper可以实现高吞吐量(high throughput)和低延迟数(latency numbers)。 ZooKeeper的实现非常重视 高性能(high performance)， 高可用(highly available)， 严格有序的访问(strictly ordered access)。性能方面意味着它可以在大型分布式系统中使用。可靠性方面使其不会成为单点故障(a single point of failure)。严格的排序意味着可以在客户端实现复杂的同步原语。 ZooKeeper is replicated 与它协调的分布式进程一样，ZooKeeper本身也可以在称为 集合(ensemble) 的一组主机上进行 副本复制(replicated)。 组成ZooKeeper服务的Server必须了解彼此。它们维护一个内存中的状态镜像，以及持久性存储的事务日志和快照。只要大多数Servers可用，ZooKeeper服务就可用。 Client连接到单个Server。Client维护TCP连接，通过该连接发送请求，获取响应，获取监视事件(watch events)，以及发送心跳(heart beats)。如果与Server的TCP连接中断，则Client将连接到其它Server。 ZooKeeper is ordered ZooKeeper使用反映所有ZooKeeper事务顺序的数字标记每个更新。后续操作可以使用该顺序来实现更高级别的抽象，例如同步原语。 ZooKeeper is fast 它在读取 read-doninant 工作负载中特别快。ZooKeeper应用程序运行在成千上万的计算机上，并且在读取别写入更常见的情况下(比率10:1)表现最佳。 \r\r","date":"2019-03-15","objectID":"/zookeeper/:1:1","tags":["Apache","ZooKeeper","DataAnalysis"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["middleware"],"content":"数据模型和分层命名空间 Data model and the hierarchical namespace ZooKeeper提供的命名空间非常类似于标准文件系统。名称是由斜杠(/)分隔的路径元素序列。ZooKeeper命名空间中的每个节点都由路径标识。 \r\r","date":"2019-03-15","objectID":"/zookeeper/:1:2","tags":["Apache","ZooKeeper","DataAnalysis"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["middleware"],"content":"节点和短暂节点 Nodes and ephemeral nodes 与标准文件系统不同，ZooKeeper命名空间中的每个节点都可包含与之关联的数据以及孩子。这就像拥有一个允许文件也是目录的文件系统。ZooKeeper旨在存储协调数据：状态信息，配置，位置信息等，因此存储在每个节点的数据通常很小。我们使用术语 znode 来表明我们正在谈论的ZooKeeper数据节点。 Znodes 维护一个 状态结构(stat structure)，其中包括数据更改、ACL更改、时间戳更改，以允许缓存验证和协调更新。每次znode的数据更改时，版本号都会增加。例如，每当Client检索数据时，它也接收数据的版本。 存储在每个znode命名空间中的数据以原子(atomically)方式进行读写。读取与znode关联的所有数据字节，写入替换所有的数据。每个节点都有一个ACL限制谁可以做什么。 ZooKeeper也有 短暂节点(ephemeral nodes) 的概念。只要创建的znode处于活动状态，就会存在这些znode，回话结束时，znode将被删除。当你想要实现 [tbd] 时，短暂节点很有用。 \r\r","date":"2019-03-15","objectID":"/zookeeper/:1:3","tags":["Apache","ZooKeeper","DataAnalysis"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["middleware"],"content":"协调更新和监视 Conditional updates and watches ZooKeeper支持监视(watch)的概念。Client可以在znode上设置监视。当znode更改时，将触发并删除监视。触发监视时，Client会受到一个数据包，指出znode已更改。如果Client与其中一个ZooKeeper Server之间的连接中断，则Client将收到本地通知。这可以用于 [tbd] 。 \r\r","date":"2019-03-15","objectID":"/zookeeper/:1:4","tags":["Apache","ZooKeeper","DataAnalysis"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["middleware"],"content":"保证 Guarantees ZooKeeper非常快速和简单。但是，由于基于目标是构建更复杂的服务(如同步)的基础，因此它提供了一系列保证。这些是: 顺序一致性(Sequential Consistency): Client的更新将按发送顺序来应用 原子性(Atomicity): 更新成功或失败，没有其它结果 单系统镜像(Single System Image): 无论连接到哪个Server，Client都将看到相同的服务视图 可靠性(Reliability): 一旦更新被应用，它将从该时间开始持续，知道Client覆盖此更新 时宜性(Timeliness): 系统的Client视图保证在特定的时间范围内是最新的 \r\r","date":"2019-03-15","objectID":"/zookeeper/:1:5","tags":["Apache","ZooKeeper","DataAnalysis"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["middleware"],"content":"API ZooKeeper的设计目标之一是提供非常简单的编程接口。因此，它仅支持以下操作: create: creates a node at a location in the tree delete: deletes a node exists: tests if a node exists at a location get data: reads the data from a node set data: writes data to a node get children: retrieves a list of children of a node sync: waits for data to be propagated \r\r","date":"2019-03-15","objectID":"/zookeeper/:1:6","tags":["Apache","ZooKeeper","DataAnalysis"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["middleware"],"content":"执行 Implementation ZooKeeper组件显示了ZooKeeper服务的高级组件。除了请求处理器，构成ZooKeeper服务的每个Server都复制自己每个组件的副本。 副本数据库是一个包含整个数据树的内存数据库。更新将记录到磁盘以获得可恢复性，并且在写入内存数据库之前会序列化的磁盘 每个ZooKeeper Server都为Client服务。Client只连接到一台Server以提交请求。读取请求由每个Server数据库的本地副本提供。更改服务状态的请求，写请求由 协定协议(agreement protocol) 处理 作为协定协议的一部分，来自Client的所有写入请求都被转发到称为 leader 的单个Server。其余的ZooKeeper Server，称为follower，接收来自leader的消息提议并同意消息传递。消息传递层负责替换失败的leader，并将follower与leader同步 ZooKeeper使用自定义的原子消息(atomic messaging)协议。由于消息传递层是原子的，因此ZooKeeper可以保证本地副本永远不会发散。当leader收到写入请求时，它会计算应用写入时系统的状态，并将其转换为捕获此新状态的事务。 \r\r","date":"2019-03-15","objectID":"/zookeeper/:1:7","tags":["Apache","ZooKeeper","DataAnalysis"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["middleware"],"content":"用户 ZooKeeper的编程接口非常简单。但是，通过它，您可以实现更高阶的操作，例如同步原语，组成员身份，所有权等。 \r\r","date":"2019-03-15","objectID":"/zookeeper/:1:8","tags":["Apache","ZooKeeper","DataAnalysis"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["middleware"],"content":"性能 Performance ZooKeeper旨在提供高性能。在读取数量超过写入的应用程序中，它的性能尤其高，因为写入涉及同步所有Server的状态。 The events marked in the figure are the following: Failure and recovery of a follower Failure and recovery of a different follower Failure of the leader Failure and recovery of two followers Failure of another leader \r\r\r","date":"2019-03-15","objectID":"/zookeeper/:1:9","tags":["Apache","ZooKeeper","DataAnalysis"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["middleware"],"content":"入门 ZooKeeper Getting Started Guide ","date":"2019-03-15","objectID":"/zookeeper/:2:0","tags":["Apache","ZooKeeper","DataAnalysis"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["devops"],"content":"参考: 维基百科 GitLab GitHub \r\r \r\r介绍 DevOps（Development和Operations的组合词）是一种重视 软件开发人员（Dev） 和 IT运维技术人员（Ops） 之间沟通合作的文化、运动或惯例。透过自动化 软件交付 和 架构变更 的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。 \r\r \r\rAuto DevOps GitLab Auto DevOps: Auto Build Auto Test Auto Code Quality Auto SAST (Static Application Security Testing) Auto Dependency Scanning Auto License Management Auto Container Scanning Auto Review Apps Auto DAST (Dynamic Application Security Testing) Auto Deploy Auto Browser Performance Testing Auto Monitoring \r\r \r\rDevOps工具 下面介绍一些DevOps需要用到的工具，可能不够详细。 \r","date":"2019-02-13","objectID":"/devops/:0:0","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"基础环境 IaaS: VMware Xen KVM OpenStack 云平台 … \r\r","date":"2019-02-13","objectID":"/devops/:1:0","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"项目管理 Task: RedaMine Jira 禅道 … \r\r","date":"2019-02-13","objectID":"/devops/:2:0","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"代码 Code: git GitLab Gogs svn 云平台 … \r\r","date":"2019-02-13","objectID":"/devops/:3:0","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"持续集成/发布 CI/CD: Jenkins Jenkins X GitLab CICD Bamboo Maven 云平台 … \r\r","date":"2019-02-13","objectID":"/devops/:4:0","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"容器 Container: Docker K8s CoreOS Mesos Helm 云平台 … \r\r","date":"2019-02-13","objectID":"/devops/:5:0","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"测试 Test: Selenium Katalon Studio Watir Jmeter Loadrunner LOCUST \r","date":"2019-02-13","objectID":"/devops/:6:0","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"Selenium Website: https://www.seleniumhq.org/ Selenium是一个用于自动化测试Web apps的可移植框架。 Selenium提供了一种用于创作功能测试的回放工具，无需学习测试脚本语言。 \r\r","date":"2019-02-13","objectID":"/devops/:6:1","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"Katalon Studio Wetsite: https://www.katalon.com/ Simplify API, Web, Mobile Automation Tests. \r\r","date":"2019-02-13","objectID":"/devops/:6:2","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"Watir Website: http://watir.com/ An open source Ruby library for automating tests. Watir interacts with a browser the same way people do: clicking links, filling out forms and validating text. \r\r","date":"2019-02-13","objectID":"/devops/:6:3","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"JMeter Apache JMeter应用程序是开源软件，纯Java应用程序，旨在加载测试功能行为和测量性能。它最初是为测试Web应用程序而设计的，但后来扩展到其他测试功能。 Apache JMeter可用于测试静态和动态资源，Web动态应用程序的性能。 它可用于模拟服务器，服务器组，网络或对象上的重负载，以测试其强度或分析不同负载类型下的整体性能。 Apache JMeter功能包括: Ability to load and performance test many different applications/server/protocol types Web - HTTP, HTTPS (Java, NodeJS, PHP, ASP.NET, …) SOAP / REST Webservices FTP Database via JDBC LDAP Message-oriented middleware (MOM) via JMS Mail - SMTP(S), POP3(S) and IMAP(S) Native commands or shell scripts TCP Java Objects Full featured Test IDE that allows fast Test Plan recording CLI mode to load test from any Java compatible OS Highly Extensible core … \r\r","date":"2019-02-13","objectID":"/devops/:6:4","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"LoadRunner Website: https://www.microfocus.com LoadRunner is a Load Testing Software \r\r","date":"2019-02-13","objectID":"/devops/:6:5","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"LOCUST Website: https://locust.io/ GitHub: https://github.com/locustio/locust/ An open source load testing tool. Define user behaviour with Python code, and swarm your system with millions of simultaneous users. \r\r\r","date":"2019-02-13","objectID":"/devops/:6:6","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"质量与安全 Quality and Security: infer SonarQube Cuckoo Sandbox OWASP ZAProxy Mobile-Security-Framework-MobSF Clair \r","date":"2019-02-13","objectID":"/devops/:7:0","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"Infer GitHub: https://github.com/facebook/infer Website: https://fbinfer.com/ Infer 是一个 Java，C ++，Objective-C 和 C 的代码静态分析工具。它会产生一个潜在的bug列表。任何人都可以使用Infer在发送给用户之前拦截关键错误，并帮助防止崩溃或性能不佳。 infer 主要用于 APP 端，也就是 Android/IOS App。 \r\r","date":"2019-02-13","objectID":"/devops/:7:1","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"SonarQube GitHub: https://github.com/SonarSource/sonarqube Website: https://www.sonarqube.org/ SonarQube 是一个开源平台，通过代码的自动化静态分析不断的检查代码质量。 SonarQube 支持20多种语言的分析，并在各种类型的项目中输出和存储问题。通过不同的插件对这些结果进行再加工处理，通过量化的方式度量代码质量的变化，从而可以方便地对不同规模和种类的工程进行代码质量管理。 \r\r","date":"2019-02-13","objectID":"/devops/:7:2","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"MobSF GitHub: https://github.com/MobSF/Mobile-Security-Framework-MobSF Mobile Security Framework is an automated, all-in-one mobile application (Android/iOS/Windows) pen-testing framework capable of performing static analysis, dynamic analysis, malware analysis and web API testing. \r\r","date":"2019-02-13","objectID":"/devops/:7:3","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"Clair GitHub: https://github.com/coreos/clair Vulnerability Static Analysis for Containers. Clair is an open source project for the static analysis of vulnerabilities in application containers (currently including appc and docker). \r\r\r","date":"2019-02-13","objectID":"/devops/:7:4","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"配置管理 Configuration Management: Ansible ZooKeeper CFEngine Chef MAAS Puppet SaltStack Vagrant Rundeck Rudder 云平台 … \r\r\r","date":"2019-02-13","objectID":"/devops/:8:0","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"数据分析 Data Analysis: Hadoop Ambari Avro Flume HBase Hive Spark Sqoop ZooKeeper \r\r\r","date":"2019-02-13","objectID":"/devops/:9:0","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"日志 Log: ElasticStack Elasticsearch Logstash Beat Hadoop, Hive - 与ELK类似的方案 Flume Fluentd Splunk Kafka Loggly Papertrail 云平台 … \r\r","date":"2019-02-13","objectID":"/devops/:10:0","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"流 Stream: Kafka Apex Flink Heron Spark Heka \r\r","date":"2019-02-13","objectID":"/devops/:11:0","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"Api网关 Api Gateway: Gloo Ambassador Spring Cloud Kong Netflix Zuul 云平台 … \r\r","date":"2019-02-13","objectID":"/devops/:12:0","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"性能 Performance: NetData Pinpoint Datadog AppDynamics Apache JMeter ab(ApacheBench) Gatling \r\r","date":"2019-02-13","objectID":"/devops/:13:0","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"监控 Monitoring: Zabbix Nagios Prometheus Grafana Netdata Graphite Cacti Glances Collectd Ganglia Kibana Sensu \r\r","date":"2019-02-13","objectID":"/devops/:14:0","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["devops"],"content":"备份 Backup: 全量 增量 \r\r \r\r灰度发布 ps: 参考百度百科! 灰度发布（金丝雀发布）是指在黑与白之间，能够平滑过渡的一种发布方式。在其上可以进行A/B testing，即让一部分用户继续用产品特性A，一部分用户开始用产品特性B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。 灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。 灰度期：灰度发布开始到结束期间的这一段时间，称为灰度期。 ","date":"2019-02-13","objectID":"/devops/:15:0","tags":["自动化运维","运维开发","devops"],"title":"DevOps","uri":"/devops/"},{"categories":["infrastructure"],"content":"参考: LDAP维基百科: https://zh.wikipedia.org/wiki/LDAP OpenLDAP维基百科: https://zh.wikipedia.org/wiki/OpenLDAP x.500维基百科: https://zh.wikipedia.org/wiki/X.500 OpenLDAP文档: http://www.openldap.org/doc/ 环境: RHEL7.x86_64 LDAP v2.4.44 \r\r \r\r概述 \r","date":"2019-01-18","objectID":"/openldap/:0:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"LDAP LDAP(轻型目录访问协议, Lightweight Directory Access Protocol）是一个开放的、中立的、工业标准的应用协议，通过IP协议提供访问控制和维护分布式信息的目录信息。 LDAP基于X.500标准的子集。因为这个关系，LDAP有时被称为X.500-lite。 LDAP在TCP/IP之上定义了一个相对简单的升级和搜索目录的协议。 LDAP目录与普通数据库的主要不同之处在于数据的组织方式，它是一种有层次的、树形结构。所有条目的属性的定义是对象类object class的组成部分，并组成在一起构成schema；那些在组织内代表个人的schema被命名为white pages schema。数据库内的每个条目都与若干对象类联系，而这些对象类决定了一个属性是否为可选和它保存哪些类型的信息。 LDAP目录的条目（entry）由属性（attribute）的一个聚集组成，并由一个唯一性的名字引用，即专有名称（distinguished name，DN）。 DN: Distinguished Name CN: Common Name OU: Domain Component LDAP组织数据方式: dc=org |dc=wikipedia / \\ ou=people ou=groups LDAP主要的应用场景是查询多而修改极少，那就充分发挥LDAP的优势了。因为没有事务处理，那数据库的速度可是比不上。 还有LDAP能存储海量的数据，还可以轻松地在各个系统之间复制，可用性超高。 目录是一个为查询、浏览和搜索而优化的专业分布式数据库，它呈树状结构组织数据，就好象Linux/Unix系统中的文件目录一样。目录数据库和关系数据库不同，它有优异的读性能，但写性能差，并且没有事务处理、回滚等复杂功能，不适于存储修改频繁的数据。所以目录天生是用来查询的，就好象它的名字一样。 \r\r\r","date":"2019-01-18","objectID":"/openldap/:1:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"OpenLDAP OpenLDAP是轻型目录访问协议（Lightweight Directory Access Protocol，LDAP）的自由和开源的实现，在其OpenLDAP许可证下发行，并已经被包含在众多流行的Linux发行版中。 OpenLDAP主要包括下述4个部分： slapd: 独立LDAP守护服务 slurpd: 独立的LDAP更新复制守护服务 实现LDAP协议的库 工具软件和示例客户端 \r\r\r","date":"2019-01-18","objectID":"/openldap/:2:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"Why OpenLDAP 账号是登录系统的唯一入口。要登录系统，首先系统要存在登录所使用的账号（/etc/passwd）及密码信息（/etc/shadow），然后经过系统查找顺序（/etc/nsswith.conf）及认证模块（/etc/pam.d/*）验证，得到授权后方可登录系统。如果多个用户登录系统，就需要在每个系统上创建用户名和密码；否则，就无法登录系统。 对于账号管理人员而言，维护10 台、100 台机器的账号，或许勉强可以维护、管理。如果机器数量达到1000 以上时，对于账号的创建、回收、权限的分配、密码策略、账号安全审计等一系列操作，账号管理人员就心有余而力不足了。此时OpenLDAP 账号集中管理软件就应用而生，它可以实现账号集中维护、管理，只需要将被管理的机器加入到服务器端即可，此后所有与账号相关的策略均在服务端实现，从而解决了运维案例所产生的众多管理问题。 关于账号的添加、删除、修改、权限的赋予等一系列操作只需要在服务端操作即可，无须在客户端机器进行单独操作。客户端账号及密码均通过OpenLDAP 服务器进行验证，从而实现账号集中认证管理，此时账号管理员只须维护OpenLDAP 服务器条目即可。 \r\r \r\rOpenLDAP目录服务 Introduction to OpenLDAP Directory Services 本节介绍如何构建，配置和操作OpenLDAP软件以提供目录服务。这包括有关如何配置和运行standalone LDAP daemon——slapd的详细信息。它适用于系统管理员。本节提供目录服务的基本介绍，特别是slapd提供的目录服务。 本简介提供足够的信息，以便您可以开始学习LDAP，X.500和目录服务。 \r","date":"2019-01-18","objectID":"/openldap/:3:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"目录服务是什么 目录是专门用于搜索(search)和浏览(browse)的专用数据库，另外还支持基本查找(lookup)和更新(update)功能。 目录往往包含描述性的，基于属性的信息，并支持复杂的过滤功能。目录通常不支持在为处理大量复杂更新而设计的数据库管理系统中发现的复杂事务或回滚方案。如果允许，目录更新通常是简单的全有或全无更改。目录通常用于快速响应高容量查找或搜索操作。他们可能具有广泛复制信息的能力，以提高可用性和可靠性，同时缩短响应时间。复制目录信息时，只要及时解决不一致问题，副本之间的临时不一致就可以了。 有许多不同的方法来提供目录服务。不同的方法允许将不同类型的信息存储在目录中，对如何引用，查询和更新信息。一些目录服务是本地的，向受限制的上下文提供服务；其它服务是全球性的，为更广泛的环境提供服务。全局服务通常是分布式的，这意味着它们包含的数据分布在许多机器上，所有机器都协作提供目录服务。通常，全局服务定义统一命名空间(namespace)，无论您在何处与数据本身相关，都可以提供相同的数据视图。 \r\r\r","date":"2019-01-18","objectID":"/openldap/:4:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"LDAP是什么 LDAP(Lightweight Directory Access Protocol, 轻型目录访问协议)，顾名思义，它是一种用于访问目录服务的轻量级协议，特别是基于X.500的目录服务。LDAP通过TCP / IP或其他面向连接的传输服务运行。 哪些种类的信息可以存储在目录中？DAP信息模型基于条目(entry)。条目是具有全局唯一可分辨名称（DN）的属性(attributes)集合。DN用于明确指代Entry，每个条目的属性都有一个类型(type)和一个或多个值(value)。 #这些类型通常是助记符字符串 cn mail #值的语法取决于属性类型 cn: ldap-test mail: example@test.com 信息是如何安排的？在LDAP中，目录条目以分层树状结构(tree-like structure)排列。 传统上，这种结构反映了地理/组织边界。表示国家/地区的条目显示在树的顶部。下面是代表各州和国家组织的条目。再下面可能是表示组织单位，人员，打印机，文档或您可以想到的任何其他内容的条目。 传统命名: 还可以基于因特网域名来安排树。这种命名方法正变得越来越流行，因为它允许使用DNS定位目录服务。 基于域名命名: 此外，LDAP允许您通过使用名为对象类(objectClass)的特殊属性来控制条目中所需和允许的属性。它的值确定条目必须遵守的模式规则。 如何引用信息？条目由其可分辨名称(DN)引用，该名称通过获取条目本身的名称来构造(称为Relative Distinguished Name, RDN)，并连接其祖先条目的名称。 如何保护信息免受未经授权的访问？某些目录服务不提供保护，允许任何人查看信息。LDAP为客户端提供了一种机制，用于对目录服务器进行身份验证或证明其身份。LDAP还支持数据安全性（完整性和机密性）服务。 \r\r\r","date":"2019-01-18","objectID":"/openldap/:5:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"什么时候应该使用LDAP 通常，当您需要通过基于标准的方法集中管理、存储、访问数据时，应使用目录服务器。 总是有新的方法来使用目录并应用LDAP原则来解决某些问题，因此这个问题没有简单的答案。 一些常见的栗子： 机器认证: Machine Authentication 用户认证: User Authentication 用户/系统组: User/System Groups 地址簿: Address book 组织代表: Organization Representation 资产追踪: Asset Tracking 电话信息存储: Telephony Information Store 用户资源管理: User resource management 电子邮件查找: E-mail address lookups 应用配置存储: Application Configuration store PBX Configuration store … \r\r\r","date":"2019-01-18","objectID":"/openldap/:6:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"LDAP如何工作 LDAP使用C-S模式。一个或多个LDAP服务器包含组成目录信息树（DIT，directory information tree）的数据。客户端连接到服务器并发出请求。服务端响应客户端的请求。无论客户端连接到哪个LDAP服务器，它都会看到相同的目录视图，这是全局目录服务的一个重要特性。 \r\r\r","date":"2019-01-18","objectID":"/openldap/:7:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"关于x.500 X.500是计算机目录服务的标准系列。X.500协议包括: DAP (Directory Access Protocol) DSP (Directory System Protocol) DISP (Directory Information Shadowing Protocol) DOP (Directory Operational Bindings Management Protocol) LDAP (Lightweight Directory Access Protocol) 从技术上讲，LDAP是X.500目录服务的目录访问协议。DAP是一种重量级协议，可在完整的OSI协议栈上运行，并且需要大量的计算资源。LDAP旨在通过TCP/IP进行操作，并以更低的成本提供DAP的大部分功能。 虽然LDAP仍然用于通过网关访问X.500目录服务，但现在更常见的是在X.500服务器中直接实现LDAP。 可以将 standalone LDAP daemon(slapd) 视为轻量级X.500目录服务器。也就是说，它没有实现X.500的DAP，也不支持完整的X.500模型。 \r\r\r","date":"2019-01-18","objectID":"/openldap/:8:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"LDAP与RDBMS 最常见的问题是——为什么OpenLDAP不使用 RDBMS(关系数据库管理系统) 而是使用像 LMDB 那样的嵌入式键/值存储？总的来说，期望商业级 RDBMS 实现的复杂算法可以使 OpenLDAP更 快或更好，并且同时允许与其他应用程序共享数据。 简而言之，使用嵌入式数据库和自定义索引系统，OpenLDAP可以在不损失可靠性的情况下提供更高的性能和可扩展性。所以OpenLDAP使用 LMDB 并发/事务 数据库软件。 下面是一个详细而冗长的答案: \u003c\u003e 很有可能认为在目录中使用RDBMS后端可以解决所有问题。但是，它是一头猪。这是因为数据模型非常不同。使用关系数据库表示目录数据将需要将数据拆分为多个表。 现在最大的问题是从一个条目访问数据需要在不同的磁盘区域上进行搜索。在某些应用程序中，这可能没问题但在许多应用程序中性能会受到影响。 \r\r\r","date":"2019-01-18","objectID":"/openldap/:9:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"slapd slapd是OpenLDAP的守护进程， 在许多不同平台上运行的LDAP目录服务器。 slapd有一些有趣的功能和特性: LDAPv3: slapd实现轻量级目录访问协议的第3版，slapd支持IPv4和IPv6以及Unix IPC上的LDAP。 Simple Authentication and Security Layer: slapd通过使用SASL支持强身份验证和数据安全性（完整性和机密性）服务 Transport Layer Security: slapd通过使用 TLS/SSL 持基于证书的身份验证和数据安全性（完整性和机密性）服务 Topology control: slapd可以配置为根据网络拓扑信息限制 socket 层的访问，基于 TCP wrapper Access control: slapd提供了丰富而强大的访问控制功能，允许您控制对数据库中信息的访问 Internationalization: slapd支持Unicode 和 Language tag Choice of database backends: slapd附带了各种不同的数据库后端，您可以从中选择 Multiple database instances: slapd可以配置为同时为多个数据库提供服务。这意味着单个slapd服务器可以使用相同或不同的数据库后端响应LDAP树的许多逻辑上不同部分的请求 Generic modules API: 如果您需要更多自定义，slapd可让您轻松编写自己的模块 Threads: slapd具有高性能的线程 Replication: slapd可以配置为维护目录信息的集群副本 Proxy Cache: slapd可以配置为缓存LDAP代理服务 Configuration: slapd可通过单个配置文件进行高度配置，允许您更改您想要更改的所有内容 \r\r \r\r快速入门 A Quick-Start Guide 注意：本快速入门指南不使用强身份验证，也不使用任何完整性或机密保护服务。这些服务在OpenLDAP的其它章节中进行了描述。 以下包括OpenLDAP v2.4软件的快速入门指南。 获取软件 打开发行包 审阅文档 运行configure 构建软件 测试构建 安装软件 编辑配置文件 导入配置数据库 启动SLAPD 添加初始化条目到目录 查看是否正常运行 \r\r \r\r配置选择 The Big Picture - Configuration Choices 本节简要概述了各种LDAP目录配置。 \r","date":"2019-01-18","objectID":"/openldap/:10:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"本地目录服务 Local Directory Service 在此配置中，您运行 slapd 实例，该实例仅为您的本地域提供目录服务。它不以任何方式与其他目录服务器进行交互。 \r\r\r","date":"2019-01-18","objectID":"/openldap/:11:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"带推荐的本地目录服务 Local Directory Service with Referrals 在此配置中，运行 slapd 实例，该实例为本地域提供目录服务，并将其配置为将引用返回到能够处理请求的其它服务器。 如果要提供本地服务并参与全局目录，或者要将下级条目的责任委派给其他服务器，请使用此配置。 \r\r\r","date":"2019-01-18","objectID":"/openldap/:12:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"副本目录服务 Replicated Directory Service slapd 包括对基于LDAP Sync 的复制的支持，称为syncrepl。可用于在多个目录服务器上维护目录信息的副本。在其最基本的配置中，master 是 syncrepl provider，slavee 是 syncrepl consumer。 集群和提供了可靠性和可用性。 \r\r\r","date":"2019-01-18","objectID":"/openldap/:13:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"分布式目录服务 Distributed Local Directory Service 在此配置中，本地服务被划分为较小的服务，每个服务都可以被复制，并与上级和下级引用粘合在一起。 \r\r \r\r安装 Building and Installing OpenLDAP Software 本章详细介绍了如何构建和安装OpenLDAP软件包。 \r","date":"2019-01-18","objectID":"/openldap/:14:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"源码安装 官方文档中是使用源码进行构建和安装。 #提取软件 gunzip -c openldap-VERSION.tgz | tar xf - cd openldap-VERSION #依赖软件 #请参考REAME，安装它所需的依赖软件 #Transport Layer Security #Simple Authentication and Security Layer #Kerberos Authentication Service #Database Software #Threads #TCP Wrappers #configure ./configure --help ./configure --enable-wrappers \\ CPPFLAGS=\"-I/usr/local/include\" \\ LDFLAGS=\"-L/usr/local/lib -Wl,-rpath,/usr/local/lib\" #构建软件 make depend make #测试 make test #安装 #如果未指定安装位置，默认安装到 /usr/local #通常，安装需要超级用户权限 sudo make install #配置文件 /usr/local/etc/openldap \r\r\r","date":"2019-01-18","objectID":"/openldap/:15:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"包安装 因为在base源里面可直接搜索到openldap软件包，所以就是用软件包进行安装。 RPM包： #查看 yum search openldap openldap.x86_64 : LDAP support libraries openldap-devel.x86_64 : LDAP development libraries and header files openldap-servers.x86_64 : LDAP server openldap-clients.x86_64 : LDAP client utilities openldap-servers-sql.x86_64 : SQL support module for OpenLDAP server compat-openldap.x86_64 : OpenLDAP compatibility shared libraries collectd-openldap.x86_64 : OpenLDAP plugin for collectd nss-pam-ldapd.x86_64 : An nsswitch module which uses directory servers #安装 yum install -y openldap.x86_64 openldap-servers.x86_64 openldap-clients.x86_64 #yum install -y collectd-openldap.x86_64 openldap-servers-sql.x86_64 compat-openldap.x86_64 openldap-devel.x86_64 nss-pam-ldapd.x86_64 #验证 rpm -qa | grep openldap #配置文件 /etc/openldap \r\r \r\r配置 Configuring slapd 安装完毕后，你就可以配置并使用它。 本章介绍 slapd-config 配置系统的一般格式。 OpenLDAP v2.3及更高版本已转换为使用动态运行配置引擎slapd-config: 完全启用LDAP 使用标准LDAP操作进行管理 将其配置数据存储在LDIF数据库中(openldap/slap.d/) 允许所有slapd的配置选项在运行中进行更改，通常无需重新启动服务器即可使更改生效 注意： 虽然 slapd-config 统将其配置存储为（基于文本的）LDIF文件，但您不应直接编辑任何LDIF文件。配置更改应通过LDAP操作执行，如 ldapadd, ldapdelete, ldapmodify \r\r","date":"2019-01-18","objectID":"/openldap/:16:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"配置的布局 Configuration Layout slapd配置存储为具有预定义模式和DIT的特殊LDAP目录。有特定的objectClasses用于承载全局配置选项，模式定义，后端和数据库定义以及各种其它项。 栗子配置树: slapd-config 配置树具有非常特定的结构。树的根名为 cn=config 并包含全局配置设置。其他设置包含在单独的子条目中： Dynamically loaded modules Schema definitions Backend-specific configuration Database-specific configuration LDIF文件的常用规则适用于配置信息: #表示注释 如果一行以单个空格开头，则将其视为前一行的延续（即使前一行是注释），并删除单个前导空格。条目由空行分隔 配置LDIF的一般布局如下： #globalconfigurationsettings dn:cn=config objectClass:olcGlobal cn:config \u003cglobalconfigsettings\u003e #schemadefinitions dn:cn=schema,cn=config objectClass:olcSchemaConfig cn:schema \u003csystemschema\u003e dn:cn={X}core,cn=schema,cn=config objectClass:olcSchemaConfig cn:{X}core \u003ccoreschema\u003e #additionaluser-specifiedschema ... #backenddefinitions dn:olcBackend=\u003ctypeA\u003e,cn=config objectClass:olcBackendConfig olcBackend:\u003ctypeA\u003e \u003cbackend-specificsettings\u003e #databasedefinitions dn:olcDatabase={X}\u003ctypeA\u003e,cn=config objectClass:olcDatabaseConfig olcDatabase:{X}\u003ctypeA\u003e \u003cdatabase-specificsettings\u003e #subsequentdefinitionsandsettings ... \r\r\r","date":"2019-01-18","objectID":"/openldap/:17:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"配置指令 Configuration Directives 本节详细介绍了常用的配置指令 \r","date":"2019-01-18","objectID":"/openldap/:18:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"cn=config 本条目中包含的指令通常适用于整个服务器。其中大多数是系统或面向连接，而不是数据库相关。条目必须具有 olcGlobal 对象类(objectClass) #指定强制关闭空闲客户端连接之前等待的秒数 #默认值为0，表示禁用此功能 olcIdleTimeout: \u003cinteger\u003e #该指令指定syslog（当前记录到syslogd）的调试语句和操作统计信息的级别。您必须已配置OpenLDAP --enable-debug（默认值）才能使用 olcLogLevel: \u003clevel\u003e #Debugging Levels Level Keyword Description -1 any enable all debugging 0 no debugging 1 (0x1 trace) trace function calls 2 (0x2 packets) debug packet handling 4 (0x4 args) heavy trace debugging 8 (0x8 conns) connection management 16 (0x10 BER) print out packets sent and received 32 (0x20 filter) search filter processing 64 (0x40 config) configuration processing 128 (0x80 ACL) access control list processing 256 (0x100 stats) stats log connections/operations/results 512 (0x200 stats2) stats log entries sent 1024 (0x400 shell) print communication with shell backends 2048 (0x800 parse) print entry parsing debugging 16384 (0x4000 sync) syncrepl consumer processing 32768 (0x8000 none) only messages that get logged whatever log level is set #指定当slapd无法找到本地数据库来处理请求时要传回的引用 olcReferral \u003cURI\u003e #栗子条目 dn: cn=config objectClass: olcGlobal cn: config olcIdleTimeout: 30 olcLogLevel: Stats olcReferral: ldap://root.openldap.org \r\r","date":"2019-01-18","objectID":"/openldap/:18:1","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"cn=module 如果在配置slapd时启用了对动态加载模块的支持，则可以使用 cn=module 条目来指定要加载的模块集。 #指定要加载的可动态加载模块的名称 olcModuleLoad: \u003cfilename\u003e #指定要搜索可加载模块的目录列表 olcModulePath: \u003cpathspec\u003e #栗子 dn: cn=module{0},cn=config objectClass: olcModuleList cn: module{0} olcModuleLoad: /usr/local/lib/smbk5pwd.la dn: cn=module{1},cn=config objectClass: olcModuleList cn: module{1} olcModulePath: /usr/local/lib:/usr/local/lib/slapd olcModuleLoad: accesslog.la olcModuleLoad: pcache.la \r\r","date":"2019-01-18","objectID":"/openldap/:18:2","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"cn=schema 此条目包含在 slapd 中硬编码的所有模式定义。因此，此条目中的值由slapd生成，因此配置文件中不需要提供 schema value。仍必须定义该条目，以作为用户定义的模式添加到下面的基础。schema entry 必须具有 olcSchemaConfig 的对象类 (objectClass)。 #定义了一个属性类型 olcAttributeTypes: \u003cRFC4512 Attribute Type Description\u003e #定义一个对象类 olcObjectClasses: \u003cRFC4512 Object Class Description\u003e #栗子条目 dn: cn=schema,cn=config objectClass: olcSchemaConfig cn: schema dn: cn=test,cn=schema,cn=config objectClass: olcSchemaConfig cn: test olcAttributeTypes: ( 1.1.1 NAME 'testAttr' EQUALITY integerMatch SYNTAX 1.3.6.1.4.1.1466.115.121.1.27 ) olcAttributeTypes: ( 1.1.2 NAME 'testTwo' EQUALITY caseIgnoreMatch SUBSTR caseIgnoreSubstringsMatch SYNTAX 1.3.6.1.4.1.1466.115.121.1.44 ) olcObjectClasses: ( 1.1.3 NAME 'testObject' MAY ( testAttr $ testTwo ) AUXILIARY ) \r\r","date":"2019-01-18","objectID":"/openldap/:18:3","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"Backend-specific Directives 后端指令适用于所有相同类型的数据库实例，并且可能会被数据库指令覆盖，具体取决于指令。后端条目必须具有 olcBackendConfig 的对象类 (objectClass)。 #命名特定于后端的配置条目 olcBackend: \u003ctype\u003e #Database Backends Types Description bdb Berkeley DB transactional backend (deprecated) config Slapd configuration backend dnssrv DNS SRV backend hdb Hierarchical variant of bdb backend (deprecated) ldap Lightweight Directory Access Protocol (Proxy) backend ldif Lightweight Data Interchange Format backend mdb Memory-Mapped DB backend meta Meta Directory backend monitor Monitor backend passwd Provides read-only access to passwd(5) perl Perl Programmable backend shell Shell (extern program) backend sql SQL Programmable backend #栗子 dn: olcBackend=bdb,cn=config objectClass: olcBackendConfig olcBackend: bdb \r\r","date":"2019-01-18","objectID":"/openldap/:18:4","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"Database-specific Directives 每种类型的数据库都支持本节中的指令。数据库条目必须含有 olcDatabaseConfig 对象类 (objectClass)。 #命名特定的数据库实例 #可以提供数字{\u003cindex\u003e}以区分相同类型的多个数据库 olcDatabase: [{\u003cindex\u003e}]\u003ctype\u003e #权限指令 #如果未指定，默认使用 to * by * read olcAccess: to \u003cwhat\u003e [ by \u003cwho\u003e [\u003caccesslevel\u003e] [\u003ccontrol\u003e] ]+ #将数据库置于“只读”模式 olcReadonly { TRUE | FALSE } #指定不受此访问控制的DN或对此数据库的操作的管理限制 #DN不需要引用此数据库中的条目，甚至不需要引用目录中的条目。 olcRootDN: \u003cDN\u003e #用于为root dn 指定DN的密码 olcRootPW: \u003cpassword\u003e #指定从搜索操作返回的最大条目数 olcSizeLimit: \u003cinteger\u003e #定将传递给此后端数据库的查询的DN后缀 olcSuffix: \u003cdn suffix\u003e #将当前 slapd 建立为运行 syncrepl 复制引擎的复制使用者站点，将当前数据库指定为主内容的副本 olcSyncrepl #指定slapd将用于回答搜索请求的最大秒数 olcTimeLimit: \u003cinteger\u003e #该指令仅适用于slave slapd olcUpdateref: \u003cURL\u003e #栗子条目 dn: olcDatabase=frontend,cn=config objectClass: olcDatabaseConfig objectClass: olcFrontendConfig olcDatabase: frontend olcReadOnly: FALSE dn: olcDatabase=config,cn=config objectClass: olcDatabaseConfig olcDatabase: config olcRootDN: cn=Manager,dc=example,dc=com \r\r","date":"2019-01-18","objectID":"/openldap/:18:5","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"BDB and HDB Database Directives 此类别中的指令适用于BDB和HDB数据库。除了上面定义的通用数据库指令之外，它们还用在 olcDatabase 条目中。除了olcDatabaseConfig 对象类之外，BDB和HDB数据库条目还必须分别具有 olcBdbConfig 和 olcHdbConfig 对象类。 #指定包含数据库和相关索引的BDB文件所在的目录 olcDbDirectory: \u003cdirectory\u003e #指定BDB后端数据库实例维护的内存高速缓存条目的大小 olcDbCachesize: \u003cinteger\u003e #指定检查BDB事务日志的频率，检查点操作将数据库缓冲区刷新到磁盘，并在日志中写入检查点记录 olcDbCheckpoint: \u003ckbyte\u003e \u003cmin\u003e #指定要放置在数据库目录的DB_CONFIG文件中的配置指令 olcDbConfig: \u003cDB_CONFIG setting\u003e #此选项会导致磁盘上的数据库内容在更改时不会立即与内存更改同步 olcDbNosync: { TRUE | FALSE } #在索引槽中指定内存中索引缓存的大小。默认值为零 olcDbIDLcacheSize: \u003cinteger\u003e #指定要为给定属性维护的索引 olcDbIndex: {\u003cattrlist\u003e | default} [pres,eq,approx,sub,none] #如果此设置为TRUE，则slapindex将一次索引一个属性。默认设置为FALSE，在这种情况下，条目的所有索引属性将同时处理 olcDbLinearIndex: { TRUE | FALSE } #指定新创建的数据库索引文件应具有的文件保护模式 olcDbMode: { \u003coctal\u003e | \u003csymbolic\u003e } #指定用于搜索过滤器评估的堆栈深度 olcDbSearchStack: \u003cinteger\u003e #为共享内存BDB环境指定 key 。默认情况下，BDB环境使用内存映射文件。如果指定了非零值，则它将用作标识将容纳环境的共享内存区域的键 olcDbShmKey: \u003cinteger\u003e #栗子条目 dn: olcDatabase=hdb,cn=config objectClass: olcDatabaseConfig objectClass: olcHdbConfig olcDatabase: hdb olcSuffix: \"dc=example,dc=com\" olcDbDirectory: /usr/local/var/openldap-data olcDbCacheSize: 1000 olcDbCheckpoint: 1024 10 olcDbConfig: set_cachesize 0 10485760 0 olcDbConfig: set_lg_bsize 2097152 olcDbConfig: set_lg_dir /var/tmp/bdb-log olcDbConfig: set_flags DB_LOG_AUTOREMOVE olcDbIDLcacheSize: 3000 olcDbIndex: objectClass eq \r\r \r\rslapd配置文件 The slapd Configuration File 本章介绍如何通过 slapd.conf 配置文件来配置 slapd。 slapd.conf 已被弃用，建议使用前面介绍的 slapd-config进行配置。 由于已经被弃用，所以此处我跳过。 文档: http://www.openldap.org/doc/admin24/slapdconfig.html \r\r \r\r运行slapd slapd 旨在作为独立服务运行。这允许服务器利用缓存，管理底层数据库的并发问题，并节省系统资源。 由于我使用RPM包进行安装，所以可利用 systemd 进行OpenLDAP的管理。 ldap默认监听地址: URL Protocol Transport ldap:/// LDAP TCP port 389 ldaps:/// LDAP over SSL TCP port 636 ldapi:/// LDAP IPC (Unix-domain socket) \r","date":"2019-01-18","objectID":"/openldap/:18:6","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"slapd方式 #查看帮助 #man slapd slapd --help #启动 slapd --option #停止 kill -INT `cat /usr/local/var/slapd.pid` \r\r","date":"2019-01-18","objectID":"/openldap/:19:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"systemd方式 systemctl status slapd systemctl start slapd #ps -ef | grep slapd #/usr/sbin/slapd -u ldap -h ldapi:/// ldap:/// systemctl stop slapd \r\r \r\r访问控制","date":"2019-01-18","objectID":"/openldap/:20:0","tags":["LDAP","Permission","权限管理"],"title":"OpenLDAP","uri":"/openldap/"},{"categories":["infrastructure"],"content":"参考: OpenVPN: https://github.com/OpenVPN/openvpn easy-rsa: https://github.com/OpenVPN/easy-rsa \r环境: RHEL7 OpenVPN v2.4.6 easy-rsa v3.0.3 \r\r \r\r概述 通过在云端VPC， k8s集群内运行OpenVPN Server，让本地可以通过连接OpenVPN进行访问云资源，而不需要将云资源开放公网访问。 我是将OpenVPN运行在k8s 集群了，对它提供ELB进行公网连接。在S端配置文件中推送对应的路由信息——如集群内节点CIDR， 服务CIDR, VPC CIDR… \r\r \r\r安装和配置 \r","date":"2019-01-16","objectID":"/openvpn/:0:0","tags":["openvpn","vpn"],"title":"OpenVPN","uri":"/openvpn/"},{"categories":["infrastructure"],"content":"安装 需要安装: EPEL openvpn easy-rsa: 用于制作CA证书，S端证书，C端证书 安装了EPEL源之后就可以直接安装openvpn和easy-rsa，当然也可以从GitHub上拉取。 yum install -y epel-release yum install -y openvpn easy-rsa \r\r\r","date":"2019-01-16","objectID":"/openvpn/:1:0","tags":["openvpn","vpn"],"title":"OpenVPN","uri":"/openvpn/"},{"categories":["infrastructure"],"content":"制作证书 \r","date":"2019-01-16","objectID":"/openvpn/:2:0","tags":["openvpn","vpn"],"title":"OpenVPN","uri":"/openvpn/"},{"categories":["infrastructure"],"content":"编辑vars文件 此处需注意，通过yum安装可能会没有example.vars这个栗子文件。没关系，请在easy-rsa GitHub去下载一份过来。 mkdir -p /etc/openvpn/easy-rsa/server mkdir -p /etc/openvpn/easy-rsa/client #拷贝easy-rsa文件，用于制作证书 cp -r /usr/share/easy-rsa/3.0.3/ /etc/openvpn/easy-rsa/server/ cp -r /usr/share/easy-rsa/3.0.3/ /etc/openvpn/easy-rsa/client/ #先制作CA和S端证书 cd /etc/openvpn/easy-rsa/server/ cp vars.example vars #修改几个配置 vim vars #根据自己的情况进行修改 set_var EASYRSA_REQ_COUNTRY “CN” #国家 set_var EASYRSA_REQ_PROVINCE “Sichuan” #省份 set_var EASYRSA_REQ_CITY “ChengDu” #城市 set_var EASYRSA_REQ_ORG “TianFu” #非盈利组织，此处可填公司之类 set_var EASYRSA_REQ_EMAIL “abc@xyz.com” #邮箱地址 set_var EASYRSA_REQ_OU “My OpenVPN” #组织单元 \r\r","date":"2019-01-16","objectID":"/openvpn/:2:1","tags":["openvpn","vpn"],"title":"OpenVPN","uri":"/openvpn/"},{"categories":["infrastructure"],"content":"创建证书和秘钥 CA证书和S端证书 cd /etc/openvpn/easy-rsa/server ./easyrsa -h #初始化，会读取vars文件 ./easyrsa init-pki #创建根证书 #这里会要求输入PEM pass，这个请记住，后面签名需要此密码 ./easyrsa build-ca #这里生成CA证书 #pki/ca.crt #创建S端证书 #nopass选项表示不加密 ./easyrsa gen-req server nopass #这里生成两个文件 #pki/reqs/server.req #pki/private/server.key #签约S端证书 #第一个server表示S端，后面是取的名字 ./easyrsa sign server server #这里需要输入CA证书的PEM pass #之后会生成S端证书 #pki/issued/server.crt #创建Diffie-Hellman ./easyrsa gen-dh #生成dh.pem文件 #pki/dh.pem C端证书 cd /etc/openvpn/easy-rsa/client/ #./easyrsa -h #初始化 ./easyrsa init-pki #创建C端证书 ./easyrsa gen-req client nopass #这里生成两个文件 #pki/reqs/client.req #pki/private/client.key #在CA端导入C端证书 cd /etc/openvpn/easy-rsa/server ./easy-rsa import-req /etc/openvpn/easy-rsa/client/reqs/client.req client #签约C端证书 #第一个client表示C端，第二个为定义的名字 ./easyrsa sign client client #这里需要输入CA证书的PEM pass #之后会生成C端证书 #/etc/openvpn/easy-rsa/server/pki/issued/client.crt #注意生成的位置，不要搞错了 梳理上面生成的文件 server/pki/ca.crt server/pki/dh.pem server/pki/reqs/server.req server/pki/reqs/client.req server/pki/private/ca.key server/pki/private/server.key server/pki/issued/server.crt server/pki/issued/client.crt #client/pki/reqs/client.req client/pki/private/client.key \r\r\r","date":"2019-01-16","objectID":"/openvpn/:2:2","tags":["openvpn","vpn"],"title":"OpenVPN","uri":"/openvpn/"},{"categories":["infrastructure"],"content":"拷贝相应证书到openvpn目录下 #S端 cd /etc/openvpn/server cp /etc/openvpn/easy-rsa/server/pki/ca.crt . cp /etc/openvpn/easy-rsa/server/pki/private/server.key . cp /etc/openvpn/easy-rsa/server/pki/issued/server.crt . cp /etc/openvpn/easy-rsa/server/pki/dh.pem . #C端 cd /etc/openvpn/client cp /etc/openvpn/easy-rsa/server/pki/ca.crt . cp /etc/openvpn/easy-rsa/client/pki/private/client.key . cp /etc/openvpn/easy-rsa/server/pki/issued/client.crt . \r\r\r","date":"2019-01-16","objectID":"/openvpn/:3:0","tags":["openvpn","vpn"],"title":"OpenVPN","uri":"/openvpn/"},{"categories":["infrastructure"],"content":"配置文件 在openvpn GitHub去下载对应配置文件，做相应的修改。 \r","date":"2019-01-16","objectID":"/openvpn/:4:0","tags":["openvpn","vpn"],"title":"OpenVPN","uri":"/openvpn/"},{"categories":["infrastructure"],"content":"S端配置文件 一下只是我的栗子，详细信息请参考自己的项目。具体的每个选项描述，栗子文件里面有解释。 vim server.conf: port 1194 proto udp dev tun ca /etc/openvpn/server/ca.crt cert /etc/openvpn/server/server.crt key /etc/openvpn/server/server.key dh /etc/openvpn/server/dh.pem #VPN CIDR server 10.8.0.0 255.255.255.0 ifconfig-pool-persist ipp.txt #推送的S端的CIDR给C端路由 push \"route 10.0.0.0 255.255.224.0\" #推送S端DNS push \"dhcp-option DNS 10.247.3.10\" push \"dhcp-option DNS 114.114.114.114\" client-to-client keepalive 20 120 cipher AES-256-CBC persist-key persist-tun log /dev/stdout log-append /dev/stdout verb 3 explicit-exit-notify 1 #启用用户/密码进行登录需要添加的选项 #栗子文件里面没有这些信息 script-security 3 auth-user-pass-verify /etc/openvpn/checkpsw.sh via-env #http://openvpn.se/files/other/checkpsw.sh #去下载这个脚本 #client-cert-not-required #此选项只使用用户密码，不使用证书 #注释它，使用证书和用户密码双重登录 username-as-common-name \r\r","date":"2019-01-16","objectID":"/openvpn/:4:1","tags":["openvpn","vpn"],"title":"OpenVPN","uri":"/openvpn/"},{"categories":["infrastructure"],"content":"C端配置文件 vim client.ovpn: client dev tun proto udp remote addr port resolv-retry infinite nobind persist-key persist-tun #此处我将CA证书和C端证书信息写入配置文件 #当然，也可下载证书在指定，但这麻烦了 \u003cca\u003e -----BEGIN CERTIFICATE----- xxxxxxxxxxx -----END CERTIFICATE----- \u003c/ca\u003e \u003ccert\u003e -----BEGIN CERTIFICATE----- xxxxxxxxxxxxxxxxx -----END CERTIFICATE----- \u003c/cert\u003e \u003ckey\u003e -----BEGIN PRIVATE KEY----- xxxxxxxxxxxxxxxx -----END PRIVATE KEY----- \u003c/key\u003e remote-cert-tls server cipher AES-256-CBC verb 3 #用户认证 script-security 3 auth-user-pass #可将用户信息写入文件，用户密码各一行 \r\r","date":"2019-01-16","objectID":"/openvpn/:4:2","tags":["openvpn","vpn"],"title":"OpenVPN","uri":"/openvpn/"},{"categories":["infrastructure"],"content":"另外几个配置 vi checksw.sh: #!/bin/sh ########################################################### # checkpsw.sh (C) 2004 Mathias Sundman \u003cmathias@openvpn.se\u003e # # This script will authenticate OpenVPN users against # a plain text file. The passfile should simply contain # one row per user with the username first followed by # one or more space(s) or tab(s) and then the password. PASSFILE=\"/etc/openvpn/psw-file\" LOG_FILE=\"/etc/openvpn/openvpn-password.log\" TIME_STAMP=`date \"+%Y-%m-%d %T\"` ########################################################### if [ ! -r \"${PASSFILE}\" ]; then echo \"${TIME_STAMP}: Could not open password file \\\"${PASSFILE}\\\" for reading.\" \u003e\u003e ${LOG_FILE} exit 1 fi CORRECT_PASSWORD=`awk '!/^;/\u0026\u0026!/^#/\u0026\u0026$1==\"'${username}'\"{print $2;exit}' ${PASSFILE}` if [ \"${CORRECT_PASSWORD}\" = \"\" ]; then echo \"${TIME_STAMP}: User does not exist: username=\\\"${username}\\\", password=\\\"${password}\\\".\" \u003e\u003e ${LOG_FILE} exit 1 fi if [ \"${password}\" = \"${CORRECT_PASSWORD}\" ]; then echo \"${TIME_STAMP}: Successful authentication: username=\\\"${username}\\\".\" \u003e\u003e ${LOG_FILE} exit 0 fi echo \"${TIME_STAMP}: Incorrect password: username=\\\"${username}\\\", password=\\\"${password}\\\".\" \u003e\u003e ${LOG_FILE} exit 1 vi psw-file: 这为可登录的用户密码 直接往这个文件写入用户和密码即可，并不需要重启openvpn服务。 user1 pass-user1 #comment user2 pass-user2 vi start_openvpn.sh: 启动脚本 #!/bin/bash mkdir -p /dev/net if [ ! -c /dev/net/tun ]; then mknod /dev/net/tun c 10 200 fi echo 'net.ipv4.ip_forward=1' \u003e\u003e /etc/sysctl.conf \u0026\u0026 sysctl -p #此处一定要记得写iptables，否则后面连上了VPN也无法正常访问 #我也是找了好久才找到这个问题 #这个网段为openvpn里面定义的网段 iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -j MASQUERADE cd /etc/openvpn #--daemon，放入后台 /sbin/openvpn --config /etc/openvpn/server/server.conf 由于我是运行在k8s集群容器内，所有还有几个文件: Dockerfile .dockerignore k8s.yaml: 由于它需要创建和使用系统资源，所以请使用特权容器运行 \r\r \r\r启动 启动S端 客户端连接 Windows客户端 Linux客户端 Mac客户端 启动之后应该就能正常访问了，如果不能正常访问，请查看你推送的CIDR和DNS，还有ipv4转发和iptables等。 #S端 #由于需要使用和创建系统资源，所以请用特权容器进行运行，不然会提示没有权限 /sbin/openvpn --config /etc/openvpn/server/server.conf #C端 #Windows下载Openvpn GUI，制定客户端配置文件进行连接，之后输入用户名和面膜 #Linux下 #/sbin/openvpn --config /etc/openvpn/client/client.ovpn #Mac下，下载对应Openvpn软件，指定配置文件进行连接 ","date":"2019-01-16","objectID":"/openvpn/:4:3","tags":["openvpn","vpn"],"title":"OpenVPN","uri":"/openvpn/"},{"categories":["middleware"],"content":"参考: Apollo官方文档: https://github.com/ctripcorp/apollo/wiki 环境: Apollo v1.2 Docker v1.18 K8s v1.11 \r\r \r\r概述 基本上按照官方文档都没什么问题，说几点我在配置过程中容易出错的地方。 总的来说就是一个portal，多个config+admin，而Eruea注册的Meta Server是和config在一起的，每个环境的admin注册到对应环境的Meta Server(config)。 我是将其放入k8s集群中运行，所以针对官方给出的Dockerfile和k8s.yaml文件做了对应的修改。 \r看一下我画的架构图和官方架构图: \r我自己画的一个Apollo项目架构图： \r多区域部署Apollo： 由于Apollo各组件之间并没有使用认证，所以如果通过公网跨区域则一定注意使用安全访问控制策略，添加白名单。 \r\r\r注意事项 为不同环境创建不同数据库 官方已经给出了创建数据库的sql语句，一个portadb, 多个configdb-project-env。我们需要修改数据库名，为不同的环境建立不同的数据库，所以需要在使用官方sql的时候把数据库名修改为自定义的即可，这样创建的各个环境数据库的表结构都是一样的。 \r 配置了一个环境变量，它也就是部署服务的集群内访问地址(不在同一VPC可能需要外部访问地址) 官方是写入了Dockerfile里面作为环境变量，我是将其写入k8s yaml中的环境变量。当然，也可以写入启动脚本中。 以下配置，随便用哪一个。 #Dockerfile中ENV APOLLO_CONFIG_SERVICE_NAME=\"{service-name}.{namespace}.svc.cluster.local\"#k8s yaml container中env:- name:APOLLO_CONFIG_SERVICE_NAMEvalue:{service_name}.{namespace}.svc.cluster.local#启动脚本#scripts/startup-kubernetes.sh#SERVER_URL=\"http://${APOLLO_ADMIN_SERVICE_NAME}:${SERVER_PORT}\"SERVER_URL=\"http://{service_name}.{namespace}.svc.cluster.local:${SERVER_PORT}\" \r 将数据库和注册地址写入config/application-github.properties配置文件 官方是写入Dockerfile中作为环境变量，然后通过entrypoint.sh进行相应的替换。我直接将其写入此配置文件，并删除entrypoint.sh。 spring.datasource.url = jdbc:mysql://{mysql-ip}:{mysql-port}/{mysql-db}?characterEncoding=utf8spring.datasource.username = userspring.datasource.password = passwdeureka.service.url = http://{service-name}.{namespace}.svc.cluster.local:8080/eureka/# 如果环境跨VPC，还需要指定公网地址的 HomePageUrl# eureka.instance.homePageUrl = http://ELB:PORT# 或 在启动命名指定: -Dapollo.configService=http://config-service的公网IP:端口来跳过meta service的服务发现# 如果不指定的话，则默认使用获取的内部地址，这无法正常访问 \r portal服务的默认环境是DEV，请注意 如果配置的第一个环境并不是DEV，请记得先修改数据库中的这个值，不然portal读取config, admin会失败。 portaldb.serverconfig的apollo.portal.envs这个key，多个环境使用,分割，后面可以在UI上配置。其它环境请修改为其它环境名。 UPDATEserverconfigSETValue='uat'WHEREKey='apollo.portal.envs'; config/apollo-env.properties#dev.meta=http://DEV_META_SERVICE_NAME:8080#fat.meta=http://TEST_ALPHA_META_SERVICE_NAME:8080#uat.meta=http://TEST_BETA_META_SERVICE_NAME:8080#pro.meta=http://PROD_META_SERVICE_NAME:8080#某个环境的configuat.meta=http://{service-name}.{namespace}.svc.cluster.local:8080 \r 将日志输出到标准输出/dev/stdout 由于我是运行在容器中，所以需要将日志输出到标准输出。 这里很奇怪，直接在主机(centos7)上运行./apollo-xxx.jar start，日志正常输出到console；在openjdk容器里运行，./apollo-portal.jar start它放到后台运行，日志不输出到console，使用java ${JAVA_OPTS} -jar ./\"${SERVICE_NAME}.jar\"日志能够正常输出到console。 所以这里修改startup-kubernetes.sh启动命令: # 原 # export JAVA_OPTS=\"$JAVA_OPTS -Dserver.port=$SERVER_PORT -Dlogging.file=$LOG_DIR/$SERVICE_NAME.log -Xloggc:$LOG_DIR/gc.log -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=5M -XX:HeapDumpPath=$LOG_DIR/HeapDumpOnOutOfMemoryError/\" # 修改 export JAVA_OPTS=\"$JAVA_OPTS-Dserver.port=$SERVER_PORT-Xloggc:$LOG_DIR/gc.log -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=5M -XX:HeapDumpPath=$LOG_DIR/HeapDumpOnOutOfMemoryError/\" # 原 # ./$SERVICE_NAME\".jar\" start # 修改 # 因为 xxx.jar start也是调用 java $opt_java -jar xxx.jar java ${JAVA_OPT} -jar ./\"${SERVICE_NAME}.jar\" \r 登录Web UI后可修改配置 如组织里面的部门名，管理员等等参数，在系统参数里面更新Key对应的Value。 具体这个Key可参考文档 —— 调整服务端配置 \r 每个环境下有多个config/admin 请注意，每个环境只有一个数据库，也就是这几个服务都要连接同一个configdb，这点请注意。 后面还需要修改ConfigDB.ServerConfig表，每个环境的都需要单独配置。这里的eureka.service.url - Eureka服务Url要来修改。 ps: 官方文档 不管是apollo-configservice还是apollo-adminservice都需要向eureka服务注册，所以需要配置eureka服务地址。 按照目前的实现，apollo-configservice本身就是一个eureka服务，所以只需要填入apollo-configservice的地址即可，如有多个，用逗号分隔（注意不要忘了/eureka/后缀）。 需要注意的是每个环境只填入自己环境的eureka服务地址，比如FAT的apollo-configservice是1.1.1.1:8080和2.2.2.2:8080，UAT的apollo-configservice是3.3.3.3:8080和4.4.4.4:8080，PRO的apollo-configservice是5.5.5.5:8080和6.6.6.6:8080，那么： 在FAT环境的ApolloConfigDB.ServerConfig表中设置eureka.service.url为： http://1.1.1.1:8080/eureka/,http://2.2.2.2:8080/eureka/ 在UAT环境的ApolloConfigDB.ServerConfig表中设置eureka.service.url为： http://3.3.3.3:8080/eureka/,http://4.4.4.4:8080/eureka/ 在PRO环境的ApolloConfigDB.ServerConfig表中设置eureka.service.url为： http://5.5.5.5:8080/eureka/,http://6.6.6.6:8080/eureka/ 更过详情请查看官方文档！ 假如UAT环境下有: config-cd, config-bj, config-gz admin-cd, adm","date":"2019-01-09","objectID":"/apollo/:0:0","tags":["apollo","分布式","配置中心"],"title":"Apollo","uri":"/apollo/"},{"categories":["middleware"],"content":"apollo-config tree . . ├── apollo-configservice.conf ├── apollo-configservice.jar ├── config │ ├── application-github.properties │ └── app.properties ├── Dockerfile ├── k8s-apollo-config-dev.yaml ├── README.md └── scripts └── startup-kubernetes.sh Dockerfile FROM openjdk:8-jre-alpine3.8 RUN \\ echo \"http://mirrors.aliyun.com/alpine/v3.8/main\" \u003e /etc/apk/repositories \u0026\u0026 \\ echo \"http://mirrors.aliyun.com/alpine/v3.8/community\" \u003e\u003e /etc/apk/repositories \u0026\u0026 \\ apk update upgrade \u0026\u0026 \\ apk add --no-cache procps curl bash tzdata \u0026\u0026 \\ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \u0026\u0026 \\ echo \"Asia/Shanghai\" \u003e /etc/timezone \u0026\u0026 \\ mkdir -p /apollo-config-server COPY . /apollo-config-server/ EXPOSE 8080 CMD [\"/apollo-config-server/scripts/startup-kubernetes.sh\"] config/ # app.properties不用修改 # application-github.properties # DataSource spring.datasource.url = jdbc:mysql://host:port/configdbtest?characterEncoding=utf8 spring.datasource.username = user spring.datasource.password = passwd eureka.service.url = http://xxx.svc.cluster.local:8080/eureka/ # 扩公网的话请修改 HomePageUrl # config-web-test service homepage ELB # eureka.instance.homePageUrl = http://ELB:PORT \rscripts/ startup-kubernetes.sh 这个文件，文件名你也可以随便修改。 有些值既可以写在这里面，也可以配置成环境变量(Dockerfile， 或k8s yaml) 这里把 APOLLO_CONFIG_SERVICE_NAME 配置成 k8s yaml 里的环境变量 xxx.apollo-test.svc.cluster.local(即k8s service)。 #!/bin/bash SERVICE_NAME=apollo-configservice ## Adjust log dir if necessary LOG_DIR=/opt/logs/apollo-config-server ## Adjust server port if necessary SERVER_PORT=8080 SERVER_URL=\"http://${APOLLO_CONFIG_SERVICE_NAME}:${SERVER_PORT}\" ## Adjust memory settings if necessary #export JAVA_OPTS=\"-Xms6144m -Xmx6144m -Xss256k -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=384m -XX:NewSize=4096m -XX:MaxNewSize=4096m -XX:SurvivorRatio=8\" ## Only uncomment the following when you are using server jvm #export JAVA_OPTS=\"$JAVA_OPTS -server -XX:-ReduceInitialCardMarks\" ########### The following is the same for configservice, adminservice, portal ########### export JAVA_OPTS=\"$JAVA_OPTS-XX:+UseParNewGC -XX:ParallelGCThreads=4 -XX:MaxTenuringThreshold=9 -XX:+UseConcMarkSweepGC -XX:+DisableExplicitGC -XX:+UseCMSInitiatingOccupancyOnly -XX:+ScavengeBeforeFullGC -XX:+UseCMSCompactAtFullCollection -XX:+CMSParallelRemarkEnabled -XX:CMSFullGCsBeforeCompaction=9 -XX:CMSInitiatingOccupancyFraction=60 -XX:+CMSClassUnloadingEnabled -XX:SoftRefLRUPolicyMSPerMB=0 -XX:+CMSPermGenSweepingEnabled -XX:CMSInitiatingPermOccupancyFraction=70 -XX:+ExplicitGCInvokesConcurrent -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationConcurrentTime -XX:+PrintHeapAtGC -XX:+UseGCLogFileRotation -XX:+HeapDumpOnOutOfMemoryError -XX:-OmitStackTraceInFastThrow -Duser.timezone=Asia/Shanghai -Dclient.encoding.override=UTF-8 -Dfile.encoding=UTF-8 -Djava.security.egd=file:/dev/./urandom\" #官方默认是这个: export JAVA_OPTS=\"$JAVA_OPTS -Dserver.port=$SERVER_PORT -Dlogging.file=$LOG_DIR/$SERVICE_NAME.log -Xloggc:$LOG_DIR/gc.log -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=5M -XX:HeapDumpPath=$LOG_DIR/HeapDumpOnOutOfMemoryError/\" # 这里我修改，不将GC信息输出到console export JAVA_OPTS=\"$JAVA_OPTS-Dserver.port=$SERVER_PORT-Xloggc:$LOG_DIR/gc.log -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=5M -XX:HeapDumpPath=$LOG_DIR/HeapDumpOnOutOfMemoryError/\" printf \"$(date)==== Starting ==== \\n\" cd `dirname $0`/.. chmod 755 $SERVICE_NAME\".jar\" # 官方默认这样启动 # ./$SERVICE_NAME\".jar\" start # 这样启动在主机上可以输出日志到console，但openjdk容器里不行，所以修改如下 java ${JAVA_OPTS} -jar ./$SERVICE_NAME\".jar\" rc=$?; if [[ $rc != 0 ]]; then echo \"$(date)Failed to start $SERVICE_NAME.jar, return code: $rc\" exit $rc; fi tail -f /dev/null \rapollo-configservice.conf 这个也不需要做什么修改，看个人情况。 MODE=service PID_FOLDER=. LOG_FOLDER=/opt/logs/apollo-config-server \r\r\r","date":"2019-01-09","objectID":"/apollo/:1:0","tags":["apollo","分布式","配置中心"],"title":"Apollo","uri":"/apollo/"},{"categories":["middleware"],"content":"apollo-admin 这个其实和 apollo-config 差不多配置，只是修改一些配置项。 \r\r\r","date":"2019-01-09","objectID":"/apollo/:2:0","tags":["apollo","分布式","配置中心"],"title":"Apollo","uri":"/apollo/"},{"categories":["middleware"],"content":"apollo-portal 这个也和上面差不多，只是修改一些配置项。 ","date":"2019-01-09","objectID":"/apollo/:3:0","tags":["apollo","分布式","配置中心"],"title":"Apollo","uri":"/apollo/"},{"categories":["infrastructure"],"content":"参考: 维基百科 Google \r\r \r\r存储方案分类： DAS(Direct-Attached Storage)，直连式存储 NAS(Network Attached Storage)，网络附加存储 SAN(Storage Area Network)，存储区域网络 NAS和SAN既竞争又合作，很多高端NAS的后端存储就是SAN。NAS和SAN的整合也是存储设备的发展趋势。SAN提供的存储单位是LUN，属于block级别的。经过NAS创建成文件系统后，就变成文件级别的了。 NAS和SAN最本质的区别就是文件管理系统在哪里。 \r\rDAS 直连式存储是指直接和计算机相连接的数据储存方式。 像固态硬盘、机械硬盘、光盘驱动器与计算机直接相连的设备都是属于直连式存储设备。实际上，直连式存储的名称是后来为了区别于存储区域网络（SAN）和网络附加储存（NAS）而添加的。 缺点： 服务器本身容易成为系统瓶颈; 服务器发生故障，数据不可访问; 对于存在多个服务器的系统来说，设备分散，不便管理。同时多台服务器使用DAS时，存储空间不能在服务器之间动态分配，可能造成相当的资源浪费; 数据备份操作复杂。 \r\rNAS 网络附加存储是一种专门的数据存储技术的名称，它可以直接连接在计算机网络上面，对异质网络用户提供了集中式数据访问服务。实际上就是网络文件服务器。 NAS设备也提供了不止一种文件传输协议。NAS系统通常有一个以上的硬盘，而且和传统的文件服务器一样，通常会把它们组成RAID来提供服务。 NAS设备直接连接到TCP/IP网络上，网络服务器通过TCP/IP网络存取管理数据。有了NAS以后，网络上的其他服务器就可以不必再兼任文件服务器的功能。 NAS是以文件为单位的通信协议，例如像是NFS（在UNIX系统上很常见）或是SMB（常用于Windows系统）。 缺点： 由于存储数据通过普通数据网络传输，因此易受网络上其它流量的影响。当网络上有其它大数据流量时会严重影响系统性能; 由于存储数据通过普通数据网络传输，因此容易产生数据泄漏等安全问题; 存储只能以文件方式访问，而不能像普通文件系统一样直接访问物理数据块，因此会在某些情况下严重影响系统效率，比如大型数据库就不能使用NAS. \r\rSAN 存储区域网络是一种连接外接存储设备和服务器的架构。人们采用包括光纤通道技术(FC)、磁盘阵列(RAID)、磁带柜、光盘柜的各种技术进行实现。 该架构的特点是，连接到服务器的存储设备，将被操作系统视为直接连接的存储设备。 SAN实际是一种专门为存储建立的独立于TCP/IP网络之外的专用网络。 SAN由于其基础是一个专用网络，因此扩展性很强，不管是在一个SAN系统中增加一定的存储空间还是增加几台使用存储空间的服务器都非常方便。 SAN是以区块为单位的通信协议，通常是透过SCSI再转为光纤通道或是iSCSI。还有其他各种不同的SAN通信协议。 缺点： 价格昂贵。不论是SAN阵列柜还是SAN必须的光纤通道交换机价格都是十分昂贵的，就连服务器上使用的光通道卡的价格也是不容易被小型商业企业所接受的; 需要单独建立光纤网络，异地扩展比较困难。 ","date":"2018-12-10","objectID":"/storage/:0:0","tags":["数据","存储"],"title":"存储方案","uri":"/storage/"},{"categories":["infrastructure"],"content":"参考： 维基百科 \r\r\r\r概述 云计算（cloud computing），是一种基于互联网的计算方式，通过这种方式，共享的软硬件资源和信息可以按需求提供给计算机各种终端和其他设备。 用户不再需要了解“云”中基础设施的细节，不必具有相应的专业知识，也无需直接进行控制云计算描述了一种基于互联网的新的IT服务增加、使用和交付模式，通常涉及通过互联网来提供动态易扩展而且经常是虚拟化的资源。 \r\r \r\r三种模式 美国国家标准和技术研究院的云计算定义中明确了三种服务模式： 基础环境即服务(IaaS, Infrastructure as a Service) 消费者使用“基础计算资源”，如处理能力、存储空间、网络组件或中间件。消费者能掌控操作系统、存储空间、已部署的应用程序及网络组件（如防火墙、负载平衡器等），但并不掌控云基础架构。例如：Amazon AWS、Rackspace。 平台即服务(PaaS, Platform as a Service) 消费者使用主机操作应用程序。消费者掌控运作应用程序的环境（也拥有主机部分掌控权），但并不掌控操作系统、硬件或运作的网络基础架构。平台通常是应用程序基础架构。例如：Google App Engine。 软件即服务(SaaS, Software as a Service) 消费者使用应用程序，但并不掌控操作系统、硬件或运作的网络基础架构。是一种服务观念的基础，软件服务供应商，以租赁的概念提供客户服务，而非购买，比较常见的模式是提供一组账号密码。例如：Microsoft CRM与Salesforce.com。 \r\r \r\r部署模型 美国国家标准和技术研究院的云计算定义中也涉及了关于云计算的部署模型: 公有云（Public Cloud） 简而言之，公用云服务可透过网络及第三方服务供应者，开放给客户使用，“公用”一词并不一定代表“免费”，但也可能代表免费或相当廉价，公用云并不表示用户数据可供任何人查看，公用云供应者通常会对用户实施使用访问控制机制，公用云作为解决方案，既有弹性，又具备成本效益。 私有云（Private Cloud） 私有云具备许多公用云环境的优点，例如弹性、适合提供服务，两者差别在于私有云服务中，数据与程序皆在组织内管理，且与公用云服务不同，不会受到网络带宽、安全疑虑、法规限制影响；此外，私有云服务让供应者及用户更能掌控云基础架构、改善安全与弹性，因为用户与网络都受到特殊限制。 社群云（Community Cloud） 社群云由众多利益相仿的组织掌控及使用，例如特定安全要求、共同宗旨等。社群成员共同使用云数据及应用程序。 混合云（Hybrid Cloud） 混合云结合公用云及私有云，这个模式中，用户通常将非企业关键信息外包，并在公用云上处理，但同时掌控企业关键服务及数据。 \r\r \r\r云技术 KVM XEN VMWare OpenStack(IaaS, 私有云) OpenShift(Paas) Docker Kubernetes Ansible Chef Puppet Salt ","date":"2018-12-07","objectID":"/%E4%BA%91%E8%AE%A1%E7%AE%97/:0:0","tags":["云计算","云服务"],"title":"云计算","uri":"/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"categories":["linux"],"content":"参考: 维基百科 GitLab文档: https://docs.gitlab.com/ 版本: GitLib-CE: v11.6.0 GitLab-Runner: v11.6.0 \r\r \r\rGitLab是由GitLab Inc.开发，使用MIT许可证的基于网络的Git仓库管理工具。包括Git仓库管理、代码审查、问题跟踪、动态订阅、wiki等功能.以及GitLab内部集成的GitLab CI 更是一个持续集成和交付的好工具。 它有两个版本： CE EE \r\r \r\rUser User docs \r\r \r\rAdmin Administrator documentation ","date":"2018-12-06","objectID":"/gitlab/:0:0","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"安装和维护 Installing and maintaining GitLab \r","date":"2018-12-06","objectID":"/gitlab/:1:0","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"安装 Installation GitLab有多种方式进行安装。 依赖(requirements) 在安装之前，请先查看相关依赖文档。 依赖: https://docs.gitlab.com/ce/install/requirements.html 操作系统 Ruby版本 硬件 CPU Memory Storage 数据库 Unicorn Workers Unicorn是多进程的Server容器。 可以增加unicorn worker的数量，这通常有助于减少应用程序的响应时间并提高处理并行请求的能力。 对于大多数情况，我们建议使用:CPU cores + 1 = unicorn workers vi /etc/gitlab/gitlab.rb #CPU Cores=2 unicorn['worker_processes'] = 3 unicorn['worker_timeout'] = 60 Redis and Sidekiq Redis存储所有用户会话和后台任务队列。Redis的存储要求很低，每个用户约25kB。 Sidekiq是多线程的异步处理程序，使用多线程进程处理后台作业。 此过程从整个Rails Stack(200MB+)开始，如果存在内存泄漏，它可能会随着时间的推移而增长。 在非常活跃的服务器上（10,000+活动用户），Sidekiq进程可能使用1GB +内存。 GitLab Runner 我们强烈不要在计划安装GitLab的同一台机器上安装GitLab Runner。根据您决定配置GitLab Runner的方式以及用于在CI环境中运行应用程序的工具，GitLab Runner可能会占用大量可用内存。 如果您决定在同一台机器上运行GitLab Runner和GitLab Rails应用程序，则上面提供的内存消耗计算将无效。 由于安全原因，将所有内容安装在一台计算机上也是不安全的——特别是当您计划将shell执行程序与GitLab Runner一起使用时。 如果您打算使用CI功能，我们建议为每个GitLab Runner使用单独的计算机。 Prometheus and its exporters 从Omnibus GitLab 9.0开始，Prometheus及其相关的exporter默认启用，一遍轻松、深入地监控GitLab。这些进程大概消耗200MB内存。 支持的浏览器 安装方式(Installation methods) Omnibus包: https://about.gitlab.com/install/ 源码 Docker 数据库(Database) PostgreSQL (highly recommended) MySQL/MariaDB (strongly discouraged, not all GitLab features are supported, no support for MySQL/MariaDB GTID) As of GitLab 10.0, PostgreSQL 9.6 or newer is required, and earlier versions are not supported. Users using PostgreSQL must ensure the pg_trgm extension is loaded into every GitLab database. This extension can be enabled (using a PostgreSQL super user) by running the following query for every database: CREATEEXTENSIONpg_trgm; 在其它系统上，你可能需要安装附加包(e.g. postgresql-contrib)才能使得扩展可用。 如果你需要使用GitLab Geo，则需要postgres_fdw扩展： CREATEEXTENSIONpostgres_fdw; \r\r包安装 Centos7为栗子 #安装依赖Ruby #因为需要v2.3版本，而yum查找出来的为v2.0，所以不使用yum安装 #yum info ruby.x86_64 #这里使用Ruby管理工具RVM（“Ruby Version Manager”）进行安装 gpg --keyserver hkp://keys.gnupg.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB #开发版 \\curl -sSL https://get.rvm.io | bash #安装稳定版 \\curl -sSL https://get.rvm.io | bash -s stable --ruby #To start using RVM you need to run source ~/.rvm/scripts/rvm source ~/.rvm/scripts/rvm #可把它写入profile vim /etc/profile source ~/.rvm/scripts/rvm source /etc/profile #查看 rvm list known #安装ruby2.3 rvm install 2.3 ruby --version ruby 2.3.7p456 (2018-03-28 revision 63024) [x86_64-linux] #使用2.3 rvm use 2.3 #设为默认 rvm use 2.3 --default #Install and configure the necessary dependencies sudo yum install -y curl policycoreutils-python openssh-server sudo systemctl enable sshd sudo systemctl start sshd sudo firewall-cmd --permanent --add-service=http sudo systemctl reload firewalld #install Postfix to send notification emails sudo yum install postfix sudo systemctl enable postfix sudo systemctl start postfix #Add the GitLab package repository and install the package curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash sudo EXTERNAL_URL=\"http://gitlab.example.com\" yum install -y gitlab-ce #镜像如无法下载，可使用国内清华，阿里镜像 #重配置GitLab sudo gitlab-ctl reconfigure #这里GitLab会安装许多软件，如Nginx，Prometheus，Redis... #首次启动会有很多信息，请稍等 #首次访问GitLab,系统会让你重新设置管理员的密码,设置成功后会返回登录界面.默认的管理员账号是root #在Web界面修改密码 #Browse to the hostname and login #浏览器访问前面定义的URL ##在Web界面修改密码，并登陆 #Set up your communication preferences \r\r配置域名或URL #Configuring the external URL for GitLab vi /etc/gitlab/gitlab.rb external_url \"http://gitlab.example.com\" #重载配置 sudo gitlab-ctl reconfigure #Configuring a relative URL for Gitlab #从v8.17以后便不需要再重新编译 #要求：4GB RAM, and 4 or 8 CPU cores #栗子: https://example.com/gitlab #Enable relative URL in GitLab #如果资源不够，可临时关闭 Unicorn and Sidekiq以节省资源 sudo gitlab-ctl stop unicorn sudo gitlab-ctl stop sidekiq vi /etc/gitlab/gitlab.rb external_url \"https://example.com/gitlab\" #重载配置 sudo gitlab-ctl reconfigure #重新启动服务，以便Unicorn和Sidekiq获取更改 sudo gitlab-ctl restart #Disable relative URL in GitLab external_url后面不包含相对路劲即可 #之后重载配置 sudo gitlab-ctl restart unicorn \r\r从non-root用户载入配置 Loading external configuration fil","date":"2018-12-06","objectID":"/gitlab/:1:1","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"更新 Update 更新方式取决你你使用的安装方法。 不停机升级(Upgrading without downtime) 从GitLab 9.1.0开始便可以非脱机更新，但要遵循一下依赖： You can only upgrade 1 minor release at a time. So from 9.1 to 9.2, not to 9.3. You have to use post-deployment migrations You are using PostgreSQL. If you are using MySQL please look at the release post to see if downtime is required. 更新版本(Upgrading between editions) CE-\u003eEE EE-\u003eCE 杂项(Miscellaneous) MySQL to PostgreSQL Restoring from backup after a failed upgrade Upgrading PostgreSQL Using Slony \r\r\r","date":"2018-12-06","objectID":"/gitlab/:1:2","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"高可用 High Availability: Configure multiple servers for scaling or high availability. GitLab支持多种不同类型的集群和高可用。方案取决于你所依赖的伸缩和可用的级别。最简单的方式是可伸缩，但并不一定是高可用的。 由于Git的分布式特性，即使GitLab不可用，开发人员仍然可以在本地提交代码。 但是，当GitLab关闭时，某些GitLab功能（如issue tracker and Continuous Integration…）不可用。 请记住，所有高可用性解决方案都需要在成本/复杂性和正常运行时间之间进行权衡。想要正常运行的时间越久，则解决方案就越复杂，则设置和维护它的工作就越多。高可用不是免费的，每个高可用方案都应该考虑成本和收益。 \r\r架构 Architecture 有两种配置： active/active active/passive Active/Active 此体系结构可轻松扩展，因为所有应用程序Server可同时处理用户请求。Database、Redis、GitLab都部署在不同的Server上，如果他们配置也是如此，则高度可用。 配置active/active所遵循的步骤： 配置Database 配置Redis 配置NFS 配置GitLab 配置LoadBlancer Active/Passive 对于没有扩展的高可用/故障转移，你可使用Active/Passive。这利用DRBD（Distributed Replicated Block Device）来保持所有数据同步。DRBD要求低延迟链接保持同步。 不建议尝试在数据中心之间或不同的云可用区域中运行DRBD。 至少需要两台机器(one active/one passive)。 \r\r\r","date":"2018-12-06","objectID":"/gitlab/:1:3","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"配置 Configuring GitLab \r配置时区 Adjust your instance’s timezone: Customize the default time zone of GitLab. GitLab默认时区为UTC， vi /etc/gitlab/gitlab.rb # gitlab_rails['time_zone'] = 'UTC' gitlab_rails['time_zone'] = 'Asia/Shanghai' #重载重启 gitlab-ctl reconfigure gitlab-ctl restart #查看时区 gitlab-rake time:zones:all \r\r系统钩子 System hook，Notifications when users, projects and keys are changed. GitLab实例可对以下事件执行HTTP POST请求： project_create project_destroy project_rename project_transfer project_update user_add_to_team user_remove_from_team user_create user_destroy user_failed_login user_rename key_create key_destroy group_create group_destroy group_rename user_add_to_group user_remove_from_group 可以使用系统钩子，如用于记录或更改 LDAP Server 中的信息。 注意： 我们遵循Webhook中对Push和Tag事件的相同结构，但不会显示commit的信息。Webhook的相同弃用在此有效。 \r\rHook请求 Request Header: X-Gitlab-Event: System Hook 项目创建栗子，还有删除、重名、更新、用户、组等其它事件。 { \"created_at\": \"2012-07-21T07:30:54Z\", \"updated_at\": \"2012-07-21T07:38:22Z\", \"event_name\": \"project_create\", \"name\": \"StoreCloud\", \"owner_email\": \"johnsmith@gmail.com\", \"owner_name\": \"John Smith\", \"path\": \"storecloud\", \"path_with_namespace\": \"jsmith/storecloud\", \"project_id\": 74, \"project_visibility\": \"private\" } \r\rTag事件 当向仓库(Repository)创建或删除标记(tag)时触发，它为每个修改过的标记生成一个事件。。 Request header: X-Gitlab-Event: System Hook Request body: { \"event_name\": \"tag_push\", \"before\": \"0000000000000000000000000000000000000000\", \"after\": \"82b3d5ae55f7080f1e6022629cdb57bfae7cccc7\", \"ref\": \"refs/tags/v1.0.0\", \"checkout_sha\": \"5937ac0a7beb003549fc5fd26fc247adbce4a52e\", \"user_id\": 1, \"user_name\": \"John Smith\", \"user_avatar\": \"https://s.gravatar.com/avatar/d4c74594d841139328695756648b6bd6?s=8://s.gravatar.com/avatar/d4c74594d841139328695756648b6bd6?s=80\", \"project_id\": 1, \"project\":{ \"name\":\"Example\", \"description\":\"\", \"web_url\":\"http://example.com/jsmith/example\", \"avatar_url\":null, \"git_ssh_url\":\"git@example.com:jsmith/example.git\", \"git_http_url\":\"http://example.com/jsmith/example.git\", \"namespace\":\"Jsmith\", \"visibility_level\":0, \"path_with_namespace\":\"jsmith/example\", \"default_branch\":\"master\", \"homepage\":\"http://example.com/jsmith/example\", \"url\":\"git@example.com:jsmith/example.git\", \"ssh_url\":\"git@example.com:jsmith/example.git\", \"http_url\":\"http://example.com/jsmith/example.git\" }, \"repository\":{ \"name\": \"Example\", \"url\": \"ssh://git@example.com/jsmith/example.git\", \"description\": \"\", \"homepage\": \"http://example.com/jsmith/example\", \"git_http_url\":\"http://example.com/jsmith/example.git\", \"git_ssh_url\":\"git@example.com:jsmith/example.git\", \"visibility_level\":0 }, \"commits\": [], \"total_commits_count\": 0 } \r\rMerge请求事件 在创建一个新的合并(merge)请求时触发，更新、合并、关闭现有合并请求，或在源分支中添加commit。 Request Header: X-Gitlab-Event: System Hook { \"object_kind\": \"merge_request\", \"user\": { \"name\": \"Administrator\", \"username\": \"root\", \"avatar_url\": \"http://www.gravatar.com/avatar/e64c7d89f26bd1972efa854d13d7dd61?s=80\u0026d=identicon\" }, \"project\": { \"name\": \"Example\", \"description\": \"\", \"web_url\": \"http://example.com/jsmith/example\", \"avatar_url\": null, \"git_ssh_url\": \"git@example.com:jsmith/example.git\", \"git_http_url\": \"http://example.com/jsmith/example.git\", \"namespace\": \"Jsmith\", \"visibility_level\": 0, \"path_with_namespace\": \"jsmith/example\", \"default_branch\": \"master\", \"ci_config_path\": \"\", \"homepage\": \"http://example.com/jsmith/example\", \"url\": \"git@example.com:jsmith/example.git\", \"ssh_url\": \"git@example.com:jsmith/example.git\", \"http_url\": \"http://example.com/jsmith/example.git\" }, \"object_attributes\": { \"id\": 90, \"target_branch\": \"master\", \"source_branch\": \"ms-viewport\", \"source_project_id\": 14, \"author_id\": 51, \"assignee_id\": 6, \"title\": \"MS-Viewport\", \"created_at\": \"2017-09-20T08:31:45.944Z\", \"updated_at\": \"2017-09-28T12:23:42.365Z\", \"milestone_id\": null, \"state\": \"opened\", \"merge_status\": \"unchecked\", \"target_project_id\": 14, \"iid\": 1, \"description\": \"\", \"updated_by_id\": 1, \"merge_error\": null, \"merge_params\": { \"force_remove_source_branch\": \"0\" }, \"merge_when_pipeline_succeeds\": false, \"merge_user_id\": null, \"merge_comm","date":"2018-12-06","objectID":"/gitlab/:1:4","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"维护GitLab Maintaining GitLab \r靶任务 Raketasks: Perform various tasks for maintenance, backups, automatic webhooks setup, etc. \r备份 Backing up and restoring GitLab 应用程序数据备份会创建一个归档文件，其中包含数据库、所有Repository和所有附件。 您只能将备份恢复到与其创建的GitLab完全相同的版本和类型（CE / EE）。将Repository从一个服务器迁移到另一个服务器的最佳方法是通过备份还原。 依赖(requirements) 为了实现备份和还原，需要在系统上安装两个工具。 rsync tar v1.3+ 备份时间戳(Backup timestamp) Note: In GitLab 9.2 the timestamp format was changed from EPOCH_YYYY_MM_DD to EPOCH_YYYY_MM_DD_GitLab_version 备份存档将保存在backup_path中，它在config/gitlab.yml文件中指定。文件名为[TIMESTAMP] _gitlab_backup.tar，其中TIMESTAMP标识每个备份的创建时间以及GitLab版本。如果需要还原GitLab并且有多个备份可用，则需要时间戳。 创建备份(Creating a backup of the GitLab system) GitLab提供了一个简单的命令行接口来备份整个实例。包括： Database Attachments Git repositories data CI/CD job output logs CI/CD job artifacts LFS objects Container Registry images GitLab Pages content 注意：GitLab不会备份配置文件、SSL证书、系统文件。 #omnibus sudo gitlab-rake gitlab:backup:create #source sudo -u git -H bundle exec rake gitlab:backup:create RAILS_ENV=production #docker docker exec -t \u003ccontainer name\u003e gitlab-rake gitlab:backup:create #k8s cluster kubectl exec -it \u003cgitlab task-runner pod\u003e backup-utility #输出栗子 sudo gitlab-rake gitlab:backup:create Dumping database ... Dumping PostgreSQL database gitlabhq_production ... [DONE] done Dumping repositories ... * root/zhangbin-test ... [DONE] [SKIPPED] Wiki * root/test02 ... [SKIPPED] [SKIPPED] Wiki done Dumping uploads ... done Dumping builds ... done Dumping artifacts ... done Dumping pages ... done Dumping lfs objects ... done Dumping container registry images ... [DISABLED] Creating backup archive: 1544578010_2018_12_12_11.5.1_gitlab_backup.tar ... done Uploading backup archive to remote storage ... skipped Deleting tmp directories ... done done done done done done done done Deleting old backups ... skipping #查看 sudo ls /var/opt/gitlab/backups/ 1544578010_2018_12_12_11.5.1_gitlab_backup.tar sudo tar -tvf backups/1544578010_2018_12_12_11.5.1_gitlab_backup.tar drwx------ git/git 0 2018-12-12 09:26 repositories/ drwxr-xr-x git/git 0 2018-12-12 09:26 repositories/root/ -rw-r--r-- git/git 476 2018-12-12 09:26 repositories/root/zhangbin-test.bundle drwxr-xr-x git/git 0 2018-12-12 09:26 repositories/root/zhangbin-test/ drwxr-xr-x git/git 0 2018-12-12 09:26 db/ -rw------- git/git 84875 2018-12-12 09:26 db/database.sql.gz -rw------- git/git 152 2018-12-12 09:26 uploads.tar.gz -rw------- git/git 151 2018-12-12 09:26 builds.tar.gz -rw------- git/git 152 2018-12-12 09:26 artifacts.tar.gz -rw------- git/git 155 2018-12-12 09:26 pages.tar.gz -rw------- git/git 152 2018-12-12 09:26 lfs.tar.gz -rw-r--r-- git/git 190 2018-12-12 09:26 backup_information.yml 保存配置文件(Storing configuration files) Omnibus /etc/gitlab/gitlab-secrets.json /etc/gitlab/gitlab.rb Source /home/git/gitlab/config/secrets.yml /home/git/gitlab/config/gitlab.yml TLS keys and certificates SSH key … 备份选项(Backup options) 备份策略提供了许多可用选项。 备份策略(Backup strategy option) 默认备份策略是使用Linux命令tar和gzip将数据从相应的数据位置流式传输到备份。这在大多数情况下都可以正常工作，但在数据快速变化时会导致问题。 当tar读取数据时数据发生变化，读取文件会发生错误，并导致备份过程失败。为了解决这个问题，v8.17引入了一种名为copy的新备份策略。该策略在调用tar和gzip之前将数据文件复制到临时位置，以避免错误。 副作用(side-effect)是备份过程中占用额外的磁盘空间，该过程尽最大努力在每个阶段清理临时文件，因此问题不会复杂化，但对于大型安装而言，这可能是一个相当大的变化。 #使用 sudo gitlab-rake gitlab:backup:create STRATEGY=copy 从备份中排出特定目录(Excluding specific directories from the backup) db (database) uploads (attachments) repositories (Git repositories data) builds (CI job output logs) artifacts (CI job artifacts) lfs (LFS objects) registry (Container Registry images) pages (Pages content) 你可以使用SKIP环境变量来跳过不需要备份的内容，使用逗号来分隔多个 #栗子 sudo gitlab-rake gitlab:backup:create SKIP=db,uploads 上传到本地挂载来共享(Uploading to locally mounted shares) 你也可以使用Fog Local存储提供程序将备份发送到已挂载的共享(NFS/CIFS/SMB…)。local_root key 指向的目录在挂载时必须由git用户拥有。 除local_root key 外，还必须设置backup_upload_remote_directory，这是已挂载目录中将要复制备份的子目录，如果不存在则将创建。 #Omnibus #vi /etc/gitlab/gitlab.rb gitlab_rails['backup_upload_connection'] = { :provider =\u003e 'Local', :local_root =\u003e '/mnt/backups' } # The directory inside the mounted fol","date":"2018-12-06","objectID":"/gitlab/:1:5","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"更新 Updating GitLab \rGitLab版本和维护策略 GitLab versions and maintenance policy: Understand GitLab versions and releases (Major, Minor, Patch, Security), as well as update recommendations. GitLab releases: Major version: 主要版本，重要内容 Minor verson: 次要版本，小功能 Patch number: 补丁，fix bug Security: 安全，临时添加的安全补丁 #栗子 GitLab v10.5.7 #10 represents major version #5 represents minor version #7 represents patch number 升级建议: GitLab鼓励每个人运行最新的稳定版本(latest stable release)，以确保您可以轻松升级到最安全，功能最丰富的GitLab体验。 如果您无法遵循GitLab的月度发布周期，则需要考虑几种情况： 在一个主要版本(Major)中升级补丁版本(Patch)和次要版本(Minor)被认为是安全的。 #Upgrade the patch version: 8.9.0 -\u003e 8.9.7 8.9.0 -\u003e 8.9.1 #Upgrade the minor version: 8.9.4 -\u003e 8.12.3 9.2.3 -\u003e 9.5.5 升级主要版本需要多加小心。GitLab无法保证主要版本之间的升级是无缝的。 GitLab建议您首先升级到主要版本中的最新可用次要版本。通过执行此操作，您可以解决可能会在下一个主要版本中更改行为的任何弃用消息。 Latest stable version Your version Recommended upgrade path Note 9.4.5 8.13.4 8.13.4 -\u003e 8.17.7 -\u003e 9.4.5 8.17.7 is the last version in version 8 10.1.4 8.13.4 8.13.4 -\u003e 8.17.7 -\u003e 9.5.10 -\u003e 10.1.4 8.17.7 is the last version in version 8, 9.5.10 is the last version in version 9 11.3.4 8.13.4 8.13.4 -\u003e 8.17.7 -\u003e 9.5.10 -\u003e 10.8.7 -\u003e 11.3.4 8.17.7 is the last version in version 8, 9.5.10 is the last version in version 9, 10.8.7 is the last version in version 10 \r\r更新GitLab Update GitLab: Update guides to upgrade your installation to a new version. 根据安装方式与GitLab版本，有多种升级方法： Omnibus packages Source installation Docker installation \r使用软件包的方式进行更新 Updating GitLab installed with the Omnibus GitLab package 特定版本: GitLab 11 GitLab 10 GitLab 8 GitLab 7 GitLab 6 升级方法: 使用官方Repo 手动下载Package 零停机更新(Zero downtime updates) 注意：这仅适用于GitLab 9.1.0或更高版本。 地址: https://docs.gitlab.com/omnibus/update/README.html#zero-downtime-updates 降级(Downgrading): 注意：本指南假定您在要还原的版本下创建了备份存档。 步骤： Download the package of a target version Stop GitLab Install the old package Reconfigure GitLab Restoring the backup Starting GitLab \r\r其它项的更新 MySQL to PostgreSQL PostgreSQL to MySQL 更新失败之后从备份文件进行还原 \r\r\r","date":"2018-12-06","objectID":"/gitlab/:1:6","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"CE-EE Upgrading or downgrading GitLab Upgrade from GitLab CE to GitLab EE Downgrade from GitLab EE to GitLab CE \r\r\r\r","date":"2018-12-06","objectID":"/gitlab/:1:7","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"平台集成 GitLab platform integrations \r","date":"2018-12-06","objectID":"/gitlab/:2:0","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"集成Mattermost Mattermost是一个开源，可托管的聊天服务。它被设计为组织和公司的内部聊天，并且主要将自己作为Slack的替代品。 https://docs.gitlab.com/omnibus/gitlab-mattermost/ \r\r\r","date":"2018-12-06","objectID":"/gitlab/:2:1","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"集成PlantUML PlantUML是一个开源工具，允许用户使用纯文本语言创建UML图表。 https://docs.gitlab.com/ce/administration/integration/plantuml.html \r\r\r","date":"2018-12-06","objectID":"/gitlab/:2:2","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"集成Web终端 从GitLab的CI/CD环境中提供对部署到Kubernetes的应用程序的终端访问。 随着Kubernetes集成的引入，GitLab获得了为Kubernetes集群存储和使用凭证的能力。它使用这些凭据的一个原因是提供对环境的Web终端的访问。 Web终端的体系结构及其工作原理： GitLab依靠用户提供他们自己的Kubernetes凭据，并在部署时适当地标记他们创建的pod。 当用户到环境的终端页面时，它们将被提供一个JavaScript应用程序，该应用程序将WebSocket连接返回给GitLab。 WebSocket在Workhorse中处理，而不是Rails Application Server。 Workhorse查询Rails的连接细节和用户权限; Rails使用Sidekiq在后台查询Kubernetes Workhorse充当用户浏览器和Kubernetes API之间的代理服务器，在两者之间传递WebSocket frame Workhorse定期轮询Rails，如果用户不再具有访问终端的权限，或者连接详细信息已更改，则终止WebSocket连接。 ps: WebSocket是一种在单个TCP连接上进行全双工通信的协议。 启用/禁用终端支持(Enabling and disabling terminal support) 当Web终端使用WebSockets时，Workhorse前面的每个HTTP/HTTPS反向代理都需要配置为将Connection和Upgrade头传递给链中的下一个，在GitLab v8.15+，这是默认选项，不需要你配置。 但是，如果在GitLab前面运行负载均衡器，则可能需要对配置进行一些更改: Apache NGINX HAProxy Varnish Workhorse不会让WebSocket请求通过non-WebSocket端点，因此可以安全地在全局范围内启用对这些Header的支持。如果您宁愿使用较窄的规则集，则可以将其限制为以/terminal.ws结尾的URL。 如果您想在GitLab中禁用Web终端支持，只需停止在链中的第一个HTTP反向代理中传递Connection和Upgrade逐跳Header。对于大多数用户来说，这将是与Omnibus GitLab捆绑在一起的NGINX服务器： #在gitLab.rb中找到 nginx['proxy_set_headers'] #移除或注释 Connection和Upgrade # nginx['proxy_set_headers'] = { # \"Upgrade\" =\u003e \"$http_upgrade\", # \"Connection\" =\u003e \"$connection_upgrade\" 限制Websocket连接时间(Limiting WebSocket connection time) ps: GitLab v8.17+ 终端会话使用长期连接。默认情况下，这些可能永远持续下去。如果从可伸缩性或安全性角度发现这是不受欢迎的，您可以在GitLab实例的Admin区域中配置最长会话时间。 \r\r \r\r","date":"2018-12-06","objectID":"/gitlab/:2:3","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"用户设置和权限 User settings and permissions \r","date":"2018-12-06","objectID":"/gitlab/:3:0","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"Libravatar Use Libravatar instead of Gravatar for user avatars. https://docs.gitlab.com/ce/customization/libravatar.html \r\r\r","date":"2018-12-06","objectID":"/gitlab/:3:1","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"注册限制 Sign-up restrictions: block email addresses of specific domains, or whitelist only specific domains. 您可以通过管理区域中的“应用程序设置”阻止特定域的电子邮件地址，或仅将某些特定域列入白名单。 Whitelist email domains Blacklist email domains 白名单和黑名单支持通配符。 如可对白名单加自己信任的域(如：company.com)，再把所有加入黑名单(如： *) \r\r\r","date":"2018-12-06","objectID":"/gitlab/:3:2","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"访问限制 Access restrictions: Define which Git access protocols can be used to talk to GitLab (SSH, HTTP, HTTPS). 启用Git访问协议 SSH 和 HTTP(s) 仅SSH 仅HTTP(s) \r\r\r","date":"2018-12-06","objectID":"/gitlab/:3:3","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"认证和授权 Authentication/Authorization: Enforce 2FA, configure external authentication with LDAP, SAML, CAS and additional Omniauth providers. https://docs.gitlab.com/ce/topics/authentication/index.html \r\r\r","date":"2018-12-06","objectID":"/gitlab/:3:4","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"传入电子邮件 Incoming email: Configure incoming emails to allow users to reply by email, create issues by email and merge requests by email, and to enable. GitLab有几个基于接收传入电子邮件的功能： Reply by Email: 允许GitLab用户通过回复notification电子邮件对issues发表comment并merge request New issue by email: 允许GitLab用户通过向用户特定的电子邮件地址发送电子邮件来创建新Issue New merge request by email: 允许GitLab用户通过向用户特定的电子邮件地址发送电子邮件来创建新的 merge request 依赖(Requirements)： Email sub-addressing Dedicated email address Catch-all mailbox 配置： #Omnibus #在gitlab.rb中找到incoming_email，启用该功能并填写IMAP信息和账户信息 ### Reply by email ###! Allow users to comment on issues and merge requests by replying to ###! notification emails. ###! Docs: https://docs.gitlab.com/ce/administration/reply_by_email.html # gitlab_rails['incoming_email_enabled'] = true #### Incoming Email Address ####! The email address including the `%{key}` placeholder that will be replaced ####! to reference the item being replied to. ####! **The placeholder can be omitted but if present, it must appear in the ####! \"user\" part of the address (before the `@`).** # gitlab_rails['incoming_email_address'] = \"gitlab-incoming+%{key}@gmail.com\" #### Email account username ####! **With third party providers, this is usually the full email address.** ####! **With self-hosted email servers, this is usually the user part of the ####! email address.** # gitlab_rails['incoming_email_email'] = \"gitlab-incoming@gmail.com\" #### Email account password # gitlab_rails['incoming_email_password'] = \"[REDACTED]\" #### IMAP Settings # gitlab_rails['incoming_email_host'] = \"imap.gmail.com\" # gitlab_rails['incoming_email_port'] = 993 # gitlab_rails['incoming_email_ssl'] = true # gitlab_rails['incoming_email_start_tls'] = false #### Incoming Mailbox Settings ####! The mailbox where incoming mail will end up. Usually \"inbox\". # gitlab_rails['incoming_email_mailbox_name'] = \"inbox\" ####! The IDLE command timeout. # gitlab_rails['incoming_email_idle_timeout'] = 60 #重载配置和重启 sudo gitlab-ctl reconfigure sudo gitlab-ctl restart #验证邮箱配置 sudo gitlab-rake gitlab:incoming_email:check \r\r \r\r","date":"2018-12-06","objectID":"/gitlab/:3:5","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"项目设置 Project settings \r","date":"2018-12-06","objectID":"/gitlab/:4:0","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"Repo检查 Repository checks: Periodic Git repository checks. 在GitLab 8.7中引入。它默认关闭，因为它仍会导致过多的误报。 Git有一个内置机制git fsck，用于验证提交到存储库的所有数据的完整性。GitLab管理员可以通过管理面板下的项目页面触发对项目的检查。检查以异步方式运行，因此可能需要几分钟才能在项目管理页面上显示检查结果。如果检查失败，您可以在repocheck.log下的管理日志页面上看到它们的输出。 定期检查(Periodic checks) 启用后，GitLab会定期对所有项目存储库和wiki存储库运行存储库检查，以检测数据损坏。一个项目每月检查不超过一次。如果任何项目未通过其存储库检查，则所有GitLab管理员都将收到有关该情况的电子邮件通知。\\ 禁用 可在管理员面板上禁用定期检查。 检查失败 如果某个存储库检查失败，你应该在repocheck.log查找错误信息: 管理员面板 磁盘日志文件 /var/log/gitlab/gitlab-rails for Omnibus installations /home/git/gitlab/log for installations from source 如果由于某种原因定期检查导致大量错误警报，您可以在管理员设置里来选择清除所有存储库检查状态。 \r\r\r","date":"2018-12-06","objectID":"/gitlab/:4:1","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"Repo存储路径 Repository storage paths: Manage the paths used to store repositories. GitLab允许您定义多个存储库存储路径，以在多个挂载点之间分配存储负载。 注意: 您必须至少有一个名为default的存储路径 路径以键值对进行定义 目标目录及其任何子路径都不能是符号链接 目标目录不能是制定路径的子目录，因为不能嵌套 #栗子 default: path: /mnt/git-storage-1 storage2: path: /mnt/git-storage-2 #错误栗子 default: path: /mnt/git-storage-1 storage2: path: /mnt/git-storage-1/git-storage-2 # \u003c- NOT OK because of nesting \r\r配置GitLab 注意: 为了使备份正常工作，存储路径不能是挂载点，GitLab用户应具有路径父目录的正确权限。在Omnibus GitLab中，这是自动处理的，但对于Source Code安装，您应该格外小心。 gitlab.rb git_data_dirs({ \"default\" =\u003e { \"path\" =\u003e \"/var/opt/gitlab/git-data\" }, \"nfs\" =\u003e { \"path\" =\u003e \"/mnt/nfs/git-data\" }, \"cephfs\" =\u003e { \"path\" =\u003e \"/mnt/cephfs/git-data\" } }) #Omnibus将存储库数据存储在git-data/repositories子目录下 \r\r选择新项目存储库的存储位置 设置了多个存储路径后，可在Admin下Application Setting选择新项目的存储路径。 从GitLab 8.13.4开始，可以选择多个路径。新项目将随机放置在其中一个选定路径上。 \r\r\r","date":"2018-12-06","objectID":"/gitlab/:4:2","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"Repo存储靶任务 Repository storage rake tasks: A collection of rake tasks to list and migrate existing projects and attachments associated with it from Legacy storage to Hashed storage 以下靶任务(rake task)，可用于帮助您列出现有项目以及与之关联的附件，从旧存储到新的Hashed存储类型。 \r将现有项目迁移到哈希存储 Migrate existing projects to Hashed storage 在迁移现有项目之前，还应为新项目启用哈希/散列存储。 #Omnibus sudo gitlab-rake gitlab:storage:migrate_to_hashed # to migrate any non migrated project from ID 20 to 50. export ID_FROM=20 export ID_TO=50 你可在 Admin \u003e Monitoring \u003e Background jobs里面进行查看。 在它达到零之后，您可以通过运行以下命令来确认已迁移每个项目。如果您认为有必要，可以再次运行此迁移脚本以安排缺少的项目。 \r\r列出旧版存储的项目 List projects on Legacy storage #获取旧项目存储摘要 #Ominibus sudo gitlab-rake gitlab:storage:legacy_projects #列出项目使用的旧存储 #Ominibus sudo gitlab-rake gitlab:storage:list_legacy_projects \r\r列出哈希散列上的项目 List projects on Hashed storage #使用哈希存储的项目的简单摘要 #Ominibus sudo gitlab-rake gitlab:storage:hashed_projects #列出项目使用的散列存储 #Ominibus sudo gitlab-rake gitlab:storage:list_hashed_projects \r\r列出旧版存储上的附件 List attachments on Legacy storage #使用旧版存储的附件的简单摘要 #Ominibus sudo gitlab-rake gitlab:storage:legacy_attachments #列出使用旧版存储的项目附件 #Ominibus sudo gitlab-rake gitlab:storage:list_legacy_attachments \r\r####列出哈希存储上的附件 List attachments on Hashed storage #使用哈希存储的附件的简单摘要 #Ominibus sudo gitlab-rake gitlab:storage:hashed_attachments #列出使用哈希存储的项目附件 #Ominibus sudo gitlab-rake gitlab:storage:list_hashed_attachments \r\r\r","date":"2018-12-06","objectID":"/gitlab/:4:3","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"限制Repo大小 Limit repository size: Set a hard limit for your repositories’ size Introduced in GitLab Enterprise Edition 8.12. GitLab实例中的存储库可能会快速增长，尤其是在使用LFS时。它们的大小可以指数级增长，并且可以非常快速地耗尽您的存储设备。为了避免这种情况发生，您可以为存储库的大小设置硬限制。 可以全局，按组或按项目设置此限制，每个项目限制具有最高优先级。 只有GitLab管理员才能设置这些限制。将限制设置为0表示没有限制。 到目前为止，无法检查新项目的第一次推送的大小，因此第一次推送将允许您上传超过限制规定，但每次后续推送都将被拒绝。但是，LFS对象可以在第一次推送时检查，如果它们的大小总和超过允许的最大存储库大小，则会被拒绝。 \r\r \r\r","date":"2018-12-06","objectID":"/gitlab/:4:4","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"CI GitLab CI/CD Continuous Integration settings \r\r","date":"2018-12-06","objectID":"/gitlab/:5:0","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"Auto DevOps GitLab Auto DevOps: Auto Build Auto Test Auto Code Quality (GitLab Ultimate) Auto SAST (Static Application Security Testing) (GitLab Ultimate) Auto Dependency Scanning (GitLab Ultimate) Auto License Management (GitLab Ultimate) Auto Container Scanning Auto Review Apps Auto DAST (Dynamic Application Security Testing) (GitLab Ultimate) Auto Deploy Auto Browser Performance Testing (GitLab Ultimate) Auto Monitoring \r\r","date":"2018-12-06","objectID":"/gitlab/:5:1","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"MR规范 一些注意事项： 分支情况 生产环境: master 测试环境: test 代码分支: dev 其它分支 分支master, test, dev受到保护 可以根据需要添加受保护的分支 Protected Branch Allowed to MR Allowed to push master Maintainer None test Developer+Maintainer None dev Developer+Maintainer None 合并请求 合并请求有权限控制 开发者发起MR请求时，即触发对MR源分支的相关检测 MR受理者根据检测结果决定是否进行分支合并 运维通过调用检测结果，将分析结果发送给相应的开发人员 MR时请注意是否修改到了CICD相关文件 任何触发的Pipeline，都可以人工终止和重做 构建时，构建过程(STAT, 编译，打包，部署，UT…)可以手动选择关闭，各个过程强依赖 可以接受从任何源分支到任何目的分支的合并请求 CICD相关文件 GitLab根据.gitlab-ci.yml文件触发相应的动作 将CICD所需文件放于cicd目录下 开发者请勿修改CICD相关文件 # CICD需要的文件cicdFile:.gitlab-ci.ymlDockerFile:- Dockerfile-test- Dockerfile-prodk8sFile:- k8s-xxx-test.yaml- k8s-xxx-prod.yaml# 一些忽略文件ignoreFile:- .gitignore- .dockerignore 打包构建 Maven使用云端私有仓库，确保开发环境与Runner的统一 Maven公共基础包可配置为阿里云、华为云仓库等 Node版本会影响项目的运行，所以Node基础镜像的版本与开发者本地保持一致 Docker镜像使用git commit id作为tag k8s yaml配置文件中的镜像tag使用TTTAAAGGG这个唯一字符，在CD时替换成对应的镜像tag k8s yaml文件只应用工作负载(Deployment)，不应用服务(Service)。由于服务基本上不用更改，所以关联的服务一律在容器服务界面上配置 检测 开发者发起MR请求时，即触发对MR源分支的相关检测 运维通过调用检测结果，将分析结果发送给相应的开发人员 dev分支将定时触发Pipeline，并将检查结果发送给相应的开发人员，开发人员可登录Web UI进行查看 持续集成/发布(CI/CD)包含哪些内容 代码检测(STAT) 单元测试(UT) 项目打包(Maven, Node, Go…) Docker构建(build, push) K8s集群 自动化测试(Testing) \r\r","date":"2018-12-06","objectID":"/gitlab/:5:2","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"启用/禁用CICD Enable/disable GitLab CI/CD: Enable or disable GitLab CI/CD for your instance. 您可以在站点范围内禁用GitLab CI/CD，方法是修改配置文件。 有两点需要注意： 禁用GitLab CI/CD只会影响新创建的项目。在此修改之前启用它的项目将像以前一样工作 即使禁用了GitLab CI/CD，用户仍然可以在项目设置中启用它 #Source vim gitlab.yml ## Default project features settings, set build to false default_projects_features: issues: true merge_requests: true wiki: true snippets: false builds: false #Omnibus /etc/gitlab/gitlab.rb gitlab_rails['gitlab_default_projects_features_builds'] = false #重载 sudo gitlab-ctl reconfigure \r\r\r","date":"2018-12-06","objectID":"/gitlab/:5:3","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"CI/CD admin设置 GitLab CI/CD admin settings: Enable or disable DevOps site-wide and define the artifacts’ max size and expiration time. 在以管理员登录GitLab Web UI，在Admin area里面，您将找到Auto DevOps，Runners和job artifacts的设置。 Auto DevOps 要为所有项目启用/禁用 Auto DevOps： 进入Admin area \u003e Settings \u003e Continuous Integration and Deployment 检查Default to Auto DevOps pipeline for all projects 可为Auto DevOps添加基本域 保存更改 从现在开始，每个现有项目和新创建的项目都没有.gitlab-ci.yml，将使用Auto DevOps pipeline。 Maximum artifacts size 可为GitLab实例设置[job artifacts][art-yml]的最大大小。它的单位为MB，默认为每个Job设置为100MB。GitLab.com上它被设置为1GB。 Default artifacts expiration 可为GitLab实例的job artifacts设置默认到期时间。GitLab.com它never expire。 这里面的设置是按Job设置的，可在.gitlab-ci.yml中覆盖它。将其设置为0表示禁用过期，默认单位是秒。 Archive jobs 归档作业通过删除作业的一些功能（运行作业所需的元数据）来减少系统上的CI/CD占用空间，但是为了审计目的而保留跟踪(traces)和工件(artifacts)。 一旦该时间过去，作业将被存档，不再能够重试。让它变空成为永不过期的工作(它必须不少于1天)。 \r\r\r","date":"2018-12-06","objectID":"/gitlab/:5:4","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"Jobs artifacts Job artifacts: Enable, disable, and configure job artifacts (a set of files and directories which are outputted by a job when it completes successfully). Artifacts是在成功完成后附加到作业的文件和目录的列表。此功能在所有的安装中默认启用。 禁用 job artifacts #Omnibus #/etc/gitlab/gitlab.rb gitlab_rails['artifacts_enabled'] = false #重载 存储 job artifacts 成功完成作业后，GitLab Runner将job artifacts的存档上传到GitLab。 使用本地存储 #默认路径 # gitlab_rails['artifacts_path'] = \"/var/opt/gitlab/gitlab-rails/shared/artifacts\" 使用对象存储 Setting Description Default enabled Enable/disable object storage false remote_directory The bucket name where Artifacts will be stored direct_upload Set to true to enable direct upload of Artifacts without the need of local shared storage. Option may be removed once we decide to support only single storage for all files. false background_upload Set to false to disable automatic upload. Option may be removed once upload is direct to S3 true proxy_download Set to true to enable proxying all files served. Option allows to reduce egress traffic as this allows clients to download directly from remote storage instead of proxying all data false connection Various connection options described below - Expiring artifacts 如果工件使用了失效日期，则在该日期过后立即标记为删除。文件由expire_build_artifacts_worker cron job清理，该作业由Sidekiq每小时的第50分钟（50 * * * *）运行。 更改工件过期的默认调度计划： #Omnibus #/etc/gitlab/gitlab.rb gitlab_rails['expire_build_artifacts_worker_cron'] = \"50 * * * *\" #重配 依赖验证(dependencies validation) 要禁用依赖验证，可在Rail Console设置。 #Omnibus #rails console sudo gitlab-rails console #禁用 Feature.enable('ci_disable_validates_dependencies') 实施细节 当GitLab收到工件存档时，GitLab Workhorse也会生成存档元数据文件。此元数据文件描述了工件存档本身中的所有条目。元数据文件采用二进制格式，具有额外的GZIP压缩。 GitLab不解压工件存档以节省Disk，Mem和I/O。它改为检查包含所有相关信息的元数据文件。当存在大量工件或存档是非常大的文件时，这一点尤为重要。 单击特定文件时，GitLab Workhorse会从存档中提取它并开始下载。此实现可节省空间，内存和磁盘I/O. \r\r\r","date":"2018-12-06","objectID":"/gitlab/:5:5","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"Job traces Job traces: Information about the job traces (logs). 作业跟踪由GitLab Runner在处理作业时发送。您可以在job, pipeline, email notification查看工作踪迹。 \r数据流 Data flow 通常，作业踪迹中有两种状态： 实时跟踪(live trace) 存档跟踪(archived trace) Phase State Condition Data flow Stored path 1: patching Live trace When a job is running GitLab Runner =\u003e Unicorn =\u003e file storage #{ROOT_PATH}/builds/#{YYYY_mm}/#{project_id}/#{job_id}.log 2: overwriting Live trace When a job is finished GitLab Runner =\u003e Unicorn =\u003e file storage #{ROOT_PATH}/builds/#{YYYY_mm}/#{project_id}/#{job_id}.log 3: archiving Archived trace After a job is finished Sidekiq moves live trace to artifacts folder #{ROOT_PATH}/shared/artifacts/#{disk_hash}/#{YYYY_mm_dd}/#{job_id}/#{job_artifact_id}/job.log 4: uploading Archived trace After a trace is archived Sidekiq moves archived trace to object storage (if configured) #{bucket_name}/#{disk_hash}/#{YYYY_mm_dd}/#{job_id}/#{job_artifact_id}/job.log \r\r修改工作踪迹本地位置 Changing the job traces local location 更改存储Job Log的位置： #Omnibus #/etc/gitlab/gitlab.rb gitlab_ci['builds_directory'] = '/mnt/to/gitlab-ci/builds' #Source #/home/git/gitlab/config/gitlab.yml gitlab_ci: # The location where build traces are stored (default: builds/). # Relative paths are relative to Rails.root. builds_path: path/to/builds/ \r\r将踪迹上传到对象存储 Uploading traces to object storage 存档的踪迹被视为工作工件。因此，在设置对象存储集成时，作业踪迹会自动与其他作业工件一起迁移到它。 \r\r####　如何归档旧的作业踪迹文件 How to archive legacy job trace files 旧的作业踪迹指的是在GitLab 10.5之前创建的，未定期归档的作业踪迹。那么你可能需要手动进行操作： #执行此任务后，GitLab实例将Sidekiq作业（异步进程）排队，以将作业跟踪文件从本地存储迁移到对象存储。完成所有迁移工作可能需要一些时间。 gitlab-rake gitlab:traces:archive sudo gitlab-rails console #如果计数变为零，则归档过程完成 [1] pry(main)\u003e Sidekiq::Stats.new.queues['pipeline_background:archive_trace'] =\u003e 100 \r\r如何将归档的作业踪迹迁移到对象存储 How to migrate archived job traces to object storage 在GitLab 11.3中引入 如果作业踪迹已存档到本地存储中，并且您希望将这些踪迹迁移到对象存储： 确保已启用Job Artifacts的对象存储集成 执行此命令: gitlab-rake gitlab:traces:migrate \r\r如何删除作业踪迹 How to remove job traces 没有办法自动使旧的作业日志过期，但如果它们占用太多空间，则可以安全地删除它们。如果手动删除日志，则UI中的作业输出将为空。 \r\r新的实时踪迹架构 New live trace architecture 在GitLab 10.4中引入。在GitLab 11.0中宣布的一般可用性。 此功能默认禁用。 这是一个详细的数据流： GitLab Runner picks a job from GitLab GitLab Runner sends a piece of trace to GitLab GitLab appends the data to Redis Once the data in Redis reach 128KB, the data is flushed to a persistent store (object storage or the database). The above steps are repeated until the job is finished. Once the job is finished, GitLab schedules a Sidekiq worker to archive the trace. The Sidekiq worker archives the trace to object storage and cleans up the trace in Redis and a persistent store (object storage or the database) Enabling live trace #console # Omnibus GitLab gitlab-rails console # Installation from source cd /home/git/gitlab sudo -u git -H bin/rails console RAILS_ENV=production #检查实时踪迹 Feature.enabled?('ci_enable_live_trace') #启用 Feature.enable('ci_enable_live_trace') #禁用 Feature.disable('ci_enable_live_trace') 潜在影响(Potential implications) 在某些情况下，将数据存储在Redis上可能会导致数据丢失： Case 1: When all data in Redis are accidentally flushed 可以通过重新发送追踪来恢复实时踪迹。未归档的已完成作业的实时踪迹将丢失踪迹数据的最后一部分。 Case 2: When Sidekiq workers fail to archive 目前，Redis中的所有踪迹数据将在一周后删除。如果Sidekiq Worker无法在过期之前完成，则踪迹数据的一部分将丢失。 可能出现的另一个问题是它可能占用Redis实例上的所有内存 如果作业数为1000，则消耗128MB（128KB*1000）。 \r\r\r","date":"2018-12-06","objectID":"/gitlab/:5:6","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"配置GitLab Runner Configuring GitLab Runners Register Shared and specific Runners: Learn how to register and configure Shared and specific Runners to your own instance. 在GitLab CI中，Runners运行.gitlab-ci.yml中定义的代码。它们是隔离(虚拟)机器，通过GitLab CI的协调器API获取作业。 Runner可以特定于某个项目，也可以为GitLab CI中的任何项目提供服务。为所有项目提供服务的Runner称为shared Runner。 理想情况下，GitLab Runner不应与GitLab安装在同一台机器上。你可以为GitLab实例配置多个Runner。 \r\rRunner的状态 Shared, specific and group Runners 安装Runner后，您可以将其注册为共享的或特定的。如果您具有GitLab实例的管理员访问权限，则只能注册shared Runner。 每个Runner可处于一下状态； shared: Runner runs jobs from all unassigned projects group: Runner runs jobs from all unassigned projects in its group specific: Runner runs jobs from assigned projects locked: Runner cannot be assigned to other projects paused: Runner will not receive any new jobs \r\r注册共享的Runner Registering a shared Runner 如果您是GitLab实例的管理员，则只能注册shared Runner。 在Web UI -\u003e Admin Area -\u003e Runner里面用它提供的URL和Token进行Runner注册。 默认情况下启用shared runner，但可在 Admin Area -\u003e CI/CD里面禁用。 \r\r注册特定的Runner Registering a specific Runner 注册特定的Runner有两种方式： 使用project registration token来注册Runner 将shared Runner 转换为 specific Runner(单向，仅限管理员) 使用项目Token注册特定的Runner： 创建一个没有GitLab实例管理员权限的特定Runner。进入此项目， Setting -\u003e CI/CD -\u003e Runner进行配置。 \r\r注册一个组Runner Registering a group Runner 创建一个group Runner，然后访问词组，Setting -\u003e CI/CD -\u003e Runner。 将共享的Runner特定化(Making an existing shared Runner specific) 如果您是GitLab实例的管理员，则可以将任何shared Runner转换为specific Runner。请记住，这是一种单向转换，不能逆向转换。 Admin Ares -\u003e Overview -\u003e Runner -\u003e 需要的Runner 对项目启用Restrict projects for this Runner 这样，shared Runner便特定于某些项目。 之后此Runner的状态便发生了改变。 \r\r锁定特定Runner Locking a specific Runner from being enabled for other projects 您可以配置Runner以将其专门分配给一个项目。当Runner以这种方式锁定时，不能再为其他项目启用它。 Visit your project’s Settings \u003e CI/CD Find the Runner you wish to lock/unlock and make sure it’s enabled Click the pencil button Check the Lock to current projects option Click Save changes for the changes to take effect \r\r将Runner分配给另外的项目 Assigning a Runner to another project 如果您是分配了特定Runner的项目的维护人员，并且Runner未仅锁定到该项目(not locked only to that project)，则还可以在具有Maintainer权限的任何其他项目上启用Runner。 请注意，如果您没有将特定的Runner锁定到特定项目，那么您项目中具有Maintainer角色的任何用户都可以将Runner分配给另一个任意项目，而无需您的授权，因此请谨慎使用。 启用： Visit your project’s Settings \u003e CI/CD Find the Runner you wish to enable/disable Click Enable for this project or Disable for this project 管理员可以为项目启用/禁用特定的Runner： Navigate to Admin \u003e Runners Find the Runner you wish to enable/disable Click edit on the Runner Click Enable or Disable on the project \r\r受保护的Runner Protected Runners 在GitLab 10.0中引入。 你可以保护Runner免于泄露敏感信息。每当Runner受到保护时，Runner仅选择在受保护的分支或受保护的标签上创建的作业，并忽略其他作业。 protect/unprotect: Visit your project’s Settings \u003e CI/CD Find a Runner you want to protect/unprotect and make sure it’s enabled Click the pencil button besides the Runner name Check the Protected option Click Save changes for the changes to take effect \r\r手动清理Runner缓存 Manually clearing the Runners cache Navigate to your project’s CI/CD \u003e Pipelines page. Click on the Clear Runner caches button to clean up the cache. On the next push, your CI/CD job will use a new cache. \r\r共享Runner如何选择作业 How shared Runners pick jobs 共享的Runner遵守我们称之为合理使用的进程队列(process queue)。公平的使用算法尝试从当前在shared Runners上运行的作业数量最少的项目中将作业分配给shared Runners。 \r\r有效地使用共享Runner Using shared Runners effectively 如果您打算使用共享的Runners，您应该记住几件事。 使用tags 您必须设置一个Runner才能运行所有不同类型的作业，它可能会在共享的项目中遇到。如果不使用tags，则对于大型项目可能会出现问题。 通过为Runner打tag来标记它可以处理的作业类型，您可以确保shared Runners只运行它们配备的作业(only run the jobs they are equipped to run)。 例如，在GitLab中，如果Runners包含运行Rails测试套件的相应依赖项，那么我们将Runners标记为“rails” Preventing Runners with tags from picking jobs without tags 您可以配置Runner以防止在Runner没有分配tag时使用tag选择作业。 Runner pick tagged/untagged jobs: Visit your project’s Settings ➔ CI/CD Find the Runner you wish and make sure it’s enabled Click the pencil button Check the Run untagged jobs option Click Save changes for the changes to take effect 为Runner设置做大作业超时 对于每个Runner，您可以指定最大作业超时时间。如果小于项目定义的超时，则此类超时将优先。 小心敏感信息 对于一些Runner Executors，如果您可以在Runner上运行作业，您就可以访问它运行的任何代码并获取Runner的Toke","date":"2018-12-06","objectID":"/gitlab/:5:7","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"Auto DevOps Enable/disable Auto DevOps: Enable or disable Auto DevOps for your instance 在GitLab 10.0中引入。一般在GitLab 11.0上可用。 Auto DevOps提供预定义的CI/CD配置，允许您自动检测(detect)，构建(build)，测试(test)，部署(deploy)和监控(monitor)应用程序。利用CI/CD最佳实践和工具，Auto DevOps旨在简化成熟和现代软件开发生命周期的设置和执行。 \r综述 从GitLab v11.3开始，默认情况下为所有项目启用Auto DevOps pipeline。如果尚未为项目显式启用，则会在第一个管道故障时自动禁用Auto DevOps。如果找到一个，您的项目将继续使用备用CI/CD配置文件。 借助Auto DevOps，软件开发过程变得更容易设置，因为每个项目都可以拥有从验证到监控的完整工作流程，并且配置最少。只需推送您的代码，GitLab就会处理其他所有事情。这样可以更轻松地启动新项目，并使整个公司的应用程序设置更加一致。 \r\r与应用程序平台和PaaS相比较 Comparison to application platforms and PaaS Auto DevOps提供通常包含在应用程序平台或PaaS的功能。它有多个灵感： Auto DevOps适用于任何k8s集群;你不仅限于在GitLab的基础设施上运行。 没有额外成本，你可在任何公共云上使用自托管的k8s集群。 Auto DevOps包括了安全测试，性能测试和代码质量测试等众多功能。 Auto DevOps提供增量分级路径。如果您需要高级自定义，则可以开始修改模板，而无需在完全不同的平台上重新开始。 \r\r特性 特性(Features): Auto Build Auto Test Auto Code Quality Auto SAST (Static Application Security Testing) Auto Dependency Scanning Auto License Management Auto Container Scanning Auto Review Apps Auto DAST (Dynamic Application Security Testing) Auto Deploy Auto Browser Performance Testing Auto Monitoring 由于Auto DevOps依赖于许多不同的组件，因此最好具备以下基本知识： Kubernetes Helm Docker GitLab Runner Prometheus Auto DevOps为所有阶段提供了很好的默认值;但是，您可以根据需要自定义几乎所有内容。 \r\r依赖 Requirements 要充分利用Auto DevOps，您需要: GitLab Runner(所有阶段都需要) Runner需要配置为能够运行Docker(通常，这意味着使用Docker或Kubernetes executor，并启用特权模式)。Runner不需要安装在k8s集群中，但k8s executor易于使用并且可以自动进行自动伸缩。基于Docker的Runner也可以使用Docker Machine配置为自动伸缩。应将Runners注册为整个GitLab实例的shared Runners，或分配给特定项目的specific Runner。 Base domain(自动审阅和自动部署所需) 您将需要一个配置了通配符DNS的域，该域将由您的所有Auto DevOps应用程序使用。 K8s(自动审阅、自动部署和自动监控所需) 要启用部署，您需要k8s v1.5+。您需要项目的Kubernetes集群，或整个GitLab安装的Kubernetes默认服务模板。 负载均衡器——您可以使用nginx-ingress Helm Chart将NGINX Ingress部署到Kubernetes集群，从而使用NGINX ingress。 Prometheus(自动监控所需) 要启用自动监控，您需要在某处（集群内部或外部）安装Prometheus并配置为刮取您的Kubernetes集群。要获得除系统指标外的响应指标(Metrics)，您还需要配置Prometheus。 注意： 如果您没有安装Kubernetes或Prometheus，则将自动跳过自动审阅，自动部署和自动监控。 \r\r自动化运维基本域 Auto DevOps base domain 如果要使用自动审阅和自动部署，则需要启用Auto DevOps base domain。它可在三个地方定义： 在项目下的CI/CD 在Admin Area -\u003e Setting -\u003e CI/CD 在项目下配置变量: AUTO_DEVOPS_DOMAIN 在组级别配置变量: AUTO_DEVOPS_DOMAIN 需要一个与基本域匹配的通配符DNS A记录，如: *.example.com 3600 A 1.2.3.4 #在这种情况下，`example.com`是用于部署应用程序的域名，`1.2.3.4`是负载均衡器的IP地址(通常是NGINX)。如何设置DNS记录超出了本文档的范围;您应该咨询您的DNS提供商。 #设置完成后，所有请求都会到达负载均衡器，然后负载均衡器会将它们路由到运行应用程序的Kubernetes pod \r\r使用多个k8s集群 Using multiple Kubernetes clusters 使用Auto DevOps时，您可能希望将不同的环境部署到不同的Kubernetes集群。 在Auto DevOps template中，您需要知道3个已定义的环境名称： review/ (从review/开始每个环境) staging production 这些环境与使用自动部署的作业相关联，因此除了环境范围之外，它们还需要具有部署到的不同域。这就是您需要根据环境为上述所有内容定义单独的AUTO_DEVOPS_DOMAIN变量的原因。 下表是如何配置三个不同群集的示例: 集群名 集群环境范围 AUTO_DEVOPS_DOMAIN变量值 环境变量范围 备注 review review/* review.example.com review/* The review cluster which will run all Review Apps. * is a wildcard, which means it will be used by every environment name starting with review/. staging staging staging.example.com staging (Optional) The staging cluster which will run the deployments of the staging environments. You need to enable it first. production production example.com production The production cluster which will run the deployments of the production environment. You can use incremental rollouts. 要为每个环境添加不同的群集： 项目的Operations -\u003e Kubernetes并使用各自的环境范围创建Kubernetes集群，如上表所述 创建群集后，到每个群集并安装Helm Tiller和Ingress 确保已使用指定的自动化运维域配置DNS 到项目的Settings -\u003e CI/CD -\u003e Variables，添加AUTO_DEVOPS_DOMAIN变量及其各自的环境范围。 注意： 具有多个群集的组不支持自动DevOps，因为无法在组级别上为每个环境设置AUTO_DEVOPS_DOMAIN。 \r\r启用/禁用Auto DevOps 首次使用Auto Devops时，请查看要求以确保可以使用所有必要的组件来充分利用Auto DevOps。 在实例级别启用/禁用Auto DevOps（仅限管理员） Admin area -\u003e Settings -\u003e Continuous Integration and Deployment Default to Auto DevOps pipeline for all projects base domain 在项目级别启用/禁用 Auto DevOps project’s Settings -\u003e CI/CD -\u003e Auto DevOps Default to Auto DevOps pipeline Domain Deployment strategy 部署策略(Deployment strategy) Introduced in GitLab 11.0 你可以更改项目的部署策略。有三种策略: Continuous deployment to production: 允许master分支启用Auto Deploy来直接部署到生产环境 Continuous deployment to production using timed incremental rollout: 将INCREMENTAL_ROLLOU","date":"2018-12-06","objectID":"/gitlab/:5:8","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"Auto DevOps template 各种模板: https://gitlab.com/gitlab-org/gitlab-ce/tree/master/lib/gitlab/ci/templates 在项目也可选择新建.gitlab-ci.yml模板文件，然后根据需要就行适当的修改。 \r\r\r","date":"2018-12-06","objectID":"/gitlab/:5:9","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"CI/CD环境变量 CI/CD Variables - Learn how to use variables defined in your .gitlab-ci.yml or the ones defined in your project’s settings 当从GitLab CI接收作业时，Runner准备构建环境。首先，设置预定义变量列表predefined variables（环境变量）和用户定义变量列表user-defined variables。 \r\r变量优先级 Priority of variables 变量可以被覆盖，并且它们按此顺序优先于彼此： Trigger variables / scheduled pipeline variables Project-level variables / protected variables Group-level variables / protected variables YAML-defined job-level variables YAML-defined global variables Deployment variables Predefined variables \r\r不支持的变量 在某些情况下，某些变量无法在.gitlab-ci.yml定义的上下文中使用——如在script下定义的变量。 \r\r预定义变量 Predefined variables (Environment variables) 注意： 从GitLab 9.0开始，我们已经弃用了一些变量。阅读9.0重命名部分以找出它们的替代品。强烈建议您使用新变量，因为我们将在以后的GitLab版本中删除旧变量。 Variable GitLab Runner Description ARTIFACT_DOWNLOAD_ATTEMPTS 8.15 1.9 Number of attempts to download artifacts running a job CI all 0.4 Mark that job is executed in CI environment CI_COMMIT_BEFORE_SHA 11.2 all The previous latest commit present on a branch before a push request. CI_COMMIT_DESCRIPTION 10.8 all The description of the commit: the message without first line, if the title is shorter than 100 characters; full message in other case. CI_COMMIT_MESSAGE 10.8 all The full commit message. CI_COMMIT_REF_NAME 9.0 all The branch or tag name for which project is built CI_COMMIT_REF_SLUG 9.0 all $CI_COMMIT_REF_NAME lowercased, shortened to 63 bytes, and with everything except 0-9 and a-z replaced with -. No leading / trailing -. Use in URLs, host names and domain names. CI_COMMIT_SHA 9.0 all The commit revision for which project is built CI_COMMIT_SHORT_SHA 11.7 all The first eight characters of CI_COMMIT_SHA CI_COMMIT_TAG 9.0 0.5 The commit tag name. Present only when building tags. CI_COMMIT_TITLE 10.8 all The title of the commit - the full first line of the message CI_CONFIG_PATH 9.4 0.5 The path to CI config file. Defaults to .gitlab-ci.yml CI_DEBUG_TRACE all 1.7 Whether debug tracing is enabled CI_DEPLOY_PASSWORD 10.8 all Authentication password of the GitLab Deploy Token, only present if the Project has one related. CI_DEPLOY_USER 10.8 all Authentication username of the GitLab Deploy Token, only present if the Project has one related. CI_DISPOSABLE_ENVIRONMENT all 10.1 Marks that the job is executed in a disposable environment (something that is created only for this job and disposed of/destroyed after the execution - all executors except shell and ssh). If the environment is disposable, it is set to true, otherwise it is not defined at all. CI_ENVIRONMENT_NAME 8.15 all The name of the environment for this job CI_ENVIRONMENT_SLUG 8.15 all A simplified version of the environment name, suitable for inclusion in DNS, URLs, Kubernetes labels, etc. CI_ENVIRONMENT_URL 9.3 all The URL of the environment for this job CI_JOB_ID 9.0 all The unique id of the current job that GitLab CI uses internally CI_JOB_MANUAL 8.12 all The flag to indicate that job was manually started CI_JOB_NAME 9.0 0.5 The name of the job as defined in .gitlab-ci.yml CI_JOB_STAGE 9.0 0.5 The name of the stage as defined in .gitlab-ci.yml CI_JOB_TOKEN 9.0 1.2 Token used for authenticating with the GitLab Container Registry and downloading dependent repositories CI_JOB_URL 11.1 0.5 Job details URL CI_MERGE_REQUEST_ID 11.6 all The ID of the merge request if it’s pipelines for merge requests CI_MERGE_REQUEST_IID 11.6 all The IID of the merge request if it’s pipelines for merge requests CI_MERGE_REQUEST_PROJECT_ID 11.6 all The ID of the project of the merge request if it’s pipelines for merge requests CI_MERGE_REQUEST_PROJECT_PATH 11.6 all The path of the project of the merge request if it’s pipelines for merge requests (e.g. namespace/awesome-project) CI_MERGE_REQUEST_PROJECT_URL 11.6 all The URL of the project of the merge request if it’s pipelines for merge requests (e.g. http://192.168.10.15:3000/namespace/awesome-project) CI_MERGE_REQUEST_REF_PATH 11.6 all The ref path of the merge request if it’s pipelines for merge requests. (e.g. refs","date":"2018-12-06","objectID":"/gitlab/:5:10","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":".gitlab-ci.yml配置 使用.gitlab-ci.yml配置你的Jobs，该文件是GitLab Runner用来管理项目作业的文件。 \rJobs YAML文件定义了一组具有约束的作业，说明应该何时运行它们。您可以指定无限数量的作业，这些作业被定义为具有任意名称的顶级元素，并且始终必须至少包含script子句。 可以是直接运行命令，也可以写成xxx.sh脚本，然后执行此脚本。 #两个单独的作业，执行各自的命令job1:script:\"execute-script-for-job1\"job2:script:\"execute-script-for-job2\" Runner选择Job并在Runner的环境中执行。重要的是，每项工作都是相互独立运作的，这里可对比Jenkins里面的workspace。 每个作业必须具有唯一的名称，但有一些**保留的关键字(keywords)**不能用作作业名称: image services stages types before_script after_script variables cache 作业由定义作业行为的参数列表定义: Keyword Required Description script yes Defines a shell script which is executed by Runner extends no Defines a configuration entry that this job is going to inherit from image no Use docker image, covered in Using Docker Images services no Use docker services, covered in Using Docker Images stage no Defines a job stage (default: test) type no Alias for stage variables no Define job variables on a job level only no Defines a list of git refs for which job is created except no Defines a list of git refs for which job is not created tags no Defines a list of tags which are used to select Runner allow_failure no Allow job to fail. Failed job doesn’t contribute to commit status when no Define when to run job. Can be on_success, on_failure, always or `manual dependencies no Define other jobs that a job depends on so that you can pass artifacts between them artifacts no Define list of job artifacts cache no Define list of files that should be cached between subsequent runs before_script no Override a set of commands that are executed before job after_script no Override a set of commands that are executed after job environment no Defines a name of environment to which deployment is done by this job coverage no Define code coverage settings for a given job retry no Define when and how many times a job can be auto-retried in case of a failure parallel no Defines how many instances of a job should be run in parallel \r\rextends extends定义了一个使用extends的作业将继承的条目名称。 这是使用YAML锚点(anchor)的替代方案，并且更加灵活和可读： .tests:script:rake teststage:testonly:refs:- branchesrspec:extends:.testsscript:rake rspeconly:variables:- $RSPEC 在上面的示例中，rspec作业继承自.tests模板作业。GitLab将根据键执行反向深度合并。GitLab将: 将rspec内容以递归方式合并到.tests中 Not merge the values of the keys 这导致以下rspec作业: #注意，script: rake test将被script: rake rspec覆盖rspec:script:rake rspecstage:testonly:refs:- branchesvariables:- $RSPEC 如果想要包含rake test, 请查看before_script-and-after_script. extends支持多级继承，但不建议使用三级以上。支持的最大嵌套级别为10。 一下栗子具有两级继承: .tests:only:- pushes.rspec:extends:.testsscript:rake rspecrspec 1:variables:RSPEC_SUITE:'1'extends:.rspecrspec 2:variables:RSPEC_SUITE:'2'extends:.rspecspinach:extends:.testsscript:rake spinach \r\rpages pages是一项特殊工作，用于将静态内容上传到GitLab，可用于为您的网站提供服务。它有一个特殊的语法，因此必须满足以下两个要求： 任何静态内容都必须放在public/目录下 须定义具有public/目录路径的artifacts pages:stage:deployscript:- mkdir .public- cp -r * .public- mv .public publicartifacts:paths:- publiconly:- master 更多详细信息请参考GitLab Pages。 \r\rimage and services 这允许指定自定义Docker镜像和可用于作业时间的服务列表。 \r\rbefore_script and after_script before_script用于定义应在所有作业（包括部署作业）之前，在恢复工件(artifacts)之后，运行的命令；这可以是数组或多行字符串。 after_script用于定义将在所有作业（包括失败的作业）之后运行的命令。这必须是数组或多行字符串。 before_script和main script连接在一个上下文/容器中运行。after_script是单独运行的，因此根据执行程序，在工作树之外完成的更改可能不可见。 如果在每个工作中定义了before_script和after_script，则可以覆盖全局定义： before_script:- global before scriptjob:before_script:- execute this instead of global before scriptscript:- my commandafter_script:- execute this after my script \r\rstages stages用于在全局范围定义可由作业使用的阶段。 stages规范允许具有灵活的多级阶段管道(multi stage pipeline)。stages元素的排序定义了作业执行的顺序: 同一阶段的作业是并行运行的 下一阶段的作业在上一阶段的作业成功完成之后运行 让我们考虑以下示例，它定义了3个阶段： stages:- build- test- deploy#首先，build阶段的所有作业都是并行执行的#如果build阶段的所有作业都成功，则test阶段的作业将并行执行#如果test阶段的所有作业都成功，则deploy阶段的作业将并行执行#如果deploy阶段的所有作业都成功，则commit将被标记为passwd#如果任何先前的作业失败，则commit被标记为failed，并且不执行其他阶段的作业 有两个边缘案例值得注意： 如果在.gitlab-ci.yml文件中没有定义stages，build、test和deploy用作默认情况允许的作业阶段； 如果作业未指定stage，则为作业分配test阶段 \r\rstage stage是按工作定义的，依赖于全局定义的stages。它允许将作业分组到不同的阶段，并且同一阶段的作业并行执行: stages:- build- test- deployjob 1:stage:buil","date":"2018-12-06","objectID":"/gitlab/:5:11","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"Pipelines for MR Pipelines for merge requests Note: 从GitLab v11.10开始，由于recent refspecs changes，Pipeline for merge requests需要GitLab Runner v11.9+。任何较低版本将导致Pipeline失败。 Introduced in GitLab 11.6. 通常，在创建新的合并请求(MR)时，管道(pipeline)会使用新的更改运行，并检查它是否有资格合并到目标分支中。此管道仅包含用于验证新更改的必要作业。例如，在此周期中使用单元测试… 使用合并请求的管道，你可以在合并请求中运行管道时设计特定的管道结构。这可能是添加或删除管道中的步骤，以确保管道尽可能高效。 \r\r为MR配置管道 Configuring pipelines for merge requests 要为合并请求配置管道，请将only: merge_requests参数添加到要仅为合并请求运行的作业。 然后，当开发人员每次创建或更新合并请求时，每次将提交推送到GitLab时都会运行管道。 Note: If you use this feature with merge when pipeline succeeds, pipelines for merge requests take precedence over the other regular pipelines. 栗子.gitlab-ci.yml： build:stage:buildscript:./buildonly:- mastertest:stage:testscript:./testonly:- merge_requests# multi conditions# only:# - test# - merge_requests# - tags# only默认是或操作，上面三个条件即是 test OR merge_requests OR tags# 下面介绍如何使用不并操作# only:# - test \u0026\u0026 tags# - test AND $name == 'bingo'# - test AND NOT $name == 'zhang'deploy:stage:deployscript:./deployonly:- master 使用新提交(commit)更新合并请求后： GitLab检测到已发生更改并为合并请求创建新管道 管道从源分支获取(fetch)最新代码并对其进行测试 Pipelines tagged with the detached badge indicate that they were triggered when a merge request was created or updated. \r\rPipelines for Merged Results Introduced in GitLab Premium 11.10. This feature is disabled by default until we resolve issues with contention handling, but can be enabled manually. 商业版的功能，此处不介绍。 \r\rMerge when pipeline succeeds 查看准备合并但仍有一个或多个CI作业运行的合并请求时，可以将其设置为在作业管道成功时自动合并(merged automatically)。这样，你不必等待作业完成，并记住去手动合并请求。 \r如何工作 当您点击**管道成功时合并(Merge When Pipeline Succeeds)**按钮时，将更新合并请求的状态以表示即将发生的合并。如果你无法等待管道成功并希望立即合并，则可以在配置中启用此选项。 开发者和MR发起者都可以选择取消自动合并，如果他们找到了不应该自动合并的原因。 管道成功后，合并请求将自动合并。当管道发生故障时，MR作者有机会重试任何失败的作业，或推送新的提交来修复失败。 在第二次尝试作业并成功时，合并请求将自动合并。使用新提交更新合并请求时，将自动取消自动合并以允许检查新更改。 \r\rOnly allow MR to be merged if the pipeline succeeds 如果合并请求的管道未成功或有待解决的问题，则可以阻止合并请求的合并。 在项目-\u003e设置-\u003e通用-\u003e合并请求-\u003eMerge checks中，选择Pipelines must succeed，单击保存以生效。 现在开始，每个管道发生故障时，你都无法合并Web UI中的合并请求，知道你通过所有相关的作业为止。 \r\r\r","date":"2018-12-06","objectID":"/gitlab/:5:12","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"Scheduling Pipelines 我们也可以使用定时任务的方式来触发Pipeline。在项目-\u003eCI/CD-\u003e计划(Sheduling)里面配置流水线计划，来定时运行Pipeline。 \r\r\r","date":"2018-12-06","objectID":"/gitlab/:5:13","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"在GitLab CI中使用git submodules Using Git submodules with GitLab CI 注意： GitLab 8.12 introduced a new CI job permissions model and you are encouraged to upgrade your GitLab instance if you haven’t done already. If you are not using GitLab 8.12 or higher, you would need to work your way around submodules in order to access the sources of e.g., gitlab.com/group/project with the use of SSH keys. With GitLab 8.12 onward, your permissions are used to evaluate what a CI job can access. More information about how this system works can be found in the Jobs permissions model.（CI jobs 默认有权限拉取所有项目） The HTTP(S) Git protocol must be enabled in your GitLab instance. \r好像之前需要先关联子模块，否则GitLab里面的.gitmodules它不生效。这个在你配置的时候先不做，如果不生效再来坐这一步。 # project 关联 project-01 git submodule add git@git.xxx.com/groupB/project-01.git \r\r配置.gitmodules文件 如果要处理Git submodules，你的项目需要一个名为.gitmodules的文件。 如果你使用GitLab v8.12+，并且你的子模块也位于同一GitLab Server上，则必须更新.gitmodules文件以使用relative URLs。由于Git允许使用.gitmodules配置相对URL，因此你可以轻松使用HTTP(S)克隆所有CI作业，并使用SSH进行所有本地checkout。 项目在同一个GitLab Server的.gitmodules示例： [submodule \"project-01\"] path = project-01 url = ../groupB/project-01.git branch = test [submodule \"project-02\"] path = project-02 url = ../project-02.git branch = master 上述配置将指示Git自动推断克隆源时应使用的URL。 对于不在同一GitLab Server上的其它子模块，请使用完整的HTTP(S)协议的URL： [submodule \"project-x\"] path = project-x url = https://gitserver.com/group/project-x.git branch = master 一旦正确配置了.gitmodules，你就可以去配置.gitlab-ci.yml。 \r\r在CI中使用git submodules 首先，确保你已使用位于同一GitLab Server中的子模块的相对URL 如果你使用GitLab Runner v1.10+，你可将GIT_SUBMODULE_STRATEGY变量设置为normal或recursive，以告知Runner在作业之前获取子模块 variables:GIT_SUBMODULE_STRATEGY:recursivebefore_script:- git submodule sync --recursive- git submodule update --init --recursive --remote#- git submodule update --init --recursive# 如果你使用旧版本的GitLab Runner，使用 git submodule sync/update# --recursive should be used in either both or none (sync/update) depending on whether you have recursive submodules# - git submodule sync/update 在before_script中设置同步和更新的基本原理是由于Git子模块的工作方式。在新的Runner Workspace中，Git将根据.gitmodules和当前远程URL设置.git/config中包含子模块的URL。 cat .git/config [core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true [remote \"origin\"] url = git@git.xxx.com:groubA/test/project.git fetch = +refs/heads/*:refs/remotes/origin/* [branch \"master\"] remote = origin merge = refs/heads/master [submodule \"project-01\"] url = git@git.xxx.com:groupB/project-01.git 这里面显示的是子模块的完整URL。 最后，在GitLab Web UI中看一下显示效果。 \r\r\r","date":"2018-12-06","objectID":"/gitlab/:5:14","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"GitLab CI/CD栗子 各种语言、框架 、操作系统 CI/CD栗子: https://docs.gitlab.com/ce/ci/examples/README.html PHP Ruby Python Java Scala Clojure Elixir IOS and MacOS Android Debian Maven \r\r \r\r","date":"2018-12-06","objectID":"/gitlab/:5:15","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"Git配置项 Git configuration options \r","date":"2018-12-06","objectID":"/gitlab/:6:0","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"自定Git hooks Custom Git hooks: Custom Git hooks (on the filesystem) for when webhooks aren’t enough 注意：必须在GitLab服务器的文件系统上配置自定义Git hooks。只有GitLab服务器管理员才能完成这些任务。 Git本身支持在不同操作上执行的hooks。服务器端git hooks的示例包括预接收，后接收和更新。从gitlab-shell 2.2.0版（需要GitLab 7.5+）开始，GitLab管理员可以为任何GitLab项目添加自定义git hooks。 \r\r配置 通常，Githooks放在存储库或项目的hooks目录中。 GitLab从每个项目的hooks目录创建一个符号链接到gitlab-shell hooks目录，以便于gitlab-shell升级之间的维护。因此，自定义挂钩的实现方式略有不同。但是，一旦创建了钩子，行为就完全相同了。 请按照以下步骤设置自定义hooks： 选择一个需要自定义Git hook的项目 在GitLab Server，导航到项目的存储库目录(如: /var/opt/gitlab/git-data/repositories/user/xx.git) 此位置创建名为custom_hooks的新目录 在custom_hooks目录中，创建一个名称与hook类型匹配的文件(如: pre-hook) 修改hook文件属主为git，添加可执行权限 编写代码以使Git hook函数按预期方式运行，可以是任何语言。确保顶部的shebang(#!/bin/python3)正确反映语言类型 假设正确实现了hook代码，hook将适当地触发。 \r\r链式hook Chained hooks support 在GitLab Shell 4.1.0和GitLab 8.15中引入 hook也可以放在hook/\u003chook_name\u003e.d（全局）或custom_hooks/\u003chook_name\u003e.d（每个项目）目录中，支持钩子的链式执行。 注意：\u003chook_name\u003e.d需要pre-receive.d，post-receive.d或update.d才能正常工作。任何其他名称都将被忽略 要查看全局自定义hook（hook/\u003chook_name.d\u003e）中的不同目录，请在gitlab-shell config中设置custom_hooks_dir。对于Omnibus安装，可在gitlab.rb中设置。 按以下顺序搜索并执行hook： gitlab-shell/hooks directory as known to Gitaly \u003cproject\u003e.git/hooks/\u003chook_name\u003e - executed by git itself, this is gitlab-shell/hooks/\u003chook_name\u003e \u003cproject\u003e.git/custom_hooks/\u003chook_name\u003e - per project hook \u003cproject\u003e.git/custom_hooks/\u003chook_name\u003e.d/* - per project hooks \u003cproject\u003e.git/hooks/\u003chook_name\u003e.d/* OR \u003ccustom_hooks_dir\u003e/\u003chook_name.d\u003e/* - global hooks: all executable files \r\r自定义错误信息 Custom error messages 在GitLab 8.10中引入 如果commit被拒绝或在Git hook检查期间发生错误，则钩子的STDERR或STDOUT消息将出现在GitLab的UI中，STDERR优先于STDOUT。 \r\r\r","date":"2018-12-06","objectID":"/gitlab/:6:1","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"Git LFS Git LFS: https://docs.gitlab.com/ce/workflow/lfs/manage_large_binaries_with_git_lfs.html Git LFS config: https://docs.gitlab.com/ce/workflow/lfs/lfs_administration.html 管理音频，视频和图形文件等大文件一直是Git的缺点之一。一般建议是不要让Git存储库大于1GB以保持性能。 \r\r\r","date":"2018-12-06","objectID":"/gitlab/:6:2","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"Housekeeping Housekeeping(管家): Keep your Git repositories tidy and fast 在GitLab 8.4中引入 \rAutomatic housekeeping 在Git push后，GitLab会自动在存储库上运行git gc和git repack命令。如果需要，您可以更改这种情况发生的频率，或者将其关闭。在Admin ares -\u003e Setting \r\rManual housekeeping housekeeping功能将运行gc还是repack，取决于你的设置。 \r\r\r","date":"2018-12-06","objectID":"/gitlab/:6:3","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"Git协议 Configuring Git Protocol v2: Git protocol version 2 support 在GitLab 11.4中引入 Git第二版协议以多种方式改进了第一版协议，并且在GitLab中默认为HTTP请求启用。要为SSH启用，管理员需要进一步配置。 Requirements： 客户端，git v2.18.0+ 服务端，如果要配置SSH，需要设置sshd以接受GIT_PROTOCOL环境变量 #/etc/ssh/sshd_config AcceptEnv GIT_PROTOCOL sudo service ssh restart #配置新协议 #局部 git -c protocol.version=2 #全局 git config --global protocol.version 2 #验证 #HTTP #C端 GIT_TRACE_CURL=1 git -c protocol.version=2 ls-remote https://your-gitlab-instance.com/group/repo.git 2\u003e\u00261 | grep Git-Protocol #S端 GIT_TRACE_PACKET=1 git -c protocol.version=2 ls-remote https://your-gitlab-instance.com/group/repo.git 2\u003e\u00261 | head #SSH #C端 GIT_SSH_COMMAND=\"ssh -v\" git -c protocol.version=2 ls-remote ssh://your-gitlab-instance.com:group/repo.git 2\u003e\u00261 |grep GIT_PROTOCOL \r\r \r\r","date":"2018-12-06","objectID":"/gitlab/:6:4","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"监控 Monitoring GitLab \r\r \r\r","date":"2018-12-06","objectID":"/gitlab/:7:0","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"故障排除 Troubleshooting \r\r \r\rRunner Runner是GitLab CI的客户端。 作为GitLab持续集成和持续部署(CI/CD)的一部分，主要用来配置和运行构建脚本以及其他的任务。 GitLab Runner 是一个开源项目， 它用来运行你定制的任务（jobs）并把结果返回给 GitLab。 GitLab Runner配合GitLab CI（GitLab 内置的持续集成服务）协调完成任务。 要求(Requirements) GitLab Runner是用Go编写的，可以作为单个二进制文件运行，不需要语言特定的要求。它可在多个操作系统上运行，只要你在此平台上编译成二进制文件。支持Docker v1.5+。 特点(Feature) Allows to run: multiple jobs concurrently(同时) use multiple tokens with multiple server (even per-project) limit number of concurrent(并发) jobs per-token Jobs can be run: locally using Docker containers using Docker containers and executing job over SSH using Docker containers with autoscaling on different clouds and virtualization hypervisors connecting to remote SSH server Is written in Go and distributed as single binary without any other requirements Supports Bash, Windows Batch and Windows PowerShell Works on GNU/Linux, OS X and Windows (pretty much anywhere you can run Docker) Allows to customize the job running environment Automatic configuration reload without restart Easy to use setup with support for Docker, Docker-SSH, Parallels or SSH running environments Enables caching of Docker containers Easy installation as a service for GNU/Linux, OSX and Windows Embedded Prometheus metrics HTTP server 兼容性图表(Compatibility chart) GitLab Runner的版本应该与GitLab同步。如果存在版本差异，则功能可能无法使用或无法正常工作。 \r\r\r","date":"2018-12-06","objectID":"/gitlab/:8:0","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"安装 Install GitLab Runner Install using GitLab’s repository for Debian/Ubuntu/CentOS/RedHat (preferred) Install on GNU/Linux manually (advanced) Install on macOS Install on Windows Install as a Docker service Install in autoscaling mode using Docker machine Install on FreeBSD Install on Kubernetes Install the nightly binary manually (development) \r","date":"2018-12-06","objectID":"/gitlab/:9:0","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"Repository Install GitLab Runner using the official GitLab repositories 安装： #添加镜像库 # For Debian/Ubuntu/Mint curl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.deb.sh | sudo bash # For RHEL/CentOS/Fedora curl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.rpm.sh | sudo bash #安装最新版 # For Debian/Ubuntu/Mint sudo apt-get install gitlab-runner # For RHEL/CentOS/Fedora sudo yum install gitlab-runner #安装制定版本 # for DEB based systems apt-cache madison gitlab-runner sudo apt-get install gitlab-runner=10.0.0 # for RPM based systems yum list gitlab-runner --showduplicates | sort -r sudo yum install gitlab-runner-10.0.0-1 #注册Runner #注册Runner参考后面 更新： # For Debian/Ubuntu/Mint sudo apt-get update sudo apt-get install gitlab-runner # For RHEL/CentOS/Fedora sudo yum update sudo yum install gitlab-runner 手动下载包安装 下载地址: https://packages.gitlab.com/runner/gitlab-runner 升级到GitLab Runner 10 #移除旧库 # For Debian/Ubuntu/Mint sudo rm /etc/apt/sources.list.d/runner_gitlab-ci-multi-runner.list # For RHEL/CentOS/Fedora sudo rm /etc/yum.repos.d/runner_gitlab-ci-multi-runner.repo #安装新库 #再安装 \r\r\r","date":"2018-12-06","objectID":"/gitlab/:9:1","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"手动安装 #下载二进制包 # Linux x86-64 sudo wget -O /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-amd64 # Linux x86 sudo wget -O /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-386 # Linux arm sudo wget -O /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-arm #添加可执行权限 sudo chmod +x /usr/local/bin/gitlab-runner #如果想使用Docker curl -sSL https://get.docker.com/ | sh #Create a GitLab CI user: sudo useradd --comment 'GitLab Runner' --create-home gitlab-runner --shell /bin/bash #Install and run as service: sudo gitlab-runner install --user=gitlab-runner --working-directory=/home/gitlab-runner sudo gitlab-runner start #Register the Runner #更新的话重新下载二进制包安装 \r\r\r","date":"2018-12-06","objectID":"/gitlab/:9:2","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"Docker #挂载运行 docker run -d --name gitlab-runner --restart always \\ -v /srv/gitlab-runner/config:/etc/gitlab-runner \\ -v /var/run/docker.sock:/var/run/docker.sock \\ gitlab/gitlab-runner:latest #Register the Runner #更新的话，停止旧容器，拉取新镜像 #GitLab Runner Logs #可以把Runner Logs目录挂载到宿主机，也可是使用docker 读取 \r\r\r","date":"2018-12-06","objectID":"/gitlab/:9:3","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"k8s \r\r\r","date":"2018-12-06","objectID":"/gitlab/:9:4","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"Autoscale \r\r\r","date":"2018-12-06","objectID":"/gitlab/:9:5","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"注册 Register GitLab Runner 安装GitLab Runner后，需要将其注册到GitLab。注册Runner是将Runner与GitLab实例绑定的过程。 要求(Requirements)，在注册Runner之前，你需要： 将其安装在与安装GitLab位置不同的Server上 通过GitLab的界面获取共享或特定Runner的Token 注册环境： GNU/Linux macOS Windows FreeBSD Docker … \r\r","date":"2018-12-06","objectID":"/gitlab/:10:0","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"GNU/Linux 在GNU / Linux下注册Runner： #URL和Token在GitLab实例的runner里面去看 #运行命令 sudo gitlab-runner register #输入GitLab 实例 URL Please enter the gitlab-ci coordinator URL (e.g. https://gitlab.com ) https://gitlab.com #输入获得的token Please enter the gitlab-ci token for this runner xxx #输入Runner的描述，之后可在Web UI下更改 Please enter the gitlab-ci description for this runner [hostame] my-runner #输入与Runner相关联的tag，之后可在Web UI下更改 Please enter the gitlab-ci tags for this runner (comma separated): my-tag,another-tag #输入Runner executor Please enter the executor: ssh, docker+machine, docker-ssh+machine, kubernetes, docker, parallels, virtualbox, docker-ssh, shell: docker #如果您选择Docker作为执行程序，则会要求您未在.gitlab-ci.yml中定义的用于项目的默认image Please enter the Docker image (eg. ruby:2.1): alpine:latest #启动runner sudo systemctl start gitlab-runner \r\r\r","date":"2018-12-06","objectID":"/gitlab/:10:1","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"单行注册命令 One-line registration command 如果要使用非交互模式注册Runner，可以使用register子命令或使用其等效的环境变量。 #查看帮助 gitlab-runner register -h #注册 sudo gitlab-runner register \\ --non-interactive \\ --url \"https://gitlab.com/\" \\ --registration-token \"PROJECT_REGISTRATION_TOKEN\" \\ --executor \"docker\" \\ --docker-image alpine:3 \\ --description \"docker-runner\" \\ --tag-list \"docker,aws\" \\ --run-untagged \\ --locked=\"false\" \\ \r\r\r","date":"2018-12-06","objectID":"/gitlab/:10:2","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"执行器 Executors GitLab Runner实现了许多执行程序，可用于在不同的场景中运行构建。 执行器： Shell Docker Docker Machine and Docker Machine SSH (autoscaling) Parallels VirtualBox SSH Kubernetes \r\r","date":"2018-12-06","objectID":"/gitlab/:11:0","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"选择执行器 Selecting the executor GitLab Runner实现了许多执行程序，可用于在不同的场景中运行构建。如果您不确定要选择什么，请阅读“我不确定”部分。访问兼容性图表，了解每个执行程序支持哪些功能，哪些功能不支持。 执行器支持不同平台和方法的项目构建： Executor SSH Shell VirtualBox Parallels Docker Kubernetes Clean build environment for every build ✗ ✗ ✓ ✓ ✓ ✓ Migrate runner machine ✗ ✗ partial partial ✓ ✓ Zero-configuration support for concurrent builds ✗ ✗ (1) ✓ ✓ ✓ ✓ Complicated build environments ✗ ✗ (2) ✓ (3) ✓ (3) ✓ ✓ Debugging build problems easy easy hard hard medium medium \r不清楚该选择哪个执行器 I am not sure Shell Shell是最简单的配置执行器。需要在安装Runner的同一台机器上手动安装构建的所有必需依赖项。 Virtual Machine 此类执行器允许您使用已创建的虚拟机，该虚拟机已克隆并用于运行构建。我们提供两种完整的系统虚拟化选项：VirtualBox和Parallels。如果您希望在不同的操作系统上运行构建，它们可以证明是有用的，因为它允许在Windows，Linux，OSX或FreeBSD上创建虚拟机，然后GitLab Runner连接到虚拟机并在其上运行构建。它的使用对于降低基础设施成本也很有用。 Docker 一个很好的选择是使用Docker，因为它允许一个干净的构建环境，并且易于依赖管理（构建项目的所有依赖项都可以放在Docker镜像中）。 Docker执行程序允许您轻松创建具有依赖服务的构建环境，如MySQL Kubernetes Kubernetes执行程序允许您使用现有的Kubernetes集群进行构建。执行程序将调用Kubernetes集群API并为每个GitLab CI作业创建一个新的Pod（带有构建容器和服务容器）。 SSH 添加SSH执行程序是为了完整性，但它是所有执行程序中支持最少的。它使GitLab Runner连接到外部服务器并在那里运行构建。(通常建议使用其它案例) \r\r兼容性 Compatibility 不同执行器支持的功能： Executor SSH Shell VirtualBox Parallels Docker Kubernetes Secure Variables ✓ ✓ ✓ ✓ ✓ ✓ GitLab Runner Exec command ✗ ✓ ✗ ✗ ✓ ✓ gitlab-ci.yml: image ✗ ✗ ✗ ✗ ✓ ✓ gitlab-ci.yml: services ✗ ✗ ✗ ✗ ✓ ✓ gitlab-ci.yml: cache ✓ ✓ ✓ ✓ ✓ ✓ gitlab-ci.yml: artifacts ✓ ✓ ✓ ✓ ✓ ✓ Absolute paths: caching, artifacts ✗ ✗ ✗ ✗ ✗ ✓ Passing artifacts between stages ✓ ✓ ✓ ✓ ✓ ✓ Use GitLab Container Registry private images n/a n/a n/a n/a ✓ ✓ Interactive Web terminal ✗ ✓ (bash) ✗ ✗ ✓ ✓ 不同shell支持的系统： Shells Bash Windows Batch PowerShell Windows ✓ ✓ (default) ✓ Linux ✓ (default) ✗ ✗ OSX ✓ (default) ✗ ✗ FreeBSD ✓ (default) ✗ ✗ 不同shell支持的交互式Web终端： Shells Bash Windows Batch PowerShell Windows ✗ ✗ ✗ Linux ✓ ✗ ✗ OSX ✓ ✗ ✗ FreeBSD ✓ ✗ ✗ \r\r\r","date":"2018-12-06","objectID":"/gitlab/:11:1","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"Shell Shell executor 是一个简单的执行程序，它允许您在运行Runner的机器上本地执行构建。它支持可以安装Runner的所有系统。这意味着它可使用Bash和PowerShell。 在Bash中，在gitlab-runner command命令之后加上--user，表示使用非特权用户运行。 源项目被切换到: \u003cworking-directory\u003e/builds/\u003cshort-token\u003e/\u003cconcurrent-id\u003e/\u003cnamespace\u003e/\u003cproject-name\u003e 项目的缓存放于: \u003cworking-directory\u003e/cache/\u003cnamespace\u003e/\u003cproject-name\u003e 这些都在GitLab-runner的配置: /etc/gitlab-runner/atom.config.toml 以非特权用户运行(Running as unprivileged user) 在Linux上(rpm/dpk)，安装程序将尝试使用gitlab_ci_multi_runner用户(如果找到)；如果找不到，它将创建一个gitlab-runner用户并改为使用它。 然后，所有shell build都将使用gitlab-runner或gitlab_ci_multi_runner用户执行。 在某些场景中，您的构建可能需要访问某些特权资源，例如Docker Engine或VirtualBox。在这种情况下，您需要将gitlab-runner用户添加到相应的组： usermod -aG docker gitlab-runner usermod -aG vboxusers gitlab-runner \r\r\r","date":"2018-12-06","objectID":"/gitlab/:11:2","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"Docker The Docker executor 文档: https://docs.gitlab.com/runner/executors/docker.html \r\r\r","date":"2018-12-06","objectID":"/gitlab/:11:3","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"K8s The Kubernetes executor 文档: https://docs.gitlab.com/runner/executors/kubernetes.html \r\r\r\r","date":"2018-12-06","objectID":"/gitlab/:11:4","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"高级配置 Advanced Configuration \r","date":"2018-12-06","objectID":"/gitlab/:12:0","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"配置文件 Advanced configuration options Learn how to use the TOML configuration file that GitLab Runner uses. GitLab Runner配置使用TOML格式，配置文件可能在如下位置: /etc/gitlab-runner/config.toml ~/.gitlab-runner/config.toml ./config.toml \rglobal部分 这定义了GitLab Runner的全局配置。 配置 描述 concurrent 限制全局可以同时运行多少个作业，0并不意味着无限制 log_level 日志级别(debug, info, warn, error, fatal, panic) log_format 日志格式(runner, text, json) check_interval 定义新作业检查之间的间隔长度(s)。默认值为3，如果设置为0或更低，将使用默认值 sentry_dsn 启用追踪所有系统级错误 listen_address host:port，Prometheus应该在其上进行监听 check_interval 如何工作: 如果config.toml配置文件中有多个[[runner]](称之为worker)，那么GitLab请求之间的间隔比人们预期的要频繁。GitLab Runner包含一个循环，该循环不断地为worker针对其配置的GitLab实例调度请求。 \r\r[session_server]部分 [session_server]是系统运行程序级别的配置，因此应该在根级别指定，而不是每个执行器指定，即它应该在[[runners]]部分之外。session server允许用户与Runner负责的作业进行交互。 如果想要禁用[session_server]部分，删掉它即可。 配置 描述 listen_address 用于session server的内部URL advertise_address 向GitLab公开的用于访问Runner的URL session_timeout 作业完成后，会话可以在多长时间内保持活动状态(默认1800s) \r\r[[runners]]部分 如下定义了Runner entry: 配置 描述 name Runner的描述 url GitLab URL token Runner指定的token tls-ca-file HTTPS的CA证书 tls-cert-file HTTP的S端证书 tls-key-file HTTPS的S端Key limit 限制此token可同时处理的作业数，0为不限制 executor 执行器 shell 用于生成脚本的shell的名称 builds_dir 构建将存储在所选执行器的上下文中的目录(local, docker, ssh) cache_dir 构建缓存将存储在所选执行器的上下文中的目录(local, docker, ssh) environment 附加或覆盖环境变量 request_concurrency 限制GitLab新作业的并发请求数（默认值为1） output_limit 最大构建日志大小(默认4096KB) pre_clone_script 在克隆Git存储库之前要在Runner上执行的命令 pre_build_script 克隆Git存储库之后但在执行构建之前要在Runner上执行的命令 post_build_script 在执行构建之后但在执行after_script之前在Runner上执行的命令 clone_url 覆盖GitLab实例的URL clone_url怎样工作: 如果GitLab实例公开给Runner无法使用的URL，则可以配置clone_url。 \r\r####　EXECUTORS shell docker docker-ssh ssh parallels virtualbox docker+machine docker-ssh+machine kubernetes \r\rSHELLS bash sh cmd powershell \r\r####　[runners.docker]部分 参数 描述 host 指定Docker endpoint (默认 $DOCKER_HOST或unix:///var/run/docker.sock) hostname 为Docker容器指定主机名 runtime 为Docker容器指定一个运行环境 tls_cert_path 证书路径 image 使用此镜像进行构建 memory 容器内存限制 memory_swap 总内存限制 memory_reservation 容器内存soft limit oom_kill_disable 容器OOM后也不kill进程 cpuset_cpus 容器使用的CPU cpus CPU数量 dns 容器使用的DNS列表 dns_search DNS搜索域列表 privileged 特权容器 disable_entrypoint_overwrite 禁用镜像端点覆盖 userns_mode 启用usernamespace重映射选项时，为容器设置usernamespace模式 cap_add 向容器添加其他Linux功能 cap_drop 从容器中移除其他Linux功能 security_opt 设置安全选项(key: value) devices 与容器共享其他主机设备 cache_dir 指定缓存目录 disable_cache 禁用缓存 network_mode 将容器添加到一个自定义的网络 wait_for_services_timeout 等待docker的时间，0为禁用(默认30) volumes docker挂载卷 extra_hosts 指定应在容器环境中定义的主机 shm_size 指定镜像共享的内存大小(Byte)) volumes_from 指定从其它容器继承的卷(格式: `\u003ccontainer name\u003e[:\u003cro volume_driver 指定容器使用的卷的驱动 links 指定与其建立链接的容器 services 指定使用build运行的其它服务 allowed_images 指定可在.gitlab-ci.yml中指定的通配符图像列表 allowed_services 指定可在.gitlab-ci.yml中指定的通配符服务列表 pull_policy 指定镜像拉取策略 sysctls 指定sysctl options helper_image 覆盖用于克隆repos和上载工件的默认帮助程序镜像 \r\r[runners.parallels]部分 参数 描述 base_name 将克隆的Parallels VM的名称 template_name Parallels VM链接模板的自定义名称 disable_snapshots 如果禁用，则在构建之后将摧毁VM \r\r[runners.virtualbox]部分 参数 描述 base_name 要克隆的VirtualBox VM的名称 base_snapshot 要从中创建链接克隆的VM的特定快照的名称或UUID disable_snapshots 如果禁用，则在构建之后将摧毁VM \r\r[runners.ssh]部分 参数 描述 host 指定主机 port 指定端口 user 指定用户 password 指定密码 identity_file 指定私钥 \r\r[runners.machine]部分 Parameter Description IdleCount Number of machines, that need to be created and waiting in Idle state. IdleTime Time (in seconds) for machine to be in Idle state before it is removed. OffPeakPeriods Time periods when the scheduler is in the OffPeak mode. An array of cron-style patterns (described below). OffPeakTimezone Time zone for the times given in OffPeakPeriods. A timezone string like Europe/Berlin (defaults to the locale system setting of the host if omitted or empty). OffPeakIdleCount Like IdleCount, but for Off Peak time periods. OffPeakIdleTime Like IdleTime, but for Off Peak time mperiods. MaxBuilds Builds count after which machine will be removed. MachineName Name of the machine. It must contain %s, which will be replaced with a unique machine identifier. MachineDriver Docker Machine driver to use M","date":"2018-12-06","objectID":"/gitlab/:12:1","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["linux"],"content":"自签名证书 Use self-signed certificates Configure certificates that are used to verify TLS peer when connecting to the GitLab server. 这允许在注册runner时解决由未知权限问题签名的证书(x509)。 支持自签名的证书: 默认情况下： GitLab Runner读取系统存储的证书并根据存储在系统中的CA验证GitLab服务器 GitLab Runner从预定义文件中读取PEM（不支持DER格式）证书: 如/etc/gitlab-runner/certs/ GitLab Runner在注册期间和[[runners]]部分下的config.toml配置中公开tls-ca-file选项，允许您指定带证书的自定义文件。每当Runner尝试访问GitLab服务器时，都会读取此文件。 ","date":"2018-12-06","objectID":"/gitlab/:12:2","tags":["GitLab","CI","CD","Git"],"title":"GitLab","uri":"/gitlab/"},{"categories":["english"],"content":"参考: 《新概念英语语法手册》 \r\r \r\r名词 ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:0:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"概述 名词是指人或事物的名称，也包括一些具有抽象概念的名词。 \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:1:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"用法 充当动词的主语 Our 'agent' in Cairo sent a telex this morning. #今天早晨我们在开罗的代理人发来一封电传。 作动词的直接宾语 Frank sent an urgent 'telex' from Cairo this morning. #弗兰克今天早上从开罗发来一份加急电传。 作动词的间接宾语 Frank sent his 'boss' a telex. #弗兰克给他的老板发了一份电传。 作介词的宾语 I read about it in 'the China Daily'. #我在中国日报上看到了这个消息。 作be、seem等系动词的表语 Jones is our 'guest'. #琼斯是我们的客人 作同位语 Laura, 'a BBC reporter', asked for an interview. #劳拉，BBC的记者，要求采访。 \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:2:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"复合名词 由两个或两个以上的名词部分组合而成的名词，称为复合名词。 复合名词通常有四种构成形式 1. 名词+名词 a keyboard(键盘) 2. 形容词+名词 a greenhouse(温室) 3. 动名词+名词 drinking water(饮用水) 4. 名词+动名词 sight-seeing(观光) 还有一些复合名词表示特定含义 Oxford Road, Beijing Capital International Airport \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:3:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"分类 专有名词 专有名词指特定的人、地方、事物或概念，他们被认为是独一无二的。专有名词的开头字母要大写，前面一般不用冠词。 #人名 Parker Mr. Parker #称呼 Mum #地名 Asia #月份、星期、节日、季节 April Monday Christmas spring(季节一般不大写) 普通名词 普通名词又可分为可数名词和不可数名词。 在普通名词前通常要使用冠词a, an, the… #可数名词 a book, an envelop how many stamps do you have? #不可数名词 water, milk, air how much milk do you have? #既是可数又是不可数 He ate much fish yesterday. There are a large variety of fishes in the pond. 复形名词 有些名词虽然形式上是复数形式，即以-s结尾，但实际上却表示单数意义。 The news is at six. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:4:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"名词的数 名词的单数形式和复数形式 拼写规则 单数 复数 一般情况下加-s cat cats 以 -o, -x, -ch, -sh 结尾的加 -es potato class box watch brush potatoes classes boxes watches brushes 以 辅音字母加 -y结尾，去-y加-ies 元音字母加 -y 结尾的加 -s country boys countries boys 以 -y 结尾的专有名词加 -s Fry Frys 以 -f, -fe 结尾的名词， 把-f, -fe变为 -ves wife wives 不规则变化 man sheep men sheep 以 -o 结尾一般要在后面加 -es 但元音字母加 -o 结尾的名词则只能加 -s。 不规则拼写法 foot/feet mouse/mice tooth/teeth 单/复数形式相同 sheep deer aricraft Chinese \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:5:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"名词的性 阳性 阴性 中性 acrot(男演员) actress(女演员) guest(客人) 有些名词可以不加思索的用阳性代词he、阴性代词she、中性代词it来指代。 表示动物性别相对的名词一般可用it指代。 \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:6:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"名词的格 名词所有格的构成 说明 栗子 单数名词末尾加's child’s 以 -s结尾的单数名词末尾加's或加' actress’s/actress' 不规则的复数名词末尾加 's children’s 以-s结尾的复数名词末尾加 ' girls' 一些以 -s 结尾的人名末尾加 's James’s 所有格一般表示人或事物的所属概念，通常可以回答Whose...?的问句。 通常来说's/s'和of的作用是一样的，但's/s'一般不和无生命的名词连用，而有生命的名词则两者通用。 \r\r \r\r冠词 有若干个词可以用在名词或形容词+名词的前面，我们把这类词统称为限定词(determiners)，因为它们影响或限定着这个名词的意义。 冠词就是其中一种。 \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:7:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"限定词 限定词分为两种： 有助于分类或确认的词 表数量的词 \r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:8:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"有助于分类或确认的词 不定冠词 I bought 'a' new shirt yesterday. 'A' girl came in and put 'an' envelope on his desk. 定冠词 'The' shirt I am wearing is new. 指示代词 I bought 'this/that' shirt yesterday. 物主代词 'My' shirt is blue. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:8:1","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"表示数量的词 数词 I bought 'two' shirts yesterday. 量词 I didn't buy 'many' new shirts yesterday. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:8:2","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"冠词的基本用法 冠词分为： 不定冠词(a/an) 定冠词(the) 零冠词 \r\r \r\r代词 代词是用来代替名词或名词短语的。 代词可分为： 人称代词: I, me, he… 物主代词: my, their, yours… 反身代词: myself, herself, themselves… 指示代词: this, that, those… 不定代词: some, many, each, any, all… 疑问代词: what, which… 关系代词: which, who(m), as, that… … \r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:9:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"人称代词 主格人称代词在句子中一般用在谓语动词前面，充当句子的主语 I think, therefore I am. it也可以用来表示人，它一般表示要确认什么人，或在表示弄不清楚小孩儿的性别的时候 There's a knock at the door. Who is 'it'? 宾格人称代词可代替处于宾语位置上的名词，充当动词或介词的宾语。有些动词接两个宾语：直接宾语和间接宾语。直接宾语指动作的承受者，间接宾语指动作所向的人或物。间接宾语必须与直接宾语连用 I gave 'him' a glass of water. #him 为间接宾语 #a glass of water 为直接宾语 使用人称代词时无论主格还是宾格，都应考虑到其所处的具体位置，在系动词be后也可以使用宾格，但不强调 Who is 'it'? 当人称代词处于同位结构中时，应与其同位的部分保持一致。也就是说当其同位的部分为主语时，其同位代词也为主语(用主格)，而当其同位的部分为宾语时，所用代词也为宾语(用宾格) Both Jack an 'I' can swim very well. 有时候，尤其在口语中，宾格人称代词me也可用作主语 Me/Not me! 注意祈使句中可用宾格人称代词作主语，起强调作用 She's been promoted. Lucky 'her'! 关于动物、东西和国家，人们通常将其人格化，这样它们也就具有了阴/阳性 The cuckoo lays 'her' eggs in other birds' nests. 当我们谈论汽车、船、摩托及其它机械时，常常把它们看做阴性 My car's not fast, but 'she' does 50 miles to the gallon. 国家通常也人格化，经常看成阴性 In 1941, America assumed 'her' role as a world power. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:10:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"不定代词 不定代词指的是some, any, no, every…以及与之组成的复合词 不定代词常常表示不确定的人、物或量。 someone, anyone, none, everyone somebody... something... 在表示一些时，some一般用于肯定陈述句中，而any则一般用于疑问句和否定句中 There are 'some' frogs in the pond. There aren't 'any' frogs in the pod. 当表示建议或请求的时候，仍用some或something等 Would you like 'something' to drink? any或anything用于陈述句的肯定形式的时候，表示泛指概念，指任何 You can choose 'anything' you like here. 复合不定代词(如something, anything)等的定语一般应后置 This is 'something' special. Is there 'anything' for me to sit on? 当需要排除概念时，经常将else与不定代词连用，构成如下组合词，表示另外的，别的之意 everyone else, someone else, anyone else, anything else, nothing else... We need one more helper. Can you find 'anyone else'? 指代a/an + 可数名词时，则必须用one作宾语 Would you like a drink? I'd love 'one'. Thank you. 当不可数名词或复数名词用于非特指时，则必须使用some或any作宾语 Have you got 'any' sugar? Can you lend me 'some'? \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:11:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"物主代词 物主代词分为: 形容词性物主代词(或所有格形容词) 名词性物主代词(或所有格代词) 形容词性:my, your, his, her, its, one's, our, your, their名词性:mine, yours, his, hers,ours, theirs 形容词性物主代词和名词性物主代词都表示所有，即某人或某物属于某个人，回答Whose…?的问题。形容词性物主代词是限定词，因此必须放在名词之前，不可单独使用。它们的形式取决于所有者，而不是被拥有的东西。 John's daugther = his daugther Jane's son = her son the cat's milk = its milk my, your, their可表示男性所有，也可表示女性所有。 \"My house is there,\" Sally/John said. Your passports, please. their也可表示动物或物品所有。 Dogs should have their own kennels outside the house. Cars with their engines at the back are very noisy. one’s 可用作非人称形容词性物主代词，但不能用作名词性物主代词。 One's first duty is to one's family. 所有格代词mine, yours不能用在名词之前，且在说话时要加重语气。它们在指人或物时，单数或复数都一样。its从来不作所有格代词用。 There are my children. These children are mine. I can't find my pen. Can you lend me yours? 名词性所有格可以放在句首。 This is my cup. Yours is the one ttat's chipped. 在特别强调所有关系时，通常用one’s own。可以在任何形容词性物主代词而不是名词性物主代词后面加上own，这样形成的词组既可以起形容词性物主代词的作用，也可以起名词性物主代词的作用。 I'd love to have my own room / a room of my own. Our cat has its own corner / a corner of its own in this room. 如果需要再进一步强调则可以加上very。 I'd love to have my very own room /a room of my very own. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:12:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"反身代词 反身代词属于所有格形容词，其构成为\"形容词性物主代词+self\"组成的复合词，或\"人称代词宾格+self\"。 单数: myself, yourself, himself, herself, itself, oneself 复数: ourselves, yourselves, themselves \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:13:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"指示代词 指示代词包括this, that, these, those。 其中， this, these为近指指示代词，与here对应； that, those为远指指示代词，与there对应。它们一般与名词连用。 this girl, that boy, these teachers, those students 通常来说，单独用指示代词时，不指人而指物；但在Who…?问句中，也可指人。 I found this watch. I found this. Who's this? Who's that? \r\r \r\r数量词 ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:14:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"概述 数量词或数量词组常用来修饰名词，表示我们所说的事物的数与量。 有些数量词修饰可数名词复数，如 many, (a) few, several... 有些数量词修饰不可数名词，如 much, (a) little... 有些两者皆可修饰，如 a lot of, lots of, some... 修饰可数名词时，用来回答How many…? How many eggs are there in the fridge? There are a few. 数量词修饰不可数名词时，用来回答How much…? How much milk is there in the fridge? There's a little. 两者皆可修饰，因此既能回答How many…? 也能回答How much…? How many eggs are there in the fridge? There are plenty. How much milk is there in the fridge? There is plenty. 数量词+名词 的组合形式 搭配形式分类 同类数量词 数量词+复数可数名词 如: many books both, a couple of, hundreds of, (a) few, a number of, serval … 数量词+不可数名词 如: much sugar a amount of, a bit of, a drop of, a deal of, (a) little of … 数量词+复数可数名词,不可数名词 如: some books, some sugar some, any, all, hardly, a lot of, lots of, the other … 数量词+单数可数名词 如: each book another, each, either, the other, some, the whole … \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:15:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"不是不确定的数量 #数量可以是确定的，也就是可确切地说出到底有多少 We need six eggs and half a kilo of butter. #更多的时候，数量是不确定的，它只说明了一个大致的情况 Are there (any) apples in the bag? There is some milk in the fridge. #数量词后常和more连用 I'd like some more chips I'd like some more milk. #数量词后也常和less连用 Much less soup, please. I want mush less, please. #数量词前用not Not enough is known about this subject. It has given not a little trouble. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:16:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"数词的分类 数词可分为: 基数词 序数词 分数 小数 百分数 … #基数词 one, two, three... #序数词 first, sixth, tenth... #分数 #英语中分数的构成为: 一个基数词加一个序数词 #分子为1时，分母直接使用序数词；分子大于1时，分母序数词+s one third, nine sixteenths #小数 0.5, nought point five, point five 2.5, two point five 2.05, two nought five, two point o five #百分数 8%, eight percent 99%, ninety-nine percent #近似的数量 about, almost, exactly, fewer than, at least, less than, nearly ... There wrer over seventy people at the party. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:17:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"not, no, none, little, bit not(any), no和none的区别 构成否定句的方式可以用not来否定动词，也可用no来否定后面的名词 none可以直接作为一个代词来用，而no则不可 There aren't buses after midnight. There are no buses after midnight. Do you have any diaries? We've got none at the moment. a great deal/amount of与a large/greate number of a great deal/amount of都有much之意，其后应接不可数名词； a great/large number of都有many之意，其后应接可数名词复数。 A great deal/amount of money is spent on research. A large/great number of our students are American. (not) (a) little与(not) a bit及(a) few的区别 few和 a few; little和a little (a) few用于修饰可数名词复数 (a) little用来修饰不可数名词 不带不定冠词a时，两者都表示否定之意，强调少的概念 (a) little和(a) bit 在肯定句中，它们几乎是通用的 在否定句中，它们的含义正好相反 He has had very few opportunities to practise his English. He has very little hope of winning the race. A lot of guests wre execpted, but few came. There are only a few seats left. There's only a little soup left. I'd like a little/bit of time to think about it, please. He was not a little surprised. # 他感到十分吃惊 I don't like the book, Not a bit. # 一点也不喜欢 \r\r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:18:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"enough enough的基本意思是充足的。它既可修饰名词，也可修饰形容词和副词，还可做名词。修饰名词时放在名词前，修饰形容词放在形容词后。 Is there enough hot water for me to take a bath? Is the water hot enough for me to take a bath? about, almost, hardly, less than, more than, nearly, not, not nearly, not quite scarcely等词常用来修饰enough。 There are hardly enoush cakes. 在特定上下文中，little和few也可以修饰enough，强调不够。 I can't lend you money. I have little enough as it is. I can't give you any stamps. I have few enough as it is. \r\r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:19:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"both, all, either, neither, each, every, other, another 这些不定代词中，either, neither, each, every只能修饰或代替单数名词 both, all一般修饰或代替复数可数名词。其中both表示两者都，通常适用于两者之间；而all表示全部，用于三者及以上 一般来说，either表示两者必有其一；而both则表示两者都 否定式用neither, nether…nor，注意当它们作主语时，谓语动词要和靠近谓语部分的名词或代词一致 当both, all, each, either, neither用在代词前面时，其后必须加of all和every都可表示泛指概念。all通常表示可视为一个整体的东西，或指一个总量；every则强调群体当中的每个单位，而且只用于修饰单数可数名词 当使用not对all或both进行否定时，其否定结果为部分否定；无论not直接用在all/both之前还是用于否定动词上，都表示一样的意义。完全否定时，应该用no, none, neither each和every的用法十分相似，经常可以通用。each更注重强调个体，every更侧重强调整体 another有两种意义: 外加的/同样的 不同的 another和other不是确指的，而the other(s)却是确指的 All thirty passengers on the boat were saved. Both of you told a lie. Either of you is wrong. Neither he nor I speak English. #他和我都不讲英语 Both of us left very early. Neither of the girls left early. I've read all these books. I've read every book in the library. Not all the girls left early. None of the girls left early. Neither of the girls left early. # 两个女孩都没有早走 Each child in the school was questioned. Every child enjoys Christmas. Do you need annother cup of coffee? Give me another cup. This one's cracked. \r\r \r\r形容词 \r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:20:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"形容词概述 形容词经常用于说明人或事物的性质，最为常见的是作名词的定语。 根据所描述的对象和意图的不同，又可分为多种类型。请看下表： 形容词类型 栗子 表质量 a beautiful lady a fine/nine day 表大小 a big car、 a tall man 表新旧/老少 a young man a new bag 表温度 a cool evening a hot summer 表形状 a round table a square box 表颜色 blue esys、grey hair 其他 a Swiss watch 形容词作表语，通常可以描述整个词组的意思。 Professor Robert’s lecture on magnetism was fascinating. 罗伯特教授的磁学讲得很精彩。 Yesterday, I bought a book. Books are not very expensive. 昨天我买了一本书。书不很贵。 \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:21:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"复合形容词 \r用过去分词构成 a candle-lit table(一张点着蜡烛的桌子)、a tree-lined avenue(林荫大道) 用现在分词构成 a long-playing record(密纹唱片)、a time-consuming job(费时的工作) 用看上去是分词，实际上是用名词+ed合成的词构成复合形容词 slow-footed(脚步慢的)、quick-witted(机敏的) 表示度量的复合形容词 特征 栗子 年龄 a three-year-old building an eighteen-year-old girl 面积/体积 a three-acre plot a two-litre car 持续时间 a four-hour meeting a two-day conference 长度/深度 a twelve-inch ruler a six-foot hole 价格 a 50 dollar dress 时间/距离 a ten-minute walk a three-hour journey 重量 a ten-stone man a five-kilo bag of flour 带序数词 a first-rate flim a second-hand car 用前缀或后缀构成的复合形容词 tax-free(免税的)、water-proof(防水的) \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:22:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"定语形容词和表语形容词 一般来讲，几乎所有的形容词都能作表语，但有些形容词却不能或不常作表语。 countless、digital、indoor、western、commanding、thankless… 有些形容词，如old, late, heavy等，既能作表语也能作定语，但表示的意思是不同的。 Jordan is old now. 乔丹现在已经老了。（old作表语，指年纪大） Jepson is an old friend. 杰普森是一位老朋友。（old作定语，指相识的时间已经很久了） 有些形容词只能作表语而不能作定语，我们通常把这类形容词成为表语形容词。 表语形容词有以下三种： 描述与健康有关的一些形容词。如：faint, ill, poorly, unwell, well… He’s ill. 他病了。(ill作表语) 很多以a开头的形容词，只能作表语而不能作定语。如：afloat, alight, awake, asleep, alone, afraid, ashamed… He ought to be ashamed. 一些描述感觉、反应的形容词，只能作表语，而不能作定语。如：content, glad, pelased, sorry, upset, far… I’m very glad to meet you. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:23:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"用在名词后的形容词 有些形容词常放到头衔名词的后面做修饰语。 Attorney General(检察总长)、Governor General(总督)、Heir Apparent(法定继承人) 还有一些固定搭配的词组，也是讲形容词置于所修饰的名词之后。 sum total(总计)、Asia Minor(小亚细亚)、hope eternal(永恒的希望) 有些形容词即可放在名词前也可放在名词后，但它们的意思通常有所改变。 如：concerned, elect, involved, present, proper, responsible… Jones is a responsible girl. 琼斯是个有责任心的姑娘。 The girl responsible was expelled. 负有责任的那个姑娘被开除了。 \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:24:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"the+形容词的用法 the+形容词表示作为整体的群体，谓语动词用复数。 the blind、 the poor/rich、the young/old… The rich should help the poor. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:25:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"形容词的词序 形容词的分级 大多数形容词是可以分级的，即有比较级和最高级形式。 但是，有一些形容词则不能分级，即没有比较级和最高级。它包括无分级形容词和极限形容词两种。 无分级形容词：daily, dead, medical, unique 极限形容词：excellent, perfect, favourite Fishing is my favorite sport. 形容词比较级的构成 形容词的比较级和最高级的一般构成方法是： 单音节形容词及少数双音节形容词直接在后面加-er和-est构成比较级和最高级。 如：clod, cloder, clodest… 在以重读闭音节结尾的形容词中，当结尾是一个元音字母加一个辅音字母时，应双写其结尾的辅音字母后再加-er和-est。 如：fat, fatter, fattest… 有些形容词是以字母-e结尾，它们的比较级和最高级可在其后直接加-r或-st。 如：fine, finer, finest… 有些形容词是以字母-y结尾，而且在-y前面有一个辅音字母，这种形容词变为比较级和最高级时应首先把y变为i，然后再加-er和-est。 如：tidy, tidier, tidiest… 三个和三个音节以上的形容词变为比较级和最高级形式时通常在词的前面加more和most。 如：beautiful, more beautiful, most beautiful… 还有一些形容词的比较级和最高级的变化是不规则的。 如：good/well, better, best… 形容词比较级和最高级的用法 当我们把一个人或事物与另一个人或事物进行比较时，用比较级。 如： Jane is taller than Alice. 将某一个范围内的一个人或事物和其他一个以上的人或物作比较时，用最高级。短语或句子中的形容词最高级钱要用定冠词the，副词则不必。 如：John is the tallest. 我们经常用more and more的句型来表示越来越…的意思。 如：Alice is getting more and more beautiful. 在表示越…就越…时，用the more...,the more...句型。 如：The more money you make, the more you spend. 可修饰形容词比较级的词 形容词的比较级通常只有少数表示程度的词才能修饰。如：a bit, a little, a few, much, a lot, by far, even, still… Houses are much/far/a lot more expensive these days. 可修饰形容词最高级的词 如：almost, altogether, by far, much, nearly, quite, the very… This is quite/by far the most expensive bicycle in the shop. 形容词原级的常用句型 当使用as+形容词原级+as的句型时， 表示前后两者具有同等程度；其否定形式一般为not as/so+形容词原级+as，一般可理解为前者不如后者。 如： Jane is as tall/intelligent as Jones. \r\r \r\r副词 \r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:26:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"副词概述 一般情况下，副词可以修饰动词、形容词、其它副词、介词短语…，具有对这些词进行补充说明的作用。 修饰对象 栗子 形容词 very good awfully hungry 其它副词 very soon awfully quickly 介词短语 You’re entirely in the wrong. 完整的句子 Strangely, I won first prize. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:27:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"副词的常见构成形式 形容词+ly是最常见的副词构成形式。 如： beautiful, beautifully… 注意有些以-ly结尾的词，并不一定是副词，挡在名词后加-ly时，则一般构成形容词。 如：friendly(有好的)、daily(每日的)… \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:28:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"副词的比较等级 副词的比较等级与形容词的类似，由它构成的句型也大致一样，只是所修饰的对象不同。 She is the fastest girl.（fastest修饰女孩，为形容词最高级） She runs fastest.（fastest修饰跑，为副词最高级。注意多数副词的最高级钱不能使用the） \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:29:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"方式副词 方式副词的位置通常有三种 在句尾或宾语/动词之后 Jane watched the small monkey curiously.（在宾语后） It snowed heavily last January.（在动词后） 在主语和动词之间 Bob angrily slammed the door behind him. 用在句子开头 Normally, our papers are delivered every morning. 有些方式副词，如：bravely, cleverly, cruelly, foolishly, kindly, simply, badly…当位置改变时，其强调的方面也随之变化。 He foolishly locked himself out.（强调他是个傻瓜） He behaved foolishly at the party.（强调可笑的行为） \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:30:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"地点副词 常用的地点副词有： abroad, ahead, anywhere, everwhere, right, left, here, there, south, north, forwards…其位置一般用于方式副词后、时间副词前。 Indoors it was nice and warm. Outdoors it was snowing heavily. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:31:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"时间副词 时间副词可分为表确定时间的副词和表不定时间的副词两种。 表确定时间的副词：tomorrow, yesterday, last month… 表不定时间的副词：already, another day, another time, at once, at last, early, eventually, formerly, immediately, just, recently, now, once… 表确定时间的的副词的位置一般在句首或句尾。 This morning I had a telephone call from Jane. We checked in at the hotel this Monday. 表不定时间的副词的位置一般放在句首、句尾、实义动词之前和助动词或系动词be之后。 Recently the clavichord was damaged by a visitor. By the way, have you seen Harry recently? I was recently in NewYork.（系动词后） \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:32:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"already和yet already一般不用在否定句和疑问句中，它的位置与非确定性频度副词相同。 This computer is out of date already. yet一般用于疑问句和否定句中，通常放在句尾。 Have the new petrol prices come into fore yet? \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:33:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"频度副词 频度副词包括频度副词和频度副词短语 频度副词：hourly、once、twice、weekly、fortnightlt、annually、never、seldom、usually… 频度副词短语：three times a week、once a month… 确定性频度副词 如：once，twice，hourly，daily， on Fridays, three times a week…通常放在句尾。 I saw my girlfriend once a week. 非确定性频度副词，如果按频率的大小来排序的话，为 always\u003ealmost always\u003enearly always\u003efenerally/normally/regularly/usually\u003efrequently\u003eoften\u003esometimes/occasionally\u003ealmost never/hardly ever/rately/scarcely ever/seleom\u003enot…ever/never 表示否定意义的非确定性频度副词不能与not连用 We hardly ever see Mr. Lee these days.（不能说We don’t hardly ever…） 在肯定句和疑问句中的非确定性频度副词通常放在句子中间。大多数非确定性频度副词一般都位于助动词之后或实义动词之前。 I was never very good at maths. 非确定性频度副词也可放在句尾。 I get paid on Fridays usually. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:34:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"程度副词 常用的程度副词有：quite, almost, altogether, barely, a bit, enough, fairly, hardly, nearly, rather, somewhat, too…这些词大部分用在所修饰的词语前面。 修饰形容词： quite good 修饰副词：quite quickly 修饰动词：I quite like her 修饰名词：quite an experience fairly与rather fairly通常表示褒义的概念，描述主语所期望的和具有积极意义的情况，表示事物处于好的状态。 The lecture was fairly good. rather比quite和fairly语气更强，往往含有过分的意思，通常用于描述主语所不愿意或消极的内容。 He is clever but rather lazy. This jacket’s rather old. rather可与比较级连用，而fairly一般不能。 Jack earns rather more than his father. rather可与too连用，强调过分的意思。 This book is rather too easy for the college students. 当与褒义的形容词连用时，rather含有惊人地意思。 I did rather well in the test——better than I had expected. rather在与名词连用时，其位置是灵活的，放在不定冠词前或不定冠词后君合；而fairly只能放在不定冠词后。 \r\r \r\r介词 \r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:35:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"概述 介词经常用在名词或名词短语、代词或动名词之前，用来表示人、物、事件等与其他人、物、事件之间的关系。 I gave the book to Jane.（介词+名词） I gave the boo to her.（介词+代词） Jane devotes her time to reading.（介词+动名词） 介词经常表示的关系如下 We ran across the field.（空间） The plane landed at 6:55 p.m. precisely.（时间） You unlock the door by turning the key to the right. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:36:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"介词的形式 常见的介词的形式有两种 单个词：at, from, in, to, into… 介词短语：according to, apart from, because of… 介词后面的名词没有格的变化 The car stopped behind/in front of the girl. He was very angry with me. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:37:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"可兼作介词和连词的词 有些词既可作介词(其后接宾语)，也可作连词(其后跟从句)。 如：as, after, till, since, before, untill… Please come to me after 3 o’clock.（介词） We went to the beach directly after we got up.（连词） \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:38:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"表示动态或静态的介词 有些介词，如：into, onto, out of…一般都与表示动作的动词连用，表示动态概念。 A bird flew into my bedroom this morning. I drove out of the car park. 还有一些介词，如：near, above, behind, across, along, beside, between…与某些表示静态概念的动词连用时，表示静态；而与表示动态概念的动词连用时，则表示动态。 I waited in the hotel lobby.（静态） He hurried across the street.（动态） \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:39:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"表示时间的介词和介词短语 介词at, in, on不仅表示地点，也表示时间。 Many tourists come here in summer. They usually come in July and in August. 用at的时间短语 at表示时间时一般表示具体的时间点，但也有例外。 适用情况 栗子 确切时间 at 10 o’clock 用餐时间 at lunch time 节日 at Christmas 年龄 at 18 其它时刻 at noon 用on的时间短语 on一般用于表示一整天的时间概念，如：on Monday… 但也有例外，如果在一段时间前面有定语修饰的时候，一般也用on。如：on Monday morning… 有些节目前也用on。如：on Christmas Day 用in的时间短语 in一般表示时间段，长短皆可。 适用情况 栗子 一天中的某段时间 in the evening 月份 in June 年份 in 1995 季节 in spring 世纪 in the 21st century 节日 in Easter Week 时期 in the holidays \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:40:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"动词+介词/副词小品词 由动词+介词/副词小品词构成的短语动词是非常普遍的，而且短语动词的用法也特别合乎英语的行文习惯。 动词+介词/副词小品词的五种类型 类别 栗子 动词+介词（及物） get over (an illness) 动词+副词小品词（及物） bring up (the children) 动词+副词小品词（不及物） come out/break out 动词+副词小品词+介词（及物） run out of (matches) 动词+名词+介词（及物） take part in 在由动词+副词小品词构成的短语动词中，副词小品词的位置是比较灵活的。当其宾语是名词时，副词可以放在名词的前面或后面；当其宾语为代词时，则副词只可放在代词之后；但如果宾语比较长时，则应尽力避免把小品词与动词分开。 She turned off all the lights which had been left on. This cat is too noisy, Take it out, please. 大部分动词+副词小品词形式的动词短语中，小品词与动词本身的意义是有一定联系的，或者有一定的参照性。 如： take off, pick up, take…away, come up, guess out… 但有些小品词与动词搭配时，动词本身已经没有什么实际意义，同一个动词在搭配了不同的小品词之后，其意思大相径庭。 bring up the children bring off a deal 在英语中有些动词是不及物动词，当它们需要带宾语时必须通过后面跟介词的方式。 如：listen to, look at, ask for, wait for, look for… She is waiting for her boyfriend. You should ask for the bill. 一些不及物动词与小品词搭配之后，形成的仍然是不及物的短语动词。 Alice went out. We set off very early. 动词+介词/副词小品词+宾语 如：dream of, think of, succeed in, insist on… Your father insist on coming with us. He dreamed of being a pilot. 使用动词+介词形式的短语动词时，不能把介词放在宾语之后。 Look at this picture.（不能说Look this picture at.） 使用由动词+介词to形式的动词短语时，to后不能跟不定式，而必须分名词或动名词。 I look forward to seeing you soon. be used to后跟不定式和动名词时，所表达的意思是不一样的。 I’m used to getting up early in the morning. \r\r \r\r动词 \r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:41:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"概述 动词是构成句子的必备元素，充当句子的谓语部分。根据其不同的用途，动词又可分为： 及物动词、不及物动词； 实义动词、情态动词、系动词、助动词； 非谓语动词和谓语动词； 及物动词与不及物动词 有些动词，如：afford, allow, blame, bring, deny, need, get…，在使用的时候，其后必须跟宾语，称为及物动词； 有些动词，如：lie, occur, happen, rain, sleep…，在使用的时候，后面不能跟宾语，称为不及物动词。 有些不表示动作而表示状态(如感受、状况等)的动词称为状态动词。 如： like(喜欢)、think(认为)、love(热爱)、understand(理解)… 状态动词在使用的时候，一般不用于进行时态。 She loves/loved her baby more than anything else in the world.（不能说She is loving…） 有些动词则表示有意识或无意识的动作或者变化着的状态，称为行为动词。 I’m making a dress. 动词在使用的时候应注意人称的一致性和时态的变化。 \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:42:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"助动词 \r助动词一般包括：am/is/are/was/were, have/has/had, do/does/did, will/would, shall/should，它们的功能主要是帮助动词完成时态、语态的变化。 助动词be的用法 与现在分词构成现在进行时 与过去分词构成被动语态 … 助动词have的用法 与过去分词都成现在完成时 与现在分词构成现在完成进行时 与过去分词构成现在完成时的被动语态 类型 栗子 祈使句 Have a cup of coffee! 一般现在时 I always have milk in my tea. 现在进行时 We are having a nice time. 一般过去时 We had a lovely holiday last summer. 过去进行时 I was having a batch when the phone rang. 现在完成时 John has just had an accident. 现在完成进行时 The children have been having a lot of fun. 过去完成时 He went out to play basketball after he had finished his homework. 过去完成进行时 The file had been showing for 15 minutes when I got to the cinema. 一般将来时 I’ll have my hair cur tomorrow. 将来进行时 If anyone phones, I’ll be having a bath. 将来完成时 Tom will have had his exam by 18 Decembr. 将来完成进行时 She will have been having treatment for three months in the hospital by the end of this week. 情态动词 You could have a cup of coffee if you like. 助动词do的用法 助动词do最主要的用法有两个： 与动词原形搭配构成一般现在时或一般过去时的疑问句和否定句 用在实义动词前起强调作用 Do you do your shopping once a week? （构成疑问句，前一个do是助动词，后一个do是实义动词） He didn’t know when to set off.（构成否定句） The farmer did drive the cattle into the field.（表强调） \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:43:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"情态动词 \r概述 情态动词一般用于描述委婉、礼貌、客气、强令等特殊语气，达到表现说话人复杂心理及情感的目的。 情态动词包括： can/could, may/might, will/would, shall/should, must, ought to。另外，need和dare既可作实义动词也可作情态动词。 情态动词的主要功能 can/could主要指能力（不需要再努力） I can type. may主要指允诺 You may leave early. will主要指预告、将要 It will rain soon. should/ought to主要指不可推卸的义务或责任 You should/ought to do as you’re told. must主要表示强令或不可推卸的责任 You must be quite. needn’t指没有义务，既可作可不做 You needn’t wati. 情态动词也叫情态助动词，它像助动词be, do, have一样可以直接在后面加not构成否定句或将其提到主语前面构成疑问句。 You mustn’t move this table.（否定句） Can I ask you some questions?（疑问句） Can’t you see the picture?（否定疑问句） 情态动词每次只能用一个 We may call a doctor. We must call a doctor. 如果需要同时表示两种意思，则要通过适当的解释。 It may be necessary (for us) to call a doctor.（may和necessary，同时表达了也许和必要两种意思） 情态动词的时态和语态 情态动词在形式上没有实义动词的各种变化，只有could, would, had to, wat/were to, might几个过去式。must和ought to过去式和现在式相同。 would, could, might, should在形式上都可以说是will, can, may, shall的过去式，但与它们的用法和意义却无多大关系。一般来说，情态动词的过去式往往可以表示更加委婉、客气等含义。当情态动词用于表示过去的状态或动作时，则是它们的过去时。 She says you can/will/may leave early.（现在时） She said you could/would/miht leave early.（过去时） 情态动词should/ought to/could/must后接动词的完成时态时，往往可以表示一些特殊含义。 The lights in her roo were out 15 minutes before I came here, so she must have been out then.（表示对过去了的情况的推测） can/could和be able to的区别 一般来说，can/could和be able to没有多大区别，经常可以互换。但can/could侧重于表示能力，而be able to则强调通过努力才能够… I can operate a computer. The girl is able to explain what had happeened to her. can/could, may/might用于表示请求别人允许或答复的情况 can, may, could, might通常都可以表示请求别人允许的意思。 Can/Could/May/Might I borrow your umbrella? 但在使用的时候应该注意一下几点区别： can最常用，但也最不正式 could比can更为犹豫和客气，通常用在补鞥你确定请求能否得到同意的时候 may比can和could更正式，而且更客气和恭敬 might显得最犹豫，也最客气而恭敬 用情态动词表示推测 在对所发生的的事情进行描述的时候，一般有肯定、可能和推测三种情况。 如果说话人对所描述的事实确信无疑，就可以用be或任何实义动词直接描述。 Jane is at home. He leaves at 9 p.m. 如果说话人指的是可能发生的事情，就可以用may/might/could+动词原形的结构表示。 Jane may/might be at home. must+动词原形一般表示有根据而且是近乎肯定的推测；must一般用于肯定句，否定句和疑问句则通常用can/can’t+动词。在表示有根据但不太肯定的情况时则常常用may/might+动词。 Jane’s light is on. She must be at home.（根据充分的肯定推测） She can’t be out.（有根据的否定推测） He may/might have left yesterday.（对过去情况的推测） 在表示推测时，其附加问句是通过情态动词后的动词形式来处理句尾的附加问句。并且，因为情态动词+动词的完成时表示对过去事实的推测，所以，有明确的的时间状语时，附加问句部分动词一般应用过去时的助动词；如果没有明确的时间状语，则可以采取have/has或did两种形式的任意一种。 She might have left.（无时间状语） She might have left the day before yesterday.（有时间状语） must, have to和have got to 这三种情况就其表示的意义而言，一般可以互换，但也有区别。用于第一人称时，must通常强调主观因素，或内在的因素；而have to, have got to则常常强调客观因素或外在因素。 用于其他人称时must表示不可推卸的责任，其迫切性往往要比have to/have got to还强。 may在套语中可表示祝愿或非常希望，may通常用在句首。 May God be with you. 作情态动词的need和dare need和dare可以作为情态动词也可以作为实义动词。 Need you leave so soon?（情态动词） You need to clean the bedroo.（实义动词） dare可表示气愤的强烈语气。 How dare you! would和used to 情态动词would和used to可以表示习惯或过去常常。 Jane used to make her own dresses. used to强调过去常常…而现在已经不… I used to smoke, but I don’t smoke any more. used to be/have 可以描述过去的状态。 He used to be a postman a long time ageo. I used to have beard, but I’ve shaved it off. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:44:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"非谓语动词 \r概述 非谓语动词包括不定式、现在分词、过去分词和动名词。 非谓语动词在句子中，一般相当于形容词、副词或名词的作用，虽然仍有动作概念但不能直接充当谓语。 He wanted to find out the secret.（wanted为谓语动词，作该句的谓语；to find为不定式，为非谓语动词，作wanted的宾语） 不定式 不定式是非谓语动词中比较常用的一种。它通常由to+动词原形构成。有些情况下to可以省略。 动词不定式的用法也相当多，它既可以像名词那样在句子中充当主语、宾语或表语，也可以像名词那样充当定语，还可以像副词那样作状语，主要作目的状语和结果状语。 It’s easy to say. （不定式作真正的主语） I’m waiting here to see the sunrise.（不定式作目的状语） However, they have decided to use the post office.（不定式作宾语） He seems to be fond of playing the guitar.（不定式作表语） I have a lot of things to deal with today.（不定式作定语） 在有些情况下不定式小品词to是可以省略的。当不定式作let, have, make的补语时，不定式小品词to可以省略。 Let’s take a taxi. 但当这些词用于被动语态时，不定式的小品词to则不能省略。 The peasants were made to work ten hours a day. help和know之后作补语的不定式小品词to可以省略亦可不省，而有时作其宾语的不定式小品词to可以省略亦可不省。 Mother helped me (to) do my homework. 被动的help和help所带的被动的不定式的区别：和let, have, make一样，当help为被动式时，其后的不定式小品词to必须有，但当help之后的动词是被动形式时，则不受此影响。 Jane wad helped to overcome her fear of flying. 并列不定式可以由and, or, but, except等连接。 Which do you prefer, to win a million US dollars or (to) have a brain like Einstein’s? 在并列不定式中，第二个to常可以省略，而只使用其纯并列部分。 I’d like to lie down and to to sleep. 叙述一些列动作时则多用不带to的不定式，或者叫省略不定式的符号to。 The crowd watched the firemen climb the ladder, break a window on the first floor, and enter the building. 动词+宾语作宾语补足语 feel(感觉)、hear(听见)、listen to(听)…动词后经常跟不带to的不定式或现在分词作补语。 I watched a pavement-artist draw a portrait in crayons. 带to的不定式。 It+is/was+形容词+of+名词/代词+带to的不定式it作为形式主语的用法比作人称主语的用法更为常见。 It’s very kind of her to help us. 动词的ing形式 动名词和现在分词皆由动词+ing构成，但是这两种词的用法却大不一样，动名词具有名词的性质，因此在句子中经常充当主语、宾语或表语；而现在分词具有形容词或副词的性质，因此在句子中充当定语、状语或补语。 动名词和现在分词虽然同形，但其作用是完全不一样的。动名词因为具有名词性质，因此常常可以做主语或宾语。而且，由于它是从动词变化而来，所以也可以在后面跟上自己的宾语。 过去分词 过去分词和现在分词一样，具有形容词或副词的功能，在句子中一般充当状语、定语、表语或补语。 现在分词和过去分词的区别。 一般来说，现在分词表示与其被修饰词之间是主动的关系，同时强调其动作时正在发生的；而过去分词则截然相反，它一般表示与其被修饰词之间是被动的关系，切强调动作为已经完成了的。 独立主格结构 独立主格结构是由名词/代词（逻辑主语部分）+逻辑谓语部分组成的，其逻辑谓语部分可以是现在分词、过去分词、不定式或介词短语。独立主格结构一般用于逻辑主语与句子的真正主语不同的句子中。 \r\r \r\r时态 \r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:45:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"概述 在英语中，动词时态的用法是尤其复杂和富于变化的。经常通过动词词尾、助动词等的变化来表明动作发生时间的先后顺序——即时态。总的来说，英语中动词的时态分为三个基本类型：过去、现在和将来。动词时态的变化常常伴随着相应的表示时间或频度的状语。 He often goes to the Great Wall. He went to the Great Wall yesterday. He will go to the Great Wall tomorrow. \r判断谓语动词的时态，除了借助于时间或频度副词之外，通常还要考虑句子的上下文，利用各个动作的时间先后或因果关系来确定动词的时态。 He tells me he plays table tennis well.（他现在打得好） He told me he played table tennis well.（他过去打得好） He told me he plays table tennis well.（他现在仍然打得好） \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:46:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"一般现在时 一般现在时可用于陈述现在时间内发生或存在的事件、动作或情况。这些事件、动作或情况也可能会无限期地延续下去。 一般来说，一般现在时可以用于以下几种情况： 一般现在时可以陈述永恒的真理。 Summer follows spring. 一般现在时可用于现阶段内发生的情况。 My father works in a school. 表示习惯性动作，通常表示不断重复的动作。 I get up at 7:00 a.m. 当谈论的是关于时间表、节目单或日程表上所安排好的事情的时候，通常用现在时表示将来的意义。 The exhibition opens on January 1st and closes on January 31st. 一般现在时中，当主语为第三人称单数时，其谓语动词后面要加-s，变化方法如下： 多数动词一般在词尾直接加-s，如：buy, buys 以字母-o, -s, -x, -ch, -sh结尾的动词词尾加-es，如：do, does 以辅音字母+-y结尾的动词变y为i，再加-es。如：fly, flies \r当使用了频度副词，如always、never、usually、rarely…副词短语every day, every week…，这种现在时可使习惯性动作表现得更加明显。 I sometimes stay up till midnight. She visits her parents every day. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:47:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"一般过去时 一般过去时通常表示过去某一时间发生的而现在已经结束的动作、事情或状态，常和表示过去某一时间的状语yesterday、just now， at that time…连用 In the early days of the settlement of Australia, enterprising settlers unwisely introduced the European rabbit. 动词过去式的构成规则 在动词原形后直接加-ed。如：open, opened 动词以-e结尾，则只加-d。如：die, died 动词以辅音+-y结尾，则去-y再加-ied。如：try, tried 规则动词过去式词尾-ed的读音 在以浊辅音或元音结尾的动词后读[d]。如：saved 在以清辅音结尾的动词后读[t]。如：shopped, asked 在以-t或-d结尾的动词后读[id]。如：visited, wanted 不规则动词（约150个）与规则动词不同，它们的过去式基本上无规则可循，需记忆。如：sit, sat 一般过去时通常和表示过去的时间连用，有时没有具体的过去时间，需要通过上下文判断时间。 I travelled to Portsmounth by bus yesterday. I got on the bus and sat down. 若所给信息影响了时间限定，则必须给出时间状语。 I received the magazine I ordered last week. 时间状语从句可以起到描述过去时间背景的作用。 When the article arrived, the editor read the first sentence and then refused to publish it. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:48:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"一般将来时 一般将来时通常由shall, will或be going to加上动词原形构成。will可用于所有人称，shall只用于第一人称。在口语中，shall和will的区别常被忽略，因为他们的缩略形式都是'll I shall/will see you tomorrow. I’ll see you tomorrow. 在口语中，缩略形式'll常用于代词之后。如：He’ll wash these dishes soon. 否定式will not和shall not的缩略形式分别为won’t和shan’t。如：I/We won’t/shan’t go to the market. be going to表示将来的用法 在非正式文体中，表示意图、打算时，一般将来时多用be going to而不常用will。 表示将来而不借助于时间状语来表达时，这种情形常指马上或不久的将来。 也可与表示将来的时间状语连用。 可用来代替直接表达打算的动词 在条件句中一般将来时通常由一般现在时表达，即主句为一般将来时，从句为一般现在时。 If he is out, I**’ll** call tomorrow. I **shall** wait here until he **comes**. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:49:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"现在进行时 现在进行时由be+动词的现在分词构成。它表示说话时正在进行的动作或事件，往往与now、at the moment、just…表示现在的时间状语连用。 Someone’s knocking at the door. Can you answer it? 现在进行时也可以描述暂时的情况或动作，强调这一动作或情况短时间内正在进行。 What’s your son doing these days? 现在进行时在与副词always、constantly、continually、forever、perpetually、repeatedly…连用时，表示不断重复的动作。 She’s always helping people. 现在进行时所描述的动作或事情发生得过多时，则有时含有抱怨的意思。 Our burglar alarm is forever going off for no reason. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:50:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"过去进行时 过去进行时表示过去某时正在进行的动作或状态，不一定需要时间状语。 His wife was sitting beside him holding a large cake. 过去进行时和以all开头的状语(all night)一起使用，强调动作的连续性。 It was raining all day. 过去进行时表示某事发生前已经开始的动作。在这种情况下，过去进行时常和一般过去时在同一个句子里使用。过去进行时表示当时正在进行的动作或情况，一般过去时则表示比较短暂的动作或事件。正在进行中的动作或情况常常和连词when、as、just as、while…等引导的时间状语从句连用。 When I was watering the garden, it began to rain. 过去进行时表示并行的动作，经常与while或at the time连用，强调同时进行的两种或几种动作。 While I was working in the garden, my wife was cooking dinner. meanwhile经常用于描述正在进行的动作。 Meanwhile, the editor was getting impatient, for the magazine would soon go to press. 过去进行时和used to 在使用时应注意的问题 过去进行时表示过去某个时间正在发生的动作；而used to +不定式表示一个动作或状态时过去的习惯，但并没有持续到现在。 I used to go to work by bus, but I go by car now. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:51:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"现在完成时 现在完成时主要有以下几种方法： 表示开始于过去并持续到现在的动作（也许还会持续下去）。它常和for+一段时间或since+某个时间点连用。 He has been there for six months. 表示在过去不确定的时间里发生但对现在仍有影响的动作。 I have read the book, but I don’t understand it. 表示刚刚完成的动作，可以与recently、just等连用。 I have been reported in Russia Recently of people who can read and detect colours with their figers, and even see through solid doors and walls. 表示最近发生的动作，常和副词already(用于肯定句)和yet(用于否定句和疑问句)连用。 Has she arrived yet? 描述重复动作 Historians have long been puzzled by dots, lines, ans symbols which have been engraved on walls, bones, and the ivory tusks of mammoths. 表示结论性的陈述也常常使用现在完成时 On the whole, business has been very good this year. 在现在完成时中，要注意have gone和have been的区别 He has gone to Alice Springs.（在那儿或在去那儿的路上） He has been to Alice Springs.（曾经去过那儿，但现在不在那） 一般过去时和现在完成时的区别 一般过去时的时间概念时明确的，我们关心的时过去的时间或过去的结果。而现在完成时的时间概念有时是不明确的，我们所关心的是现在的结果，或过去发生的事对现在的影响。 \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:52:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"过去完成时 过去完成时的主要用法时表示两个事件中过去一个动作开始之前另一个动作已经完成，前面发生的动作用过去完成时来表示。 The patient had been dead when the doctor arrived. 当句子中有after等能够暗示时间先后顺序的状语从句出现时，通常可以明确地说明主句与从句动作的先后关系。如果主句为过去时，那么从句中的动作就形成了过去的过去，因此表示从句动作的动词常常使用过去完成时。 After her husband had gont to work, Mrs. Richards sent her children to school and went upstaits to her bedroom. 但在谈及过去不同时间所发生的的两个动作时，并非总是要将先发生的动作用过去完成时表示。当按动作发生的顺序进行描述时，通常使用一般过去时即可。 Mary said some tather norrible things to me; I felt pretty upset, but tried not to think about thme too much. 当我们要强调过去时间以后的动作，而只想将发生再次动作之前的动作作为临时性过渡时，这一动作通常用过去完成时表达。这样使用时，并没有强调多去完成时表达的动作之意。 I felt pretty upset because of what Mary had said, but I tried not to think about it too much. 在过去完成时中，表示之前概念时不能使用ago，而必须使用before。因为前者用于表示时间的起点是现在，而后者描述的时间起点则为过去的时间概念。因此，前者一般适用于一般过去时，而后者可以用于过去完成时。 A week before, he had completed a successful overland flight furing which he covered 26 miles. 过去完成时的作用有时完全相当于现在完成时的过去形式，在间接引语中这种情况尤其多。 Juliet is excited because she has never been to a dance before. Juliet was excited because she had never benn to a dance before. 过去完成时被动语态为had+been+过去分词。 When she came, the room had already been cleaned. no sooner…than和scarcely/barely/hardly…when表示某件事仅随着另一件事发生。 \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:53:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"现在/过去完成进行时 现在/过去完成进行时由have、has/had been + 现在分词构成，所描述的动作主要强调以下几种情况： 表示动作在某一段时间内一直在进行 She is very tired, she’s been typing letters all day. 表示持续性的动作 I have been learning English. 表示经常重复的动作 Jim has been phoning Jenny every night for the last week. 描述通过直接或间接的证据得出的结论。 Your eyes are red. You’ve been crying. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:54:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"过去将来时 过去将来时是由was/were going to, was/were about to, was/were to, was to have + 过去分词, was/were on the point of, was/were due to和would等来表示。 We were about to leave when a car drove up. 表示无法预见结果 Little did they know they were to be reunited ten years later. 过去将来时也可以表示过去因故中断的动作，通常用just ... when形式 We were just going to leave when Jean fell and hurt her ankle. was going to和was to have + 过去分词的异同 I was going to see Mr. Kay. 我要去看凯先生（可能见到，也可能没见到） I was to have seen Mr. Kay. 我本来要去见凯先生（没有见到他） \r\r \r\r被动语态 \r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:55:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"概述 在英语中，语态分为两种：主动语态和被动语态，它们都是指动词的形式而言。在主动句中，句子的主语时执行动作的人或物。 John cooked the food last night. 在主动语态中强调的是执行动作的人或物，即主语时动作的执行者；而在被动语态中强调的是接受动作的人或物，即主语时动作的承受者。 This bridge was built in 1942. 被动语态所强调的是动作的承受者而不是动作的执行者。因此，有时为了把话说得谨慎些，可以使用被动语态。 Muriel pays less income tax than she should. 为了使句子的结构更加平稳、严谨，经常使用下列三种被动结构： It is/was + 动词过去分词 + that 引导的从句 It is said that there is plenty of oil off our coast. There + 动词 + to be + 补足语 There is suppsed to be a train at 12:37. 除it意外的主语 + 动词 + 带to的动词不定式 Tuner was considered to be a genius even in his lifetime. 被动语态所强调的对象是动作的承受者，即行为客体。如果需要说明动作的执行者即行为主体时，常常可以用by+行为主体的结构表示。 The windows was broken by the boy who lives opposite. It was composed by Mozart. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:56:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"被动语态的构成 在被动语态中，句子的主语是动作的承受者。被动语态的形式由相应的助动词加上动词的过去分词构成。 The food was cooked last night. 被动语态的构成形式分为： 一般现在时的被动语态: am/is/are + 过去分词 一般过去时的被动语态: was/were + 过去分词 现在进行时的被动语态: am/is/are + being + 过去分词 现在完成时的被动语态: have/has + been + 过去分词 过去进行时的被动语态: was/were + being + 过去分词 一般将来时的被动语态: be going to/ will/ shall + be + 过去分词 过去完成时的被动语态: had been + 过去分词 \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:57:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"不定式的被动语态 在主语+谓语+宾语+不定式结构中，当动词时被动语态时，其后的不定式可保持主动语态。 He told me/I was told to wait for him. 当含有被动含义时，不定式本身能变成被动语态。 He never expected te bicycle to be found. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:58:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"情态动词的被动语态 情态动词的被动语态是在will, can, must等情态动词后加 be + 过去分词构成。 Your watch will/can/must/should be repaired. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:59:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"分词结构的被动语态 现在分词的被动语态由being+过去分词构成，它的完成式由having been + 过去分词构成。 He hates to be criticized. I was worried about you all night. \r\r \r\r直接引语和间接引语 \r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:60:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"直接引语 一字不改地引述别人的话，叫直接引语。 “Why don’t we go sailing?” Diana said. 如果通过第三者进行转述，可以不用引号。 Diana suggested they should go sailing. 当把直接引语变为间接引语的时候，人称、时态、时间状语、地点等通常都应发生相应的变化。 \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:61:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"间接引语 说话人用自己的话转述别人的话，叫间接引语。间接引语需要由动词引述，因此这种动词称为引述动词。如say、tell、ask、declare… 动词tell、say…通常引述间接引语。tell后面必须跟人称间接宾语(tell sb…)，而say后面则可跟或不跟to引导的讲话对象。 He tells me/syas to me (that) he’s very busy. 直接引语变成间接引语时，其谓语动词时态变化规则如下： 当引述动词为现在或将来时态时，间接引语的时态不变。 He says, “I’m tired.” He says he is tired. 当引述动词为过去时态时，间接引语的时态则一般应作为相应的变化，即时态的呼应。规则如下： 直接引语中的一般现在时，间接引语要变成一般过去时。 He said, “I never work on Sundays.” He said he never worked on Sundays. 直接引语中的现在完成时，在间接引语中要变为过去完成时。 Sylvia said, “I’ve moved to another flat.” Sylvia said (that) she had moved to another flat. 直接引语中的一般过去时，在间接引语中则通常变为过去完成时，当然不排除仍用一般过去时。 “I moved to anther flat,” she said. She said she moved to another flat. 直接引语为现在进行时，间接引语变为过去进行时。 She said, “he’s waiting.” She said (that) he was waiting. 直接引语为过去进行时和过去完成时，间接引语变为过去完成进行时或不变。 “I was waiting for hours before you arrived,” he told Harriet. He told Harriet that he had been waiting for hours before she arrived. 直接引语为一般将来时，间接引语为过去将来时。 “Where are you going?” he asked. He asked (us) where we were going. 直接引语为含情态动词的一般现在时，间接引语中情态动词变为一般过去时，如: shall/will变为would; can变为could… “I can/will/may see you later,” he said. He said he could/would/might see me later. 当must指过去时，可以不变；如果是指“不可推卸的义务”时，在间接引语中也可由had to代替。 “I must warn you of the consequences,” He said. He told me (that) he must/had to warn me of the consequences. 如果直接引语内容为普遍真理，主句谓语时过去时，变成间接引语时，引语部分时态不变。 “Light travels faster than sound,” the teacher said to his students. The teacher told hist students that light travels faster than sound. 直接引语变成间接引语时，人称、指示代词、时间状语、地点状语也应有相应的变化。 代词的变化 I-\u003eshe/he, me/you-\u003ehim/her/I… 时间状语的变化 now-\u003ethen, ago-\u003ebefore… 地点状语的变化 here-\u003ethere, this place-\u003e that place… 直接引语为特殊疑问句，在变为间接引语时，其引导词应用疑问代词或特殊副词。ask可以转述疑问句，包括一般疑问句和特殊疑问句。 “When will Jack arrive?” Tom asked. Tom asked when Jack would arrive. 除了ask之外，转述疑问句(包括一般疑问句和特殊疑问句)的动词还可以是want to know, see, say, tell, wonder, inquire(较正式) 如果直接引语为选择疑问句，变为间接引语时，应有whether…or… They asked me whether I was ill or not. They asked whether I was ill or just lazy. 如果直接引语为一般疑问句，间接引语中用if或whether引导。 “Have you been abroad?” Mary asked. Mary asked me whether we had been abroad. 当直接引语为祈使句时，间接引语中通常要用tell, order, command, ask等代替直接引语中的say，并且动词后要用“名词/代词+不定式”结构。 “Open the door for me, please.” She said (to me). She asked me to open the door for her. 动词insist和suggest不能用于“名词/代词+不定式”结构，其后通常要跟一个“that从句+(should)+动词原形”的结构。 “You really must stay and have lunch,” he said. He insisted that I (should) stay to have lunch. \r\r \r\r倒装句 \r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:62:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"概述 倒装句分为： 完全倒装句：指谓语动词完全在主语之前； 部分倒装句：通常是说相应的助动词在主语前面，而谓语动词仍在主语后面。 Here comes the taxi! （The taxi comes here.） Seldom did I go to the cinema.（助动词did提到主语前） \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:63:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"完全倒装句 当地点副词如here、there以及back、down、off、up…在句首时，要求句子为完全倒装。 Down came the rain and up the umbrellas. 但是，当主语为代词时，主谓并不倒装。 There comes the bus.（主语为名词，主谓应倒装） There she goes.（主语为代词，主谓不倒装） 地点状语在句首时一般也要完全倒装。 At the top of the hill stood the tiny chapel. 定语从句中，也有少数情况适用这个规则。 We arrived at a farm house, in front of which sat a girl. 此规则也适用于被动语态。 In the distance could be seen the purple mountains. \r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:64:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"部分倒装句 当表示否定概念的副词，如：little, seldom, hardly, scarcely, never…，在句首时，要求使用部分倒装句。部分倒装句指的是谓语动词位置不变，而其相应的助动词要放在主语前面。 Little does he realize how important this meeting is. 但是，当否定副词不在句首时，则不倒装。 Never do cats fail to facinate human beings. 当only修饰状语或状语从句时，要求部分倒装；但当only不修饰状语而修饰其他成分时，则不倒装。 The pilot reassured the passengers. Only then did I realize how dangerous the situation had been.（修饰时间状语，因此需要倒装） Only girls are permitted to enter the theatre.（only修饰名词girls，所以不倒装） 关于so和such的倒装句 so和such在句首时也可引起部分倒装，通常可以分为两种情况： so+形容词+从句/such+从句 So sudden was the attack (that) we had no time to escape. 在表示与前面句子有相同情形时，常用\"so+倒装\"结构 He likes fishing. So do I. 当前面的句子为否定形式时，则应用\"neither/nor+倒装句\"，而不是使用\"so+否定形式\"。 She doesn’t like dancing, nor/neither do I. 当前面句子中的动词出现并列，而且形式不统一时，后面的句子需要用so it is/was with结构。 He was once a soldier and enjoyed hunting, so it was tieh me. 在as引导的让步状语从句中，需要倒装其表语、宾语或状语部分。 Much as we may pride ourselves on our good taste, we are no longer free to choose the things we want. \r\r \r\r虚拟语气 ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:65:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"概述 虚拟语气一般表示说话人的主观愿望、推测等，而非客观情况，常用在非真实条件句当中。 # 非客观事实 How I wish I were a bird. If I were you I would buy this book. \r\r\r","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:66:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"虚拟语气的基本形式 虚拟语气根据其所表达意思的不同也有各种时态的变化。 如果所描述的情况与目前事实不符，用现在虚拟语气； 所描述的情况与将来的情况可能不符时，用将来虚拟语气； 而当所描述的情况与过去发生的情况不符时，则用过去虚拟语气。 主/从句中的动词形式 时态分类 主句中的动词形式 从句中的动词形式 与现在事实相反 should/would/could/might + 动词原形 动词的过去式(be一般用were) 与将来事实相反 should/would/could/might + 动词原形 动词的过去式、were to + 动词原形或should + 动词原形 与过去事实相反 should/would/could/might + 动词的现在完成式 动词的过去完成式 # 与现在事实不符 If I were you, I should try it again. If you had gone to the exhibition, you would have enjoyed it. might/should/ought to + 动词的完成时态 结构表示过去可能发生而没有发生的事情。 We should have caught the first train if we had got up earlier. wish与if only引起的虚拟语气 在英语中，可用wish或短语if only表示愿望，两者往往可以互换。if only侧重于强调所希望的情况并不存在；而wish则通常表示所希望的事情有可能发生。 I wish/If only Tessa were here now. I wish you wouldn't. I wish he would come tomorrow. ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:67:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"宾语从句中的虚拟语气 当wish, would rather/had better后接宾语从句，或在 It’s time that从句结构中，要使用虚拟语气，其虚拟语气的动词应为过去式/过去完成式，表示与现在/过去事实相反。 I wish you saw the exhibition. I'd rather she sat next to me. would rather/sooner + 从句时，从句通常使用虚拟语气。 I would rather Jack take the former train. would rather/sooner + 从句结构也可以用于表示和过去的情况相反。 I'd rather he hadn't told me about it. suggest, propose, advise, insist, command, order, require, request和recommend等动词，在引导宾语从句时通常使用虚拟语气。 上述动词一般表示使令概念，因此它所要求的宾语从句当中的动作未必一定能实现，符合虚拟语气所表达的概念特点，其虚拟语气的谓语动词为should + 动词原形，但should常可以省略。 To save time, I suggest we meet at the restaurant. ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:68:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"主语从句中的虚拟语气(It’s vital/essential + that 从句等引导的虚拟语气) 表示重要、必要等意义的形容词，如important， vital，essential，necessary，desirable等，从句中的谓语用should + 动词原形。 Was it essential that my uncle be informed? It is vital that we should control the spread of malaria. ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:69:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"由as if/though 引导的虚拟语气 当as if/though 进行非事实的比喻或夸张时，经常可以引导虚拟语气。 The old machine runs as if it were a new one. He talked about Japan as if he had been there for many times. as if也可以用在句首，表示惊讶、不满、气愤的语气。 As if we were all stupid and he alone clever! 如果as if表示的是一种真实的情况，应该用正常语气。 It looks as if it is going to rain soon. ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:70:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"虚拟语气中的倒装结构 在虚拟条件中，可以使用倒装结构的形式代替if。 Should you change your mind, let us know. Had I realized what you intended I should not have wasted my time trying to explain matters to you. it的用法 ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:71:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"it作非人称代词 it指前面已经提到过的人或物时，作真实主语。 What a beautiful baby, is it your nephew? it在句子当中作非人称代词时，常常用来表示时间、天气、温度、度量衡、距离等，因为在这种情况下它没有实际意义。 适用范围 栗子 时间、季节 It’s Spring Festival today. 天气、气候 It’s hot, though it’s raining. 温度 It’s 33 centigrade in the room. 距离、度量 It’s 10 KM to Paris. 环境 It’s noisy in here. 现状 Isn’t it a shame! 与since/says等连用 It’s 3 years since we last met. It says there was an earthquake in Japan yesterday. ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:72:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"it作形式主语 当不定式、动名词或名词从句作主语时，为了使句子的结构更加平稳、对称，我们经常使用it作形式主语，后面接不定式、动名词或名词从句作真正主语。 It is pleasant to lie in the sun. It doesn't matter when we arrive. ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:73:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"it用在强调句中 强调句也叫分裂句，它通常可以用于强调某个词或短语。其结构为It is/was + 被强调的对象 + that 或 who(m)从句，其中that可用于引导强调任何内容的从句，who(m)只用于强调人的从句。 It was Freda who/that phoned Jack last night. It was last night that Freda phoned. ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:74:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"it作形式宾语 it + 形容词 可用在像find一类的动词之后作形式宾语或先行宾语，再接作真正宾语的动词不定式或that引导的从句。 Tom finds it diffcult to concenrate. Jones thinks it funny that I've taken up yoga. ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:75:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"it的一些搭配 it还可用在enjoy, like, love, hate等动词后。 I don't like it when you shout at me. ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:76:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"It seems that/is possible that从句 这种从句中it常常充当先行主语。 It seems that he forgot to sign the letter. 句子 ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:77:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"概述 句子是一个完整的意义表述单位，通常由主语和谓语动词及其它附加成分组成。句子的主语可能藏而不漏。 They arrived. Open the door, please. 由一个单词构成的或缩略的话同样也是一个完整的意义单位，特别是在口语或书面对话中尤为常见。 Good. All right! Want any help? 就其功能来说，句子是可以在基本句型的基础上进行扩充的。 The man ran away. The man who stole the money ran away. ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:78:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"简单句 简单句是最小的句子单位。简单句一般只有一个谓语动词，并且由一个主谓结构组成。 Last week I went to the theatre. 简单陈述句的语序很重要，否则表达的意思不同。 The police arrested the thief. The thief arrested the policeman. 一个简单陈述句可以包含五个部分： 主语、谓语、宾语或表语、补语、状语。状语可以根据需要放在句尾、句中或句首。 I(主) enjoyed(谓) the film(宾) yesterday(状). They(主) appointed(谓) him(宾) chairman(宾补). 有时，简单句中主语、谓语及宾语会通过连词(and, or, but, both and, either or, neither nor等)串接起来，从而形成主语、谓语、宾语并列的形式。 The boss and his secreteary(并列主语) are flying to Paris. I met Jane and her husband(并列宾语). We sang and danced(并列谓语) all night. 在英语中，状语是使用最频繁和最富变化的，它能使语言描述更加具体、形象、生动。 In those days(时间状语) wandering minstrels(主语) were welcome(谓语) everwhere(地点状语)。 Editors of newspapers and magazines(主语) often(频度状语) go to extremes(谓语) to provide their readers(目的状语) with unimportant facts and statistics(方式状语). 英语中常会出现同位语，它通常与所说的此有对等的关系。 This was the Vasa, royal flagship of the great imperial fleet. 根据动词后面所使用的不同成分，简单句可分为五种基本句型。 # 主语+动词 My head aches. # 主语+动词+主语补足语 # 主语补足语通常出现在被动语态中。当还原为主动语态时，主语补足语则变成宾语补足语。 Trump was made President of the U.S.A. Americans make Trump President of the U.S.A. # 主语+动词+直接宾语 My sister enjoyed the play. # 主语+动词+间接宾语+直接宾语(双宾语) # 直接宾语一般表示物，而间接宾语则表示人 # 通常间接宾语在前，直接宾语在后 The firm gave Sam a watch. # 主语+动词+宾语+宾语补足语 They made Sam chairman. ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:79:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"并列句 并列句一般是由并列连词(and, but, so, yet等)，分号或分号后跟一个并列连接副词(however, above, all, as far as等)，将两个或两个以上的简单句连接而成。 # 用并列连词连接 You can wait here adn I'll get the car. # 用分号连接 We fished all day; we didn't catch a thing. # 分号后再跟连接副词 We fished all day; however, we didn't catch a thing. 并列句中不存在单独的主句和从属于它的从句。各并列句根据上下文的要求按逻辑顺序排列，但各个并列句均同等重要并且独立存在。 The swimmer seemed to be in diffculty, but he managed to reach the shore in the end. I saw him yesterday but he did not greet me. ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:80:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"复合句 英语中复合句的使用最为广泛，在书面语中更是如此。 复合句的构成方法通常是用从属连词，如if/unless引导条件状语从句、because/as/since表示原因、when/while/as soon as/until表示时间、where表示地点、although/though/as表示让步…把简单句连接起来。其中包括一个独立的简单句(主句)和一个或几个从属简单句(从句)。主句可以单独存在。 The alarm was raised(主句) as soon as the fire was discovered(从句). 复合句从其作用上来说大致分为三个类型。 # 状语从句 However hard I try, I can't remember people's names. # 名词性从句 He told me (that) the match had been cancelled. # 定语从句 All the things (that) I had packed so carefully were soon in a dreadful mess. ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:81:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"状语从句 状语从句在句子中可以说明事情发生的时间、地点、原因、方式、结果、目的等，用相关的从属连词引导。 The children ran away after they had broken the window. As soon as the sun set we returned to our hotel. He missed the train because he did not hurry. 时间状语从句 时间状语从句一般回答when的问题，并且可以由下列从属连词引导(when, after, as soon as, before, by the time…)当状语从句位于句首时，后常用逗号隔开。 You didn't look very well when you got up this moring. When he got married, Alf was too embarrassed to say anything to his wife adout his job. Whenever I meet his, he always talks about his personal problems. The moment he arrives, I shall let you know. 地点状语从句 这类从句回答where的问题，可由where， wherever, anywhere等连词引导。地点状语从句一般置于主语之后。 You can't camp anywhere you like these days. Everywhere Jenny goes she's mistaken for Princess Diana. 方式状语从句 这类从句回答how问题，它可以由as和(in) the way引导。方式状语从句一般置于主句之后。be, act, appear, behave,sound…等后面通常用as if 和 as though。 I feel as if/as though I'm floating on air. It feels as if it's going to rain. The fish isn't cooked as I like it. 原因状语从句 原因状语从句回答由why引导的问题，由以下从属连词(because, as, seeing, since…)引导。 As/Because/Since there was very little support, the strike was not successful. I'm afraid we don't stock refills for pens like yours because there's little demand for them. 条件状语从句 条件状语从句表示动作发生的条件，通常由连词(if, on condition that, unless, as/so long as…)引导。 If you see him, will you tell him about it? If I lose my job, I will go abroad. If the weather clears, we'll go for a walk. If you went to the exhibition you would enjoy it. If I had been in your position, I would have acted differently. If it rains tomorrow, we'll stay at home. 让步状语从句 让步状语从句含有使句子有对比的意义。引导让步状语从句的常用连词有: although, considering, though/as, even if, even though, while, whereas, no matter how, however… While I disapprove of what you say, I would defend to the death your right to say it. I told him to report to me after the job was completed, no matter how late it was. # though多用于正式的口语或书面语， although用于各种文体 Although/Though the factory is small, its products are of very good quality. ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:82:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"名词性从句 名词性从句在句子中起名词的作用，可以作主语、宾语、表语及同位语。因此从功能上将其定义主语从句、宾语从句、表语从句和同位语从句。 主语从句 主语从句通常由which, who, that, what, when, where, whether等引导，在句子当中一般充当主语。 Whether we find a joke funny or not largely depends on where we have been brought up. It has been said that everyone lives by selling something. 宾语从句 名词性从句作宾语时，前面的that经常被省略，特别是在非正式文体中更是如此。 Everyone knows (that) money doesn't grow on trees. 同位语从句 跟在fact, idea, news, information, thought…后面的名词性从句通常是同位语从句。同位语从句中的that不能省略且不作任何成分，从含义上来说，它对其所修饰的词具有同等解释的作用。 The fact that his proposal makes sense should be recognized. ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:83:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"定语从句 定语从句通常由关系代词(who, whom, which, that, whose)或关系副词(where, when, why)等引导。 从形式上来说，它通常分为两种情况: 限制性定语从句（它一般提供被修饰名词的重要信息，对中心词起修饰作用，不能省略。这种定语从句与其修饰的词之间一般没有逗号隔开。） 非限制性定语从句（它提供补充性信息，对其中心词起补充说明作用，可以省去。这种关系从句与其所修饰的词之间一般要有逗号隔开。） # 限制性 The government which promises to cut taxes。 # 非限制性 The government, which promises to cut taxes, will be popular. 定语从句中关系代词和关系副词的使用是有严格的界限和规定的。 定语从句中常用的关系代词有that(指人或物，在从句中充当主语或宾语)、who(指人，在从句中充当主语)、whom(指人，在从句中充当宾语)、which(指物或修饰整个句子)、whose(所指对象不限，在从句中充当定语)、as(指事件或现象，在从句中充当主语或宾语)。关系副词有(where, when, why…)。 在表示时间、地点、原因的限制性及非限制性定语从句中，可以使用关系副词when, where, why。这些关系副词在定语从句中作状语。 1989 was the year when (in which) my son was born. She knows a wood where (in which) we can find wild strawberries. 在有些情况下，不管先行词是表示人还是物，只要指代它的是关系代词，即在剧中不作状语，就只用that而不用which或who/whom。 I'll do anything (that) I can. Bach is the greatest composer that's ever lived. Which is the flower that you just watered? 在所有的关系词中as的用法最为特殊。它主要有以下三种用法: # 当从句的先行词前有有such或the same时，必须使用as。 I haven't seen such a good painting as you described just now. # as可像which一样引导一个定语从句修饰整个线性主句，而不是某一个单词。 Taiwan belongs to China, as is known. # as是关系词中唯一可以置于句首的关系词。 As is known., Taiwan belongs to China. ","date":"2018-11-14","objectID":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/:84:0","tags":["English","Grammar"],"title":"英语语法","uri":"/%E8%8B%B1%E8%AF%AD%E8%AF%AD%E6%B3%95/"},{"categories":["english"],"content":"参考： 国际音标维基 巴士英语网: https://en-yinbiao.xiao84.com/yinbiaofayin/ 知乎@姜枣茶茶母的回答: https://www.zhihu.com/question/19913374 \r\r\r\r介绍 英语发音有多个国家的区别，我们重点了解两个： 公认发音，英国标准（Received pronunciation, RP） 通用美式英语（General American, GA） 国际音标(International Phonetic Alphabet，缩写：IPA)旁边的分隔号和括号并非音标的一部分，它们是语言专家用以分辨两个主要标音方法：音位标音和语音学标音。 48个国际音标通常是国内学生学习英语、学好英语发音必须掌握的发音基础，48个国际音标表也被称作48个音标表、48个英语音标表、48个英语国际英标表，48个国际英语音标表，这些称呼通常都是指48个英语国际英标表。 48个国际音标中有20个元音、28个辅音。 元音，又称母音。 元音是在发音过程中由气流通过口腔而不受阻碍发出的音。 按前后分类为高 、中、低元音。 按音节分，可分为单元音和双元音。 气流在口腔或咽头受到阻碍而形成的音叫做辅音，辅音又叫子音。 共分为清辅音、浊辅音、鼻音、舌侧音 、半元音五种不同类型。 其中鼻音、舌侧音 、半元音为浊辅音。 英语元音和辅音在英语发音中扮演着重要的角色，英语元音和辅音组合起来就成为英语音标，共48个音位，是英语发音的基础。 \r\r \r\r发音与技巧 巴士英语网有每个音标的发音: https://en-yinbiao.xiao84.com/yinbiaofayin/ 国际音标： 1 2 3 4 元音 单元音 双元音 前元音 中元音 后元音 开合双元音 集中双元音 /iː/, /ɪ/, /e/, /æ/ /ɜː/, /ə/, /ʌ/ /uː/, /ʊ/, /ɔː/, /ɒ/, /ɑː/ /eɪ/, /aɪ/, /ɔɪ/, /aʊ/, /əʊ/ /ɪə/, /eə/, /ʊə/ 辅音 爆破音 摩擦音 破擦音 鼻音 舌则音 半元音 清辅音 浊辅音 清辅音 浊辅音 清辅音 浊辅音 浊辅音 浊辅音 浊辅音 /p/, /t/, /k/ /b/, /d/, /ɡ/ /f/, /s/, /ʃ/, /θ/, /h/ /v/, /z/, /ʒ/, /ð/, /r/ /tʃ/, /tr/, /ts/ /dʒ/, /dr/, /dz/ /m/, /n/, /ŋ/ /l/ /j/, /w/ 1 2 3 元音20个 长元音 短元音 双元音 /iː/, /ɑː/, /ɔː/, /uː/, /ɜː/ /ɪ/, /ʌ/, /ɒ/, /ʊ/, /ə/, /æ/, /e/ /eɪ/, /aɪ/, /ɔɪ/, /ɪə/, /eə/, /ʊə/, /aʊ/, /əʊ/ 辅音28个 轻辅音 浊辅音 轻辅音 浊辅音 鼻音 半元音 边音 /p/, /t/, /k/, /f/, /θ/, /s/ /b/, /d/, /ɡ/, /v/, /ð/, /z/ /ʃ/, /h/, /ts/, /tʃ/, /tr/ /ʒ/, /r/, /dz/, /dʒ/, /dr/ /m/, /n/, /ŋ/ /j/, /w/ /l/ \r\r\r","date":"2018-11-13","objectID":"/internationalphoneticalphabet/:0:0","tags":["English","国际音标"],"title":"国际音标","uri":"/internationalphoneticalphabet/"},{"categories":["english"],"content":"知识点讲解 长短元音的区别在于——是否有: 有，则拖长音节 无，则短促音结尾 双元音就是把两个单元音拼到一起 发音也是两个拼到一起的，如： /iə/= /i/ + /ə/ /uə/= /u/ + /ə/ /εə/= /e/ + /ə/ 清浊辅音的区别在于——喉结是否震动 震动，浊辅音 不震动，清辅音 鼻音–鼻腔发出 \r\r\r","date":"2018-11-13","objectID":"/internationalphoneticalphabet/:1:0","tags":["English","国际音标"],"title":"国际音标","uri":"/internationalphoneticalphabet/"},{"categories":["english"],"content":"难读的音标 易出问题的地方： 核心技巧： 用中文的音近字代替 用简单的英文字母或单词进行备注 中文字很挫，两种方法结合使用，哪个好记用哪个。 元音部分发音讲解： /ei/ ：A /ai/ ：I /ɔi/ ：“噢一” /iə/ : /i/ + /ə/ = ear /eə/ : /e/ + /ə/ = air /uə/ : /u/ + /ə/ = 污饿 /əu/ ：O /au/ ：嗷（张大嘴） 辅音部分发音讲解： 第一组：/s/, /z/ 和 /θ/, /ð/ 这两组发音听起来差不多，唯一的区别在于：舌头是否看得见 看不见，/s/, /z/ 看得见，/θ/, /ð/ 第二组：/ʃ/, /ʒ/ “屎” “日” 第三组：/h/, /r/ “喝” “弱” 第四组：/ts/, /dz/ “此” “滋” 第五组：/tʃ/, /dʒ/ “尺” “之” 第六组：/tr/, /dr/ “戳” “捉” 第七组：/m/, /n/, /ŋ/ 都是发**“嗯”**的音，只是嘴型大小不一样。 /m/, 闭紧 /n/, 半张开 /ŋ/, 张大嘴 第八组：/l/ 这个音最难发，因为声音有点奇怪，像大舌头。发音技巧在于，把舌尖抵在上门牙底端，然后自然发出声音，就是这个音标啦。 知识点讲解 /m/, /n/, /l/ 分别有两个发音，一个是上面讲解的发音，另一个是他们的本来音，即英文字母m/n/l的发音（么，讷，勒）。 本身发音： 出现在每个音节的开头 奇怪音： 出现在每个音节的中间 \r\r\r练习 自己找单词书进行测试和练习。 ","date":"2018-11-13","objectID":"/internationalphoneticalphabet/:2:0","tags":["English","国际音标"],"title":"国际音标","uri":"/internationalphoneticalphabet/"},{"categories":["frontend"],"content":"参考： Bootstrap中文文档: https://v3.bootcss.com/ 环境： CentOS7x86_64 Bootstrap v3 \r\r \r\r概述 Bootstrap是最受欢迎的HTML、CSS和JS框架，用于开发响应式布局、移动设备优先的WEB项目。 Bootstrap让前端开发更快速、简单。所有开发者都能快速上手、所有设备都可以适配、所有项目都适用。 \r\r \r\r起步 ","date":"2018-09-18","objectID":"/bootstrap/:0:0","tags":["frontend","bootstrap"],"title":"Bootstrap","uri":"/bootstrap/"},{"categories":["frontend"],"content":"安装 \r\r\r","date":"2018-09-18","objectID":"/bootstrap/:1:0","tags":["frontend","bootstrap"],"title":"Bootstrap","uri":"/bootstrap/"},{"categories":["frontend"],"content":"包含的内容 Bootstrap 提供了两种形式的压缩包，在下载下来的压缩包内可以看到以下目录和文件，这些文件按照类别放到了不同的目录内，并且提供了压缩与未压缩两种版本。 Bootstrap 插件全部依赖 jQuery 请注意，Bootstrap 的所有 JavaScript 插件都依赖 jQuery，因此 jQuery 必须在 Bootstrap 之前引入，就像在基本模版中所展示的一样。 预编译版，预编译文件可以直接使用到任何 web 项目中。 bootstrap/ ├── css/ │ ├── bootstrap.css │ ├── bootstrap.css.map │ ├── bootstrap.min.css │ ├── bootstrap.min.css.map │ ├── bootstrap-theme.css │ ├── bootstrap-theme.css.map │ ├── bootstrap-theme.min.css │ └── bootstrap-theme.min.css.map ├── js/ │ ├── bootstrap.js │ └── bootstrap.min.js └── fonts/ ├── glyphicons-halflings-regular.eot ├── glyphicons-halflings-regular.svg ├── glyphicons-halflings-regular.ttf ├── glyphicons-halflings-regular.woff └── glyphicons-halflings-regular.woff2 Bootstrap源码，源码包含了预先编译的 CSS、JavaScript 和图标字体文件，并且还有 LESS、JavaScript 和文档的源码。 bootstrap/ ├── less/ ├── js/ ├── fonts/ ├── dist/ │ ├── css/ │ ├── js/ │ └── fonts/ └── docs/ └── examples/ \r\r\r","date":"2018-09-18","objectID":"/bootstrap/:2:0","tags":["frontend","bootstrap"],"title":"Bootstrap","uri":"/bootstrap/"},{"categories":["frontend"],"content":"编译CSS和JS文件 \r\r\r","date":"2018-09-18","objectID":"/bootstrap/:3:0","tags":["frontend","bootstrap"],"title":"Bootstrap","uri":"/bootstrap/"},{"categories":["frontend"],"content":"基本模板 这份超级简单的 HTML 模版，我们强烈建议你对这些实例按照自己的需求进行修改，而不要简单的复制、粘贴。 \u003c!DOCTYPE html\u003e \u003chtml lang=\"zh-CN\"\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\"\u003e \u003cmeta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"\u003e \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e \u003c!-- 上述3个meta标签*必须*放在最前面，任何其他内容都*必须*跟随其后！ --\u003e \u003ctitle\u003eBootstrap 101 Template\u003c/title\u003e \u003c!-- Bootstrap --\u003e \u003clink href=\"https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/css/bootstrap.min.css\" rel=\"stylesheet\"\u003e \u003c!-- HTML5 shim 和 Respond.js 是为了让 IE8 支持 HTML5 元素和媒体查询（media queries）功能 --\u003e \u003c!-- 警告：通过 file:// 协议（就是直接将 html 页面拖拽到浏览器中）访问页面时 Respond.js 不起作用 --\u003e \u003c!--[if lt IE 9]\u003e \u003cscript src=\"https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js\"\u003e\u003c/script\u003e \u003cscript src=\"https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js\"\u003e\u003c/script\u003e \u003c![endif]--\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003e你好，世界！\u003c/h1\u003e \u003c!-- jQuery (Bootstrap 的所有 JavaScript 插件都依赖 jQuery，所以必须放在前边) --\u003e \u003cscript src=\"https://cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js\"\u003e\u003c/script\u003e \u003c!-- 加载 Bootstrap 的所有 JavaScript 插件。你也可以根据需要只加载单个插件。 --\u003e \u003cscript src=\"https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/js/bootstrap.min.js\"\u003e\u003c/script\u003e \u003c/body\u003e \u003c/html\u003e \r\r\r","date":"2018-09-18","objectID":"/bootstrap/:4:0","tags":["frontend","bootstrap"],"title":"Bootstrap","uri":"/bootstrap/"},{"categories":["frontend"],"content":"实例精选 我们鼓励你根据自身项目的需要对 Bootstrap 进行定制和修改。 ","date":"2018-09-18","objectID":"/bootstrap/:5:0","tags":["frontend","bootstrap"],"title":"Bootstrap","uri":"/bootstrap/"},{"categories":["frontend"],"content":"框架基本用法 入门级模板(starter template) 只有基本的东西：引入了预编译版的 CSS 和 JavaScript 文件，页面只包含了一个 container 元素。 Bootstrap主题(theme) 加载可选的 Bootstrap 主题，获得增强的视觉体验。 栅格(grids) 多个关于栅格布局方面的实例，涉及到层级（tier）、嵌套（nesting）等等。 Jumbotron Build around the jumbotron with a navbar and some basic grid columns. Narrow jumbotron Build a more custom page by narrowing the default container and jumbotron. \r\r","date":"2018-09-18","objectID":"/bootstrap/:5:1","tags":["frontend","bootstrap"],"title":"Bootstrap","uri":"/bootstrap/"},{"categories":["frontend"],"content":"导航条实例(navbars) 导航条(navbar) 包含导航条和一起附加内容的超级基础的模板。 静态导航条(static top navbar) 包含一个静态导航条以及一些附加内容的超级基础的模板。 固定位置的导航条(fixed navbar) 这是一个超简单的页面，拥有一个固定在顶部的导航条和一些演示内容。 \r\r","date":"2018-09-18","objectID":"/bootstrap/:5:2","tags":["frontend","bootstrap"],"title":"Bootstrap","uri":"/bootstrap/"},{"categories":["frontend"],"content":"自定义组件(customed Components) 封面图(cover) 一个简单、漂亮的首页。 Carousel Customize the navbar and carousel, then add some new components. 博客页面(blog) 简单的两列式博客布局，还包含了自定义的导航、页头、分类等元素。 控制台(dashboard) 包含基本结构的后台管理模板，还有固定的侧边栏和导航条。 登录页(sign-in) 自定义的表单布局以及经过简单设计的登录表单。 Justified nav Create a custom navbar with justified links. Sticky footer Attach a footer to the bottom of the viewport when the content is shorter than it. Sticky footer with navbar Attach a footer to the bottom of the viewport with a fixed navbar at the top. \r\r","date":"2018-09-18","objectID":"/bootstrap/:5:3","tags":["frontend","bootstrap"],"title":"Bootstrap","uri":"/bootstrap/"},{"categories":["frontend"],"content":"实现性案例(Experiments) 非响应式Bootstrap布局(Non-responsive) Easily disable the responsiveness of Bootstrap per our docs. Offcanvas Build a toggleable off-canvas navigation menu for use with Bootstrap. \r\r\r","date":"2018-09-18","objectID":"/bootstrap/:5:4","tags":["frontend","bootstrap"],"title":"Bootstrap","uri":"/bootstrap/"},{"categories":["frontend"],"content":"工具 Tools \r\r \r\rCSS docs: https://getbootstrap.com/docs/3.3/css/ docs-cn: https://v3.bootcss.com/css/ \r","date":"2018-09-18","objectID":"/bootstrap/:6:0","tags":["frontend","bootstrap"],"title":"Bootstrap","uri":"/bootstrap/"},{"categories":["frontend"],"content":"概览 设置全局CSS样式；基本的HTML元素均可以通过class设置样式并得到增强效果；还有先进的栅格系统。 深入了解 Bootstrap 底层结构的关键部分，包括我们让 web 开发变得更好、更快、更强壮的最佳实践。 \r","date":"2018-09-18","objectID":"/bootstrap/:7:0","tags":["frontend","bootstrap"],"title":"Bootstrap","uri":"/bootstrap/"},{"categories":["frontend"],"content":"HTML5文档类型 HTML5 DOCTYPE Bootstrap使用到某些HTML元素和CSS属性需要将页面设置为HTML5文档类型。在你项目的每个页面下都要参照下面的格式进行设置。 \u003c!DOCTYPE html\u003e \u003chtml lang=\"zh-CN\"\u003e ... \u003c/html\u003e \r\r","date":"2018-09-18","objectID":"/bootstrap/:7:1","tags":["frontend","bootstrap"],"title":"Bootstrap","uri":"/bootstrap/"},{"categories":["frontend"],"content":"移动设备优先 Bootstrap 是移动设备优先的。 \r\r","date":"2018-09-18","objectID":"/bootstrap/:7:2","tags":["frontend","bootstrap"],"title":"Bootstrap","uri":"/bootstrap/"},{"categories":["frontend"],"content":"排版与链接","date":"2018-09-18","objectID":"/bootstrap/:7:3","tags":["frontend","bootstrap"],"title":"Bootstrap","uri":"/bootstrap/"},{"categories":["monitor"],"content":"参考： Prometheus文档： https://prometheus.io/docs GitHub: https://github.com/prometheus/ PrometheusAlert: https://github.com/feiyu563/PrometheusAlert 环境： CentOS7x86_64 Prometheus v2.14 \r\r \r\r介绍 Introduction \r","date":"2018-09-11","objectID":"/prometheus/:0:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"概述 \r","date":"2018-09-11","objectID":"/prometheus/:1:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"Prometheus是什么 What is Prometheus? Prometheus是一个最初在SoundCloud上构建的开源监控系统和报警工具包。现在是一个独立的开源项目，由社区进行维护。 功能(Features) Prometheus的主要特点： 具有由度量名称(metric name)和键值对(key-value)标识的时间序列(time series)数据的多维(multi-dimensional)数据模型 灵活的查询语言，以利用此维度 不依赖分布式存储(distributed storage)，单个服务器节点是自治的(autonomous) 时间序列集合通过HTPP的pull model发生 push时间序列通过中间网关(intermediary gateway)的支持 通过服务发现或静态配置来发现目标 图形和仪表盘支持多种模式 组件(Components) Prometheus系统由多个组件构成，其中某些组件是可选的： 主要的Prometheus Server，用于存储时间序列数据 client libraries，用于检测应用程序代码 push gateway，用于支持短暂的(short-lived)工作 exporters，用于服务的特殊目的 alertmanager，用于处理报警 各种支持工具 架构(Architecture) Prometheus的体系结构和系统组件图： \r\r","date":"2018-09-11","objectID":"/prometheus/:1:1","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"什么时候适合 When does it fit? Prometheus适用于记录任何纯数字时间序列。它既适用于以机器为中心的监控，也适用于高度动态的面向服务架构的监控。在微服务的世界中，它对多维数据收集和查询的支持是一种特殊的优势。 Prometheus专为提高可靠性而设计，是你在断电期间可以快速诊断问题的系统。每个Prometheus Server都是独立的，不依赖于网络存储或其它远程服务。当基础架构其它部分损坏时，你仍可以依赖它，并且你不需要设置大量的基础架构来使用它。 \r\r","date":"2018-09-11","objectID":"/prometheus/:1:2","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"什么时候不适合 When does it not fit? Prometheus重视可靠性。即使在系统故障情况下，你也可以随时查看有关系统的可用统计信息。如果你需要100%的准确度，Prometheus不是一个好的选择，你可能需要使用其它系统。 \r\r\r","date":"2018-09-11","objectID":"/prometheus/:1:3","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"第一步 步骤： 下载 配置 运行 使用表达式浏览器 使用图形接口 监控其它目标 \r\r\r","date":"2018-09-11","objectID":"/prometheus/:2:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"术语 GLOSSARY Alert 是Prometheus正在开火的警报规则的结果。警报从Prometheus发送到AlterManger。 Alertmanager 接收警报，将它们聚合成组，删除重复数据，应用静音、限制，然后发送电子邮件等通知。 Bridge 是一个从Client Library中获取样本并将它们暴露给 non-Prometheus 监控系统的组件。例如，Python、Java、Go…客户端可将指标导出到Graphite。 Client library 是某种语言的库(Go, Java, Python…)，可以直接检测代码，编写自定义收集器以从其它系统中收集指标并将指标公开给Prometheus。 Collector 是表示一组度量标准的 exporter 的一部分。如果它是直接检测的一部分，则可以是单个度量，如果是从另一个系统提取度量，则可以是许多度量。 Direct instrumentation 作为源代码程序的一部分内联添加的检测。 Endpoint Exporter 是一个公开Prometheus指标的程序，通常将 non-prometheus 格式的指标转换为 Prometheus 支持的格式。 Instance 唯一标识作业中目标的标签 Job 具有相同目的的目标集合 Notification 代表一组多个警报 Promdash 原生Prometheus仪表盘构建器。它已被弃用，并被 Grafana 取代 Prometheus 通常指的是Prometheus System的核心程序，也可指整个监控系统。 PromQL Prometheus Query Language Pushgateway 持续从批量作业中最新推出的指标 Remote Read 允许从其它系统透明读取时间序列作为查询的一部分 Remote Read Adapter 并非所有系统都支持远程读取。远程读取适配器便是用于此。 Remote Read Endpoint Prometheus进行远程读取时的对象 Remote Write 允许动态地将采集的样本发送到其它系统 Remote Write Adapter Remote Write Endpoint Sample 时间序列中某个时间点的单个值，Prometheus中，每个样本都包含一个float64和ms精度的时间戳。 Silence 防止报警 Target 抓取对象的定义 \r\r\r","date":"2018-09-11","objectID":"/prometheus/:3:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"FAQ faq: https://prometheus.io/docs/introduction/faq/ \r\r \r\r概念 CONCEPTS \r","date":"2018-09-11","objectID":"/prometheus/:4:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"数据模型 Data model Prometheus从根本上将所有数据存储为时间序列(time series): 属于同一指标和同一标记维度的带时间戳值的流。除了存储时间序列，Prometheus还可以临时生成时间序列作为查询的结果。 \r\r","date":"2018-09-11","objectID":"/prometheus/:5:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"指标名称和标签 Metric names and labels 每个时间序列都是有指标名称(metric name)和一组键值对(也称为标签(label))来唯一标识。 指标名称： 可能包含ASCII字母，下划线，冒号。它必须匹配正则: [a-zA-Z_:][a-zA-Z0-9_:]*。 标签启用Prometheus的维度数据模型： \r\r\r","date":"2018-09-11","objectID":"/prometheus/:5:1","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"指标类型 metric types: https://prometheus.io/docs/concepts/metric_types/ Prometheus Client Library提供了四个核心指标类型。这些目前仅在客户端和在有线协议(wire protocol)中区分。Prometheus Server尚未使用的类型信息和所有数据合并为无类型(untyped)时间序列。这在未来可能改变。 Prometheus clinet使用文档: Go Java Python ","date":"2018-09-11","objectID":"/prometheus/:6:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"Counter Counter，只增不减的计数器。 Counter是一个累计指标，代表一个单调递增计数器，即只增不减，除非重启或被重置为0。例如，你可以使用counter来代表服务的请求数、已完成的任务数、错误的数量… 不要用counter来暴露一个可以减少的值。例如，不要对当前运行的进程数使用counter类型，使用gauge类型。 一般在定义counter类型指标的名称时，推荐使用xxx_total作为后缀名。（如http_request_total） # 获取HTTP请求量的增长率 rate(http_requests_total[5m]) # 统计前十 topk(10, http_requests_total) ","date":"2018-09-11","objectID":"/prometheus/:6:1","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"Gauge Gauge，可以任意变化的仪表盘。 Gauge类型代表一个样本数据可以任意变化，即可增可减。通常用于像温度、内存使用率这种指标数据，也可表示能随时升降的计数（如当前的并发数）。 # 获取一段时间内的变化情况 dalta(cpu_temp_celsius{host=\"zeus\"}[2h]) # 简单线性回归，预测未来数据 predict_linear(node_filesystem_free{job=\"node\"}[2h], 4 * 3600) \u003c 0 ","date":"2018-09-11","objectID":"/prometheus/:6:2","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"Histogram Histogram和Summary主用用于统计和分析样本的分布情况。 Histogram(直方图)在一段时间范围内对数据进行采样（通常是请求持续时间(request durations)和响应大小(response sizes)等），并将其计入可配置的存储桶(bucket)中，后续可通过指定区间筛选样本，也可以统计样本总数，最后一般将数据展示为直方图。 Histogram类型的样本会提供三种指标： 样本值分布在桶中的数量，命名为xxx_bucket{le=\"\u003c上边界\u003e\"}。标识指标值小于等于上边界所有样本数量。 所有样本值的大小总和，命名为xxx_sum。 样本总数，命名为xxx_count，值和xxx_bucket{le=\"+Inf}相同。 可使用histogram_quantile()函数来计算Histogram类型样本的分位数。 ","date":"2018-09-11","objectID":"/prometheus/:6:3","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"Summary Summary(摘要)与Histogram类似，表示一段时间内的数据采集结果（通常是请求持续时间或响应大小）。它直接存储了分位数，而不是通过区间来计算。 Summary类型的样本也提供了三种指标： 样本值的分位数分布情况，命名为xxx{quantile=\"\u003cφ\u003e\"}。 所有样本值的大小总和，命名为xxx_sum。 样本总数，命名为xxx_count。 \r\r\r","date":"2018-09-11","objectID":"/prometheus/:6:4","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"作业和实例 Job and Instance Prometheus配置文件中配置。 \r\r \r\rPrometheus \r","date":"2018-09-11","objectID":"/prometheus/:7:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"入门 GETTING STARTED 本节介绍如何安装，配置，使用Prometheus的简单例子。你将在本地安装和运行Prometheus，将其配置为自我填充和示例应用程序，然后使用查询，规则和图表来使用收集的序列数据。 下载 下载地址: https://prometheus.io/download/ tar xvfz prometheus-*.tar.gz cd prometheus-* 配置和监控 Prometheus通过在目标上通过HTTP endPoints来抓取指标，来收集受监控目标的指标。由于Prometheus也以相同的方式公开自身数据，它也可以获取和监测自身的健康状况。 虽然Prometheus Server只收集有关自身的数据在实践中不是很有用，但它是一个很好的示例。如prometheus.yml示例配置文件： global:scrape_interval:15s# By default, scrape targets every 15 seconds.# Attach these labels to any time series or alerts when communicating with# external systems (federation, remote storage, Alertmanager).external_labels:monitor:'codelab-monitor'# A scrape configuration containing exactly one endpoint to scrape:# Here it's Prometheus itself.scrape_configs:# The job name is added as a label `job=\u003cjob_name\u003e` to any timeseries scraped from this config.- job_name:'prometheus'# Override the global default and scrape targets from this job every 5 seconds.scrape_interval:5sstatic_configs:- targets:['localhost:9090'] 启动 启动后，可访问9090端口查看状态。可访问localhost:9090/metrics查看有关自身的相关指标。 cd prometheus-2.3.2.linux-amd64 ./prometheus --config.file=\"prometheus.yml\" 使用表达式浏览器 让我们看一下Prometheus收集的一些数据。要使用Prometheus的内建表达式浏览器(expression browser)，请跳转到http://localhost:9090/graph并选择Graph -\u003e Console，在其中输入表达式。 绘制表达式图形同样在此操作。 #表达式 prometheus_target_interval_length_seconds #表达式 prometheus_target_interval_length_seconds{quantile=\"0.99\"} #计算返回的时间序列数 count(prometheus_target_interval_length_seconds) 启动简单的目标 启动一些示例目标让Prometheus获取。 确保已安装Go表一起并设置了正常的GO PATH。 mkdir ./sample \u0026\u0026 cd sample git clone https://github.com/prometheus/client_golang.git cd client_golang/examples/random go get -d go build # Start 3 example targets in separate terminals: ./random -listen-address=:9091 ./random -listen-address=:9092 ./random -listen-address=:9093 #访问 http://localhost:9091/metrices http://localhost:9092/metrices http://localhost:9093/metrices 监控示例目标 现在需要配置Prometheus来抓取目标。 scrape_configs:- job_name:'example-random'# Override the global default and scrape targets from this job every 5 seconds.scrape_interval:5sstatic_configs:- targets:['localhost:8080','localhost:8081']labels:group:'production'- targets:['localhost:8082']labels:group:'canary' 重启Prometheus，检测rpc_durations_seconds metric来验证。 配置规则 Configure rules for aggregating scraped data into new time series 聚合超过数千个时间序列的查询在计算ad-hoc时会变慢。为了提高效率，Prometheus允许你通过配置的规则将预录表达式预先记录到全新的持久时间序列中。 创建规则文件prometheus.rules.yml： #job_service:rpc_durations_seconds_count:avg_rate5m groups: - name: example rules: - record: job_service:rpc_durations_seconds_count:avg_rate5m expr: avg(rate(rpc_durations_seconds_count[5m])) by (job, service) 要是Prometheus选择此新规则，需要修改Prometheus配置： global: scrape_interval: 15s # By default, scrape targets every 15 seconds. evaluation_interval: 15s # Evaluate rules every 15 seconds. # Attach these extra labels to all timeseries collected by this Prometheus instance. external_labels: monitor: 'codelab-monitor' rule_files: - 'prometheus.rules.yml' scrape_configs: - job_name: 'prometheus' # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: ['localhost:9090'] - job_name: 'example-random' # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: ['localhost:8091', 'localhost:8092'] labels: group: 'production' - targets: ['localhost:9093'] labels: group: 'canary' 重启Prometheus，使用job_service:rpc_durations_seconds_count:avg_rate5m metric验证。 \r\r","date":"2018-09-11","objectID":"/prometheus/:8:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"安装 ","date":"2018-09-11","objectID":"/prometheus/:9:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"使用预编译的二进制文件 \r\r","date":"2018-09-11","objectID":"/prometheus/:9:1","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"使用源码 \r\r","date":"2018-09-11","objectID":"/prometheus/:9:2","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"使用Docker 所有的Prometheus服务都可以作为 Docker image 来使用。 Prometheus image 使用 volume 来存储实际的指标。对于生产部署，强烈建议使用 Data Volume Container 来升级数据的管理。 栗子： #bind-mount docker run -p 9090:9090 -v /tmp/prometheus.yml:/etc/prometheus.yml prom/prometheus #volume docker run -p 9090:9090 -v /promethe-data prom/prometheus --config.file=/prometheus-data/prometheus.yml 自定义镜像 Dockerfile: FROM prom/prometheus ADD prometheus.yml /etc/prometheus/ xxx 构建： docker build -t my-prometheus . \r\r","date":"2018-09-11","objectID":"/prometheus/:9:3","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"使用配置管理系统 Ansible Chef Puppet SaltStack \r\r\r","date":"2018-09-11","objectID":"/prometheus/:9:4","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"配置 Configuration Prometheus通过命令行标志(flag)和配置文件进行配置。使用./prometheus -h查看所有命令行标志。 Prometheus可在运行时重新加载配置。 \r","date":"2018-09-11","objectID":"/prometheus/:10:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"配置文件 configuration file: https://prometheus.io/docs/prometheus/latest/configuration/configuration/ 使用--config.file标志指定配置文件。配置文件使用YAML格式。 一个配置文件栗子: global:# How frequently to scrape targets by default.[ scrape_interval:\u003cduration\u003e | default = 1m ]# How long until a scrape request times out.[ scrape_timeout:\u003cduration\u003e | default = 10s ]# How frequently to evaluate rules.[ evaluation_interval:\u003cduration\u003e | default = 1m ]# The labels to add to any time series or alerts when communicating with# external systems (federation, remote storage, Alertmanager).external_labels:[ \u003clabelname\u003e:\u003clabelvalue\u003e ... ]# Rule files specifies a list of globs. Rules and alerts are read from# all matching files.rule_files:[- \u003cfilepath_glob\u003e ... ]# A list of scrape configurations.scrape_configs:[- \u003cscrape_config\u003e ... ]# Alerting specifies settings related to the Alertmanager.alerting:alert_relabel_configs:[- \u003crelabel_config\u003e ... ]alertmanagers:[- \u003calertmanager_config\u003e ... ]# Settings related to the remote write feature.remote_write:[- \u003cremote_write\u003e ... ]# Settings related to the remote read feature.remote_read:[- \u003cremote_read\u003e ... ] 各个配置项，详细详细请看文档: https://prometheus.io/docs/prometheus/latest/configuration/configuration/ scrape_config tls_config azure_sd_config consul_sd_config dns_sd_config ec2_sd_config openstack_sd_config file_sd_config gce_sd_config kubernetes_sd_config marathon_sd_config nerve_sd_config serverset_sd_config triton_sd_config static_config relabel_config metric_relabel_configs alert_relabel_configs alertmanager_config remote_write remote_read ","date":"2018-09-11","objectID":"/prometheus/:10:1","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"记录规则 Recording rules 配置规则 Configuring rules Prometheus支持两种类型的可被配置的以规定的间隔进行评估的规则: recording rules alterting rules 要在Prometheus中包含规则，创建包含必要规则的语句并在Prometheus配置文件中通过rule_files字段配置并加载文件。规则使用YAML格式。 规则文件可在Prometheus运行通过发送SIGHUP到Prometheus来进行重载。只有在所有规则文件都是正确格式下才会应用更改。 语法检查规则 Syntax-checking rules 要快速检查规则文件的语法是否正确，而无需启动Prometheus Server，可安装和运行Prometheus的promtool命令行工具: go get github.com/prometheus/prometheus/cmd/promtool promtool check rules /path/to/example.rules.yml 如果规则文件语法正确，会返回0状态码。如果语法错误，会返回错误信息和1状态码。 记录规则 Recording rules 记录规则允许你预先计算经常需要或计算昂贵的表达式并保存它们的结果到一个新的时序集(set of time series)。查询预先计算的结果会比每次执行原始表达式快得多。这对Dashboard来说尤其有用，它经常刷新时间反复查询同样的表达式。 记录和告警规则位于一个规则组(rule group)。一个组内的规则在一个规定的间隔内依序运行。 规则文件语法: groups:[- \u003crule_group\u003e ] 栗子: groups: - name: example relues: - record: job:http_inprogress_requests:sum expr: sum(http_inprogress_requests) by (job) \u003crule_group\u003e # The name of the group. Must be unique within a file.name:\u003cstring\u003e# How often rules in the group are evaluated.[ interval:\u003cduration\u003e | default = global.evaluation_interval ]rules:[- \u003crule\u003e ... ] 记录规则的语法: # The name of the time series to output to. Must be a valid metric name.record:\u003cstring\u003e# The PromQL expression to evaluate. Every evaluation cycle this is# evaluated at the current time, and the result recorded as a new set of# time series with the metric name as given by 'record'.expr:\u003cstring\u003e# Labels to add or overwrite before storing the result.labels:[ \u003clabelname\u003e:\u003clabelvalue\u003e] 告警规则的语法: # The name of the alert. Must be a valid metric name.alert:\u003cstring\u003e# The PromQL expression to evaluate. Every evaluation cycle this is# evaluated at the current time, and all resultant time series become# pending/firing alerts.expr:\u003cstring\u003e# Alerts are considered firing once they have been returned for this long.# Alerts which have not yet fired for long enough are considered pending.[ for:\u003cduration\u003e | default = 0s ]# Labels to add or overwrite for each alert.labels:[ \u003clabelname\u003e:\u003ctmp_string\u003e]# Annotations to add to each alert.annotations:[ \u003clabelname\u003e:\u003ctmpl_string\u003e ] ","date":"2018-09-11","objectID":"/prometheus/:10:2","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"告警规则 Alerting rules 告警规则允许你根据Prometheus表达式语言来定义告警条件，并发送提醒到外部服务。每当告警表达式在给定的时间内导致一个或多个矢量元素，告警计数主动作为这些元素的标签集。 定义告警规则 在Prometheus中，告警规则的配置与记录规则的配置一样。 栗子: groups:- name:examplerules:- alerts:HighRequestLatencyexpr:job:request_latency_seconds:mean5m{job=\"myjob\"} \u003e 0.5for:10mlabels:severity:pageannotations:summary:High request latency 可选的for子句导致Prometheus等待在第一次遇到一个新的表达式输出矢量元素和计数的告警作为点燃的此元素的一定持续时间。在这个栗子中，Prometheus将检查在点燃告警之前的每个10分钟的警告持续激活。元素是活跃的，但未点燃，出于待定(pending)状态。 labels子句允许指定一组附加标签到告警。任何目前有冲突的标签将被覆盖。标签的值可以作为模板。 annotations子句指定的一组信息可用来存储更长的附加信息。注释的值可以作为模板。 模板 Templating 标签和注释的值可以使用console template作为模板。$labels变量保存一个告警实例的k/v键值对。已配置的外部标签可通过$externalLabels变量进行访问。$value变量保存告警实例的评估值。 # To insert a firing element's label values:{{$labels.\u003clabelname\u003e }}# To insert the numeric expression value of the firing element:{{$value }} 栗子: groups:- name:examplerules:# Alert for any instance that is unreachable for \u003e5 minutes.- alert:InstanceDownexpr:up == 0for:5mlabels:severity:pageannotations:summary:\"Instance {{ $labels.instance }} down\"description:\"{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.\"# Alert for any instance that has a median request latency \u003e1s.- alert:APIHighRequestLatencyexpr:api_http_request_latencies_second{quantile=\"0.5\"} \u003e 1for:10mannotations:summary:\"High request latency on {{ $labels.instance }}\"description:\"{{ $labels.instance }} has a median request latency above 1s (current value: {{ $value }})s\" 运行时检查告警 Inspecting alerts during runtime 要手动检查告警是否活跃(active)(pending或firing)，请浏览原生Prometheus的Alerts栏目项。这里将确切地显示标签集，每个定义的告警当前的状态。 对于pengding和firing的告警，Prometheus还存储合成ALERTS{alertname=\"\u003calert name\u003e\", alertstate=\"pending|firing\", \u003cadditional alert labels\u003e}形式的时间序列。只要该警告是在所指示的active(pending或firing)状态，样本值被设置为1。当不再是这样时，该系列被标记为stale。 发送告警通知 Sending alert notifications Prometheus的告警规则善于盘算现在什么坏了(broken)，但是它不是一个成熟的通知解决方案。需要另一层添加汇总，通知速率限制，沉默和告警依赖于简单告警定义。在Prometheus的生态系统中，Alertmanager承担了这一角色。因此，Prometheus可以配置成定期发送关于告警状态信息到Alertmanager实例，然后采取调度权发送通知。 Prometheus通过集成服务发现，可配置为自动发现可用的Alertmanager实例。 ","date":"2018-09-11","objectID":"/prometheus/:10:3","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"模板 Template example Prometheus在alerts的annotations和labels中支持模板化，以及在控制台页面。模板要针对本地数据库运行查询、迭代数据，使用条件、格式数据等能力。Prometheus模板语言是基于Go template system。 简单告警字段模板 alert:InstanceDownexpr:up == 0for:5mlabels:severity:pageannotations:summary:\"Instance {{$labels.instance}} down\"description:\"{{$labels.instance}} of job {{$labels.job}} has been down for more than 5 minutes.\" 告警字段模板为每个点燃的告警在每一个规则迭代过程中执行，所以保持任意查询和模板的轻量化。如果你需要为告警编写更复杂的模板，建议链接到控制台。 简单迭代 simple iteration 这显示的实例列表，以及它们是否up: {{range query \"up\" }}{{.Labels.instance }} {{ .Value }}{{end }} 特殊的.变量包含对于每次循环迭代当前样本的值。 展示一个值 {{with query \"some_metric{instance='someinstance'}\" }}{{. | first | value | humanize }{{end }} Go和Go的模板语言两者都是强类型，因此必须检查阳平返回，以避免执行错误。 这里所包含的prom_query_drilldown模板处理，允许结果的格式，并链接到表达式浏览器。 使用控制台url参数 Using console URL parameters {{with printf \"node_memory_MemTotal{job='node', instance='%s'}\" .Params.instance | query}}{{. | first | value | humanize1024 }}B{{end }} 如果作为console.html?instance=hostname访问, .Params.instance将评估hostname。 高级的迭代 Advanced iteration \u003ctable\u003e{{range printf \"node_network_receive_bytes{job='node',instance='%s',device!='lo'}\" .Params.instance | query | sortByLabel \"device\"}}\u003ctr\u003e\u003cth colspan=2\u003e{{ .Labels.device }}\u003c/th\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eReceived\u003c/td\u003e\u003ctd\u003e{{ with printf \"rate(node_network_receive_bytes{job='node',instance='%s',device='%s'}[5m])\" .Labels.instance .Labels.device | query }}{{ . | first | value | humanize }}B/s{{end}}\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eTransmitted\u003c/td\u003e\u003ctd\u003e{{ with printf \"rate(node_network_transmit_bytes{job='node',instance='%s',device='%s'}[5m])\" .Labels.instance .Labels.device | query }}{{ . | first | value | humanize }}B/s{{end}}\u003c/td\u003e\u003c/tr\u003e{{ end }}\u003c/table\u003e 这里，我们迭代了所有网络设备，并显示每个设备的网络流量。随着range动作不指定变量，.Params.instance循环内不可用，.现在是作为循环变量。 定义可重复使用的模板 Defining reusable templates Prometheus支持定义可重复使用的模板。当与控制台库相结合时，使得可共享模板，这很有用。 {{/* Define the template */ }}{{define \"myTemplate\"}}do something{{end }}{{/* Use the template */}}{{template \"myTemplate\"}} 模板仅限于一个参数。args函数可包装多个参数。 {{define \"myMultiArgTemplate\"}}First argument:{{.arg0}}Second argument:{{.arg1}}{{end }}{{template \"myMultiArgTemplate\" (args 1 2)}} ","date":"2018-09-11","objectID":"/prometheus/:10:4","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"模板引用 TEMPLATE REFERENCE 数据结构 Data Structures 用于处理时间序列数据的主要数据结构栗子: type sample struct { Labels map[string]string Value float64 } 栗子的指标名称(metric)编码在Labelsmap的特殊的__name__标签里。 []sample表示实例列表。 Go中的interface{}与C中的void pointer类似。 函数 除了Go模板提供的默认函数，Prometheus为模板查询结果提供了更易处理的函数。 如果函数在管道中使用，管道值将作为最后一个参数传递。 Queries Numbers Strings Others 模板类型差异 Template type differences 每种类型的模板提供了可用于参数模板的不同信息，并有一些其它差异。 ","date":"2018-09-11","objectID":"/prometheus/:10:5","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"规则单元测试 Unit Testing for Rules 你可使用promtool来测试你的规则。 ","date":"2018-09-11","objectID":"/prometheus/:10:6","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"查询 Querying ","date":"2018-09-11","objectID":"/prometheus/:11:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"查询Prometheus Prometheus提供了一个名为PromQL(Prometheus Query Language)功能化查询语言，让用户选择并实时汇总时间序列数据。表达式的结果可被显示为图形，可在Prometheus浏览器上查看，或通过HTTP API来获取。 表达式语言数据类型 Expression language data types 在Prometheus表达式语言中，一个表达式或子表达式可以评估为四种类型中的一种: 瞬时向量(Instant vector): 包含每个时间序列的单个样品的一组时间序列，全部共享相同的时间戳 区间向量(Range vector): 包含随时间序列的范围的数据点的一组时间序列 标量(Scalar): 一个简单的数字浮点值 字符串(String): 一个简单的字符串值，当前未使用 根据不同的使用情况(graphing, displaying the output of an expression)，例如：瞬时向量表达式返回的数据类型是唯一可以直接绘制成图表的数据类型。 Literals String literals 字符串可以被指定为在单引号、双引号或反引号内的文字。 PromQL遵循Go的转义规则。 不像Go，Prometheus不丢弃反引号里面的换行符。 \"this is a string\" 'these are unescaped: \\n \\\\ \\t' `these are not unescaped: \\n ' \" \\t`\"'` Float literals 标量浮点值可被逐字地写为[-](digits)[.(digits)]数字形式。 -2.43 时序选择器 Time series Selectors Prometheus中的所有正则表达式使用RE2 syntax。 Instant vector selectors Instant vector selectors允许一组时间序列并为每个在给定的时间戳单一样品值的选择: 在最简单的格式中，只制定了一个指标名称。这导致了包含有该指标名称的所有时间序列的元素instant vector。 这个栗子将选择具有http_requests_total指标名称的所有时间序列: http_requests_total 有可能通过附加一组标签在大括号来匹配进一步过滤这些时间序列。 这个栗子只选择job label为prometheus和group lable为canary的http_requests_total指标名称。 http_requests_total{job=\"prometheus\", group=\"canary\"} 也可将标签值负匹配，或匹配正则表达式。下面的标签匹配操作符存在: =: 等于; != 不等于; =~: 正则匹配; !~: 非正则匹配. 举个栗子，以下匹配staging, testing, development环境变量和GET以外的HTTP方法的http_requests_total指标名称的所有时序。 http_requests_total{environment=~\"staging|testing|development\", method!=\"GET\"} 栗子: {job=~\".*\"} # Bad! {job=~\".+\"} # Good! {job=~\".*\",method=\"get\"} # Good! {__name__=~\"job:.*\"} Range Vector Selectors Range vector literals与 instant vector literals类似，不同之处在于它选择了一个范围。时间序列放在方括号[]内。 时间范围被指定为一个数字，使用以下单位: s: 秒; m: 分; h: 时; d: 天; w: 周; y: 年。 栗子: http_requests_total{job=\"prometheus\"}[5m] Offset modifier offset修饰符允许为查询中的individual instant和range vectors改变时间偏移。 栗子: http_requests_total offset 5m sum(http_requests_total{method=\"GET\"} offset 5m) // GOOD. sum(http_requests_total{method=\"GET\"}) offset 5m // INVALID. rate(http_requests_total[5m] offset 1w) 子查询 Subquery 子查询允许你为一个给定的range和resolution运行一个即时查询(instant)。子查询的结果为range vector。 语法: # resolution可选。Default is the global evaluation interval. Syntax: \u003cinstant_query\u003e '[' \u003crange\u003e ':' [\u003cresolution\u003e] ']' [ offset \u003cduration\u003e ] ","date":"2018-09-11","objectID":"/prometheus/:11:1","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"操作符 Operators: https://prometheus.io/docs/prometheus/latest/querying/operators/ 二元运算符 Binary Operators Prometheus查询语言支持基本的逻辑和算数运算符。 Arithmetic binary operators Prometheus中存在以下二元算术运算符: + (addition) - (subtraction) * (multiplication) / (division) % (modulo) ^ (power/exponentiation) 二元运算符在下列之间定义: scalar/scalar vector/scalar vector/vector Comparison binary operators Prometheus中有以下二元比较符: == (equal) != (not-equal) \u003e (greater-than) \u003c (less-than) \u003e= (greater-or-equal) \u003c= (less-or-equal) 比较运算符在下列之间定义，默认情况下进行筛选。它们的行为可由运算符之后提供的bool进行修改，这将返回0或1而不是过滤。 scalar/scalar vector/scalar vector/vector Logical/set binary operators logical/set 二元运算符尽在instan vectors之间定义: and (intersection) or (union) unless (complement) 矢量匹配 Vector matching 矢量之间的操作试图找到为左手侧的每个条目匹配右手侧的元素。有两种基本类型匹配的行为: One-to-one 和 many-to-one/one-to-many。 One-to-one vector matches 一对一从操作的每一侧查找唯一的一对条目。在默认情况下，操作遵循如下格式vector1 \u003coperator\u003e vector2。如果它们有完全相同的一组标签和相应的值，则两个条目匹配。ignoring关键字允许匹配忽略某些标签，on关键字允许降低考虑的标签集来提供列表: \u003cvector expr\u003e \u003cbin-op\u003e ignoring(\u003clabel list\u003e) \u003cvector expr\u003e \u003cvector expr\u003e \u003cbin-op\u003e on(\u003clabel list\u003e) \u003cvector expr\u003e 输入案例: method_code:http_errors:rate5m{method=\"get\", code=\"500\"} 24 method_code:http_errors:rate5m{method=\"get\", code=\"404\"} 30 method_code:http_errors:rate5m{method=\"put\", code=\"501\"} 3 method_code:http_errors:rate5m{method=\"post\", code=\"500\"} 6 method_code:http_errors:rate5m{method=\"post\", code=\"404\"} 21 method:http_requests:rate5m{method=\"get\"} 600 method:http_requests:rate5m{method=\"del\"} 34 method:http_requests:rate5m{method=\"post\"} 120 查询栗子: method_code:http_errors:rate5m{code=\"500\"} / ignoring(code) method:http_requests:rate5m Many-to-one and one-to-many vector matches 多对一或一对多匹配指的是一侧能够匹配多侧的多个元素。这明确要求必须使用group_left或group_right修饰符，其中左/右确定该矢量有更高的基数。 \u003cvector expr\u003e \u003cbin-op\u003e ignoring(\u003clabel list\u003e) group_left(\u003clabel list\u003e) \u003cvector expr\u003e \u003cvector expr\u003e \u003cbin-op\u003e ignoring(\u003clabel list\u003e) group_right(\u003clabel list\u003e) \u003cvector expr\u003e \u003cvector expr\u003e \u003cbin-op\u003e on(\u003clabel list\u003e) group_left(\u003clabel list\u003e) \u003cvector expr\u003e \u003cvector expr\u003e \u003cbin-op\u003e on(\u003clabel list\u003e) group_right(\u003clabel list\u003e) \u003cvector expr\u003e 查询案例: method_code:http_errors:rate5m / ignoring(code) group_left method:http_request:rate5m {method=\"get\", code=\"500\"} 0.04 // 24 / 600 {method=\"get\", code=\"404\"} 0.05 // 30 / 600 {method=\"post\", code=\"500\"} 0.05 // 6 / 120 {method=\"post\", code=\"404\"} 0.175 // 21 / 120 聚合运算符 Aggregation operators Prometheus支持以下内置聚合运算符，可以用于聚合单一瞬间向量的元素: sum (calculate sum over dimensions) min (select minimum over dimensions) max (select maximum over dimensions) avg (calculate the average over dimensions) stddev (calculate population standard deviation over dimensions) stdvar (calculate population standard variance over dimensions) count (count number of elements in the vector) count_values (count number of elements with the same value) bottomk (smallest k elements by sample value) topk (largest k elements by sample value) quantile (calculate φ-quantile (0 ≤ φ ≤ 1) over dimensions) 栗子: \u003caggr-op\u003e [without|by (\u003clabel list\u003e)] ([parameter,] \u003cvector expression\u003e) \u003caggr-op\u003e([parameter,] \u003cvector expression\u003e) [without|by (\u003clabel list\u003e)] sum without (instance) (http_requests_total) sum by (application, group) (http_requests_total) count_values(\"version\", build_version) topk(5, http_requests_total) 二元运算符优先级 Binary operator precedence 以下优先级由高到低: ^ *, /, % +, - ==, !=, \u003c=, \u003c, \u003e=, \u003e and, unless or ","date":"2018-09-11","objectID":"/prometheus/:11:2","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"函数 Founctions: https://prometheus.io/docs/prometheus/latest/querying/functions/ 一些函数有默认的参数，如year(v=vector(time()) instant-vector)。 abs() abs(v instant-vector) 返回输入向量的所有样本的绝对值 absent() absent(v instant-vector)，判断是否存在 absent(nonexistent{job=\"myjob\"}) # =\u003e {job=\"myjob\"} absent(nonexistent{job=\"myjob\",instance=~\".*\"}) # =\u003e {job=\"myjob\"} absent(sum(nonexistent{job=\"myjob\"})) # =\u003e {} ceil() ceil(v instant-vector) 将v中所有元素的样本值向上四舍五入到最接近的整数 floor() floor(v instant-vector) 与ceil()相反，将v中所有元素的样本值向下四舍五入到最接近的整数 changes() changes(v range-vector) 输入一个区间向量，返回这个区间向量内每个样本数据值变化的次数（瞬时向量）。如果样本数据值没有发生变化，则返回结果为1 clamp_max() clamp_max(v instant-vector, max scalar) 输入一个瞬时向量和最大值，样本数据值若大于max，则改为max，否则不变 clamp_min() clamp_min(v instant-vector, min scalar) 输入一个瞬时向量和最小值，样本数据值若小于min，则改为min，否则不变 day_of_month() day_of_month(v=vector(time()) instant-vector) 值范围为1-31 day_of_week() day_of_week(v=vector(time()) instant-vector) 值范围为0-6 days_in_month() days_in_month(v=vector(time()) instant-vector) 月份的天数，值范围为28-31 minute() minute(v=vector(time()) instant-vector) 函数返回给定UTC时间当前小时的第多少分钟，范围为0-59 month() month(v=vector(time()) instant-vector) 函数返回给定UTC时间当前属于第几个月，范围为1-12 year() year(v=vector(time()) instant-vector) 返回被给定 UTC 时间的当前年份 hour() hour(v=vector(time()) instant-vector) 值范围为0-23 delta() delta(v range-vector) 它计算一个区间向量v的第一个元素和最后一个元素之间的差值，返回一个瞬时向量 delta(cpu_temp_celsius{host=\"zeus\"}[2h]) # 现在和两小时前的CPU温度差 idelta() idelta(v range-vector) 计算最后两个样本之间的差 deriv() deriv(v range-vector) 使用简单的线性回归计算区间向量v中各个时间序列的导数 exp() exp(v instant-vector) 输入一个瞬时向量，返回各个样本值的e的指数值 histogram_quantile() histogram_quantile(φ float, b instant-vector) histogram_quantile(0.9, rate(http_request_duration_seconds_bucket[10m])) # 计算过去10分钟内请求持续在90% histogram_quantile(0.9, sum(rate(http_request_duration_seconds_bucket[10m])) by (job, le)) # 聚合 holt_winters() holt_winters(v range-vector, sf scalar, tf scalar) 基于区间向量v，生成时间序列数据平滑值 increase() increase(v range-vector) 获取区间向量中的第一个和最后一个样本并返回其增长量 increase(http_requests_total{job=\"api-server\"}[5m]) # 区间向量中每个时间序列过去5分钟内HTTP请求数的增长数 label_join() label_replace() ln() ln(v instant-vector) 计算瞬时向量v中所有样本数据的自然对数 log2() log2(v instant-vector) 函数计算瞬时向量v中所有样本数据的二进制对数 log10() log10(v instant-vector) 计算瞬时向量v中所有样本数据的十进制对数 predict_linear() predict_linear(v range-vector, t scalar) 函数可以预测时间序列v在t秒后的值 predict_linear(node_filesystem_free{job=\"node\"}[2h], 4 * 3600) \u003c 0 # 基于2小时的样本数据，来预测主机可用磁盘空间的是否在4个小时候被占满 rate() rate(v range-vector) 直接计算区间向量 v 在时间窗口内平均增长速率 rate(http_requests_total[5m]) 区间向量中每个时间序列过去5分钟内HTTP请求数的每秒增长率 irate() irate(v range-vector) 用于计算区间向量的增长率，但是其反应出的是瞬时增长率。通过区间向量中最后两个两本数据来计算区间向量的增长速率。 irate(http_requests_total{job=\"api-server\"}[5m]) # 区间向量中每个时间序列过去 5 分钟内最后两个样本数据的 HTTP 请求数的增长率 resets() resets(v range-vector) 的参数是一个区间向量。对于每个时间序列，它都返回一个计数器重置的次数。两个连续样本之间的值的减少被认为是一次计数器重置。 round() round(v instant-vector, to_nearest=1 scalar) 与ceil和floor函数类似，返回向量中所有样本值的最接近的整数 scalar() scalar(v instant-vector) 函数的参数是一个单元素的瞬时向量,它返回其唯一的时间序列的值作为一个标量 sort() sort(v instant-vector) 函数对向量按元素的值进行升序排序 sort_desc() 降序排列 sqrt() sqrt(v instant-vector) 计算向量v 所有元素的平方根 vector() vector(s scalar) \u003caggregation\u003e_over_time() avg_over_time(range-vector) : 区间向量内每个度量指标的平均值。 min_over_time(range-vector) : 区间向量内每个度量指标的最小值。 max_over_time(range-vector) : 区间向量内每个度量指标的最大值。 sum_over_time(range-vector) : 区间向量内每个度量指标的求和。 count_over_time(range-vector) : 区间向量内每个度量指标的样本数据个数。 quantile_over_time(scalar, range-vector) : 区间向量内每个度量指标的样本数据值分位数，φ-quantile (0 ≤ φ ≤ 1)。 stddev_over_time(range-vector) : 区间向量内每个度量指标的总体标准差。 stdvar_over_time(range-vector) : 区间向量内每个度量指标的总体标准方差。 ","date":"2018-09-11","objectID":"/prometheus/:11:3","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"查询栗子 Query examples: https://prometheus.io/docs/prometheus/latest/querying/examples/ 简单时序选择 返回指标http_requests_total的所有时间序列数据: http_requests_total 返回指标名为http_requests_total，给定标签job和handler: http_requests_total{job=\"apiserver\", handler=\"/api/comments\"} 加上时间，5分钟内: http_requests_total{job=\"apiserver\", handler=\"/api/comments\"}[5m] 使用正则: http_requests_total{job=~\".*server\"} http状态码不为4xx: http_requests_total{status!~\"4..\"} 子查询 Return the 5-minute rate of the http_requests_total metric for the past 30 minutes, with a resolution of 1 minute. rate(http_requests_total[5m])[30m:1m] 嵌套子查询: max_over_time(deriv(rate(distance_covered_total[5s])[30s:5s])[10m:]) 使用函数，运算符 过去5分钟的平均值 rate(http_requests_total[5m]) 过去5分钟平均值综合 sum by (job) ( rate(http_requests_total[5m]) ) 如果两个指标具有相同维度的标签，我们可以使用二元操作符计算样本数据: (instance_memory_limit_bytes - instance_memory_usage_bytes) / 1024 / 1024 # 同样的表达式，只不过通过应用相加 sum by (app, proc) ( instance_memory_limit_bytes - instance_memory_usage_bytes ) / 1024 / 1024 获取CPU使用最高的三个样本: topk(3, sum by (app, proc) (rate(instance_cpu_time_ns[5m]))) 假设一个服务实例只有一个时间序列数据，那么我们可以通过下面表达式统计出每个应用的实例数量: count(instance_cpu_time_ns) by (app) ","date":"2018-09-11","objectID":"/prometheus/:11:4","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"HTTP API HTTP API: https://prometheus.io/docs/prometheus/latest/querying/api/ 目前稳定的HTTP API在Prometheus Server的/api/v1下。 格式 API响应格式为JSON。每个成功的请求都返回2xx状态码。 到达API处理程序无效的请求返回一个错误的JSON对象和以下状态码之一: 400 Bad Request: 当参数错误或者缺失 422 Unprocessable Entity: 当表达式无法执行 503 Service Unavailable: 当请求超时或者被中断时 JSON响应包格式如下: { \"status\": \"success\" | \"error\", \"data\": \u003cdata\u003e, // Only set if status is \"error\". The data field may still hold // additional data. \"errorType\": \"\u003cstring\u003e\", \"error\": \"\u003cstring\u003e\", // Only if there were warnings while executing the request. // There will still be data in the data field. \"warnings\": [\"\u003cstring\u003e\"] } 请求中输入的时间为RFC3339或Unix原子时间，输出时间戳总是Unix原子时间。 查询参数的名称可用中括号[]重复次数。 \u003cduration\u003e占位符指的是[0-9]+[smhdwy]形式的Prometheus 持续时间字符串。例如，5m表示5分钟的持续时间。 表达式查询 查询语言表达式可在单个时刻或一定范围内进行评估。以下部分用于描述每个类型的表达式查询的API endpoint。 瞬时查询(Instant query) 端点: GET /api/v1/query POST /api/v1/query URL查询参数: # 表达式 query=\u003cstring\u003e # 时间戳，可选。默认使用当前系统时间 time=\u003crfc3339 | unix_timestamp\u003e # 超时，可选。默认使用全局的-query.timeout参数 timeout=\u003cduration\u003e 查询结果的data部分格式如下: { \"resultType\": \"matrix\" | \"vector\" | \"scalar\" | \"string\", \"result\": \u003cvalue\u003e } 栗子: $ curl 'http://localhost:9090/api/v1/query?query=up\u0026time=2015-07-01T20:10:51.781Z' { \"status\" : \"success\", \"data\" : { \"resultType\" : \"vector\", \"result\" : [ { \"metric\" : { \"__name__\" : \"up\", \"job\" : \"prometheus\", \"instance\" : \"localhost:9090\" }, \"value\": [ 1435781451.781, \"1\" ] }, { \"metric\" : { \"__name__\" : \"up\", \"job\" : \"node\", \"instance\" : \"localhost:9100\" }, \"value\" : [ 1435781451.781, \"0\" ] } ] } } 区间查询(range query) 端点: GET /api/v1/query_range POST /api/v1/query_range URL查询参数: # 表达式 query=\u003cstring\u003e # 时间戳 start=\u003crfc3339 | unix_timestamp\u003e end=\u003crfc3339 | unix_timestamp\u003e # 查询时间步长，时间区间内每step秒执行一次 step=\u003cduration | float\u003e # 超时，可选 timeout=\u003cduration\u003e 查询结果的data部分格式如下: { \"resultType\": \"matrix\", \"result\": \u003cvalue\u003e } 栗子: $ curl 'http://localhost:9090/api/v1/query_range?query=up\u0026start=2015-07-01T20:10:30.781Z\u0026end=2015-07-01T20:11:00.781Z\u0026step=15s' { \"status\" : \"success\", \"data\" : { \"resultType\" : \"matrix\", \"result\" : [ { \"metric\" : { \"__name__\" : \"up\", \"job\" : \"prometheus\", \"instance\" : \"localhost:9090\" }, \"values\" : [ [ 1435781430.781, \"1\" ], [ 1435781445.781, \"1\" ], [ 1435781460.781, \"1\" ] ] }, { \"metric\" : { \"__name__\" : \"up\", \"job\" : \"node\", \"instance\" : \"localhost:9091\" }, \"values\" : [ [ 1435781430.781, \"0\" ], [ 1435781445.781, \"0\" ], [ 1435781460.781, \"1\" ] ] } ] } } 查询元数据 通过标签匹配器查找序列(Finding series by label matchers) 端点: GET /api/v1/series POST /api/v1/series URL请求参数: # 标签选择器是 series_selector。必须至少提供一个match[]参数 match[]=\u003cseries_selector\u003e # 时间戳 start=\u003crfc3339 | unix_timestamp\u003e end=\u003crfc3339 | unix_timestamp\u003e 返回结果的data部分，由k/v键值对的对象列表组成。 栗子: $ curl -g 'http://localhost:9090/api/v1/series?' --data-urlencode='match[]=up' --data-urlencode='match[]=process_start_time_seconds{job=\"prometheus\"}' { \"status\" : \"success\", \"data\" : [ { \"__name__\" : \"up\", \"job\" : \"prometheus\", \"instance\" : \"localhost:9090\" }, { \"__name__\" : \"up\", \"job\" : \"node\", \"instance\" : \"localhost:9091\" }, { \"__name__\" : \"process_start_time_seconds\", \"job\" : \"prometheus\", \"instance\" : \"localhost:9090\" } ] } 获取标签名(label) 端点: GET /api/v1/labels POST /api/v1/labels 返回结果的data部分是一个标签名字符串列表。 栗子: $ curl 'localhost:9090/api/v1/labels' { \"status\": \"success\", \"data\": [ \"__name__\", \"call\", \"code\", \"config\", \"dialer_name\", \"endpoint\", \"event\", \"goversion\", \"handler\", \"instance\", \"interval\", \"job\", \"le\", \"listener_name\", \"name\", \"quantile\", \"reason\", \"role\", \"scrape_job\", \"slice\", \"version\" ] } 查询标签值 请求如下端点: GET /api/v1/label/\u003clabel_name\u003e/values JSON响应的data部分是标签值字符串列表。 栗子: $ curl http://localhost:9090/api/v1/label/job/values { \"status\" : \"success\", \"data\" : [ \"node\", \"prometheus\" ] } 表达式查询结果的格式 Expression query result formats 表达式查询结果可能会在data部分的result字段中返回以下响应值。 区间向量(range vectors) 区间向量返回matrix resultType。result的响应格式如下: [ { \"metric\": { \"\u003clabel_name\u003e\": \"\u003clabel_value\u003e\", ... }, \"values\": [ [ \u003cunix_time\u003e, \"\u003csample_value\u003e\" ], ... ] }, ... ] 瞬时向量(instant vectors) 瞬时向量返回vector resultType。result的响应格式如下: [ { \"metric","date":"2018-09-11","objectID":"/prometheus/:11:5","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"存储 Storage: https://prometheus.io/docs/prometheus/latest/storage/ Prometheus包含了一个本地磁盘上的时序数据库(time series database)，但是可选地与远程存储系统集成。 ","date":"2018-09-11","objectID":"/prometheus/:12:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"本地存储 Local storage Prometheus本地时序数据库存储时序数据自定义格式存储到磁盘上。 On-disk layout Prometheus按两小时为一个时间窗口分组存储在一个块(block)中。每个块是一个单独地目录，里面包含该时间窗口内的所有样本数据(chunks)，元数据文件(meta.json)以及索引文件(index)。其中索引文件会将指标名称和标签索引到样板数据的时间序列中。此期间如果通过 API 删除时间序列，删除记录会保存在单独的逻辑文件tombstone当中。 当前样本数据所在的块会被直接保存在内存中，不会持久化到磁盘中。为了确保Prometheus发生崩溃或重启时能够恢复数据，Prometheus启动时会通过预写日志（write-ahead-log(WAL)）重新记录，从而恢复数据。预写日志文件保存在wal目录中，每个文件大小为128MB。wal 文件包括还没有被压缩的原始数据，所以比常规的块文件大得多。一般情况下，Prometheus 会保留三个 wal 文件，但如果有些高负载服务器需要保存两个小时以上的原始数据，wal文件的数量就会大于3个。 Prometheus块数据的目录结构如下所示: ./data ├── 01BKGV7JBM69T2G1BGBGM6KB12 │ └── meta.json ├── 01BKGTZQ1SYQJTR4PB43C8PD98 │ ├── chunks │ │ └── 000001 │ ├── tombstones │ ├── index │ └── meta.json ├── 01BKGTZQ1HHWHV8FBJXW1Y3W0K │ └── meta.json ├── 01BKGV7JC0RY8A6MACW02A2PJD │ ├── chunks │ │ └── 000001 │ ├── tombstones │ ├── index │ └── meta.json └── wal ├── 00000002 └── checkpoint.000001 本地存储的局限性是它无法构建集群(clustered)或副本(replicated)。因此，如果本地磁盘或节点出现故障，存储将无法扩展和迁移。使用RAID用于磁盘的可用性，使用快照用于备份，容量规划…建议提高耐用性。如果你对数据持久化的要求不是很严格，可以使用本地磁盘存储多达数年的数据。 可替代地，外部存储可通过使用remote read/write APIs。仔细评估这些系统，因为它们在耐用性，性能和效率差异很大。 有关存储格式的详细信息，请参考 TSDB格式 ","date":"2018-09-11","objectID":"/prometheus/:12:1","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"Compaction 最初两个小时的块最终会在后台被压缩成更长的块。 ","date":"2018-09-11","objectID":"/prometheus/:12:2","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"操作配置 Prometheus提供了几个标志来允许配置本地存储。最重要的几个: # 数据存储路径，默认data/ --storage.tsdb.path # 样本数据在存储中保存的时间。超过该时间限制的数据就会被删除。默认15d -storage.tsdb.retention.time # 每个块的最大字节数（不包括 wal 文件）。如果超过限制，最早的样本数据会被优先删除。支持的单位有 KB, MB, GB, PB。默认0，即为不限制 --storage.tsdb.retention.size # 压缩wal --storage.tsdb.wal-compression 一般情况下，Prometheus中存储的每一个样本大概会占用1-2Byte。因此，如果需要对Prometheus Server的本地磁盘空间做容量规划，可通过以下公式计算: needed_disk_space = retention_time_seconds * ingested_samples_per_second * bytes_per_sample 从上面公式中可以看出在保留时间（retention_time_seconds）和样本大小（bytes_per_sample）不变的情况下，如果想减少本地磁盘的容量需求，只能通过减少每秒获取样本数（ingested_samples_per_second）的方式。因此有两种手段，一是减少时间序列的数量，二是增加采集样本的时间间隔。考虑到 Prometheus 会对时间序列进行压缩效率，减少时间序列的数量效果更明显。 \r\r \r\r可视化 Visualization ","date":"2018-09-11","objectID":"/prometheus/:12:3","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"表达式浏览器 Expression browser 表达其浏览器在 Prometheus Server 的 /graph 处。 对于图形，请使用 Grafana 或 Console template。 \r\r\r","date":"2018-09-11","objectID":"/prometheus/:13:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"Grafana Grafana: https://grafana.com/ Grafana，美丽的分析和监控的开放平台，时序分析的开源那软件。 Grafana 支持查询 Prometheus。如下是一个Grafana仪表盘，用于查询Prometheus的数据： \r","date":"2018-09-11","objectID":"/prometheus/:14:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"安装 完整的安装说明，请查看Grafana Docs。 \rCentOS RPM #sudo yum install \u003crpm package url\u003e sudo yum install https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-5.1.4-1.x86_64.rpm repo [grafana] name=grafana baseurl=https://packagecloud.io/grafana/stable/el/7/$basearch repo_gpgcheck=1 enabled=1 gpgcheck=1 gpgkey=https://packagecloud.io/gpg.key https://grafanarel.s3.amazonaws.com/RPM-GPG-KEY-grafana sslverify=1 sslcacert=/etc/pki/tls/certs/ca-bundle.crt sudo yum install -y grafana #启动 systemctl start grafana-server #命令行工具 grafana-cli 包详情 Installs binary to /usr/sbin/grafana-server Copies init.d script to /etc/init.d/grafana-server Installs default file (environment vars) to /etc/sysconfig/grafana-server Copies configuration file to /etc/grafana/grafana.ini Installs systemd service (if systemd is available) name grafana-server.service The default configuration uses a log file at /var/log/grafana/grafana.log The default configuration specifies an sqlite3 database at /var/lib/grafana/grafana.db 二进制tar文件 # Download and unpack Grafana from binary tar (adjust version as appropriate). curl -L -O https://grafanarel.s3.amazonaws.com/builds/grafana-2.5.0.linux-x64.tar.gz tar zxf grafana-2.5.0.linux-x64.tar.gz # Start Grafana. cd grafana-2.5.0/ ./bin/grafana-server web \r\rDocker #基础栗子 docker run -d -p 3000:3000 grafana/grafana #配置化 docker run \\ -d \\ -p 3000:3000 \\ --name=grafana \\ -e \"GF_SERVER_ROOT_URL=http://grafana.server.name\" \\ -e \"GF_SECURITY_ADMIN_PASSWORD=secret\" \\ grafana/grafana:version #默认环境变量值 GF_PATHS_CONFIG /etc/grafana/grafana.ini GF_PATHS_DATA /var/lib/grafana GF_PATHS_HOME /usr/share/grafana GF_PATHS_LOGS /var/log/grafana GF_PATHS_PLUGINS /var/lib/grafana/plugins GF_PATHS_PROVISIONING /etc/grafana/provisioning \r\r","date":"2018-09-11","objectID":"/prometheus/:14:1","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"使用 默认情况下，访问http://localhost:3000来访问Grafana。默认登录的用户名和密码： admin/admin。 创建Prometheus数据源 创建Prometheus图表 \r\r\r","date":"2018-09-11","objectID":"/prometheus/:14:2","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"Console template 控制台模板允许使用Go templating language创建任意控制台。这些都是从Prometheus Server提供的。 示例配置 由于prometheus自带的alertmanager对国内通知支持不够完善，因此使用PrometheusAlert做告警通知。 ","date":"2018-09-11","objectID":"/prometheus/:15:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"prometheus配置样例 prometheus的配置示例: # my global configglobal:scrape_interval:1m# Set the scrape interval to every 15 seconds. Default is every 1 minute.evaluation_interval:1m# Evaluate rules every 15 seconds. The default is every 1 minute.scrape_timeout:1m# scrape_timeout is set to the global default (10s).# for thanosexternal_labels:region:ali# hw|txreplica:full# Alertmanager configurationalerting:alertmanagers:- static_configs:- targets:[\"localhost:9093\"]# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.rule_files:- \"rules/*.yml\"# 通用告警规则模板- \"rules/nodes/*.yml\"# 各主机告警规则# A scrape configuration containing exactly one endpoint to scrape:# Here it's Prometheus itself.scrape_configs:# The job name is added as a label `job=\u003cjob_name\u003e` to any timeseries scraped from this config.- job_name:node-process-exporterfile_sd_configs:- files:- \"discovery/exporter/*.yml\"# metrics_path defaults to '/metrics'# scheme defaults to 'http'.- job_name:mongodb-exporterfile_sd_configs:- files:- \"discovery/mongodb/*.yml\"- job_name:kafka-exporterfile_sd_configs:- files:- \"discovery/kafka/*.yml\"- job_name:aliyun-exporterstatic_configs:- targets:[\"localhost:9525\",\"localhost:9526\",\"localhost:9527\",\"localhost:9528\",\"localhost:9529\"]- job_name:blackbox_exportermetrics_path:/probefile_sd_configs:- files:- \"discovery/blackbox/*.yml\"relabel_configs:- source_labels:[__address__]target_label:__param_target- source_labels:[module]target_label:__param_module- source_labels:[__param_target]target_label:instance- target_label:__address__replacement:127.0.0.1:9115 ","date":"2018-09-11","objectID":"/prometheus/:16:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"alertmanager配置样例 alertmanager的配置示例: # global configglobal:resolve_timeout:5m# smtp config# slack config# wechat config# http config# templates configtemplates:[]# route treeroute:receiver:'web.hook.prometheusalert'group_by:- instanceId- hostnamegroup_wait:30sgroup_interval:1m# notification againrepeat_interval:10m# continue config# match: [ \u003clabelname\u003e: \u003clabelvalue\u003e, ... ]# match_re: [ \u003clabelname\u003e: \u003cregex\u003e, ... ]routes:- match:severity:warningrepeat_interval:1h- match_re:severity:notice|inforepeat_interval:6h# receiver listsreceivers:- name:'web.hook.prometheusalert'webhook_configs:- url:'http://127.0.0.1:8080/prometheus/alert'# list of inhibit rulesinhibit_rules:# aliyun- source_match:severity:'critical'target_match_re:severity:'warning'# source_match_re# target_match_re# Labels that must have an equal value in the source and targetequal:['instance','job','instanceId','kind']# nodes- source_match:severity:'critical'target_match_re:severity:'warning'equal:- instance- job- hostname- kind ","date":"2018-09-11","objectID":"/prometheus/:17:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"prometheus自动发现 prometheus的文件自动发现示例: - labels:hostname:localhosthostgroup:testtargets:- \"localhost:9100\"# node-exporter- \"localhost:9256\"# process-exporter ","date":"2018-09-11","objectID":"/prometheus/:18:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"prometheus告警规则 prometheus的告警规则示例: groups:- name:node-cpurules:# cpu核数- record:instance:node_cpus:countexpr:count without (cpu, mode) (node_cpu_seconds_total{mode=\"idle\"})# 每个cpu使用率- record:instance_cpu:node_cpu_seconds_not_idle:rate2mexpr:sum without (mode) (1 - rate(node_cpu_seconds_total{mode=\"idle\"}[2m]))# 总cpu使用率- record:instance:node_cpu_utilization:ratioexpr:avg without (cpu) (instance_cpu:node_cpu_seconds_not_idle:rate2m)- alert:cpu使用率大于85%### expr: (1 - avg(irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) by(instance,hostname)) * 100 \u003e 85expr:instance:node_cpu_utilization:ratio * 100 \u003e 85for:3mlabels:severity:warninglevel:2kind:CpuUsageannotations:summary:\"cpu使用率大于85%: {{ $labels.hostname }}\"description:\"{{ $labels.hostname }}的cpu使用率: {{ $value | humanize }}%\"- alert:cpu使用率大于90%### expr: (1 - avg(irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) by(instance,hostname)) * 100 \u003e 90expr:instance:node_cpu_utilization:ratio * 100 \u003e 90for:1mlabels:severity:criticallevel:3kind:CpuUsageannotations:summary:\"cpu使用率大于90%: {{ $labels.hostname }}\"description:\"{{ $labels.hostname }}的cpu使用率: {{ $value | humanize }}%\"wxurl:\"xxx\"- alert:cpu使用率一分钟内增长30%且大于70%expr:delta(instance:node_cpu_utilization:ratio[2m]) * 100 \u003e 30 and on(hostname) instance:node_cpu_utilization:ratio * 100 \u003e 70labels:severity:warninglevel:2kind:CpuUsageDeltaannotations:summary:\"cpu使用率一分钟内增长30%且大于70%: {{ $labels.hostname }}\"description:\"{{ $labels.hostname }} 的cpu使用率一分钟内增长30%且大于70%，增长率: {{ $value | humanize }}%\"wxurl:\"xxx\"- alert:cpu使用率一分钟内增长40%且大于80%expr:delta(instance:node_cpu_utilization:ratio[2m]) * 100 \u003e 40 and on(hostname) instance:node_cpu_utilization:ratio * 100 \u003e 80labels:severity:criticallevel:3kind:CpuUsageDeltaannotations:summary:\"cpu使用率一分钟内增长40%且大于80%: {{ $labels.hostname }}\"description:\"{{ $labels.hostname }} 的cpu使用率一分钟内增长40%且大于80%，增长率: {{ $value | humanize }}%\"- alert:cpu使用率一分钟内增长50%expr:delta(instance:node_cpu_utilization:ratio[2m]) * 100 \u003e 50labels:severity:criticallevel:3annotations:summary:\"cpu使用率一分钟内增长50%: {{ $labels.hostname }}\"description:\"{{ $labels.hostname }} 的cpu使用率一分钟内增长50%，增长率: {{ $value | humanize }}%\"- alert:cpu负载大于Cores### expr: node_load1 \u003e count(node_cpu_seconds_total{mode=\"idle\"}) without (cpu,mode)expr:node_load1 \u003e instance:node_cpus:countfor:3mlabels:severity:warninglevel:2kind:CpuLoadannotations:summary:\"cpu负载大于cpu核数: {{ $labels.hostname }}\"description:\"{{ $labels.hostname }}的cpu负载: {{ $value }}\"- alert:cpu负载大于2Cores-2### expr: node_load1 \u003e 2 * (count(node_cpu_seconds_total{mode=\"idle\"}) without (cpu,mode)) - 2expr:node_load1 \u003e (instance:node_cpus:count * 2) - 2for:1mlabels:severity:criticallevel:3kind:CpuLoadannotations:summary:\"cpu负载大于2Cores-2: {{ $labels.hostname }}\"description:\"{{ $labels.hostname }}的cpu负载: {{ $value }}\"- alert:主机上下文切换忙### expr: (rate(node_context_switches_total[5m])) / (count without(cpu, mode) (node_cpu_seconds_total{mode=\"idle\"})) \u003e 2000expr:(rate(node_context_switches_total[5m]) / instance:node_cpus:count) \u003e 2000for:5mlabels:severity:warninglevel:2annotations:summary:\"主机上下文切换忙: {{ $labels.hostname }}\"description:\"主机{{ $labels.hostname }}的上下文切换大于2000/s: {{ $value | humanize }}/s\"- name:node-memoryrules:# 内存可用率- record:instance:node_memory_available:ratioexpr:\u003e( node_memory_MemAvailable_bytes or ( node_memory_Buffers_bytes + node_memory_Cached_bytes + node_memory_MemFree_bytes + node_memory_Slab_bytes ) ) / node_memory_MemTotal_bytes# 内存使用率- record:instance:node_memory_utilization:ratioexpr:1- instance:node_memory_available:ratio- alert:主机内存面临压力expr:rate(node_vmstat_pgmajfault[1m]) \u003e 1000for:5mlabels:severity:warninglevel:2annotations:summary:\"主机内存面临压力: {{ $labels.instance }}\"description:\"节点内存面临压力。High rate of major page faults: {{ $value }}\"- alert:内存使用率大于85%### expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 \u003e 85expr:instance:node_memory_utilization:ratio * 100 \u003e 85for:3mlabels:severity:warninglevel:2kind:MemoryUsageannotations:summary:\"内存使用率超过85%: {{ $labels.hostname }}\"descri","date":"2018-09-11","objectID":"/prometheus/:19:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"进程探针配置 process-exporter探针配置示例: # https://github.com/ncabatoff/process-exporter# /proc/\u003cpid\u003e/xxxprocess_names:# java- name:\"{{.Matches}}\"cmdline:- '.+/bin/java .+'- name:\"{{.Matches}}\"cmdline:- 'java .+'#匹配完整的运行命令- name:\"{{.Matches}}\"#- name: \"{{.Comm}}\"cmdline:- '.+' ","date":"2018-09-11","objectID":"/prometheus/:20:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"进程告警规则 prometheus进程告警规则示例: groups:- name:测试进程告警规则rules:- alert:nginx进程不存在expr:'sum(namedprocess_namegroup_states{groupname=~\"map\\\\[:nginx: master process .+\"}) without(state) == 0'for:1mlabels:severity:criticallevel:3annotations:summary:\"nginx进程不存在, 实例: {{ $labels.instance }}\"description:\"主机: {{ $labels.hostname }}, 进程不存在: {{ $labels.groupname }}\"wxurl:webhook1,webhook2mobile:phone1,phone2- alert:filebeat进程不存在expr:sum without(state) (namedprocess_namegroup_states{groupname=~\"map\\\\[:/usr/share/filebeat/bin/filebeat -e -c .+\", hostgroup=\"xxx\"}) == 0for:1mlabels:severity:criticallevel:3annotations:summary:\"filebeat进程不存在, 实例: {{ $labels.instance }}\"description:\"主机: {{ $labels.hostname }}, 进程不存在: {{ $labels.groupname }}\"wxurl:webhook1,webhook2mobile:phone1,phone2 集成 INSTRUMENTING ","date":"2018-09-11","objectID":"/prometheus/:21:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"客户端库 CLIENT LIBRARIES: https://prometheus.io/docs/instrumenting/clientlibs/ 在监控服务之前，您需要通过 Prometheus 客户端库在其代码中添加集成。 选择与你编程语言相匹配的prometheus client library。你可以通过你的应用程序实例的HTTP endpoint来定义和暴露内部指标数据。 当prometheus采集你实例的HTTP端点时，客户端库会将所有指标的当前状态发送给prometheus server。 ","date":"2018-09-11","objectID":"/prometheus/:22:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"编写客户端库 WRITING CLIENT LIBRARIES: https://prometheus.io/docs/instrumenting/writing_clientlibs/ 本章涵盖了Prometheus client libraries应该提供的功能和API。支持10种编程语言，因此编写客户端有很好的感觉。 ","date":"2018-09-11","objectID":"/prometheus/:23:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"惯例 Conventions 应该注意的事： 采取每门语言的优点 常见的使用情况应该很容易 做某事的正确方式应该是简单的方式 更复杂的用例应该是可能的 常见用例： Counters without labels spread liberally around libraries/applications Timing functions/blocks of code in Summaries/Histograms Gauges to track current states of things (and their limits) Monitoring of batch jobs ","date":"2018-09-11","objectID":"/prometheus/:23:1","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"整体结构 Overall structure 客户端必须在内部进行回调以进行写操作。客户端一般应该遵循如下描述的结构。 关键类是收集器(collector)。这有个方法(一般称为collect)，此方法返回0和更多指标和样本。Collectors get registered with a CollectorRegistry. 数据通过传递一个CollectorRegistry到一个bridge类/方法/函数来公开，返回的是Promehteus支持的格式指标。每次CollectorRegistry抓取它必须回调每个收集器的收集方法。 大多数用户交互的接口是Counter, Gauge, Summary, Histogram收集器。这些代表一个单一指标，并应涵盖绝大多数使用情况，其中用户集成自己的代码。 更高级的用户案例（如从其它监控系统进行代理）需要编写一个自定义收集器。有人可能还希望编写一个bridge，以一个格式不同的监控系统来产生CollectorRegistry和生成数据，允许用户只考虑一个集成系统。 CollectorRegistry应该提供register(), unregister()函数，并且一个收集器应该被允许注册到多个CollectorRegistrys。 客户端必须是线程安全的。 命名 Namming 客户端库应遵循此文档中提及的函数，方法，类名称，记住它们的命名规范。例如，set_to_current_time()是一个好的Python命名规范，SetToCurrentTime()是一个好的Go命名规范，setToCurrentTime()是一个好的Java命名规范。 ","date":"2018-09-11","objectID":"/prometheus/:23:2","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"指标 Metrics Counter, Gauge, Summary, Histogram指标类型是用户的主要接口。 Counter和Gauge必须是客户端库的一部分。Summary和Histogram至少有一个必须提供。 这些应主要用于为静态文件变量(file-static variables)，也就是说，全局变量定义在同一个文件，因为他们集成代码。客户端库应该启用它。常用情况是集成一段整体代码，而不是一个对象的一个实例的上下文中的一段代码。用户不应该在代码中担心探测他们的指标，客户端库应该代劳。 必须有一个默认的CollectorRegistry，默认的标准指标必须隐式注册到它与该用户不需要的特殊工作。必须有一个方式来让指标不注册到默认CollectorRegistry，在批处理作业和单元测试。自定义收集器应该遵顼这一点。 究竟编程语言应该如何创建指标。对于一些(Java, Go)构建器方法是最好的，对于其它(Python)函数参数是足够丰富的。 Java样例客户端: class YourClass { static final Counter requests = Counter.build() .name(\"requests_total\") .help(\"Requests.\").register(); } Counter Counter是一个单调递增的计数器。它不允许值减少，但可能被重置为0（如服务器重启）。 计数器必须有以下方法： inc()：计数器递增1 inc(douvel v)：计数器由给定数增加（v\u003e=0） 计数器必须从0开始。 计数器建议有： 计算给定一段代码异常抛出/升起的方法，可选地仅特定异常类型 Gauge Gauge表示一个值可增可减。 测量必须有以下方法： inc()：测量递增1 inc(double v)：测量由给定数增加 dec()：测量递减1 dec(double v)：测量由戈丁数减少 set(double v)：测量被设置为给定值 测量必须从0开始，你也可以在启动时提供一个不同值。 测量应该有以下方法： set_to_current_time()：将测量设置为unixtime 测量建议有： 使用一个方法来追踪某条函数/代码正在进行的请求。在Python中是track_inprogress。 测试一段代码实践的一个方法和测试测量的持续时间。这对于批量作业很有用。 Summary Summary样例观察滑动时间窗，兵器提供分布、频率、和的瞬时观察。 摘要绝不允许用户设置quantile作为标签名，因为这是内部使用的指定摘要总数(summary quantiles)。摘要鼓励提供quantiles作为exports，但这些都布恩那个进行聚合，并趋于缓慢。摘要必须允许每个quantiles，如_count, _sum是非常有用的，这必须是默认的。 摘要_count, _sum必须从0开始。 摘要必须有的方法： observe(double v)：观察给定的量 摘要应该有的方法： 以秒为用户的时间码。在Python中是time()。不能提供除了秒之外的其它单位。 Histogram Histogram允许事件的可分布聚合，如请求的等待时间。 直方图绝不允许le作为用户设置的label，le用于内部指派桶。 直方图必须提供一个方式来手动选择桶。方式以linear(start, width, count)和exponential(start, factor, count)应该提供来设置桶。计数必须排除+Inf桶。 直方图应该有相同的默认桶作为其它客户端库。一旦创建了指标桶就不能改变。 直方图必须有的方法： observe(double v) 直方图应该有的方法： 以秒为用户的时间码。不能提供除了秒之外的其它单位。 标签 Labels 标签是Prometheus最强大的一个方面，但容易被滥用。因此客户端库必须在提供标签给用户时必须非常小心。 客户端库必须在任何情况下让用户为Gauge, Counter, Summary, Histogram或其它由库提供的任意收集器有不同的标签名。 自定义收集器指标应该总是具有一致的标签名。客户端不该对此进行验证。 虽然标签很强大，但多数指标没有标签。因此，API应该允许标签，而不是控制它。 一个客户端库必须允许在Gauge, Counter, Summary, Histogram创建时间指定任意标签名的列表。客户端库应该支持任意数量的标签名。客户端库必须验证标签名称符合文件要求。 提供访问指标的标记尺寸的一般方法是通过labels()方法，它可以以标签指列表或从标签名到标签执的映射，并返回一个child。通常是.inc(), .dec(), .observe()等等。方法可以在child上调用。 通过labels()返回的Child应该由用户缓存，以避免再次看到它。 有标签的指标应该支持有相同签名作为labels()的remove()方法，这将从指标中移除一个child并不再公开它，clear()方法将移除指标的所有孩子。 这应该有一个方法，来初始化一个带有默认值的孩子，通常只是调用labels()。不带标签的指标必须总是被初始化，以避免缺失指标问题。 指标名称 Metric names 指标名称必须遵循规范。正如指标名称，这必须满足Gauge, Counter, Summary, Histogram的用途，并与该库提供的任意收集器。 许多客户端库提供三个部分来设置名称：namespace_subsystem_name。 动态/生成 指标名称或指标名子部分必须阻止，当一个自定义收集器从其它监控系统代理时除外。动态的/生成的 指标名称是你要使用的标签而不是一个标志。 指标描述和帮助 Metric description and help Gauge/Counter/Summary/Histogram 必须要求提供指标描述和帮助。客户端库提供的任意自定义收集器必须在指标上有描述和帮助。 ","date":"2018-09-11","objectID":"/prometheus/:23:3","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"公开 Exposition 客户端必须执行基于文本的公开格式，详细文档: https://prometheus.io/docs/instrumenting/exposition_formats/ 公开的指标的可再现的顺序是鼓励的（尤其是以人类可读的格式），如果它可在没有显著资源成本增加来实现。 ","date":"2018-09-11","objectID":"/prometheus/:23:4","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"标准和运行时收集器 Standard and runtime collectors 客户端库应该在标准导出中提供些什么，下面将介绍。 这些应该被实现为自定义收集器，并在默认的CollectorRegistry默认注册。应该有方式来禁用这些。 进程指标 Process metrics 这有一些以process_为前缀的指标。如果获得必要的值是有问题的，或甚至根本无法使用语言，或运行时，客户端库应该留出相应的指标或特殊值(如NaN)。所有以字节的内存值，所有以unixtime/seconds的时间。 指标名 帮助字符串 单位 process_cpu_seconds_total Total user and system CPU time spent in seconds seconds process_open_fds Number of open file descriptors file descriptors process_max_fds Maximum number of open file descriptors file descriptors process_virtual_memory_bytes Virtual memory size in bytes bytes process_virtual_memory_max_bytes Maximum amount of virtual memory available in bytes bytes process_resident_memory_bytes Resident memory size in bytes bytes process_heap_bytes Process heap size in bytes bytes process_start_time_seconds Start time of the process since unix epoch in seconds seconds 运行时指标 Runtime metrics 此外，客户端库鼓励提供有意义的指标当语言运行时，如go_, hotspot_等等前缀开头的相关指标。 ","date":"2018-09-11","objectID":"/prometheus/:23:5","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"单元测试 Unit tests 客户端库应该有覆盖核心集成库和公开的单元测试。 客户端库鼓励提供一个方式，使用户更容易进行单元测试。例如，在Python中有CollectorRegistry.get_sample_value。 ","date":"2018-09-11","objectID":"/prometheus/:23:6","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"打包和依赖 Packaging and dependencies 理想情况下，客户端库可以被包括在任意应用程序中添加一些集成而不会破坏程序。因此，添加客户端库的依赖时请小心。 ","date":"2018-09-11","objectID":"/prometheus/:23:7","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"性能考虑 Performance considerations 由于客户端库必须是线程安全的，需要某种形式的并发控制和考虑多核机器和应用程序的性能。 根据经验最少的高性能是互斥。处理器原子指令往往是在中间，并且一般是可接受的。 如上所述，labels()的结果应该是可缓存的。指标应该避免被阻塞当它们被递增或递减时。 ","date":"2018-09-11","objectID":"/prometheus/:23:8","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"推送指标 PUSHING METRICS: https://prometheus.io/docs/instrumenting/pushing/ 偶尔，你需要监控不能被抓取的组件。Prometheus Pushgateway允许你推送指标。与Prometheus简单额基于文本格式相结合，这使得它很容易集成，甚至使用shell脚本而不需要客户端库。 ","date":"2018-09-11","objectID":"/prometheus/:24:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"探针和集成 EXPORTERS AND INTEGRATIONS: https://prometheus.io/docs/instrumenting/exporters/ 有许多库和第三方系统可为Prometheus提供相应的指标。 ","date":"2018-09-11","objectID":"/prometheus/:25:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"第三方探针 Third-party exporters 有一些探针是由Prometheus官方维护的，其它的是由第三方贡献和维护。 ","date":"2018-09-11","objectID":"/prometheus/:25:1","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"编写探针 WRITING EXPORTERS: https://prometheus.io/docs/instrumenting/writing_exporters/ 如果你在集成自己的代码，那么Prometheus client library如何集成自己的代码的通用规则应该被遵守。当从另一个监控或集成系统采取指标时，事情往往并不是非黑即白。 当编写一个探针或自定义收集器时，此文档包含的事情你应该考虑。 ","date":"2018-09-11","objectID":"/prometheus/:26:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"可维护性和纯度 Maintainability and purity 当你编写一个探针时，你需要做出的一个决定是有多少工作你愿意放在获得完美的指标上。 如果有问题的系统只有很少改变的指标的一小撮，然后让一切完美是一个容易的选择，一个好的样例是HAProxy exporter 在另一方面，当系统上有上百个指标是新版本经常变动的，如果你想试图把事情做完美，那么你已经给自己制造了许多正在进行的工作。MysQL exporter在这系列(spectrum)的末端。 node exporter是这些的混合。例如，mdadm收集器手动解析一个文件并公开为此收集器特定创建的指标。对于meminfo收集器，结果跨越不同内核版本，因此我们最终做足够的转换来创建有效的指标。 ","date":"2018-09-11","objectID":"/prometheus/:26:1","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"配置 Configuration 当程序工作时，你的目标应该是探针不需要用户自定配置就可以运行。你可能还希望提供过滤某些指标的能力（用户定义只需要收集的指标，不需要收集所有指标），降低系统的开销。例如node exporter可让用户定义收集哪些指标，虽然我是全部收集。 当与其它监控系统一起工作时，框架和协议，你将提供额外的配置或自定义来生成适合Prometheus的指标。在最好的情况下，一个监控系统有类似的足够的Prometheus数据模型，你可以自动确定如何转换指标。如Cloudwatch, SNMP, collectd的情况。至多，我们需要让用户选择获取的那些指标。 也就是探针配置简单化，探针指标用户可选择。 在其它情况下，系统指标是不是十分标准的，这却决于系统和底层应用的使用情况。在这种情况下，用户必须告诉我们如何转换转换指标。JMX exporter是最明显的案例，与Graphite exporter和StatsD exporter也需要配置来提取标签。 确保探针出口开箱没有配置，以及提供需要转换的示例配置的选择，这是一个建议。 YAML是标准的Prometheus配置格式，所有配置默认都应该适应YAML。 ","date":"2018-09-11","objectID":"/prometheus/:26:2","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"指标 Metrics 命名 Naming 遵循指标命名的最佳实践。 指标名不应该由程序产生，除非在编写自定义收集器或探针时。 指标必须使用基础单位并让它们转换为更可读的图形工具。无论你使用了什么单位，指标名中的单位必须匹配在使用的单位。类似地，公开比率(ratios)，而不是百分比(percentages)。 指标名不应该包含导出的标签，如果标签被聚集将没有意义。Prometheus指标和标签名以snake_case编写。公开的指标不应包含冒号，这些被保留用于用户定义记录规则(recording rules)，当使用聚合时。 只有[a-zA-Z0-9:_]是有效的指标名。 _sum, _count, _bucket, _total后缀用于Summary, Histogram, Counter。_total是Counter的惯例，如果你使用COUNTER类型你应该使用它。 process_, scrape_前缀是保留的。 当你有一个successful request count和一个failed request count，最佳的方式是一个指标用于成功的请求，另一个指标用于失败的请求。这很容易计算出失败率。不要使用带success或failed标签的一个指标。同样，此规则也同样适用于其它指标。 一个带有原始名的HELP字符串可以提供大部分相同的好处。 标签 Labels 避免将type作为标签名称，它过于笼统往往无意义。你应该尝试尽可能地避免发生冲突，如region, cluster等等。但是，如果这就是应用程序调用的一些资源，最好不要通过重命名来引起混乱。 因此要避免把东西放入一个指标，只是因为它们共享一个前缀。除非你确定一个指标是有意义的，多个指标是安全的。 le标签对于Histogram有特殊意义，quantile标签对于Summary有特殊意义。通常避免使用这些标签。write/read， send/receive最好划分为单独的指标，而不是一个指标。 经验法则是，当求和或求平均值时，一个指标应该是有意义的。 类型 Type 你应该尝试匹配你的指标类型到Prometheus类型。这通常是counters和gauges。通常它不会很明显指标是什么类型，特别是如果你自动处理一组指标。一般UNTYPED是一个安全的默认值。 帮助字符串 Help strings 当你转换指标时，它对用于能够追踪原来是什么样的有帮助，以及造成这种转换有什么规则。将收集器或探针名称、应用的任意规则的ID和名称和原始指标的详情写入帮助字符串将极大地帮助用户。 Prometheus不喜欢一个字段有不同的帮助字符串。 示例: # HELP node_cooling_device_max_state Maximum throttle state of the cooling device # TYPE node_cooling_device_max_state gauge node_cooling_device_max_state{name=\"0\",type=\"Processor\"} 7 node_cooling_device_max_state{name=\"1\",type=\"Processor\"} 7 node_cooling_device_max_state{name=\"2\",type=\"Processor\"} 7 丢弃更少的有用信息 Drop less useful statistics 有些集成系统公开了1m, 5m, 15m率、平均率，在应用程序启动的时候。 这些都应该被丢弃，因为它们不是很有用，并添加了混乱。Prometheus可以自己计算比率，并且通常作为公开的平均值呈指数衰减。 点字符串 Dotted strings 许多监控系统没有标签，而是使用点: my.class.path.mymetric.labelvalue1.labelvalue2.labelvalue3 ","date":"2018-09-11","objectID":"/prometheus/:26:3","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"收集器 Collectors 当为探针实现收集器时，你永远不应该使用通常的直接集成方法，并在每个抓取上更新指标。 每次创建新的指标。在Go的Collect()方法中使用MustNewConstMetric。Python请参考: https://github.com/prometheus/client_python#custom-collectors 原因有两方面。首先，两个抓取可能发生在同一时间，和直接集成使用的什么是文件级别的全局变量。其次，如果一个标签执消失，它仍然将公开。 关于抓取自身的指标 Metrics about the scrape itself 有时你想导出关于抓取的指标，如处理了多少记录等。这应该被公开为gauges当它们关于事件时，通过探针名的指标名前缀，如jmx_scrape_duration_seconds。 机器和进程指标 Machine and process metrics 许多系统，如ES，会公开机器指标（如cpu, memory, filesystem）等信息。Prometheus生态中的node exporter提供了这些信息，这些指标就应该被丢弃。 在Java世界里，许多集成框架公开了程序级别和JVM级别的统计信息，如CPU, GC等。Java客户端和JMX探针已包含这些，所以也应该丢弃。这同样也可用于其它类似的语言和框架。 ","date":"2018-09-11","objectID":"/prometheus/:26:4","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"部署 Deployment 每个探针应该监控只有一个实例的应用程序，preferably sitting right beside it on the same machine。这意味着你运行没给一个HAProxy，你运行了一个haproxy_exporter进程。 调度 Scheduling 当Prometheus抓取指标时，指标应该从应用处拉取，探针不应该基于自己的定时器执行抓取。也就是说，所有的抓取都应该是同步的(synchronous)。 因此，你不应该在公开的指标上设置时间戳，而让Prometheus来做。如果你认为需要时间戳，那么你可能需要使用pushgateway来代替。 如果检索指标特别昂贵，即超过了一分钟，可以接受的是缓存它(cache it)。这应该在注释在HELP字符串中。 Prometheus默认抓取的超时时间是10s。如果你的探针希望超过这一点，你应该在你的用户文档中明确的调用此。 推送 Pushes 有些应用程序和监控系统只能推送指标(push metrics)，如StatsD, Graphite, collectd。有两方面的考虑： 首先，指标什么时候过期？ 其次，这些类型的系统倾向于允许你的用户发送变化量(deltas)或原始计数器(raw counter)。你应该尽可能依赖原生计数器，因为这一般是Prometheus model。 对于服务级别的指标，你应该有探针推送到Pushgateway，在事件而不是你自己处理状态之后退出。对于实例级别的指标，还没有明确模式。 抓取失败 Failed scrapes 目前有两种模式的抓取失败，当应用程序不响应或其它问题时。 第一个就是返回5xx错误。 第二个是有一个myexporter_up，如haproxy_up，值是0还是1依赖于抓取工作。 后者更好，即使抓取失败，你还可以得到一些有用的指标。 抓取页面 Landing page 访问地址，如http://expoter:port作为一个简单的包含探针名称的HTML页面，并有指向/metrics页面的链接。 端口号 Port numbers 用户在一个机器上可能有多个探针和Prometheus组件，为了使得事情更简单每个需要有一个唯一的端口号。这个页面https://github.com/prometheus/prometheus/wiki/Default-port-allocations包含了Prometheus组件和探针目前使用的端口号。 为自己的探针分配一个合理的，没有使用的端口号。 ","date":"2018-09-11","objectID":"/prometheus/:26:5","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"宣布 Announcing 一旦你准备向世界宣布你的探针，请在可用的探针列表提交一个PR。 \r\r","date":"2018-09-11","objectID":"/prometheus/:26:6","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"textfile 可以在node_exporter中使用textfile，来获取用户生成的自定义的指标，存入textfile目录下文件内。 启动的时候加上--collector.textfile.directory参数，此目录下文件后缀为xxx.prom。 可以使用supervisor守护编写的脚本，每分钟生成自定义指标写入textfile目录下的对应指标文件。 示例: node_exporter --collector.textfile.directory=/tmp/textfile cd /tmp/textfile cat test1.prom # TYPE test1 gauge # HELP test1 test test1 1 最佳实践 BEST PRACTICES ","date":"2018-09-11","objectID":"/prometheus/:27:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"指标和标签命名 METRIC AND LABEL NAMING: https://prometheus.io/docs/practices/naming/ 指标和标签的约定不需要使用Prometheus，但可以作为一个风格指南和最佳实践的集合。 ","date":"2018-09-11","objectID":"/prometheus/:28:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"指标名称 Metric names 一个指标名称： 必须符合有效字符的数据模型 应该有一个应用程序(single-word)相关的指标所属前缀。如： prometheus_notifications_total process_cpu_seconds_total http_request_duration_seconds 必须有一个单一的单位（如秒，毫秒等） 应该使用基本单位（如seconds, bytes, meters，而不是milliseconds, megabytes, kilometers） 应该有一个描述单位的后缀。如： http_request_duration_seconds node_memory_usage_bytes http_requests_total process_cpu_seconds_total foobar_build_info should represent the same logical thing-being-measured across all label dimensions request duration bytes of data transfer instantaneous resource usage as a percentage 作为一个经验，在给定指标的所有尺寸上，无论是sum()还是avg()都应该是有意义的。如果没有意义，则将数据分裂成多个指标。 ","date":"2018-09-11","objectID":"/prometheus/:28:1","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"标签 Labels 使用标签来区分被测量的事物的特点： api_http_requests_total，不同的请求类型：operation=\"create|update|delete\" api_request_duration_seconds，不同的请求阶段：stage=\"extract|transform|load\" 不要将标签名对应到指标名，如果相应的标签聚合了，这会冗余并造成混乱。 注意： 请记住，标签键值对每一个独特的组合代表了一个新的时间序列，这可能会极大的提高存储的数据量。不要使用标签来存储高基数，如用户ID，邮件地址等。 ","date":"2018-09-11","objectID":"/prometheus/:28:2","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"基本单位 Base units Prometheus没有硬编码任何单位。为了更好的兼容性，应该使用基本单位。以下是一些栗子： Family Base unit Remark Time seconds - Temperature celsius 摄氏度优于开尔文 Length meters - Bytes bytes - Bits bytes 为了避免混淆，通常使用bytes Percent ratio 0-1而不是0-100 Voltage volts - Electric current amperes - Energy joules - Mass grams 克优于千克 ","date":"2018-09-11","objectID":"/prometheus/:28:3","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"控制台和仪表盘 CONSOLES AND DASHBOARDS: https://prometheus.io/docs/practices/consoles/ 可在仪表盘上显示尽可能多的数据，特别是像Prometheus这样的系统提供了集成你的应用程序的能力。 我们发现以下原则非常有效： 在一个控制台上不要超过五个图 每个图上不要超过五个线 当使用控制台提供的模板示例，请避免在右边表超过20-30项 ","date":"2018-09-11","objectID":"/prometheus/:29:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"集成 INSTRUMENTATION: https://prometheus.io/docs/practices/instrumentation/ 本章提供了集成你的代码的一套指导方案。 ","date":"2018-09-11","objectID":"/prometheus/:30:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"如何集成 How to instrument 简短的回答是集成一切。每个库、子系统和服务应该至少有几个指标来给你一个粗略的想法它是如何执行的。 服务的三种类型 The three types of services 为了监控的目的，服务大致可以分为三类：在线服务(online-serving)，离线处理(offline-processing)，批处理作业(batch jobs)。它们之间有重叠，但每个服务往往很好地成为这些类别。 在线服务系统 Online-serving systems 一个在线服务系统期待立即响应。例如，大多数数据库和HTTP请求都属于这一类。这种系统的关键指标是执行的查询数，错误和延迟。 离线处理 Offline processing 对于离线处理，没有人正在等待响应。也可能有多个处理阶段。对于每一个阶段，跟踪进入的项目，有多少在处理，最后一次处理的事物，以及发送了多少事物。 批处理作业 Batch jobs 在离线处理和批处理作业之间有一些模糊线，离线处理也可在批处理作业中完成。批处理作业不连续运行，这使得它们难以区分。 批处理作业的关键指标是它最后一次成功。这对于追踪各个阶段的花费时间，整体运行和最后一次作业完成很有用。对于那些超过几分钟时间运行的批处理作业，使用基于Pull监控的数据抓取很有用。对于运行很频繁地批处理作业，你应该考虑将其转换为守护程序(daemons)，作为离线处理作业来处理它们。 子系统 Subsystems 除了三种主要类型的服务，系统也应该监控子部分(sub-parts)。 库 Libraries 库应该提供无需用户额外配置的集成。 如果一个库经常访问进程外的资源（如网络、磁盘、IPC…），追踪整个查询计数，错误和延迟。 日志 Logging 作为一般规则，对与日志代码的每一行，你应该有一个递增的计数器(counter)。如果你发现一个有趣的日志信息，你要能过够看到它如何发生，而且持续多久。 失败 Failures 故障应该与日志有相似的处理。每次出现故障，计数器(counter)都应增加。不像日志，取决于你的代码结构，错误也可以丢到一个更普遍的错误计数器。当报告故障，你通常应该有一些其它指标来表示尝试的总数。这使得故障率很容易计算。 线程池 Threadpools 对于任何形式的线程池，关键指标是排队请求数，在使用的线程数，总线程数，处理的任务数，以及它们耗时多久。 缓存 Caches 缓存的关键指标是总查询、点击、总延时、查询数、错误和任何在线服务缓存前的延迟。 收集器 Collectors 当实现一个自定义指标收集器时，建议为收集花费的时间(s)导出为gauge，另一个是遇到的错误的数量。 ","date":"2018-09-11","objectID":"/prometheus/:30:1","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"要提防的事 Things to watch out for 当做监控时，有些事需要注意，Prometheus-specific尤其如此。 使用标签 Use labels 很少有监控系统有标签和表达式语言的来利用这些优点，所以需要一些时间来使用。当你有多个指标要添加/求平均值/求和，它们通常是带有标签的指标，而不是多个指标。 例如，创建一个带有code标签的http_responses_total指标，而不是http_responses_500_total，http_responses_403_total两个指标。 不要滥用标签 Do not overuse labels 每个标签集(labelset)是具有RAM, CPU, disk, network开销的额外时间序列。通常情况下，开销可以忽略不计，但有很多机器和很多指标和很多标签的情况下，这可能会迅速增加。 作为一般原则，尽量保持指标的基础低于10。绝大多数的指标没有任何标签。如果你有一个有100多个基数的指标，调查替代解决方案。 为了让你对基数有一个更好的主意，让我们来看下node_exporter。节点探针公开每个挂载的文件系统的指标。如果你有10000台机器，有10000个node_filesystem_avail时间序列，这对于Prometheus处理很好。 如果你不确定，就不用标签，并随着时间的推移添加更多标签。 四种类型比较 Counter vs. gauge, summary vs. histogram 对一个给定的指标用哪个四种主要的指标类型是很重要的。 在Counter和Gauge之间选择，有一个简单的经验法则：如果值可减少，这是一个Gauge。Counter只能增加，如累积的量。Gauge可以设置，增加或减少。 Summaries和Histograms是更复杂的指标类型。 时间戳 Timestamps, not time since 如果你想追踪从某事发生时的时间量，导出在它发生时的Unix时间戳，而不是从它发生的时间。 导出了时间戳，可以使用time() - my_timestamp_metric表达式计算时间。 避免缺失指标 Avoid missing metrics 时间序列，直到某事发生不存在难以应付，因为通常的简单操作不足以正确处理它们。为了避免这种情况，你事先知道可能存在的任何时间序列输出为0(或NaN)。 大多数Prometheus Client Libraries(go, java, python)会为没有标签的指标自动导出0。 ","date":"2018-09-11","objectID":"/prometheus/:30:2","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"Hisgogram和Summary HISTOGRAMS AND SUMMARIES: https://prometheus.io/docs/practices/histograms/ ","date":"2018-09-11","objectID":"/prometheus/:31:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"告警 ALERTING: https://prometheus.io/docs/practices/alerting/ 请先阅读My Philosophy on Alerting ","date":"2018-09-11","objectID":"/prometheus/:32:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"告警什么 What to alert on 目标是告警越少越好，告警要有目的，别瞎告。告警应该很容易找到哪些部件的故障。 ","date":"2018-09-11","objectID":"/prometheus/:32:1","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"记录规则 RECORDING RULES: https://prometheus.io/docs/practices/rules/ 记录规则的一致性命名方案，可以一目了然地理解规则的含义。本节可以正确聚合和建议命名规范。 ","date":"2018-09-11","objectID":"/prometheus/:33:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"命名和聚合 Naming and aggregation 记录规则(recording rules)应该是这样的一般形式：level:metric:operations。level表示聚合级别和规则输出的标签；metric是指标名称并在使用rate()这些方法时应该保持不变；operations是一个应用到指标的操作列表。 保持指标名称不变，使得易于知道指标是什么和容易在代码库中找到它。 如一些常见的: sum, ratio, count这些。 ","date":"2018-09-11","objectID":"/prometheus/:33:1","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"示例 - record:instance_path:requests:rate5mexpr:rate(requests_total{job=\"myjob\"}[5m])- record:path:requests:rate5mexpr:sum without (instance)(instance_path:requests:rate5m{job=\"myjob\"})- record:instance_path:request_failures:rate5mexpr:rate(request_failures_total{job=\"myjob\"}[5m])- record:instance_path:request_failures_per_requests:ratio_rate5mexpr:|2instance_path:request_failures:rate5m{job=\"myjob\"}/instance_path:requests:rate5m{job=\"myjob\"}- record:job:request_latency_seconds_count:avg_rate5mexpr:avg without (instance, path)(instance:request_latency_seconds_count:rate5m{job=\"myjob\"}) ","date":"2018-09-11","objectID":"/prometheus/:33:2","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"Pushgateway WHEN TO USE THE PUSHGATEWAY: https://prometheus.io/docs/practices/pushing/ Pushgateway是一个中间服务，允许你从无法抓取的作业处推送指标。更多详情，查看push metrics ","date":"2018-09-11","objectID":"/prometheus/:34:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"应该使用Pushgateway吗 Should I be using the Pushgateway? 我们只建议在某些有限的示例中使用Pushgateway。盲目地使用Pushgateway push来代替Prometheus pull有几个陷阱： 通过Pushgateway监控多个实例，Pushgateway成为单一的失败点和潜在的瓶颈。 你失去了Prometheus通过up自动检测实例健康。 Pushgateway永远不会忘记推送它，并公开它们给Prometheus，除非这些序列通过PushgatewayApi手动删除。 如果原始实例重命名或删除，实例的指标将保留在Pushgateway中。这是因为PushGateway作为指标缓存的生命周期与推送指标的进程的生命周期分开。与Prometheus pull方式对比时，当一个实例消失时，实例的指标将自动消失。使用Pushgateway时，不不是这种情况，你必须手动删除任何陈旧的指标，或自动执行生命周期同步。 通常，Pushgateway的唯一有效用例是用于捕获一个服务级别的批处理作业的结果(outcome)。一个服务级别的批处理作业是与特定机器或作业实例相关的。这样的作业的指标不应包含一个机器或实例标签，以将特定机器的生命周期与推送指标的实例分开。这降低了管理Pushgateway中的陈旧指标的负担。 ","date":"2018-09-11","objectID":"/prometheus/:34:1","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"替代策略 Alternative strategies 如果入站防火墙和NAT阻止您从目标机器抓取指标，考虑将Prometheus Server移动到网络后面。我们通常建议在同一网络上运行Prometheus Server来作为监控实例。否则，考虑PushProx，它允许Prometheus跨过防火墙或NAT。 ","date":"2018-09-11","objectID":"/prometheus/:34:2","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["monitor"],"content":"远程存储 REMOTE WRITE TUNING: https://prometheus.io/docs/practices/remote_write/ Prometheus实现了合理的默认远程写，但许多用户有不同的要求，并希望优化远程设置。 ","date":"2018-09-11","objectID":"/prometheus/:35:0","tags":["DevOps","Prometheus","Monitor","Alert"],"title":"Prometheus","uri":"/prometheus/"},{"categories":["cncf"],"content":"参考： Kubernetes: https://zh.wikipedia.org/wiki/Kubernetes 官方文档: https://kubernetes.io/docs/ 中文文档: http://docs.kubernetes.org.cn/ GitHub: https://github.com/kubernetes/kubernetes etcd: https://coreos.com/etcd/docs/latest/ flannel: https://coreos.com/flannel/docs/latest/ 环境： CentOS7x86_64 Kubernetes v1.11 \r\r \r\r配置 此章节提供了有关安装k8s和配置k8s集群的相关说明。 \r","date":"2018-06-26","objectID":"/kubernetes/:0:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"安装 有几种方式创建k8s集群： minikube(自动部署) kubeadm(自动部署) 软件包(建议初学者使用此方式) \r","date":"2018-06-26","objectID":"/kubernetes/:1:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"使用minikube创建集群 Using Minikube to Create a Cluster 目标： 了解k8s集群是什么 了解Minikube是什么 启动一个k8s集群 k8s 集群 k8s协调一个高度可用的计算机集群，它们连接起来作为一个单元工作 。 k8s以更有效的方式自动化跨集群分发和调整应用程序容器。 k8s集群包含两种类型的资源： Master Nodes Master负责管理集群。它协调集群中的所有活动。 Node是工作主机。每个节点有一个Kubelet的Agent，负责管理节点并与Master(API)通信。此外，节点上还应有处理容器操作的工具(如Docker)。生成环境的k8s集群至少有三个节点。 用户可通过k8s API直接与集群进行交互。 使用Minikube部署集群: https://github.com/kubernetes/minikube Minikube是一个工具，它运行一个单节点的k8s集群供开发用户使用。 Linux平台 curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \u0026\u0026 \\ chmod +x minikube \u0026\u0026 \\ sudo mv minikube /usr/local/bin/ ##安装kubectl curl -Lo kubectl https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64/kubectl \u0026\u0026 \\ chmod +x kubectl \u0026\u0026 \\ sudo mv kubectl /usr/local/bin/ minikube version minikube start kubectl version kubectl cluster-info kubectl get nodes \r\r","date":"2018-06-26","objectID":"/kubernetes/:1:1","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"kubeadm创建集群 安装kubeadm 本节介绍了如何安装kubeadm工具。 安装前 2GB RAM+ 2 cpus+ 集群主机网络互通 node上唯一的主机名，MAC，UUID 开放特定端口(防火墙) Swap disabled。必须关闭swap才能使kubelet正常工作。 验证MAC或UUID对每个node都是唯一的 ifconfig -a获取MAC cat /sys/class/dmi/id/product_uuid查看UUID 检查网络适配器 如果k8s组件不可达，请手动添加路由。 检查需要的端口 #master Protocol Direction Port Range Purpose Used By TCP Inbound 6443* Kubernetes API server All TCP Inbound 2379-2380 etcd server client API kube-apiserver, etcd TCP Inbound 10250 Kubelet API Self, Control plane TCP Inbound 10251 kube-scheduler Self TCP Inbound 10252 kube-controller-manager Self #worker Protocol Direction Port Range Purpose Used By TCP Inbound 10250 Kubelet API Self, Control plane TCP Inbound 30000-32767 NodePort Services** All 安装docker 使用阿里云镜像。 kubeadm v1.11.1最高支持Docker 17.03，请注意。 wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo mv docker-ce.repo /etc/yum.repos.d yum install -y docker-ce.x84_64 #由于kubeadm不支持最新版的docker，所以需要安装指定版本 yum list docker-ce --showduplicates yum install -y docker-ce-17.03.2.ce 安装kubeadm, kubelet, kubectl kubeadm: 引导集群 kubelet: k8s agent kubectl: command line #创建repo cat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg EOF #国外镜像凉凉，所以换用阿里云 cat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF #禁用防火墙 systemctl stop firewalld systemctl disable firewalld #关闭selinux setenforce 0 sed -i \"s/^SELINUX=permissive/SELINUX=disabled/g\" /etc/selinux/config #关闭swap，否则kubelet无法正常使用 swapoff -a #将/etc/fstab中swap注释掉 sed -i 's/.*swap.*/#\u0026/' /etc/fstab #安装 yum install -y epel-release ebtables ethtool yum install -y kubelet kubeadm kubectl systemctl enable kubelet \u0026\u0026 systemctl start kubelet #系统配置，开启网络桥接 cat \u003c\u003cEOF \u003e /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF #生效 sysctl -p /etc/sysctl.d/k8s.conf sysctl --system systemctl daemon-reload #各主机时区，时间同步 timedatectl set-timezone Asia/Shanghai #crontab -e #ntp */30 * * * * /sbin/ntpdate 1.cn.pool.ntp.org \u003e /dev/null 2\u003e\u00261 #hosts \u003cmaster-ip\u003e master \u003cnode-ip\u003e node 配置cgroup driver 使用docker时，kubelet会将其驱动设置与Docker相同。kubeadm会自动检查kubelet的cgroup驱动，并在运行时将其设置到/var/lib/kubelet/kubeadm-flags.env文件。 docker info | grep -i 'cgroup driver' Cgroup Driver: systemd #此文件是kubeadm init生成的 cat /var/lib/kubelet/kubeadm-flags.env KUBELET_KUBEADM_ARGS=--cgroup-driver=systemd --cni-bin-dir=/opt/cni/bin --cni-conf-dir=/etc/cni/net.d --network-plugin=cni #如果此文件未配置此信息，我们手动添加 cd /etc/systemd/system/kubelet.service.d vim 10-kubeadm.conf KUBELET_KUBEADM_ARGS=--cgroup-driver=systemd --cni-bin-dir=/opt/cni/bin --cni-conf-dir=/etc/cni/net.d --network-plugin=cni \r\r挂载SS拉取k8s镜像 由于无法直接拉去Google k8s镜像，所以可让Docker使用SS来拉取镜像。 # 安装ss 客户端 yum install libsodium libsodium-devel -y pip3 install https://github.com/shadowsocks/shadowsocks/archive/master.zip -U # 配置ss # /etc/shadowsocks.json # nohup sslocal -c /etc/shadowsocks.json \u003e ./ss.log 2\u003e\u00261 \u0026 yum -y install privoxy # 配置 /etc/privoxy/config # forward-socks5t / 127.0.0.1:1080 . # 参考: https://dylanyang.top/post/2019/05/15/centos7%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEshadowsocks%E5%AE%A2%E6%88%B7%E7%AB%AF/ # systemctl start privoxy # vim /etc/profile # export http_proxy=http://127.0.0.1:8118 # export https_proxy=http://127.0.0.1:8118 # source /etc/profile # 这样其实Docker还是无法使用代理，但机器可以 # 这是因为 systemd 引导启动的 service 默认不会读取这些变量，所以需要手动修改 service 启动文件，在其中加入环境变量解决。 # 解决方法： 设置docker代理 # vim /usr/lib/systemd/system/docker.service # 配置SS socks端口 [Service] ... Environment=\"ALL_PROXY=socks5://127.0.0.1:1080\" 之后进行kubeadm初始化就没问题了，用完之后","date":"2018-06-26","objectID":"/kubernetes/:1:2","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"使用软件包创建集群 请定义相应的防火墙规则！ 我是CentOS7x86_64，所以只包含了RPM包。 自带的源安装的k8s可能版本比较老，如需较新版本，可以在网上搜索kubernetes rpm包进行手动安装。 Rpmfind: https://rpmfind.net/ k8s集群组件 etcd flannel kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy kube-dns kubectl Master etcd flannel kube-apiserver kube-controller-manager kube-scheduler kubectl #默认镜像源安装 yum install -y etcd flannel kubernetes-master kubernetes-client #配置kubernetes-master #cd /etc/kubernetes #apiserver config controller-manager scheduler #修改监听地址 vim apiserver KUBE_API_ADDRESS=\"--insecure-bind-address=0.0.0.0\" #生成环境一定要加上认证，我由于是测试，并未做认证 #未添加认证，去掉 KUBE_ADMISSION_CONTROL中的SecurityContextDeny,ServiceAccount #Flag --admission-control has been deprecated, Use --enable-admission-plugins or --disable-admission-plugins instead. #KUBE_ADMISSION_CONTROL=\"--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota\" KUBE_ADMISSION_CONTROL=\"--enable-admission-plugins=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota\" #此处我修改了cidr KUBE_SERVICE_ADDRESSES=\"--service-cluster-ip-range=172.16.0.0/16\" #配置etcd，可先使用默认值 #后面可创建etcd-cluster vim /etc/etcd/etcd.conf #修改监听地址 ETCD_LISTEN_CLIENT_URLS=\"http://0.0.0.0:2379\" #创建pod-network，cidr为kube-apiserver中的配置项 #/atomic.io/network为flannel_etcd前缀,之后再启动flannel etcdctl mk /atomic.io/network/config '{\"Network\":\"172.16.0.0/16\"}' etcdctl ls etcdctl get '/atomic.io/network/config' #配置flannel vim /etc/sysconfig/flanneld #配置后启动 systemctl start etcd flannel kube-apiserver kube-controller-manager kube-scheduler #查看 [root@master kubernetes]# kubectl get all NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 172.16.0.1 \u003cnone\u003e 443/TCP 4m #具体参数请根据实际情况来配置 Node flannel kubelet kube-porxy kubectl #epel yum install -y flannel kubernetes-node kubernetes-client #ls /etc/kubertes #config kubelet proxy #配置etcd的地址 vim /etc/sysconfig/flanneld FLANNEL_ETCD_ENDPOINTS=\"http://master:2379 vim /etc/kubernertes/config KUBE_MASTER=\"--master=http://master:8080\" #修改kubelet地址 KUBELET_ADDRESS=\"--address=node_addr\" KUBELET_HOSTNAME=\"--hostname-override=node_addr\" KUBELET_API_SERVER=\"--api-servers=http://master:8080\" #配置后启动 systemctl start flanneld kube-proxy kubelet #具体参数请根据实际情况来配置 \r验证集群 #Master #kubectl安装如前 kubectl get nodes \r安装较新的k8s 由于自带的源k8s版本比较低，可能我们需要较新的k8s版本。 #安装较新的Kubernetes 浏览器访问 https://rpmfind.net/ 搜索： kubernetes-master(x86-64) kubernetes-node(x86-64) kubernetes-client(x86-64) 选择合适的版本进行下载，三者版本请一致 安装步骤和下面类似 请注意，k8s组件安装好后，还需要安装额外组件。 如docker, flannel, etcd... #master yum install -y k8s-master k8s-client #node yum install -y k8s-node k8s-client \r\r","date":"2018-06-26","objectID":"/kubernetes/:1:3","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"k8s-release生成rpm包 kubernetes-release: https://github.com/kubernetes/release 使用k8s-release手动生成rpm/dep包。 由于yum源更不上k8s的更新速度，所以才需要我们手动制作。 需要安装并运行Docker，它要运行一个rpm-builder容器。 它生成一下rpm包： kubeadm kubelet kubectl 官方说明： \r git clone https://github.com/kubernetes/release.git cd ./release/rpm ./docker-build.sh #此处如果连接google下载超时的话，可以在其它主机上下载，然后复制到此目录下 #成功 ---------------------------------------- RPMs written to: cri-tools-1.11.0-0.x86_64.rpm kubectl-1.11.0-0.x86_64.rpm kubernetes-cni-0.6.0-0.x86_64.rpm kubeadm-1.11.0-0.x86_64.rpm kubelet-1.11.0-0.x86_64.rpm repodata Yum repodata written to: 5e470d3c1c28cdd798237a48172b46f753655edee30988f4fde7000fde859d5a-primary.xml.gz 9497c84e5650b15bf6edcffb68900b4f59f7271fa6318d3c0336386c99afd2d8-other.xml.gz 94da9da6abd2dc8364ef51b4ca135b804deef0a37f1f13e4abeee455a8b0e897-primary.sqlite.bz2 971e5af9d861f5ba85b12bad481749aa26546051090fa4e21c2393c21590dd5a-filelists.xml.gz b752df67070ff5552bd3137f00fb217578f1d810084a3e42579a53eee2a26085-other.sqlite.bz2 f0ec7692c0654c1ec5ad9c8576ebe5b8f135c45b5d5242066df6e2d631a3ef6f-filelists.sqlite.bz2 repomd.xml #会在./release/rpm/output/x86_64下生成特定版本的rpm包 pwd #/root/release/rpm/output/x86_64 ls -l total 47056 -rw-r--r-- 1 root root 4383318 Aug 3 10:25 cri-tools-1.11.0-0.x86_64.rpm -rw-r--r-- 1 root root 7906382 Aug 3 10:25 kubeadm-1.11.0-0.x86_64.rpm -rw-r--r-- 1 root root 7859238 Aug 3 10:25 kubectl-1.11.0-0.x86_64.rpm -rw-r--r-- 1 root root 19012182 Aug 3 10:25 kubelet-1.11.0-0.x86_64.rpm -rw-r--r-- 1 root root 9008530 Aug 3 10:25 kubernetes-cni-0.6.0-0.x86_64.rpm drwxr-xr-x 2 root root 4096 Aug 3 10:25 repodata 请注意，默认会自动编译所有平台。如果只需要x84_64，可以更改entry.sh文件，将其它平台去掉，以加快编译速度。 vim ./release/rpm/entry.sh ARCHS=( amd64/x86_64 #arm/armhfp #arm64/aarch64 #ppc64le/ppc64le #s390x/s390x ) 后面还是需要使用kubeadm来进行引导！ \r\r","date":"2018-06-26","objectID":"/kubernetes/:1:4","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"编译源码生成rpm包 参考： How to build Kubernetes RPM: https://mritd.me/2017/07/12/how-to-build-kubernetes-rpm/ 由于墙的原因，使用kubeadm进行引导还是会timeout。使用自带的yum源或网上下载的k8s rpm可能也不是最新的版本。因此需要手动编译源码以生成rpm包。 生成如下rpm包： kubernetes-master kubernetes-client kubernetes-node \r\r","date":"2018-06-26","objectID":"/kubernetes/:1:5","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"k8s Dashboard 说明: GitHub: https://github.com/kubernetes/dashboard image: kubernetes-dashboard-amd64:v1.8.3 FAQ: https://github.com/kubernetes/dashboard/wiki/FAQ Let’s Encrypt: https://letsencrypt.org/ Let’s Encrypt是一个免费，自动化和开放的证书颁发机构。 快速配置 Quick setup 快速部署kubernetes-dashboard的方法请参考README。它适用于k8s新手并希望快速开始使用Dashboard的人。其它配置适用于有一定经验的用户，详情在以下章节。 k8s Dashboard是k8s集群的基于Web的通用UI。它允许用户管理运行在集群中的应用程序，并对应用程序进行故障排除，以及管理集群本身。 请注意，Dashboard使用了安全设置。这意味着，默认情况下它具有最小的权限集，并且只能通过https访问。 建议在安装和执行Dashboard之前，先阅读**Access Control**指南。 kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml #或 #wget https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml #kubectl apply -f /path/kubernetes-dashboard.yaml secret/kubernetes-dashboard-certs created serviceaccount/kubernetes-dashboard created role.rbac.authorization.k8s.io/kubernetes-dashboard-minimal created rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard-minimal created deployment.apps/kubernetes-dashboard created service/kubernetes-dashboard created #查看 kubectl get pods -n kube-system -o wide |grep dashboard kubernetes-dashboard-6948bdb78-rnnjp 1/1 Running 1 1d 10.244.1.2 node kubectl get service -n kube-system -o wide |grep dashboard kubernetes-dashboard ClusterIP 10.110.83.129 \u003cnone\u003e 443/TCP 13m k8s-app=kubernetes-dashboard #要从本地访问Dashboard，必须为k8s集群创建安全通道 kubectl apply Starting to serve on 127.0.0.1:8001 #访问Dashboard http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/ #http://localhost:8001/ui已弃用 #\u003ch3\u003eUnauthorized\u003c/h3\u003e #会直接报403，还需要做前面所说的操作。 #Heapster必须在集群中运行才能使metric, graphs可用 #Heapster已被弃用，请考虑使用metrics-server和第三方metrics pipeline收集Prometheus格式的指标 \r\r安装 Installation 官方版 当从旧版Dashboard升级到 v1.7+，请确保删除kubernetes-dashboard服务账户的集群角色绑定，否则Dashboard将具有对集群的完全管理权限。 快速配置 快速部署kubernetes-dashboard的方法请参考README。它适用于k8s新手并希望快速开始使用Dashboard的人。 推荐配置 直接访问Dashboard(不是kubectl proxy)，应该使用有效的证书来建立安全的HTTPS连接。它们可由公共可信证书颁发机构(如Let’s Encrypt)生成，使用它们替代Dashboard自动生成的证书。 此配置要求证书存储在kube-system命名空间中名为kubernetes-dashboard-certs的证书中。 假设你有存储在$HOME/certs目录下的dashboard.crt和dashboard.key文件。你应该使用这些文件创建secret。之后，便可以开始配置Dashboard。 #查看 kubectl get secret -n kube-system | grep dashboard #查看 kubectl describe secret/kubernetes-dashboard-certs -n kube-system Name: kubernetes-dashboard-certs Namespace: kube-system Labels: k8s-app=kubernetes-dashboard Annotations: Type: Opaque Data ==== #创建 kubectl create secret generic kubernetes-dashboard-certs --from-file=$HOME/certs -n kube-system #部署Dashboard kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml 替代配置 此配置并不安全。不使用证书，仅通过HTTP公开Dashboard。在此配置中，只能通过使用Authorization Header功能来确保访问控制。 #配置 kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/alternative/kubernetes-dashboard.yaml 开发版 不建议在线上环境使用开发版，请使用稳定的正式版。 #部署 kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard-head.yaml 升级 安装后，Deployment不会自动更新。为了更新它，你需要删除部署的pod并等待它重新创建。重新创建之后，它会使用最新的镜像image:latest. #删除pod kubectl -n kube-system delete $(kubectl -n kube-system get pod -o name | grep dashboard) \r\r证书管理 Certificate management 本节简短介绍了如何获取可在Dashboard中启用HTTPS的证书。有两个步骤要做： 生成证书 证书认证机构(Certificate Authority) 自签名证书(Self-signed certificate) 将证书传递给Dashboard 按照前面的推荐配置方法 其它情况，你需要修改Dashboard的YAML部署文件，并将--tls-key-file, --tls-cert-file传递给Dashboard 公众信任的证书认证机构 Public trusted Certificate Authority 有许多公共和免费的证书提供商可供选择。如前面提到的Let’s encrypt，具体操作查看此网站说明。 自签名证书 Self-signed certificate 如果你打算自己生成证书，你需要像OpenSSL这样的库来帮助你。 生成私钥(private key)和证书签名请求(certificate signing request) 生成SSL证书 #Generate private key and certificate signing request #创建SSL证书需要私钥和证书签名请求 openssl genrsa -des3 -passout pass:x -out dashboard.pass.key 2048 openssl rsa -passin pass:x -in dashboard.pass.key -out dashboard.key rm dashboard.pass.key #需要填写一些信息 #A challeng","date":"2018-06-26","objectID":"/kubernetes/:1:6","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"Heapster GitHub: https://github.com/kubernetes/heapster 注意: Heapster已被启用，考虑使用metric-server和第三方metric pipeline来收集Prometheus格式的指标。 Heapster 启用时间轴 Kubernetes Release Action Policy/Support Kubernetes 1.11 Initial Deprecation No new features or sinks are added. Bugfixes may be made. Kubernetes 1.12 Setup Removal The optional to install Heapster via the Kubernetes setup script is removed. Kubernetes 1.13 Removal No new bugfixes will be made. Move to kubernetes-retired organization. \r\r","date":"2018-06-26","objectID":"/kubernetes/:1:7","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"metric-server GitHub: https://github.com/kubernetes-incubator/metrics-server 具体详情可参考README。 #下载到本地 git clone https://github.com/kubernetes-incubator/metrics-server.git #移动到管理目录 mv metrics-server/ /etc/kubernetes/ #k8s v1.8+ ls /etc/kubernetes/metrics-server/deploy/v1.8+/ auth-delegator.yaml auth-reader.yaml metrics-apiservice.yaml metrics-server-deployment.yaml metrics-server-service.yaml resource-reader.yaml #注意metrics-server-deployment.yaml文件，需要一个镜像，请准备 #gcr.io/google_containers/metrics-server-amd64:v0.2.1 docker pull zhang21/metrics-server-amd64:v0.2.1 docker tag zhang21/metrics-server-amd64:v0.2.1 gcr.io/google_containers/metrics-server-amd64:v0.2.1 #创建 #注意，在顶层进行创建 cd /etc/kubernetes/metrics-server kubectl create -f deploy/v1.8+/ clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created serviceaccount/metrics-server created deployment.extensions/metrics-server created service/metrics-server created clusterrole.rbac.authorization.k8s.io/system:metrics-server created clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created #查看 kubectl -n kube-system get deployment NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE coredns 2 2 2 2 2d kubernetes-dashboard 1 1 1 1 19h metrics-server 1 1 1 0 39s \r\r","date":"2018-06-26","objectID":"/kubernetes/:1:8","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"pause容器 参考: 《Kubernetes之“暂停”容器》: http://dockone.io/article/2785 《Pause容器》: https://jimmysong.io/kubernetes-handbook/concepts/pause-container.html GitHub: https://github.com/kubernetes/kubernetes/tree/master/build/pause Pause容器，又叫Infra容器。它不是pod，而是一个容器。 docker ps | grep pause 35c9aaa68a06 k8s.gcr.io/pause:3.1 \"/pause\" 18 hours ago Up 18 hours k8s_POD_coredns-78fcdf6894-hn46d_kube-system_daab8e60-9a0d-11e8-a08a-000c298ee39f_0 d22a1baac736 k8s.gcr.io/pause:3.1 \"/pause\" 18 hours ago Up 18 hours k8s_POD_coredns-78fcdf6894-wqxbx_kube-system_daac5838-9a0d-11e8-a08a-000c298ee39f_0 4d0cdc392629 k8s.gcr.io/pause:3.1 \"/pause\" 18 hours ago Up 18 hours k8s_POD_kube-flannel-ds-7gbvd_kube-system_59129dff-9a0f-11e8-a08a-000c298ee39f_0 4f28747a2044 k8s.gcr.io/pause:3.1 \"/pause\" 18 hours ago Up 18 hours k8s_POD_kube-proxy-rhrks_kube-system_da990e28-9a0d-11e8-a08a-000c298ee39f_0 f2bd7bd47eb4 k8s.gcr.io/pause:3.1 \"/pause\" 18 hours ago Up 18 hours k8s_POD_kube-scheduler-master_kube-system_537879acc30dd5eff5497cb2720a6d64_0 d732ffba5530 k8s.gcr.io/pause:3.1 \"/pause\" 18 hours ago Up 18 hours k8s_POD_kube-controller-manager-master_kube-system_01c36146e2c80849d7b6993e68aa5e67_0 cd7636bac6df k8s.gcr.io/pause:3.1 \"/pause\" 18 hours ago Up 18 hours k8s_POD_kube-apiserver-master_kube-system_1bd24cc043a06bf7e71b96167946c220_0 d4adb3504543 k8s.gcr.io/pause:3.1 \"/pause\" 18 hours ago Up 18 hours k8s_POD_etcd-master_kube-system_2cc1c8a24b68ab9b46bca47e153e74c6_0 #或者是这样 #registry.access.redhat.com/rhel7/pod-infrastructure:latest #rpm包安装kubelet的默认配置 KUBELET_POD_INFRA_CONTAINER=\"--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest\" #kubeadm安装kubelet的默认配置 KUBELET_POD_INFRA_CONTAINER=--pod-infra-container-image=k8s.gcr.io/pause:3.1 pause容器的作用 k8s中的pause容器主要为每个业务提供以下功能： 在pod中担任Linux命名空间共享的基础 启用pid命名空间，开启init进程 使用pause容器和共享命名空间创建pod示例： #启动pause，以便可以将容器添加到pod中 docker run -d --name pause k8s.gcr.io/pause-amd64:3.1 #nginx cat \u003c\u003cEOF \u003e\u003e /tmp/nginx.conf \u003e error_log stderr; \u003e events { worker_connections 1024; } \u003e http { \u003e access_log /dev/stdout combined; \u003e server { \u003e listen 80 default_server; \u003e server_name example.com www.example.com; \u003e location / { \u003e proxy_pass http://127.0.0.1:2368; \u003e } \u003e } \u003e } \u003e EOF #指定网络和命名空间 docker run -d --name nginx -v /tmp/nginx.conf:/etc/nginc/nginx.conf -p 8880:80 --net=container:pause --ipc=container:pause --pid=container:pause docker.io/nginx:lates #ghost博客 docker run -d --name ghost --net=container:pause --ipc=container:pause --pid=container:pause docker.io/ghost:latest 在这两种情况下，我们将pasue容器指定为我们要加入的命名空间容器。这将有效地创建我们的pod。 访问localhost:8880可以看到ghost通过nginx代理运行。因为网络命名空间在pause, nginx, ghost容器之间共享。 而这两个容器的init进程都是pause这个容器。 docker logs -f nginx 192.168.31.28 - - [08/Aug/2018:02:00:49 +0000] \"GET / HTTP/1.1\" 200 3195 \"-\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36\" 192.168.31.28 - - [08/Aug/2018:02:00:49 +0000] \"GET /assets/built/screen.css?v=0bf822a279 HTTP/1.1\" 200 7360 \"http://node:8880/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36\" ...... docker logs -f ghost [2018-08-08 02:00:30] INFO Creating table: posts [2018-08-08 02:00:30] INFO Creating table: users [2018-08-08 02:00:30] INFO Creating table: posts_authors ...... #查看init docker exec -it ghost /bin/bash root@f12a374141a7:/var/lib/ghost# ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 01:55 ? 00:00:00 /pause root 5 0 0 01:58 ? 00:00:00 nginx: master process nginx -g daemon off; systemd+ 9 5 0 01:58 ? 00:00:00 nginx: worker process node 10 0 0 02:00 ? 00:00:03 node current/index.js root 127 0 0 02:37 ? 00:00:00 /bin/bash root 131 127 0 02:37 ? 00:00:00 ps -ef \r\r","date":"2018-06-26","objectID":"/kubernetes/:2:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"构建大型集群 Building Large Clusters 在k8s v1.11，k8s支持做多5 000个节点的集群。更具体地说，支持满足以下条件的配置： 不超过5 000个node 总量不超过150 000个pod 总量不超过300 000个container 每个节点不超过100个pod \r\r","date":"2018-06-26","objectID":"/kubernetes/:3:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"使用salt配置k8s Configuring Kubernetes with Salt k8s集群能够使用salt进行配置。 \r\r","date":"2018-06-26","objectID":"/kubernetes/:4:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"验证节点配置 Validate Node Setup \r节点一致性测试 Node Conformance Test 节点一致性测试是一种容器化测试框架，为节点提供系统验证和功能测试。 该测试验证节点是够满足k8s的最低要求，通过测试的节点有资格加入k8s集群。 \r局限 Limitations 在k8s v1.5中，节点一致性测试具有如下限制： 节点一致性测试仅支持Docker作为容器runtime \r节点先决条件 Node Prerequisite 要运行节点一致性测试，节点必须满足与标准k8s节点相同的先决条件。该节点至少要安装一下守护进程: Container Runtime(Docker) Kubelet \r运行节点一致性测试 Running Node Conformance Test 执行如下步骤： 1. 将kubelet执行localhost，测试框架启动一个master来测试kubelet #可使用 --pod-cidr, --cloud-provide标志 --api-servers=\"http://localhost:8080\" 2. 运行节点一致性测试 # $CONFIG_DIR is the pod manifest path of your Kubelet. # $LOG_DIR is the test output path. sudo docker run -it --rm --privileged --net=host \\ -v /:/rootfs -v $CONFIG_DIR:$CONFIG_DIR -v $LOG_DIR:/var/result \\ k8s.gcr.io/node-test:0.2 #一致性测试的架构支持 node-test-adm64 node-test-arm node-test-arm64 运行选定测试 Running Selected Test #运行指定测试，使用你想要运行的测试的正则表达式 覆盖环境变量FOCUS sudo docker run -it --rm --privileged --net=host \\ -v /:/rootfs:ro -v $CONFIG_DIR:$CONFIG_DIR -v $LOG_DIR:/var/result \\ -e FOCUS=MirrorPod \\ # Only run MirrorPod test k8s.gcr.io/node-test:0.2 #跳过指定测试，覆盖环境变量SKIP sudo docker run -it --rm --privileged --net=host \\ -v /:/rootfs:ro -v $CONFIG_DIR:$CONFIG_DIR -v $LOG_DIR:/var/result \\ -e SKIP=MirrorPod \\ # Run all conformance tests but skip MirrorPod test k8s.gcr.io/node-test:0.2 强烈建议仅运行一致性测试，因为它需要更复杂的配置来运行不一致性测试。 \r\r \r概念 concepts 概念部分可帮助你了解k8s系统的各个部分以及k8s用于表示集群的抽象，并帮助你更深入地了解k8s的工作原理。 \r","date":"2018-06-26","objectID":"/kubernetes/:5:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"标准词汇 Standardized Glossary Annotation 用于将任意非标识元数据(metadata)附加到随想的键值对。 Application Architect 负责程序高级设计的人员。 Application Developer 编写在Kubernetes集群中运行的应用程序的人。 Approver 可以审批Kubernetes代码贡献的人。 CLA(Contributor License Agreement) 贡献者向开源项目授予其贡献许可的条款。 Certificate 一个加密安全文件，用于验证对Kubernetes集群的访问的加密。 Cloud Controller Manager Cloud Provider Cluster 一组称为节点(node)的机器，运行着由Kubernetes管理的容器化的应用程序。 Cluster Architect 设计一个或多个Kubernetes集群的基础架构的人。 Cluster Operator 配置，控制和监控集群的人。 Code Contributor 为Kubernetes开源代码库开发和共享代码的人。 ConfigMap 一个API对象，用于在键值对中存储非机密的数据。可认为是环境变量，命令行参数… Container 一个轻量化和可移植的包含应用程序及其依赖项的可执行的镜像。 Container Environment Variables 容器环境变量是name/value对，为Pod中运行的容器提供有用的信息。 Contributor 捐赠代码，文档或时间来帮助Kubernetes项目或社区的人。 Controller 一个控制循环，通过APIServer监视集群的共享状态，并进行修改，尝试将当前状态移至理想(desired)状态。 CronJob 管理一个定期运行的工作。 CustomResourceDefinition 自定义码，用于定义要添加到Kubernetes APIServer的资源，而无需构建完整的自定义服务器。 DaemonSet 确保Pod的副本在集群的一组节点上运行。 Deployment 一个管理副本应用程序的API对象 Dynamic Volume Provision 允许用户请求自动创建存储卷。 etcd 一致且高度可用的键值存储，用作Kubernetes所有集群数据的备份存储。 Helm Chart 可以使用Helm工具管理的预配置Kubernetes资源包。 Horizontal Pod Autoscaler 一个API资源，可根据目标CPU利用率或自定义的指标自动调整Pod副本数。 Image 一个容器的存储实例，其中包含运行一个应用程序需要的一组软件。 Ingress 一个管理集群中服务的外部访问的API对象，通常是HTTP。 Init Container 一个或多个初始化容器，必须在任意应用程序容器运行之前完成运行。 Istio 一个开放平台，提供统一的方式来继承微服务，管理流量，实施策略和聚合遥测数据。 Job 运行完成的 有限/一批 任务。 Kops 一个命令行工具，可帮助你创建，销毁，升级和维护生产级、高可用性的Kubernetes集群。(仅支持AWS) Kubeadm 一个快速安装Kubernetes和设置安全集群的工具。 Kubectl 用于与Kubernetes APIServer通信的命令行工具。 Kubelet 在集群的每个节点上运行的Agent。它确保容器运行在Pod中。 Kubernetes API 通过RESTful接口提供Kubernetes功能的应用程序，用于存储集群的状态。 Label 标记与用户有意义且相关的标识属性的对象。 Minikube 一个在本地运行Kubernetes的工具。 Name 客户端提供的字符串，用于引用资源URL中的对象。如/api/vi/pods/some-name. Namespace 一个抽象概念，用于Kubernetes支持同一物理集群上的多个虚拟集群。 Network Policy 允许Pod组如何与其它网络端点进行通信的规范。 Node 节点是Kubernetes中的一个工作机器。 Persistent Volume 一个表示集群中一块存储的API对象。 Persistent Volume Claim 声明定义在一个PersistentVolume中的存储资源，以便可以作为一个volume挂载到容器中。 Pod 最小和最简单的Kubernetes对象。Pod表示集群上一组正在运行的容器。 Pod Security Policy 启用Pod创建和更新的细粒度授权。 PodPreset 一个API对象，在创建时将信息(secrets, volume, env var…)注入到Pod中。 RBAC（role-basesd access control) 管理授权决策，允许管理员通过Kubernetes API动态配置访问策略。 ReplicaSet 副本集是下一代副本控制器。 Resource Quotas 提供限制每个命名空间的聚合资源消耗的约束。 Reviemer 在项目的某些部分检查代码质量和正确性的人。 Secret 存储敏感信息，如密码，token… Security Context securityContext字段定义Pod或容器的权限和访问控制设置，包括运行时UID和GID。 Selector 允许用户根据label过滤资源列表。 Service 一个API对象，描述如何访问应用程序，并可以描述端口和负载均衡器。 Service Account 为运行在Pod中的进程提供一个标识。 Service Catalog 一个扩展API，允许Kubernetes集群中运行的应用程序能够轻松使用外部托管软件，如数据库存储服务。 StatefulSet 管理一组Pods的部署和伸缩，并提供有关这些Pod的排序和唯一性的保证。 UID Kubernetes系统生成的一个字符串，用于唯一标识对象。 Volume 一个包含数据的目录，可供Pod中的容器访问。 Volume Plugin 卷插件可在Pod中集成存储。 kube-apiserver 一个Master组件，用于暴露Kubernetes API。它是Kubernetes控制面的前端。 kube-controller-manager 一个Master组件，用于运行控制器。 kube-proxy 运行在集群中的每一个节点上的网络代理。 kube-scheduler Master上的组件，用于监测未创建节点新创建的Pod，并选择一个节点供其运行。 \r\r","date":"2018-06-26","objectID":"/kubernetes/:6:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"概述 ","date":"2018-06-26","objectID":"/kubernetes/:7:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"K8s是什么 Kubernetes（常简称为K8s），Kubernetes的名字来自希腊语，意思是“舵手”或“领航员”。K8s是将8个字母“ubernete”替换为“8”的缩写。 它用于自动部署、扩展和管理容器化（containerized）应用程序的开源系统。它旨在提供“跨主机集群的自动部署、扩展以及运行应用程序容器的平台”。它支持一系列容器工具, 包括Docker等。 通过Kubernetes你可以： 快速部署应用 快速扩展应用 无缝对接新的应用功能 优化硬件资源，降低成本 Kubernetes特点： 可移植(portable) 可扩展( extensible) 自动化(automatic) 容器优点： 快速创建/部署应用 持续开发、集成和部署(CI/CD) 开发和运维相分离 开发、测试、生产环境的一致性 可移植性 松耦合、分布式、弹性伸缩、微服务化 资源隔离 资源利用 Kubernetes能做什么 Kubernetes还允许开发人员从物理和虚拟机脱离，从以主机为中心的基础架构转移到以容器为中心的基础架构。这样可以使用容器固有的全部优点。 Kubernetes满足的应用程序常见需求： Pod 挂载外部存储 分布式secrets 应用健康检查 副本应用实例 横向自动伸缩 服务发现 负载均衡 滚动更新 资源监控 日志采集和存储 自检和调试 认证和授权 这提供了**平台即服务(PAAS)的简单性以及基础架构即服务(IAAS)**的灵活性，并促进基础设施供应商的可移植性。 Kubernetes不是什么 Kubernetes 不是一个传统意义上，包罗万象的PaaS(平台即服务)系统。 不限制支持的应用程序类型，不限制应用程序框架 不提供中间件(如消息中间件)、数据处理框架(如spark)，数据库或集群存储系统 不提供点击即部署的服务市场 不部署代码不构建应用 允许用户选择日志、监控和报警 不提供或授权一个全面的应用程序配置系统/语言 不提供任何机器配置、维护、管理或自我修复系统 你可以自定义你的PAAS，与你选择的CI系统集成，或与Kubernetes一起使用，将你的容器镜像部署到Kubernetes。 由于Kubernetes在应用级别而不仅仅在硬件级别上运行，因此它提供了PAAS产品通用的一些功能。如部署、扩展、负载均衡、日志记录、监控等。 \r\r","date":"2018-06-26","objectID":"/kubernetes/:7:1","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"k8s组件 Kubernetes Components Kubernetes 所需的各种二进制组件, 用于提供齐全的功能。 \rMaster组件 Master组件提供的集群控制面(control plane)。Master作出集群的全局决策，以及检测和相应集群事件。 Master组件可在集群中任何节点上运行。然而，为了简单，通常在一台机器上启动所有Master组件，并且不会在此机器上运行用户容器。 可使用多个机器的设置来构建高可用性能集群。 kube-apiserver kube-apiserver对外展示Kubernetes API。它是Kubernetes前端控制层，任何的资源请求/调用都是通过它提供的接口进行。 它被设计为水平扩展，即通过部署更多实例来扩展。 etcd 持久化和高可用的K/V存储，用于Kubernetes所有集群数据的后端存储。 请始终为k8s集群的etcd数据做备份。 kube-controller-manager Master上运行的控制器组件，它们是集群中处理常规任务的后台线程。 逻辑上讲，每个控制器都是一个单独的进程，但为了降低复杂性，它们都被编译为单个二进制文件并在单个进程中运行。 这些控制器包含： 节点控制器(Node Controller): 负责在节点故障时通知和响应 副本控制器(Replication Controller): 负责维护系统中每个副本控制器对象正确的pod数 端点控制器(Endpoints Controller): 填入端点对象 服务账户(service accoute)和令牌控制器(token controller): 为新的命名空间(namespace)创建默认账户和API访问令牌 cloud-controller-manager 云控制器管理器用于与底层云提供商进行交互。它仅运行云提供商特定的控制器循环。你必须在kube-controller-manager中禁用这些controller loops，将--cloud-provider标志设置为external来禁用。 以下控制器具有云提供商依赖关系： 节点控制器: 用于检查云服务商提供的程序 路由控制器: 用于在底层云基础架构中设置路由 服务控制器: 用于创建，更新，删除云服务商提供的负载均衡器 数据卷控制器: 用于创建，附件和挂载卷，以及与云服务商提供的卷进行交互 kube-scheduler 监视还未分配节点的新创建的pod，选择一个节点供pod运行。 调度决策所考虑的因素包括： 个体/集体的资源需求，硬件/软件/策略的约束，亲和力/反亲和性的规范，工作负载和期限。 \r\rNode组件 节点(node)组件运行在每个节点，维护运行的pod并提供Kubernetes运行时环境。 kubelet 在集群中每个节点上运行的Agent，它确保container运行在pod中。 kubelet采用通过各种机制提供的一组PodSpecs，并确保这些PodSpecs中描述的容器运行且健康。kubelet不管理不是由k8s创建的容器。 提供如下功能： 挂载pod所需的数据卷 下载pod的secrets pod中运行docker容器 周期性的容器健康检查 如有需要，通过创建mirror pod将pod的状态报告回系统的其余部分 将节点的状态报告回系统的其余部分 kube-proxy 通过维护主机上的网络规则并执行连接转发，来实现Kubernetes服务抽象。 container runtime 负责运行容器的软件。k8s支持多种runtimes： docker, rkt, runc… docker, rkt, supervisord, fluentd… \r\rAddons 扩展是实现集群功能的Pod和Service。pod可由Deployment， Replication等管理。命名空间扩展对象在kube-system命名空间中创建。 DNS 虽然其它插件并非严格要求，但所有k8s集群都应具有集群DNS，因为许多示例都依赖于它。 集群DNS是一个DNS服务器，除了你环境中的DNS服务器，它还为k8s服务提供DNS记录。 由k8s启动的容器会在DNS搜索中自动包含此DNS服务器。 Web UI(dashboard) 仪表盘。 container resource monitoring 记录有关中央数据库中容器的通用时间序列度量标准，并提供用于浏览该数据的UI。 cluster-level logging 集群级别的日志记录机制，复制将容器日志保存到具有search/browse界面的中央日志存储。 \r\r","date":"2018-06-26","objectID":"/kubernetes/:7:2","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"k8s API k8s API还可作为系统声明性配置架构的基础。kubectl命令行工具可用于创建，更新，删除和获取API对象。 k8s还根据API资源存储其序列化状态(etcd中)。k8s自身被分解为多个组件，这些组件通过其API进行交互。 OpenAPI和Swagger定义 完整的API详细信息记录在Swagger v1.2和OpenAPI。k8s apiserver(master)公开了一个API，可用于检索位于/swaggerapi的Swagger v1.2 k8s API. 从k8s 1.10开始，OpenAPI规范在单个/openapi/v2端点中提供。单独格式的端点(如swagger.json...)已被弃用，后面会被移除。 通过设置HTTP header指定请求格式: Header Possible Values Accept application/json, application/com.github.proto-openapi.spec.v2@v1.0+protobuf (the default content-type is application/json for / or not passing this header) Accept-Encoding gzip (not passing this header is acceptable) 栗子： Before 1.10 Starting with Kubernetes 1.10 GET /swagger.json GET /openapi/v2 Accept: application/json GET /swagger-2.0.0.pb-v1 GET /openapi/v2 Accept: application/com.github.proto-openapi.spec.v2@v1.0+protobuf GET /swagger-2.0.0.pb-v1.gz GET /openapi/v2 Accept: application/com.github.proto-openapi.spec.v2@v1.0+protobuf Accept-Encoding: gzip #查看 curl localhost:8080 { \"paths\": [ \"/api\", \"/api/v1\", \"/apis\", \"/apis/apps\", \"/apis/apps/v1beta1\", \"/apis/authentication.k8s.io\", \"/apis/authentication.k8s.io/v1beta1\", \"/apis/authorization.k8s.io\", \"/apis/authorization.k8s.io/v1beta1\", \"/apis/autoscaling\", \"/apis/autoscaling/v1\", \"/apis/batch\", \"/apis/batch/v1\", \"/apis/batch/v2alpha1\", \"/apis/certificates.k8s.io\", \"/apis/certificates.k8s.io/v1alpha1\", \"/apis/extensions\", \"/apis/extensions/v1beta1\", \"/apis/policy\", \"/apis/policy/v1beta1\", \"/apis/rbac.authorization.k8s.io\", \"/apis/rbac.authorization.k8s.io/v1alpha1\", \"/apis/storage.k8s.io\", \"/apis/storage.k8s.io/v1beta1\", \"/healthz\", \"/healthz/ping\", \"/healthz/poststarthook/bootstrap-controller\", \"/healthz/poststarthook/extensions/third-party-resources\", \"/healthz/poststarthook/rbac/bootstrap-roles\", \"/logs\", \"/metrics\", \"/swaggerapi/\", \"/ui/\", \"/version\" ] API 版本 为了更容易消除字段或重构资源表示，k8s支持多个API版本，每个版本位于不同的API路径。如/api/vi或/apis/extensions/v1beta1. 我们选择在API级别，而不是资源级别/字段级别进行版本控制，以确保API提供干净、一致的系统资源和行为视图，并允许控制对生命末端和实验性API的访问。json和protobuf序列化模式都遵循相同的模式更改指南。请注意，API版本和软件版本仅间接相关。 不同的API版本意味着不同级别的稳定性和支持： Alpha level 版本名包含alpha(如 v1aplha1) 启用该功能可能会暴露bug，默认禁用 可随时删除对功能的支持，恕不另行通知 可能会在以后软件版本中以不兼容的方式更改，恕不另行通知 由于错误风险和缺乏长期支持，建议仅在短期测试集群中使用 Beta level 版本名包含beta(如 v2beta3) 代码经过充分测试，启用该功能被认为是安全的。默认启用 虽然细节会有所变化，但不会删除对整体功能的支持 建议仅用于非关键业务，因为后续版本可能会发生不兼容的更改 请尝试我们测试版功能并提供反馈 Stable level 版本名是vx，x为整数 许多后续版本的软件将出现稳定版的功能 API groups 为了更容易扩展k8s API，我们实施了API Groups，它在REST path和序列化对象的apiVersion字段中指定。 目前在使用的几个API groups: 核心组(core group)，又称遗留组，位于REST path的/api/v1，并使用apiVersion: v1 命名组(named group)，位于REST path的/apis/$GROUP_NAME/$VERSION，并使用apiVersion: $GROUP_NAME/$VERSION 两种受支持的自定义资源扩展API的路径： 自定义资源(CustomResourceDefiniton) 适用于具有非常基本CRUD需求的用户 需要完整k8s API语义的用户可以实现自己的apiserver，并使用聚合器使其无缝连接到客户端 启用 API groups 默认情况下启用某些资源和API groups。通过在apiserver设置--runtime-config可启用/禁用它。此配置接收逗号分隔的KV，描述了apiserver运行时配置。 在API groups中启用资源 默认情况下启动 DeamonSets, Deployments, HorizontalPodAutoscalers, Ingress, Jobs, ReplicaSets。其它扩展资源可通过在apiserver上设置--runtime-config启用或禁用。 \r\r","date":"2018-06-26","objectID":"/kubernetes/:7:3","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"k8s 对象 本节解释了如何在k8s API中表示k8s对象，以及如何以.yaml格式表示它们。 \r理解k8s对象 在k8s系统中，k8s对象是持久化的实体。k8s使用这些实体来表示整个集群的状态。特别地，它们描述了如下信息： 哪些容器化应用程序正在运行(以及运行在哪个节点上) 可以被这些应用程序使用的资源 应用程序行为方式的策略(重启、升级、容错) k8s 对象是一个意图记录(record of intent) —— 一旦创建了对象，k8s系统将持续工作以确保对象存在。通过创建一个对象，你可以有效地告诉k8s系统你希望集群的工作负载看起来像什么，这是你的集群的期望状态(desired state)。 要使用k8s对象(创建, 修改, 删除)，需要使用k8s API。当你使用kubectl命令行接口时，CLI会为你进行必要的k8s API调用。 对象规约与状态 Object Spec and Status 每个k8s 对象都包含了两个嵌套的对象字段，用于控制对象的配置：对象规约和对象状态。 在任何时刻，k8s controller plane都会主动管理对象的实际状态，以匹配你提供的期望状态。 规约(spec)，必须提供。描述了对象的期望状态(diresed state)——你希望对象具有的特征。 状态(status)，描述对象的实际状态，由k8s系统提供和更新。 例如，k8s Deployment是一个可以表示你集群上运行的应用程序的对象。当你创建一个Deployment，你可以设置部署规约以指定你希望应用程序运行三个副本。k8s系统读取部署规约并启动应用程序所需的三个实例——更新状态以符合你的规范。如果这些事例中的任何一个失败(状态改变)，k8s系统通过进行校正来响应规约和状态之间的差异。在这种情况下，启动替换实例。 描述k8s 对象 在k8s中创建对象时，必须提供描述其期望状态的对象规约，以及有关对象的一些基本信息(如 名称)。当你使用k8s API来创建对象时，API请求必须在请求正文中将信息作为JSON格式。通常，你在.yaml文件中向kubectl提供信息，kubectl在发出API请求时将信息转换为JSON格式。 栗子： # for versions before 1.9.0 use apps/v1beta2 apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 使用类似上面的.yaml文件创建部署的方法，是在kubectl命令行工具中使用kubectl create命令，将.yaml文件作为参数传递。 kubectl create -f https://k8s.io/examples/application/deployment.yaml --record #deployment \"nginx-deployment\" created 必填字段 在要创建k8s 对象的.yaml文件中，必须配置一下字段： apiVersion： 创建对象的k8s API版本 kind： 创建的对象类型 metadata： 有助于识别对象唯一性的数据，包括name, uid, namespace… 你还需要提供spec字段。对于每个k8s对象，对象规约的精确格式是不同的，并且包含特定于该对象的嵌套字段。 \r\rNames Kubernetes REST API中所有对象都用Name和UID来明确标识。 对于用户提供的非唯一的属性，k8s提供labels和annotations。 Names 客户端提供的字符串，用于引用资源URL中的对象。如/api/v1/pods/some-name. 一个给定kind的对象同时只能有一个name。但如果你删除了此对象，便可以为新对象赋予此名字。 按照惯例，k8s资源的名称的最大长度应为253个字符，并由小写字母,数字, -, .字符组成。但某些资源可能具有更过限制。 UIDs k8s 系统生成的字符串，用于唯一标识对象。 在k8s集群的整个生命周期中创建的每个对象都具有一个唯一的UID。它旨在区分类似实体的历史事件。 \r\rNamespace k8s支持在物理集群中创建多个虚拟集群，这些虚拟机群称为namespaces。命名空间是一种将集群资源划分为多个用途的方法。 命名空间名称满足正则表达式，最大长度为63位。 什么时候使用多个命名空间 命名空间旨在用于多个用户分布在多个团队/多个项目的环境中。对于具有几个到几十个用户的集群，你根本不需要创建和考虑命名空间。 命名空间提供名称范围。资源名称在命名空间中必须唯一，但不能跨命名空间。 命名空间是一种在多个用户之间划分集群资源的方法。 在k8s的未来版本中，默认情况下，同一命名空间中的对象将具有相同的访问控制策略(ACP)。 没有必要使用多个命名空间仅来分隔略有不同的资源。如同一软件的不同版本，使用labels来区分同一命名空间内的资源。 操作命名空间 #查看 kubectl get ns NAME STATUS AGE default Active 13d kube-system Active 13d #通过命令创建 kubectl create namespace my-namespace #或通过文件创建 vim my-namespace.yaml apiVersion: v1 kind: Namespace metadata: name: my-namespace kubectl create -f ./my-namespace.yaml #查看 kubectl get namespace NAME STATUS AGE default Active 13d kube-system Active 13d my-namespace Active 4s #删除 kubectl delete namespace my-namespace #设置请求的命名空间 #使用--namespace标志临时设置请求的命名空间 kubectl kubectl get pods --namespace=default #设置命名空间首选项 kubectl config set-context $(kubectl config current-context) --namespace=my-namespace kubectl config view Kubernetes有三个初始的命名空间： default: 没有其它命名空间时，对象的默认命名空间 kube-system: k8s系统创建的对象的命名空间 kube-public: 此命名空间是自动创建的，可供所有用户读取(包括未认证用户)。此命名空间主要用于集群使用，以防止某些资源在整个集群中可见且可公开读取。此命名空间的公共方面只是一个约定，而非要求。 注意： 删除一个命名空间会自动删除所有属于该命名空间的资源 k8s初始化的两个命名空间无法删除 持久化卷(persistent volume)不属于任何命名空间，但持久化卷声明(persistent volume claim)是属于某个特定命名空间的 事件(event)是否属于命名空间取决于产生事件的对象 命名空间和DNS 当你创建一个服务(service)，它会创建相应的DNS条目(dns entry)。此条目的格式为\u003cservice-name\u003e.\u003cnamespace-name\u003e.svc.cluster.local，这表示如果一个容器只是用\u003cservice-name\u003e，它将会解析为命名空间本地的服务。这对于在多个命名空间(如 开发/测试/生产)中使用相同的配置非常有用。如果想要扩命名空间访问，则需要使用完全限定的域名(fully qualified domain name)。 不是所有对象都在命名空间中 大多数k8s资源(pods, services, replication controller…)都在某些命名空间中。然而，命名空间资源本身并不在命名空间中。并且，低级资源(node, persistentVolumes)并不在任何命名空间中。 查看k8s资源是否在命名空间中： kubectl api-resources --namespaced=true kubectl api-resources --namespaced=false \r\rLabels和Selectors 标签是被关联到对象上的key/value对。标签旨在用于指定对用户有意义且相关的对象的标识属性，但不直接按时核心系统的语义。标签可用于组织和选择对象的子集。标签可在创建时附加到对象，随时可以添加和修改。每个对象可拥有多个标签，对于给定的对象，key必须唯一。 \"metadata\": { \"labels\": { \"key1\" : \"value1\", \"key2\" : \"value2\", \"keyN\" : \"valueN\" } } #栗子 \"labels\": { \"release\" : \"stable\", \"environment\" : \"dev\", \"track\" : \"daily\" } 我们最终将**索","date":"2018-06-26","objectID":"/kubernetes/:7:4","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"使用kubectl进行对象管理 kubectl命令行工具支持多种方式来创建和管理k8s对象。 应该只使用一种技术来管理k8s对象。对同一个对象的混合和匹配技术会导致未定义的行为。 Management technique Operates on Recommended environment Supported writers Learning curve Imperative commands Live objects Development projects 1+ Lowest Imperative object configuration Individual files Production projects 1 Moderate Declarative object configuration Directories of files Production projects 1+ Highest \r\r必要的命令 Managing Kubernetes Objects Using Imperative Commands 使用k8s命令行工具内置的必要命令，可直接快速创建、更新、删除k8s对象。 权衡 kubectl工具支持三种对象管理： Imperative commands(必要的命令) Imperative object configuration(必要的对象配置) Declarative object configuration(声明的对象配置) \r\r创建对象 kubectl工具支持动词驱动的命令，用以创建一些最常见的对象类型。这些命令被命名为即使不熟悉k8s对象类型的用户也能够识别。 #创建一个新的Deployment对象，以在一个或多个pod中运行container run #创建一个新的Service对象，以在pod间对流量进行负载均衡 expose #创建一个新的Autoscaler对象，用以自动水平伸缩控制器 autoscale kubectl工具还支持由对象类型驱动的创建命令。这些命令支持更多对象类型，并且更明确地表达了它们的意图，但要求用户知道他们打算创建的对象类型。 create \u003cobjecttype\u003e [\u003csubtype\u003e] \u003cinstancename\u003e #栗子 kubectl create service nodeport \u003cservice-name\u003e \r\r更新对象 kubectl命令支持动词驱动的命令，用于一些常见的更新操作。 #通过更新控制器的副本数，水平伸缩控制器，以添加或删除pod scale #在对象中添加或删除注释 annotate #在对象中添加或删除标签 label kubectl工具还支持由对象的某个驱动的更新命令: #设置对象的一个方面 set kubectl工具支持这些直接地更新实时对象的额外方法，但他们需要更好地裂解k8s对象模式。 #通过在编辑器中打开其配置，直接编辑实时对象的原始配置文件 edit #使用补丁字符串，直接修改实时对象的特定字段 patch \r\r删除对象 #从集群中删除对象 delete \u003ctype\u003e/\u003cname\u003e kubectl delete deployment/nginx \r\r查看对象 如下这些命令可用于打印除对象信息: #打印有关匹配对象的基本信息 get #打印有关匹配对象的详细信息 describe #打印运行在pod中容器的stdout和stderr logs \r\r创建对象前修改对象 有些对象字段没有可在create命令汇总使用的标志。在某些情况下，你可使用set和create的组合在对象创建之前为字段指定值。 #set命令 kubectl create service clusterip my-svc --clusterip=\"None\" -o yaml --dry-run \\ | kubectl set selector --local -f - 'environment=qa' -o yaml \\ | kubectl create -f - #--edit标志 kubectl create service clusterip my-svc --clusterip=\"None\" -o yaml --dry-run \u003e /tmp/srv.yaml kubectl create --edit -f /tmp/srv.yaml \r\r配置文件 Imperative Management of Kubernetes Objects Using Configuration Files #创建对象 kubectl create -f \u003cfile | url\u003e #更新 kubectl replace -f \u003cfile | url\u003e #删除 kubectl delete -f \u003cfile | url\u003e #查看 kubectl get -f \u003cfile | url\u003e -o yaml \r\r使用配置文件声明管理的k8s对象 Declarative Management of Kubernetes Objects Using Configuration Files 可通过在目录中存储多个对象配置文件来创建、更新、删除k8s对象，并使用kubectl apply根据递归创建和更新这些对象。 kubectl apply不支持对象配置命令create和replace。 开始前 声明性对象配置需要深入理解k8s对象定义和配置。 \r\r创建对象 使用kubectl apply创建除指定目录中的配置文件定义的已存在的所有对象。 kubectl apply -f \u003cdirectory\u003e/ 栗子： apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: selector: matchLabels: app: nginx minReadySeconds: 5 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 #创建 kubectl apply -f https://k8s.io/examples/application/simple_deployment.yaml #查看 kubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml \r\r更新对象 使用kubectl apply更新目录中定义的所有对象，即使这些对象已经存在。 kubectl apply -f \u003cdirectory\u003e/ 栗子： #伸缩 kubectl scale deployment/nginx-deployment --replicas=2 #更新nginx版本，从1.7.9升级到1.11.9 #删除minReadySeconds字段 apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.11.9 ports: - containerPort: 80 #应用更新 kubectl apply -f https://k8s.io/examples/application/update_deployment.yaml #查看 kubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml \r\r删除对象 有两种方法: #推荐 kubectl delete -f \u003cfilename\u003e #选择 kubectl apply -f \u003cdirectory/\u003e --prune -l \u003clabels\u003e \r\r查看对象 kubectl get -f \u003cfile | url\u003e -o yaml \r\r","date":"2018-06-26","objectID":"/kubernetes/:7:5","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"计算,存储和网络 Compute, Storage, and Networking Extensions \r","date":"2018-06-26","objectID":"/kubernetes/:8:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"集群管理 Cluster Administration 规划集群 管理集群 保护集群 集群服务 详情见配置章节。 \r\r","date":"2018-06-26","objectID":"/kubernetes/:8:1","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"证书 Certificates 当使用客户端证书认证时，你可以通过easyras, openssl, cfssl手动生成证书。 \ropenssl #Generate a ca.key with 2048bit openssl genrsa -out ca.key 2048 #According to the ca.key generate a ca.crt openssl req -x509 -new -nodes -key ca.key -subj \"/CN=${MASTER_IP}\" -days 10000 -out ca.crt #Generate a server.key with 2048bit openssl genrsa -out server.key 2048 #reate a config file for generating a Certificate Signing Request (CSR) [ req ] default_bits = 2048 prompt = no default_md = sha256 req_extensions = req_ext distinguished_name = dn [ dn ] C = \u003ccountry\u003e ST = \u003cstate\u003e L = \u003ccity\u003e O = \u003corganization\u003e OU = \u003corganization unit\u003e CN = \u003cMASTER_IP\u003e [ req_ext ] subjectAltName = @alt_names [ alt_names ] DNS.1 = kubernetes DNS.2 = kubernetes.default DNS.3 = kubernetes.default.svc DNS.4 = kubernetes.default.svc.cluster DNS.5 = kubernetes.default.svc.cluster.local IP.1 = \u003cMASTER_IP\u003e IP.2 = \u003cMASTER_CLUSTER_IP\u003e [ v3_ext ] authorityKeyIdentifier=keyid,issuer:always basicConstraints=CA:FALSE keyUsage=keyEncipherment,dataEncipherment extendedKeyUsage=serverAuth,clientAuth subjectAltName=@alt_names #Generate the certificate signing request based on the config file openssl req -new -key server.key -out server.csr -config csr.conf #Generate the server certificate using the ca.key, ca.crt and server.csr openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key \\ -CAcreateserial -out server.crt -days 10000 \\ -extensions v3_ext -extfile csr.conf #View the certificate openssl x509 -noout -text -in ./server.crt \reasyrsa \rcfssl \r分发自签名CA证书 客户端节点可以拒绝将自签名(self-signed)CA 证书识别为有效。对于非生产环境火灾防火墙后面运行的部署，你可以将自签名CA证书分发给客户端，并刷新本地列表以获取有效证书。 sudo cp ca.crt /usr/local/share/ca-certificates/kubernetes.crt sudo update-ca-certificates Updating certificates in /etc/ssl/certs... 1 added, 0 removed; done. Running hooks in /etc/ca-certificates/update.d.... done. \r\r","date":"2018-06-26","objectID":"/kubernetes/:8:2","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"云提供商 跳过！ \r\r","date":"2018-06-26","objectID":"/kubernetes/:8:3","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"管理资源 可能，你已经部署应用程序并通过服务公开它。接下来怎么办？k8s提供了许多工具来帮助你管理应用程序部署(包括伸缩和更新)。我们将更深入讨论配置文件和标签。 \r组织资源配置 Organizing resource configurations 许多应用程序需要创建多个资源，如Deployment和Service。通过将多个资源组合在同一个文件中(在yaml中以---分隔)，可以简化多个资源的管理。 栗子：nginx-app.yaml apiVersion:v1kind:Servicemetadata:name:my-nginx-svclabels:app:nginxspec:type:LoadBalancerports:- port:80selector:app:nginx---apiVersion:apps/v1kind:Deploymentmetadata:name:my-nginxlabels:app:nginxspec:replicas:3selector:matchLabels:app:nginxtemplate:metadata:labels:app:nginxspec:containers:- name:nginximage:nginx:1.7.9ports:- containerPort:80 使用与单个资源相同的方式创建多个资源。 资源将按照它们在文件中出现的顺序创建。因此，最好首先指定Service，因为这将确保Scheduler可以扩展与服务关联的pod，因为它们是由Controller创建的。 kubectl create -f https://k8s.io/examples/application/nginx-app.yaml #service \"my-nginx-svc\" created #deployment \"my-nginx\" created #同样也支持多个-f kubectl create -f https://k8s.io/examples/application/nginx/nginx-svc.yaml -f https://k8s.io/examples/application/nginx/nginx-deployment.yaml #或者指定一个目录，读取yaml, yml, json文件 kubectl create -f https://k8s.io/examples/application/nginx/ #url kubectl create -f https://raw.githubusercontent.com/kubernetes/website/master/content/en/examples/application/nginx/nginx-deployment.yaml 建议的做法是，将与同一微服务或应用程序相关的资源放入同一配置文件中，或将相关联的配置文件分组到同一目录下。 \r\rkubectl批量操作 Bulk operations in kubectl 资源创建并不是kubectl可执行的唯一操作。 kubectl delete -f https://k8s.io/examples/application/nginx-app.yaml #deployment \"my-nginx\" deleted #service \"my-nginx-svc\" deleted #分开的资源 kubectl delete deployments/my-nginx services/my-nginx-svc #指定label(selector)删除 kubectl delete deployment,services -l app=nginx #deployment \"my-nginx\" deleted #service \"my-nginx-svc\" deleted #递归删除--recursive -R kubectl create -f project/k8s/development --recursive kubectl create -f project/k8s/namespaces -f project/k8s/development --recursive \r\r高效使用label Using labels effectively 到目前为止，我们使用的示例最多只能将一个标签应用于任意资源。在许多情况下，应该使用多个标签来区分集合。 labels:app:guestbooktier:backendrole:master#查看kubectl get pods -Lapp -Ltier -Lrolekubectl get pods -l app=guestbook,role=master \r\rCanary deployments 需要多个标签的另一种情况是区分不同版本的部署，或同一组件的配置。通常的做法是将新应用程序版本的canary与先前版本并排部署，以便新版本可以在完全推出前接收实时生产流量。 例如，你可以使用track标签来区分不同的版本: #stable versionname:frontendreplicas:3...labels:app:guestbooktier:frontendtrack:stable...image:gb-frontend:v3#new versionname:frontend-canaryreplicas:1...labels:app:guestbooktier:frontendtrack:canary...image:gb-frontend:v4#前端服务将通过选择其标签的公共子集(`track`)来跨越两组副本，以便将流量定向到两个应用程序。selector:app:guestbooktier:frontend \r\r更新标签 Updating labels 有时，在创建新资源之前，需要重新标记现有的pod和其它资源。这可使用kubectl label来完成。 #更新 kubectl label pods -l app=nginx tier=fe #查看 kubectl get pods -l app=nginx -L tier \r\r更新注释 Updating annotations 有时，你会想要将注释附加到资源。这个使用kubectl annotatie来完成。 kubectl annotate pods my-nginx-v4-9gw19 description='my frontend running nginx' #查看 kubectl get pod my-nginx-v4-9gw19 -o yaml \r\r伸缩应用程序 Scaling your application 当应用程序上的负载增大或缩小时，可以使用kubectl轻松扩展。 kubectl scale deployment/my-nginx --replicas=2 kubectl get pods -l app=nginx #自动伸缩 kubectl autoscale deployment/my-nginx --min=1 --max=3 \r\r就地更新资源 In-place updates of resources 有时，需要对创建的资源进行简单，无中断(non-disruptive)的更新。 kubectl apply 建议在源代码管理中维护一组配置文件，以便可以对它们配置的资源的代码进行维护和版本化。这样，你可以使用kubectl apply将更改的配置推送的集群。 kubectl apply会将注释附加到资源，以便确定自上次调用以来对配置所做的更改。在调用它是，kubectl apply会在先前的配置，提供的输入和资源的当前配置之间进行差异比较，已确定如何修改资源。 kubectl edit 或者，你可使用kubectl edit来更新资源。 kubectl edit deployment/my-nginx #这样就和vim差不多，可修改此部署 kubectl patch 你可使用kubectl patch来更新API对象。此命令支持JSON patch, JSON merge patch和 strategic merge patch。 \r\r破坏性更新 Disruptive updates 在某些情况下，你可能需要更新初始化后无法更新的资源字段，或者你可能只想立即进行递归更改，例如修复部署创建的损坏的pod。要更改此类资源，请使用replace --force——它将删除并重新创建资源。 kubectl replace -f https://k8s.io/examples/application/nginx/nginx-deployment.yaml --force deployment \"my-nginx\" deleted deployment \"my-nginx\" replaced \r\r在服务没有中断的情况下更新应用程序 Updating your application without a service outage 在某些时候，你最终需要更新已部署的应用程序，通常是指定新的image或image tag。kubectl支持多种更新操作，每种操作都适用于不同的场景。 kubectl run my-nginx --image=nginx:1.7.9 --replicas=3 #deployment \"my-nginx\" created #更新nginx版本为: 1.","date":"2018-06-26","objectID":"/kubernetes/:8:4","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"集群网络 Cluster Networking 默认情况下，k8s与docker的网络方式有所不同。有4个网络问题需要解决： 高度耦合的容器到容器的通信: 这通过pod和localhost通信解决 pod到pod的通信： 这是侧重点 pod到service的通信： 这包含在Service中 external到service的通信： 这包含在service中 k8s假设pod与pod间是可以通信的，无论它们位于哪个主机。每个pod都有自己的IP地址，因此你无需在pod之间明确创建链接，也几乎不需要处理映射容器端口到主机端口。这创建了一个干净的向后兼容的模型，从端口分配、命名、服务发现、负载均衡、应用程序配置和迁移的角度来看，pod可以像VM或物理主机一样。 为实现此目的，你需要设置集群网络。 \rDocker模型 在讨论k8s网络方法之前，有必要回顾Docker网络方式。默认情况下，Docker使用host-private网络。它创建一个虚拟网桥(称为docker0)，并从RFC1918中为该网桥定义的一个专用地址块中分配一个子网。对于Docker创建的每个容器，它分配一个连接到网桥的虚拟以太网设备(称为veth)。使用Linux命名空间将veth映射为容器中的eth0。容器内的eth0网口从桥接器的地址范围获取IP地址。 为了使Docker容器跨节点进行通信，必须在计算机自己的IP地址上分配端口，然后将这些端口转发/代理到容器。这意味着容器必须小心地使用端口，或动态分配端口。 \r\rk8s模型 跨多开发者协调端口非常难以大规模地进行，并使用户暴露在他们无法控制的集群级别问题之外。动态端口分配给系统带来了很多复杂性——每个应用程序都必须将端口作为标志，API server必须知道如何将动态端口号插入配置块，服务必须知道如何找到彼此。与此相关，k8s采取了不同的方法。 k8s对任何网络实施都强加了一下基本要求： 容器间可互相通信而无需NAT 所有节点都可与所有容器通信而无需NAT 容器看到的IP与其他人看到的IP相同 实际上，k8s在pod范围应用IP地址，pod中的容器共享其网络命名空间(包括IP地址)。这意味着pod中的容器都可以在localhost上彼此通信。这被称为ip-per-pod模型。 #在Docker中查看 docker network inspect bridge #可看到副本集的容器，都是pod，而非container #这也证明container共享pod的网络空间 #注意它的网关便是docker0 [ { \"Name\": \"bridge\", \"Id\": \"68bc0cf07a4d7666e1d35f2c1cf179ae8605b431353ba93446abc898de086a9c\", \"Created\": \"2018-07-23T17:45:54.42038221+08:00\", \"Scope\": \"local\", \"Driver\": \"bridge\", \"EnableIPv6\": false, \"IPAM\": { \"Driver\": \"default\", \"Options\": null, \"Config\": [ { \"Subnet\": \"10.254.76.0/24\", \"Gateway\": \"10.254.76.1\" } ] }, \"Internal\": false, \"Attachable\": false, \"Containers\": { \"7d2e6561fa81730ae05743f78871666df75cf5e6f483b71da33137823c172333\": { \"Name\": \"k8s_POD.24f70ba9_hello-world-3198537413-138pg_default_adb8f0fe-8fea-11e8-b10b-000c29aa7e75_785c4a84\", \"EndpointID\": \"bf50c5a71ad26531a370a73ce8da5903d32b9e2f8b8397d7405b914203071c45\", \"MacAddress\": \"02:42:0a:fe:4c:06\", \"IPv4Address\": \"10.254.76.6/24\", \"IPv6Address\": \"\" }, \"ea9fbf660f27943b866759a084dc26457474d73c50082939f157ed1dfe0bc806\": { \"Name\": \"k8s_POD.24f70ba9_hello-world-3198537413-ddgb3_default_adb90c8c-8fea-11e8-b10b-000c29aa7e75_0452e1f4\", \"EndpointID\": \"e83401827e0e6d2896eb46c7b252594c1694ca119d0cbd74c29383209b80a128\", \"MacAddress\": \"02:42:0a:fe:4c:02\", \"IPv4Address\": \"10.254.76.2/24\", \"IPv6Address\": \"\" } }, \"Options\": { \"com.docker.network.bridge.default_bridge\": \"true\", \"com.docker.network.bridge.enable_icc\": \"true\", \"com.docker.network.bridge.enable_ip_masquerade\": \"true\", \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\", \"com.docker.network.bridge.name\": \"docker0\", \"com.docker.network.driver.mtu\": \"1500\" }, \"Labels\": {} } ] \r\r如何实现k8s网络模型 How to implement the Kubernetes networking model 有多种方式实现此网络模型，以下做一个概述。 ACI AOS from Apstra Big Cloud Fabric from Big Switch Networks Cilium CNI-Genie from Huawei Contiv Contrail Flannel Google Compute Engine Kube-router L2 networks and linux bridging Multus NSX-T Nuage Networks VCS OpenVSwitch OVN Project Calico Romana Weave Net from Weaveworks \r\r","date":"2018-06-26","objectID":"/kubernetes/:8:5","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"日志架构 Logging Architecture 应用程序和系统日志可以帮助你了解集群内部发生的情况。大多数现代应用程序都有某种日志机制，因此，大多数容器化引擎同样设计来支持多种日志。容器化应用程序最简单、最受欢迎的日志方法是写入stdout和stderr。 但是，容器引擎或runtime提供的本地(native)功能通常不足以构建完整的日志解决方案。例如，如果container crashe、pod evicted、node dies，你通常仍然希望访问应用程序的日志。因此，日志应独立于container、pod、node，并具有单独存储(separate storage)和生命周期(lifecycle)。这个概念称为集群级日志(cluster-level-loggin)。集群级日志需要单独的后端来**存储(store)、分析(analyze)、查询(query)**日志。k8s不提供日志数据的本地存储解决方案，但你可以将许多现有的日志解决方案集成到k8s集群中。 集群级日志架构假设在集群内部或外部存在日志记录后端。 \r\rk8s基本日志 Basic logging in Kubernetes 本节中，k8s将日志记录到到标准输出。 vim /etc/k8s/test/counter-pod.yaml #此pod每秒输出一条信息 apiVersion: v1 kind: Pod metadata: name: counter spec: containers: - name: count image: busybox args: [/bin/sh, -c, 'i=0; while true; do echo \"$i: $(date)\"; i=$((i+1)); sleep 1; done'] #创建 #kubectl create -f /etc/k8s/test/counter-pod #不指定命名空间，则默认default #也可在配置文件里指定命名空间 #kubectl create -f /etc/k8s/test/counter-pod --namespace=test #查看 #如果pod有多个容器，则应该指定容器名称 kubectl logs counter 0: Fri Aug 10 07:43:09 UTC 2018 1: Fri Aug 10 07:43:10 UTC 2018 2: Fri Aug 10 07:43:11 UTC 2018 3: Fri Aug 10 07:43:12 UTC 2018 4: Fri Aug 10 07:43:13 UTC 2018 5: Fri Aug 10 07:43:14 UTC 2018 6: Fri Aug 10 07:43:15 UTC 2018 7: Fri Aug 10 07:43:16 UTC 2018 8: Fri Aug 10 07:43:17 UTC 2018 9: Fri Aug 10 07:43:18 UTC 2018 ...... \r\r节点级日志记录 Logging at the node level 容器化应用程序写入stdout, stderr的所有内容，都由容器引擎处理并重定向到某处。Docker容器引擎可修改日志驱动程序，将日志写入到其它地方(file, json, fluent…)。 注意 Docker json日志驱动将每一行视为单独的消息，它没有直接支持多行消息，你需要使用更高级别来处理它。 默认情况下，如果容器重启，kubelet会使用其日志保留一个已终止(terminated)的容器。如果从节点上驱逐pod，则所有相应的容器也会被驱逐(包括日志)。 节点级日志记录中，一个重要考虑因素是实现日志轮询(log rotation)，以便日志不会占用节点所有可用存储。k8s目前不负责轮询日志，但部署工具应该配置方案来解决日志轮询问题。 例如，在k8s集群中，部署一个脚本程序，用于日志轮询。或设置Docker container runtime的log-opt标志已自动轮询应用程序日志。 当在基本日志记录中运行kubectl logs命令时，节点上的kubelet会处理请求直接从日志文件读取，返回响应的内容。 注意： 如果某个外部系统已执行轮询，则kubectl logs只能获取到最新的日志文件。 system component logs 有两种类型的系统组件: run in container: 如kube-proxy not run in container: 如kubelet, Docker 在使用systemd的机器上，kubelet和container runtime将日志写到journald。如果没有systemd，则写到/var/log/下。容器内的系统组件始终将日志写入/var/log目录下，绕过默认的日志机制。 与容器日志类似，在/var/log/目录下的系统组件日志也应该被轮询。 \r\r集群级日志架构 Cluster-level logging architectures k8s官方没有提供原生的集群级日志记录，但你可以考虑集中常见方法： 在每个节点上使用node-level logging agent 用于记录应用程序pod的专用sidecar container 将日志直接从应用程序推送到后端 Using a node logging agent 你可以通过在每个节点上包含一个 节点级日志记录代理 来实现集群级日志记录。它是一个用于公开日志或将日志推送到后端的专用工具。 通常，此日志代理是一个容器，它可以访问该节点上所有应用程序容器的日志文件的目录。 由于日志记录代理必须在每个节点上运行，因此，将其实现为节点上的DaemonSet replica, manifest pod, dedicated native process是很常见的。然后，后两种方法已被弃用，并且非常不建议。 对于k8s集群，使用节点级日志代理是最常见和鼓励的方法，因为它在每个节点上只创建一个Agent，并且不需要对节点上运行的应用程序进行任何更改。然而，节点级日志仅适用于应用程序的stdout和stderr。 k8s并未指定logging Agent，但有两个可选的日志代理与k8s一同打包。两者都使用fluentd的自定义配置作为节点上的代理。 Stackdriver Logging: 用于Google Cloud Platform Elasticsearch Using a sidecar container with the logging agent 你可通过以下方式使用sidecar container: sidecar container将应用程序的日志传输到自己的stdout sidecar container容器运行一个Logging Agent，此代理从应用程序容器中获取日志 通过让sidecar container的stream流向他们自己的stdout/stderr，你可利用已经在每个节点上运行的kubelet和logging agent。sidecat container从file、socket、journald读取日志。每个单独的sidecar container将日志打印到自己的stdout/stderr。 此方法允许你从应用程序的不同部分分离多个日志流，其中一些可能缺乏对写入stdout/stderr的支持。重定向日志背后的逻辑是最小的，因此它几乎不是一个重要的开销。此外，因为stdout/stderr由kubelet处理，所以你可以使用如kubectl logs这样的内置工具。 考虑如下栗子，pod运行单个容器，此容器使用两种不同的日志格式写入两个不同的日志。 two-files-counter-pod.yaml apiVersion:v1kind:Podmetadata:name:counterspec:containers:- name:countimage:busyboxargs:- /bin/sh- -c- \u003ei=0; while true; do echo \"$i: $(date)\" \u003e\u003e /var/log/1.log; echo \"$(date) INFO $i\" \u003e\u003e /var/log/2.log; i=$((i+1)); sleep 1; donevolumeMounts:- name:varlogmountPath:/var/logvolumes:- name:varlogemptyDir:{} 即使你设法将两个组件重定向到容器的stdout，在同一个日志流中包含不同格式的日志条目也会很麻烦。相反，你可以引入两个sidecar container。每个sidecar container可以从共享卷(shared volume)中tail特定的日志文件，然后将日志重定向到自己的stdout。 这是pod运行两个sidecat container的配置文件。 三个容器共享了/var/log。 two-file-counter-pod-streaming-sidecar.yaml apiVersion:v1kind:Podmetadata:name:counterspec:containers:- name:countimage:busyboxargs:- /bin/sh- -c- \u003ei=0; while true; do echo \"$i: $(date)\" \u003e\u003e /var/log/1.log; echo \"$(dat","date":"2018-06-26","objectID":"/kubernetes/:8:6","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"kubelet垃圾回收 Configuring kubelet Garbage Collection 垃圾回收是一个有用的kubelet功能，它将清理未使用的镜像和容器。每分钟对容器执行垃圾回收，每五分钟对镜像进行垃圾回收。 不推荐使用额外的垃圾回收工具，因为这可能会破坏kubelet的行为。 \r镜像回收 Image Collection k8s在cadvisor的配合下，通过imageManager管理所有镜像的生命周期。 镜像垃圾回收策略考虑了两个要素： HighThresholdPercent LowThresholdPercent 磁盘使用率高于高阈值将触发垃圾回收，垃圾回收将删除最近最少使用的镜像，直到满足低阈值。 镜像垃圾回收的kubelet flag: #触发镜像垃圾回收的磁盘使用率百分比 #默认值 90% image-gc-high-threshold #镜像垃圾回收尝试释放磁盘使用的百分比 #默认值 80% image-gc-low-threshold \r\r容器回收 Container Collection 容器垃圾回收策略考虑了三个用户定义的变量： MinAge MaxPerPodContainer MaxContainers MinAge是容器可以被垃圾回收的最小年龄。设置为0可禁用。 MaxPerPodContainer是允许每个pod对允许拥有的最大死容器数。设置小于0可禁用。 MaxContainers是总死亡容器的最大数量。设置小于0可禁用。 kubelet将对未识别、删除或标志设置的边界之外的容器起作用。通常首先移除最旧的容器。 不受kubelet管理的容器不受容器垃圾回收的限制。 容器垃圾回收的kubelet flag: #完成的容器在垃圾回收之前的最低年龄 #默认值 0min，意味着每个完成的容器都将被垃圾回收 minimum-container-ttl-duration #每个容器要保留的最大旧实例数 #默认值 1 #强烈建议使用足够大的值，以允许每个预期容器保留至少1个死亡容器 maximum-dead-containers-per-container #全局要保留的最大容器实例数 #默认值 -1，意味着禁用 #处于类似的原因，同样建议使用较大的值 maximum-dead-containers \r\r启用 一些kubelet垃圾回收标志未来将被启用或取代。 Existing Flag New Flag Rationale –image-gc-high-threshold –eviction-hard or –eviction-soft existing eviction signals can trigger image garbage collection –image-gc-low-threshold –eviction-minimum-reclaim eviction reclaims achieve the same behavior –maximum-dead-containers xxx deprecated once old logs are stored outside of container’s context –maximum-dead-containers-per-container xxx deprecated once old logs are stored outside of container’s context –minimum-container-ttl-duration xxx deprecated once old logs are stored outside of container’s context –low-diskspace-threshold-mb –eviction-hard or eviction-soft eviction generalizes disk thresholds to other resources –outofdisk-transition-frequency –eviction-pressure-transition-period eviction generalizes disk pressure transition to other resources \r\r","date":"2018-06-26","objectID":"/kubernetes/:8:7","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"Federation 先跳过，后面来学习。 \r\r","date":"2018-06-26","objectID":"/kubernetes/:8:8","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"Proxy Proxies in Kubernetes 使用Kubernetes时可能会遇到几种不同的代理。 代理已经取代了重定向功能，重定向已被弃用。 kubectl proxy runs on a user’s desktop or in a pod proxies from a localhost address to the Kubernetes apiserver client to proxy uses HTTP proxy to apiserver uses HTTPS locates apiserver adds authentication headers \r\rapiserver proxy is a bastion built into the apiserver connects a user outside of the cluster to cluster IPs which otherwise might not be reachable runs in the apiserver processes client to proxy uses HTTPS (or http if apiserver so configured) proxy to target may use HTTP or HTTPS as chosen by proxy using available information can be used to reach a Node, Pod, or Service does load balancing when used to reach a Service \r\rkube proxy runs on each node proxies UDP and TCP does not understand HTTP provides load balancing is just used to reach services \r\rA Proxy/Load-balancer in front of apiserver existence and implementation varies from cluster to cluster(e.g. nginx) sits between all clients and one or more apiservers acts as load balancer if there are several apiservers \r\r云负载均衡器 由云服务商提供 当k8s服务有LoadBalancer类型时自动创建 仅使用udp/tcp 具体详情因云服务商而异 \r\r","date":"2018-06-26","objectID":"/kubernetes/:8:9","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"控制器管理器指标 Controller manager metrics 控制器管理器指标，提供有关控制器管理器性能和运行状况的重要信息。 这些指标包括常见的Go语言运行时指标、控制器特定指标。可用于衡量集群的运行状况。 在集群中，当控制器管理器运行时，可从http://localhost:10252/metrics获取控制器管理器指标。 netstat -nltup | grep 10252 tcp 0 0 127.0.0.1:10252 0.0.0.0:* LISTEN 11088/kube-controll curl http://localhost:10252/metrics 这些指标以prometheus format格式发出，并且是人类可读的。 \r\r","date":"2018-06-26","objectID":"/kubernetes/:8:10","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"附加组件 Installing Addons 附加组件扩展了k8s的功能。 \r网络和网络策略 Networking and Network Policy ACI： 通过 Cisco ACI提供集成的容器网络和网络完全 Calico： 是一个安全的L3网络和网络策略提供商 Canal: 将Flannel和Calico联合起来，提供网络和网络策略 Cilium： 是一个L3网络和网络策略插件 CNI-Genie： 使k8s能够无缝连接到各种CNI插件 Contiv： 提供可配置的网络，用于各种用例和丰富的策略框架 Flannel： 是一个可以与k8s一起使用的overlay网络提供商 Knitter： 是一个支持k8s多个网络的网络解决方案 Multus： 是一个用于k8s中多个网络支持，以支持所有CNI插件的多插件 NSX-T： 提供VMware NSX-T与容器协调器之间的集成 Nuage： 是一个SDN平台，可在k8s Pod和non-k8s环境之间提供基于策略的网络，并提供可见性和安全性监控 Romana： 用于Pod网络的L3网络解决方案 Weave Net： 提供网络和网络策略，将在网络分区的两侧进行工作，而不需要外部数据库 \r\r服务发现 Service Discovery CoreDNS： 是一个灵活，可扩展的DNS服务器，可作为用于pod的集群DNS。 \r\r可视化，控制 Visualization, Control Dashboard： k8s的Dashboard Web Interface Weave Scope： 是一个用于以图形可视化显示container, pod, service… \r\r\r","date":"2018-06-26","objectID":"/kubernetes/:8:11","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"k8s架构 Kubernetes Architecture \r","date":"2018-06-26","objectID":"/kubernetes/:9:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"Node node是k8s中的工作机器，以前称为minion。也就是集群中的一台主机。节点可以是VM或物理机。每个节点都具有用于运行pod所需的服务，并由master组件管理。节点上的服务包括docker, kubelet, kube-proxy。 \r节点状态 Node Status 节点的状态包含以下信息： 地址(Address) 条件(Condition) 容量(Capacity) 信息(Info) 地址 这些字段的使用取决于机器配置。 HostName： 节点内核报告的主机名 ExternalIP： 通常是可从外部路由的节点IP地址 InternalIP： 通常是仅在集群内可路由的节点IP地址 kubectl get node -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME master Ready master 7d v1.11.1 192.168.31.49 \u003cnone\u003e CentOS Linux 7 (Core) 3.10.0-862.9.1.el7.x86_64 docker://1.13.1 node Ready \u003cnone\u003e 7d v1.11.1 192.168.31.174 \u003cnone\u003e CentOS Linux 7 (Core) 3.10.0-862.9.1.el7.x86_64 docker://1.13.1 salt01 Ready \u003cnone\u003e 1d v1.11.1 192.168.31.159 \u003cnone\u003e CentOS Linux 7 (Core) 3.10.0-862.9.1.el7.x86_64 docker://1.13.1 kubectl describe node/salt01 Addresses: InternalIP: 192.168.31.159 Hostname: salt01 条件 该字段描述了所有运行中节点的状态。节点条件使用JSON对象表示。 条件 描述 OutOfDisk True(节点上的可用空间不足以添加新pod), 否则为False Ready True(节点健康并准备好接受pod) False(节点不健康且不接受pod) Unknown(节点控制器在最后一个node-monitor-grace-period期限内没有从节点收到消息。默认40s) MemoryPressure True(节点内存有压力，即内存不足)，否则为False PIDPressure True(进程存在压力，即节点上有太多进程)，否则为False DiskPressure True(磁盘大小存在压力，即磁盘容量较低), 否则为False NetworkUnavailable True(节点网络配置错误)，否则为False ConfigOK True(kubelet配置正确)，否则为False kubectl describe node/salt01 Conditions: Type Status LastHeartbeatTime LastTransitionTime Reason Message ---- ------ ----------------- ------------------ ------ ------- OutOfDisk False Wed, 15 Aug 2018 11:10:49 +0800 Mon, 13 Aug 2018 15:51:40 +0800 KubeletHasSufficientDisk kubelet has sufficient disk space available MemoryPressure False Wed, 15 Aug 2018 11:10:49 +0800 Mon, 13 Aug 2018 15:51:40 +0800 KubeletHasSufficientMemory kubelet has sufficient memory available DiskPressure False Wed, 15 Aug 2018 11:10:49 +0800 Mon, 13 Aug 2018 15:51:40 +0800 KubeletHasNoDiskPressure kubelet has no disk pressure PIDPressure False Wed, 15 Aug 2018 11:10:49 +0800 Mon, 13 Aug 2018 15:51:40 +0800 KubeletHasSufficientPID kubelet has sufficient PID available Ready True Wed, 15 Aug 2018 11:10:49 +0800 Mon, 13 Aug 2018 15:53:00 +0800 KubeletReady kubelet is posting ready status 容量 描述节点上的可用资源：CPU，内存，可调度到节点上的最大pods数。 kubectl describe node/salt01 Capacity: cpu: 2 ephemeral-storage: 49250820Ki hugepages-2Mi: 0 memory: 3881332Ki pods: 110 信息 关于节点的一般信息，如Kernel版本，Kubernetes版本，Docker版本，OS… kubectl describe node/salt01 System Info: Machine ID: e48d6bf22f9b4c8da5cb1a07b2fec730 System UUID: 564D1413-905B-64D6-E9A2-92E37F9B5BDA Boot ID: 1df89a81-77a4-44a0-9241-e6d766795e32 Kernel Version: 3.10.0-862.9.1.el7.x86_64 OS Image: CentOS Linux 7 (Core) Operating System: linux Architecture: amd64 Container Runtime Version: docker://1.13.1 Kubelet Version: v1.11.1 Kube-Proxy Version: v1.11.1 \r\r管理 Management 与Pod与Service不同，k8s本身并不创建节点： 它由云服务商创建，或存在于物理机/虚拟机的pool中。 当k8s创建节点时，它实际上只是创建了一个表示节点的对象。创建之后，k8s将检查节点是否有效。 栗子： { \"kind\": \"Node\", \"apiVersion\": \"v1\", \"metadata\": { \"name\": \"10.240.79.157\", \"labels\": { \"name\": \"my-first-k8s-node\" } } } k8s将在内部创建节点对象，并通过基于metadata.name字段的运行状况检查来验证节点。 如果节点有效(valid)，即所有必要的服务都已运行，它就符合了运行pod的条件。否则它将被所有的集群动作忽略，直到它变为有效。请注意，Kubernetes将保持无效(invalide)节点的对象，除非它被手动删除。Kubernetes将持续检查节点是否变得可用。 目前，有3个组件与k8s节点接口交互： Node Controller kubelet kubectl 节点控制器 节点控制器是一个k8s Master组件，用于管理节点的各个方面。 节点控制器在节点的生命周期中具有多个角色(role)。第一个便是在节点注册时为其分配CIDR地址块。 第二个是使节点控制器的内部节点列表与可用机器保持一致。只要节点不健康，节点控制器就会询问该节点是否仍然可用。如果不是，则节点控制器从其节点列表中删除该节点。 第三个是监控节点的健康状况。当节点不可达时，节点控制器负责更新节点的条件(condition)状态，从Ready变为Unknown。如果节点继续无法访问，则稍后从节点中驱逐(evict)所有pod(graceful termination)。默认超时时间为40s开始上报Unknown，然后5min之后开始驱逐pods。节点控制器通过--node-nonitor-period秒检查每个节点的状态。 在大多数情况下，节点控制器将驱逐率(evication rate)限制为--node-eviction-rate(默认值 0.1)每秒。这意味着它将不会每10s从超过1个节点驱逐pod。 当给定可用区域中的节点变得不健康时，节点驱逐行为会发生变化。同时，节点控制器检查此区域中不健康节点的百分比。 如果节点不健康比例至少为--unhealthy-zone-threshold(默认值 0.55)，那么驱逐率会降低； 如果集群很小，小于或等于--large-cluster-size-threshold(默认值 50)，则停止驱逐； 否则，驱逐率减小到每秒--secondary-node-eviction-rate(默认值 0.01)。 每个可用区域实施这些策略的原因是，一个可用区域可能与其它可用区域保持连接。 在可用区域之间传播节点的一个关键原因是，当整个区域出现故障时，工作负载可以转移到健康区域。因此，如果区域中","date":"2018-06-26","objectID":"/kubernetes/:9:1","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"节点通信 Master-Node communication Master(APIserver)与k8s cluster之间的通信。 目的是允许用户自定义其安装以强化网络配置，以便集群可在不受信任的网络上运行。 Cluster-\u003eMaster 从Cluster到Master的所有通信路径都终止于API server。在典型部署中，API server配置为在安全的HTTPS(443)端口上监听远程连接，并启用一种或多种形式的Client认证。 应该为节点配置集群的公共根证书，以便他们可以使用有效证书安全地连接到API server。 希望连接到API server的Pod可以利用Service Account安全地执行此操作，这样k8s在实例化时自动将公共根证书和有效bearer token注入到Pod中。the kubernetes service配置了一个虚拟IP地址，该地址被重定向到API server的HTTPS endpoint。 Master组件还通过安全端口与Cluster API server通信。 kubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 \u003cnone\u003e 443/TCP 8d 因此，默认情况下，从Cluster到Master的连接的默认操作模式是安全的，可在不受信任网络/公共网络上运行。 \r\rMaster-\u003eCluster 从Master(API server)到Cluster有两条主要通信路径： API server -\u003e kubelet API server -\u003e node, pod, service API server -\u003e kubelet 从API server到kubelet(它运行在集群中的每个节点上)。 从API server到kubelet的连接用于： 获取Pod的日志 附加到运行的Pod 提供kubelet的端口转发功能 这些连接终止于kubelet的HTTPS endpoint。默认情况下，API server不会验证kubelet的证书，这会使连接可能受到中间人工具，并且不安全地运行在不受信任/公共的网络上。 要验证此连接，使用--kubelet-certificate-authority标志位API server提供根证书，用于验证kubelet的证书。 如果无法做到，请在API server和kubelet之间使用SSH隧道保障连接安全。 API server -\u003e node, pod, service 从API server到node, pod, service的连接默认为纯HTTP，因此既不需要认证也未加密。他们可以通过在API URI的前缀使用https://来运行安全的HTTPS，但他们不会验证HTTPS endpoint提供的证书，也不会提供客户端凭据。因此连接将被加密，它不会提供任何完整性保证。 \r\r","date":"2018-06-26","objectID":"/kubernetes/:9:2","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"云控制器管理器 Cloud Controller Manager 暂时跳过！ \r\r\r","date":"2018-06-26","objectID":"/kubernetes/:9:3","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"扩展k8s \r","date":"2018-06-26","objectID":"/kubernetes/:10:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"扩展k8s集群 Extending your Kubernetes Cluster k8s具有高度可配置化和可扩展化。 定制方法可大致分为配置，只涉及更改标志，本地配置文件或API资源；扩展，设计运行其它程序或服务。 \r扩展模式 Extensions Patterns k8s旨在通过编写客户端程序实现自动化。任意 read/write k8s API的程序都可以提供有用的自动化。自动化可在集群上启用或关闭。自动化通常适用于k8s集群，包括托管集群和管理安装。 有一种编写与k8s一起使用的称为控制器模式(Controller Pattern)客户端程序的特定模式。控制器通常读取对象的.spec，可能做些事情，然后更新对象的.status。 控制器(Controller)是一个k8s client。当k8s为client并调用远程服务时，它被称为Webhook。远程服务被称为Webhook Backend。与控制器一样，Webhook确实增加了一个失败点。 在webhook模式中，k8s 向远程服务发出网络请求。在二进制插件模型中，k8s执行二进制程序。二进制插件由kubelet和kubectl使用。 \r扩展点 Extension Points k8s 系统的扩展点: 用户使用kubectl与k8s API进行交互 API server处理所有请求 API server提供各种资源 k8s调度器决定将pod放在哪个节点上 k8s大部分行为都是由控制器实现的 kubelet帮助pod在集群网络上显示为具有自己IP的虚拟服务 kubelet还可挂载和解挂容器的卷 如果你不确定如何开始，查看如下流程图： \rAPI扩展 API Extensions User-Defined Types 如果想要定义新的控制器、应用程序配置对象、声明性API并管理他们，请考虑向k8s添加自定义资源。 不要讲自定义资源用作应用程序、用户、监控数据的数据存储。 Combining New APIs with Automation 通常，当添加新API时，还会添加一个 read/write 新API的控制循环。当自定义API和控制循环的组合用于管理特定的，通常是有状态的应用程序时，这被称为操作者模式(Operator Pattern)。 Changing Built-in Resources 通过自定义资源添加扩展k8s API时，添加的资源始终属于新的API组。你无法替换或修改已经存在的API组。添加API不会直接影响现有API的行为，但API Access Extensions会影响现有API的行为。 API Access Extensions 当请求到达k8s API server时，它首先进行身份验证，然后授权，然后进行各种准入控制。每个步骤都提供了扩展点。 Authentication 身份验证将所有请求中的Header或证书映射到发出请求的客户端的用户名中。 Authorization 授权确定特定用户是否可以对API资源进行读写和其它操作。它只是在整个资源的层面上工作，不基于任意对象字段进行区分。 Dynamic Admission Control 当请求授权之后，如果它是一个写操作，它还需要通过Admission Control步骤。除了内建步骤之外，还有其它扩展： Image Policy webhook限制可在容器中运行的镜像 为了做出任意的admission control决策，可使用普通admission webhook 初始化程序可在创建对象之前修改对象的控制器 \r基础设施扩展 Infrastructure Extensions Storage Plugins Flex Volumes允许用户通过kubelet调用二进制插件来安装卷，来安装没有内置支持的卷类型 Device Plugins 设备插件允许节点通过设备发现插件发现新的节点资源 Network Plugins 支持不同的网络结构 Scheduler Extensions 调度器是一种特殊类型的控制器，用于监视Pod，并将Pod分配给节点。 \r\r","date":"2018-06-26","objectID":"/kubernetes/:10:1","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"扩展k8s API Extending the Kubernetes API \r在聚合层扩展k8s API Extending the Kubernetes API with the aggregation layer 聚合层允许在集群中安装其它k8s-style的API。 \r自定义资源 Custom Resources 自定义资源是k8s API的扩展，包括何时向k8s集群添加自定义资源以及何时使用独立服务。 资源是k8s API中的端点(endpoint)，用于存储某种API对象的集合。如，内建的pods资源包含了Pod对象的集合。 自定义资源是k8s API的扩展，不一定在每个k8s集群上都可用。换句话说，它代表了特定k8s的定制安装。 自定义资源可通过动态注册在正在运行的集群中出现和消失，集群管理员可独立于集群本身更新自定义资源。安装自定义资源后，用户可使用kubectl创建和访问其对象。 Custom controllers 自定义字段本身可让你存储和检索结构化数据。只有与控制器结合使用才能成为真正的声明性API。declare API允许你声明或指定资源的所需状态，并尝试将实际状态与此期望状态相匹配。这里，控制器将结构化的数据解释为用户期望状态的记录，并且不断采取行动以实现和维护该状态。 自定义控制器是一种用户可在正在运行的集群上进行部署和更新，而与集群自身的生命周期无关的控制器。自定义控制器可使用任何类型的资源，但与自定义资源结合使用时，它们更有效。 Should I add a custom resource to my Kubernetes Cluster? 当创建新的API时，考虑是使用k8s cluster API还是让API独立运行。 Consider API aggregation if: Prefer a stand-alone API if: Your API is Declarative. Your API does not fit the Declarative model. You want your new types to be readable and writable using kubectl. kubectl support is not required You want to view your new types in a Kubernetes UI, such as dashboard, alongside built-in types. Kubernetes UI support is not required. You are developing a new API. You already have a program that serves your API and works well. You are willing to accept the format restriction that Kubernetes puts on REST resource paths, such as API Groups and Namespaces. (See the API Overview.) You need to have specific REST paths to be compatible with an already defined REST API. Your resources are naturally scoped to a cluster or to namespaces of a cluster. Cluster or namespace scoped resources are a poor fit; you need control over the specifics of resource paths. You want to reuse Kubernetes API support features. You don’t need those features 声明性API Declarative APIs 在一个声明性API中，通常： 你的API由相对较少的相对较小的对象组成 应用程序或基础结构的对象定义配置 对象很少更新 人们通常需要读写对象 对象的主要操作时CRUD 跨对象的事务不是必需的：API表示期望状态，而不是精确的状态 imperative API不是声明性的，你的API可能不是声明性的标志包括： 客户端说执行此操作，完成后获得同步响应 客户端说执行此操作，然后获取操作ID，并且必须检查单独的Operation对象以确定请求的完成 谈论Remote Procedure Calls(RPCs) 直接存储大量数据 需要高带宽访问 存储最终用户数据，或应用程序处理的其它大规模数据 对象非CRUD的自然操作 API不容易建模为对象 使用操作ID或操作对象表示挂起的操作 Should I use a configMap or a custom resource? 如果符合以下任意条件，请使用ConfigMap: 存在现有的，记录完备的配置文件格式 你希望将整个配置文件放入ConfigMap的一个key中 配置文件的主要用途是在集群上的Pod中运行的程序使用该文件来配置自身 文件的消费者更喜欢使用Pod中的文件或环境变量，而不是k8s API 你希望在文件更新时通过部署执行滚动升级 如果符合以下大部分情况，请使用自定义资源： 你希望使用k8s client library和CLI来创建和更新新资源 你希望来自kubectl的顶级支持 你希望构建新的自动化，监视新对象的更新，然后CRUD其它对象 你希望编写处理对象更新的自动化 你希望使用k8s API约定，如.spec, .status, .metadata 你希望对象是受控资源集合的抽象，或其它资源的汇总 添加自定义资源 k8s提供了两种方式来向你的集群中添加自定义资源： CRD很简单，无需任何编程即可创建 API聚合需要编程，但允许更多控制API行为，如数据的存储方式和API版本间的转换 聚合API是位于主API server后面的从属API server，它充当代理。这种安排称为API聚合(AA, API Aggregation)。 CRD允许用户添加新类型的资源，而无需添加其它API server，你无需了解API聚合即可使用CRD。 无论如何安装，新资源都成为自定义资源，以区别于内置的k8s 资源。 自定义资源定义 自定义资源定义 API资源允许你去定义自定义资源。定义CRD对象会创建一个新的自定义资源，其中包含指定的名称和架构。k8s API提供并处理自定义资源的存储。 这使你无需编写自己的API server来处理自定义资源，但实现的一般特性意味着你的灵活性低于API server聚合。 API server aggregation 通常，k8s API中的每个资源都需要处理REST 请求的代码并管理对象的持久化存储。k8s API server处理pod等内建资源，还可通过CRD处理自定义资源。 聚合层允许你通过编写和部署自己的独立API server为自定义资源提供专门的实现。API server将请求委托给你处理的自定义资源，使其对所有客户端可用。 为添加自定义资源选择一个方法 通常情况下，CRD很适合，如果： 你有少数几个领域 你正在使用公司内的资源，或作为小型开源项目的一部分 易用性比较： CRDs Aggregated API Do not require programming. Users can choose any language for a CRD controller. Requires programming in Go and building binary and image. Users can choose any language for a CRD controller. No additional service to run; CRs are handled by API Server. An additional service to create and that could fail. No ongoing support once the CRD is created. Any bug fixes are picked up as part of normal Kubernetes Master upgrades. May need to periodically pickup bug fixes from upstream and rebuild and update the Aggregated APIserver. No need to handle multiple versions of your API. For example: when you control the client for this resource, you can upgrade it in sync with the API. You need to handle multiple versions of your API, for example: when developing an extension to share with the world. 高级功能和灵活性： Feature Description CRDs Aggregated ","date":"2018-06-26","objectID":"/kubernetes/:10:2","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"计算，存储和网络插件 Compute, Storage, and Networking Extensions 网络插件 Network Plugins Notice: FEATURE STATE: Kubernetes v1.11 alpha Alpha features change rapidly k8s中的网络插件有几种风格： CNI plugins: 遵守appc/CNI规范，旨在实现互操作性 Kubenet plugin: 使用bridge和host-local CNI plugins实现基本的cbr0 安装 kubelet有一个默认的网络插件，以及整个集群的默认网络。它在启动时探测插件，记住它找到的内容，并在pod声明周期中的适当时间执行所选插件。 使用插件时，请记住两个kubelet命令行参数： cni-bin-dir: kubelet在启动时检测此目录以获取插件 network-plugin： 从cni-bin-dir使用的网络插件 ps -ef | grep kubelet /usr/bin/kubelet xxx --cni-bin-dir=/opt/cni/bin --cni-conf-dir=/etc/cni/net.d --network-plugin=cni 网络插件需求 除了提供网络插件接口来配置和清理pod网络外，该插件还可能需要对kube-proxy提供特定支持。iptables proxy依赖于iptables，插件可能需要确保容器流量可用于iptables。 默认情况下，如果未指定kubelet网络插件，则使用noop插件，它设置net/bridge-nf-call-iptables=1来确保简单配置与iptables proxy正常工作。 CNI 通过kubelet传递--network-plugin=cni选项来选择CNI插件。kubelet从cni-conf-dir(默认/etc/cni/net.d)中读取文件，并使用该文件中的CNI配置来设置每个pod的网络。引用的插件必须存在于--cni-bin-dir(默认/opt/cni/bin)中。 如果目录中有多个CNI配置文件，则使用文件名的词典顺序的第一个。 除了配置文件指定的CNI插件外，k8s还需要标准的CNI lo插件(loopback)，最低版本 v0.2.0 kubenet kubelet是一个仅使用与Linux的基本和简单的网络插件。它本身并不实现高级的功能，如跨节点网络或网络策略。kubenet创建一个名为cbr0的Linux bridge，并为每个pod创建一个veth对，每对的主机端连接到连接到cbr0。通过配置或控制器管理器为该对的pod端分配范围内的IP地址。为cbr0分配一个MTU，该MTU与主机上启用的普通接口的最小MTU相匹配。 此插件需要一些东西： 需要标准的CNI bridge, lo, host-local插件，最小版本 v0.2.0。首先从/opt/cni/bin查找。 kubelet必须使用--network-plugin=kubenet参数来启用此插件 kubelet应该指定--non-masquerade-cidr=\u003cclusterCidr\u003e参数确保超出范围的IP流量将使用IP masquerade。 必须通过kubelet的--pod-cidr选项或控制器管理器的--allocate-node-cidrs=true --cluster-cidr=\u003ccidr\u003e选项来为节点分配IP子网 自定义MTU(kubenet) 应该始终正确配置MTU以获得最佳网络性能。网络插件通常会推断合理的MTU，但有时不会产生最佳的MTU。 如果需要，你可使用kubenet的network-plugin-mtu选项来明确指定MTU，仅有kubenet插件支持此选项。 使用摘要 --network-plugin=cni --network-plugin=kubenet --network-plugin-mtu=9001 \r\r设备插件 Device Plugins 从v1.8开始，k8s为Vendors提供了设备插件框架，以便在不更改k8s核心代码的情况下将资源通知到kubelet，Vendor可实现手动部署或作为DaemonSet部署的设备插件，而不是编写自定义的k8s插件。目标设备包括GPU，高性能NIC， FPGA， InfiniBand和其它计算资源。 设备插件注册 设备插件功能由DevicePlugins功能控制，默认在 v1.10之前禁用。当启用设备插件功能，kubelet将导出Registration gRPC服务: service Registration { rpc Register(RegisterRequest) returns (Empty) {} } 设备插件可通过gRPC服务向kubelet注册自己。在注册中，它需要发送： Unix socket名 设备插件API版本 想要告知的ResourceName 栗子： apiVersion: v1 kind: Pod metadata: name: demo-pod spec: containers: - name: demo-container-1 image: k8s.gcr.io/pause:2.0 resources: limits: vendor-domain/resource: 2 # requesting 2 vendor-domain/resource 设备插件实现 设备插件的一般工作流包括如下步骤： 初始化 插件启动gRPC服务 插件使用kubelet的Unix socket注册自己 注册成功之后，设备插件以服务模式运行，在此期间，它会持续监控设备运行状况，并在任何设备状况发生变化时向kubelet报告 设备插件部署 设备插件可手动或作为DaemonSet来部署。 k8s 设备插件的支持人处于alpha状态。 \r\r","date":"2018-06-26","objectID":"/kubernetes/:10:3","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"服务目录 Service Catalog 服务目录是一种扩展API，它使在k8s集群中运行的应用程序能够轻松使用外部托管软件。 它提供了从Service Broker 列出，配置和绑定外部托管服务的方法，而无需详细了解如何创建或管理这些服务。 使用服务目录，集群操作人员可以浏览服务代理提供的托管服务列表，配置托管服务的实例，并与其绑定以使其可供k8s集群中应用程序使用。 \r\r\r","date":"2018-06-26","objectID":"/kubernetes/:10:4","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"Containers ","date":"2018-06-26","objectID":"/kubernetes/:11:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"Images 你创建Docker image并将其push到registry，然后在k8s pod中引用它。 容器的镜像属性支持与Docker命令相同的语法，包括私有注册表和标记。 更新镜像 默认的拉取策略是ifNotPresent，这会导致kubelet跳过拉取镜像(如果镜像已存在)。所以在网络不好时，我们可以首先将镜像拉取下来。 如果你总想强制拉取镜像，可以执行如下操作： 设置容器imagePullPolicy为Always 使用:latest作为镜像的标记 启用AlwaysPullImages准入控制器 如果没有对镜像指定标记，则假定为:latest标记。 使用私有注册表 Using a Private Registry 私有注册表有： Docker Hub Aliyun Tencent yun Google Container Registry AWS Container Registry Azure Container Registry … 以下是配置节点已使用私有注册表的推荐步骤： 1. 运行 docker login 2. 查看 ~/.docker/config.json { \"auths\": { \"https://index.docker.io/v1/\": { \"auth\": \"xxxxxxxxxxxxxxx\" } }, \"HttpHeaders\": { \"User-Agent\": \"Docker-Client/18.03.1-ce (linux)\" } 3. 获取节点列表 #name nodes=$(kubectl get nodes -o jsonpath='{range.items[*].metadata}{.name} {end}') #IPs nodes=$(kubectl get nodes -o jsonpath='{range .items[*].status.addresses[?(@.type==\"ExternalIP\")]}{.address} {end}') 4. 复制 .docker/config.json 到上面的搜索路径列表 for n in $nodes; do scp ~/.docker/config.json root@$n:/var/lib/kubelet/config.json; done 通过创建pod来验证私有镜像： kubectl create -f - \u003c\u003cEOF apiVersion: v1 kind: Pod metadata: name: private-image-test-1 spec: containers: - name: uses-private-image image: $PRIVATE_IMAGE_NAME imagePullPolicy: Always command: [ \"echo\", \"SUCCESS\" ] EOF pod \"private-image-test-1\" created 预拉取镜像 Pre-pulling Images 默认情况下，kubelet将尝试从指定的注册表中拉取镜像。但是，如果容器的imagePullPolicy属性为ifNotPresent或Never，则会使用本地镜像。 如果你希望依赖于预先拉取的镜像作为注册表身份验证的替代，则必须确保集群中的所有节点都具有相同的预拉取镜像。 这可以用于预加载某些镜像以提高速度，或者作为对私有注册表进行身份认证的替代方法。 请确保所有的pods都对预拉取的镜像由访问权限。 Specifying ImagePullSecrets on a Pod k8s支持在pod上指定registry keys。 #使用Docker config创建secret kubectl create secret docker-registry -h #Create a new secret for use with Docker registries. kubectl create secret docker-registry zhang21-secret --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAIL secret \"myregistrykey\" created. kubectl get secret NAME TYPE DATA AGE zhang21-secret kubernetes.io/dockerconfigjson 1 22s #查看和修改 kubectl edit secret/zhang21-secret 如果需要访问多个注册表，你可以为每个注册表创建一个secret。当为pod来取镜像时，kubelet会将imagePullSecret合并到 一个虚拟的.docker/config.json文件中。 pod只能在自己的命名空间中引用image pull secret，因此每个命名空间都需要执行一次此过程。 pod上的imagePullSecret apiVersion: kind: Pod xxx spec: container: xxx imagePullSecretes: name: zhang21-secret \r\r","date":"2018-06-26","objectID":"/kubernetes/:11:1","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"容器环境变量 Container Environment Variables k8s容器环境为容器提供了几个重要资源： 文件系统(是镜像和卷的组合) 容器自身信息 集群中对象的信息 \r\r","date":"2018-06-26","objectID":"/kubernetes/:11:2","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"容器生命周期钩子 Container Lifecycle Hooks 本节描述了kubelet如何使用容器生命周期钩子框架来运行在管理生命周期中由事件触发的代码。 与许多具有组件生命周期钩子的编程语言框架类似，k8s为容器提供了生命周期钩子。钩子使容器能够了解其生命周期中的事件，并在执行相应的生命周期钩子时运行在处理程序中实现的代码。 \r容器钩子 有两个公开给容器的钩子： PostStart 此钩子在容器创建后立即执行。但是，无法保证钩子将在容器ENTRYPOINT之前执行。没有参数传递给处理程序。 PreStop 此钩子在容器终止前立即调用。它是阻塞的，意味着它是同步的。所以它必须在调用删除容器之前完成才能发送。没有参数传递给处理程序。 Hook handler implementations 容器可以通过实施和注册该钩子的处理程序来访问钩子。可为容器实施两种类型的钩子处理程序： Exec： 在cgroup和namespace内执行特定的命令 HTTP： 在容器的特定端点上执行一个HTTP请求 Hook handler exection 调用容器生命周期管理钩子时，k8s管理系统会在为钩子注册的容器中执行处理程序。 钩子处理程序调用包含在容器的Pod的上下文中是同步的。这意味着对PostStart钩子，容器ENTRYPOINT和钩子异步启动。但是，如果钩子 运行/挂起 太长时间，则容器无法达到running state。 PreStop钩子的行为类似。如果钩子在执行期间挂起，则pod阶段将保持在Terminating state，并在pod结束的terminationGracePeriodSeconds之后被杀掉。 如果PostStart或PreStop钩子失败，则会杀掉容器。 用户应该使他们的钩子处理程序尽可能的轻量化。 Hook delivery guarantees 钩子交付至少是一次，这意味着对于任何给定的事件可以多次调用钩子。由钩子实现来正确处理这个问题。 通常，只进行当次交付。在一些罕见的情况下，可能会发生双重交付。 Debugging Hook handlers 钩子处理程序的日志并不会在Pod事件中公开。如果处理程序由于某种原因失败，它会广播这个事件。 \r\r\r","date":"2018-06-26","objectID":"/kubernetes/:11:3","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"工作负载 Workloads ","date":"2018-06-26","objectID":"/kubernetes/:12:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"Pods Pod是k8s的基本构建块，是你创建和部署k8s对象模型中最小和最简单的单元。Pod代表了集群上正在运行的进程。 Pod封装了(encapsulates) 一个/多个 应用程序容器，存储资源，唯一的IP地址(集群内)以及控制容器运行需要的选项。Pod代表了一个部署单元，k8s中的单个应用程序实例可能包含单个或少量紧密耦合且共享资源的容器。 Docker是k8s Pod中最常使用的容器运行环境(runtime)，Pod同样也支持其它容器运行环境。 k8s 集群中的Pods可以用两种主要方法来使用： 运行单个容器的Pod Pods that run a single container one-container-per-pod模型时最常见的k8s用例。在这种情况下，你可将Pod视为单个容器的包装，而k8s直接管理Pod而不是容器。 运行多个需要协同工作的容器的Pod Pods that run multiple containers that need to work together Pod可能封装了由多个协同定位(co-located)容器组成的应用程序，这些容器紧密耦合并且需要共享资源。这些协同的容器可能形成一个统一的服务单元——一个容器从共享卷向公众提供文件，而一个单独的sidecar容器刷新或更新这些文件。Pod将这些容器和资源作为单个可管理的实体包装在一起。 每个Pod都用于运行给定应用程序的单个实例。如果你想要水平扩展应用程序，你可以使用多个Pods(每个实例一个)。在k8s中，这通常称为副本(replication)。 Replicated Pods通常通过称为**控制器(Controller)**的抽象来创建和管理。 Pod如何管理多个容器 Pods旨在支持多个协作进程(as container)，形成一个具有凝聚力的服务单元。Pod中的容器将自动协同定位(co-located)，并在集群中的同一主机上协同调度(co-scheduled)。容器可以共享资源和依赖，彼此通信，并协调它们何时以及如何终止。 注意，将多个协同定位和协同管理的容器分组到一个Pod中是一个相对高级的栗子。你应该仅在容器紧密耦合的特定实例中使用此模式。 例如，你可能有一个容器充当共享卷中文件的Web Server，以及一个单独的sidecat容器——用于从远程更新这个文件： Pod共享资源 Pod为其组成容器提供了两种共享资源： Networking 每个Pod都被分配了一个唯一的IP地址(within cluster)。Pod中的每个容器都共享网络命名空间，包括IP地址和网络端口。Pod内的容器可使用localhost相互通信。当Pod内的容器与Pod外的实体通信时，它们必须协调如何使用共享网络资源。 Storage Pod可以指定一组共享存储卷。Pod中的所有容器都可以访问这个共享卷，允许这些容器共享数据。还是关于数据持久化的卷。 使用Pods 你很少直接在k8s(甚至是单例Pod)中创建单独的Pod。这是因为Pod被设计为相对短暂的一次性实体，即用后即焚。当Pod被创建后，都会被调度到集群中的节点上运行。Pod保留在该节点上，知道进程终止，Pod对象被删除，Pod因资源不足而被驱逐，或节点失效。Pod不会自愈。 注意： 重启Pod中的容器与重启Pod不是一回事。Pod本身不运行，它只提供容器的运行环境并保持容器的运行状态。但是容器运行的环境会持续存在，直到删除为止。 Pod本身不提供自我修复(self-heal)。如果将Pod调度到一个失败的节点，或调度操作本身失败，则会删除Pod。同样，由于缺乏资源或节点维护中，Pod将无法在驱逐中存活。k8s使用一个高更级别的抽象，称为控制器(Controller)。它管理相对可处理的Pod实例的工作。因此，尽管可以直接使用Pod，但在k8s中使用控制器管理Pod更为常见。 控制器可为你创建和管理多个Pod，处理副本和上线，并在集群范围内提供自我修复功能。例如，如果节点故障，控制器可能会通过在不同节点上安排相同的替换来自动替换Pod。 通常，控制器使用你提供的Pod模板来创建它负责的Pod。 Pod Templates Pod模板是Pod规范，包含在其它对象中。控制器使用Pod模板制作实际的Pod。 栗子： apiVersion: v1 kind: Pod metadata: name: myapp-pod labels: app: myapp spec: containers: - name: myapp-container image: busybox command: ['sh', '-c', 'echo Hello Kubernetes! \u0026\u0026 sleep 3600'] Pod模板不是指定所有副本的当前所需状态，而是像饼干切割器。饼干被切割后，饼干与切割器无关。 \r\rPod Pod是可在k8s中创建和管理的最小可部署的计算单元。 Pod是什么 Pod是一组 一个/多个容器，具有共享存储/网络，以及如何运行容器的规范。Pod中的容器总是co-located和co-scheduler，并在共享上下文中运行。一个pod模拟特定应用程序的逻辑主机，它包含一个/多个紧密耦合的应用程序容器。 Pod的共享上下文十一组Linux namespace， cgroup，以及隔离方面。在Pod的上下文中，各个应用程序科恩能够回应用进一步的子隔离。 Pod中的容器共享IP地址和端口空间，并且可通过localhsot找到彼此。它们还可使用IPC相互通信。不同Pod中的容器具有不同的IP地址，默认情况下无法通信，需要进行额外配置。 Pod中的应用程序还可访问共享卷，共享卷被定义为Pod的一部分，可挂载到每个应用程序的文件系统中。 就Docker构造而言，Pod被建模为一组具有共享命名空间和共享卷的Docker容器。 与单个应用程序容器类似，Pod被认为是相对短暂(非持久)的实体。 Pod动机 管理(Management) Pod是多个协作过程进程模式的模型，形成了一个有凝聚力的服务单元。它们通过提供更高级别的抽象来简化应用程序部署和管理。Pod提供用于部署，水平扩展，副本的单元。对于Pod中的容器，它们将自动处理协同调度， 共享命运， 协同副本，资源共享和依赖管理… 资源共享和交流 Pod可以实现成员之间的数据共享和通信。 Pod中的应用程序都是用相同的网络命名空间，因此可通过localhost进行通信。因此，Pod中的应用程序必须协调对端口的使用。 主机名设置为Pod中应用程序容器的Pod名。 除了定义在Pod中运行的应用程序容器，Pod还制定了一组共享存储卷(持久化)。 kubectl -n kube-system get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE kubernetes-dashboard-6948bdb78-tdh5v 1/1 Running 0 8d 10.244.2.3 salt01 metrics-server-85ff8f7b84-72rd4 1/1 Running 0 9d 10.244.2.2 salt01 kubectl -n kube-system exec -it metrics-server-85ff8f7b84-72rd4 /bin/sh / # hostname metrics-server-85ff8f7b84-72rd4 / # ifconfig eth0 10.244.2.2 / # ping 10.244.2.3 PING 10.244.2.3 (10.244.2.3): 56 data bytes 64 bytes from 10.244.2.3: seq=0 ttl=64 time=0.115 ms 64 bytes from 10.244.2.3: seq=1 ttl=64 time=0.062 ms Pod使用 Pod可用于托管垂直集成的应用程序栈，但主要动机是用于支持协同共处，协同管理的应用程序。如： 内容管理系统，文件和数据加载器，本地缓存管理器 日志和检查点的备份、压缩、轮询、快照 数据变更观察器，日志和监控适配器，事件发布器 代理，网桥和适配器 控制器，管理器，配置器和更新器 通常，单个Pod不用于运行同一程序的多个实例。 替代考虑 为什么不在单个容器中运行多个程序？ 透明度 解耦软件依赖关系 使用方便 效率 Pod耐久性 Pod不应被视为耐用实体。它们不会在 调度失败，节点故障，驱逐，节点维护等情况下存活。 通常，用户不需要直接创建Pod。而应该(几乎总是)使用控制器。控制器提供了集群范围内的自修复(self-healing)，副本和上线管理。 Pod公开为一个原语以便于使用： 调度器和控制器可插拔 支持Pod级操作，而无需通过控制器API代理 将Pod寿命与控制器寿命分离 控制器和服务的分离 kubelet实际是Pod控制器 高可用应用程序 Pod终止 由于Pod表示集群中节点上正在运行的进程，因此允许这些进程在不需要时优雅地终止(gracefully terminate)非常重要。用户应该能够请求并指导进程何时终止，但也要确保删除最终完成。当用户请求删除Pod时，系统会在允许Pod强制终止之前记录预期的宽限期(grace period)，并将TERM信号(-15)发送到每个容器的主进程中。宽限期到期后，KILL信号(-9)发送到这些进程，然后从API server中删除该Pod。如果在等待进程","date":"2018-06-26","objectID":"/kubernetes/:12:1","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"Controller ReplicaSet 副本集是下一个副本控制器。现在副本集和副本控制器之间的唯一区别是selector的支持。副本集支持labels user guide中描述的新的基于集合selector的要求，而副本控制器仅支持基于等同selector的要求。 如何使用副本集 大多数支持副本控制器的kubectl命令也支持副本集。一个例外是rolling-update命令。如果你想要滚动更新功能，请考虑使用Deployments代替。 虽然副本集可独立使用，但它主要被Deployment用作协调Pod创建，删除和更新的机制。使用部署时，你不必担心管理它们创建的副本集，部署拥有并管理其副本集。 何时使用副本集 副本集确保在任何给定时间运行指定数量的Pod副本。但是，部署是一个更高级别的概念，它管理副本集并为Pod提供声明性更新以及许多其它有用的功能。因此，除非你需要自定义更新或无需更新，否则建议你使用部署而不是直接使用副本集。 这实际上意味着，你不需要操作副本集对象：改为使用部署，并在spec部分定义你的应用程序。 栗子 apiVersion:apps/v1kind:ReplicaSetmetadata:name:frontendlabels:app:guestbooktier:frontendspec:# modify replicas according to your casereplicas:3selector:matchLabels:tier:frontendmatchExpressions:- {key: tier, operator: In, values:[frontend]}template:metadata:labels:app:guestbooktier:frontendspec:containers:- name:php-redisimage:gcr.io/google_samples/gb-frontend:v3resources:requests:cpu:100mmemory:100Mienv:- name:GET_HOSTS_FROMvalue:dns# If your cluster config does not include a dns service, then to# instead access environment variables to find service host# info, comment out the 'value: dns' line above, and uncomment the# line below.# value: envports:- containerPort:80 kubectl create -f /etc/k8s/test/frontend.yaml 编写副本集spec 与所有其它k8s API对象一样，副本集需要apiVersion, kind, metadata字段，副本集还需要一个.spce部分。 #Pod Template .spec.template是.spec唯一必需的字段 除了pod的必须字段，副本集中的Pod模板还必须指定适当的`label`和`restart policy` #Pod Selector .spec.selector字段是一个label selector。副本集使用与selector匹配的label来管理所有pod。 它不区分创建或删除的Pod以及人或进程创建或删除的pod。这允许替换副本集而不会影响正在运行的Pod。 .spec.template.metadata.labels 必须匹配 .spec.selector，否则它将被API拒绝。 此外，你通常不应创建任何label与selector匹配的pod。如果你这样做了，副本集会认为它创建了其它pod，k8s并没有阻止你这样做。 #Labels on a ReplicaSet 副本集本身可以有标签(.metadata.labels)。通常，你可将其设置为与 .spec.template.metadata.labels 一致。但，允许他们不同，并且 .metadata.labels 不会影响副本集的行为 #Replicas 你可通过设置 .spec.replicas 来指定应同时运行的pod数量。如果未指定，默认为1 使用副本集 #删除副本集和它的pods kubectl delete replicaset/xxx #或 kubectl proxy --port=8080 curl -XDELETE 'localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/frontend \\ -d '{\"kind\":\"DeleteOptions\",\"apiVersion\":\"v1\",\"propagationPolicy\":\"Foreground\"}' \\ -H \"Content-Type: application/json\" #仅删除副本集 kubectl delete rs/xxx --cascade=false #或 kubectl proxy --port=8080 curl -X DELETE 'localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/frontend' \\ -d '{\"kind\":\"DeleteOptions\",\"apiVersion\":\"v1\",\"propagationPolicy\":\"Foreground\"}' \\ -H \"Content-Type: application/json\" #从副本隔离pods 可通过更改label从副本集的目标中删除Pod。此技术可用于从服务中删除pod以进行调试，数据恢复等。以这种方式删除的pod将自动替换 #伸缩副本集 只需更新副本集的 .spec.replicas 字段轻松伸缩副本集。副本集控制器确保具有匹配 label selector 所需数量的pod可用且可操作。 #作为水平pod自动伸缩目标的副本集 Horizontal Pod Autoscalers(HPA)，意味着副本集可通过HPA自动伸缩。 #栗子 apiVersion: autoscaling/v1 kind: HorizontalPodAutoscaler metadata: name: frontend-scaler spec: scaleTargetRef: kind: ReplicaSet name: frontend minReplicas: 3 maxReplicas: 10 targetCPUUtilizationPercentage: 50 kubectl create -f /path/xx/hpa.rs.yaml #此外，可使用kubectl命令来自动伸缩 #kubectl autoscale rs frontend 替代副本集 Deployment(推荐) Bare Pods Job DaemonSet \r\rReplicationController 注意：现在，配置副本集的推荐方法是使用部署。 副本控制器确保一次运行指定数量的Pod副本。换言之，副本控制器确保一个Pod或一组同类Pod总是可用。 \r\rDeployments 部署控制器为Pod和ReplicaSet提供了声明性更新。 在部署对象中描述所需的状态，部署控制器以受控速率将实际状态更改为所需状态。你可定义部署来创建新的副本集，或删除现有的部署并使用新的部署收纳所有资源。 你不应该直接管理部署所拥有的副本集，应该通过操作部署对象来涵盖所有用例。 栗子 以下是部署的典型案例： 创建部署来上线副本集 声明Pod的新状态 回滚到早期的部署版本 伸缩部署 暂定部署 使用部署的状态 清理旧的副本集 创建一个部署 下面的栗子，创建一个3个Nginx pods的副本集: apiVersion:apps/v1kind:Deploymentmetadata:name:nginx-deploymentlabels:app:nginxspec:replicas:3selector:matchLabels:app:nginxtemplate:metadata:labels:app:nginxspec:containers:- name:nginximage:nginx:1.7.9ports:- containerPort:80 kubectl create -f ./nginx-deployment.yaml kubectl get deployment kubectl get rs kubectl get pod --show-labels 更新部署 当且仅当部署的pod template发生更改时，才会触发部署更新上线。 假如我们要更新Nginx的版本为1.9.1: kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1 deployment.extensions/nginx-deployment image updated #或者 kubectl edit deployment/nginx-deployment deployment.extensions/nginx-deployment edited #查看上线状态 kubectl rollout s","date":"2018-06-26","objectID":"/kubernetes/:12:2","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"配置 Configuration \r","date":"2018-06-26","objectID":"/kubernetes/:13:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"配置最佳实践 Configuration Best Practices 一般配置技巧 General Configuration Tips 定义配置时，请指定最新的稳定的API版本 在推送到集群之前，配置文件应存储在版本控制系统中。这允许你在必要时快速回滚配置，有助于集群重建和恢复 使用YMAL而不是JSON来编写配置文件，YAML格式更用户友好 只要有意义，就将相关对象分组到一个文件中。管理一个文件比管理一堆文件更便捷 可以在目录上调用许多kubectl命令。例如，你可在配置文件目录上调用kubectl create 不要不必要地指定默认值 将对象描述写在注释中，以便更好进行内省 \r\rNaked Pod vs 副本集，部署和作业 “Naked” Pods vs ReplicaSets, Deployments, and Jobs 不要使用Naked Pods(即未绑定到副本集或部署的Pod) 如果节点发生故障，裸Pod将不会被重新调度。 \r\r服务 Service 在相应的后端工作负载(部署或副本集)访问它之前创建服务 当k8s启动容器时，它提供指向启动容器时正在运行的所有服务的环境变量。 除非绝对必要，否则不要为Pod指定hostPort 将Pod绑定到hostPort时，它会限制Pod可调度的位置数。因为每个hostIP, hostPort, protocol的组合必须是独特的。如果没有指定hostIp和protocol，k8s将使用0.0.0.0作为默认的hostIP，使用TCP作为默认协议。 如果你只需要访问端口以进行调试，可使用apiserver proxy或kubectl port-forward。 如果你需要公开节点上Pod的端口，考虑使用NodePort服务。 避免使用hostNetwork， 原因与hostPort类似 当不需要kube-proxy负载均衡时，使用 headless Services可轻松服务发现 \r\r使用标签 Using Labels 为你的应用程序或部署定义和使用标签 你可使用这些标签为其它资源筛选合适的Pod \r\r容器镜像 Container Images 默认的镜像拉取策略。对于容器是ifNotPresent，kubelet只有在本地镜像不存在时才拉取镜像。如果希望每次k8s启动容器时都拉取镜像，请指定imagePullPolicy: Always。 一个已弃用的替代方案。设置k8s总是拉取镜像的:latest标记，它会隐式地将imagePullPolicy设置为Always。 注意： 在生产环境中部署容器时，你应该避免使用:latest标记，因为这使得正在运行的镜像版本难以回滚。 如果镜像使用:latest标记，回滚的话其实需要回滚代码，然后打包上线，然后触发动态更新，之后就还原成了之前的版本。这样确实要复杂很缓慢一些。 确保容器使用使用相同版本的镜像 \r\r使用kubectl 使用kubectl apply -f \u003cdirectory\u003e 或 kubectl create -f \u003cdirectory\u003e 它在此目录中所有.yaml, .yml, .json文件汇总寻找k8s配置配置文件，并将其传递给kubectl。 使用label selectors进行get和delete操作，而不是特定的对象名称 使用kubectl run和kubectl expose快速创建单容器部署和服务 \r\r","date":"2018-06-26","objectID":"/kubernetes/:13:1","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"管理容器的计算资源 Managing Compute Resources for Containers 指定Pod时，可以选择指定每个容器需要多少CPU和MEM。当容器指定了请求(requests)的资源时，调度器可以更好地决定将Pod放在哪个节点上。当容器指定了限制(limit)时，可以以指定的方式处理节点上资源的争用。 \r\r资源类型 Resource types CPU和MEM都是资源类型。资源类型具有基本单元(unix)。CPU以核(cores)为指定单位，MEM以字节(Byte)为指定单位。 CPU和MEM统称为计算资源，或资源。计算资源是可以请求，分配和使用的可测量数据。它们与API资源不同。API资源(如Pod和Service)，是可通过k8s APIserver读取和修改的对象。 \r\r资源的请求和限制 Resource requests and limits of Pod and Container Pod中的容器都可指定一个或多个限制： spec.containers[].resources.limits.cpu spec.containers[].resources.limits.memory spec.containers[].resources.requests.cpu spec.containers[].resources.requests.memory 虽然只能在单独的容器上指定请求和限制，但是讨论Pod资源的请求和限制很方便。特定资源类型的Pod资源 请求/限制 是Pod中每个容器的该类型的资源 请求/限制 的总和。 \r\rCPU Meaning of CPU CPU资源的限制和请求以CPU单位进行测量。在k8s中，1 cpu等于： 1 AWS vCPU 1 GCP Core 1 Azure vCore 1 IBM vCPU 1 Hyperthread on a bare-metal Intel processor with Hyperthreading 允许分数请求。如spec.containers[].resources.requests.cpu: 0.5。表达式0.1相当于表达式100m。具有小数点的请求资源(如0.1)由API转换为100m，不允许精度小于1m。 始终要求CPU作为绝对数量，而不是相对数量。因此，0.1单元对于单核，双核，八核机器上的CPU资源时相同的。 \r\rMemory Meaning of memory 内存的限制和请求以字节为单位。 你可使用以下后缀来表示整数内存: E, P, T, G, M, K； 你还还可以使用2的幂等: Ei, Pi, Ti, Gi, Mi, Ki。 #相同值的不同表达 128974848 129e6 129M 123Mi 栗子： apiVersion: v1 kind: Pod metadata: name: frontend spec: containers: - name: db image: mysql env: - name: MYSQL_ROOT_PASSWORD value: \"password\" resources: requests: memory: \"64Mi\" cpu: \"250m\" limits: memory: \"128Mi\" cpu: \"500m\" - name: wp image: wordpress resources: requests: memory: \"64Mi\" cpu: \"250m\" limits: memory: \"128Mi\" cpu: \"500m\" \r\r如何调度具有资源请求的Pod How Pods with resource requests are scheduled 创建Pod时，k8s调度器会选择要运行Pod的节点。每个节点都具有每种资源类型的最大容量，它可为Pod提供CPU和MEM。调度程序确保对于每种资源类型，调度的容器的资源请求总和小于节点的容量。请注意，即使节点上的实际内存或CPU资源使用率非常低，但如果容量检查失败，调度器扔拒绝在节点上放置Pod。当资源使用随后增加时，这可以防止节点上的资源短缺。 \r\r如何运行具有资源限制的Pod How Pods with resource limits are run 当kubelet启动Pod中的容器时，它会将CPU和MEM限制传递给容器运行环境。 当使用Docker时： spec.container[].resources.requests.cpu被转换成core value，分数的话会乘以1024。此数字中的较大值用作docker run命令中--cpu-shares标志的值 spec.container[].resources.limits.cpu被转换为millicore value并乘以100。结果值代表容器每100ms可以使用的CPU时间总量。 在此间隔期间，容器不能使用超过其CPU时间的份额。 默认配额时间是100ms，CPU配额的最小解析为1ms。 spec.containers[].resources.limits.memory被转换为整数，并用作docker run命令中--memory标志的值 如果容器超出其内存限制(mem limit)，则容器可能会终止。如果它可以重启，则kubelet将重启它； 如果容器超出其内存请求(mem request)，当节点内存不足时，它的Pod可能会被驱逐； 容器可能会/可能不会被允许在较长时间内超过其CPU限制。但是，它不会因CPU使用率过高而被杀死。 \r\r监控计算资源使用 Monitoring compute resource usage Pod的资源使用情况将作为Pod Status的一部分进行上报。 \r\r本地短暂存储 Local ephemeral storage FEATURE STATE: Kubernetes v1.11 beta k8s v1.8介绍了一种新资源，用于管理本地短暂存储的短暂存储(ephemeral-storage)。在每个k8s 节点上，kubelet的根目录(默认/var/lib/kubelet)和日志目录(/var/log)存储在节点的根分区上。Pod还通过emptyDir volume，容器日志，镜像层，容器可写层共享和使用此分区。 此分区是短暂的，应用程序不能指望来自此分区的任何SLA(如磁盘IO)。本地临时存储仅适用于根分区，镜像层和可写层的可选分区超出了范围。 本地短暂存储的请求和限制设置 Requests and limits setting for local ephemeral storage Pod中的容器可指定一个或多个短暂存储： spec.containers[].resources.limits.ephemeral-storage spec.containers[].resources.requests.ephemeral-storage 短暂存储的限制和请求以字节(Byte)为单位。 你可以使用一下后缀表示整数存储: E, P, T, G, M, K； 你也可以使用2的幂等: Ei, Pi, Ti, Gi, Mi, Ki。 128974848 129e6 129M 123Mi 栗子： Pod由两个容器，每个容器都有2GiB的本地短暂存储请求，4GiB的本地短暂存储限制。因此，总共是4GiB请求，8GiB限制。 apiVersion: v1 kind: Pod metadata: name: frontend spec: containers: - name: db image: mysql env: - name: MYSQL_ROOT_PASSWORD value: \"password\" resources: requests: ephemeral-storage: \"2Gi\" limits: ephemeral-storage: \"4Gi\" - name: wp image: wordpress resources: requests: ephemeral-storage: \"2Gi\" limits: ephemeral-storage: \"4Gi\" 如何调度具有本地短暂存储的Pod How Pods with ephemeral-storage requests are scheduled 对于容器级的隔离，如果容器的可写层和日志使用量超过其存储限制，则Pod将被驱逐。对于Pod级别的隔离，如果所有容器的本地短暂存储使用量与Pod的emptyDir volume的总和超过了限制，则Pod将被驱逐。 \r\r扩展的资源 Extended resources 扩展资源是kubernetes.io域之外的完全限定资源名称。它们允许集群操作者通告和用户使用非k8s内置资源。 使用扩展资源需要两个步骤，首先，集群操作者必须通告扩展资源；其次，用户必须在Pod中请求扩展资源。 节点级扩展资源 节点级扩展资源与节点相关联。 集群级扩展资源 集群级扩展资源不依赖与节点。它们通常由调度器扩展程序管理——它处理资源消耗和资源配额。 使用扩展资源 用户可以在pod spec中项CPU和MEM一样使用扩展资源。调度程序负责资源核算，以便不会同时为Pod分配可用的数量。 API server将扩展资源的数量限制为整数。 要在Pod中使用扩展资源，在container spec中的spec.container[].resources.limits映射中包含资源名称作为键。 只有","date":"2018-06-26","objectID":"/kubernetes/:13:2","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"分配Pod到节点 Assigning Pods to Nodes 你可以将Pod约束为只能在特定节点上运行，或更喜欢在特定节点上运行。有几种方法做到这一点，它们都使用label selector来进行选择。通常这种约束是不必要的，因为调度程序将自动进行合理的放置。但在某些情况下，你可能希望对Pod放置的节点进行更多控制。如确保Pod放置在安装有SSD的计算机上… \r\r节点选择器 nodeSelector 节点选择器是最简单的约束形式。nodeSelector是PodSpecs的一个字段，它指定了一个键值对的映射。要使Pod有资格在节点上运行，该节点必须将每个指示的的键值对作为标签。最常见的用法是一个键值对。 Prerequisites k8s 集群 Attach label to the node #获取节点名 kubectl get node NAME STATUS ROLES AGE VERSION master Ready master 33d v1.11.1 node Ready \u003cnone\u003e 33d v1.11.1 salt01 Ready \u003cnone\u003e 27d v1.11.1 #打标签 kubectl label nodes \u003cnode-name\u003e \u003clabel-key\u003e=\u003clabel-value\u003e #查看标签 kubectl get node --show-labels Add a nodeSelector field to your pod configuration apiVersion: v1 kind: Pod metadata: name: nginx labels: env: test spec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent nodeSelector: \u003clabel-key\u003e: \u003clabel-value\u003e 当创建这个资源时，Pod将调度到附加此标签的节点上。 \r\r内置节点标签 built-in node labels 除了你附加的标签之外，节点还有一些预先填充的标准标签。 kubernetes.io/hostname failure-domain.beta.kubernetes.io/zone failure-domain.beta.kubernetes.io/region beta.kubernetes.io/instance-type beta.kubernetes.io/os beta.kubernetes.io/arch \r\r亲和力和反亲和力 Affinity and anti-affinity 节点选择器提供了一种非常简单的方法，使用特定标签约束Pod到特定节点。目前处于测试阶段的亲和力/反亲和力功能，极大地扩展了你可以表达的约束类型。关键的改进有： 语言更具表达性 你可以指示规则是soft/preference而不是硬性要求，因此如果调度程序不能满足，也仍然会调度Pod 你可以约束运行在节点上的其它Pod的标签，而不是对节点本身的标签进行约束 亲和力有两种类型： node-affinity inter-pod affinity/anti-affinity 节点亲和力 节点亲和力在概念上类似于nodeSelector，它允许你根据节点标签约束pod调度的节点。 目前有两种类型的节点亲和力： requiredDuringSchedulingIgnoredDuringExecution preferredDuringSchedulingIgnoredDuringExecution 你可将它们分别是为hard和soft，前者指定了将Pod调度到节点上必须满足的规则，后者指定调度程序将尝试执行但不保证的首选项。名称的IgnoredDuringExecution部分意味着，与节点选择器的工作方式类似，如果节点标签在运行时更改，而不再满足Pod的亲和力规则，则Pod将继续在节点上运行。 未来，我们计划提供requiredDuringSchedulingRequiredDuringExecution，就像Ignored一样，它将从不再满足Pod的亲和力要求的节点中驱逐Pod。 节点亲和力在spec.affinity.nodeAffinity字段中指定： apiVersion: v1 kind: Pod metadata: name: with-node-affinity spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/e2e-az-name operator: In values: - e2e-az1 - e2e-az2 preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 preference: matchExpressions: - key: another-node-label-key operator: In values: - another-node-label-value containers: - name: with-node-affinity image: k8s.gcr.io/pause:2.0 此节点亲和力规则表示，Pod只能防止在kubernetes.io/e2e-az-name标签键，值为e2e-az1或e2e-az2的节点上。此外，在满足条件的节点中，应优先选择具有another-node-label-key键，值为another-node-label-value的节点。 节点亲和力语法支持如下操作符: In, NotIn, Exists, DoesNotExist, Gt, Lt。 如果你同时指定了nodeSelector和nodeAffinity，则必须满足两者以将Pod调度到候选节点上； 如果你指定了与nodeAffinity类型关联的多个nodeSelectorTerms。那么，如果满足其中一个nodeSelectorTerms，则可以将Pod调度到节点上； 如果你指定了与nodeSelectorTerms关联的多个matchExpressions。那么，只有满足所有matchExpressions的情况下，才能将Pod安排到节点上； 如果删除或更改调度Pod的节点标签，则Pod不会被删除。换句话说，亲和力仅在调度Pod时起作用。 Pod间亲和力和反亲和力 Pod间亲和力和反亲和力，你可以根据已在节点上运行的Pod上的标签(而不是节点标签)，来约束Pod可以调度的节点。与节点不同，Pod有命名空间，Pod标签的标签选择器必须指定选择器应该应用于哪些命名空间。 注意： Pod间亲和力和反亲和力需要大量的处理，可会显著减慢大型集群中的调度。因此，不建议在大于几百个节点的集群中使用； 注意： Pod反亲和力要求节点一致地标签节点，即集群中的每个节点都必须具有匹配的topologyKey标签，如果某些节点缺少，可能会导致意外情况。 目前有两种类型的Pod亲和力和反亲和力: requiredDuringSchedulingIgnoredDuringExecution preferredDuringSchedulingIgnoredDuringExecution 同样表示hard和soft要求。 apiVersion: v1 kind: Pod metadata: name: with-pod-affinity spec: affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: security operator: In values: - S1 topologyKey: failure-domain.beta.kubernetes.io/zone podAntiAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 100 podAffinityTerm: labelSelector: matchExpressions: - key: security operator: In values: - S2 topologyKey: kubernetes.io/hostname containers: - name: with-pod-affinity image: k8s.gcr.io/pause:2.0 Pod亲和力和反亲和力的有效操作符有: In, NotIn, Exists, DoesNotExist 原则上，topologyKey可以是任一合法的label-key。但是，出于性能和安全的原因，它也有一些限制： 对于亲和力和requiredDuringSchedulingIgnoredDuringExecution的Pod的反亲和力，不允许使用空的topologykey 对于requiredDuringSchedulingIgnoredDuringExecution的Pod的反亲和力，引入控制器LimitPodHardAntiAffinityTopo","date":"2018-06-26","objectID":"/kubernetes/:13:3","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"污点和容忍 Taints and Tolerations 节点亲和力是Pod的属性，它将它们吸引到节点；Taints则相反——它允许节点排斥Pod。 Taints 和 Tolerations 一起工作以确保Pod不被安排的不适当的节点上。将一个或多个污点(taints)应用于节点，这标志着节点不应该接受任何不能容忍污点的Pod。容忍(tolerations)应用于Pod，并允许Pod安排到具有匹配污点的节点上。 \r概念 使用kubectl taint命令对节点添加污染: #除非具有匹配的容忍，否则不会将Pod调度到此节点上 kubectl taint nodes \u003cnode-name\u003e key=value:NoSchedule #删除 kubectl taint nodes \u003cnode-name\u003e key:NoSchedule- 你可以在PodSpec的指定Pod的容忍度： tolerations: - key: \"key\" operator: \"Equal\" #default value: \"value\" effect: \"NoSchedule\" tolerations: - key: \"key\" operator: \"Exists\" effect: \"NoSchedule\" effect的三个选项： NoSchedule PreferNoSchedule: soft of NoSchedule NoExecute 你可在同一个节点上放置多个污点，并在同一个Pod上放置多个容忍。k8s处理多个污点和容忍的方式就像一个过滤器：从节点的所有污点开始，忽略Pod匹配的容忍度的那些，剩下的未被忽略的污点对Pod有明显的影响。尤其是： 如果至少有一个未被忽略的effect为NoSchedule的污点，则k8s将不会调度Pod到该节点 如果没有effect为NoSchedule，但至少有一个未被忽略的effect为PreferNoSchedule的污点，则k8s将尝试不将Pod调度到该节点 如果至少有一个未被忽略的effect为NoExecute的污点，则Pod将从节点驱逐(如果它已经在节点上运行)，并且不会被调度到该节点上 栗子： kubectl taint nodes node1 key1=value1:NoSchedule kubectl taint nodes node1 key1=value1:NoExecute kubectl taint nodes node1 key2=value2:NoSchedule 有两个容忍度的Pod： tolerations:- key:\"key1\"operator:\"Equal\"value:\"value1\"effect:\"NoSchedule\"- key:\"key1\"operator:\"Equal\"value:\"value1\"effect:\"NoExecute\" 对于NoExecute的容忍度可以指定一个可选tolerationSeconds字段，它指示在添加污点后Pod将保持绑定到节点的时间： tolerations:- key:\"key1\"operator:\"Equal\"value:\"value1\"effect:\"NoExecute\"tolerationSeconds:3600 \r\r使用案例 Example Use Cases 污点和容忍是一种灵活的方式来引导Pod远离节点或驱逐不应该运行的Pod。一些栗子： 专用节点(Dedicated Nodes) 特殊硬件的节点(Nodes with Special Hardware) 基于污点的驱逐(Taint based Evictions) \r\rTaint based Evictions 内置的污点： node.kubernetes.io/not-ready node.kubernetes.io/unreachable node.kubernetes.io/out-of-disk node.kubernetes.io/memory-pressure node.kubernetes.io/disk-pressure node.kubernetes.io/network-unavailable node.kubernetes.io/unschedulable node.cloudprovider.kubernetes.io/uninitialized 使用NoExecute容忍的DaemonSet Pod为以下污点创建，没有tolerationSeconds： node.alpha.kubernetes.io/unreachable node.kubernetes.io/not-ready 这可确保DaemonSet Pod永远不会因为这个问题而被驱逐，这与禁用此功能时的行为相匹配。 \r\r按条件污染节点 Taint Nodes by Condition 节点控制器创建对应于节点条件的污点。当启用此功能，调度程序不检查节点条件，调度程序检查污点。这可确保节点条件不会影响节点上的调度。用户可以通过添加适当的Pod容忍来选择忽略节点的一些问题。 DaemonSet controller自动将一下NoSchedule的容忍度添加到所有的守护进程，以防止守护进程破坏： node.kubernetes.io/memory-pressure node.kubernetes.io/disk-pressure node.kubernetes.io/out-of-disk (only for critical pods) node.kubernetes.io/unschedulable (1.10 or later) node.kubernetes.io/network-unavailable (host network only) 添加这些容忍度可确保向后兼容，你还可以向DaemonSet添加任意容忍度。 \r\r","date":"2018-06-26","objectID":"/kubernetes/:13:4","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"Secrets Secrets类型的对象旨在保存敏感信息，如密码、OAuth token、ssh keys。把这些敏感信息放在Secrets中比将其放在Pod中或image中更安全、更灵活。 \r概述 用户和系统都可以创建一些秘密(Secrets)。 要使用秘密，Pod需要引用该秘密。秘密可以通过两种方式与Pod一起使用： 作为挂载到容器中的卷中的文件 为Pod拉取镜像时由kubelet使用的文件 内建的秘密 Built-in Secrets Service Accounts Automatically Create and Attach Secrets with API Credentials k8s会自动创建包含用于访问API的证书的秘密，并自动修改Pod以使用此类秘密。你可禁用它，但不推荐。 创建自己的秘密 Creating your own Secrets 使用kubectl创建秘密(Creating a Secret Using kubectl create secret) 假设一些Pod需要访问数据库： $ echo -n 'admin' \u003e ./username.txt $ echo -n '1f2d1e2e67df' \u003e ./password.txt #创建秘密 $ kubectl create secret generic db-user-pass --from-file=./username.txt --from-file=./password.txt secret/db-user-pass created #查看 #默认都不会显示文件内容，为了安全 kubectl get secrets kubectl describe secrets/db-user-pass Name: db-user-pass Namespace: default Labels: \u003cnone\u003e Annotations: \u003cnone\u003e Type: Opaque Data ==== password.txt: 12 bytes username.txt: 5 bytes 手动创建秘密(Creating a Secret Manually) 每项必须是base64编码： $ echo -n 'admin' | base64 YWRtaW4= $ echo -n '1f2d1e2e67df' | base64 MWYyZDFlMmU2N2Rm #现在编写一个秘密对象文件 #db-user-pass.yaml apiVersion: v1 kind: Secret metadata: name: mysecret type: Opaque data: username: YWRtaW4= password: MWYyZDFlMmU2N2Rm #创建它 $ kubectl create -f ./secret.yaml secret \"mysecret\" created 解码秘密(Decoding a Secret) kubectl get secret mysecret -o yaml apiVersion: v1 data: username: YWRtaW4= password: MWYyZDFlMmU2N2Rm kind: Secret metadata: creationTimestamp: 2016-01-22T18:41:56Z name: mysecret namespace: default resourceVersion: \"164619\" selfLink: /api/v1/namespaces/default/secrets/mysecret uid: cfee02d6-c137-11e5-8d73-42010af00002 type: Opaque #解码 $ echo 'MWYyZDFlMmU2N2Rm' | base64 --decode 1f2d1e2e67df \r使用秘密 Using Secrets 秘密可以作为数据卷来挂载，也可作为环境变量公开，以供Pod中的容器使用。它们也可以由系统的其它部分使用，而不是直接暴露在Pod中。 将秘密用作Pod中的文件(Using Secrets as Files from a Pod) 在Pod中的卷中使用秘密： 创建或使用已有的秘密。多个Pod可以引用相同的秘密 修改Pod定义以添加卷和挂载卷 修改镜像或命令行，以便程序在该挂载目录中查找文件 栗子： apiVersion:v1kind:Podmetadata:name:mypodspec:containers:- name:mypodimage:redisvolumeMounts:- name:foomountPath:\"/etc/foo\"readOnly:truevolumes:- name:foosecret:secretName:mysecret 向指定路径投射密钥(Projection of secret keys to specific paths) 栗子： apiVersion:v1kind:Podmetadata:name:mypodspec:containers:- name:mypodimage:redisvolumeMounts:- name:foomountPath:\"/etc/foo\"readOnly:truevolumes:- name:foosecret:secretName:mysecretitems:- key:usernamepath:my-group/my-username#username秘密存储在/etc/foo/my-group/my-username而不是/etc/foo/username#password秘密没有投射 **秘密文件权限(Secret files permissions) 你还可以指定秘密所具有的的权限: apiVersion:v1kind:Podmetadata:name:mypodspec:containers:- name:mypodimage:redisvolumeMounts:- name:foomountPath:\"/etc/foo\"volumes:- name:foosecret:secretName:mysecretdefaultMode:256#0400(八进制) apiVersion:v1kind:Podmetadata:name:mypodspec:containers:- name:mypodimage:redisvolumeMounts:- name:foomountPath:\"/etc/foo\"volumes:- name:foosecret:secretName:mysecretitems:- key:usernamepath:my-group/my-usernamemode:511#0777 从卷中使用秘密值(Consuming Secret Values from Volumes) 在挂载秘密卷的容器内，密钥显示为文件，秘密值基于base64进行解码并存储在这些文件中。 $ ls /etc/foo/ username password $ cat /etc/foo/username admin $ cat /etc/foo/password 1f2d1e2e67df 挂载的秘密会自动更新(Mounted Secrets are updated automatically) 当更新卷中已经使用的秘密时，最终也会更新投射的密钥。 使用秘密作为环境变量(Using Secrets as Environment Variables) 要在Pod中的环境变量中使用秘密： 创建或使用已有的秘密。多个Pod可引用同一个秘密 修改Pod定义 修改Image或命令行，以便程序在指定的环境变量中查找值 栗子： apiVersion:v1kind:Podmetadata:name:secret-env-podspec:containers:- name:mycontainerimage:redisenv:- name:SECRET_USERNAMEvalueFrom:secretKeyRef:name:mysecretkey:username- name:SECRET_PASSWORDvalueFrom:secretKeyRef:name:mysecretkey:passwordrestartPolicy:Never 从环境变量中使用秘密值 Consuming Secret Values from Environment Variables 容器内使用的环境变量的秘密值，它显示为base64的解码值。 $ echo $SECRET_USERNAME admin $ echo $SECRET_PASSWORD 1f2d1e2e67df Using imagePullSecrets imagePullSecret是一种包含docker image registry password的秘密传递给kubelet的方法，因此它可以用于Pod拉取你的私有镜像。 \r\r细节 限制 Restrictions 验证密钥卷源以确保指定的对象引用实际指向的秘密类型对象。因此，需要在任何Pod依赖它之前先创建秘密。 Secret API对象驻留在命名空间中，它们只能由同一命名空间中的Pod引用。 单个秘密的大小被限制为1MB。这是为了阻止创建非常大的秘密，这会耗尽apiserver和kubelet的","date":"2018-06-26","objectID":"/kubernetes/:13:5","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"使用kubeconfig文件组织集群访问 Organizing Cluster Access Using kubeconfig Files 使用kubeconfig文件来组织有关集群、用户、命名空间、身份验证机制的信息。kubectl使用kubeconfig文件来查找选择集群并与集群apiserver通信所需的信息。 用于配置对集群的访问的文件称为kubeconfig。这是引用配置文件的普通方法，这并不意味着有一个名为kubeconfig的文件。 默认情况下，kubectl从$HOME/.kube目录下查找名为config的文件。你可以通过--kubeconfig标志设置KUBECONFIG环境变量来指定kubeconfig文件。 \r支持多集群、用户、认证机制 Supporting multiple clusters, users, and authentication mechanisms 假设你有多个集群，并且用户和组件以各种方式进行认证： 正在运行的kubelet可能使用证书进行认证 用户可能使用令牌认证 管理员可能拥有他为用户提供的证书集 使用kubeconfig，你可以组织集群、用户和命名空间。你还可以定义上下文，以便在集群和命名空间之间快速进行切换。 \r\r上下文 kubeconfig文件中的上下文元素用于在方便的名称下对访问参数进行分组。每个上下文都有三个参数：集群、命名空间、用户。默认情况下，kubectl使用从当前上下文的参数与集群通信。 #Modify kubeconfig files kubectl config -h \r\rKUBECONFIG环境变量 $KUBECONFIG环境变量包含kubeconfig文件列表，它不是必须的。如果不存在，则kubectl使用默认的$HOME/.kube/config；如果存在，则kubectl使用有效配置。在Linux/Mac上使用冒号分隔，Windows使用分号分隔。 echo $KUBECONFIG /etc/kubernetes/admin.conf \r\r合并kubeconfig文件 Merging kubeconfig files #查看配置 kubectl config view 如果设置了--kubeconfig标志，则仅使用指定的文件。不合并，只允许此标志的一个实例。 否则，如果设置了$KUBECONFIG环境变量，将其应用于合并的文件列表。遵循以下规则： 忽略空文件名 对包含无法反序列化内容的文件生成错误 设置成特定值或映射见的第一个文件获胜 切勿修改值或映射键 否则，使用默认的$HOME/.kube/config文件，不做合并 \r\r","date":"2018-06-26","objectID":"/kubernetes/:13:6","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"Pod优先级和抢占 Pod Priority and Preemption FEATURE STATE: Kubernetes 1.8 alpha FEATURE STATE: Kubernetes 1.11 beta Pod也有优先级，优先级表示Pod相对于其它Pod的重要性。如果无法调度Pod，则调度程序会尝试抢占(驱逐)较低优先级的Pod，以便可以处理待调度(Pending)的Pod。 优先级还会影响Pod的调度顺序和节点上的资源驱逐顺序。 \r使用优先级和抢占 How to use priority and preemption 要在k8s v1.11+使用优先级和抢占，遵循以下步骤： 添加一个或多个优先级类(PriorityClassed) 创建带有priorityClassName的Pod设置为添加的优先级类之一。当然，你不需要直接创建Pod，通常你只需要将priorityClassName添加到对象的Pod模板(如deployment) \r\r禁用抢占 How to disable preemption 禁用Pod优先级和抢占 要禁用Pod优先级，请为apiserver、调度程序、kubelet将该功能设置false——--feature-gates=PodPriority=false 仅禁用抢占 在k8s v1.11+，抢占由kube-scheduler的disablePreemption标志控制，默认设置为fasle。 apiVersion: componentconfig/v1alpha1 kind: KubeSchedulerConfiguration algorithmSource: provider: DefaultProvider ... disablePreemption: true \r\rPriorityClass 优先级类(priorityClass)是一个非命名空间的对象，它定义从优先级类名到优先级的整数值的映射。该名称在PriorityClass对象的metadata的name字段中指定，必须的值在value字段中定义。值越高，优先级越高。 优先级类对象可以具有小于等于10亿的任何32位整数值。较大的数字保留给通常不会被抢占或驱逐的系统Pod。集群管理员应为他们想要的每个这样的映射创建一个优先级类对象。 优先级类有两个可选字段： globalDefault： 表示该优先级类的值应该用于没有priorityClassName的Pod，系统中只能有一个globalDefault为true的Pod。如果没有设置为globalDefault的优先级类，则Pod的优先级为零。 description： 旨在告诉用户何时应该使用此优先级类 有关PodPriority和现有集群的说明： 如果升级现有集群并启用此功能，则现有的Pod的优先级实际上为零 将globalDefault设置为true的优先级类添加将不会更改现有Pod的优先级。它的值仅用于添加优先级类之后创建的Pod 如果删除优先级类，则使用已删除的优先级类名称的现有Pod保持不变，但无法创建使用已删除的优先级类名称的Pod 栗子： apiVersion: scheduling.k8s.io/v1beta1 kind: PriorityClass metadata: name: high-priority value: 1000000 globalDefault: false description: \"This priority class should be used for XYZ service pods only.\" \r\rPod priority 当有一个或多个优先级类之后，你就可以创建在spec中指定priority class name的Pod。优先级许可控制器使用priorityClassName字段并填充优先级的整数值。如果为找到优先级，则决绝Pod。 栗子： apiVersion: v1 kind: Pod metadata: name: nginx labels: env: test spec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent priorityClassName: high-priority Pod优先级对调度顺序的影响 启用Pod优先级后，调度程序按其优先级对挂起的Pod进行排序，并将挂起的Pod置于调度队列中优先级较低的其它挂起Pod之前。因此，如果满足调度要求，则优先级较低的Pod可以更快地安排具有较低优先级的Pod。如果无法调度此类Pod，则调度程序将继续并尝试安排其它较低优先级的Pod。 \r\rPreemption 创建Pod时，它们会进入队列并等待调度。调度程序从队列中选择一个Pod并尝试在节点上调度它。如果未找到满足Pod的所有指定要求的节点，则会为挂起的Pod触发抢占逻辑。抢占逻辑试图找到一个节点，其中删除优先级低于Pod P的一个或多个Pod，使得能够在该节点上调度Pod P。如果找到了此节点，则会删除那些Pod，在他们消失后，可在节点上调度Pod P。 用户公开的信息 User exposed information 当Pod P在节点上抢占一个或多个Pod时，Pod P的状态的nominatedNodeName字段被设置为节点的名称。该字段帮助调度器追踪为Pod P保留的资源，并且还向用户提供关于其集群中的抢占信息。 请注意，Pod P不一定安排到nominated node。在受害Pod被抢占后，它们将获得优雅的终止期。如果在调度程序等待受害Pod终止时另一个节点可用，则调度程序将使用另一个节点来调度Pod P。因此，Pod spec中的nominatedNodeName和nodeName并不总是相同。此外，如果调度程序在节点上抢占Pod，然后有比Pod P更高优先级的Pod到达，则调度程序可以将节点提供给新的更高优先级的Pod。 抢占的局限性 Limitations of preemption Graceful termination of preemption victims PodDisruptionBudget is supported, but not guaranteed! Inter-Pod affinity on lower-priority Pods Cross node preemption \r调试Pod优先级和抢占 优先级和抢占可能会引起潜在的问题： Pods are preempted unnecessarily Pods are preempted, but the preemptor is not scheduled Higher priority Pods are preempted before lower priority pods \r\rPod优先级和QoS的交互 Interactions of Pod priority and QoS 调度程序的抢占逻辑在选择抢占目标是会考虑QoS。 考虑QoS和Pod优先级的唯一组件kubelet out of resource驱逐。kubelet首先根据他们对饥饿资源的使用是否超过请求，然后按优先级，通过相对于Pod的调度请求消耗的计算资源来排除Pod的驱逐。kubelet资源溢出驱逐不会驱逐资源使用不超过其请求的Pod。如果 优先级较低的未超过其请求，则不会被驱逐。另一个优先级高高于其请求的Pod可能被驱逐。 \r\r\r","date":"2018-06-26","objectID":"/kubernetes/:13:7","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"服务，负载均衡和网络 Services, Load Balancing, and Networking \r","date":"2018-06-26","objectID":"/kubernetes/:14:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"Services k8s Pod是会死的，从出生到死亡，它们没有复活(resurrected)。副本集特别地动态创建和销毁Pod。虽然每个Pod都有自己的IP，但即使是那些IP也不能依赖它们随时间变得稳定。这导致一个问题，如果某些Pod为k8s集群内的其它Pod提供功能，那么它们如何找出并追踪它们呢？ 这就需要用到服务了。 k8s 服务是一个抽象，它定义了一组逻辑Pod和一个访问它们的策略，有时称为微服务(micro-service)。服务目标的Pod由Label Selector来确定。 对于原生k8s应用程序，k8s提供了提供了一个简单的Endpoints API，只要服务中的Pod集发生变化，它就会更新。对于非原生k8s应用程序，k8s提供了一个基于虚拟IP的服务桥接器，可以重定向到后端的Pod。 \r定义服务 Defining a service k8s中的服务是一个REST对象，类似于Pod。与所有REST对象一样，可以将服务定义POST到apiserver以创建实例。 例如： kind: Service apiVersion: v1 metadata: name: my-service spec: selector: app: MyApp ports: - protocol: TCP port: 80 targetPort: 9376 此规范会创建一个名为my-service的服务对象，该对象使用app=MyApp的标签定位任何Pod上的TCP协议9376端口。服务还将分配一个IP地址(称为cluster IP)，由服务代理(service proxy)使用。将连续评估服务的selector，并将结果POST到名为my-service的Endpoints对象。 请注意，服务可以将传入端口映射到任何targetPort。默认情况下，targetPort将设置为与port字段相同的值。也许更有趣的是targetPort可以是一个字符串，指的是后端Pod中端口的名称。分配给该名称的实际端口号在每个后端Pod中可以不同。这为部署和发展你的服务提供了很大的灵活性。例如，你可以更改Pod的后端软件中公开的端口号，而不会破坏客户端。 k8s 服务支持TCP和UDP协议，默认是TCP。 Services without selectors 服务通常抽象访问k8s Pods，但它们也可以抽象访问其它类型的后端。例如： 你希望在生产环境中拥有外部数据库集群，但在测试环境中你使用自己的数据库 你希望将服务指向另外的命名空间或集群 你正在将工作负载迁移到k8s，并且你的一些后端运行在k8s之外 在任何方案中，你都可以定义不带选择器(selector)的服务： kind:ServiceapiVersion:v1metadata:name:my-servicespec:ports:- protocol:TCPport:80targetPort:9376 由于此服务没有选择器(selector)，因此不会创建相应的Endpoints对象。你可以手动将服务映射到你自己的特定端点： kind: Endpoints apiVersion: v1 metadata: name: my-service subsets: - addresses: - ip: 1.2.3.4 ports: - port: 9376 在没有选择器的情况下访问服务的工作方式与使用选择器的方式相同。流量都会被路由到定义的端点。 ExternalName service是一种特殊的服务案例，它没有选择器并且使用DNS名称代替。 \r\r虚拟IP和服务代理 Virtual IPs and service proxies 在k8s v1.0中，服务是四层构造(tcp/udp)，代理纯粹实在用户空间中。在k8s v1.1中，添加了Ingress API来表示七层服务(HTTP)，也添加了iptables proxy。并成为k8s v1.2的默认操作模式。在k8s v1.8.0中，添加了ipvs proxy。 k8s 集群中的每个节点都运行一个kube-proxy——它负责为ExternalName以外类型的服务实现一种形式的虚拟IP。 在任何这些代理模式中，绑定到服务的ip:port的任何流量都将代理到适当的后端，而客户端不知道有关k8s或服务或Pod的任何信息。 Proxy-mode: userspace 在userspace模式下，kube-proxy会监视k8s master以添加和删除Service和Endpoints对象。对于每个服务，它在本地节点上打开一个端口(随机选择)。与此proxy port的任何连接都将代理到服务后端的Pod之一，并根据服务的SessionAffinity决定使用哪个后端Pod。最后，它将安装iptables规则，捕获流量到服务的cluster IP(虚拟IP)，并将流量重定向到代理后端Pod的代理端口。默认情况下，后端的选择是轮询(round robin)。 Proxy-mode: iptables 在iptables模式下，kube-proxy会监视k8s master以添加和删除Service和Endpoint对象。对于每个服务，它将安装iptables规则，捕获流量到服务的cluster IP和端口，并将流量重定向到服务的后端集之一。对于每个Endpoint对象，它会按照选择后端Pod的iptables规则。默认情况下，后端的选择是随机的。 显然，iptables不需要再用户空间(userspace)和内核空间(kernelspace)之间切换，它应该比用户空间代理更快更可靠。然而，与用户空间代理不同，如果最初选择的Pod没有响应，则iptables代理无法自动重试另一个Pod，因此它依赖于readiness probes的工作。 Proxy-mode： ipvs FEATURE STATE: Kubernetes v1.9 beta 在ipvs模式下，kube-proxy监视k8s的Service和Endpoints，调用netlink接口以相应地创建ipvs规则，并定期与k8s的Service和Endpoint同步ipvs规则，以确保ipvs转台与期望一致。访问服务时，流量将被重定向到其中一个后端Pod。 与iptables类似，ipvs基于netfilter hook函数，但是用hash table作为底层数据结构，并在内核空间中工作。这意味着ipvs可以更快地重定向流量，并且再同步代理规则时具有更好的性能。此外，ipvs为负载均衡算法提供了更多选项： rr： round-robin lc： least connection dh： destination hashing sh： source hashing sed： shortest expected delay nq： never queue **注意：**ipvs模式假设在运行kube-proxy之前便已在节点上安装了IPVS内核模块。当kube-proxy以ipvs代理模式启动时，kube-proxy将验证节点上是否安装了IPVS模块，如果未安装，则kube-proxy将回退到iptables代理模式。 \r\r多端口服务 Multi-Port Services 许多服务可能需要公开多个端口。对于此情况，k8s支持服务对象上的多个端口定义。当使用多个端口时，必须提供所有端口名称，以便消除端点(Endpoint)的歧义。 请注意，端口名称只能包含小写字母数字和横杠-，并须以字母数字结尾。 kind: Service apiVersion: v1 metadata: name: my-service spec: selector: app: MyApp ports: - name: http protocol: TCP port: 80 targetPort: 9376 - name: https protocol: TCP port: 443 targetPort: 9377 \r\r选择自己的IP Choosing your own IP address 你可以将自己的cluster ip指定为服务创建请求的一部分。为此，请设置.spec.clusterIP字段。用户选择的IP地址必须是有效的IP地址，并且在apiserver的标志指定的service-cluster-ip-range CIDR范围内。如果IP地址无效，则apiserver返回422 HTTP statuscode以指示该值无效。 为什么不适用DNS轮询？ Why not use round-robin DNS? 为什么我们使用虚拟IP来完成所有这些工作，而不仅仅是标准的DNS轮询。原因如下： DNS libraries的历史悠久，不尊重DNS TTL并缓存名称的查找结果 许多应用程序执行一次DNS查找并缓存结果 即使应用程序和库进行了适当的重新解析，每个客户算反复重新解析DNS的负载也是难以管理的 我们试图阻止用户做出伤害自己的事情。也就是说，如果有足够的人要求这样做，我们可以将其作为替代方案来实施。 \r\r服务发现 Discovering services k8s支持两种寻找服务的主要模式： enviroment variables和DNS。 Environment variables 当Pod在节点上运行时，kubelet为每个活跃的服务添加一组环境变量。它支持Docker links compatible变量和更简单的{SVCNAME}_SE","date":"2018-06-26","objectID":"/kubernetes/:14:1","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"DNS DNS for Services and Pods \r介绍 k8s DNS在集群上调度DNS Pod和Service，并配置kubelet以告知各个容器使用DNS Service’s IP 来解析DNS名称。 集群中定义的每个服务(包括DNS服务自身)，都会分配一个DNS名称。默认情况下，客户端Pod的DNS搜索列表将包含Pod自己的命名空间和集群的默认域。 栗子： 假设在k8s的bar命名空间中有一个foo服务，运行在bar命名空间中的Pod可通过简单地为foo执行DNS查询来查找此服务。运行在quux命名空间中的Pod可通过foo.bar执行DNS查询来查找此服务。 \r\rServices A records 正常的服务(非headless)都分配了一个名为my-svc.my-namespace.svc.cluster.local形式的DNS A记录，这将解析为服务的cluster ip。 Headless服务同样分配了一个名为my-svc.my-namespace.svc.cluster.local形式的DNS A记录。与服务不同，这将解析为服务选择的Pod的IP。 SRV records 为命名端口创建SRV记录，这些端口是普通服务或headless服务的一部分。 对于每个命名端口，SRV记录的格式为_my-port-name._my-port-protocol.my-svc.my-namespace.svc.cluster.local； 对于常规的服务，这将解析为端口号和域名：my-svc.my-namespace.svc.cluster.local； 对于headless服务，这将解析为多个答案。一个用于支持服务的每个Pod，并且包含Pod形式的端口号和域名:auto-generated-name.my-svc.my-namespace.svc.cluster.local。 \r\rPods A records 启用后，将以pod-ip-address.my-namespace.pod.cluster.local的形式为Pod分配DNS A记录。如10-0-1-11.default.pod.cluster.local。 Pod’s hostname and subdomain fields 目前，当创建Pod时，其主机名时Pod的metadata.name值。Pod spec有一个可选的hostname字段，可用于指定Pod的主机名。指定后，它优先于Pod的名称作为Pod的主机名。 Pod spec同样有一个可选的subdomain字段，可用于指定其子域。 栗子： apiVersion:v1kind:Servicemetadata:name:default-subdomainspec:selector:name:busyboxclusterIP:Noneports:- name:fooport:1234targetPort:1234---apiVersion:v1kind:Podmetadata:nam:busybox1labels:name:busyboxspec:hostname:busybox-1subdomain:default-subdomaincontainers:- image:busyboxcommand:- sleep- '3600'name:busybox---apiVersion:v1kind:Podmetadata:name:busybox2labels:name:busyboxspec:hostname:busybox-2subdomain:default-subdomaincontainers:- image:busyboxcommand:- sleep- \"3600\"name:busybox Pod’s DNS Policy 可以基于每个Pod设置DNS策略。目前，k8s支持以下特定于Pod的DNS策略。这些策略在Pod spec中的dnsPolicy字段中指定。 Default Pod从Pod的节点继承名称解析配置。 ClusterFirst 任何与配置的集群域后缀名称不匹配的DNS查询，都会转发到从该节点继承的上游名称服务器。集群管理员可能配置了额外的存根域和上游DNS server。 注意Default不是默认的DNS策略，如果未指定DNS策略，则使用ClusterFirst。 ClusterFirstWithHostNet 对于使用hostNetwork运行的Pod，你应该明确设置其DNS策略为ClusterFirstWithHostNet。 None k8s v1.9+中引入的新功能。它允许Pod忽略k8s环境中的DNS设置。应该使用DNS spec中的dnsConfig字段提供所有的DNS设置。 Pod’s DNS Config 要启用此功能，集群管理员需要在apiserver和kubelet上启用--feature-gates=CustomPodDNS=true,...。之后，用户便可以将Pod的dnsPolicy字段设置为None，并可以将新字段dnsConfig添加到Pod spec中。 dnsConfig字段是可选的，它可与任何dnsPolicy设置一起使用。但是，当Pod的dnsPolicy字段设置为None时，必须指定dnsConfig字段。 用户可在dnsConfig字段中指定的属性： nameservers 用作Pod的DNS服务器的IP地址列表，最多可以指定3个IP地址。当dnsPolicy设置为None时，必须至少包含一个IP地址，否则此属性是可选的。 searches Pod中主机名查找的DNS搜索域列表，此属性是可选的。k8s最多允许6个搜索域。 options 一个可选的对象属性，其中每个对象有name(必须): value(可选)。 栗子： apiVersion:v1kind:Podmetadata:namespace:defaultname:dns-examplespec:containers:- name:testimage:nginxdnsPolicy:\"None\"dnsConfig:nameservers:- 1.2.3.4searches:- ns1.svc.cluster.local- my.dns.search.suffixoptions:- name:ndotsvalue:\"2\"- name:edns0 查看: kubectl exec -it -- cat /etc/resolv.conf nameserver 1.2.3.4 search ns1.svc.cluster.local my.dns.search.suffix options ndots:2 edns0 \r\r","date":"2018-06-26","objectID":"/kubernetes/:14:2","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"连接应用与服务 Connecting Applications with Services 现在你拥有了一个连续运行的副本应用程序，你可以在网络上公开它。在讨论k8s网络方法之前，值得将它与Docker的方式进行对比。 默认情况下，Docker使用host-private网络，因此只有当容器位于同一台主机上时，容器才能与其它容器进行通信。为了使Docker容器能够跨节点通信，必须在主机的IP地址上分配端口，然后将这些端口转发或代理到容器。这意味着容器要小心协调它们使用的端口。 k8s假设Pod可与其它Pod通信，无论它们着落在哪个主机。我们为每个Pod提供了集群专用IP，因此无需在Pod之间明确创建链接，或将容器端口映射到主机端口。这意味着Pod中的容器都可以在localhost上到达彼此的端口，并且集群中的所有Pod都可以在没有NAT的情况下看到对方。 \r将Pod公开给集群 Exposing pods to the cluster apiVersion:apps/v1kind:Deploymentmetadata:name:my-nginxspec:selector:matchLabels:run:my-nginxreplicas:2template:metadata:labels:run:my-nginxspec:containers:- name:my-nginximage:nginxports:- containerPort:80 \r创建服务 Creating a Service apiVersion:v1kind:Servicemetadata:name:my-nginxlabels:run:my-nginxspec:ports:- port:80protocol:TCPselector:run:my-nginx \r访问服务 Accessing the Service Environment Variables DNS kubectl exec \u003cpod\u003e -- printenv kubectl get services kube-dns --namespace=kube-system 服务安全 Securing the Service 在将服务公开到因特网之前，你需要确保通信渠道是安全的。你需要： https签名证书 使用证书的nginx server 使证书可供Pod访问的secret \r公开服务 Exposing the Service NodePort LoadBalancer \r\r","date":"2018-06-26","objectID":"/kubernetes/:14:3","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"Ingress 管理集群中外部访问服务的API对象，通常是HTTP。 Ingress(入口)可以提供负载均衡，SSL终止和基于名称的虚拟主机。 \r术语 Terminology Node Cluster Edge router Cluster network Service \rIngress是什么 通常，服务和Pod具有的IP仅可在集群网络路由。最终在边缘路由器上的所有流量都被丢弃或转发到其它地方。从概念上讲，这可能看起来像： internet | ------------ [ Services ] Ingress是一组允许访问连接到达集群服务的一组规则： internet | [ Ingress ] --|-----|-- [ Services ] 它可以配置为微服务提供外部可访问的URL，负载均衡流量、ssl terminate、基于名称的虚拟主机等。用户通过POST ingress资源到api-server来请求ingress。Ingress Controller负责完成ingress，通常使用负载均衡器(loadbalancer)，但也可配置为edge router或其它前端以帮助以HA方式处理流量。 \r\r先决条件 Prerequisites 在开始使用ingress资源之前，你应该了解一些事项。Ingress是beta resource，在k8s v1.1 之前的版本中都没有。你需要一个ingress controller来满足Ingress，简单地创建资源将无法生效。 GCE/Google Kubernetes Engine在master上部署ingress controller。你可以在Pod中部署任意数量的自定义入口控制器。你必须使用适当的class对每个入口进行注释。在GCE/google kubernetes engine以外的环境中，你需要将ingress controller部署为Pod。 \r\rIngress资源 一个最小化的Ingress看起来如下： apiVersion:extensions/v1beta1kind:Ingressmetadata:name:test-ingressannotations:nginx.ingress.kubernetes.io/rewrite-target:/#ingress spec需要配置负载均衡器或代理服务器所需的信息spec:rules:- http:paths:- path:/testpathbackend:serviceName:testservicePort:80 如果尚未配置ingress controller，则将此操作发送到api-verser将不起作用。 和其它k8s配置一样，Ingress也需要apiVersion, kind, metadata, spec字段。 Ingress spec字段需要配置负载均衡器和代理服务器所需的所有信息。最重要的是，它包含与所有传入请求匹配的规则列表。目前，Ingress仅支持http规则。 每个http rule都包含如下信息： a host，默认值为*；与后端挂念的一组path列表。在负载均衡器将流量定向到后端之前，host和path都必须与传入请求的内容匹配。 后端(backend)是一个service:port的组合。入口流量通常直接发送到与后端匹配的端点(endpoint)。 实例中没有包含Ingress的全局参数(global patameters)，详情请查看文档。 \r\rIngress controllers 为了使ingress资源正常工作，集群必须运行ingress controller——这与其它类型的控制器不同，后者通常为kube-controller-manager程序的一部分，并且通常作为集群创建的一部分而自启动。选择最适合你的集群的ingress controller。 k8s目前支持和维护GCE和Nginx控制器 GCE: https://github.com/kubernetes/ingress-gce/blob/master/README.md F5 BIG-IP Controller for Kubernetes 链接： http://clouddocs.f5.com/products/connectors/k8s-bigip-ctlr/latest Kong Ingress Controller for Kubernetes 链接： https://konghq.com/blog/kubernetes-ingress-controller-for-kong/ Traefik Traefik: https://github.com/containous/traefik Containous: https://containo.us/services NGINX Ingress Controller for Kubernetes 链接: https://www.nginx.com/products/nginx/kubernetes-ingress-controller/ github: https://github.com/jcmoraisjr/haproxy-ingress HAProxy Ingress Controller for Kubernetes 链接： https://www.haproxy.com/blog/haproxy_ingress_controller_for_kubernetes/ 基于istio的Control Ingress Traffic istio: https://istio.io/ 链接: https://istio.io/docs/tasks/traffic-management/ingress/ \r\r####Ingress的类型 \rSingle Service Ingress 现有的k8s概念允许你公开单个服务，但你也可以通过Ingress指定不使用规则的默认后端。 apiVersion:extensions/v1beta1kind:Ingressmetadata:name:test-ingressspec:backend:serviceName:testsvcservicePort:80 #创建 kubectl create -f #查看 kubectl get ingress test-ingress NAME HOSTS ADDRESS PORTS AGE test-ingress * 107.178.254.228 80 59s #107.178.254.228是ingress controller为满足此Ingress而分配的IP \rSimple fanout 如前所述，k8s中Pod只能在集群内网络上看到IP，因此我们需要在边缘处接收入口流量并将其代理到正确的端点。该组件通常是高可用的负载均衡器。Ingress允许你将负载均衡器的数量将至最低。例如： foo.bar.com -\u003e 178.91.123.132 -\u003e / foo s1:80 / bar s2:80 需要一个Ingress，例如： apiVersion:extensions/v1beta1kind:Ingressmetadata:name:testannotations:nginx.ingress.kubernetes.io/rewrite-target:/spec:rules:- host:foo.bar.comhttp:paths:- path:/foobackend:serviceName:s1servicePort:80- path:/barbackend:serviceName:s2servicePort:80 kubectl create -f xxx kubectl describe ingress test Name: test Namespace: default Address: 178.91.123.132 Default backend: default-http-backend:80 (10.8.2.3:8080) Rules: Host Path Backends ---- ---- -------- foo.bar.com /foo s1:80 (10.8.0.90:80) /bar s2:80 (10.8.0.91:80) Annotations: nginx.ingress.kubernetes.io/rewrite-target: / Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ADD 22s loadbalancer-controller default/test \rName based virtual hosting 基于名称的虚拟主机对同一IP地址使用多个主机名。 foo.bar.com --| |-\u003e foo.bar.com s1:80 | 178.91.123.132 | bar.foo.com --| |-\u003e bar.foo.com s2:80 如下的Ingress告诉后端负载均衡器根据Host Header来路由请求： apiVersion:extensions/v1beta1kind:Ingressmetadata:name:testspec:rules:- host:foo.bar.comhttp:paths:- backend:","date":"2018-06-26","objectID":"/kubernetes/:14:4","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"LoadBalancer/NodePort/Ingress比较 参考: Kubernetes NodePort vs LoadBalancer vs Ingress? When should I use what? 这几种服务类型的优缺点，以及什么时候使用它们。 \rCluster IP Cluster IP是默认的k8s服务，它提供集群内部的访问，外部无法访问。 但你可以使用kubernetes proxy来访问它。 什么时候使用： 调试服务 内部访问就可 #开启proxy kubectl proxy --port=8080 #访问资源 http://localhost:8080/api/v1/proxy/namespaces/\u003cNAMESPACE\u003e/services/\u003cSERVICE-NAME\u003e:\u003cPORT-NAME\u003e/ \rNodePort NodePort是公开服务的最原始的方式。 什么时候使用？此方法有许多缺点： 每个端口只能有一个服务 默认端口范文30000-32767 如果节点IP地址发生更改，则需要处理该问题 由于这些原因，不建议在生产环境使用这种方法 LoadBalancer LoadBalancer是公开服务的标准方式。 什么时候用： 指定端口上的所有流量都被转发到该服务，没有过滤、路由等。这意味着你可以发送任何类型的流量，如HTTP, TCP, UDP, Websocket, gRPC… 最大的缺点，你必须为每一个公开的服务使用一个负载均衡器，这个负载均衡器公开的服务都将获得自己的IP，这可能会付出比较大的代价 Ingress 与以上方式不同，Ingress不是一种服务。相反，它位于多个服务之前，充当集群中的入口。 你可以使用Ingress做很多不同的事，并且有许多类型的 ingress controller，具有不同的功能。 什么时候用： Ingress可能是公开服务最强大的方式，但也可能是最复杂的 如果你希望在相同的IP下公开多个服务，则Ingress是最有用的 \r\r","date":"2018-06-26","objectID":"/kubernetes/:14:5","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"网络策略 Network Policies 网络策略是允许容器组如何与彼此以及其它网络端点通信的规范。 NetworkPolicy资源使用labels选择Pod并定义规则，这些规则指定允许选定的Pod的流量。 \r先决条件 网络策略由网络插件来实现，因此你必须使用支持NetworkPolicy的网络解决方案——简单地创建资源而没有控制器来实现它将不起作用。 \r\rIsolated and Non-isolated Pods 默认情况下，Pod是非隔离的(non-isolated)。它们接受任何来源的流量。 可选择NetworkPolicy来隔离Pod，一旦命名空间中任何NetworkPolicy选择了特定的Pod，该Pod将拒绝网络策略不允许的任何连接。 \r\rNetworkPolicy资源 The NetworkPolicy Resource 栗子： apiVersion:networking.k8s.io/v1kind:NetworkPolicymetadata:name:test-network-policynamespace:defaultspec:podSelector:matchLabels:role:dbpolicyTypes:- Ingress- Egressingress:- from:- ipBlock:cidr:172.17.0.0/16except:- 172.17.1.0/24- namespaceSelector:matchLabels:project:myproject- podSelector:matchLabels:role:frontendports:- protocol:TCPport:6379egress:- to:- ipBlock:cidr:10.0.0.0/24ports:- protocol:TCPport:5978 必填字段： NetworkPolicy, apiVersion, kind, metadata spec: 网络策略所需的所有信息 podSelector： 选择策略适用的Pod分组。(如果为空，则表示此命名空间下的所有Pod) policyTypes： 可能包含Ingress, Egress。指示给定策略是否适用于入口流量和出口流量。(如果为空，默认为Ingress) ingress： 允许配置from和ports部分的流量。ipBlock, namespaceSelector, podSelector指定具体信息 egress： 允许配置to和ports部分的流量 \r\r默认策略 Default policies 默认情况下，如果命名空间中不存在任何策略，则允许所有入口(ingress)和出口(egress)流量进出该命名空间中的Pod。 默认拒绝所有入口流量(Default deny all ingress traffic) 你可以通过创建NetworkPolicy来为命名空间创建默认的隔离策略，该策略选择所有Pod但不允许任何入口流量到这些Pod。 apiVersion:networking.k8s.io/v1kind:NetworkPolicymetadata:name:default-denyspec:podSelector:{}policyTypes:- Ingress 默认允许所有入口流量(Default allow all ingress traffic) 如果要允许所有流量到命名空间的所有Pod，你可以创建一个明确允许该命名空间中所有流量的策略。 apiVersion:networking.k8s.io/v1kind:NetworkPolicymetadata:name:allow-allspec:podSelector:{}ingress:- {} 默认拒绝所有出口流量(Default deny all egress traffic) 可通过创建NetworkPolicy来为命名空间创建默认的出口隔离策略，该策略选择所有Pod但不允许来自这些Pod的出口流量。 apiVersion:networking.k8s.io/v1kind:NetworkPolicymetadata:name:default-denyspec:podSelector:{}policyTypes:- Egress 默认允许所有出口流量(Default allow all egress traffic) apiVersion:networking.k8s.io/v1kind:NetworkPolicymetadata:name:allow-allspec:podSelector:{}egress:- {}policyTypes:- Egress 默认拒绝所有入口/出口流量(Default deny all ingress and all egress traffic) apiVersion:networking.k8s.io/v1kind:NetworkPolicymetadata:name:default-denyspec:podSelector:{}policyTypes:- Ingress- Egress \r\r","date":"2018-06-26","objectID":"/kubernetes/:14:6","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"使用HostAliases向Pod的hosts添加条目 Adding entries to Pod /etc/hosts with HostAliases 当DNS和其它选项不适用时，向Pod的/etc/hosts文件添加条目可提供主机名解析的Pod级别的覆盖。在 v1.7 中，用户可以使用pod spec中的HostAliases字段来添加这些自定义条目。 不建议不使用HostAliases进行修改，因为该文件由Kubelet管理，并且可以在Pod 创建/重启 期间覆盖。 \r默认hosts文件 Default Hosts File Content 查看Pod hosts文件： kubectl get pod -o=wide NAME READY STATUS RESTARTS AGE IP NODE nginx-deployment-597549df56-chjps 1/1 Running 0 26d 10.244.2.52 salt01 #kubectl exec POD [-c CONTAINER] -- COMMAND [args...] [options] kubectl exec nginx-deployment-597549df56-chjps -- cat /etc/hosts # Kubernetes-managed hosts file. 127.0.0.1 localhost ::1 localhost ip6-localhost ip6-loopback fe00::0 ip6-localnet fe00::0 ip6-mcastprefix fe00::1 ip6-allnodes fe00::2 ip6-allrouters 10.244.2.52 nginx-deployment-597549df56-chjps \r\r使用HostAliases添加额外条目 Adding Additional Entries with HostAliases hostaliases-pod.yaml: apiVersion:v1kind:Podmetadata:name:hostaliases-podspec:restartPolicy:NeverhostAliases:- ip:\"127.0.0.1\"hostnames:- \"foo.local\"- \"bar.local\"- ip:\"192.168.31.119\"hostnames:- zhang21containers:- name:cat-hostsimage:busyboxcommand:- catargs:- \"/etc/hosts\" kubectl apply -f hostaliases-pod.yaml kubeclt logs hostaliases-pod # Kubernetes-managed hosts file. 127.0.0.1 localhost ::1 localhost ip6-localhost ip6-loopback fe00::0 ip6-localnet fe00::0 ip6-mcastprefix fe00::1 ip6-allnodes fe00::2 ip6-allrouters 10.244.1.69 hostaliases-pod # Entries added by HostAliases. 127.0.0.1 foo.local 127.0.0.1 bar.local 192.168.31.119 zhang21 \r\r为什么kubelet管理hosts Why Does Kubelet Manage the Hosts File? Kubelet管理Pod中每个容器的hosts文件，以防止Docker在容器已启动后修改文件。 由于文件的托管性质，只要在容器重启或Pod重新调度的情况下由Kubelet重新挂载hosts文件，因此用户编写的内容都将被覆盖。因此，不建议直接修改文件的内容。 \r\r\r","date":"2018-06-26","objectID":"/kubernetes/:14:7","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"存储 Storage \r\r","date":"2018-06-26","objectID":"/kubernetes/:15:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"Volumes 容器中的磁盘文件是短暂的，这在容器中运行时会给重大的应用程序带来一些问题。首先，当一个容器奔溃时，kubelet将重启它，但文件会丢失，容器将以干净的状态启动。其次，在Pod中一起运行容器时，通常需要在这些容器间共享文件。k8s volume抽象解决这些问题。 \r\rBackground Docker也有关于卷的概念，虽然它有点宽松和管理较少。在Docker中，卷是磁盘上或其它容器中的目录，声明周期不受管理。Docker提供了卷驱动，但目前功能非常有限。 另一方面，k8s的卷具有明确的生命周期。因此，卷可以比Pod中运行的任何容器活得更久，并且可在容器重启之间保留数据。当然，当Pod不再存在时，卷也将不复存在。更重要的是，k8s支持多种类型的卷，Pod可以同时使用任意数量的卷。 从本质上讲，卷只是一个目录，可能包含一些数据，Pod中的容器可以访问它。该目录如何形成，支持它的介质以及它的内容都由所用特定卷的类型决定。 要使用卷，Pod Spec要指定提供的卷(.spec.volumes字段)，以及将这些卷挂载到容器中的位置(.spec.containers.volumeMounts字段)。 容器中的进程可以看到由Docker镜像和卷组成的文件系统视图。Docker镜像位于文件系统层次结构的根下，任何卷都挂载到镜像中的指定路径。卷不能挂载到其它卷或其它卷的硬链接上，Pod中的每个容器必须独立的指定每个卷的挂载位置。 \r\r卷类型 k8s支持如下卷类型。注意，这些卷并非全部都是持久化的(如emptyDir)，它们会随着Pod的消亡而消亡。 awsElasticBlockStore azureDisk azureFile cephfs configMap csi downwardAPI emptyDir fc (fibre channel) flocker gcePersistentDisk gitRepo (deprecated) glusterfs hostPath iscsi local nfs persistentVolumeClaim projected portworxVolume quobyte rbd scaleIO secret storageos vsphereVolume 具体例子请参考: https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes configMap configMap资源提供了一种将配置数据注入Pod的方法。存储在configMap对象中的数据可以在configMap类型的卷中引用，然后由Pod中运行的应用程序使用。 引用configMap对象时，只需在卷中提供其名称即可引用它。你还可以自定义configMap中的特定条路的路径。 例如，要将log-config的ConfigMap挂载到名为configmap-pod的Pod上，你可以这样操作： 注意，在使用之前你先得创建ConfigMap 使用ConfigMap作为subPath的卷挂载将不会收到ConfigMap的更新 apiVersion:v1kind:Podmetadata:name:configmap-podspec:containers:- name:testimage:busyboxvolumeMounts:- name:config-volmountPath:/etc/configvolumes:- name:config-volconfigMap:name:log-configitems:- key:log_levelpath:log_level#log-config configMap作为卷挂载，存储在`log_level`的所有内容都挂载到路径`/etc/config/log_level`的Pod中 emptyDir 将Pod分配给节点时，首先会创建一个emptyDir卷。只要节点还在该节点上运行，它就会存在。就如同它的名称一样，它最初是空的。Pod中的容器都可以在emptyDir卷中读取和写入相同的文件，尽管改卷可以安装在每个容器中相同或不同的路径上。当从节点上删除Pod时，将永久删除emptyDir中的数据。 注意：容器奔溃不会从节点中删除Pod，因此emptyDir卷中的数据在容器奔溃时是安全的。 emptyDir的一些用途： 临时空间 检查从崩溃中恢复的长计算 保存内容管理器容器在Web服务器提供数据时提取的文件 默认情况下，emptyDir卷存储在节点的任何介质上(磁盘、SSD、网络存储…)，取决于你的环境。但是，你可以将emptyDir.medium字段设置为Memory，以告诉k8s为你安装tmpfs(RAM支持的文件系统)。tmpfs非常快，但请注意断电就没有了，并且你编写的任何文件都将计入容器的内存限制。 栗子： apiVersion:v1kind:Podmetadata:name:test-pdspec:containers:- image:k8s.gcr.io/test-webservername:test-containervolumeMounts:- mountPath:/cachename:cache-volumevolumes:- name:cache-volumeemptyDir:{} hostPath hostPath卷将文件或目录从主机节点的文件系统挂载到Pod中。这不是大多数Pod需要的东西，但它为某些应用程序提供了强大的逃生舱。 hostPath的一些用途： 运行需要访问Docker内部的容器，使用/var/lib/docker的hostPath 在容器中运行cAdvisor 允许Pod指定在Pod运行之前是否应该存在给定的hostPath，是否应该创建它以及它应该存在的内容 三个字段: hostPath path type 支持的type的值： Value Behavior 空 Empty string (default) is for backward compatibility, which means that no checks will be performed before mounting the hostPath volume. DirectoryOrCreate If nothing exists at the given path, an empty directory will be created there as needed with permission set to 0755, having the same group and ownership with Kubelet. Directory A directory must exist at the given path FileOrCreate If nothing exists at the given path, an empty file will be created there as needed with permission set to 0644, having the same group and ownership with Kubelet. File A file must exist at the given path Socket A UNIX socket must exist at the given path CharDevice A character device must exist at the given path BlockDevice A block device must exist at the given path 请注意何时使用此类型的卷，因为： 由于节点上的文件不同，具有相同配置的Pod在不同节点上的行为可能有所不同 当k8s按计划添加资源，它将无法考虑hostPath使用的资源 在底层主机上创建的文件或目录只能由root写入 栗子: apiVersion:v1kind:Podmetadata:name:test-pdspec:containers:- image:k8s.gcr.io/test-webservername:test-containervolumeMounts:- mountPath:/test-pdname:test-volumevolumes:- name:test-volumehostPath:# directory location on hostpath:/data# this field is optionaltype:Directory local local卷表示已挂载的本地存储设备，如磁盘，分区或目录。它只能用作静态创建的持久化卷，尚不支持动态配置。 与hostPath卷相比，可以以持久且可移植的方式使用lobal卷，而无需手动将Pod调度到节点。 然而，local卷仍受基础节点可用性的限制，并不适用于所有应用程序。如果节点变得不健康，则local卷也将变得不可访问，并且使用它的Pod将无法运行。使用local volume的应用程序必须能够容忍这种降低的可用性以及潜在的数据丢失，具体取决于底层磁盘的持久性特征。 栗子： apiVersion:v1kind:PersistentVolumemetadata:name:example-pvspec:capacity:storage:100Gi# volumeMode field requi","date":"2018-06-26","objectID":"/kubernetes/:15:1","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"持久化卷 Persistent Volumes \r简介 PersistentVolume 子系统为用户和管理员提供了一个API，它提供了如何根据消耗提供存储的详细信息。为此，我们引入了两个新的API资源： PersistentVolume(PV) PersistentVolumeClaim(PVC) PersistentVolume 是群集中由管理员配置的一块存储。它是集群中的资源，就像节点是集群资源一样。它是像 Volume 的 Volume Plugin，但其生命周期独立于使用它的任何单个 pod 。此API对象捕获存储实现的详细信息，包括NFS，iSCSI或特定于云提供程序的存储系统。 PersistentVolumeClaim 是用户存储的请求。与 Pod 类似，Pod 消耗 Node 资源，而 PVC 消耗 PV 的资源。Pod可以请求特定级别的资源(CPU, MEM)，Claim 可以请求特定的大小和访问模式。 虽然 PersistentVolumeClaims 允许用户使用抽象存储资源，但是对于不同的问题，用户需要具有不同属性的 PersistentVolumes。群集管理员需要能够提供各种PersistentVolume，这些PersistentVolume在多种方式上而不仅仅是大小和访问模式，而不会让用户了解这些卷的实现方式。对于这些需求，有 StorageClass 资源。 \r\rvolume和claim的生命周期 Lifecycle of a volume and claim PV是群集中的资源。 PVC是对这些资源的请求，并且还充当对资源的声明检查。PV和PVC之间的相互作用遵循如下生命周期。 \rProvisioning 有两种方式配置PV: Static 集群管理员创建了许多PV。它们包含可供群集用户使用的实际存储的详细信息。它们存在于Kubernetes API中，可供使用。 Dynamic 当管理员创建的 Static PV 都不匹配用户的 PersistentVolumeClaim 时，群集可能会尝试为PVC 专门动态配置Volume。此 Provision 基于StorageClasses， PVC必须请求存储类，管理员必须已创建并配置该类，以便进行动态供应。 \rBinding 用户在动态配置的情况下创建或已创建 PersistentVolumeClaim，其具有请求的特定存储量和某些访问模式。Master中的控制循环观察新PVC，找到匹配的PV（如果可能），并将它们绑定在一起。如果为新PVC动态配置PV，则循环将始终将该PV绑定到PVC。否则，用户将始终至少得到他们要求的内容，但是Volume可能超过所要求的数量。绑定后，PersistentVolumeClaim 绑定是独占的，无论它们如何绑定，PVC到PV绑定是一一对应。 如果不存在匹配的卷，则 Claim 将无限期地保持未绑定状态。Claim 将在匹配卷可用时受到绑定。例如，集群配置了许多50Gi PV，与请求100Gi的PVC不匹配。当100Gi PV添加到集群时，可以绑定PVC。 \rUsing Pods 使用 Claim 作为 Volume。群集检查 Claim 以查找绑定卷并为该 Pod 挂载该卷。对于支持多种访问模式的卷，用户在将其声明用作 Pod 的卷时指定所需的模式。 一旦用户具有声明并且该声明被绑定，绑定的PV就属于用户，只要用户需要它。用户通过在Pod的 Volume Block 中包含 persistentVolumeClaim 来调度Pod并访问其声明的PV。 \rStorage Object in Use Protection 使用中的存储对象保护 功能的目的是确保不会从系统中删除 绑定到 PVC，由 Pod 和 PV 主动使用的 PVC，因为这可能会导致数据丢失。 注意：当pod状态为Pending且pod已分配给Node，或pod状态为Running时，pod将主动使用PVC。 \rReclaiming 当用户完成卷时，他们可以从API中删除PVC对象，从而允许回收资源。PersistentVolume 的回收策略告诉群集在释放其声明后如何处理该卷。 目前，卷可以保留、回收、删除: Retain 保留回收政策允许手动回收资源。删除 PVC 时，PV 仍然存在，并且该卷被视为 已释放。但它还不能被 Claim 使用，因为之前的 Claim 的数据仍在卷上。管理员可以通过以下步骤手动回收该卷: 1. 删除此PV 2. 手动清理相关数据 3. 手动删除关联的存储资产 Recycle 警告：Recycle Claim Policy 将会被移除，不推荐使用。相反，推荐的方法是使用动态配置。 Delete 对于支持删除回收策略的卷插件，将删除k8s中的 PV 对象以及外部基础结构中的关联存储资产。动态配置的卷继承其 StorageClass 的回收策略(默认为Delete)。管理员应根据用户的期望配置StorageClass，否则PV必须在创建后进行编辑或修补。 \r\rExpanding Persistent Volumes Claims FEATURE STATE: Kubernetes v1.8 alpha FEATURE STATE: Kubernetes v1.11 beta 只有将 StorageClass 的 allowVolumeExpansion 字段设置为 true，才能使用扩展的PVC。 现在默认启用对扩展PVC的支持。您可以扩展以下类型的卷： gcePersistentDisk awsElasticBlockStore Cinder glusterfs rbd Azure File Azure Disk Portworx Resizing a volume containing a file system 如果文件系统是XFS，Ext3或Ext4，你可调整包含文件系统的卷的大小。 当卷包含文件系统时，仅在使用 RW模式下的 PVC 启动新Pod时才调整文件系统的大小。 #如果PVC的状态为FileSystemResizePending，则使用PVC重新创建pod是安全的 kubectl describe pvc \u003cpvc_name\u003e Resizing an in-use PersistentVolumeClaim FEATURE STATE: Kubernetes v1.11 alpha 要使用它，请启用 ExpandInUsePersistentVolumes。在这种情况下，您无需删除并重新创建使用现有PVC的Pod或Deployment。任何正在使用的PVC在其文件系统扩展后自动可用于其Pod。 \r\r持久化卷的类型 Types of Persistent Volumes PV类型实现为插件， k8s 目前支持以下插件: GCEPersistentDisk AWSElasticBlockStore AzureFile AzureDisk FC (Fibre Channel) FlexVolume Flocker NFS iSCSI RBD (Ceph Block Device) CephFS Cinder (OpenStack block storage) Glusterfs VsphereVolume Quobyte Volumes HostPath Portworx Volumes ScaleIO Volumes StorageOS \r\rPersistent Volumes 每个PV都包含 spec 和 status: apiVersion:v1kind:PersistentVolumemetadata:name:pv0003spec:capacity:storage:5GivolumeMode:FilesystemaccessModes:- ReadWriteOncepersistentVolumeReclaimPolicy:RecyclestorageClassName:slowmountOptions:- hard- nfsvers=4.1nfs:path:/tmpserver:172.17.0.2 \r\rPersistentVolumeClaims 每个PVC都包含了 spec 和 status: kind:PersistentVolumeClaimapiVersion:v1metadata:name:myclaimspec:accessModes:- ReadWriteOncevolumeMode:Filesystemresources:requests:storage:8GistorageClassName:slowselector:matchLabels:release:\"stable\"matchExpressions:- {key: environment, operator: In, values:[dev]} \r\rClaims As Volumes Pods使用 claim as a volume 来访问存储。声明必须与使用声明的pod存在于同一名称空间中。群集在pod的命名空间中查找声明，并使用它来获取支持声明的PV，然后将卷挂载到主机并进入容器。 kind:PodapiVersion:v1metadata:name:mypodspec:containers:- name:myfrontendimage:dockerfile/nginxvolumeMounts:- mountPath:\"/var/www/","date":"2018-06-26","objectID":"/kubernetes/:15:2","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"Storage Classes StorageClass 为管理员提供了一种描述他们提供的 存储类 的方法。不同的类可能映射到服务质量级别、备份策略，或者由集群管理员确定的任意策略。k8s 本身对于类代表什么是不受任何影响的，这个概念有时在其他存储系统中称为profile。 \r\r\r","date":"2018-06-26","objectID":"/kubernetes/:15:3","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"垃圾收集 Kubernetes 垃圾收集器的角色是删除指定的对象，这些对象曾经有但以后不再拥有 Owner 了。 某些Kubernetes对象是其它一些对象的Owner。如，一个副本集是一组pod的Owner。 具有Owner的对象被称为是Owner的Dependent。每个Dependent对象具有一个执行所属对象的metadata.ownerReference字段。 有时，Kubernetes会自动设置ownerReference的值。 也可以手动设置ownerReference的值，来指定Owner和Dependent之间的关系。 控制垃圾收集器删除Dependent 级联删除 background foreground 删除对象时自动删除Dependent。 在bg级联删除模式下，k8s会立即删除Owner对象，然后垃圾收集器会在后台删除这些Dependent。 在fg级联删除模式下，根对象首先进入删除中状态。一旦对象被设置为删除中状态，垃圾收集器会删除对象的所有Dependent。 孤儿 删除对象时，不自动删除它的Dependent。这些Dependent就被称作孤儿。垃圾收集器在删除了所有 “Blocking” 状态的 Dependent（对象的 ownerReference.blockOwnerDeletion=true）之后，它会删除 Owner 对象。 ","date":"2018-06-26","objectID":"/kubernetes/:16:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"安全 Security: https://kubernetes.io/docs/concepts/security/ ","date":"2018-06-26","objectID":"/kubernetes/:17:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"云原生安全概述 Overview of Cloud Native Security 本概述定义了一个模型，用于在 Cloud Native 安全性上下文中考虑 Kubernetes 安全性。 警告: 此容器安全模型只提供建议，而不是经过验证的信息安全策略。 云原生安全的4个C The 4C’s of Cloud Native security 你可以分层去考虑安全性，云原生安全的 4 个 C 分别是云（Cloud）、集群（Cluster）、容器（Container）和代码（Code）。 云原生安全模型的每一层都是基于下一个最外层，代码层受益于强大的基础安全层（云、集群、容器）。你无法通过在代码层解决安全问题来为基础层中糟糕的安全标准提供保护。 云 Cloud 如果云层容易受到攻击（或者被配置成了易受攻击的方式），就不能保证在此基础之上构建的组件是安全的。 每个云提供商都会提出安全建议，以在其环境中安全地运行工作负载。 各个云提供商(IaaS)的安全性。 基础设施安全 关于在 Kubernetes 集群中保护你的基础设施的建议 k8s基础架构关注领域 建议 通过网络访问 API 服务（控制平面） 所有对 Kubernetes 控制平面的访问不允许在 Internet 上公开，同时应由网络访问控制列表控制，该列表包含管理集群所需的 IP 地址集 通过网络访问 Node（节点 节点应配置为 仅能 从控制平面上通过指定端口来接受（通过网络访问控制列表）连接，以及接受 NodePort 和 LoadBalancer 类型的 Kubernetes 服务连接。如果可能的话，这些节点不应完全暴露在公共互联网上 Kubernetes 访问云提供商的 API 每个云提供商都需要向 Kubernetes 控制平面和节点授予不同的权限集。为集群提供云提供商访问权限时，最好遵循对需要管理的资源的最小特权原则 访问 etcd 对 etcd（Kubernetes 的数据存储）的访问应仅限于控制平面。根据配置情况，你应该尝试通过 TLS 来使用 etcd etcd 加密 在所有可能的情况下，最好对所有驱动器进行静态数据加密，但是由于 etcd 拥有整个集群的状态（包括机密信息），因此其磁盘更应该进行静态数据加密 集群 Cluster 保护k8s有两个方面需要注意: 保护可配置的集群组件 保护在集群中运行的应用程序 根据您的应用程序的受攻击面，您可能需要关注安全性的特定面。 工作负载安全性关注领域 建议 RBAC 授权(访问 Kubernetes API) https://kubernetes.io/zh/docs/reference/access-authn-authz/rbac/ 认证方式 https://kubernetes.io/zh/docs/reference/access-authn-authz/controlling-access/ 应用程序 Secret 管理 (并在 etcd 中对其进行静态数据加密) https://kubernetes.io/zh/docs/concepts/configuration/secret/ https://kubernetes.io/zh/docs/tasks/administer-cluster/encrypt-data/ Pod 安全策略 https://kubernetes.io/zh/docs/tasks/configure-pod-container/quality-service-pod/ 网络策略 https://kubernetes.io/zh/docs/concepts/services-networking/network-policies/ Ingress 的 TLS 支持 https://kubernetes.io/zh/docs/concepts/services-networking/ingress/#tls 容器 Container 一些建议: 容器关注领域 建议 容器漏洞扫描和操作系统依赖安全性 作为镜像构建的一部分，您应该扫描您的容器里的已知漏洞 镜像签名和执行 对容器镜像进行签名，以维护对容器内容的信任 禁止特权用户 构建容器时，请查阅文档以了解如何在具有最低操作系统特权级别的容器内部创建用户，以实现容器的目标 代码 Code 应用程序代码是您最能够控制的主要攻击面之一，一些建议： 代码关注领域 建议 仅通过 TLS 访问 如果您的代码需要通过 TCP 通信，请提前与客户端执行 TLS 握手。除少数情况外，请加密传输中的所有内容。更进一步，加密服务之间的网络流量是一个好主意。这可以通过被称为相互 LTS 或 mTLS 的过程来完成，该过程对两个证书持有服务之间的通信执行双向验证 限制通信端口范围 此建议可能有点不言自明，但是在任何可能的情况下，你都只应公开服务上对于通信或度量收集绝对必要的端口 第三方依赖性安全 最好定期扫描应用程序的第三方库以了解已知的安全漏洞。每种编程语言都有一个自动执行此检查的工具 静态代码分析 大多数语言都提供给了一种方法，来分析代码段中是否存在潜在的不安全的编码实践 动态探测攻击 您可以对服务运行一些自动化工具，来尝试一些众所周知的服务攻击。这些攻击包括 SQL 注入、CSRF 和 XSS。OWASP Zed Attack 代理工具是最受欢迎的动态分析工具之一 ","date":"2018-06-26","objectID":"/kubernetes/:17:1","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"k8s api访问控制 Controlling Access to the Kubernetes API 用户使用 kubectl、客户端库或构造 REST 请求来访问 Kubernetes API。用户和 Kubernetes 服务账户都可以被鉴权访问 API。 当请求到达 API 时，它会经历多个阶段，如下图所示： 传输安全 Transport security 在典型的 Kubernetes 集群中，API 服务器在 443 端口上提供服务，受 TLS 保护。 API 服务器出示证书。如果你的集群使用私有证书颁发机构，你需要在客户端的 ~/.kube/config 文件中提供该 CA 证书的副本， 以便你可以信任该连接并确认该连接没有被拦截。 认证 Authentication 建立 TLS 后， HTTP 请求将进入认证（Authentication）步骤。 认证步骤的输入整个 HTTP 请求；但是，通常组件只检查头部或/和客户端证书。 认证模块包含客户端证书、密码、普通令牌、引导令牌和 JSON Web 令牌（JWT，用于服务账户）。 可以指定多个认证模块，在这种情况下，服务器依次尝试每个验证模块，直到其中一个成功。 授权 Authorization 请求必须包含请求者的用户名、请求的行为以及受该操作影响的对象。 如果现有策略声明用户有权完成请求的操作，那么该请求被鉴权通过。 Kubernetes 鉴权要求使用公共 REST 属性与现有的组织范围或云提供商范围的访问控制系统进行交互。 使用 REST 格式很重要，因为这些控制系统可能会与 Kubernetes API 之外的 API 交互。 Kubernetes 支持多种鉴权模块，例如 ABAC 模式、RBAC 模式和 Webhook 模式等。 管理员创建集群时，他们配置应在 API 服务器中使用的鉴权模块。 准入控制 Admission control 准入控制模块是可以修改或拒绝请求的软件模块。 除鉴权模块可用的属性外，准入控制模块还可以访问正在创建或修改的对象的内容。 准入控制器对创建、修改、删除或（通过代理）连接对象的请求进行操作。 准入控制器不会对仅读取对象的请求起作用。 有多个准入控制器被配置时，服务器将依次调用它们。 API 服务器端口和IP API server ports and IPs ","date":"2018-06-26","objectID":"/kubernetes/:17:2","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"Pod安全标准 Pod Security Standards Pod 的安全性配置一般通过使用 安全性上下文（Security Context） 来保证。安全性上下文允许用户逐个 Pod 地定义特权级及访问控制。 以前，对集群的安全性上下文的需求的实施及其基于策略的定义都通过使用 Pod 安全性策略来实现。Pod 安全性策略是一种集群层面的资源，控制 Pod 规约中 安全性敏感的部分。 安全上下文在运行时配置 Pod 和容器。安全上下文是在 Pod 清单中作为 Pod 和容器规约的一部分来定义的，所代表的是 传递给容器运行时的参数。 安全策略则是控制面用来对安全上下文以及安全性上下文之外的参数实施某种设置的机制。 在 2020 年 2 月，目前实施这些安全性策略的原生解决方案是 Pod 安全性策略 - 一种对集群中 Pod 的安全性策略进行集中控制的机制。 Kubernetes 生态系统中还在开发一些其他的替代方案，例如 OPA Gatekeeper。 策略类型 Policy Types 策略可以是很严格的也可以是很宽松的： Privileged - 不受限制的策略，提供最大可能范围的权限许可。这些策略 允许已知的特权提升。 Baseline/Default - 限制性最弱的策略，禁止已知的策略提升。 允许使用默认的（规定最少）Pod 配置。 Restricted - 限制性非常强的策略，遵循当前的保护 Pod 的最佳实践。 Privileged Privileged 策略是有目的地开放且完全无限制的策略。此类策略通常针对由 特权较高、受信任的用户所管理的系统级或基础设施级负载。 Baseline/Default 策略的目标是便于常见的容器化应用采用，同时禁止已知的特权提升。 下面列举的控制应该被实施（禁止）： 控制 Control 策略 Policy 宿主名字空间 必须禁止共享宿主名字空间 特权容器 特权 Pod 禁用大多数安全性机制，必须被禁止 权能 必须禁止添加默认集合之外的权能 HostPath 卷 必须禁止 HostPath 卷 宿主端口 应禁止使用宿主端口，或者至少限定为已知列表 AppArmor 在受支持的宿主上，默认应用 ‘runtime/default’ AppArmor Profile。默认策略应禁止重载或者禁用该策略，或将重载限定未所允许的 profile 集合 SELinux 应禁止设置定制的 SELinux 选项 /proc 挂载类型 求使用默认的 /proc 掩码以减小攻击面 Sysctls Sysctls 可以禁用安全机制或影响宿主上所有容器，因此除了若干安全的子集之外，应该被禁止。 如果某 sysctl 是受容器或 Pod 的名字空间限制，且与节点上其他 Pod 或进程相隔离，可认为是安全的 Restricted Restricted 策略旨在实施当前保护 Pod 的最佳实践，尽管这样作可能会牺牲一些兼容性。 该类策略主要针对运维人员和安全性很重要的应用的开发人员，以及不太被信任的用户。 下面列举的控制需要被实施（禁止）： 控制 Control 策略 Policy 卷类型 除了限制 HostPath 卷之外，此类策略还限制可以通过 PersistentVolumes 定义的非核心卷类型 特权提升 禁止（通过 SetUID 或 SetGID 文件模式）获得特权提升 以非 root 账号运行 必须要求容器以非 root 用户运行 非 root 组 禁止容器使用 root 作为主要或辅助 GID 来运行 Seccomp 必须要求使用 RuntimeDefault seccomp profile 或者允许使用特定的 profiles ","date":"2018-06-26","objectID":"/kubernetes/:17:3","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"策略 Policies ","date":"2018-06-26","objectID":"/kubernetes/:18:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"限制范围 Limit Ranges 默认情况下， Kubernetes 集群上的容器运行使用的计算资源没有限制。 使用资源配额，集群管理员可以以命名空间为单位，限制其资源的使用与创建。 一个 LimitRange（限制范围） 对象提供的限制能够做到： 在一个命名空间中实施对每个 Pod 或 Container 最小和最大的资源使用量的限制。 在一个命名空间中实施对每个 PersistentVolumeClaim 能申请的最小和最大的存储空间大小的限制。 在一个命名空间中实施对一种资源的申请值和限制值的比值的控制。 设置一个命名空间中对计算资源的默认申请/限制值，并且自动的在运行时注入到多个 Container 中。 ","date":"2018-06-26","objectID":"/kubernetes/:18:1","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"资源配额 Resource Quotas 当多个用户或团队共享具有固定节点数目的集群时，人们会担心有人使用超过其基于公平原则所分配到的资源量。 资源配额是帮助管理员解决这一问题的工具。 资源配额，通过 ResourceQuota 对象来定义，对每个命名空间的资源消耗总量提供限制。 它可以限制命名空间中某种类型的对象的总数目上限，也可以限制命令空间中的 Pod 可以使用的计算资源的总上限。 资源配额的工作方式如下： 不同的团队可以在不同的命名空间下工作，目前这是非约束性的，在未来的版本中可能会通过 ACL (Access Control List 访问控制列表) 来实现强制性约束。 集群管理员可以为每个命名空间创建一个或多个 ResourceQuota 对象。 当用户在命名空间下创建资源（如 Pod、Service 等）时，Kubernetes 的配额系统会 跟踪集群的资源使用情况，以确保使用的资源用量不超过 ResourceQuota 中定义的硬性资源限额。 如果资源创建或者更新请求违反了配额约束，那么该请求会报错（HTTP 403 FORBIDDEN）， 并在消息中给出有可能违反的约束。 如果命名空间下的计算资源 （如 cpu 和 memory）的配额被启用，则用户必须为 这些资源设定请求值（request）和约束值（limit），否则配额系统将拒绝 Pod 的创建。 提示: 可使用 LimitRanger 准入控制器来为没有设置计算资源需求的 Pod 设置默认值。 ","date":"2018-06-26","objectID":"/kubernetes/:18:2","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"Pod安全策略 Pod Security Policies FEATURE STATE: Kubernetes v1.20 beta Pod 安全策略使得对 Pod 创建和更新进行细粒度的权限控制成为可能。 Pod 安全策略（Pod Security Policy） 是集群级别的资源，它能够控制 Pod 规约 中与安全性相关的各个方面。 PodSecurityPolicy 对象定义了一组 Pod 运行时必须遵循的条件及相关字段的默认值，只有 Pod 满足这些条件 才会被系统接受。 ","date":"2018-06-26","objectID":"/kubernetes/:18:3","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"进程 ID 约束与预留 Process ID Limits And Reservations FEATURE STATE: Kubernetes v1.20 stable Kubernetes 允许你限制一个 Pod 中可以使用的 进程 ID（PID）数目。你也可以为每个 节点 预留一定数量的可分配的 PID，供操作系统和守护进程（而非 Pod）使用。 进程 ID（PID）是节点上的一种基础资源。很容易就会在尚未超出其它资源约束的时候就 已经触及任务个数上限，进而导致宿主机器不稳定。 集群管理员需要一定的机制来确保集群中运行的 Pod 不会导致 PID 资源枯竭，甚而 造成宿主机上的守护进程（例如 kubelet 或者 kube-proxy 乃至包括容器运行时本身）无法正常运行。 此外，确保 Pod 中 PID 的个数受限对于保证其不会影响到同一节点上其它负载也很重要。 在某些 Linux 安装环境中，操作系统会将 PID 约束设置为一个较低的默认值，例如 32768。这时可以考虑提升 /proc/sys/kernel/pid_max 的设置值。 节点级别PID限制 Pod级别PID限制 基于PID的驱逐 ","date":"2018-06-26","objectID":"/kubernetes/:18:4","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"调度和驱逐 Scheduling and Eviction ","date":"2018-06-26","objectID":"/kubernetes/:19:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"Kubernetes调度器 Kubernetes Scheduler 在 Kubernetes 中，调度 是指将 Pod 放置到合适的 Node 上，然后对应 Node 上的 Kubelet 才能够运行这些 pod。 调度器通过 kubernetes 的监测（Watch）机制来发现集群中新创建且尚未被调度到 Node 上的 Pod。 调度器会将发现的每一个未调度的 Pod 调度到一个合适的 Node 上来运行。 调度器会依据下文的调度原则来做出调度选择。 kube-scheduler kube-scheduler 是 Kubernetes 集群的默认调度器，并且是集群 控制面 的一部分。 对每一个新创建的 Pod 或者是未被调度的 Pod，kube-scheduler 会选择一个最优的 Node 去运行这个 Pod。然而，Pod 内的每一个容器对资源都有不同的需求，而且 Pod 本身也有不同的资源需求。因此，Pod 在被调度到 Node 上之前， 根据这些特定的资源调度需求，需要对集群中的 Node 进行一次过滤。 在一个集群中，满足一个 Pod 调度请求的所有 Node 称之为 可调度节点。 如果没有任何一个 Node 能满足 Pod 的资源请求，那么这个 Pod 将一直停留在 未调度状态直到调度器能够找到合适的 Node。 调度器先在集群中找到一个 Pod 的所有可调度节点，然后根据一系列函数对这些可调度节点打分， 选出其中得分最高的 Node 来运行 Pod。之后，调度器将这个调度决定通知给 kube-apiserver，这个过程叫做 绑定。 在做调度决定时需要考虑的因素包括：单独和整体的资源请求、硬件/软件/策略限制、 亲和以及反亲和要求、数据局域性、负载间的干扰等等。 kube-scheduler调度流程 kube-scheduler 给一个 pod 做调度选择包含两个步骤： 过滤(Filtering) 打分(Scoring) 过滤阶段会将所有满足 Pod 调度需求的 Node 选出来。在过滤之后，得出一个 Node 列表，里面包含了所有可调度节点。通常情况下， 这个 Node 列表包含不止一个 Node。如果这个列表是空的，代表这个 Pod 不可调度。 在打分阶段，调度器会为 Pod 从所有可调度节点中选取一个最合适的 Node。 根据当前启用的打分规则，调度器会给每一个可调度节点进行打分。 最后，kube-scheduler 会将 Pod 调度到得分最高的 Node 上。 如果存在多个得分最高的 Node，kube-scheduler 会从中随机选取一个。 支持以下两种方式配置调度器的过滤和打分行为： 调度策略 允许你配置过滤的 断言(Predicates) 和打分的 优先级(Priorities) 。 调度配置 允许你配置实现不同调度阶段的插件， 包括：QueueSort, Filter, Score, Bind, Reserve, Permit 等等。 你也可以配置 kube-scheduler 运行不同的配置文件。 ","date":"2018-06-26","objectID":"/kubernetes/:19:1","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"污点和容忍度 Taints and Tolerations 节点亲和性是 Pod 的一种属性，它使 Pod 被吸引到一类特定的节点。 这可能出于一种偏好，也可能是硬性要求。 Taint（污点）则相反，它使节点能够排斥一类特定的 Pod。 容忍度（Tolerations）是应用于 Pod 上的，允许（但并不要求）Pod 调度到带有与之匹配的污点的节点上。 污点和容忍度（Toleration）相互配合，可以用来避免 Pod 被分配到不合适的节点上。 每个节点上都可以应用一个或多个污点，这表示对于那些不能容忍这些污点的 Pod，是不会被该节点接受的。 概念 Concepts 给节点增加一个污点。给节点node1增加一个污点，它的键名是key1，键值是value1，效果是NoSchedule。这表示只有拥有和这个污点相匹配的容忍度的Pod才能够被分配到node1这个节点。 kubectl taint nodes node1 key1=value1:NoSchedule # 移除污点 kubectl taint nodes node1 key1=value1:NoSchedule- 你可以在Pod spec中定义Pod的容忍度。 od 拥有其中的任何一个容忍度都能够被分配到 node1 ：tolerations:- key:\"key1\"operator:\"Equal\"value:\"value1\"effect:\"NoSchedule\" 或 tolerations:- key:\"key1\"operator:\"Exists\"effect:\"NoSchedule\" 一个容忍度和一个污点相匹配是指它们有一样的键名和效果，并且： 如果 operator 是 Exists （此时容忍度不能指定 value） 如果 operator 是 Equal ，则它们的 value 应该相等 上述例子中 effect 使用的值为 NoSchedule，您也可以使用另外一个值 PreferNoSchedule。这是优化或软版本的 NoSchedule —— 系统会 尽量 避免将 Pod 调度到存在其不能容忍污点的节点上， 但这不是强制的。effect 的值还可以设置为 NoExecute。 您可以给一个节点添加多个污点，也可以给一个 Pod 添加多个容忍度设置。Kubernetes 处理多个污点和容忍度的过程就像一个过滤器：从一个节点的所有污点开始遍历， 过滤掉那些 Pod 中存在与之相匹配的容忍度的污点。余下未被过滤的污点的 effect 值决定了 Pod 是否会被分配到该节点。特别是以下情况： 如果未被过滤的污点中存在至少一个 effect 值为 NoSchedule 的污点， 则 Kubernetes 不会将 Pod 分配到该节点。 如果未被过滤的污点中不存在 effect 值为 NoSchedule 的污点， 但是存在 effect 值为 PreferNoSchedule 的污点， 则 Kubernetes 会 尝试 不将 Pod 分配到该节点。 如果未被过滤的污点中存在至少一个 effect 值为 NoExecute 的污点， 则 Kubernetes 不会将 Pod 分配到该节点（如果 Pod 还未在节点上运行）， 或者将 Pod 从该节点驱逐（如果 Pod 已经在节点上运行）。 通常情况下，如果给一个节点添加了一个 effect 值为 NoExecute 的污点， 则任何不能忍受这个污点的 Pod 都会马上被驱逐， 任何可以忍受这个污点的 Pod 都不会被驱逐。 但是，如果 Pod 存在一个 effect 值为 NoExecute 的容忍度指定了可选属性 tolerationSeconds 的值，则表示在给节点添加了上述污点之后， Pod 还能继续在节点上运行的时间。 tolerations:- key:\"key1\"operator:\"Equal\"value:\"value1\"effect:\"NoExecute\"tolerationSeconds:3600 这表示如果这个 Pod 正在运行，同时一个匹配的污点被添加到其所在的节点， 那么 Pod 还将继续在节点上运行 3600 秒，然后被驱逐。 如果在此之前上述污点被删除了，则 Pod 不会被驱逐。 使用栗子 Example Use Cases 通过污点和容忍度，可以灵活地让 Pod 避开 某些节点或者将 Pod 从某些节点驱逐。下面是几个使用例子： 专用节点：如果您想将某些节点专门分配给特定的一组用户使用，您可以给这些节点添加一个污点，然后给这组用户的 Pod 添加一个相对应的 toleration。拥有上述容忍度的 Pod 就能够被分配到上述专用节点，同时也能够被分配到集群中的其它节点。如果您希望这些 Pod 只能被分配到上述专用节点，那么您还需要给这些专用节点另外添加一个和上述 污点类似的 label，同时 还要在上述准入控制器中给 Pod 增加节点亲和性要求上述 Pod 只能被分配到添加了对应标签的节点上。 配备了特殊硬件的节点：在部分节点配备了特殊硬件（比如 GPU）的集群中， 我们希望不需要这类硬件的 Pod 不要被分配到这些特殊节点，以便为后继需要这类硬件的 Pod 保留资源。 基于污点的驱逐： 这是在每个 Pod 中配置的在节点出现问题时的驱逐行为。 基于污点的驱逐 Taint based Evictions FEATURE STATE: Kubernetes v1.18 stable 污点的 effect 值 NoExecute会影响已经在节点上运行的 Pod： 如果 Pod 不能忍受 effect 值为 NoExecute 的污点，那么 Pod 将马上被驱逐 如果 Pod 能够忍受 effect 值为 NoExecute 的污点，但是在容忍度定义中没有指定 tolerationSeconds，则 Pod 还会一直在这个节点上运行。 如果 Pod 能够忍受 effect 值为 NoExecute 的污点，而且指定了 tolerationSeconds， 则 Pod 还能在这个节点上继续运行这个指定的时间长度。 当某种条件为真时，节点控制器会自动给节点添加一个污点。当前内置的污点包括： node.kubernetes.io/not-ready：节点未准备好。这相当于节点状态 Ready 的值为 \"False\"。 node.kubernetes.io/unreachable：节点控制器访问不到节点. 这相当于节点状态 Ready 的值为 \"Unknown\"。 node.kubernetes.io/out-of-disk：节点磁盘耗尽。 node.kubernetes.io/memory-pressure：节点存在内存压力。 node.kubernetes.io/disk-pressure：节点存在磁盘压力。 node.kubernetes.io/network-unavailable：节点网络不可用。 node.kubernetes.io/unschedulable: 节点不可调度。 node.cloudprovider.kubernetes.io/uninitialized：如果 kubelet 启动时指定了一个 \"外部\" 云平台驱动， 它将给当前节点添加一个污点将其标志为不可用。在 cloud-controller-manager 的一个控制器初始化这个节点后，kubelet 将删除这个污点。 在节点被驱逐时，节点控制器或者 kubelet 会添加带有 NoExecute 效应的相关污点。 如果异常状态恢复正常，kubelet 或节点控制器能够移除相关的污点。 为了保证由于节点问题引起的 Pod 驱逐 速率限制行为正常， 系统实际上会以限定速率的方式添加污点。在像主控节点与工作节点间通信中断等场景下， 这样做可以避免 Pod 被大量驱逐。 DaemonSet 中的 Pod 被创建时， 针对以下污点自动添加的 NoExecute 的容忍度将不会指定 tolerationSeconds： node.kubernetes.io/unreachable node.kubernetes.io/not-ready 这保证了出现上述问题时 DaemonSet 中的 Pod 永远不会被驱逐。 基于节点状态添加污点 Taint Nodes by Condition Node 生命周期控制器会自动创建与 Node 条件相对应的带有 NoSchedule 效应的污点。 同样，调度器不检查节点条件，而是检查节点污点。这确保了节点条件不会影响调度到节点上的内容。 用户可以通过添加适当的 Pod 容忍度来选择忽略某些 Node 的问题(表示为 Node 的调度条件)。 DaemonSet 控制器自动为所有守护进程添加如下 NoSchedule 容忍度以防 DaemonSet 崩溃： node.kubernetes.io/memory-pressure node.kubernetes.io/disk-pressure node.kubernetes.io/out-of-disk (只适合关键 Pod) node.kubernetes.io/unschedulable (1.10 或更高版本) node.kubernetes.io/network-unavailable (只适合主机网络配置) 添加上述容忍度确保了向后兼容，您也可以选择自由向 DaemonSet 添加容忍度。 ","date":"2018-06-26","objectID":"/kubernetes/:19:2","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"将Pod分配给节点 Assigning Pods to Nodes 你可以约束一个 Pod 只能在特定的 节点 上运行，或者优先运行在特定的节点上。推荐的方法是使用标签选择符(label selectors)。通常这样的约束不是必须的，因为调度器将自动进行合理的放置。 nodeSelector nodeSelector 是节点选择约束的最简单推荐形式。 内置的节点标签 built-in node labels 除了添加的标签外，节点还预先填充了一组标准标签。 这些标签有： kubernetes.io/hostname failure-domain.beta.kubernetes.io/zone failure-domain.beta.kubernetes.io/region topology.kubernetes.io/zone topology.kubernetes.io/region beta.kubernetes.io/instance-type node.kubernetes.io/instance-type kubernetes.io/os kubernetes.io/arch 节点隔离/限制 Node isolation restriction 向 Node 对象添加标签可以将 pod 定位到特定的节点或节点组。 这可以用来确保指定的 Pod 只能运行在具有一定隔离性，安全性或监管属性的节点上。 当为此目的使用标签时，强烈建议选择节点上的 kubelet 进程无法修改的标签键。 这可以防止受感染的节点使用其 kubelet 凭据在自己的 Node 对象上设置这些标签， 并影响调度器将工作负载调度到受感染的节点。 亲和性和反亲和性 Affinity and anti-affinity nodeSelector 提供了一种非常简单的方法来将 Pod 约束到具有特定标签的节点上。 亲和性/反亲和性功能极大地扩展了你可以表达约束的类型。 nodeName nodeName 是节点选择约束的最简单方法，但是由于其自身限制，通常不使用它。 ","date":"2018-06-26","objectID":"/kubernetes/:19:3","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"扩展资源的资源装箱 Resource Bin Packing for Extended Resources FEATURE STATE: Kubernetes 1.16 alpha 使用 RequestedToCapacityRatioResourceAllocation 优先级函数，可以将 kube-scheduler 配置为支持包含扩展资源在内的资源装箱操作。 优先级函数可用于根据自定义需求微调 kube-scheduler 。 ","date":"2018-06-26","objectID":"/kubernetes/:19:4","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"Pod开销 Pod Overhead FEATURE STATE: Kubernetes v1.18 beta 在节点上运行 Pod 时，Pod 本身占用大量系统资源。这些资源是运行 Pod 内容器所需资源的附加资源。 POD 开销 是一个特性，用于计算 Pod 基础设施在容器请求和限制之上消耗的资源。 在 Kubernetes 中，Pod 的开销是根据与 Pod 的 RuntimeClass 相关联的开销在 准入 时设置的。 如果启用了 Pod Overhead，在调度 Pod 时，除了考虑容器资源请求的总和外，还要考虑 Pod 开销。 类似地，kubelet 将在确定 Pod cgroups 的大小和执行 Pod 驱逐排序时也会考虑 Pod 开销。 ","date":"2018-06-26","objectID":"/kubernetes/:19:5","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"驱逐策略 Eviction Policy Kubelet 主动监测和防止 计算资源的全面短缺。在资源短缺时，kubelet 可以主动地结束一个或多个 Pod 以回收短缺的资源。 当 kubelet 结束一个 Pod 时，它将终止 Pod 中的所有容器，而 Pod 的 Phase 将变为 Failed。 如果被驱逐的 Pod 由 Deployment 管理，这个 Deployment 会创建另一个 Pod 给 Kubernetes 来调度。 ","date":"2018-06-26","objectID":"/kubernetes/:19:6","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"调度框架 Scheduling Framework FEATURE STATE: Kubernetes 1.15 alpha 调度框架是 Kubernetes Scheduler 的一种可插入架构，可以简化调度器的自定义。 它向现有的调度器增加了一组新的“插件” API。插件被编译到调度器程序中。 这些 API 允许大多数调度功能以插件的形式实现，同时使调度“核心”保持简单且可维护。 ","date":"2018-06-26","objectID":"/kubernetes/:19:7","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"调度器性能调优 Scheduler Performance Tuning FEATURE STATE: Kubernetes 1.14 beta 作为 kubernetes 集群的默认调度器， kube-scheduler 主要负责将 Pod 调度到集群的 Node 上。 在一个集群中，满足一个 Pod 调度请求的所有 Node 称之为 可调度 Node。 调度器先在集群中找到一个 Pod 的可调度 Node，然后根据一系列函数对这些可调度 Node 打分， 之后选出其中得分最高的 Node 来运行 Pod。 最后，调度器将这个调度决定告知 kube-apiserver，这个过程叫做 绑定（Binding）。 在大规模集群中，你可以调节调度器的表现来平衡调度的延迟（新 Pod 快速就位） 和精度（调度器很少做出糟糕的放置决策）。 你可以通过设置 kube-scheduler 的 percentageOfNodesToScore 来配置这个调优设置。 这个 KubeSchedulerConfiguration 设置决定了调度集群中节点的阈值。 ","date":"2018-06-26","objectID":"/kubernetes/:19:8","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"集群管理 Cluster Administration 并非所有发行版都是被积极维护的。 请选择使用最近 Kubernetes 版本测试过的发行版。 ","date":"2018-06-26","objectID":"/kubernetes/:20:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"证书 Certificates 当使用客户端证书进行认证时，用户可以使用现有部署脚本，或者通过 easyrsa、openssl 或 cfssl 手动生成证书。 ","date":"2018-06-26","objectID":"/kubernetes/:20:1","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"管理资源 Managing Resources 你已经部署了应用并通过服务暴露它。然后呢？ Kubernetes 提供了一些工具来帮助管理你的应用部署，包括扩缩容和更新。 我们将更深入讨论的特性包括 配置文件和 标签。 # yaml这种使用---分隔多个资源 # 一些命令 kubectl apply -f xxx.yaml kubectl apply -f xxx/dir --recursive kubectl delete deployment,services -l app=xxx kubectl label pods -l app=nginx author=xxx kubectl annotate pods my-nginx-v4-9gw19 description='my frontend running nginx' kubectl scale deployment/my-nginx --replicas=1 kubectl autoscale deployment/my-nginx --min=1 --max=3 kubectl edit xxx ","date":"2018-06-26","objectID":"/kubernetes/:20:2","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"集群网络系统 Cluster Networking 集群网络系统是 Kubernetes 的核心部分，但是想要准确了解它的工作原理可是个不小的挑战。 下面列出的是网络系统的的四个主要问题： 高度耦合的容器间通信 Pod 间通信 Pod 和服务间通信 外部和服务间通信 Kubernetes网络模型 The Kubernetes network model 每一个 Pod 都有它自己的IP地址，这就意味着你不需要显式地在每个 Pod 之间创建链接， 你几乎不需要处理容器端口到主机端口之间的映射。 Kubernetes 对所有网络设施的实施，都需要满足以下的基本要求（除非有设置一些特定的网络分段策略）： 节点上的 Pod 可以不通过 NAT 和其他任何节点上的 Pod 通信 节点上的代理（比如：系统守护进程、kubelet）可以和节点上的所有Pod通信 那些运行在节点的主机网络(host network)里的 Pod 可以不通过 NAT 和所有节点上的 Pod 通信 Kubernetes 的 IP 地址存在于 Pod 范围内 - 容器共享它们的网络命名空间 - 包括它们的 IP 地址和 MAC 地址。 这就意味着 Pod 内的容器都可以通过 localhost 到达各个端口。 这也意味着 Pod 内的容器都需要相互协调端口的使用，但是这和虚拟机中的进程似乎没有什么不同， 这也被称为一个 Pod 一个 IP模型。 如何实现k8s的网络模型 How to implement the Kubernetes networking model 有很多种方式可以实现这种网络模型。以下的网络技术是按照首字母排序，顺序本身并无其他意义。 ACI Antrea Apstra AOS AWS VPC CNI Azure CNI Big Cloud Fabric Calico Cilium CNI-Genie cni-ipvlan-vpc-k8s Coil Contiv Tungsten Fabric DANM Flannel Jaguar Weave Net … ","date":"2018-06-26","objectID":"/kubernetes/:20:3","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"k8s系统组件指标 Metrics For Kubernetes System Components 系统组件指标可以更好地了解系统内部发生的情况。指标对于构建仪表板和告警特别有用。Kubernetes 组件以 Prometheus 格式 生成度量值。 k8s中的指标，在大多数情况下，可以在 HTTP 服务器的 /metrics 端点上访问度量值。 组件: kube-controller-manager, kube-proxy, kube-apiserver, kube-scheduler, kubelet 请注意，kubelet 还会在 /metrics/cadvisor， /metrics/resource 和 /metrics/probes 端点中公开度量值。这些度量值的生命周期各不相同。 ","date":"2018-06-26","objectID":"/kubernetes/:20:4","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"日志架构 Logging Architecture 针对容器化应用，最简单且最广泛采用的日志记录方式就是写入标准输出和标准错误流。 但是，由容器引擎或运行时提供的原生功能通常不足以构成完整的日志记录方案。 例如，如果发生容器崩溃、Pod 被逐出或节点宕机等情况，你可能想访问应用日志。 在集群中，日志应该具有独立的存储和生命周期，与节点、Pod 或容器的生命周期相独立。 这个概念叫 集群级的日志 。 集群级日志架构需要一个独立的后端用来存储、分析和查询日志。 Kubernetes 并不为日志数据提供原生的存储解决方案。 相反，有很多现成的日志方案可以集成到 Kubernetes 中。 ","date":"2018-06-26","objectID":"/kubernetes/:20:5","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"系统日志 System Logs 系统组件的日志记录集群中发生的事件，这对于调试非常有用。 ","date":"2018-06-26","objectID":"/kubernetes/:20:6","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"容器镜像的垃圾回收 Garbage collection for container images 垃圾回收是 kubelet 的一个有用功能，它将清理未使用的镜像和容器。 Kubelet 将每分钟对容器执行一次垃圾回收，每五分钟对镜像执行一次垃圾回收。 不建议使用外部垃圾收集工具，因为这些工具可能会删除原本期望存在的容器进而破坏 kubelet 的行为。 容器回收 Container Collection 容器垃圾回收策略考虑三个用户定义变量。 MinAge 是容器可以被执行垃圾回收的最小生命周期。 MaxPerPodContainer 是每个 pod 内允许存在的死亡容器的最大数量。 MaxContainers 是全部死亡容器的最大数量。 可以分别独立地通过将 MinAge 设置为 0，以及将 MaxPerPodContainer 和 MaxContainers 设置为小于 0 来禁用这些变量。 kubelet 将处理无法辨识的、已删除的以及超出前面提到的参数所设置范围的容器。 最老的容器通常会先被移除。 不被 kubelet 管理的容器不受容器垃圾回收的约束。 镜像回收 Image Collection Kubernetes 借助于 cadvisor 通过 imageManager 来管理所有镜像的生命周期。 镜像垃圾回收策略只考虑两个因素：HighThresholdPercent 和 LowThresholdPercent。 磁盘使用率超过上限阈值（HighThresholdPercent）将触发垃圾回收。 垃圾回收将删除最近最少使用的镜像，直到磁盘使用率满足下限阈值（LowThresholdPercent）。 ","date":"2018-06-26","objectID":"/kubernetes/:20:7","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"k8s中的代理 Proxies in Kubernetes 用户在使用 Kubernetes 的过程中可能遇到几种不同的代理： kubectl proxy apiserver proxy kube proxy apiserver之前的代理 外部服务的云负载均衡器 ","date":"2018-06-26","objectID":"/kubernetes/:20:8","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"api优先级和公平性 API Priority and Fairness FEATURE STATE: Kubernetes v1.20 beta 对于集群管理员来说，控制 Kubernetes API 服务器在过载情况下的行为是一项关键任务。 kube-apiserver 有一些控件（例如：命令行标志 --max-requests-inflight 和 --max-mutating-requests-inflight）, 可以限制将要接受的未处理的请求，从而防止过量请求入站，潜在导致 API 服务器崩溃。 但是这些标志不足以保证在高流量期间，最重要的请求仍能被服务器接受。 API 优先级和公平性是一种替代方案，可提升上述最大并发限制。 APF 以更细粒度的方式对请求进行分类和隔离。 它还引入了空间有限的排队机制，因此在非常短暂的突发情况下，API 服务器不会拒绝任何请求。 通过使用公平排队技术从队列中分发请求，这样， 一个行为不佳的 控制器 就不会饿死其他控制器（即使优先级相同）。 ","date":"2018-06-26","objectID":"/kubernetes/:20:9","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"安装扩展 Installing Addons Add-ons 扩展了 Kubernetes 的功能。 ","date":"2018-06-26","objectID":"/kubernetes/:20:10","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"扩展k8s Extending Kubernetes Kubernetes 是高度可配置且可扩展的。因此，大多数情况下，你不需要 派生自己的 Kubernetes 副本或者向项目代码提交补丁。 ","date":"2018-06-26","objectID":"/kubernetes/:21:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"扩展k8s集群 Extending your Kubernetes Cluster 定制化的方法主要可分为 配置（Configuration） 和 扩展（Extensions） 两种。 前者主要涉及改变参数标志、本地配置文件或者 API 资源； 后者则需要额外运行一些程序或服务。 本文主要关注扩展。 配置 Configuration 包括kubelet, kube-apiserver, kube-controller-manager, kube-scheduler的配置文件和参数标志。 扩展 Extensions 扩展是一些扩充 Kubernetes 能力并与之深度集成的软件组件。 它们调整 Kubernetes 的工作方式使之支持新的类型和新的硬件种类。 大多数集群管理员会使用一种托管的 Kubernetes 服务或者其某种发行版本。 因此，大多数 Kubernetes 用户不需要安装扩展， 至于需要自己编写新的扩展的情况就更少了。 扩展模式 Extension Patterns kubernetes从设计上即支持通过编写客户端程序来将其操作自动化。 任何能够对 Kubernetes API 发出读写指令的程序都可以提供有用的自动化能力。 自动化组件可以运行在集群上，也可以运行在集群之外。 编写客户端程序有一种特殊的 Controller（控制器）模式，能够与 Kubernetes 很好地 协同工作。控制器是 Kubernetes 的客户端。当 Kubernetes 充当客户端，调用某远程服务时，对应 的远程组件称作Webhook。 远程服务称作Webhook 后端。 与控制器模式相似，Webhook 也会在整个架构中引入新的失效点（Point of Failure）。 在 Webhook 模式中，Kubernetes 向远程服务发起网络请求。 在可执行文件插件（Binary Plugin）模式中，Kubernetes 执行某个可执行文件（程序）。 下图展示了这些扩展如何与k8s控制面板交互： 扩展点 Extension Points 下图显示k8s系统中的扩展点： 用户通常使用kubectl与k8s api交互。 kubectl 插件能够扩展 kubectl 程序的行为。 API 服务器处理所有请求。API 服务器中的几种扩展点能够使用户对请求执行身份认证、 基于其内容阻止请求、编辑请求内容、处理删除操作等等。 API 服务器向外提供不同类型的资源（resources）。 Kubernetes 调度器负责决定 Pod 要放置到哪些节点上执行。 Kubernetes 中的很多行为都是通过称为控制器（Controllers）的程序来实现的，这些程序也都是 API 服务器 的客户端。控制器常常与自定义资源结合使用。 组件 kubelet 运行在各个节点上，帮助 Pod 展现为虚拟的服务器并在集群网络中拥有自己的 IP。 网络插件使得 Kubernetes 能够采用 不同实现技术来连接 Pod 网络。 组件 kubelet 也会为容器增加或解除存储卷的挂载。 如果你无法确定从何处入手，下面的流程图可能对你有些帮助。 注意，某些方案可能需要同时采用几种类型的扩展。 API扩展 API Extensions 用户定义的类型(User-Defined Types) 如果你想要定义新的控制器、应用配置对象或者其他声明式 API，并且使用 Kubernetes 工具（如 kubectl）来管理它们，可以考虑向 Kubernetes 添加自定义资源。不要使用自定义资源来充当应用、用户或者监控数据的数据存储。 结合使用新API与自动化组件(Combining New APIs with Automation) 自定义资源 API 与控制回路的组合称作 Operator 模式。 Operator 模式用来管理特定的、通常是有状态的应用。 这些自定义 API 和控制回路也可用来控制其他资源，如存储或策略。 更改内置资源(Changing Built-in Resources) 当你通过添加自定义资源来扩展 Kubernetes 时，所添加的资源通常会被放在一个新的 API 组中。你不可以替换或更改现有的 API 组。 API访问扩展(API Access Extensions) 当请求到达 Kubernetes API 服务器时，首先要经过身份认证，之后是鉴权操作， 再之后要经过若干类型的准入控制器的检查。Kubernetes 提供若干内置的身份认证方法。 它也可以运行在某中身份认证代理的后面，并且可以将来自鉴权头部的令牌发送到 某个远程服务（Webhook）来执行验证操作。 身份认证(Authentication) 身份认证负责将所有请求中 的头部或证书映射到发出该请求的客户端的用户名。 鉴权(Authorization) 鉴权操作负责确定特定的用户 是否可以读、写 API 资源或对其执行其他操作。 此操作仅在整个资源集合的层面进行。 换言之，它不会基于对象的特定字段作出不同的判决。 如果内置的鉴权选项无法满足你的需要，你可以使用 鉴权 Webhook来调用用户提供 的代码，执行定制的鉴权操作。 动态准入控制(Dynamic Admission Control) 请求的鉴权操作结束之后，如果请求的是写操作，还会经过 准入控制处理步骤。 基础设施扩展 Infrastructure Extensions 存储插件(Storage Plugins) 设备插件(Device Plugins) 网络插件(Network Plugins) 调度器扩展(Scheduler Extensions) ","date":"2018-06-26","objectID":"/kubernetes/:21:1","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"扩展k8s api Extending the Kubernetes API 定制资源 Custom Resources 定制资源（Custom Resource） 是对 Kubernetes API 的扩展。 资源（Resource） 是 Kubernetes API 中的一个端点， 其中存储的是某个类别的 API 对象 的一个集合。 例如内置的 pods 资源包含一组 Pod 对象。 定制资源（Custom Resource） 是对 Kubernetes API 的扩展，不一定在默认的 Kubernetes 安装中就可用。定制资源所代表的是对特定 Kubernetes 安装的一种定制。 不过，很多 Kubernetes 核心功能现在都用定制资源来实现，这使得 Kubernetes 更加模块化。 定制资源可以通过动态注册的方式在运行中的集群内或出现或消失，集群管理员可以独立于集群 更新定制资源。一旦某定制资源被安装，用户可以使用 kubectl 来创建和访问其中的对象。 定制控制器 Custom controllers 就定制资源本身而言，它只能用来存取结构化的数据。 当你将定制资源与 定制控制器（Custom Controller） 相结合时，定制资源就能够 提供真正的 声明式 API（Declarative API）。 使用声明式 API， 你可以 声明 或者设定你的资源的期望状态，并尝试让 Kubernetes 对象的当前状态 同步到其期望状态。控制器负责将结构化的数据解释为用户所期望状态的记录，并 持续地维护该状态。 你可以在一个运行中的集群上部署和更新定制控制器，这类操作与集群的生命周期无关。 定制控制器可以用于任何类别的资源，不过它们与定制资源结合起来时最为有效。 Operator 模式就是将定制资源 与定制控制器相结合的。你可以使用定制控制器来将特定于某应用的领域知识组织 起来，以编码的形式构造对 Kubernetes API 的扩展。 声明式APIs Declarative APIs 典型地，在声明式API中： 你的API包含相对而言为数不多的、尺寸较小的对象 对象定义了应用或者基础设施的配置信息 对象更新操作频率较低 通常需要人来读取或写入对象 对象的主要操作是 CRUD 风格的 需要跨对象的事务支持，API对象代表的是期望状态而非确切实际状态 命令式API与声明式有所不同： 客户端发出做这个操作的指令，之后在该操作结束时获得同步响应 客户端发出做这个操作的指令，并获得一个操作ID，之后需要检查一个操作对象来判断请求是否成功完成 将你的 API 类比为远程过程调用 直接存储大量数据 需要较高的访问带宽 存储有应用来处理的最终用户数据 在对象上执行的常规操作并非 CRUD 风格 API 不太容易用对象来建模 你决定使用操作 ID 或者操作对象来表现悬决的操作 ConfigMap还是定制资源 configMap or a custom resource 以下条件大多数都满足，应该使用CRD或聚合API： 你希望使用 Kubernetes 客户端库和 CLI 来创建和更改新的资源 你希望 kubectl 能够直接支持你的资源 你希望构造新的自动化机制，监测新对象上的更新事件，并对其他对象执行 CRUD 操作，或者监测后者更新前者 你希望编写自动化组件来处理对对象的更新 你希望使用 Kubernetes API 对诸如spec等字段的约定 你希望对象是对一组受控资源的抽象，或者对其他资源的归纳提炼 添加定制资源 Adding custom resources Kubernetes 提供了两种方式供你向集群中添加定制资源： CRD，相对简单，创建CRD可以不必编程 API聚合，需要编程，但支持对 API 行为进行更多的控制 Kubernetes 提供这两种选项以满足不同用户的需求，这样就既不会牺牲易用性也不会牺牲灵活性。 CRD CustomResourceDefinition API 资源允许你定义定制资源。 定义 CRD 对象的操作会使用你所设定的名字和模式定义（Schema）创建一个新的定制资源， Kubernetes API 负责为你的定制资源提供存储和访问服务。 CRD 对象的名称必须是合法的 DNS 子域名。 API聚合 API server aggregation 通常，Kubernetes API 中的每个都需要处理 REST 请求和管理对象持久性存储的代码。 聚合层（Aggregation Layer） 使得你可以通过编写和部署你自己的独立的 API 服务器来为定制资源提供特殊的实现。 主 API 服务器将针对你要处理的定制资源的请求全部委托给你来处理，同时将这些资源 提供给其所有客户。 准备安装定制资源 在向集群添加定制资源之前，有些事情需要搞清楚。 第三方代码和新的失效点的问题 存储 身份认证、鉴权授权和审计 访问定制资源 Kubernetes 客户端库可用来访问定制资源。 并非所有客户端库都支持定制资源。Go 和 Python 客户端库是支持的。 当添加了新的定制资源后，可用以下方式访问它们： kubectl k8s动态库 你所编写的REST客户端 k8s客户端工具所生成的客户端 通过聚合层扩展k8s api Extending the Kubernetes API with the aggregation layer 使用聚合层，用户可以通过额外的 API 扩展 Kubernetes， 而不局限于 Kubernetes 核心 API 提供的功能。 ","date":"2018-06-26","objectID":"/kubernetes/:21:2","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"Operator Operator 是 Kubernetes 的扩展软件，它利用 定制资源 管理应用及其组件。 Operator 遵循 Kubernetes 的理念，特别是在控制器方面。 在 Kubernetes 上运行工作负载的人们都喜欢通过自动化来处理重复的任务。 Operator 模式会封装你编写的（Kubernetes 本身提供功能以外的）任务自动化代码。 k8s上的Operator Kubernetes 为自动化而生。无需任何修改，你即可以从 Kubernetes 核心中获得许多内置的自动化功能。 你可以使用 Kubernetes 自动化部署和运行工作负载， 甚至 可以自动化 Kubernetes 自身。 Kubernetes 控制器 使你无需修改 Kubernetes 自身的代码，即可以扩展集群的行为。 Operator 是 Kubernetes API 的客户端，充当 定制资源 的控制器。 示例 使用Operator可以自动化的事情包括： 按需部署应用 获取/还原应用状态的备份 处理应用代码的升级以及相关改动 发布一个 service，要求不支持 Kubernetes API 的应用也能发现它 模拟整个或部分集群中的故障以测试其稳定性 在没有内部成员选举程序的情况下，为分布式应用选择领导角色 部署Operator 部署 Operator 最常见的方法是将自定义资源及其关联的控制器添加到你的集群中。 跟运行容器化应用一样，控制器通常会运行在控制平面之外。 使用Operator 部署 Operator 后，你可以对 Operator 所使用的资源执行添加、修改或删除操作。 编写Operator 如果生态系统中没可以实现你目标的 Operator，你可以自己编写代码。 ","date":"2018-06-26","objectID":"/kubernetes/:21:3","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"计算、存储和网络扩展 Compute, Storage, and Networking Extensions 网络插件 Network Plugins k8s中的网络插件有几种类型： CNI插件：遵守容器网络接口（Container Network Interface，CNI） 规范，其设计上偏重互操作性 kubenet插件：使用 bridge 和 host-local CNI 插件实现了基本的 cbr0 设备插件 Device Plugins 使用 Kubernetes 设备插件框架来实现适用于 GPU、NIC、FPGA、InfiniBand 以及类似的需要特定于供应商设置的资源的插件。 Kubernetes 提供了一个 设备插件框架，你可以用它来将系统硬件资源发布到 Kubelet。 ","date":"2018-06-26","objectID":"/kubernetes/:21:4","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"服务目录 Service Catalog 服务目录是一种扩展 API，它能让 Kubernetes 集群中运行的应用易于使用外部托管的的软件服务，例如云供应商提供的数据仓库服务。 服务目录可以检索、供应、和绑定由 服务代理人（Service Brokers） 提供的外部托管服务（Managed Services）， 而无需知道那些服务具体是怎样创建和托管的。 示例 应用开发人员， 希望使用消息队列，作为其在 Kubernetes 集群中运行的应用程序的一部分。 但是，他们不想承受构造这种服务的开销，也不想自行管理。 幸运的是，有一家云服务提供商通过其服务代理以托管服务的形式提供消息队列服务。 集群操作员可以设置服务目录并使用它与云服务提供商的服务代理通信，进而部署消息队列服务的实例 并使其对 Kubernetes 中的应用程序可用。 应用开发者于是可以不关心消息队列的实现细节，也不用对其进行管理。 他们的应用程序可以简单的将其作为服务使用。 架构 服务目录使用Open Service Broker API 与服务代理进行通信，并作为 Kubernetes API 服务器的中介，以便协商启动部署和获取 应用程序使用托管服务时必须的凭据。 服务目录实现为一个扩展 API 服务器和一个控制器，使用 Etcd 提供存储。 \r\r \r教程 Tutorials 教程展示了如何实现比单个任务更大的目标(task)。 \r","date":"2018-06-26","objectID":"/kubernetes/:21:5","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"一个栗子 栗子里面包含一个Service和Deployment，请一定要注意yaml的语法格式，不使用-的话可能会报错。 很多k8s配置我们只需要在云界面上小配置，看它生成的YAML文件如何，之后再进行相应修改即可。 #注意yaml语法错误 apiVersion: extensions/v1beta1 kind: Deployment metadata: name: nginx-deployment-test namespace: default labels: k8s-app: nginx env: test annotations: des: A k8s-deployment test author: Zhang21 date: 2018-09-13 spec: replicas: 1 selector: matchLabels: k8s-app: nginx strategy: type: RollingUpdate rollingUpdate: maxUnavailable: 50% maxSurge: 50% template: metadata: labels: k8s-app: nginx spec: dnsPolicy: ClusterFirst restartPolicy: Always volumes: - name: test01 emptyDir: {} - name: test02 hostPath: path: /tmp/k8s/volume/test02 containers: - name: nginx image: nginx:1.12.2 imagePullPolicy: Always #特权容器 securityContext: privileged: true workingDir: /usr/share/nginx/html ports: - protocol: TCP containerPort: 80 readinessProbe: httpGet: path: / port: 80 scheme: HTTP initialDelaySeconds: 10 periodSeconds: 5 livenessProbe: httpGet: path: / port: 80 scheme: HTTP #60s内，Server未启动则重启容器 initialDelaySeconds: 60 periodSeconds: 10 env: - name: AUTHOR value: Zhang21 - name: EMAIL value: me@zhang21.cn volumeMounts: - name: test01 mountPath: /usr/share/nginx/html/test01 - name: test02 mountPath: /usr/share/nginx/html/test02 resources: requests: cpu: 100m memory: 100Mi limits: cpu: 0.3 memory: 300Mi imagePullSecrets: - name: docker-secret --- apiVersion: v1 kind: Service metadata: name: nginx-service-test namespace: default labels: k8s-app: nginx annotations: des: A k8s Service test author: Zhang21 date: 2018-09-13 spec: #记得指定应用，不然服务无法找到后端端点和容器组 selector: k8s-app: nginx type: NodePort ports: - name: http nodePort: 31234 #The range of valid ports is 30000-32767 protocol: TCP port: 80 targetPort: 80 status: loadBalancer: {} # #ClusterIP #spec: # ports: # - name: http # protocol: TCP # port: 80 # targetPort: 80 # selector: # k8s-app: nginx # type: ClusterIP # # #spec: # ports: # - name: http # protocol: TCP # port: 80 # targetPort: 80 # selector: # k8s-app: nginx # type: LoadBalancer # loadBalancerIP: 1.2.3.4 执行: kubectl apply -f ./nginx.yaml #apply可修改后更新 kubectl apply -f ./nginx.yaml #之后在dashboard中查看成功与否 #访问master 31234 port curl master:31234 \r\r","date":"2018-06-26","objectID":"/kubernetes/:22:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"k8s基本 \r","date":"2018-06-26","objectID":"/kubernetes/:23:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"综述 本教程提供了Kubernetes集群编排系统基础知识的介绍。 你将学到： 在集群上部署容器化服务 伸缩部署 使用新软件版本更新容器化应用程序 调试容器化应用程序 k8s能为你做什么？ 容器化有助于打包软件以实现这些目标，是应用程序能够以简单快速的方式发布和更新，而无需停机。k8s可帮助你确保这些容器化应用程序随时随地运行，并帮助它们找到运行所需的资源。 k8s 基础模块 创建(create)一个k8s集群 部署(deploy)应用程序 探索(explore)应用程序 公开(expose)展示应用程序 伸缩(scale)应用程序 升级(update)应用程序 \r\r","date":"2018-06-26","objectID":"/kubernetes/:23:1","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"创建集群 Create a Cluseter 详情见安装部分。 \r\r","date":"2018-06-26","objectID":"/kubernetes/:23:2","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"部署应用程序 Deploy an APP \r使用kubectl创建部署 Using kubectl to create a Deployment 目标： 了解应用程序部署 在k8s上使用kubectl部署你的第一个应用程序 k8s Deployments 一旦运行了k8s集群，就可在其上部署容器化应用程序。为此，你需要创建Kubernetes Deployment configuration。它指示k8s 如何创建和更新应用程序实例。创建部署后，k8s master将应用程序实例调度到各个node上。 创建应用程序实例后，Kubernetes Deployment Controller会持续监控这些实例。如果主机节点上的实例关闭或删除，Deployment Controller会替换它。这提供了一种自我修复(self-healing)机制来解决机器故障或维护。 部署应用程序 可使用kubectl(使用k8s api与集群交互)来创建和管理Deployment。下面有一些关于使用kubectl在k8s集群上创建和管理Deployment的基础命令。 创建部署时，你需要指定应用程序的容器镜像(image)，以及要运行的副本数(replicas)。你可在以后改变这些信息来更新你的部署。 栗子： 第一个部署，k8s使用一个Docker容器的Node.js应用程序包。 kubectl version #client #server kubectl get nodes #创建名为k8s-bootcamp的deployment kubectl run kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1 --port=8080 #这是国内镜像: docker.io/jocatalin/kubernetes-bootcamp:v1 kubectl get deployments NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE kubenetes-bootcamp 1 1 1 1 1h #表示 希望副本数，当前副本数，最新副本数，可用副本数 #由于pod被封装在集群私网，没有对外开放 #proxy将通信转发到集群内私网 kubectl proxy curl http://localhost:8081/version curl http://localhost:8001/api/v1/namespaces/default/pods/$POD_NAME/proxy/ #Hello Kubernetes bootcamp! 此处我遇到一个错误，replicats unavailable: 原因是拉取的镜像在谷歌云上，无法访问\u003cgcr.io\u003e，拉取失败所以导致部署失败。 gcr(google container Registry) #查看部署信息 kubectl get deployment kubernetes-bootcamp -o yaml message: 'unable to create pods: No API token found for service account \"default\", retry after the token is automatically created and added to the service account' reason: FailedCreate status: \"True\" type: ReplicaFailure kubectl get deployments NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE kubernetes-bootcamp 1 0 0 0 33m kubectl describe deployments kubernetes-bootcamp Replicas: 1 desired | 0 updated | 0 total | 0 available | 1 unavailable StrategyType: RollingUpdate ReplicaFailure True FailedCreate 针对**unable to create pods: No API token found for service account “default”**这个问题，需要修改kube-apiserver配置文件： #去掉 KUBE_ADMISSION_CONTROL中的SecurityContextDeny,ServiceAccount KUBE_ADMISSION_CONTROL=\"--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota\" #重启kube-apiserver systemctl restart kube-apiserver #之后查看副本数就正常了 kubectl get deployments NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE kubernetes-bootcamp 1 1 1 0 8m #这里available还是0 kubectl get pods NAME READY STATUS RESTARTS AGE kubernetes-bootcamp-390780338-6x48n 0/1 ContainerCreating 0 21h #pod处于创建状态 #查看详情 kubectl describe pods #错误信息 Warning FailedSync 4m (x258 over 21h) kubelet, 192.168.31.159 Error syncing pod, skipping: failed to \"StartContainer\" for \"POD\" with ErrImagePull: \"image pull failed for registry.access.redhat.com/rhel7/pod-infrastructure:latest, this may be because there are no credentials on this request. details: (open /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt: no such file or directory)\" Warning FailedSync 9s (x5728 over 21h) kubelet, 192.168.31.159 Error syncing pod, skipping: failed to \"StartContainer\" for \"POD\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.access.redhat.com/rhel7/pod-infrastructure:latest\\\"\" #在node上查看此文件，发现它指向了一个空链接 #并不存在/etc/rhsm目录 ll /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt lrwxrwxrwx. 1 root root 27 7月 16 16:58 /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt -\u003e /etc/rhsm/ca/redhat-uep.pem #在node安装此rhsm yum search rhsm #python-rhsm-certificates.x86_64 #python-rhsm.x86_64 yum install -y python-rhsm.x86_64 python-rhsm-certificates.x86_64 #之后在node上手动拉取下image便可看到pod正常运行 \r\r","date":"2018-06-26","objectID":"/kubernetes/:23:3","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"探索应用程序 Explore Your App \r查看Pods和Nodes 目标： 了解k8s Pods 了解k8s Nodes 部署应用的故障解决(troubleshoot) k8s Pods 当你创建一个部署时，k8s创建了一个pod来托管你的应用程序实例。pod是k8s的一个抽象，表示一组(一个/多个)应用程序容器，以及这些容器的共享资源。 pod有一个唯一的IP地址，甚至是同一节点上的pod。pod中的容器共享IP地址和端口，始终位于同一位置并共同调度，并在同一节点上共享上下文中运行。 这些资源包括： 共享存储(volumes) 网络(唯一的集群内ip) 运行容器的相关信息 Nodes pod总是运行在node上，一个node上可运行多个pod。每个node由master管理，master自动处理在node上调度pod。 node至少运行如下组件： kubelet container runtime(如docker) Troubleshooting with kubectl 最常用的kubectl命令： #列出资源 kubectl get #kubectl get nodes #某个资源的详细信息 kubectl describe #kubectl describe deployments kubernetes-bootcamp #pod中容器日志 kubectl logs #kubectl logs $pod --since=1h #在pod的容器执行命令 kubectl exec #kubectl ecec $pod env #kubectl exec -it $pod /bin/bash \r\r","date":"2018-06-26","objectID":"/kubernetes/:23:4","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"公开展示应用程序 Expose Your App Publicly \r使用服务来展示应用程序 Using a Service to Expose Your App 目标： 了解k8s中的服务(service) 理解labels和LabelSelector对象如何关联服务 使用服务将应用程序展示在集群外部 k8s Service 事实上，pods有一个生命周期。当工作node死亡，node上运行的pods也会丢失。ReplicationController可以通过创建新的Pod来动态地将集群驱动会所需状态，以使应用程序保持运行。 k8s的服务是一个抽象概念，它定义了一组逻辑Pod和一个访问pods的策略。服务使用YAML或JSON来定义。由一组pods所构成的服务通常由LabelSelector来确定。 尽管每个Pod都有一个唯一的IP地址，但如果没有服务，这些IP就不会在集群外公开。 通过指定ServeceSpec中的type，可以不同方式公开服务: ClusterIP(默认方式) 在集群内部IP公开服务，只可内部访问 NodePort 使用NAT在集群的指定节点上公开服务 LoadBalancer 创建一个外部负载均衡器，并给服务分配一个外部IP ExternalName 通过返回带有名称的CNAME(k8s-dns)记录，使用任意名称公开服务 Services和Labels 服务使用labels和selectors匹配一组pod这是一个允许对k8s的对象进行逻辑操作的分组原语。 Label是附件到对象的键/值对，随时随地可修改。有多种方式可使用： 指定用于开发(development)、测试(test)、生产(procuct)的对象 嵌入版本tag 使用tag对对象进行分类 栗子： kubectl get pods #NAME READY STATUS RESTARTS AGE #kubernetes-bootcamp-390780338-6x48n 1/1 Running 0 22h kubectl get services #NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE #kubernetes ClusterIP 10.254.0.1 \u003cnone\u003e 443/TCP 1d #公开展示应用程序 kubectl expose deployment/kubernetes-bootcamp --type=\"NodePort\" --port 8080 #service \"kubernetes-bootcamp\" exposed kubectl get services #NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE #kubernetes ClusterIP 10.254.0.1 \u003cnone\u003e 443/TCP 1d #kubernetes-bootcamp NodePort 10.254.11.76 \u003cnone\u003e 8080:31514/TCP 2m kubectl describe services/kubernetes-bootcamp kubectl describe deployment #Labels: run=kubernetes-bootcamp #使用label查询 kubectl get pods -l run=kubernetes-bootcamp kubectl get services -l run=kubernetes-bootcamp #使用label删除 kubectl delete service -l run=kubernetes-bootcamp kubectl describe pods kubernetes-bootcamp-390780338-6x48n kubectl exec -it kubernetes-bootcamp-390780338-6x48n /bin/bash \r\r","date":"2018-06-26","objectID":"/kubernetes/:23:5","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"扩展应用程序 Scale Your App Running Multiple Instances of Your App 目标： 使用kubectl伸缩应用程序 伸缩应用程序 前面通过部署创建的服务仅有一个pod，当遇到流量激增，我们便需要扩展应用程序。 通过更改部署中的副本数来完成扩展。 扩展部署将确保使用可用资源(available resource)创建新的pod并将其调度到node。k8s支持Pod的自动伸缩，缩放到0(也就是没有pod)也是可能的，它将终止指定部署的所有Pod。 对应用程序运行多个实例需要一种方法将流量分配给所有这些实例。服务有集成的负载均衡器(load-blancer)，可将网络流量分配到公开部署的所有Pod。服务将使用endpoint持续监控运行的Pod，以确保网络流量发送到可用的Pods。 一旦运行的应用程序有了多个实例，你就可以在不停机(downtime)的情况下执行滚动更新(rolling update)。 kubectl get deployments #1个 #扩展实例 kubectl scale deployments/kubernetes-bootcamp --replicas=4 #deployment.extensions \"kubernetes-bootcamp\" scaled kubectl get deployments #4个 kubectl get pods -o wide #4个 kubectl describe deployment/kubernetes-bootcamp kubectl describe services/kubernetes-bootcamp #缩放实例 kubectl scale deployments/kubernetes-bootcamp --replicas=2 #deployment.extensions \"kubernetes-bootcamp\" scaled kubectl get deployments #2个 #有两个pods正在关闭中 kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE kubernetes-bootcamp-390780338-1zgvs 1/1 Terminating 0 7m 10.254.76.5 192.168.31.159 kubernetes-bootcamp-390780338-6x48n 1/1 Running 0 2d 10.254.76.2 192.168.31.159 kubernetes-bootcamp-390780338-bqztg 1/1 Running 0 7m 10.254.76.4 192.168.31.159 kubernetes-bootcamp-390780338-hkwfd 1/1 Terminating 0 7m 10.254.76.3 192.168.31.159 #关闭完成 kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE kubernetes-bootcamp-390780338-6x48n 1/1 Running 0 2d 10.254.76.2 192.168.31.159 kubernetes-bootcamp-390780338-bqztg 1/1 Running 0 15m 10.254.76.4 192.168.31.159 \r\r","date":"2018-06-26","objectID":"/kubernetes/:23:6","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"升级应用程序 Update your App Performing a Rolling Update 目标： 使用kubectl执行滚动升级 滚动更新 用户希望应用程序始终可用，可发人员可能会多次部署新版本应用程序。在k8s中，这都可以通过滚动更新(rolling update)完成。 滚动更新允许通过使用新的实例逐步更新Pod来实现部署的更新，而不需停机(downtime)。新的Pod将在具有可用资源的node上进行调度。 在k8s中，更新是版本化的，任何部署更新都可以恢复到以前的版本。 与应用程序扩展类似，服务在更新期间仅会将流量负载均衡到可用的Pod(应用实例)。 滚动更新允许以下操作： 将应用程序从一个环境推到另一个环境 回滚(rollback)到之前的版本 无需停机的持续集成(CI)和持续交付(CD) kubectl get deployments kubectl get pods #2个 #更新镜像 kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=docker.io/jocatalin/kubernetes-bootcamp:v2 deployment.apps \"kubernetes-bootcamp\" image updated # kubectl get pods NAME READY STATUS RESTARTS AGE kubernetes-bootcamp-390780338-6x48n 1/1 Terminating 0 3d kubernetes-bootcamp-390780338-bqztg 1/1 Terminating 0 38m kubernetes-bootcamp-472176051-m6h1q 1/1 Running 0 29s kubernetes-bootcamp-472176051-z4wqs 1/1 Running 0 29s # kubectl get pods NAME READY STATUS RESTARTS AGE kubernetes-bootcamp-472176051-m6h1q 1/1 Running 0 42s kubernetes-bootcamp-472176051-z4wqs 1/1 Running 0 42s #检查回滚状态 kubectl rollout status deployments/kubernetes-bootcamp deployment \"kubernetes-bootcamp\" successfully rolled out #更新 kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=docker.io/jocatalin/kubernetes-bootcamp:v10 deployment.apps \"kubernetes-bootcamp\" image updated #有错 kubectl get deployments NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE kubernetes-bootcamp 2 3 2 1 3d #有错 kubectl get pods NAME READY STATUS RESTARTS AGE kubernetes-bootcamp-384357858-7kjx1 0/1 ErrImagePull 0 2m kubernetes-bootcamp-384357858-t0wmt 0/1 ImagePullBackOff 0 2m kubernetes-bootcamp-472176051-m6h1q 1/1 Running 0 9m # kubectl describe pods #回滚 kubectl rollout undo deployments/kubernetes-bootcamp deployment.apps \"kubernetes-bootcamp\" #查看 kubectl get pods kubectl decribe pods #Image: docker.io/jocatalin/kubernetes-bootcamp:v2 #回到了V2版 \r\r","date":"2018-06-26","objectID":"/kubernetes/:23:7","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"配置 Configuration ","date":"2018-06-26","objectID":"/kubernetes/:24:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"使用ConfigMap配置Redis 目标(Objective) 创建ConfigMap 使用ConfigMap创建Pod规范 创建Pod 验证配置是否正确应用 开始之前 需要有k8s集群，并且安装了kubectl命令行工具。 栗子：使用ConfigMap配置Redis #Master #创建redis的ConfigMap kubectl create configmap redis-config --from-file=xxx/redis-config kubectl get configmap redis-config -o yaml #创建redis-pod.yaml文件 apiVersion: v1 kind: Pod metadata: name: redis spec: containers: - name: redis image: kubernetes/redis:v1 env: - name: MASTER value: \"true\" ports: - containerPort: 6379 resources: limits: cpu: \"0.1\" volumeMounts: - mountPath: /redis-master-data name: data - mountPath: /redis-master name: config volumes: - name: data emptyDir: {} - name: config configMap: name: redis-config items: - key: redis-config path: redis.conf #创建pod kubectl create -f /etc/k8s/pods/config/redis-pod.yaml kubectl exec -it redis redis-cli \r\r","date":"2018-06-26","objectID":"/kubernetes/:24:1","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"无状态应用程序 Stateless Applications \r","date":"2018-06-26","objectID":"/kubernetes/:25:0","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["cncf"],"content":"公开外物IP以访问集群中的应用程序 Exposing an External IP Address to Access an Application in a Cluster 目标 为一个Hello World应用程序运行五个实例 创建一个展示外部IP的服务对象 使用服务对象去访问运行的应用程序 为运行五个pods的应用程序创建一个服务 #运行hello world kubectl run hello-world --replicas=5 --labels=\"run=load-balancer-example\" --image=gcr.io/google-samples/node-hello:1.0 --port=8080 #--image=docker.io/jocatalin/hellonode:v1 #查看信息 kubectl get deployments hello-world kubectl describe deployments hello-world kubectl get replicasets kubectl describe replicasets #创建展示部署的服务对象 kubectl expose deployment hello-world --type=LoadBalancer --name=my-service #如果外部地址显示为pending，请等待几分钟 #查看信息 kubectl get services my-service kubectl describe services my-service #可看到LoanBlancer Ingress kubectl get pods --output=wide #访问外部地址(LoadBalancer Ingress) curl http://\u003cexternal-ip\u003e:\u003cport\u003e 清理 #删除服务 kubectl delete services my-service #删除正在运行的程序的Deployment，ReplicaSet，Pods kubectl delete deployment hello-world \r \r","date":"2018-06-26","objectID":"/kubernetes/:25:1","tags":["Kubernetes","k8s","CNCF"],"title":"Kubernetes","uri":"/kubernetes/"},{"categories":["linux"],"content":"环境： CentOS7.x84_64 参考: strace命令: http://man.linuxde.net/strace pstack命令: http://man.linuxde.net/pstack lsof命令: http://man.linuxde.net/lsof 系统调用: https://zh.wikipedia.org/wiki/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8 Linux系统调用列表: https://www.ibm.com/developerworks/cn/linux/kernel/syscall/part1/appendix.html#8 高CPU分析: http://blog.51cto.com/yaocoder/1543352 \r系统调用 系统调用(system call)，指运行在用户态的程序向操作系统内核请求需要更高权限运行的服务。系统调用提供用户程序与操作系统之间的接口。 操作系统的进程空间可分为用户态和内核态，它们需要不同的执行权限。其中系统调用运行在内核态。 大多数系统交互式操作需求在内核态运行。如设备I/O或进程间通信。 内核态(kernel space) 内核、核心扩充、驱动程序运行在内核空间上。 用户态(user space) 其它的应用程序，则运行在用户空间上。 所有运行在用户空间的应用程序，都被统称为用户级(userland)。 库函数 系统调用和普通库函数调用非常相似，只是系统调用由操作系统内核提供，运行于内核核心态；而普通的库函数调用由函数库或用户自己提供，运行于用户态。 系统调用的意义 内核提供用户空间程序与内核空间进行交互的一套标准接口，这些接口让用户态程序能受限访问硬件设备，比如申请系统资源，操作设备读写，创建新进程等。用户空间发生请求，内核空间负责执行，这些接口便是用户空间和内核空间共同识别的桥梁，这里提到两个字“受限”，是由于为了保证内核稳定性，而不能让用户空间程序随意更改系统，必须是内核对外开放的且满足权限的程序才能调用相应接口。 在用户空间和内核空间之间，有一个叫做Syscall(系统调用, system call)的中间层，是连接用户态和内核态的桥梁。这样即提高了内核的安全型，也便于移植，只需实现同一套接口即可。Linux系统，用户空间通过向内核空间发出Syscall，产生软中断，从而让程序陷入内核态，执行相应的操作。对于每个系统调用都会有一个对应的系统调用号，比很多操作系统要少很多。 安全性与稳定性：内核驻留在受保护的地址空间，用户空间程序无法直接执行内核代码，也无法访问内核数据，通过系统调用 性能：Linux上下文切换时间很短，以及系统调用处理过程非常精简，内核优化得好，所以性能上往往比很多其他操作系统执行要好。 \r","date":"2018-05-14","objectID":"/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:0:0","tags":["Linux","系统调优"],"title":"性能分析","uri":"/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"categories":["linux"],"content":"Linux系统调用方法 futex Futex 是fast userspace mutex的缩写，意思是快速用户空间互斥体。Linux内核把它们作为快速的用户空间的锁和信号量的预制构件提供给开发者。 select select系统调用允许程序同时在多个底层文件表述符上，等待输入的到达或输出的完成。 进程控制 函数 描述 fork 创建一个新进程 clone 按指定条件创建子进程 execve 运行可执行文件 exit 中止进程 _exit 立即中止当前进程 getdtablesize 进程所能打开的最大文件数 getpgid 获取指定进程组标识号 setpgid 设置指定进程组标志号 getpgrp 获取当前进程组标识号 setpgrp 设置当前进程组标志号 getpid 获取进程标识号 getppid 获取父进程标识号 getpriority 获取调度优先级 setpriority 设置调度优先级 modify_ldt 读写进程的本地描述表 nanosleep 使进程睡眠指定的时间 nice 改变分时进程的优先级 pause 挂起进程，等待信号 personality 设置进程运行域 prctl 对进程进行特定操作 ptrace 进程跟踪 sched_get_priority_max 取得静态优先级的上限 sched_get_priority_min 取得静态优先级的下限 sched_getparam 取得进程的调度参数 sched_getscheduler 取得指定进程的调度策略 sched_rr_get_interval 取得按RR算法调度的实时进程的时间片长度 sched_setparam 设置进程的调度参数 sched_setscheduler 设置指定进程的调度策略和参数 sched_yield 进程主动让出处理器,并将自己等候调度队列队尾 vfork 创建一个子进程，以供执行新程序，常与execve等同时使用 wait 等待子进程终止 wait3 参见wait waitpid 等待指定子进程终止 wait4 参见waitpid capget 获取进程权限 capset 设置进程权限 getsid 获取会晤标识号 setsid 设置会晤标识号 文件系统控制： 文件读写操作 fcntl 文件控制 open 打开文件 creat 创建新文件 close 关闭文件描述字 read 读文件 write 写文件 readv 从文件读入数据到缓冲数组中 writev 将缓冲数组里的数据写入文件 pread 对文件随机读 pwrite 对文件随机写 lseek 移动文件指针 _llseek 在64位地址空间里移动文件指针 dup 复制已打开的文件描述字 dup2 按指定条件复制文件描述字 flock 文件加/解锁 poll I/O多路转换 truncate 截断文件 ftruncate 参见truncate umask 设置文件权限掩码 fsync 把文件在内存中的部分写回磁盘 文件系统操作 access 确定文件的可存取性 chdir 改变当前工作目录 fchdir 参见chdir chmod 改变文件方式 fchmod 参见chmod chown 改变文件的属主或用户组 fchown 参见chown lchown 参见chown chroot 改变根目录 stat 取文件状态信息 lstat 参见stat fstat 参见stat statfs 取文件系统信息 fstatfs 参见statfs readdir 读取目录项 getdents 读取目录项 mkdir 创建目录 mknod 创建索引节点 rmdir 删除目录 rename 文件改名 link 创建链接 symlink 创建符号链接 unlink 删除链接 readlink 读符号链接的值 mount 安装文件系统 umount 卸下文件系统 ustat 取文件系统信息 utime 改变文件的访问修改时间 utimes 参见utime quotactl 控制磁盘配额 系统控制： ioctl I/O总控制函数 _sysctl 读/写系统参数 acct 启用或禁止进程记账 getrlimit 获取系统资源上限 setrlimit 设置系统资源上限 getrusage 获取系统资源使用情况 uselib 选择要使用的二进制函数库 ioperm 设置端口I/O权限 iopl 改变进程I/O权限级别 outb 低级端口操作 reboot 重新启动 swapon 打开交换文件和设备 swapoff 关闭交换文件和设备 bdflush 控制bdflush守护进程 sysfs 取核心支持的文件系统类型 sysinfo 取得系统信息 adjtimex 调整系统时钟 alarm 设置进程的闹钟 getitimer 获取计时器值 setitimer 设置计时器值 gettimeofday 取时间和时区 settimeofday 设置时间和时区 stime 设置系统日期和时间 time 取得系统时间 times 取进程运行时间 uname 获取当前UNIX系统的名称、版本和主机等信息 vhangup 挂起当前终端 nfsservctl 对NFS守护进程进行控制 vm86 进入模拟8086模式 create_module 创建可装载的模块项 delete_module 删除可装载的模块项 init_module 初始化模块 query_module 查询模块信息 *get_kernel_syms 取得核心符号,已被query_module代替 ioctl I/O总控制函数 _sysctl 读/写系统参数 acct 启用或禁止进程记账 getrlimit 获取系统资源上限 setrlimit 设置系统资源上限 getrusage 获取系统资源使用情况 uselib 选择要使用的二进制函数库 ioperm 设置端口I/O权限 iopl 改变进程I/O权限级别 outb 低级端口操作 reboot 重新启动 swapon 打开交换文件和设备 swapoff 关闭交换文件和设备 bdflush 控制bdflush守护进程 sysfs 取核心支持的文件系统类型 sysinfo 取得系统信息 adjtimex 调整系统时钟 alarm 设置进程的闹钟 getitimer 获取计时器值 setitimer 设置计时器值 gettimeofday 取时间和时区 settimeofday 设置时间和时区 stime 设置系统日期和时间 time 取得系统时间 times 取进程运行时间 uname 获取当前UNIX系统的名称、版本和主机等信息 vhangup 挂起当前终端 nfsservctl 对NFS守护进程进行控制 vm86 进入模拟8086模式 create_module 创建可装载的模块项 delete_module 删除可装载的模块项 init_module 初始化模块 query_module 查询模块信息 *get_kernel_syms 取得核心符号,已被query_module代替 内存管理： brk 改变数据段空间的分配 sbrk 参见brk mlock 内存页面加锁 munlock 内存页面解锁 mlockall 调用进程所有内存页面加锁 munlockall 调用进程所有内存页面解锁 mmap 映射虚拟内存页 munmap 去除内存页映射 mremap 重新映射虚拟内存地址 msync 将映射内存中的数据写回磁盘 mprotect 设置内存映像保护 getpagesize 获取页面大小 sync 将内存缓冲区数据写回硬盘 cacheflush 将指定缓冲区中的内容写回磁盘 网络管理： getdomainname 取域名 setdomainname 设置域名 gethostid 获取主机标识号 sethostid 设置主机标识号 gethostname 获取本主机名称 sethostname 设置主机名称 socket控制： socketcall socket系统调用 socket 建立socket bind 绑定socket到端口 connect 连接远程主机 accept 响应socket连接请求 send 通过socket发送信息 sendto 发送UDP信息 sendmsg 参见send recv 通过socket接收信息 recvfrom 接收UDP信息 recvmsg 参见recv listen 监听socket端口 select 对多路同步I/O进行轮询 shutdown 关闭socket上的连接 getsockname 取得本地socket名字 getpeername 获取通信对方的socket名字 getsockopt 取端口设置 setsockopt 设置端口参数 sendfile 在文件或端口间传输数据 socketpair 创建一对已联接的无名socket 用户管理： getuid 获取用户标识号 setuid 设置用户标志号 getgid 获取组标识号 setgid 设置组标志号 getegid 获取有效组标识号 setegid 设置有效组标识号 geteuid 获取有效用户标识号 seteuid 设置有效用户标识号 setregid 分别设置真实和有效的的组标识号 setreuid 分别设置真实和有效的用户标识号 getresgid 分别获取真实的,有效的和保存过的组标识号 setresgid 分别设置真实的,有效的和保存过的组标识号 getresuid 分别获取真实的,有效的和保","date":"2018-05-14","objectID":"/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:1:0","tags":["Linux","系统调优"],"title":"性能分析","uri":"/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"categories":["linux"],"content":"问题案例 当发现进程或服务异常时，我们可以通过strace来跟踪其系统调用，“看看它在干啥”，进而找到异常的原因。熟悉常用系统调用，能够更好地理解和使用strace。 当然，万能的strace也不是真正的万能。当目标进程卡死在用户态时，strace就没有输出了。 定位进程异常退出 定位共享内存异常 性能分析 \r \rpstack命令 pstack命令可显示每个进程(线程)的栈跟踪。 yum install -y gdb pstack $PID \r \rlsof命令 lsof命令用于查看你进程开打的文件，打开文件的进程，进程打开的端口(TCP、UDP)。 -a：列出打开文件存在的进程 -c\u003c进程名\u003e：列出指定进程所打开的文件 -g：列出GID号进程详情 -d\u003c文件号\u003e：列出占用该文件号的进程 +d\u003c目录\u003e：列出目录下被打开的文件 +D\u003c目录\u003e：递归列出目录下被打开的文件 -n\u003c目录\u003e：列出使用NFS的文件 -i\u003c条件\u003e：列出符合条件的进程（4、6、协议、:端口、 @ip ） -p\u003c进程号\u003e：列出指定进程号所打开的文件 -u：列出UID号进程详情 -h：显示帮助信息 -v：显示版本信息 \r \r高CPU占用分析 步骤： 查看进程 top 查看线程 top -H -p $pid 查看进程打开连接数 lsof -p ${pid} 追踪 strace -T -r -c -p $pid 栈 pstack $pid ","date":"2018-05-14","objectID":"/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/:2:0","tags":["Linux","系统调优"],"title":"性能分析","uri":"/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"categories":["programming"],"content":"环境: rhel7 Python3 参考: Python教程: https://docs.python.org/3.5/tutorial/index.html Python术语: https://docs.python.org/3.5/glossary.html Python语言参考: https://docs.python.org/3.5/reference/index.html Python HOWTOs: https://docs.python.org/3.5/howto/index.html Python标准库: https://docs.python.org/3.5/library/ PyPI: https://pypi.org/ Awesome-Python https://github.com/vinta/awesome-python https://github.com/jobbole/awesome-python-cn \r 术语 Glossary \u003e\u003e\u003e 交互式shell的默认Python提示符 ... 在为缩进代码块输入代码时，或在一对匹配的左右分隔符中，交互式shell的默认Python提示符 2to3 将Python2.x代码转换为Python3.x代码的工具 抽象基类(abstract base class) 参数(argument) 调用函数时传递给(或方法)的值: 关键字参数/可选参数 异步上下文管理器(asynchronous context manager) 控制在异步语句中看到的环境对象 异步生成器(asynchronous generator) 返回一个生成器迭代器的函数 异步生成器迭代器(asynchronous generator iterator) 由异步生成器创建的对象 异步可迭代(asynchronous iterable) 一个对象 异步迭代器(asynchronous iterator) 一个对象 属性(attribute) 按名称引用的对象关联的值 awaitable 一个对象 二进制文件(binary file) 能读写bytes-like对象的文件对象 bytes-like对象 支持Buffer Protocol并可以导出C-contiguous buffer的对象 字节码(bytecode) Python源代码被编译成字节码 类(class) 用于创建用户对象的模板 coercion 在涉及两个相同类型参数的操作中，将一个类型的实例隐式转换为另一个类型的实例 复数(complex number) 上下文管理器(context manager) contiguous 协程(coroutine) coroutine function CPython Python语言的规范实现 修饰器(decorator) 返回另一个函数的函数 描述(descriptor) 字典(dictionary) 字典视图(dictionary view) 从dict.keys(), dict.values(), dict.items()返回的对象称为字典视图 文档字符串(docstring) 在类，函数，或模块中的第一个表达式出现的字符串文字 duck-typing 一种编程风格 表达式(expression) 扩展模块(extension module) 由C/C++编写，通过Python API与核心和用户代码交互 f-string 文件对象(file object) finder 为正在导入的模块查找加载程序的对象 地板除(floor division) 函数(function) 函数注释(function annotation) __future__ 可使用伪模块来启用与当前解释器不兼容的新语言功能 垃圾回收(garbage collection) 不再使用时释放内存的过程 生成器(generator) generator iterator 生成器表达式(generator expression) 返回迭代器的表达式 通用函数(generic function) 由多个函数组成的函数 global interpreter lock 确保一次只有一个线程执行Python字节码的机制 hashable 如果一个对象具有在其生命周期内从不改变的hash值，并且可与其它对象相比，那么这个对象就是可hash的 IDLE Python的集成开发环境 一成不变的(immutable) 具有固定值的对象 易变的(mutable) 可改变它们值得对象 import path importing 一个模块中的Python代码在另一个Python代码中可获取 importer 既能找到又能加载模块的对象 交互式(interactive) 解释型(interpreted) Python是一种解释型语言，与编译型语言相反 interpreter shutdown 迭代(iterable) 一次能够返回其成员的对象 迭代器(iterator) 表示数据流的对象 关键函数(key function) 关键函数或整理函数是一个可调用函数，它返回用于排序的值 关键字参数(keyword argument) lambda 一个匿名内联函数，由调用该函数时评估的单个表达式组成 LBYL 三思而后行(Look before you leap) 列表(list) 一个内建Python序列 list comprehension 一种紧凑的方式来处理序列中的全部或部分元素，并返回列表和结果 loader 加载模块的对象 映射(mapping) 支持任意键查找并实现映射中指定方法的容器对象 meta path finder metaclass The class of a class 方法(method) 类里面定义的函数 method resolution order 模块(module) Python代码的组织单元的对象 module spec named tuple 命名空间(namespace) 变量存储的地方 namespace package 仅用作子包的包 嵌套范围(nested scope) 能够在封闭变量中引用变量 new-style class 对象(object) 具有状态和定义行为的任一数据 包(package) 可包含子模块或递归子模块的Python模块 参数(parameter) 函数或方法定义中的一个命名实体，用于指定该函数可接受的参数。 有5中参数: positional-or-keyword: positional-only keyword-only var-positional var-keyword path entry path entry finder path entry hook path based finder path-like object portion 单目录中的一组文件 positional argument provisional API provisional package Python 3000 Python3.x发行版的昵称 Python化(Pythonic) 与Python语言最常见的习惯用法密切相关的想法或代码片段，而不是使用其它语言通用的概念来实现该代码 合格的名字(qualified name) 引用计数(reference count) 对某个对象的引用次数 regular package __slots__ 类中的声明，通过预先声明实例属性的空间并消除实例字典来节省内存 序列(sequence) 单一调度(single dispatch) 通用函数调度的一种形式 切片(slice) 通常包含一部分序列的对象 special method 一种由Python隐式调用的方法 声明(statement) struct sequence 具有命名元素的元组 text encoding text file 三重引号(triple-quoted string) type 通用换行符(universal newlines) Unix: \\n; Windows: \\r\\n 变量注释(variable annotation) 与模块全局变量或类属性关联的类型元数据值 虚拟环境(virtual environment) 虚拟机(virtual machine) Zen of Python Pythono的设计原理和哲学 \r 教程 官网: https://www.python.org/ Python教程非正式地向读者介绍了Python语言和系统的基本概念和功能。 Python是一种易于学习，功能强大的编程语言。它具有高效的高级数据结构以及面向对象(object-oriented)编程的简单而有效的方法。优雅的语法和动态类型以及其解释的特性，使其成为大多数平台上许多领域脚本编写(scripting)和快速应用程序开发的理想语言。 Python解释器很容易用C或C++实现新功能和数据类型进行扩展。Python也适合作为定制程序的扩展语言。 本教程非正式地向读者介绍了Python语言和系统的基本概念和功能，不会涵盖每个功能。相反，它引入了许多Python最值得注意的功能和语言风格。 \r","date":"2018-05-06","objectID":"/python/:0:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"激起你的胃口 Whetting Your Appetite 将一些工作自动化，或编写一个小程序。 C/C++/Java，编写/编译/测试/重编译周期太慢，但你又不想为你的应用程序开发和设计一门全新的语言。 这样的话，Python就是适合你的语言！ 为一些任务编写Unix shell script或Windows batch file，但它们只适合文本数据，而不适合GUI应用程序… 你可以编写C/C++/Java程序，但需要很长的开发时间。Python简单易用，可帮助你更快完成工作。 Python为大型程序提供更多的结构和支持，它提供了更多的错误检查。作为一种非常高级的语言，它有内建的高级数据类型(如灵活的数组和字典)。 由于其更通用的数据类型，Python适用于比awk甚至Perl更大的问题域，但Python中的许多事情至少与这些语言一样容易。 Python允许你将你的程序拆分成模块，使其它Python程序能重用。它附带了大量的标准模块，你可将它们作为学习Python编程的基础。包括了: 文件I/O；系统调用；socket；GUI… Python是一种解释型语言，在程序开发中节省大量时间，因为不需要编译和链接。 Python可以使程序紧凑而易读，由Python编写的程序通常比等效的C/C++/Java程序代码少得多。原因如下: 高级数据类型允许你在单个语句中表达复杂的操作 语句分组通过缩进(4个空格)来完成，而不是开始和结束 无需声明变量和参数 Python是可扩展的，如果你会C编程的话，很容易为解释器添加一个新的内置函数或模块，或将Python程序链接到可用库的二进制形式。也可将Python解释器链接到C编写的应用程序中。 顺便说一句，该语言是根据BBC节目Monty Python’s Flying Circus命名，与爬行动物无关。 学习语言的最好方法就是使用它，以工代练！ \r\r","date":"2018-05-06","objectID":"/python/:1:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"解释器 Python Interpreter My Linux: /usr/bin/python3 /lib64/python3.5/ \r","date":"2018-05-06","objectID":"/python/:2:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"交互模式 Interactive Mode python3 \u003e\u003e\u003efor i in range(4): ... \r","date":"2018-05-06","objectID":"/python/:2:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"参数传递 Argument Passing 使用sys模块的argv变量给脚本传递参数。 import sys num = len(sys.argv) if num != 3: print('Usage: xxx.py argv1 argv2') else: print('argu[0] is ' + sys.argv[0]) print('argu[1] is ' + sys.argv[1]) print('argu[2] is ' + sys.argv[2]) chmod u+x xxx.py ./argvPass.py 1 22 argu[0] is ./argvPass.py argu[1] is 1 argu[2] is 22 \r","date":"2018-05-06","objectID":"/python/:2:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"编码格式 Source Code Encoding #!/usr/bin/python3 # -*- coding: utf-8 -*- \r\r","date":"2018-05-06","objectID":"/python/:2:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"介绍 An Informal Introduction to Python 注意Python的两个默认提示符: \u003e\u003e\u003e ... \r","date":"2018-05-06","objectID":"/python/:3:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"作为计算器 Using Python as a Calculator Numbers + - * / //(取商) %(取余) ** int float decimal fraction(分数) comlex number(复数) Strings '(single quote) \"(double quote) \\(转义) r(元字符) ''' \"\"\" + * index string[-1] string[0:2] len() Lists list = [xx, x, ...] index list[index] list[start:stop] method append() pop() del() ... \r","date":"2018-05-06","objectID":"/python/:3:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"编程第一步 First Steps Towards Programming 斐波那契数列(Fibonacci series) a, b = 0, 1 while b \u003c 10: print(b, end=',') a, b = b, a+b #多重赋值(multiple assignment) #关键字参数(keyword argument) \r\r","date":"2018-05-06","objectID":"/python/:3:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"控制流 Control Flow Tools ","date":"2018-05-06","objectID":"/python/:4:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"while while Statements a = input(int('Please input an int: ')) whiel a \u003c 50: a += 1 print(a) ","date":"2018-05-06","objectID":"/python/:4:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"if if Statements x = int(input(\"please input an int: \")) if x \u003c 0: x = 0 print('Negative changed to zero') elif x == 0: print('Zero') elif x == 1: print('Single') else: print('More') ","date":"2018-05-06","objectID":"/python/:4:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"for for Statements words = ['a', 'bb', 'ccc'] for w in words: print(w, len(w)) ''' 如果需要修改迭代中的序列，建议先制作副本，遍历一个序列并不会隐式地创建一个副本 ''' words = ['a', 22, 'ccc'] for w in words[:]: if type(w) is int: words.insert(0, w) words [22, 'a', 22, 'ccc'] ","date":"2018-05-06","objectID":"/python/:4:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"range The range() Function 遍历一系列数字 for i in range(5): print(i) for i in range(0, 101, 10): print(i) a = [1, 22, 'A', 'AA'] for i in range(len(a)) print(i, a[i]) list(range(5)) [0, 1, 2, 3, 4] 注意 在许多方面，由range()返回的对象的行为就好像它是一个列表，但事实并非如此。它是一个对象，在你迭代时才返回所需序列，但它并不真正生成列表，从而节省空间。 我们说这样一个对象是可迭代的(iterable)。 print(range(10)) range(0, 10) ","date":"2018-05-06","objectID":"/python/:4:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"break/continue break and continue Statements, and else Clauses on Loops break 结束循环 continue 结束本次循环 ","date":"2018-05-06","objectID":"/python/:4:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"pass pass Statements pass语句什么也不做！当语句需要语法而程序不需要任何操作时，可使用它。 while True: pass class emptyClass: pass ","date":"2018-05-06","objectID":"/python/:4:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"函数定义 Defining Functions 关键字def引入一个函数定义，必须跟随函数名称和形式参数。函数主体语句必须缩进 函数主体的第一个语句是可选的字符串文字(sting literal)，用于描述函数。 在编写的代码中包含文档字符串是一种很好的做法，请养成此习惯。 函数中的所有变量赋值都将值存储在本地符号表中，而变量引用首先在本地符号表中查找，然后是封闭函数的本地符号表，然后是全局符号表，最后是内置名称表。 因此，全局变量不能直接在函数内赋值(除非是global语句)，尽管它们可能被引用。 事实上即使是没有return语句的函数也会返回一个值，它被称为None(一个内建名) def fib(n): \"\"\"function's documentation print a Fibonacci series up to n. \"\"\" a, b = 0, 1 while a \u003c n: print(a, end=' ') a, b = b, a+b print() fib(100) f = fib f(100) print(fib()) None 也可以使用可变数量的参数来定会函数。 默认参数值 Default Argument Values 最有用的形式是为一个或多个参数指定默认值。 def ask_ok(prompt, retries=4, reminder='Please try again!'): while True: ok = input(prompt) if ok in ('y', 'ye', 'yes'): return True if ok in ('n', 'no', 'nop', 'nope'): return False retries = retries - 1 if retries \u003c 0: raise ValueError('invalid user response') print(reminder) 函数可通过如下方法调用: 只给出必须的参数: ask_os('Prompt xxx') 给出可选参数: ask_ok('Prompt xx', 3) 给出所有参数: ask_ok(agr1, arg2, arg3) 关键字参数 Keyword Arguments 也可使用kwarg = value来调用函数。 def parrot(voltage, state='a stiff', action='voom', type='Norwegian Blue'): print(\"-- This parrot wouldn't\", action, end=' ') print(\"if you put\", voltage, \"volts through it.\") print(\"-- Lovely plumage, the\", type) print(\"-- It's\", state, \"!\") parrot(1000) # 1 positional argument parrot(voltage=1000) # 1 keyword argument parrot(voltage=1000000, action='VOOOOOM') # 2 keyword arguments parrot(action='VOOOOOM', voltage=1000000) # 2 keyword arguments parrot('a million', 'bereft of life', 'jump') # 3 positional arguments parrot('a thousand', state='pushing up the daisies') # 1 positional, 1 keyword *name/**name **name，它接收一个字典(keyword=value)。可能与*name结合使用。*name必须出现在**name之前。 def shop(kind, *arguments, **keywords): print(\"-- Do you have any \", kind, \"?\") print(\"-- I'm sorry, we're all out of \", kind) for arg in arguments: print(arg) print('\\n-----\\n') for kw in keywords: print(kw, ':', keywords[kw]) shop('Kind', 'arg1', 'arg2', kw1='KW1', kw2='KW2', kw3='KW3') \"\"\" -- Do you have any Kind ? -- I'm sorry, we're all out of Kind arg1 arg2 ----- kw3 : KW3 kw1 : KW1 kw2 : KW2 \"\"\" 任意参数列表 Arbitrary Argument Lists 最不经常使用的选项是指定可以用任意数量的参数调用一个函数，这些参数将被封装在一个元组中。 def arb(*args): for arg in args: print(arg) art(1, 22, 'CCC') 解包参数 Unpacking Argument Lists 当参数已经在一个列表或元组中时，会出现相反的情况。需要对单独的位置参数的函数调用进行解包。 list(range(5)) [0, 1, 2, 3, 4] args = [5] list(range(*args)) [0, 1, 2, 3, 4] Lambda表达式 可以使用lambda关键字创建小的匿名函数。 Lambda函数可用于需要函数对象的任何地方，它在语法上受限于单个表达式。 def lambdaTest(n): return lambda x: x + n f = lambdaTest(10) f(1) 11 f(5) 15 文档字符串 Documentation Strings 以下是关于文档字符串内容和格式的一些约定: 第一行应该始终是对象目的的简短摘要 第二行应该是空白，如果有多行的话 以下几行应该是描述 def func(): \"\"\"Document it. This func just print one argument. \"\"\" print(sys.argv[1]) print(func.__doc__) Document it. This func just print one argument. 函数注释 Function Annotations 函数注释完全是关于用户定义函数使用的类型的可选元数据信息。 Annotations以字典的形式存储在函数的__annotations__属性中，并且不影响函数的其它部分。参数注释由参数名称后面的冒号:定义，后跟表达式评估注释的值。注释由参数列表和def语句结束的冒号之间的-\u003e定义，后跟一个表达式。 def f(name: str, age: int = 18) -\u003e str: print(\"Annotations: \", f.__annotations__) print(\"Arguments: \", name, age) return name + 'and' + str(age) f('Zhang21') ","date":"2018-05-06","objectID":"/python/:4:7","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"编码风格 不同的语言有不同的编码风格。但是，让别人很轻松便能阅读你的代码总是一个好主意！ 对于Python而言，PEP(Python Enhanced Proposals) 8 已成为大多数项目遵循的风格指南。它促进了非常可读和令人喜爱的编码风格，每个Python开发者都应该阅读它。 以下是最重要的几点： 使用4空格缩进，而不是tab 自动换行，不要超过79个字符 使用空白行来分割函数和类，以及函数内的更大快代码 如有可能，请将注释放在它们的上一行 使用文档字符串 在运算符和逗号后面使用空格，但不要直接在包围结构中使用空格 -\u003e (a + b) 一致地命名函数和类 建议使用UTF-8编码方式 建议不要在标识符中使用non-ASCII字符，如果有其它语言的人会去维护代码 \r\r","date":"2018-05-06","objectID":"/python/:4:8","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"数据结构 Data Structures ","date":"2018-05-06","objectID":"/python/:5:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"列表 More on Lists 列表数据类型有多种方法： list.append(x) 添加一个项到列表的末尾 list.extend(iterable) 通过添加迭代中的所有项来扩展列表 list.insert(i, x) 在列表中给定位置插入一个项 list.remove(x) 删除列表中给定值的第一项 list.pop() 返回并删除列表中给定位置的项 如果未指定index，则默认为最后一项 list.clear() 删除列表中的所有项 list.index(x) 返回指定值的第一个索引 如果没有此值，返回ValueError list.count(x) 返回列表中指定值出现的次数 list.sort() 对列表中的项进行排序 list.reverse() 反转列表中的元素 list.copy() 返回列表的shallow copy 列表用处： Stack Queue 列表解析 List Comprehensions #列表解析提供了一个简洁的方式来创建列表 l = [] for i in range(10): l.append(i**2) #lambda l = list(map(lambda i: i**2, range(10))) #or l = [x**2 for i in range(10)] [(x, y) for x in [1, 2, 3] for y in [3, 2, 1] if x != y] 嵌套列表解析 Nested List Comprehensions 列表解析中的初始表达式可以是任意表达式，包括另一个列表解析。 l = [ [1, 2, 3, 4], [5, 6, 7, 8], [9, 10 ,11, 12] ] [[row[i] for row in l] for i in range(4)] \r","date":"2018-05-06","objectID":"/python/:5:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"del语句 del语句可从列表中删除切片或整个列表。 a = [1, 2, 3, 4] del a[0] del a[1:3] del a[:] del a \r","date":"2018-05-06","objectID":"/python/:5:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"元组和序列 Tuples and Sequences 列表和字符串由许多共同属性，如索引和切片操作。 列表是可变的，它们的元素通常是同类，并且通过遍历列表可访问。 元组是不可变的！无法对元组项赋值，但可创建包含可变对象的元组。 t = (123, 321, 'hello') tt = t, ('a', 'bb') (123, 321, 'hello), ('a', 'bb') #对元组赋值会出错 t[0] = 888 TypeError: 'tuple' object does not support item assignment #序列拆包(unpacking) #要求变量数量等于元素数量 x, y, z = t x 123 y 321 z 'hello' \r","date":"2018-05-06","objectID":"/python/:5:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"集合 Sets Python中的集合是没有重复元素的无序集合，并支持数学操作: 并集 a | b 交集 a \u0026 b 差集 a - b 异或 a ^ b 使用大(花)括号{}或set()创建集合，但创建一个空集合使用set()，而不是{}——后者创建一个空字典。 集合也支持集合解析。 alpha = {'a', 'b', 'c', 'a'} alpha {'c', 'b', 'a'} 'c' in alpha True #数学运算 a = set('abracadabra') b = set('alacazam') a | b a \u0026 b a - b a ^ b #集合解析 {x for x in 'abcdefgabc' if x not in 'abc'} \r","date":"2018-05-06","objectID":"/python/:5:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"字典 Dictionaries 字典数据类型在其它语言中被称为“associative memories” or “associative arrays”。与由数字索引的序列不同，字典由key索引(可以是任何不可变类型)，字符串和数字都可作为key。如果元组只包含字符串，数字或元组，则可作为key。若包含任何可变对象，则不能作为key。你不能使用列表作为key。 可将字典视为无序的键:值对，并要求键是唯一！ 花括号{}创建一个空字典。 字典的主要操作是用某个key存储value，并提取给定key的value。使用del语句删除一个键值对；新键值对会替换旧键值对。 info = {'name': 'AA', 'id': 1, 'tel': 155} info['addr'] = 'Chengdu' info info['name'] del info['id'] list(info.keys()) print(info.values()) print(info.items()) #dict()构造函数 dict([('name', 'A'), ('age', 11)]) dict({'name': 'A', 'age': 11}) dict(name='zhang', age=11) #字典解析 {x: x**2 for x in (2, 4, 6)} \r","date":"2018-05-06","objectID":"/python/:5:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"循环技巧 Looping Techniques 字典循环 info = {'name': 'AA', 'age': 11} for k, v in info.items(): print(k, v, sep=':') name:AA age:11 序列循环 可使用enumerate()函数同时检索位置索引和相应值 for i, v in enumerate(['a', 'b', 'c']): print(i, v) 0 a 1 b 2 c 同时循环多个序列 要同时循环多个序列，可将这些条目与zip()函数配对 aa = [1, 2, 3] bb = ['a', 'b', 'c'] for a, b in zip(aa, bb): print('{0}, {1}'.format(a, b)) 1, a 2, b 3, c 反向循环序列 for i in reversed(range(6)): print(i, end=',') 5,4,3,2,1,0, 循环排序 l = ['ac', 'fb', 'nx', 'by'] for i in sorted(l): print(i) ac by fb nx ll = ['ac', 'fb', 'nx', 'by', 'ac', 'by'] for i in sorted(set(ll)): print(i) ac by fb nx \r","date":"2018-05-06","objectID":"/python/:5:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"关于条件 More on Conditions while和if语句中使用的条件可以包含任何运算符，而不仅仅是比较。 比较操作符in和not in检查值是否在序列中 操作符is和is not比较两个对象是否相同，这适用于可变对象(如list) 比较操作可以使用布尔运算符and和or进行组合，结果可用not。它们的优先级低于比较操作 所有的比较操作符(comparison operators)具有相同的优先级，都低于数值运算符 \r","date":"2018-05-06","objectID":"/python/:5:7","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"模块 Modules 如果你从Python解释器中退出并重新进入，你所做的定义(函数和变量)将会丢失。因此，如果编写一个稍长的程序，最好使用文本编辑器，然后将代码文件作文输入来运行它。这就被称为创建一个脚本。 随着程序变长，可能需要将其分割为便于维护的多个文件。你可能还想使用你在多个程序中编写的某个功能(函数)，而不是将其定义复制到每个程序中。 为了支持此，Python有一种方法可将定义(definition)放入一个文件中，并在脚本或交互式实例中使用它们。这样的文件被称为模块(module)。 来自模块的定义可以被导入到其它模块或主模块中。 模块是一个包含Python定义和语句的文件。文件名是带有.py的模块名。 在模块中，模块的名称(string)用作全局变量__name__的值。 编写一个模块： vim /path/fibo.py #Fibonacci numbers module def fib(n): a, b = 0, 1 while b \u003c n: print(b, end=' , ') a, b = b, a+b print() def fib2(n): result = [] a, b = 0, 1 while b \u003c n: result.appen(b) a, b = b, a+b return result 载入此模块： 如果没有将此模块放入Python默认lib目录(如/usr/lib64/python3.5/)的话，则需要进入模块所在目录打开Python解释器。 cd /path python3 \u003e\u003e\u003e import fibo \u003e\u003e\u003e fibo.fb(100) 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, \u003e\u003e\u003e fibo.fib2(100) [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89] \u003e\u003e\u003e fibo.__name__ 'fibo' \u003e\u003e\u003e fibo.__str__() module 'fibo' from '/path/fibo.py' ","date":"2018-05-06","objectID":"/python/:6:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"更多模块信息 More on Modules 一个模块可以包含可执行语句以及函数定义。这些语句旨在初始化模块，它们仅在import语句中第一次遇到模块名称时执行。 每个模块都有自己的私人符号表(private symbol table)，它被模块中定义的所有函数(functions)用作全局符号表(global symbol talbe)。因此，模块的作者可以在模块中使用全局变量(global variable)，而不用担心与用户的全局变量发生意外冲突。 模块可以导入其它模块。习惯上(但不是硬性要求)，将import语句放在模块(脚本)的开头。导入模块的名称被放置在导入模块的全局符号表中。 将模块名称直接导入到导入模块的符号表中，这不会在本地符号表中引入导入模块的名称 #fibo模块名并没有被定义 from fibo import fib, fib2 导入模块中定义的所有名称 在大多数情况下，Python程序员不会使用这个工具。因为它会向解释器引入一组未知的名称，可能会隐藏你已经定义的一些东西。 注意，通常从模块或包中import *的做法是不被接受的，因为它经常会导致代码可读性很差。但是，可以使用它来保存交互式会话中的输入。 #这会导入除了以下划线开头的所有名称 from fibo import * 将导入模块名称绑定到指定名称 import fibo as fib fib.fib(100) fib.fib2(100) from fibo import fib2 as fibonacci fibonacci(100) 把模块作为脚本来执行 Executing modules as scripts 如果你将模块中的__name__设置为__main__，模块中的代码就会被执行，就像导入它一样。这意味着你需要在你的模块的末尾添加它们。 如果模块被导入，代码也不会执行。 这通常用于为模块提供用户接口，或测试。 if __name__ == \"__main__\": import sys fib(int(sys.argv[1])) python3 fibo.py {args} 模块的搜索路径 The Module Search Path 当import fibo模块时，解释器首先在内建模块中搜索此名称。如果找不到，它会在sys.path给出的目录列表中搜索fibo.py文件。 sys.path从以下位置初始化： 包含输入脚本的目录(未指定文件时的当前目录) PYTHONPATH 依赖于安装的默认值 包含符号链接的目录不会被添加到模块的搜索路径中 编译的Python文件 Compiled Python files 为了加速载入模块，Python将每个模块的编译版本缓存在名为module.version.pyc的__pycache__目录下，对编译文件的格式进行编码，它通常包含Python版本号。 Python根据编译后的版本检查源代码的修改日期，看它是否过期并需要重新编译。这是一个完全自动的过程。另外，编译后的模块时独立于平台的，因此可以在不同体系结构的系统之间共享相同的库。 有两种情况，Python不会检查缓存： 总是重新编译并且不存储从命令行直接加载的模块的结果 没有源模块 专家提示： 可以Python命令中使用-0或-00来减少已编译模块的大小 读取.pyc文件不会比.py文件快，唯一更快的事情是它们被加载的速度 模块compileall可以为目录中的所有模块创建.pyc文件 更多细节，参见PEP 3147 \r","date":"2018-05-06","objectID":"/python/:6:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"标准模块 Standard Modules Python提供了一个标准模块库。 一些模块被内置到解释器中，提供了对操作的访问。这些操作不属于语言核心的一部分，但是为了提高效率或提供对操作系统的访问权限。 import sys sys.ps1 '\u003e\u003e\u003e' sys.ps2 '...' sys.ps1 = '\u003c\u003c\u003c' sys.ps1 '\u003c\u003c\u003c' #查看PYTHONPATH sys.path.__str__ #添加PYTHONPATH sys.path.append('/home/zhang/venv/python') \r","date":"2018-05-06","objectID":"/python/:6:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"dir()函数 内建函数dir()用于找出模块定义的名称。 它列出所有类型的名称： 变量，模块，函数… import fibo, sys dir(fibo) ['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'fib', 'fib2'] dir(sys) ['__displayhook__', '__doc__', '__excepthook__', '__interactivehook__', '__loader__', '__name__', '__package__', '__spec__', '__stderr__', '__stdin__', '__stdout__', '_clear_type_cache', '_current_frames', '_debugmallocstats', '_getframe', '_home', '_mercurial', '_xoptions', 'abiflags', 'api_version', 'argv', 'base_exec_prefix', 'base_prefix', 'builtin_module_names', 'byteorder', 'call_tracing', 'callstats', 'copyright', 'displayhook', 'dont_write_bytecode', 'exc_info', 'excepthook', 'exec_prefix', 'executable', 'exit', 'flags', 'float_info', 'float_repr_style', 'getallocatedblocks', 'getcheckinterval', 'getdefaultencoding', 'getdlopenflags', 'getfilesystemencoding', 'getprofile', 'getrecursionlimit', 'getrefcount', 'getsizeof', 'getswitchinterval', 'gettrace', 'hash_info', 'hexversion', 'implementation', 'int_info', 'intern', 'last_traceback', 'last_type', 'last_value', 'maxsize', 'maxunicode', 'meta_path', 'modules', 'path', 'path_hooks', 'path_importer_cache', 'platform', 'prefix', 'ps1', 'ps2', 'setcheckinterval', 'setdlopenflags', 'setprofile', 'setrecursionlimit', 'setswitchinterval', 'settrace', 'stderr', 'stdin', 'stdout', 'thread_info', 'version', 'version_info', 'warnoptions'] #它不会列出内建函数和变量的名称，除非如下操作 import builtins dir(builtins) ['ArithmeticError', 'AssertionError', 'AttributeError', 'BaseException', 'BlockingIOError', 'BrokenPipeError', 'BufferError', 'BytesWarning', 'ChildProcessError', 'ConnectionAbortedError', 'ConnectionError', 'ConnectionRefusedError', 'ConnectionResetError', 'DeprecationWarning', 'EOFError', 'Ellipsis', 'EnvironmentError', 'Exception', 'False', 'FileExistsError', 'FileNotFoundError', 'FloatingPointError', 'FutureWarning', 'GeneratorExit', 'IOError', 'ImportError', 'ImportWarning', 'IndentationError', 'IndexError', 'InterruptedError', 'IsADirectoryError', 'KeyError', 'KeyboardInterrupt', 'LookupError', 'MemoryError', 'NameError', 'None', 'NotADirectoryError', 'NotImplemented', 'NotImplementedError', 'OSError', 'OverflowError', 'PendingDeprecationWarning', 'PermissionError', 'ProcessLookupError', 'ReferenceError', 'ResourceWarning', 'RuntimeError', 'RuntimeWarning', 'StopIteration', 'SyntaxError', 'SyntaxWarning', 'SystemError', 'SystemExit', 'TabError', 'TimeoutError', 'True', 'TypeError', 'UnboundLocalError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeError', 'UnicodeTranslateError', 'UnicodeWarning', 'UserWarning', 'ValueError', 'Warning', 'ZeroDivisionError', '_', '__build_class__', '__debug__', '__doc__', '__import__', '__loader__', '__name__', '__package__', '__spec__', 'abs', 'all', 'any', 'ascii', 'bin', 'bool', 'bytearray', 'bytes', 'callable', 'chr', 'classmethod', 'compile', 'complex', 'copyright', 'credits', 'delattr', 'dict', 'dir', 'divmod', 'enumerate', 'eval', 'exec', 'exit', 'filter', 'float', 'format', 'frozenset', 'getattr', 'globals', 'hasattr', 'hash', 'help', 'hex', 'id', 'input', 'int', 'isinstance', 'issubclass', 'iter', 'len', 'license', 'list', 'locals', 'map', 'max', 'memoryview', 'min', 'next', 'object', 'oct', 'open', 'ord', 'pow', 'print', 'property', 'quit', 'range', 'repr', 'reversed', 'round', 'set', 'setattr', 'slice', 'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple', 'type', 'vars', 'zip'] \r","date":"2018-05-06","objectID":"/python/:6:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"包 Packages 包是通过”dotted(.) module names“，来构造Python模块命名空间的一种方式。 假设你想设计一个模块集(包)来统一处理声音文件和声音数据。有许多不同的声音文件格式。因此你需要创建和维护不断增长的模块集合，以便在各种文件格式之间进行转换。你还可能需要对声音数据执行各种不同的操作，因此你还需要编写无止境的模块流以执行这些操作。 这可能是一个包结构: sound/ Top-level package __init__.py Initialize the sound package formats/ Subpackage for file format conversions __init__.py wavread.py wavwrite.py aiffread.py aiffwrite.py auread.py auwrite.py ... effects/ Subpackage for sound effects __init__.py echo.py surround.py reverse.py ... filters/ Subpackage for filters __init__.py equalizer.py vocoder.py karaoke.py ... 当导入包时，Python将搜索sys.path，并查找包的子目录。 需要__init__.py文件才能使Python将目录视为包含包。这是为了防止具有通用名称的目录(如字符串)无意中隐藏稍后在模块搜索路径中发生的有效模块。 在最简单的情况下，__init__.py可以是一个空文件，但它也可以执行包的初始化代码。 导入包: from package import item item可以是子模块，子包，函数，类，变量 import语句首先测试项目是否在包中定义。 如果不在，它假定它是一个模块并尝试加载它。如果找不到它，则会引发ImportError异常 import item.subitem.subsubitem 相反，当使用这种语法时，除最后一项外必须都是一个包，最后一项可以是模块或包，但不能是类或函数或变量 import sound.effects.echo from sound.effects import echo importing * from a package 当输入from sound.effects import *会发生什么？理想情况下，人们会希望以某种方式进入文件系统，查找包中存在哪些子模块，然后将它们全部导入。这可能需要很长时间，并且导入子模块可能具有不希望的副作用，这些副作用在明确导入子模块时才会发生。 唯一的解决方案是软件包作者提供包的明确索引。import使用以下声明: 如果某个包的__init__.py定义了一个名为__all__的列表，则它将成为from package import *时应该导入的模块名称列表。 当软件包新版本发布时，软件包作者需要保持该列表是最新版本。 栗子sound/effects/__init__.py: #这意味着from sound.effects import *只会导入以下子模块 __all__ = [\"echo\", \"surround\", \"reverse\"] 如果__all__没有被定义，则from sound.effcts import *语句不会将包sound.effects中所有子模块导入到当前命名空间。它只能确保包sound.effects被导入，然后导入包中定义的任何名称。这包括__init__.py定义的任何名称，还包括由以前的导入语句显示加载的软件包的任何子模块。 请记住，使用from packagee import submodule没有任何问题。事实上，这也是推荐的方法。除非导入模块需要使用不同包中具有相同名称的子模块。 内部包装 Intra-package References 当包被构建为子包时，可以使用绝对导入来引用邻包中的模块。 同样，也可以使用相对导入来导入邻包中的模块。 #Absolute from sound.effects import echo #Relative from . import echo from .. import formats from ..filter import equalizer 多个目录中的包 Packages in Multiple Directories 包还支持一个特殊的属性__path__。在执行该文件中的代码之前，它被初始化为一个包含__init__.py的目录名称的列表。这个变量可以修改，这样做会影响将对包中包含的模块和子包的搜索。 虽然此功能通常不是必需的，但它可用于扩展包中找到的一组模块。 \r \r","date":"2018-05-06","objectID":"/python/:6:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"输入和输出 Input and Output 有多种方式来呈现程序的输出；数据也可以打印成人类可读的形式，或写入文件供将来使用。 ","date":"2018-05-06","objectID":"/python/:7:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"幻想的输出格式 Fancier Output Formatting 到目前为止，我们知晓两种写入值的方法: 表达式语句 print()函数 有两种方法可以格式化输出： 自己完成所有的字符串处理(使用切片和连接操作，你可创建任何你能想到的布局) 格式化字符串文字或str.format()方法 string模块提供了一个Template类，它提供了另一种将值替换为字符串的方法。 Python有办法将任何值转换为字符串：将它传递给repr()或str()函数。 str()函数，用于返回相当可读(human-readable)的值的表示 repr()函数，用于生成可由解释器读取的表示 对于没有人定义的特定表示的对象，str()将返回与repr()相同的值 for x in range(1, 6): print(repr(x).rjust(2), repr(x**2).rjust(3), end=' ') print(repr(x**3).rjust(4)) #Or for x in range(1, 6): print('{0:2d} {1:3d} {2:4d}'.format(x, x**2, x**3)) 1 1 1 2 4 8 3 9 27 4 16 64 5 25 125 字符串对象的str.rjust()方法，它在给定宽度的字段中通过填充左边的空格来右对齐字符串。类似方法还有: str.ljust(), str.center()。这些方法不写入任何东西，它们只是返回一个新的字符串。 还有一种str.zfill()方法，它在数字字符串的左边填充数字0，它能识别加号和减号： \u003e\u003e\u003e '12'.zfill(5) '00012' \u003e\u003e\u003e \u003e\u003e\u003e '-3.14'.zfill(7) '-003.14' \u003e\u003e\u003e \u003e\u003e\u003e '3.1415678'.zfill(5) '3.1415678' str.format()方法: #{} print('We are {} who say {} is \"{}!\".format('A', 'BB', 'WONDERFUL')) We are A who say BB is \"WONDERFUL!\" #括号中的数字用来指向传入的位置 #{index},从0开始 print('{0} and {1}'.format('A', 'BB')) A and BB print('{1} and {0}'.format('A', 'BB')) BB and A #关键字参数 print('My name is {name}, I\\'m {age} years old!'.format(name='Zhang21', age=21)) My name is Zhang21, I'm 21 years old! #位置参数和关键字参数的组合 print('The story of {0}, {1}, and {other}'.format('A', 'BB', other='CCC')) The story of A, BB, and CCC ''' !a, 应用ascii() !s, 应用str() !r, 应用repr() :, 更好的控制格式 :5 :7d :.3f ''' print('My full name is {!s}'.format('Zhang21')) My full name is Zhang21 print('My full name is {!r}'.format('Zhang21')) My full name is 'Zhang21' print('The value of {} is approximately {:.3f}'.format('PI', 3.141567)) The value of PI is approximately 3.142 info = {'A': 68, 'BB': 79, 'CCC': 89} for k, v in info.items(): print('{0:5} ==\u003e {1:6d}'.format(k, v)) A ==\u003e 68 BB ==\u003e 79 CCC ==\u003e 89 print('A: {A:d}; B: {BB:d}, C: {CCC:d}'.format(**info)) A: 68; B: 79, C: 89 %操作符同样可用于字符格式化: print('The value of %sis approximately %5.3f' % ('PI', 3.1415678)) The value of PI is approximately 3.142 \r","date":"2018-05-06","objectID":"/python/:7:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"读写文件 Reading and Writing Files open()返回一个文件对象，它最常用的两个参数：open(filename, mode) f = open('/tmp/1.txt, 'r') f.readline() '1\\n' f.closed Fasle f.close() f.closed True mode: r: read only，未指定模式时的默认模式 w: only writing a: appending r+: reading and writing b: binary mode 通常情况下，文件以文本模式打开，这意味着你可读写文件中的字符串，并以特定编码方式进行编码(如UTF-8)。如果未指定编码，则默认值取决于平台。 b以二进制模式打开文件，数据以字节对象的形式读写，该模式应该用于所有不包含文本的文件。在读写文件时要非常小心的使用二进制模式。 推荐使用with关键字处理文件对象，优点是，即使在某个时间点出现异常，文件在其套件结束后也能正常关闭。也比try-finally块短得多。 如果没有使用with关键字，则你需要调用f.close()来关闭文件，并立即释放它使用的系统资源。如果你没有明确关闭一个文件，Python的垃圾回收器最终会摧毁这个对象并为你关闭吧这个打开的文件，但这个文件可能会保持打开一段时间。 在关闭文件对象之后，尝试使用文件对象将会自动失败。 with open('/tmp/1.txt') as f: read_Data = f.read() f.closed True f.read() Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e ValueError: I/O operation on closed file. 文件对象方法 Methods of File Objects f.read(size)读取文件内容，以字符串或字节对象的形式返回。size是一个可选的数值参数，当size被忽略或为负数时，文件的全部内容被读取并返回。如果超过内存限制，那就是你的问题了。 f.readline()从文件读取一行，换行符Unix\\n，Windows\\r\\n f.readlines(), list(f)读取文件的所有行 f.write(string)向文件中写入字符内容，并返回写入的字符数 f.tell()返回一个整数，表示二进制模式下文件开头的字节数 f.seek(offset, from_what)改变文件对象的位置 f = open('/tmp/1.txt', 'r+') f.write('Line4\\n') 6 string = ('AAA', 11) s = str(string) f.write(s) 11 f = open('/tmp/1.txt', 'rb+') f.write(b'0123456789abcde') f.seek(1) 1 f.read(1) b'1' 使用json保存结构化数据 Saving structured data with json 字符串可以很容易地读写文件和从文件读取。当你想要保存更复杂的数据类型——如嵌套列表和字典，手动解析和序列化将变得很复杂。 JSON格式通常被现代应用程序用于数据交换。 Python允许你使用名为JSON的流行数据交换格式。称为json的标准模块可采用Python数据层次结构，并将其转换为字符串表示形式，这个过程被称为序列化(serializing)。重建字符串表示中的数据称为反序列化(deserializing)。 import json json.dumps([1, 'simple', 'list']) '[1, \"simple\", \"list\"]' json.dump(x, f) x = json.load(f) \r\r","date":"2018-05-06","objectID":"/python/:7:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"错误和异常 Errors and Exceptions 至少有两种可区分的错误: syntax errors exceptions \r","date":"2018-05-06","objectID":"/python/:8:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"语法错误 Syntax Errors 语法错误，也称为解析错误。这是最常见的语法问题错误。 \r","date":"2018-05-06","objectID":"/python/:8:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"异常 Exceptions 即使语法是正确的，但在执行时也可能导致错误。执行过程中检查到的错误称为异常。 Built-in Exceptions列出了内置的异常及其含义。 \u003e\u003e\u003e 10 * (1/0) Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e ZeroDivisionError: division by zero \u003e\u003e\u003e 4 + spam*3 Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e NameError: name 'spam' is not defined \u003e\u003e\u003e '2' + 2 Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e TypeError: Can't convert 'int' object to str implicitly \r","date":"2018-05-06","objectID":"/python/:8:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"处理异常 Handling Exceptions 编写处理选定异常的程序是可能的。 while True: try: x = int(input(\"Please enter a number: \")) break except ValueError: print(\"Oops! That was no valid number. Try again...\") #多个异常放入一个元组 except (RuntimeError, TypeError, NameError): pass try语句工作原理： 首先，try子句(try...except之间的语句)被执行 如果没有异常发生，则执行try语句并跳过except子句后便结束 如果在执行try子句时发生异常，则跳过子句的其余部分。然后，如果异常类型匹配execpt后面的异常名称，则except子句被执行，然后在try语句后继续执行 如果产生的异常与except的异常名称不匹配，它将传递给外部try语句。如果没有找到处理程序，则它是一个未处理的异常，执行停止并显示错误消息 try语句可能有多个except子句，用于处理不同的异常。最多只有一个处理程序被执行 处理程序只处理发生在相应try子句中的异常，而不处理相同try语句的其它处理程序 except子句可将多个异常名放入一个元组 如果是相同的类或其基类，则except子句中的类与异常兼容 未使用异常名称的except子句作为通配符 请谨慎使用此功能，因为以这种方式很容易掩盖真正的编程错误 try...except语句还有一个可选的else子句。当存在时，它必须遵循所有except子句。如果try子句不引发异常，则必须执行该代码 import sys try: f = open('/tmp/1.txt') s = f.readline() i = int(s.strip()) except OSError as err: print('OS error: {}'.format(err)) except ValueError: print(\"Could not convert data to an integer.\") except: print(\"Unexpected erros\", sys.exc_info()[0]) raise try: sum = 'a' + 1 except TypeError: print('TypeError') else: print('else: ', sum) \r","date":"2018-05-06","objectID":"/python/:8:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"引发异常 Raising Exceptions raise语句允许程序员强制执行指定的异常。 \u003e\u003e\u003e raise NameError('HiThere') Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e NameError: HiThere \u003e\u003e\u003e try: ... raise NameError('HiThere') ... except NameError: ... print('An exception flew by!') ... raise ... An exception flew by! Traceback (most recent call last): File \"\u003cstdin\u003e\", line 2, in \u003cmodule\u003e NameError: HiThere \r","date":"2018-05-06","objectID":"/python/:8:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"用户定义的异常 User-defined Exceptions 程序可以通过创建一个新的异常类(exception class)来为自己的异常命名。异常通常应该直接或间接地从 Exception class 派生。 可以定义异常类，它可以执行任何其它类可以执行的任何操作，但通常很简单，通常只提供一些属性，以便处理程序为异常提取有关错误的信息。 创建可引发多个不同错误的模块时，通常的做法是为该模块定义的异常创建基类，并创建用于为不同错误条件创建特定异常类的子类: class Error(Exception): \"\"\"Base class for exceptions in this module.\"\"\" pass class InputError(Error): \"\"\"Exception raised for errors in the input. Attributes: expression -- input expression in which the error occurred message -- explanation of the error \"\"\" def __init__(self, expression, message): self.expression = expression self.message = message class TransitionError(Error): \"\"\"Raised when an operation attempts a state transition that's not allowed. Attributes: previous -- state at beginning of transition next -- attempted new state message -- explanation of why the specific transition is not allowed \"\"\" def __init__(self, previous, next, message): self.previous = previous self.next = next self.message = message 大多数异常的名称都以Error结尾来定义，类似于标准异常的命名。 许多标准模块定义了它们自己的异常，用于在其定义的功能中可能发生的错误。 \r","date":"2018-05-06","objectID":"/python/:8:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"定义清理行为 Defining Clean-up Actions try语句还有一个可选的子句，用于定义在任何情况下都必须执行的清理操作(clean-up actions). finally子句总是在离开try语句之前执行，无论是否发生异常。 \u003e\u003e\u003e try: ... raise KeyboardInterrupt ... finally: ... print('Goodbye, world!') ... Goodbye, world! KeyboardInterrupt Traceback (most recent call last): File \"\u003cstdin\u003e\", line 2, in \u003cmodule\u003e \r","date":"2018-05-06","objectID":"/python/:8:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"预定义的清理操作 Predefined Clean-up Actions 某些对象定义了在不再需要对象是要执行的标准清楚操作，而不管使用对象的操作是成功还是失败。 with open(\"myfile.txt\") as f: for line in f: print(line, end=\"\") \r\r","date":"2018-05-06","objectID":"/python/:8:7","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"类 Classes 类提供了将数据和功能捆绑在一起的手段。每个类实例都可附加属性以保持其状态。类实例也可以有方法来修改其状态。 与其它编程语言相比，Python的类机制为其添加了最少量的新语法和语义。Python类 提供了面向对象编程的所有标准功能: 类继承机制(inheritance mechanism)允许多个基类(base class)，派生类(derived class)可以重写其基类或类的任何方法，并且方法(method)可以调用具有相同名称的基类的方法。对象(object)可以包含任意数量和种类的数据。与模块一样，类也具有Python的动态特性: 它们是在运行时创建的，并且可以在创建后进一步修改。 \r","date":"2018-05-06","objectID":"/python/:9:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"关于名称和对象 A Word About Names and Objects Objects have individuality, 并且可以将多个名称(在多作用域中)绑定到同一个对象。这在其它语言中被称为别名。别名在不可变类型中被安全地忽略。但对涉及可变对象(dict, list…)的Python代码的语义可能会有惊人的影响。这通常有利于程序，因为别名在某些方面表现得像指针。 \r","date":"2018-05-06","objectID":"/python/:9:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"作用域和命名空间 Python Scopes and Namespaces 类定义在命名空间中扮演一些巧妙的技巧，并且你需要知道作用域和命名空间如何工作才能完全理解正在发生的事情。顺便一提，有关此主题的知识对于任何高级Python程序员都很有用。 让我们从一些定义开始: 命名空间是名称到对象的映射。大多数命名空间目前都是作为Python字典实现的，但通常不会以任何方式显示。 命名空间的例子： 内建名称的集合；模块中的全局名称；函数调用中的本地名称。 从某种意义上说，对象的一组属性也构成一个命名空间。了解命名空间的重要之处在于，不同命名空间中的名称之间没有绝对的关系。 顺便一提，使用单词属性来表示任意一个点.后面的名称——z.real，real是对象z的属性。严格地说，对模块中的名称引用是属性引用——modname.funcname，modname是一个模块对象，并且funcname是它的一个属性。 在这种情况下，模块的属性和模块中定义的全局名称之间会有一个直接的映射关系: 它们共享相同的命名空间。 属性可以是只读或可写。 命名空间是在不同的时刻创建的，并且具有不同的生命周期。包含内建名称的命名空间是在Python解释器启动时创建的，并且永远不会被删除。读取模块定义时创建模块的全局命名空间，通常，模块命名空间也会持续到解释器退出。 由解释器的顶层调用执行的语句，无论是从脚本文件读取还是交互式读取，都被视为名为__main__模块的一部分，因此它们具有其自己的全局命名空间。 函数的本地命名空间是在调用函数时创建，并在函数返回时删除或引发(raise)不在函数内处理的异常。当然，递归调用每个都有自己的本地命名空间。 作用域(scope)是Python程序的文本区域，可以直接访问命名空间(namespace)。这意味着对名称的非限定引用(unqualified reference)会尝试在命名空间中查找名称。 尽管作用域是静态确定的，但它们是动态使用的。在执行期间的任何时候，至少有三个作用域的命名空间都可以直接访问: 最先搜索的最内层作用域，包含本地名称 从最近封闭作用域开始搜索的任何封闭函数的作用域，包含非本地名称，也包含非全局名称 倒数第二个作用域包含当前模块的全局名称 最外层的作用域是包含内建名称的命名空间 如果某个名称被声明为全局(global)，则所有的引用(reference)和赋值(assignment)都将直接转到包含模块全局名称的中间作用域。要重新绑定(rebind)最内层作用域外发现的变量，可以使用nonlocal语句；如果没有声明nonlocal，那些变量是只读的。 通常，本地作用域引用当前函数的本地名称。在外部函数中，本地作用域引用与全局作用域相同的命名空间:模块的命名空间。类定义在本地作用域中放置另一个命名空间。 认识到作用域是以文本方式确定是很重要的: 模块中定义的函数的全局作用域是该模块的命名空间，无论从何处调用函数或调用函数的别名。另一方面，名称的实际搜索是在运行时动态完成的——但是，在编译时间，语言定义正在向静态名称解析发展，因此不要依赖动态名称解析。 Python的特殊之处在于——如果global语句没有生效，对名称的赋值总是进入最内层的范围。赋值不会分配数据——它们只是将名称绑定到对象。删除操作也是如此: 语句del x从本地作用域引用的命名空间中删除x的绑定。实际上，所有引用新名称的操作都是用本地作用域: 特别是，import语句和函数定义将模块或函数名称绑定到本地作用域。 global声明可以用来表明特定变量存在于全局作用域内，应该在此rebound(反弹)。nonlocal声明表明特定变量存在于封闭作用域内，应该在那里rebound. 作用域和命名空间的栗子 def scope_test(): def do_local(): spam = \"local spam\" def do_nonlocal(): nonlocal spam spam = \"nonlocal spam\" def do_global(): global spam spam = \"global spam\" spam = \"test spam\" do_local() print(\"After local assignment: \", spam) do_nonlocal() print(\"After nonlocal assignment: \", spam) do_global() print(\"After global assignment: \", spam) scope_test() print(\"In global scope: \", spam) #输出 After local assignment: test spam After nonlocal assignment: nonlocal spam After global assignment: nonlocal spam In global scope: global spam \r","date":"2018-05-06","objectID":"/python/:9:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"首先看类 A first look at class 类引入了一些新的语法，三种新的对象类型和一些新的语义。 类定义语法 Class Definition Syntax 类定义，像函数定义，必须在它们有效之前被执行。 class ClassName: \u003cstatement-1\u003e . . . \u003cstatement-N\u003e 实际上，类定义中的语句通常是函数定义，但其他语句是允许的，有时也是有用的。类中的函数定义通常有一个特殊形式的参数列表，由方法的调用约定决定。 当输入一个类定义时，会创建一个新的命名空间，并将其用作本地作用域——因此，所有对局部变量的赋值都会进入这个新的命名空间。特别是，函数定义在此绑定新函数的名称。 当类定义保持正常时，会创建一个类对象。这基本上是由类定义创建的命名空间的内容的一个包装。最初的本地作用域被恢复，并且类对象在这里被绑定到类定义头中给出的类名。 \r类对象 Class Objects 类对象支持两种操作: 属性引用(attribute reference)和实例化(instantiation). 属性引用使用 用于Python中所有属性引用的标准语法: obj.name. 有效的属性名称在创建类对象时时位于类命名空间中的所有名称。 class MyClass: \"\"\"A simple example class\"\"\" i = 12345 def f(self): return 'hello world' MyClass.i和MyClass.f是有效的属性引用，分别返回一个整数和函数对象。类属性也可以被分配，所以也可以通过赋值来改变MyClass.i的值。__doc__也是一个有效的属性，返回该类的文档字符串\"A simple example class\". 类实例化使用函数表示法。假设类对象是一个返回类的新实例的无参数函数。 #创建类的新实例，并将该对象分配给局部变量x x = MyClass() 实例化操作(“调用\"一个类对象)创建一个空对象。许多类喜欢创建具有定制(customized)到特定初始状态(initial state)的实例对象。因此，类可以定义一个名为__init__()的特殊方法。 def __init__(self): self.data = [] 当一个类定义了一个__init__()方法时，类实例化会自动为新创建的类实例调用__init__(). 当然，__init__()方法可能有更多灵活的参数。在这种情况下，给类实例化操作符的参数被传递给__init__(). class Complex: def __init__(self, realpart, imagpart): self.r = realpart self.i = imagpart x = Complex(3.0, -4.5) x.r, x.i 3.0, -4.5 实例对象 Instance Objects 实例对象理解的唯一操作是属性引用。有两种有效的属性名称，数据属性和方法。 数据属性不需要声明，像局部变量一样，当它们在第一次分配时就会弹出。 另一种实力属性引用是一种方法。方法是属于对象的函数。 实例对象的有效方法名称取决于它的类。根据定义，作为函数对象的类的所有属性都定义其实例的相应方法。 \r方法对象 Method Objects 关于方法的特殊之处在于 实例对象作为函数的第一个参数传递。一般来说，调用带有n个参数列表的方法相当于使用通过在第一个参数之前插入方法实例对象创建的参数列表来调用相应的函数。 当引用不是数据属性的实例属性时，将搜索类。如果名称表示一个有效的类属性，它是一个函数对象，则通过打包实例对象和在抽象对象中一起找到的函数对象来创建方法对象，这就是方法对象。当使用参数列表调用方法对象时，会从实例对象和参数列表构造一个新参数列表，并使用此新参数列表调用函数对象。 \r类变量和实例变量 Class and Instance Variables 一般来说，实例变量是针对每个实例唯一的数据，而类变量是针对类的所有实例共享的属性和方法。 class Dog: kind = 'canine' # class variable shared by all instances def __init__(self, name): self.name = name # instance variable unique to each instance \u003e\u003e\u003e d = Dog('Fido') \u003e\u003e\u003e e = Dog('Buddy') \u003e\u003e\u003e d.kind # shared by all dogs 'canine' \u003e\u003e\u003e e.kind # shared by all dogs 'canine' \u003e\u003e\u003e d.name # unique to d 'Fido' \u003e\u003e\u003e e.name # unique to e 'Buddy' 共享数据可能会带来令人惊讶的影响，涉及列表和字典等可变对象: class Dog: tricks = [] # mistaken use of a class variable def __init__(self, name): self.name = name def add_trick(self, trick): self.tricks.append(trick) \u003e\u003e\u003e d = Dog('Fido') \u003e\u003e\u003e e = Dog('Buddy') \u003e\u003e\u003e d.add_trick('roll over') \u003e\u003e\u003e e.add_trick('play dead') \u003e\u003e\u003e d.tricks # unexpectedly shared by all dogs ['roll over', 'play dead'] 正确的类设计应该使用实例变量: class Dog: def __init__(self, name): self.name = name self.tricks = [] # creates a new empty list for each dog def add_trick(self, trick): self.tricks.append(trick) \u003e\u003e\u003e d = Dog('Fido') \u003e\u003e\u003e e = Dog('Buddy') \u003e\u003e\u003e d.add_trick('roll over') \u003e\u003e\u003e e.add_trick('play dead') \u003e\u003e\u003e d.tricks ['roll over'] \u003e\u003e\u003e e.tricks ['play dead'] \r\r","date":"2018-05-06","objectID":"/python/:9:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"随机备注 Random Remarks 数据属性覆盖具有相同名称的方法属性；为了避免意外的名称冲突，这可能会在大型程序中导致难以发现的错误，使用某种最小化冲突几率的约定是明智的。可能的约定(convention)包括: 大写的方法名称，小唯一字符串(可能只是下划线)为数据属性名称加前缀，或者为方法和名词使用动词来表示数据属性。 数据属性可由方法及对象的普通用户引用。换句话说，累不可用于实现纯粹的抽象数据类型。事实上，Python中没有任何东西可以强制执行数据隐藏——它都基于约定。 客户端应该小心使用数据属性。请注意，客户端可以将自己的数据属性添加到实例对象，而不会影响方法的有效性，只要避免名称冲突——再次注意，命名约定可在此节省大量令人头痛的问题。 从方法中引用数据类型没有简写，这增加了方法的可读性: 在浏览方法时，不会混淆局部变量和实例变量。 通常，方法的第一个参数称为self。这只不过是一个约定: 名字self对Python来说绝对没有特殊含义。但是，请注意，不遵循约定的Python代码对于Python程序员来说可能不易读取。 任何作为类属性的函数对象都为该类的实例定义了一个方法 # Function defined outside the class def f1(self, x, y): return min(x, x+y) class C: f = f1 def g(self): return 'hello world' h = g #f, g, h都是类C的所有属性，它们都是指向函数对象的，因此它们都是C实例的所有方法。 方法可以通过使用self参数的方法属性来调用其它方法: class Bag: def __init__(self): self.data = [] def add(self, x): self.data.append(x) def addtwice(self, x): self.add(x) self.add(x) 方法可以像普通函数一样引用全局名称。与方法关联的全局作用域是包含其定义的模块。(一个类永远不会被用作全局作用域) 虽然很少有人在方法中使用全局数据，但全局作用域有许多合法用途: 首先，导入全局作用域的函数和模块可以被方法使用，以及在其中定义的函数和类。通常，包含该方法的类本身是在全局作用域内定义的。 每个值都是一个对象，因此有一个类(类型)。它被存储为object.__class__ \r\r","date":"2018-05-06","objectID":"/python/:9:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"继承 Inheritance 当然，如果不支持继承，语言特性就不值得称为\"类”。 #派生(derived) class DerivedClassName(BaseClassName): \u003cstatement-1\u003e . . . \u003cstatement-N\u003e 基类(BaseClassName)必须在包含派生类(derived class)定义的作用域中定义。代替基类名称，其它表达式也是允许的。 #当基类在另一个模块中被定义 class DerivedClassName(modname.BaseClassName): 派生类(derived class)定义的执行过程与基类(base class)相同。当构造(constructed)类对象时，基类将被记住。这用于解析属性引用: 如果在类中未找到请求的属性，则搜索继续查找基类。如果基类本身是从其它类派生的，则此规则将递归应用。 派生类的实例化么有什么特别的: DerivedXlassName()创建一个新的类实例。方法解析如下: 如果需要，搜索相应的类属性，沿着基类链降序排列，如果产生函数对象，则方法引用是有效的。 派生类可以覆盖(override)基类的方法。由于方法在调用同一对象的其它方法时没有特殊的权限，因此调用另一个在同一基类中定义的方法的基类方法可能最终会调用派生类的方法来覆盖它。 派生类的覆盖(override)方法事实上可能需要扩展而不是简单地替换同名的基类方法。有一种简单的方法可以直接调用基类方法: 只需调用BaseClassName.methodname(self, arguments)即可。 Python有两个与继承有关的内建函数: isinstance() 检查一个实例的类型。isinstance(obj, int)只有在obj.__class__是int或从int派生的某个类时才为true issubclass() 检查类继承。 \r多重继承 Multiple Inheritance Python支持多重继承的形式。 class DerivedClassName(Base1, Base2, Base3): \u003cstatement-1\u003e . . . \u003cstatement-N\u003e 在最简单的情况下，你可以将从父类继承的属性视为深度优先(depth first)，从左到右搜索，而不是在同一个类中进行两次搜索，其中层次结构中存在重叠。 因此，如果在DerivedClassName中找不到属性，则在Base1中搜索该属性，然后(递归)在Base1的基类中搜索该属性。如果未找到，则在Base2中搜索该属性，依此类推。 动态排序是必要的，因为多重继承的情况都表现出一个或多个菱形关系。例如，所有类都从对象继承，所以任何多重继承的情况都会提供多条路径来达到对象。为了避免基类被多次访问，动态算法使搜索顺序线性化，以保留没各类众指定的从左到右的顺序，每个父类只调用一次，这是单调的。 \r私有变量 Private Variables Python中不存在私有(private)实例变量，这些变量除了在对象内部以外不能访问。不过，大多数Python代码都有一个约定，以下划线_spam为前缀的名称应被视为API的非公共部分(无论是函数，方法或数据成员)。 由于私有类(class-private)成员有一个有效的用例(即为了避免名称与由子类定义的名称的冲突)，所以对这种称为name mangling的机制的支持有限。任何__spam形式的标识符在文本上用_classname__spam替换，其中classname是当前类名称，前导下划线被去除。只要它在类的定义类发生，就不会考虑标识符位置。 Name mangling 有助于让子类重写方法而不会破坏intraclass方法调用: class Mapping: def __init__(self, iterable): self.items_list = [] self.__update(iterable) def update(self, iterable): for item in iterable: self.items_list.append(item) __update = update # private copy of original update() method class MappingSubclass(Mapping): def update(self, keys, values): # provides new signature for update() # but does not break __init__() for item in zip(keys, values): self.items_list.append(item) 请注意，强化规则的设计主要是为了避免事故；它仍然可以访问或修改被认为是私有的变量。 注意传递给exec()或eval()的代码并不认为调用类的类名是当前类；这与global语句的效果类似，其效果同样局限于一起进行字节编译的代码。getattr(), setattr()和delattr()以及直接使用__dict__时也有相同的限制。 \r\r","date":"2018-05-06","objectID":"/python/:9:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"Odds and Ends class Employee: pass john = Employee() # Create an empty employee record # Fill the fields of the record john.name = 'John Doe' john.dept = 'computer lab' john.salary = 1000 一段期望特定抽象数据类型的Python代码通常通常可以传递一个模拟该数据类型方法的类。 例如，如果你有一个函数可以格式化文件对象中的某些数据，则可以使用方法read()和readline()来定义一个类，以便从字符串缓冲区总获取数据，然后将其作为参数传递。 \r\r","date":"2018-05-06","objectID":"/python/:9:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"迭代器 Iterators 你可能注意到大多数容器对象可以使用for语句循环遍历: for element in [1, 2, 3]: print(element) for element in (1, 2, 3): print(element) for key in {'one':1, 'two':2}: print(key) for char in \"123\": print(char) for line in open(\"myfile.txt\"): print(line, end='') 这种访问方式清晰，简洁，方便。迭代器的使用贯穿并统一了Python。for语句在容器对象上调用iter()。该函数返回一个迭代器对象，该对象定义一次访问容器中元素的方法__next__()。当没有更多元素是，__next__()引发一个StopIteration异常，它告诉for循环终止。 你可使用next()内置函数调用__next__()方法: \u003e\u003e\u003e s = 'abc' \u003e\u003e\u003e it = iter(s) \u003e\u003e\u003e it \u003citerator object at 0x00A1DB50\u003e \u003e\u003e\u003e next(it) 'a' \u003e\u003e\u003e next(it) 'b' \u003e\u003e\u003e next(it) 'c' \u003e\u003e\u003e next(it) Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e next(it) StopIteration 看到了迭代器协议背后的机制，很容易将迭代器行为添加到类中。定义一个__iter__()方法，该方法使用__next__()方法返回一个对象。 class Reverse: \"\"\"Iterator for looping over a sequence backwards.\"\"\" def __init__(self, data): self.data = data self.index = len(data) def __iter__(self): return self def __next__(self): if self.index == 0: raise StopIteration self.index = self.index - 1 return self.data[self.index] \u003e\u003e\u003e rev = Reverse('spam') \u003e\u003e\u003e iter(rev) \u003c__main__.Reverse object at 0x00A1DB50\u003e \u003e\u003e\u003e for char in rev: ... print(char) ... m a p s \r\r","date":"2018-05-06","objectID":"/python/:9:7","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"生成器 Generators 生成器是创建迭代器的简单而强大的工具。它们像常规函数一样编写，但只要它们想返回数据就是用yield语句。每次next()被调用时，生成器都会从停止的地方恢复(它记住所有的数据值以上次执行的代码)。 def reverse(data): for index in range(len(data)-1, -1, -1): yield data[index] \u003e\u003e\u003e for char in reverse('golf'): ... print(char) ... f l o g 任何可用生成器完成的事情也可用前面的基于类的迭代器完成。使生成器如此紧凑的原因是__iter__()和__next__()方法时自动创建的。 另一个关键特性是本地变量和执行状态在调用之间自动保存。这使得该函数更容易编写，并且比使用self.index和self.data等实例变量的方法更加清晰。 除了自动方法创建和保存程序状态之外，当生成器终止时，它们会自动产生StopIteration。结合起来，这些功能可以轻松创建迭代器，而无需编写常规函数。 \r\r","date":"2018-05-06","objectID":"/python/:9:8","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"生成器表达式 Generator Expressions 一些简单的生成器可以使用与列表解析类似的语法简洁地编码为表达式，带括号而不是方括号。这些表达式适用于通过封闭函数立即使用生成器的情况。 生成器表达式比完整的生成器定义更紧凑但功能更少，并且倾向于比等效的列表解析更具有内存友好性。 \u003e\u003e\u003e sum(i*i for i in range(10)) # sum of squares 285 \u003e\u003e\u003e xvec = [10, 20, 30] \u003e\u003e\u003e yvec = [7, 5, 3] \u003e\u003e\u003e sum(x*y for x,y in zip(xvec, yvec)) # dot product 260 \u003e\u003e\u003e from math import pi, sin \u003e\u003e\u003e sine_table = {x: sin(x*pi/180) for x in range(0, 91)} \u003e\u003e\u003e unique_words = set(word for line in page for word in line.split()) \u003e\u003e\u003e valedictorian = max((student.gpa, student.name) for student in graduates) \u003e\u003e\u003e data = 'golf' \u003e\u003e\u003e list(data[i] for i in range(len(data)-1, -1, -1)) ['f', 'l', 'o', 'g'] \r \r","date":"2018-05-06","objectID":"/python/:9:9","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"虚拟环境 Virtual Environments and Packages 应用程序有时候需要特定的模块版本，或者某个模块只支持特定Python版本。 这就意味着一个Python安装版本可能无法满足每个应用程序的要求。(如某个应用程序支持Python2.7，而某个应用程序支持Python3.x) 此问题的解决方案是创建一个虚拟环境(virtual environment)——一个包含特定Python安装包和软件包的目录树。 这样，不同的应用程序就可以使用不同的虚拟环境。 \r\r","date":"2018-05-06","objectID":"/python/:10:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"创建虚拟环境 Creating Virtual Environments 用于创建和管理虚拟环境额模块称为venv.它通常会为你安装最新版本的Python，你也可以选择Python版本。 激活虚拟环境后，会改变提示符并修改环境，以便提供特定的Python版本。 #创建虚拟环境 python3 -m venv /tmp/pythonVenv #激活 source /tmp/pythonVenv/bin/activate (pythonVenv) [zhang@zhang21 ~]$ (pythonVenv) [zhang@zhang21 ~]$ python \u003e\u003e\u003e import sys \u003e\u003e\u003e sys.path ['', '/usr/lib64/python34.zip', '/usr/lib64/python3.4', '/usr/lib64/python3.4/plat-linux', '/usr/lib64/python3.4/lib-dynload', '/tmp/pythonVenv/lib64/python3.4/site-packages', '/tmp/pythonVenv/lib/python3.4/site-packages'] #退出 deactivate \r\r","date":"2018-05-06","objectID":"/python/:10:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"pip包管理 你可以使用pip程序进行搜索、安装、升级和移除软件包。pip程序默认从\u003cpypi.org\u003e安装软件包。 pip freeze 以requirements的格式输出已安装软件包。这很重要。 pip search sh #默认安装最新版本 pip install sh #安装指定版本 pip install sh=1.10.2 pip install --upgrade sh pip uninstall sh #显示已安装的模块的详细信息 pip show sh #列出已安装模块 pip list pip freeze \u003e requirements.txt #安装依赖 pip install -r ./requirements.txt \r配置国内源 Linux: # global vim ~/.pip/pip.conf # aliyun [global] trusted-host=mirrors.aliyun.com index-url=https://mirrors.aliyun.com/pypi/simple/ # temporary pip install xxx -i https://mirrors.aliyun.com/pypi/simple/ \r\r\r","date":"2018-05-06","objectID":"/python/:10:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"下划线 参考: https://shahriar.svbtle.com/underscores-in-python https://segmentfault.com/a/1190000002611411 https://zhuanlan.zhihu.com/p/36173202 本节讨论Python中下划线(_)的使用，它的大部分用法都是一种惯例约定。 模式 栗子 含义 单下划线前缀 _var 命名约定，仅供内部使用。通常不会有Python解释器强制执行，只作为对程序员的提示 单下划线后缀 var_ 按约定使用以避免与Python关键字的命名冲突 双下划线前缀 __var 当在类上下文中使用时，触发名称修饰 双下划线前后缀 __var__ 表示Python语言定义的特殊方法 单个下划线 _ 三个情况 \r","date":"2018-05-06","objectID":"/python/:11:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"单个下划线 单下划线(_)主要有三种情况: 解释器中 下划线(_)符号指交互式解释器中最后一次执行语句的返回结果。 \u003e\u003e\u003e _ Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e NameError: name '_' is not defined \u003e\u003e\u003e \u003e\u003e\u003e 111 111 \u003e\u003e\u003e \u003e\u003e\u003e _ 111 作为名称使用 下划线(_)用作被丢弃的名称。这样可以让阅读你代码的人知道，这是个不会被使用的特定名称。 国际化 下划线(_)用作函数名。这种情况下，单下划线经常被用作国际化和本地化字符串翻译查询的函数名。 在Django中，你可能会看到: from django.utils.translation import ugettext as _ from django.http import HttpResponse def my_view(request): output = _(\"Welcome to my site.\") return HttpResponse(output) \r\r","date":"2018-05-06","objectID":"/python/:11:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"单下划线前缀的名称 以单下划线做前缀的名称(如_shahriar)，指定了这个名称是私有的。 在有些import *的场景中，下一个使用你代码的人会明白这个名称仅供内部使用。 下划线前缀的含义是告知其他程序员：以单个下划线开头的变量或方法仅供内部使用。 该约定在PEP 8中有定义。 如果你写了from module import *，那么以单下划线开头的名称都不会被导入，除非模块或包中的__all__列表显式地包含了它们。 \r\r","date":"2018-05-06","objectID":"/python/:11:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"单下划线后缀的名称 以单下划线后缀的名称(如var_)，有时，一个变量的最合适的名称已被一个关键字所占用。在这种情况下，你可以附加一个下划线来解决命名冲突。 \u003e\u003e\u003e def make_object(name, class): SyntaxError: \"invalid syntax\" \u003e\u003e\u003e def make_object(name, class_): ... pass \r\r","date":"2018-05-06","objectID":"/python/:11:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"双下划线前缀的名称 以双下划线做前缀的名称(如__shahriar)，它对解释器有特定含义。Python中的这种用法是为了避免与子类定义的名称冲突。 \r\r","date":"2018-05-06","objectID":"/python/:11:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"前后都有双下划线的名称 前后都有双下划线的名称(如__init__)，是Python的特殊方法名，这是一种惯例，一种确保Python系统中的名称不会跟用户自定义的名称发生冲突的方式。 \r\r\r","date":"2018-05-06","objectID":"/python/:11:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"代码和命名规范 \r","date":"2018-05-06","objectID":"/python/:12:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"代码规范 编码: 如无特殊情况，一律使用utf-8编码，文件头部加入#-*-coding: utf-8-*- 缩进: 统一使用4个空格进行缩进，不要使用tab 行宽: 每行代码尽量不要超过80个字符（特殊情况下最长不要超过120个字符） 引号: 自然语言使用双引号，机器语言使用单引号。因此，代码里多数应该使用单引号 空行: 模块级函数和类定义之间空两行； 类成员函数之间空一行。函数中可以使用空行分隔出逻辑相关的代码 class Abc: def __init__(self): pass def bcd(self): pass def main(): pass import语句: 应该分行书写；应该放在模块说明和文档字符串之后，全局变量之前；应按照顺序排列，每组之间用一个空行分隔 import os import sys from subprocess import Popen, PIPE from abc.bcd import Xyz 换行: python支持括号内换行；使用反斜杠换行 文档字符串: 所用公共模块、函数、类、方法，都应该写文档字符串 \r\r","date":"2018-05-06","objectID":"/python/:12:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"命名规范 模块名: 尽量使用小写、尽量短，尽量不要使用下划线（除非多个单词，且数量不多的情况） # 正确的模块名 import abc import abc_def # 不推荐的模块名 import Abc 包名: 和模块名一样 文件名: 小写，可使用下划线 类名: 使用驼峰命名风格，首字母大写，私有类可用一个下划线开头。 Class Abc(): pass Class _PrivateAbc(Abc): pass 函数名: 一律小写，如有多个单词，用下划线隔开。私有函数在前面加一个下划线。 def abc(): pass def abc_def(): pass def _abc(): pass 变量名: 尽量小写，如有多个单词，用下划线隔开；常量和全局变量采用全大写，如果多个单词，用下划线隔开。 name = 'abc' MAX_CLIENT = 1000 \r 语言参考 The Python Language Reference Python参考手册描述了Python语言的语法(syntax)和核心语义(core semantics)。 \r\r","date":"2018-05-06","objectID":"/python/:12:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"介绍 Introduction 此参考手册描述了Python编程语言，它并不是一个教程。 如果你正在使用Python并且想知道关于改语言的特定区域的精确规则是什么，那么你绝对应该能够在这里找到它们。 \r\r","date":"2018-05-06","objectID":"/python/:13:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"词法分析 Lexical analysis 解析器(parser)读取Python程序。解析器的输入是由词法分析器生成的令牌流(stream of tokens)。本章描述了词法解析器如何将文件分解为令牌。 Python将程序文本读作Unicode code point，源文件的编码可以通过编码声明给出，默认为UTF-8，具体请参阅PEP 320。如果源文件无法被编码，则抛出语法错误。 \r\r","date":"2018-05-06","objectID":"/python/:14:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"行结构 Line structure Python程序分为许多逻辑行。 逻辑行 Logical lines 逻辑行的结尾由token NEWLINE表示。语句不能跨过逻辑行边界，除非语法允许NEWLINE。通过遵循显式或隐式的行连接规则，从一个或多个物理行构造逻辑行。 物理行 Physical lines 物理行是由行尾序列终止的字符序列。在源文件和字符串中，可使用任何标准平台的行终止序列。Unix格式使用ASCII的LF，Windows格式使用ASCII的CR LF，或使用旧的Macintosh格式ASCII CR字符。无论平台如何，所有这些格式都可以平等使用。输入的结尾也充当最终物理行的隐式终止符。 嵌入Python时，应使用标准C约定的换行符将源代码字符传递给Python API。 注释 Comments 注释以哈希字符(#)开头，以物理行的末尾结束。注释表示逻辑行的结束，除非调用隐式行连接规则。语法会直接忽略注释。 编码声明 Encoding declarations 如果Python脚本中的第一行或第二行中的注释与正则表达式coding[=:]\\s*([-\\w.]+)相匹配，则此注释将作为编码声明处理。编码声明必须出现在它自己的一行上。若果是第二行，则第一行也必须是仅注释行。 编码表达式的推荐格式: # -*- coding: \u003cencoding-name\u003e -*- 如果未发现编码声明，默认编码为UTF-8。 如果声明了编码，则必须有Python识别编码名称。编码用于所有词法分析，包括字符串文字，注释和标识符。 显式行连接 Explicit line joining 可使用反斜杠(\\)将两个或多个物理行连接到逻辑行中。 if 1900 \u003c year \u003c 2100 and 1 \u003c= month \u003c= 12 \\ and 1 \u003c= day \u003c= 31 and 0 \u003c= hour \u003c 24 \\ and 0 \u003c= minute \u003c 60 and 0 \u003c= secod \u003c 60: #Look like a valid date return 1 以反斜杠结尾的行不能编写注释。反斜杠在字符串文字外的一行上的其他位置是非法的。 隐式行连接 Implicit line joining 括号，方括号，花括号中的表达式可以在不使用反斜杠的情况下分割为多个物理行。 month_names = ['January', ‘February', 'March', #comments 'April', 'May', 'June', #comments 'July', 'Auguest', 'September', #comments 'October, 'November', 'December'] 隐式的连续行可以带有注释，连续行的缩进并不重要。允许空白的连续行。 空白行 Blank lines 包含空格，制表符，换页符，注释的逻辑行会被忽略。在标准的交互式解释器中，完全空白的逻辑行终止多行语句。 缩进 Indentation 逻辑行开头的前导空白(空格和制表符)用于计算行的缩进级别，而后者又用于语句的分组。 tabs被1-8个空格替换(从左到右)，使得包括被替换的字节数总是八的倍数。第一个非空白字符前面的空格总数确定行的缩进。缩进不能够使用反斜杠在多个物理行上分隔。 如果源文件以一种方式混合制表符(tab)和空格，使得含义取决于空格中制表符的价值，则缩进被拒绝为不一致。会抛出TabError异常。 跨平台兼容性说明： 由于non_Unix平台上文本编辑器的性质，在源文件中使用制表符和空格的混合来缩进是不明智的。还应注意，不同平台可以明确地限制最大缩进级别。 \r\r","date":"2018-05-06","objectID":"/python/:14:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"标识符和关键字 Identifiers and keywords 标识符也称为名称，标识符的长度不受限制。 Python中标识符的语法基于Unicode标准附件UAX-31，详情请参考PEP 3131 在ASCII范围内(U+0001...U+007F)，有效的字符与Python2相同。大小写字母A-z，除第一个字符外的下划线(_)，数字0-9。 Python3引入了ASCII范围外的其它字符，对于这些字符，分类使用unicodedata模块中包含的Unicode Character Database的版本。 Unicode类别代码表示： Lu： uppercase letters Ll： lowercase letters Lt： titlecase letters Lm： modifier letters Lo： other letters Nl： letter numbers Mn： nonspacing marks Mc： spacing combining marks Nd： decimal numbers Pc： connector punctuations Other_ID_Start： explicit list of characters in PropList.txt to support backwards compatibility Other_ID_Continue： likewise 关键字 Keywords 以下标识符用作保留字或关键字，不能用作普通标识符。 help(keywords) False class finally is return None continue for lambda try True def from nonlocal while and del global not with as elif if or yield assert else import pass break except in raise 保留的类标识符 Reserved classes of identifiers 某些类标识符(除了关键字)具有特殊含义。这些类由前导/后置下划线(_)字符标识： _* 特殊标识符_，用于交互式解释器中存储上次评估的结果，它保存在内建模块中。当不处于交互式模式时，下划线_没有特殊含义，也没有定义。 名称_通常与国际化一起使用，这是一种约定。 __*__ 系统定义的名称。这些名称由解释器及其实现(包括标准库)来定义。在任何情况下，任何使用__*__名称都不会明确记录，在没有任何警告的情况下会受到破坏。 __* 私有类(class-private)名称。在类定义的上下文中使用中使用此目录中的名称，名称将被重写，以使用损坏的格式来帮助避免基类和派生类(base and derived class)的私有属性之间的名称冲突。 \r\r","date":"2018-05-06","objectID":"/python/:14:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"文字值 Literals 文字值是一些内建类型的常量值的符号。 字符串和字节文字值 String and Bytes literals 字符串文字值和字节文字值描述： stringliteral ::= [stringprefix](shortstring | longstring) stringprefix ::= \"r\" | \"u\" | \"R\" | \"U\" | \"f\" | \"F\" | \"fr\" | \"Fr\" | \"fR\" | \"FR\" | \"rf\" | \"rF\" | \"Rf\" | \"RF\" shortstring ::= \"'\" shortstringitem* \"'\" | '\"' shortstringitem* '\"' longstring ::= \"'''\" longstringitem* \"'''\" | '\"\"\"' longstringitem* '\"\"\"' shortstringitem ::= shortstringchar | stringescapeseq longstringitem ::= longstringchar | stringescapeseq shortstringchar ::= \u003cany source character except \"\\\" or newline or the quote\u003e longstringchar ::= \u003cany source character except \"\\\"\u003e stringescapeseq ::= \"\\\" \u003cany source character\u003e bytesliteral ::= bytesprefix(shortbytes | longbytes) bytesprefix ::= \"b\" | \"B\" | \"br\" | \"Br\" | \"bR\" | \"BR\" | \"rb\" | \"rB\" | \"Rb\" | \"RB\" shortbytes ::= \"'\" shortbytesitem* \"'\" | '\"' shortbytesitem* '\"' longbytes ::= \"'''\" longbytesitem* \"'''\" | '\"\"\"' longbytesitem* '\"\"\"' shortbytesitem ::= shortbyteschar | bytesescapeseq longbytesitem ::= longbyteschar | bytesescapeseq shortbyteschar ::= \u003cany ASCII character except \"\\\" or newline or the quote\u003e longbyteschar ::= \u003cany ASCII character except \"\\\"\u003e bytesescapeseq ::= \"\\\" \u003cany ASCII character\u003e 两种类型的文字值都可用单引号(')或双引号(\")括起来，也能包含在三个引号中。反斜杠(\\)字符用于转义好友特殊含义的字符。 字节文字值总是以b或B为前缀，它们生成byte类型的实例，而不是str类型。它们可能只包含ASCII字符(128)，更大的字节必须转义。 字符串和字节文字值都可以选择以字母r或R为前缀，如原始字符串将反斜杠视为文字字符。因此，在字符串文字值中，原始字符串中的\\u和\\U不会被特殊处理。 公认的转义序列： Escape Sequence Meaning \\newline Backslash and newline ignored \\\\ Backslash () \\' Single quote (') \\\" Double quote (\") \\a ASCII Bell (BEL) \\b ASCII Backspace (BS) \\f ASCII Formfeed (FF) \\n ASCII Linefeed (LF) \\r ASCII Carriage Return (CR) \\t ASCII Horizontal Tab (TAB) \\v ASCII Vertical Tab (VT) \\ooo Character with octal value ooo \\xhh Character with hex value hh 仅在字符串文字值中识别的转义序列： Escape Sequence Meaning \\N{name} Character named name in the Unicode database \\uxxxx Character with 16-bit hex value xxxx \\Uxxxxxxxx Character with 32-bit hex value xxxxxxxx 字符串文字串联 String literal concatenation 多个相邻的字符串或字节文字值(由空格分隔)，可能使用不同的引用约定，并且它们的含义与它们的串联相同。因此，\"hello\" 'world'等同于\"helloworld\"。此功能可用于减少反斜杠的数量，方便地跨长行分隔长字符串，甚至可以为字符串的某些部分添加注释。 re.compile(\"[A-Za-z]\" #letter or underscore \"[A-Za-z0-9_]*\" #letter, digit or underscore ) 注意，此功能在语法级别上定义，但在编译时实现。必须使用+操作符在运行时连接字符串表达式。 格式化的字符串文字值 Formatted string literals 格式化的字符串文字值是以f或F为前缀的字符串文字，这些字符串可能包含替换字段——由{}分隔的表达式。 f_string ::= (literal_char | \"{{\" | \"}}\" | replacement_field)* replacement_field ::= \"{\" f_expression [\"!\" conversion] [\":\" format_spec] \"}\" f_expression ::= (conditional_expression | \"*\" or_expr) (\",\" conditional_expression | \",\" \"*\" or_expr)* [\",\"] | yield_expression conversion ::= \"s\" | \"r\" | \"a\" format_spec ::= (literal_char | NULL | replacement_field)* literal_char ::= \u003cany code point except \"{\", \"}\" or NULL\u003e 栗子： \u003e\u003e\u003e name = \"Fred\" \u003e\u003e\u003e f\"He said his name is {name!r}.\" \"He said his name is 'Fred'.\" \u003e\u003e\u003e f\"He said his name is {repr(name)}.\" # repr() is equivalent to !r \"He said his name is 'Fred'.\" \u003e\u003e\u003e width = 10 \u003e\u003e\u003e precision = 4 \u003e\u003e\u003e value = decimal.Decimal(\"12.34567\") \u003e\u003e\u003e f\"result: {value:{width}.{precision}}\" # nested fields 'result: 12.35' \u003e\u003e\u003e today = datetime(year=2017, month=1, day=27) \u003e\u003e\u003e f\"{today:%B %d, %Y}\" # using date format specifier 'January 27, 2017' \u003e\u003e\u003e number = 1024 \u003e\u003e\u003e f\"{number:#0x}\" # using integer format specifier '0x400' 数字文字值 Numeric literals 有三种类型的数字文字值： integers floating point numbers imaginary numbers 没有复数文字值。 请注意，数字文字值不包含符号。像-1实际是由一元运算符-和文字值1组成的表达式。 整数文字值 除了可以存储在可用内存中之外，整数文字值的长度没有限制。 integer ::= decinteger | bininteger | octinteger | hexinteger decinteger ::= nonzerodigit ([\"_\"] digit)* | \"0\"+ ([\"_\"] \"0\")* bininteger ::= \"0\" (\"b\" | \"B\") ([\"_\"] bindigit)+ octinteger ::= \"0\" (\"o\" | \"O\") ([\"_\"] octdigit)+ hexinteger ::= \"0\" (\"x\" | \"X\") ([\"_\"] hexdigit)+ nonzerodigit ::= \"1\"...\"9\" digit ::= \"0\"...\"9\" bindigit ::= \"0\" | \"1\" octdigit ::= \"0\"...\"7\" hexdigit ::= digit | \"a\"...\"f\" | \"A\"...\"F\" 浮点数文字值 floatnumber ::= pointfloat | exponentfloat pointfloat ::= [digitpart] fractio","date":"2018-05-06","objectID":"/python/:14:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"运算符 Operators + - * ** / // % @ \u003c\u003c \u003e\u003e \u0026 | ^ ~ \u003c \u003e \u003c= \u003e= == != \r\r","date":"2018-05-06","objectID":"/python/:14:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"分隔符 Delimiters ( ) [ ] { } , : . ; @ = -\u003e += -= *= /= //= %= @= \u0026= |= ^= \u003e\u003e= \u003c\u003c= **= Python中以下ASCII字符有重要意义： ' \" # \\ Python中不使用以下ASCII字符: $ ? \r\r\r","date":"2018-05-06","objectID":"/python/:14:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"数据模型 Data model \r","date":"2018-05-06","objectID":"/python/:15:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"对象，值和类型 Objects, values and types **对象(Objects)**是Python的数据抽象。Python程序中的所有数据都由对象或对象之间的关系表示。 每个对象都有一个标识(Identity)，一个类型(Type)和一个值(Value)。对象的标识一旦创建就永远不会改变。is操作符就是比较两个对象的标识；id()函数返回一个表示其标识的整数。 name = 'zhang' NAME = 'ZHANG' name is NAME False CPython中，id(x)是存储x的内存地址。 对象的**类型(Type)**确定了对象支持的操作，并且还定义了该类型的对象的可能值。type()函数返回对象的类型。与对象标识一样，对象的类型也是不可更改的。 某些对象的**值(Value)**可以改变。值可以改变的对象被认为是可变的(mutable)，值不可改变的的对象被称为是不可变的(immutable)。对象的可变性由其类型决定。例如，数字(number)，字符串(string)，元组(tulple)是不可变的，字典(dictionary)和列表(list)是不可变的。 对象永远不会被明确销毁，然而，当它们变得无法到达(unreachable)时，它们可能会被垃圾回收(garbage-collected)。允许实现推迟垃圾回收或完全省略垃圾回收——只要没有回收到仍然是可以访问的对象，垃圾回收的实现方式就是如此。 请注意，使用实现的tracing或debugging工具可以使对象保持活动状态，这些对象通常是可回收的。另请注意，使用try...except语句捕获异常可能会使对象保持活动状态。 某些对象包含对外部(external)资源的引用，如打开的文件。当对象被垃圾回收时，这些资源被释放，但由于不能保证垃圾回收发生，这些对象还提供了一种释放外部资源的明确的方法——close()方法。强烈建议程序明确关闭此类对象。try...finally语句和with语句提供了方便的方法。 一些对象包含对其它对象的引用，这被称为容器(container)，容器的栗子是元组，列表和字典。引用是容器值的一部分。在大多数情况下，当我们谈论容器的值时，指的是值而并非容器对象的标识；但是，但我们谈论容器的可变性时，只隐含了直接包含的对象的标识。因此，如果一个不可变容器(如元组)包含对可变对象的引用，则如果更改了可变对象，则其值会改变。 类型几乎影响对象行为的所有方面。在某种意义上，即使对象标识的重要性也会受到影响：对于不可变类型，计算新值的操作实际上可以返回对具有相同类型和值的任何对象的引用，而对于可变对象，这是不允许的。 \r\r\r","date":"2018-05-06","objectID":"/python/:15:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"标准类型层次结构 The standard type hierarchy 下面列出了Python內建的类型，扩展模块可定义其它类型。 下面的一些类型描述包含一个列出的special attributes段落。这些属性提供对实现的访问，不适用于一般用途。它们的定义未来可能发生变化。 None 此类型具有单个值(single value)。有一个具有此值的对象，可通过內建名称None访问此对象。在许多情况下它用于表示缺少值，例如，它是未明确返回任何内容的函数的返回。Its truth value is false. NotImplemented 此类型具有单个值。有一个具有此值的对象，可通过內建名称NotImplemented访问此对象。如果数值方法和富比较方法尉氏县所提供的操作数的操作，则返回此值。Its truth value is true. Ellipsis 此类型具有单个值。有一个具有此值的对象，可通过...或內建名称Ellipsis访问此对象。Its truth value is true. numbers.Number 由数字创建，并由算术运算符和算术内置函数作为结果返回。数值对象是不可变的。Python数字与数学数字密切相关，但收到计算机中数值表示的限制。 Python区分整数(integer)、浮点数(floating point number)和复数(complex number)： numbers.Integral 表示整数的数学集合(正数和复数)的元素，有两种类型的整数: Integers (int) 这代表无限范围内(unlimited range)的数字，仅受到可用(virtual)memory的限制。 Booleans (bool) 这代表真值的True和False，这两个对象是唯一的布尔值对象。布尔类型是整数类型的子类型，布尔值在几乎所有上下文中的行为分别类似于值0和1，例外的是，当转换为字符串时，分别返回字符串False或True。 numbers.Real (float) 这代表机器级双精度(double precision)浮点数。您可以接受底层机器架构，以获得可接受的范围和溢出处理。Python不支持单精度浮点数，没有理由使用两种浮点数复杂化语言。 numbers.Complex (complex) 这将复数表示为一对机器级双精度浮点数。可通过只读属性z.real和z.imag来检索复数z的实部(real)和虚部(imaginary)。 Sequences 这表示由非负数索引的有限有序集。內建函数len()返回序列的项数。当序列长度为n时，索引集数字为0, 1, ..., n-1。序列的i项由a[i]选择。 序列还支持切片(slicing): a[i:j]选择一定范围内的项。当使用表达式时，切片是相同类型的序列。 一些序列还支持带有步进(step)参数的扩展切片: a[i:j:k]。 序列根据其可变性进行区分： Immutable sequences 不可变序列类型的对象一旦创建就不能更改。如果对象包含对其它对象的引用，则这些其它对象可能是可变的并且可能会被更改；但是，由不可变对象直接引用的对象集合不能更改。 不可变序列有以下类型： Strings 字符串是表示Unicode code ponit的值序列。U+0000 - U+10FFFF范围内的代码点都可以用字符串表示。Python没有char类型；相反，字符串中的每个代码点都表示为长度为1的字符串对象。內建函数ord()将代码点从字符串形式转换为0-10FFFF范围内的整数；chr()将0-10FFFF范围内的整数转化为对应长度为1的字符串对象；str.encode()可用于将str转换为bytes，而bytes.decode()用于实现相反的操作。 \u003e\u003e\u003e ord('a') 97 \u003e\u003e\u003e chr(97) a \u003e\u003e\u003e str.encode('a') b'a' \u003e\u003e\u003e bytes.decode(b'a') a Tuples 元组的项是任意Python对象。两个或多个项的元组由逗号分隔的表达式列表组成。空元组可由一对空括号组成。 Bytes 字节对象是一个不可变的数组。这些项是8-bit bytes，由0-255范围内的整数表示。 Mutable sequences 可变序列创建之后可以更改。订阅和切片表示法可用作赋值和del语句的目标。 目前有两种可变序列类型： **Lists 列表的项是任意Python对象。通过将逗号分隔的表达式放在方括号中来形成列表。 Byte Arrays bytearray对象是一个可变数组。它们由內建的bytearray()构造器(constructor)创建。 扩展模块array提供了可变序列类型的另一个示例，collections模块也是如此。 Set types 这代表无序，有限的唯一不可变的对象集。因此，它们不能被任何下标索引。但是，它们可以迭代，內建函数len()返回集合的项目数。集合的常见用途是进行快速成员资格测试，从序列中删除重复项，以及计算数学运算(交集、并集、差集…)。 对于集合元素，相同的不可变性规则适用于字典的键。请注意，数字类型遵循数字比较的常规规则：如果两个数字相等(如 1, 1.0)，则它们中只能包含其中一个。 目前有两种固有的集合类型: Sets 这代表一个可变集合。它们通过內建的set()构造器进行创建，之后可通过多种方法进行修改(如 add())。 Frozen sets 这代表一个不可变集合。它们通过內建的frozenset()构造器进行创建。它是可变且可清除的，因此它可以再次用作另一个集合的元素，或作为字典的键。 Mappings 这表示由任意索引集合索引的有限对象集。如下标符号a[k]从映射a中选择由k索引的项；这可在表达式中使用，也可作为赋值或del语句的目标。內建函数len()返回映射中的项数。 目前有一种内在映射类型： Dictionaries 这表示有几乎任意值索引的有限对象集。唯一不能作为键接受的值是包含列表或字典或其它可变类型的值，这些值通过值而不是按对象标识进行比较，原因是字典的有效实现需要键的哈希值保持不变。用于键的数字类型遵循用于数字比较的正常规则：如果两个数字相等(如1, 1.0)，则它们互相地用于索引相同的字典项。 字典是可变的，它们可通过{...}符号创建。 扩展模块dbm.ndbm和dbm.gnu提供了映射类型的其它实例，collections模块也是如此。 Callable types 这是可应用函数调用操作的类型： User-defined functions 用户定义的函数对象由函数定义创建。它应使用包含于函数的形式参数列表相同数量的项的参数列表来调用它。 特殊属性(special attributes): Attribute Meaning - __doc__ The function’s documentation string, or None if unavailable; not inherited by subclasses Writable __name__ The function’s name Writable __qualname__ The function’s qualified name. New in version 3.3. Writable __module__ The name of the module the function was defined in, or None if unavailable. Writable __defaults__ A tuple containing default argument values for those arguments that have defaults, or None if no arguments have a default value Writable __code__ The code object representing the compiled function body. Writable __globals__ A reference to the dictionary that holds the function’s global variables — the global namespace of the module in which the function was defined. Read-only __dict__ The namespace supporting arbitrary function attributes. Writable __closure__ None or a tuple of cells that contain bindings for the function’s free variables. Read-only __annotations__ A dict containing annotations of parameters. The keys of the dict are the parameter names, and return for the return annotation, if provided. Writable __kwdefaults__ A dict containing defaults for keyword-only parameters. Writable","date":"2018-05-06","objectID":"/python/:15:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"特殊方法名称 Special method names 类可以通过定义具有特殊名称的方法来实现有特殊语法调用的某些操作。这是Python的运算符重载方法，允许类根据语言运算符定义自己的行为。 将特殊方法设置为None表示相应的操作不可用。例如，如果将类的__iter__()设置为None，则该类不可迭代，因此在其实例调用iter()将引发TypeError。 \r基本定制 Basic customization object.__new__(cls[,...]) 被调用来创建类cls.__new__()的新实例是一个静态方法，它将请求实例的类作为其第一个参数。其余参数是传递给对象构造函数表达式的参数。 \r\r\r\r","date":"2018-05-06","objectID":"/python/:15:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"执行模块 Execution model \r","date":"2018-05-06","objectID":"/python/:16:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"程序结构 Structure of a program Python程序由代码块构成。块是一段Python程序文档，作为一个单元执行。模块、函数体、类定义都是块。交互式输入的每个命令都是一个块。脚本文件是代码块，脚本命令是代码块。传递给内建函数eval()和exec()的字符串参数是一个代码块。 \r\r","date":"2018-05-06","objectID":"/python/:16:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"命名和绑定 Naming and binding \r名称绑定 Binding of names 名称指的是对象。名称有名称绑定操作引入。 以下构造绑定名称: 函数的形式参数(formal parameters) import语句 from...import *的import语句绑定导入模块中定义的所有名称，但以下划线(_)开头的名称除外。 类和函数的定义 作为标识符的目标 for循环头 在with...as或except子句之后 在del语句中出现的目标也被认为是此目的绑定的。 每个赋值或导入语句都发生在由类或函数定义或模块级别定义的块中。 如果名称绑定在块中，则它是该块的局部变量(local variable)，除非声明为nonlocal或global。如果名称绑定在模块级别，则它是全局变量(global variable)。模块代码块中的变量是本地和全局的。如果一个变量在代码块中使用但未在此定义，则它是一个自由变量(free variable)。 程序文本中每次出现的名称都是指由以下名称解析规则建立的名称的绑定。 \r\r名称解析 Resolution of names 范围(scopt)定义了块内名称的可见性。如果在块中定义了局部变量，则其范围包括该块。如果定义发生在函数块内，则作用于将扩展到定义块中包含的任何块，除非包含块为名称引入不同的绑定。 在代码块中使用名称时，将使用最近的封闭范围解析该名称。代码块可见的所有此类范围的集合称为块的环境。 如果找不到名称，则会引发NameError异常。如果当前作用域是函数作用域，并且名称引用尚未绑定到使用该名称的值的本地变量，则会引发UnboundLocalError异常(它是NameError的子类)。 如果名称绑定操作发生在代码块中的任何位置，则块中名称的所有使用都将被视为对当前块的引用。在绑定之前在块中使用名称时，可能会导致错误。这条规则很微妙，Python缺少声明，并允许在代码块中的任何位置进行名称绑定操作。可以通过扫描块的整个文本以确定名称绑定操作来确定代码块的局部变量。 如果global语句发生在块中，则语句中指定的名称的所有使用都将引用在顶级命名空间中的绑定的名称。通过搜索全局(global)命名空间(包含代码块的命名空间)和內建(build-in)命名空间(內建模块的命名空间)，在顶级命名空间中解析名称。首先搜索全局命名空间。如果在那里找不到名称，则搜索內建命名空间。global语句必须在名称的所有使用之前。 global语句与同一块中名称绑定具有相同的范围。如果自由变量的最近封闭范围包含全局语句，则将自由变量视为全局变量。 nonlocal语句使相应的名称引用最近的封闭函数范围中的先前绑定的变量。如果任何封闭的函数作用域中不存在给定的名称，则在编译时引发SyntaxError。 模块的命名空间在第一次导入模块式自动创建。脚本的主要模块始终被称为__main__。 exec()和eval()的类定义块和参数在名称解析的上下文中是特殊的。类定义是可以使用和定义名称的可执行语句。这些引用遵循名称解析的常规规则，但在全局命名空间中查找未绑定的局部变量。类定义的命名空间成为类的属性字典。类块中定义的名称范围仅限于类块;它没有扩展到方法的代码块——这包括了解和生成器表达式，因为它们是使用函数作用域实现的。 \r\r內建和严格执行 Builtins and restricted execution CPython实现细节：用户不该触碰__builtins__，它严格来说是一个实现细节。想要覆盖內建命名空间中的值的用户应该导入內建模块并适当地修改其属性。 与代码块执行相关联的內建命名空间实际上是通过在其全局命名空间中查找名称__builtins__来找到的；这应该是字典或模块。默认情况下，在__main__模块中，__builtin__是內建的builtins模块；在任何其它模块中，__builtins__是內建模块本身的字典的别名。 \r\r与动态功能的交互 Interaction with dynamic features 自由变量的名称解析在运行时发生，而不是在编译时发生。 eval()和exec()函数无权访问用于解析名称的完整环境。可在调用者的本地好全局命名空间中解析名称。自由变量不在最近的封闭空间中解析，而是在全局命名空间中解析。 \r\r\r","date":"2018-05-06","objectID":"/python/:16:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"异常 Exceptions **异常(exception)**是一种打破代码块正常控制流已处理错误或其它异常情况的方法。检测到错误时会出现异常，它可以由周围的代码块直接或间接调用发生错误的代码块的任何代码块处理。 Python解释器在检测到运行时错误引发异常。Python程序也可使用raise语句显式地引发异常。使用try...execpt语句处理异常，这种语句的finally子句可用于指定不处理异常的清理代码。 Python使用错误处理的termination模型：异常处理程序可找出发生的情况并继续在外层执行，但它无法修复错误原因并重试失败操作。 当根本不处理异常时，解释器终止程序的执行，或返回其交互式主循环。在任何一种情况下，它都会打印stack backtrace除非异常是SystemExit。 异常由类实例标识。根据实例的类选择except子句，它必须引用实例的类或其基类。该实例可以由处理程序接收，并且可以携带关于异常情况的附加信息。 \r\r\r\r","date":"2018-05-06","objectID":"/python/:16:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"import系统 The import system 通过导入(import)，一个模块中的Python代码可以访问另一个模块中的Python代码。import语句是调用导入机制的最常用方法，但它不是唯一的方法。importlib.import_module()和內建__import__()等函数也可用于导入机制。 import语句结合了两个操作，它搜索命名模块，然后将搜索结果绑定到本地范围中的名称。import语句的搜索操作定义为使用适当的参数调用__import__()函数。__import__()的返回值用于执行import语句的名称绑定操作。 对__import__()的直接调用仅执行模块搜索，如果找到，则执行模块创建操作。虽然可能会发生某些副作用，如导入父包…但只有import语句执行名称绑定操作。 当调用__import__()作为import语句的一部分时，将调用标准的内置__import__()。调用导入系统的其它机制可选择颠覆__import__()并使用自己的解决方案来实现导入语义。 首次导入模块时，Python会搜索模块。如果找到，它会创建一个模块对象，并对其进行初始化。如果找不到名称模块，则引发ModuleNotFoundError异常(No module named ‘xxx’)。Python在调用导入机制时实现了搜索命名模块的各种策略，可以修改和扩展这些策略。 \r\r","date":"2018-05-06","objectID":"/python/:17:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"importlib importlib模块提供了一个丰富的API，用于与导入系统进行交互。 \r\r","date":"2018-05-06","objectID":"/python/:17:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"Packages Python只有一种类型的模块对象，所有模块都属于这种类型，无论模块是用Python、C还是其它方式实现。为了帮助组织模块并提供命名层次结构，Python有一个**包(package)**的概念。 你可将包视为文件系统上的目录，将模块视为目录中的文件。处于此文档的目的，我们将使用这种方便的类比。包是按层次结构组织的，包本身可能包含子包以及常规模块。 需要记住的是，所有包都是模块，但并非所有模块都是包。换句话说，包是一种特殊的模块。具体来说，任何包含__path__属性的模块都被视为包。 Python定义了两种类型的包： Regular Packages Namespace packages \r\rRegular packages 常规包是Python v3.2及更早版本中存在的传统的包。常规包通常实现为包含__init__.py文件的目录。导入常规包时，将隐式地执行此__init__.py文件，并且它定义的对象将绑定到包命名空间的名称。__init__.py文件可以包含与任何其它模块可以包含的相同的Python代码，并且Python将在导入模块时向模块添加一些其它属性。 # 栗子 # 导入parent.one将隐式地执行parent/__init__.py和parent/one/__init__.py parent/ __init__.py one/ __init__.py two/ __init__.py three/ __init__.py \r\rNamespace packages 命名空间包是各个部分的组合，其中每个部分为父包提供子包。它可位于文件系统某个位置上，也可在zip文件、网络或Python导入期间其它位置。命名空间包可能/可能不(may or may not)直接对应于系统上得对象，它们可能是没有具体表示的虚拟模块。 命名空间包不使用普通列表作为其__path__属性。它们使用自定义可迭代类型，如果其父包的路径发生更改，它将在该包的下一次导入尝试时自动执行对包部分的新搜索。 使用命名空间包，没有parent/__init__.py文件。实际上，在导入搜索期间可能会找到多个父目录，其中每个目录由不同的部分提供。因此，parent/one可能不在物理上位于parent/two旁边。在这种情况下，Python就会为顶级父包创建一个命名空间包。 \r\r","date":"2018-05-06","objectID":"/python/:17:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"Searching 要开始搜素(search)，Python需要导入模块的完全限定名称。此名称可能来自import语句或其它导入函数的各种参数。 \r\r模块缓存 The module cache 导入期间检查的第一个位置是sys.modules。此映射用作先前已导入的所有模块的缓存，包括中间路径。因此，如果先前导入了a.b.c，则sys.modules将包含a, a.b, a.b.c的条目。每个键的值都是相应的模块对象。 在导入期间，将在sys.modules中查找模块名称。如果存在，则关联的值是满足导入的模块，并且该过程完成。但是，如果值为None，则引发ModuleNotFoundError异常。如果缺少模块名称，Python将继续搜索模块。 sys.modules是可写的。删除key可能不会破坏关联的模块，但它会使命名模块的缓存条目无效，导致Python在下次导入时重新搜索命名模块。key也可以分配None，强制下次导入模块导致ModuleNotFoundError异常。 请注意，就好像你保留对模块对象的引用，使其在sys.modules中的缓存条目无效，然后重新导入命名模块，两个模块对象将不同。相比之下，importlib.reload()将重用相同的模块对象，只需重新运行模块的代码即可重新初始化模块内容。 \r\r查找器和载入器 Finders and loaders 如果在sys.modules中找不到指定的模块，则调用Python的导入协议来**查找(find)和加载(load)**模块。该协议有两个概念对象。实现这两个接口的对象称为导入器，当它发现可以加载所请求的模块时，它们会自行返回。 查找器(finder)：查找器的工作是确定它是否可以使用它所知道的任何策略找到命名模块。 加载器(loader) Python包含了许多默认查找器和导入器。第一个知道如何定位內建模块，第二个知道如何定位冻结模块。第三个默认查找器搜索模块的导入路径。 导入机制是可扩展的，因此可以添加新的查找器以扩展模块搜索的范围。 查找器实际上并没有加载模块。如果它可以找到命名模块，则返回模块规范、模块的导入相关信息的封装，然后导入机器在加载模块时使用。 \r\rImport hooks 导入机制设计为可扩展，它的主要机制是导入钩子(import hooks)。它有两种类型： Meta hooks：在进行任何其它导入之前，在导入处理开始时调用元钩子，而不是使用sys.modules缓存查找。这允许云钩子覆盖sys.path、冻结模块甚至内置模块。 Path hooks：导入路径钩子作为sys.path处理的一部分在遇到其关联路径时被调用。 \r\r","date":"2018-05-06","objectID":"/python/:17:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"载入 Loading 如果找到模块规范，导入机制将在加载模块时使用它。 module = None if spec.loader is not None and hasattr(spec.loader, 'create_module'): # It is assumed 'exec_module' will also be defined on the loader. module = spec.loader.create_module(spec) if module is None: module = ModuleType(spec.name) # The import-related module attributes get set here: _init_module_attrs(spec, module) if spec.loader is None: if spec.submodule_search_locations is not None: # namespace package sys.modules[spec.name] = module else: # unsupported raise ImportError elif not hasattr(spec.loader, 'exec_module'): module = spec.loader.load_module(spec.name) # Set __loader__ and __package__ if missing. else: sys.modules[spec.name] = module try: spec.loader.exec_module(module) except BaseException: try: del sys.modules[spec.name] except KeyError: pass raise return sys.modules[spec.name] \r HOWTOs Python HOWTOs是覆盖单个特定主机的文档，并尝试完全包含它。此文档比Python参考库更详细。 \r 标准库 \r","date":"2018-05-06","objectID":"/python/:17:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"介绍 Python标准库包含了各种不同类型的组件。 一些模块提供了特定于Python的接口；一些提供特定于特定操作系统的接口，一些提供特定于特定应用程序的接口。 一些模块适用于所有Python版本和端口；一些只有在底层系统支持或需要它们是才可用；还有一些只有在编译和安装Python特定配置时才可用。 ","date":"2018-05-06","objectID":"/python/:18:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"内建函数 Python解释器内置了许多功能和类型，它们始终可用。 | | | 内建函数 | | | - | - | - | - | abs() | dict() | help() | min() | setattr() | all() | dir() | hex() | next() | slice() | any() | divmod() | id() | object() | sorted() | ascii() | enumerate() | input() | oct() | staticmethod() | bin() | eval() | int() | open() | str() | bool() | exec() | isinstance() | ord() | sum() | bytearray() | filter() | issubclass() | pow() | super() | bytes() | float() | iter() | print() | tuple() | callable() | format() | len() | property() | type() | chr() | frozenset() | list() | range() | vars() | classmethod() | getattr() | locals() | repr() | zip() | compile() | globals() | map() | reversed() | __import__() | complex() | hasattr() | max() | round() | | delattr() | hash() | memoryview() | set() | abs(x) 返回一个数字的绝对值 all(iterable) 如果迭代的所有元素均为真(或为空)，返回True any(iterable) 如果迭代的任一元素为真，返回True；为空返回False ascii(object) bin(x) 将整数转换为二进制字符串 bool( ) 返回一个布尔值，True或False bytearray() 返回一个新的字节数组 byte() 返回一个新的字节对象，它是一个在0\u003c=x\u003c256范围内的不可变整数序列 callable(object) 如果对象参数显示为可调用，返回True；否则返回False chr(i) 返回代表Unicode编码为整数i的字符的字符串 classmethod(function) 为函数返回一个类方法 compile() 将源编译为代码或AST对象 complex() 返回一个复数，或将字符串或数字转换为复数 delattr(object, name) 这是setattr()的相对值 dict(kwarg) 创建一个新的字典 dir(object) 无参数，返回当前本地作用域中的名称列表 有参数，尝试返回该对象的有效属性列表 divmod(a, b) 以两个数字(非复数)为参数，使用整数除法时返回由它们的商和余数组成的一对数字 enumerate(iterable, start=0) 返回一个枚举对象 eval(expression, globals, locals) exec() 动态执行Python代码 filter(function, iterable) 从函数返回true的可迭代元素构造一个迭代器 float() 返回由数字或字符串构造的浮点数 format() 将值转换为特定格式 frozenset() 返回一个新的frozenset对象，可选用来自迭代的元素 getattr() 返回对象命名属性的值 globals() 返回表示当前全局符号表的字典 hasattr(obj, name) 参数是一个对象和一份字符串，如果字符串是对象属性之一的名称，结果为True，否则False hash(obj) 返回对象的hash值 help() 调用内建的帮助系统 hex(x) 将整数转换为十六进制数 id(obj) 返回一个对象的标识 input() 从标准输入中读取一行，转换为字符串，然后返回该行 int(x) 返回一个整数对象，如果没有参数，则返回0 isinstance(obj, classinfo) 如果对象参数是classinfo参数的实例或其子类的实例，返回true issubclass(class, classinfo) 如果class是类信息的子类，返回true iter(obj) 返回一个迭代器对象 len() 返回对象的长度 list() 列表实际上是一个可变的序列类型，而不是一个函数 locals() 更新并返回表示当前本地符号表的字典 map() 返回一个将函数应用于每个迭代项的迭代器，从而产生结果 max() 返回最大项 memoryview(obj) 从给定参数返回内存视图对象 min() 返回最小项 next() 从迭代器中检索下一项 object() 返回一个新的无特征的对象 oct() 将整数转换为八进制字符串 open() 打开文件并返回相应的文件对象 ord() 给定一个表示一个Unicode编码的字符，返回一个表示该字符的Unicode编码的整数 pow() print() 将对象打印到流文件 property() 返回一个property属性 range() 范围一个不可变的序列类型，而不是函数 repr() 返回一个包含对象可打印表示的字符串 reversed() 返回一个反向迭代器 round() 返回数字小数点后ndigits精度 set() 返回一个新的集合对象，可选来自迭代的元素 setattr() getattr的对应部分 slice() 返回由范围指定的一组索引的切片(slice)对象 sorted() 从迭代项中返回一个新的排序列表 staticmethod() 为函数返回一个静态方法 str() 返回一个字符串对象 sum() 对迭代项求和 super() 返回将方法调用委托个父类或同类的代理对象 tuple() 元组是一个不可变的序列类型，而不是函数 vars() 返回对象的__dict__属性 zip() 制作一个迭代器，用于聚合来自每个迭代器的元素 __import__ 这个函数被import语句调用 \r","date":"2018-05-06","objectID":"/python/:19:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"内建常量 少量常量存在于命名空间中。 False True None NotImplemented Ellipsis __debug__ \r","date":"2018-05-06","objectID":"/python/:20:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"内建类型 主要的内建类型有： 数字(numeric) 序列(sequence) 映射(mapping) 类(class) 实例(instance) 异常(exception) \r","date":"2018-05-06","objectID":"/python/:21:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"真值测试 任何对象都可进行真值测试。 \r","date":"2018-05-06","objectID":"/python/:21:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"布尔操作 and or not \r","date":"2018-05-06","objectID":"/python/:21:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"比较操作 Python中有8个比较操作： \u003c \u003c= \u003e \u003e= == != is isnot \r","date":"2018-05-06","objectID":"/python/:21:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"数字类型 int float complex \r","date":"2018-05-06","objectID":"/python/:21:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"迭代器类型 Python支持对容器进行迭代的概念。 \r","date":"2018-05-06","objectID":"/python/:21:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"序列类型 list 列表是可变序列，通常用于存储同类项目的集合 tuple 元组是不可变序列，通常用于存储异构数据的集合 range 范围表示一个不可变的数字序列，通常用于for循环 range(start, stop, step) 通用序列操作 in not in + * [i] [i:j] [i:j:k] len() min() max() count() index() 不可变序列类型 可变序列类型 可变定义类型的操作： [i] [i:j] del [i:j:k] append() clear() copy() += *= insert() pop remove() reverse() \r","date":"2018-05-06","objectID":"/python/:21:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"文本序列类型 Python中的文本数据由str对象处理，字符串是Unicode编码点的不可变序列。 字符串以各种方式书写： 单引号 双引号 三引号 字符串方法 https://docs.python.org/3.5/library/stdtypes.html#string-methods 样式字符串格式 字符串对象有一个唯一的内建操作: %操作符，也称为字符串格式化操作符。 转换类型： % s i x f c \r","date":"2018-05-06","objectID":"/python/:21:7","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"二进制序列类型 bytes 字节对象是单字节的不可变序列 bytearray 是字节对象的可变对象 memoryview 运行Python代码访问支持缓冲区协议的对象的内部数据，而无需复制 字节和字节数组对象操作符都支持普通序列操作符，同样也支持字节格式。 \r","date":"2018-05-06","objectID":"/python/:21:8","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"集合类型 set frozenset 集合对象是不同可散列对象的无序集合。常见用途包含成员测试、删除重复项，数学计算(交集，并集，差集) \r","date":"2018-05-06","objectID":"/python/:21:9","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"映射类型 dict 映射对象可将散列值映射到任意对象，它是可变对象。 字典视图对象 dict.keys() dict.values() dict.items() \r","date":"2018-05-06","objectID":"/python/:21:10","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"上下文管理类型 Python的with语句支持由上下文管理器定义的运行时上下文的概念。 \r","date":"2018-05-06","objectID":"/python/:21:11","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"其它内建类型 模块 类和类实例 函数 方法 代码对象 类型对象 null对象 ellipsis对象 notImplimented对象 布尔值 内部对象 \r","date":"2018-05-06","objectID":"/python/:21:12","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"特殊属性 一些特殊的只读属性： object.__dict__ instance.__class__ class.__bases__ definition.__name__ definition.__qualname__ class.__mro__ class.__subclasses__() \r","date":"2018-05-06","objectID":"/python/:21:13","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"内建异常 在Python中，所有异常(exception)都必须是派生自Baseexception的类的实例。 \r","date":"2018-05-06","objectID":"/python/:22:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"基类 BaseException Exception ArithmeticError bufferError LookupError \r","date":"2018-05-06","objectID":"/python/:22:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"具体异常 AssertionError AttributeError EOFError FloatingPointError GeneratorExit ImportError IndexError KeyError KerboardInterrupt MemoryError NameError NotImplementedError OSError OverflowError RecursionError ReferenceError RuntimeError StopAsyncIteration SyntaxError IndentationError TabError SystemError SystemExit TypeError UnboundLocalError UnicodeError UnicodeEncodeError UnicodeDecodeError UnicodeTranslateError ValueError ZeroDivisionError EnvironmentError IOError \r","date":"2018-05-06","objectID":"/python/:22:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"文本处理 ","date":"2018-05-06","objectID":"/python/:23:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"string string模块，字符串操作 ","date":"2018-05-06","objectID":"/python/:23:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"re re模块，提供了正则表达式匹配操作。 字符串模式匹配 \u003e\u003e\u003e import re \u003e\u003e\u003e re.findall(r'f[a-z]*', 'which foot or hand fell fastest') ['foot', 'fell', 'fastest'] #替换 \u003e\u003e\u003e 'aaa and bbb'.replace('bbb', 'BBB') 'aaa and BBB' \r","date":"2018-05-06","objectID":"/python/:23:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"difflib difflib，助手计算三角洲。 该模块提供用于比较序列的类和函数。 ","date":"2018-05-06","objectID":"/python/:23:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"textwrap textwrap模块，文本环绕和填充。 将段落文本格式化以适应给定的屏幕宽度。 \u003e\u003e\u003e import textwrap \u003e\u003e\u003e doc = \"\"\" 1111 1111 1111 1111 1111 1111 ... 2222 2222 2222 2222 2222 2222 ... 3333 3333 3333 3333 3333 3333\"\"\" \u003e\u003e\u003e print(textwrap.fill(doc, width=50)) 1111 1111 1111 1111 1111 1111 2222 2222 2222 2222 2222 2222 3333 3333 3333 3333 3333 3333 \r","date":"2018-05-06","objectID":"/python/:23:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"unicodedata unicodedata，Unicode数据库。 该模块提供对Unicode字符数据库(UCD)的访问，此数据库为所有Unicode字符定义字符属性。 \r","date":"2018-05-06","objectID":"/python/:23:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"stringprep stringprep，因特网字符串准备。 \r","date":"2018-05-06","objectID":"/python/:23:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"readline readline，GNU读行接口。 该模块定义了许多方便Python解释器完成和读写历史文件的函数。 \r","date":"2018-05-06","objectID":"/python/:23:7","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"rlcompleter rlcompleter，GNU读行的完成函数。 该模块通过完成有效的Python标识符合关键字来定义适用于readline模块的完成函数。 \r","date":"2018-05-06","objectID":"/python/:23:8","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"二进制数据 ","date":"2018-05-06","objectID":"/python/:24:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"struct struct模块，将字节解释为打包的二进制数据。 提供了pack()和unpack()函数来处理可变长度的二进制记录格式。 \r","date":"2018-05-06","objectID":"/python/:24:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"codecs codes，编解码注册和基类。 \r","date":"2018-05-06","objectID":"/python/:24:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"数据和时间 ","date":"2018-05-06","objectID":"/python/:25:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"time time模块，提供了许多操作时间值(time value)的函数，用于取得Unix纪元时间戳。 import time #Unix时间 time.time() #1531364576.3187952 #delay for a number of seconds given as a float time.sleep() time.time();time.sleep(10);time.time() \r\r","date":"2018-05-06","objectID":"/python/:25:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"datetime datetime模块，基本日期和时间类型。 支持日期和时间计算，并对输出做格式化处理。 import datetime datetime.datetime.now() #datetime.datetime(2018, 7, 12, 13, 45, 43, 127838) datetime.datetime.now().year, datetime.datetime.now().month, datetime.datetime.now().hour #Unix纪元转换 datetime.datetime.fromtimestamp(1531374507.8268566) #datetime.datetime.fromtimestamp(time.time()) #datetime.datetime(2018, 7, 12, 13, 48, 27, 826857) #日期比较 yesterday = datetime.datetime(2018, 7, 11, 00, 00, 00, 00000) today = datetime.datetime.now() future = datetime.datetime(2018, 8, 12, 00, 00, 00, 00000) today \u003e yesterday while future \u003e today: time.sleep(1) #timedelta表示一段时间 #周，时，分，秒，毫秒，微秒 period = datetime.timedelta(days=7, hours=6, minutes=20, seconds=55) str(period) #'7 days, 6:20:55' datetime.datetime.strftime()将datetime对象转换为字符串 datetime.datetime.strptime()将字符串转换为datetime对象 格式栗子: %Y: 2018 %y: 18 %m: 07 %B: July %b: Jul %d: 一月中的第几天 %j: 一年中的第几天 %w: 一周中的第几天(0-6) %A: Thursday %a: Thu %H: 14(00-23) %I: 2(0-12) %M: 分(00-59) %S: 秒(00-59) %p: AM/PM datetime.datetime.now().strftime('%Y-%m-%d%H:%M:%S') #'2018-07-12 14:11:20' datetime.datetime.strptime(2018-07-12 14:11:20', '%Y-%m-%d %H:%M:%S') #datetime.datetime(2018, 7, 12, 14, 11, 20) \r","date":"2018-05-06","objectID":"/python/:25:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"calendar calendar，日历相关函数。 \r","date":"2018-05-06","objectID":"/python/:25:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"collections collections，容器数据类型。 \r","date":"2018-05-06","objectID":"/python/:25:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"collections.abc collections.abc，容器的抽象基类 \r","date":"2018-05-06","objectID":"/python/:25:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"heapq heapq，堆队列算法。 \r","date":"2018-05-06","objectID":"/python/:25:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"bisect bisect，数组二等分算法。 \r","date":"2018-05-06","objectID":"/python/:25:7","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"array array模块，有效的数值数组。 它提供了一个array()对象，就像一个只存储同质数据并将其存储更紧凑的列表。 \r","date":"2018-05-06","objectID":"/python/:25:8","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"weakref weakref，弱引用。 weakref模块提供了用于跟踪对象而不创建参考的工具。当不再需要该对象时，它将自动从弱参考表中移除，并为弱参考对象触发回调。 Python支持自动内存管理，内存在最后一次被删除后不久就被释放。 \r","date":"2018-05-06","objectID":"/python/:25:9","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"copy copy，浅层和深层操作。 \r","date":"2018-05-06","objectID":"/python/:25:10","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"pprint pprint模块，漂亮打印。 \u003e\u003e\u003e import pprint \u003e\u003e\u003e t =[[[['black', 'cyan'], 'white', ['green', 'red']], [['magenta','yellow'], 'blue']]] \u003e\u003e\u003e pprint.pprint(t, width=30) [[[['black', 'cyan'], 'white', ['green', 'red']], [['magenta', 'yellow'], 'blue']]] \r","date":"2018-05-06","objectID":"/python/:25:11","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"reprlib reprlib模块，提供repr自定义显示 \r","date":"2018-05-06","objectID":"/python/:25:12","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"enum enum，支持枚举。 \r","date":"2018-05-06","objectID":"/python/:25:13","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"数字和数学 ","date":"2018-05-06","objectID":"/python/:26:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"numbers numbers，数字抽象基类。 \r","date":"2018-05-06","objectID":"/python/:26:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"round 按指定精度四舍五入一个浮点数。 round(1.23456, 4) #1.236 \r\r","date":"2018-05-06","objectID":"/python/:26:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"math math模块，数学函数。 \u003e\u003e\u003e import math \u003e\u003e\u003e math.sin(math.pi / 2) 1.0 \u003e\u003e\u003e math.log(256, 2) 8.0 \r","date":"2018-05-06","objectID":"/python/:26:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"cmath cmath，复数数学函数。 \r","date":"2018-05-06","objectID":"/python/:26:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"decimal decimal，十进制定点和浮点运算。 \r","date":"2018-05-06","objectID":"/python/:26:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"fractions fractions，有理数。 \r","date":"2018-05-06","objectID":"/python/:26:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"random random，生成伪随机数。 \u003e\u003e\u003e import random \u003e\u003e\u003e random.choice(['a', 'b', 'c']) 'a' \u003e\u003e\u003e random.sample(range(10), 2) [2, 6] \u003e\u003e\u003e random.random() 0.9714711378164909 \u003e\u003e\u003e random.randrange(10) 5 \r","date":"2018-05-06","objectID":"/python/:26:7","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"statistics statistics模块，数学统计函数。 计算基本的统计属性： 平均数(mean) 中位数(median) 方差(variance) \u003e\u003e\u003e import statistics \u003e\u003e\u003e num = [1, 2, 3, 4, 5] \u003e\u003e\u003e statistics.mean(num) 3 \u003e\u003e\u003e statistics.median(num) 3 \u003e\u003e\u003e statistics.variance(num) 2.5 \r","date":"2018-05-06","objectID":"/python/:26:8","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"函数式编程模块 本章模块提供了支持函数式编程风格的函数和类，以及可调用函数的一般操作。 \r","date":"2018-05-06","objectID":"/python/:27:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"itertools itertools，为高校循环创建迭代器。 \r","date":"2018-05-06","objectID":"/python/:27:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"functools functools，可调用对象的高阶函数和操作 \r","date":"2018-05-06","objectID":"/python/:27:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"operator operator，作为函数的标准操作符 \r","date":"2018-05-06","objectID":"/python/:27:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"文件和目录 本章介绍的模块处理磁盘文件和目录。 \r","date":"2018-05-06","objectID":"/python/:28:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"pathlib pathlib，面向对象的文件系统路径 此模块提供了代表文件系统路径的类，其语义适用于不同的操作系统。 \r","date":"2018-05-06","objectID":"/python/:28:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"os.path os.path，通用路径名操作 该模块在路径名上实现了一些有用的功能。 \r","date":"2018-05-06","objectID":"/python/:28:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"fileinput fileinput，迭代来自多个输入流的行 该模块实现了从一个帮助类和函数，可在标准输入或文件列表上快速编写循环。 \r","date":"2018-05-06","objectID":"/python/:28:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"stat stat，解释stat()结果 此模块定义用于解释os.stat(),os.fstat(),os.lstat()的结果的常量和函数。 \r","date":"2018-05-06","objectID":"/python/:28:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"filecmp filecmp，文件和目录比较 此模块定义了比较文件和目录的函数，以及各种可选的时间和权衡。 \r","date":"2018-05-06","objectID":"/python/:28:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"tempfile tempfile，生成临时文件和目录 此模块创建临时文件和目录。 \r","date":"2018-05-06","objectID":"/python/:28:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"glob glob，Unix样式路径名称模式扩展 此模块根据Unix shell使用的规则查找与指定模式匹配的所有路径名，结果以任意顺序返回。 \r","date":"2018-05-06","objectID":"/python/:28:7","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"fnmatch fnmatch，Unix文件名模式匹配 此模块提供了对Unix shell风格的通配符的支持，它与正则表达式不同。 通配符: * ? [seq] [!seq] \r","date":"2018-05-06","objectID":"/python/:28:8","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"linecache linecache，随机访问文本行 此模块允许从Python源文件中获取任意行，同时尝试使用缓存进行内部优化，这是一种从单个文件中读取多行的常见情况。 \r","date":"2018-05-06","objectID":"/python/:28:9","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"shutil shutil，高级文件操作 此模块提供了许多关于文件和文件集合的高级操作。 目录和文件操作 copytree rmtree 归档操作 \u003e\u003e\u003e shutil.copyfile('/tmp/1.txt', '/tmp/111.txt') '/tmp/111.txt' \u003e\u003e\u003e shutil.move('/tmp/today', '/tmp/TODAY') '/tmp/TODAY \r\r","date":"2018-05-06","objectID":"/python/:28:10","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"glob glob模块，从通配符中搜索创建文件列表 \u003e\u003e\u003e import glob \u003e\u003e\u003e glob.glob('/tmp/*.txt') ['/tmp/1.txt', '/tmp/2.txt', '/tmp/111.txt'] \r","date":"2018-05-06","objectID":"/python/:28:11","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"数据持久化 本章介绍的模块支持将Python数据持久化存储到磁盘上。 \r","date":"2018-05-06","objectID":"/python/:29:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"pickle pickle，Python对象序列化 此模块用于实现序列化(serializing)和反序列化Python对象结构的二进制协议。 \r","date":"2018-05-06","objectID":"/python/:29:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"copyreg copyreg，注册pickle支持函数 该模块提供了一种定义胭脂(pickle)特定对象时使用的函数方法。 \r","date":"2018-05-06","objectID":"/python/:29:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"shelve shelve，Python对象持久化 shelf是一个持久的，类似字典的对象。 \r","date":"2018-05-06","objectID":"/python/:29:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"marshal marshal，内部Python对象序列化 此模块包含了可以以二进制格式读写Python值得函数。 \r","date":"2018-05-06","objectID":"/python/:29:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"dbm dbm，到Unix数据库的接口 dbm是DBM数据库变体的通用接口。 \r","date":"2018-05-06","objectID":"/python/:29:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"sqlite3 sqlite3，SQLite数据库的DB-API 2.0接口 SQLite是一个C库，它提供了一个轻量级的基于磁盘的数据库，它不需要单独的服务器进程，并允许使用SQL查询语言的非标准变体访问数据库。 \r","date":"2018-05-06","objectID":"/python/:29:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"数据压缩和归档 本章介绍的模块，支持使用zlib, gzip, bzip2, lzma算法进行数据压缩，以及创建zip和tar格式的归档文件。 \r","date":"2018-05-06","objectID":"/python/:30:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"zlib zlib，兼容gzip的压缩 对于需要数据压缩的应用程序，此模块中的功能允许使用zlib库进行压缩(compression)和解压缩(decompression)。 \r","date":"2018-05-06","objectID":"/python/:30:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"gzip gzip，支持gzip文件 此模块提供了一个简单的接口来压缩和解压缩文件，就行GNU程序gzip和gunzip一样。 ","date":"2018-05-06","objectID":"/python/:30:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"bz2 bz2，支持bz2压缩 该模块提供了一个全面的接口，用于使用bzip2压缩算法进行压缩和解压缩数据。 \r","date":"2018-05-06","objectID":"/python/:30:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"lzma lzma，使用lzma算法进行压缩 该模块提供了类和函数，用于使用lzma进行压缩和解压缩数据。 \r","date":"2018-05-06","objectID":"/python/:30:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"zipfile zipfile，使用zip归档 zip文件格式是一个常用的归档和压缩标准。此模块提供了工具，用于创建，读写，追加和列出zip文件的工具。 \r","date":"2018-05-06","objectID":"/python/:30:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"tarfile tarfile，读写tar归档文件 该模块可读写tar归档文件，包括使用gzip，bz2和lzma压缩。 \r","date":"2018-05-06","objectID":"/python/:30:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"文件格式 本章描述的模块，解析各种各样的文件格式，不包含标记语言和e-mail。 \r","date":"2018-05-06","objectID":"/python/:31:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"csv csv，读写CSV文件 所谓的CSV(comma separated values)逗号分隔值，它是一种简化的电子表格，保存为纯文本文件。是电子表格和数据库最常用的导入和导出格式。 该模块实现了以CSV格式读写表格数据。 CSV文件很简单，缺少了Excel表格的许多功能： 值没有类型，都是字符串 没有字体大小或颜色 没有多个工作表 不能指定单元格的宽度和高度 不能合并单元格 不能签入图像和图标 import csv file = open('/tmp/test.csv') reader = csv.reader(file) data = list(reder) #写 file = open('/tmp/test.csv', 'w', newline='') writer = csv.writer(file) writer.writerow('[1, 11, 111]') file.close() \r\r","date":"2018-05-06","objectID":"/python/:31:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"configparser configparser，配置文件解析器 此模块提供了ConfigParser类，它实现了一种基本配置，你可以使用它来编写可由最终用户轻松定制的Python程序。 \r","date":"2018-05-06","objectID":"/python/:31:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"netrc netrc文件处理 netrc类解析和封装Unix FTP程序和其它FTP客户端使用的netrc文件格式。 \r","date":"2018-05-06","objectID":"/python/:31:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"xdrlib xdrlib，编码(encode)和解码(decode)XDR数据 该模块支持外部数据表示标准(External Data Representation Standard)。此模块定义了两个类，一个将变量打包(packing)到XDR，另一个从XDR中解包(unpack)。 \r","date":"2018-05-06","objectID":"/python/:31:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"加密服务 本章描述的模块，实现了各种加密(cryptographic)算法 \r","date":"2018-05-06","objectID":"/python/:32:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"hashlib hashlib，安全散列和消息摘要(digest) 该模块为许多不同安全散列和消息摘要算法实现了通用接口。 SHA1 SHA224 SHA256 SHA384 MD5 \r","date":"2018-05-06","objectID":"/python/:32:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"hmac hmac，用于消息认证的键控散列 \r","date":"2018-05-06","objectID":"/python/:32:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"操作系统接口 本章介绍的模块，提供了操作系统功能的接口。 \r","date":"2018-05-06","objectID":"/python/:33:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"os os，各种操作系统接口 该模块为使用操作系统相关的功能提供了一种便携方式。 文件名，命令行参数，环境变量 进程参数 文件对象创建 文件描述符操作 文件和目录的Linux扩展属性 进程管理 调度程序的接口 各种各样的系统信息 各种各样的功能 \u003e\u003e\u003e import os \u003e\u003e\u003e os.getcwd() '/home/zhang' \u003e\u003e\u003e os.chdir('/tmp') #在shell中运行命令 \u003e\u003e\u003e os.system('mkdir /tmp/today') 0 \r","date":"2018-05-06","objectID":"/python/:33:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"io io，流处理的核心工具 该模块提供了Python用于处理各种类型I/O的主要工具。 text i/o binary i/o raw i/o \r","date":"2018-05-06","objectID":"/python/:33:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"time time，访问和转换时间 此模块提供了各种与时间相关的函数 \r","date":"2018-05-06","objectID":"/python/:33:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"argparse argparse，解析命令行选项、参数和子命令 该模块可以轻松编写用户友好的命令行接口。 \r","date":"2018-05-06","objectID":"/python/:33:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"getopt getopt，用于命令行选项的C风格解析器 该模块帮助脚本解析sys.argv中的命令行参数。 \r","date":"2018-05-06","objectID":"/python/:33:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"logging logging，Python的日志工具。 该模块定义了函数和类，为应用程序和库实现灵活事件记录系统。 log level: DEBUG 最低级别。用于小细节，通常只有在诊断问题时，才需要关心这些信息。 INFO 用于记录程序中的一般事件的信息。 WARNING 用于表示可能的问题 ERROR 用于记录错误 CRITICAL 最高级别，用于表示致命的错误 日志级别是一种建议。归根到底，还是由你来决定日志消息属于哪一种类型。 import logging logging.basicConfig(level=logging.INFO, format='%(asctime)s- %(levelname)s- %(lineno)d- %(message)s') logging.debug('Debugging information') logging.info('Informational message') logging.warning('Warning:config file %snot found', 'server.conf') logging.error('Error occurred') logging.critical('Critical error -- shutting down') #输出 2018-07-10 14:50:13,060 - INFO - 6 - Informational message 2018-07-10 14:50:13,061 - WARNING - 7 - Warning:config file server.conf not found 2018-07-10 14:50:13,061 - ERROR - 8 - Error occurred 2018-07-10 14:50:13,061 - CRITICAL - 9 - Critical error -- shutting down 日志格式: | %(name)s Name of the logger (logging channel) | %(levelno)s Numeric logging level for the message (DEBUG, INFO, WARNING, ERROR, CRITICAL) | %(levelname)s Text logging level for the message (\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\") | %(pathname)s Full pathname of the source file where the logging call was issued (if available) | %(filename)s Filename portion of pathname | %(module)s Module (name portion of filename) | %(lineno)d Source line number where the logging call was issued (if available) | %(funcName)s Function name | %(created)f Time when the LogRecord was created (time.time() return value) | %(asctime)s Textual time when the LogRecord was created | %(msecs)d Millisecond portion of the creation time | %(relativeCreated)d Time in milliseconds when the LogRecord was created, relative to the time the logging module was loaded (typically at application startup time) | %(thread)d Thread ID (if available) | %(threadName)s Thread name (if available) | %(process)d Process ID (if available) | %(message)s The result of record.getMessage(), computed just as the record is emitted \r","date":"2018-05-06","objectID":"/python/:33:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"logging.config logging.config，日志配置 \r","date":"2018-05-06","objectID":"/python/:33:7","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"logging.handlers logging.handlers，日志处理程序 \r","date":"2018-05-06","objectID":"/python/:33:8","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"getpass getpass，便携式密码输入 \r","date":"2018-05-06","objectID":"/python/:33:9","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"curses curses，字符单元显示的终端处理 \r","date":"2018-05-06","objectID":"/python/:33:10","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"curses.textpad curses.textpad，用于curses程序的文本输入小部件 此模块提供了一个Textbox类，他在curses窗口中处理基本的文本编辑。 \r","date":"2018-05-06","objectID":"/python/:33:11","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"curses.ascii curses.ascii，用于ASCII字符的使用程序 该模块为ASCII字符提供名称常量，并为各种ASCII字符类中的成员测试函数。 \r","date":"2018-05-06","objectID":"/python/:33:12","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"curses.panel curses.panel，curses的面板堆栈扩展 面板是具有深度附加功能的窗口，因此它可堆叠在彼此的顶部，并且只显示每个窗口的可见部分。 \r","date":"2018-05-06","objectID":"/python/:33:13","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"platform platform，访问底层平台的识别数据 \r","date":"2018-05-06","objectID":"/python/:33:14","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"errno errno，标准的errno系统符号 \r","date":"2018-05-06","objectID":"/python/:33:15","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"ctypes ctypes，一个Python的外部函数库 该模块提供了C兼容的数据类型，并允许在DLL或共享中调用函数。 \r","date":"2018-05-06","objectID":"/python/:33:16","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"并发执行 本章介绍的模块，为并发执行(consurrent execution)代码提供了支持。 这里需要理解一些基本知识: 并发：并发的关键是处理多个任务，不一定要同时，可理解为交替做不同事情； 并行：并行的关键是同时处理多个任务，可理解为同时做不同事情； 进程：进程是操作系统资源分配的最小单元，每个进程拥有独立的内存单元； 线程：线程是程序执行的最小单元，是系统独立调度和分配CPU（独立运行）的基本单位。进程内的线程共享资源。进程内的线程通信比进程之间的通信更快更有效，因为共享资源； 多进程：同时执行多个进程——同时运行wecat, qq 多线程：同时执行多个线程——浏览器边看视频、边听歌、边下载 \r","date":"2018-05-06","objectID":"/python/:34:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"threading threading，基于线程的并行 此模块在较低级别的_thread模块之上构建较高级别的线程接口。 如果多线程同时读写变量，导致互相干扰，就会发生所谓的并发问题。 import time, threading print('thread start.') def wakeup(times): time.sleep(5) n = times for i in range(n): print('Wake Up!') thread01 = threading.Thread(target=wakeup, args=[3]) #thread01 = threading.Thread(target=wakeup, kwargs={'times': 3}) thread01.start() print('End of program!') 使用queue队列通信-经典的生产者和消费者模型 一个负责生成，一个负责消费，所生成的产品存放在queue里，实现了不同线程间沟通 # Producer class Producer(threading.Thread): def __init__(self, name, queue): threading.Thread.__init__(self, name=name) self.queue = queue def run(self): for i in range(1, 5): print('{} 生产 {} 到队列'.format(self.getName(), i)) self.queue.put(i) time.sleep(random.randrange(10) / 5) print('{} 完成!'.format(self.getName())) # Consumer class Consumer(threading.Thread): def __init__(self, name, queue): threading.Thread.__init__(self, name=name) self.queue = queue def run(self): for i in range(1, 5): val = self.queue.get() print('{} 消费队列中的 {}'.format(self.getName(), val)) time.sleep(random.randrange(10)) print('{} 完成!'.format(self.getName())) def main(): queue = Queue() producer = Producer('Producer', queue) consumer = Consumer('Consumer', queue) producer.start() consumer.start() producer.join() consumer.join() print('所有线程已完成!') if __name__ == \"__main__\": main() \r","date":"2018-05-06","objectID":"/python/:34:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"multiprocessing 参考: https://zhuanlan.zhihu.com/p/46368084 multiprocessing，基于进程的并行 它是一个使用类似线程模块的API来支持产生进程的包。 新创建的进程与进程的切换都是要耗资源的，所以平时工作中进程数不能开太大 同时可以运行的进程数一般受制于CPU的核数 除了使用Process方法，我们还可以使用Pool类创建多进程 '''Learn multiprocess Learn multiprocess of python. ''' import time import os from multiprocessing import Process \"\"\" # singe process def long_time_task(): print('当前进程: {}'.format(os.getpid())) time.sleep(2) print('结果: {}'.format(8 ** 20)) if __name__ == \"__main__\": print('当前母进程: {}'.format(os.getpid())) start = time.time() for i in range(2): long_time_task() end = time.time() print('用时: {}s'.format((end - start))) \"\"\" # multiprocess def long_time_task(i): print(\"子进程: {} - 任务{}\".format(os.getpid(), i)) time.sleep(2) print(\"结果: {}\".format(8 ** 20)) if __name__ == '__main__': print('当前母进程: {}'.format(os.getpid())) start = time.time() p1 = Process(target=long_time_task, args=(1,)) p2 = Process(target=long_time_task, args=(2,)) print('等待所有子进程完成!') p1.start() p2.start() p1.join() p2.join() end = time.time() 多进程间的数据共享与通信 通常，进程之间是相互独立的，每个进程都有独立的内存。通过共享内存(nmap模块)，进程之间可以共享对象，使多个进程可以访问同一个变量(地址相同，变量名可能不同)。多进程共享资源必然会导致进程间相互竞争，所以应该尽最大可能防止使用共享状态。还有一种方式就是使用队列queue来实现不同进程间的通信或数据共享，这一点和多线程编程类似。 from multiprocessing import Process, Queue import os, time, random # share data with multiprocess # 2 process, one for write, one for read. Implemented sharing a queue def write(q): print('进程写: {}'.format(os.getpid())) for value in ['A', 'B', 'C']: print('将 {} 放入队列...'.format(value)) q.put(value) time.sleep(random.random()) def read(q): print('进程读: {}'.format(os.getpid())) while True: value = q.get(True) print('从队列获取 {}'.format(value)) if __name__ == '__main__': q = Queue() pw = Process(target=write, args=(q,)) pr = Process(target=read, args=(q,)) pw.start() pr.start() # 等待pw结束 pw.join() # pr进程里是死循环，无法等待其结束，只能强行终止 pr.terminate() \r","date":"2018-05-06","objectID":"/python/:34:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"concurrent concurrent包中只有一个模块 concurrent.futures，启动并行任务 该模块为异步(asynchronously)执行可调用提供了一个高级的接口。 \r","date":"2018-05-06","objectID":"/python/:34:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"subprocess subprocess，子进程管理 该模块允许你生成新的进程，连接到它们的input/output/error pipes，并获得它们返回的代码。 每个进程可以有多个线程。 import subprocess #在Python脚本中启动一个外部程序 subprocess.Popen(‘/tmp/hello.py’) #hello world! #用Popen传递参数，这需要传递一个列表 subprocess.Popen([‘/tmp/hello.py’, 'argv1']) #它还有许多参数 help(subprocess.Popen) \r****\r","date":"2018-05-06","objectID":"/python/:34:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"sched sched，事件调度程序(scheduler) 该模块定义了一个实现通用时间调度器的类。 \r","date":"2018-05-06","objectID":"/python/:34:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"queue queue，一个同步队列类 该模块实现了多生产者、多消费者队列。当信息必须在多线程之间安全地交换时，它在线程编程中特别有用。 \r","date":"2018-05-06","objectID":"/python/:34:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"进程间的通信和网络 本章介绍的模块，提供了不同进程进行通信的机制。 \r","date":"2018-05-06","objectID":"/python/:35:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"socket socket，低级网络接口 该模块提供了对BSD socket的访问。 Socket是网络编程的一个抽象概念。通常我们用一个Socket表示“打开了一个网络链接”，而打开一个Socket需要知道目标计算机的IP地址和端口号，再指定协议类型即可。 tcp需要建立连接，udp不需要建立连接，因此udp每次需要指定发送地址。 socket类型： socket.AF_UNIX 本机通信 socket.AF_INET 服务器间的网络通信 socket.AF_INET6 IPv6的服务器间的通信 socket.SOCK_STREAM 基于TCP的流式socket通信 socket.SOCK_DGRAM 基于UDP数据包的socket通信 socket.SOCK_RAM 原始套接字 socket.SOCK_SEQPACKET 可靠的连续数据包服务 #服务端socket函数： bind() 在AF_INET下，以tuple(host, port)的方式传入，如s.bind((host, port)) listen() 可设置挂起的最大连接数 accept() 接收tcp连接并返回(conn, address), conn是新的套接字对象, address是客户端地址 #客户端socket函数： connect() connect_ex() #公共socket函数 #tcp recv() 接受TCP套接字的数据，数据以字符串形式返回，buffsize指定要接受的最大数据量 send() sendall() 完整发送tcp数据 #udp recvfrom() sendto() close() socket编程思想： #Server-side 1. 创建socket 2. 监听 3. 接收client请求 4. 接收C端数据 5. 关闭头街子 #Client-side 1. 创建socket 2. 连接到S端 3. 发送数据 4. 关闭套接字 注意 在Python3.x中，byte strings 和 unicodestrings是两种不同的类型，相互之间需要进行decode()和encode() send()和recv()都是bytes类型，需要与str类型进行转换。 #tcp #S端 import socket host = 'localhost' port = 5678 bf = 1024 maxConn = 3 tcpS = socket.socket(socket.AF_INET, socket.SOCK_STREAM) tcpS.bind((host, port)) tcpS.listen(maxConn) print('Server start at {host}:{port}'.format(host=host, port=port)) print('Waiting for connection...') while True: conn, addr = tcpS.accept() print('Connected by: {addr}'.format(addr=addr)) while True: data = conn.recv(bf) print(data.decode('utf-8')) conn.send('server received message.'.encode('utf-8')) tcpS.close() #C端 import socket host = 'localhost' port = 5678 bf = 1024 tcpC = socket.socket(socket.AF_INET, socket.SOCK_STREAM) tcpC.connect((host, port)) while True: msg = input('Please input message: \\n') tcpC.send(msg.encode('utf-8')) data = tcpC.recv(bf) print(data.decode('utf-8')) #udp #S端 from pymongo import MongoClient import socket, datetime host = 'localhost' port = 5679 bf = 1024 mongoPort = 27017 mongoUser = 'zhang' mongoPw = 'password' mongoDb = 'zhang' mongoColl = 'udpS' udpS = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) udpS.bind((host, port)) collection = MongoClient(host=host, port=mongoPort, \\ username=mongoUser, password=mongoPw).zhang.udpS print('udp socket on {host}:{port}...'.format(host=host, port=port)) while True: data, addr = udpS.recvfrom(bf) print('Received from {addr}'.format(addr=addr)) print(data.decode('utf-8')) print('\\n') msg = 'Server has recived!\\n' udpS.sendto(msg.encode('utf-8'), addr) dateTime = datetime.datetime.now().strftime('%Y-%m-%d%H:%M:%S') post = { 'author': 'Server', 'date': dateTime, 'message': data.decode('utf-8') } collection.insert_one(post) #C端 from pymongo import MongoClient import socket, datetime host = 'localhost' port = 5679 bf = 1024 mongoPort = 27017 mongoUser = 'zhang' mongoPw = 'password' mongoDb = 'zhang' mongoColl = 'udpC' udpC = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) collection = MongoClient(host=host, port=mongoPort, \\ username=mongoUser, password=mongoPw).zhang.udpC while True: msg = str(input('Please input message: \\n')) udpC.sendto(msg.encode('utf-8'), (host, port)) data = udpC.recv(bf) print(data.decode('utf-8')) dateTime = datetime.datetime.now().strftime('%Y-%m-%d%H:%M:%S') post = { 'author': 'Client', 'date': dateTime, 'message': data.decode('utf-8') collection.insert_one(post) udpC.close() \r","date":"2018-05-06","objectID":"/python/:35:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"ssl ssl，套接字对象的TLS/SSL封装 此模块提供了对网络套接字的传输层安全(通常称为安全套接字层)的加密和对等身份验证功能。 \r","date":"2018-05-06","objectID":"/python/:35:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"select select，等待I/O完成 该模块提供对大多数操作系统中可用的select()和poll()函数的访问。 \r","date":"2018-05-06","objectID":"/python/:35:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"selector selector，高级I/O复用 该模块基于select()模块构建，有序高级和高效的I/O复用。 \r","date":"2018-05-06","objectID":"/python/:35:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"asyncio asyncio，异步I/O，事件循环，协同程序和任务 该模块提供了使用协同程序编写单线程并发代码的基础结构，在套接字和其它资源上多路复用I/O访问，运行网络客户端和服务器以及其它相关基元。 \r","date":"2018-05-06","objectID":"/python/:35:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"asyncore asyncore，异步套接字处理器 该模块为编写异步套接字服务(客户端和服务端)提供了基本的基础结构。 \r","date":"2018-05-06","objectID":"/python/:35:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"asynchat asynchat，异步套接字命令/响应处理器 该模块构建在asyncore之上，简化了异步客户端和服务端，并更容易处理其元素被任何字符串终止和长度可变的协议。 \r","date":"2018-05-06","objectID":"/python/:35:7","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"signal signal，为异步事件设置处理器 该模块提供了在Python中使用信号处理程序的机制。 \r","date":"2018-05-06","objectID":"/python/:35:8","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"mmap mmap，内存映射文件支持 内存映射文件对象的行为与bytearray和文件对象类似。 \r","date":"2018-05-06","objectID":"/python/:35:9","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"网络数据处理 本章介绍的模块，支持处理常用网络数据格式。 \r","date":"2018-05-06","objectID":"/python/:36:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"email email，一个email和MIME处理包 该包是用于管理电子邮件信息的库，包含MIME和其它基于RFC 2822的消息文档。 MIME(Multipurpose Internet Mail Extensions)多用途互联网邮件扩展，是一种标准化的方式来标识文档的性质和格式。浏览器通常使用MIME类型(而不是文件扩展名)来确定如何处理文档。 栗子： type/subtype text/plain text/html image/jpeg image/png audio/mpeg audio/ogg audio/* video/mp4 application/octet-stream … email.message 表示一个电子邮件信息 email.parser 解析电子邮件信息 email.generator 生成MIME文档 email.policy 政策对象 email.headerregistry 自定义头对象 email.contentmanager 管理MIME内容 email.mime 从抓挠中创建电子邮件和MIME对象。 email.header Internationalized headers email.charset 表示字符集 email.encoders 编码器 email.errors 异常和缺陷类 email.utils 各种各样的功能 email.iterators 迭代器 \r","date":"2018-05-06","objectID":"/python/:36:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"json json，JSON编码器和解码器 JSON(JavaScript Object Notation)，是一个受JavaScript对象语法启发的轻量级的数据交换格式。 json只能包含如下Python数据类型的值： 字符串 整型 浮点数 布尔型 列表 字典 NoneType import json JSONDATA = '{\"name\": \"zhang\", \"age\": 21, \"likeFootball\": true} loadData = json.loads(JSONDATA) dumpData = json.dumps(jsonData) \r","date":"2018-05-06","objectID":"/python/:36:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"mailcap mailcap，mailcap文件处理 mailcap文件用于配置感知MIME的应用程序(如邮件阅读器和Web浏览器)，如何对具有不同MIME类型的文件做出反应。 \r","date":"2018-05-06","objectID":"/python/:36:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"mailbox mailbox，以各种格式操作邮箱 该模块定义了两个类: Mailbox和Message，用于访问和操作磁盘邮箱及其包含的邮件。 \r","date":"2018-05-06","objectID":"/python/:36:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"mimetypes mimetypes，将文件名映射到MIME类型 该模块在文件名或URL和MIME类型之间进行转换。 \r","date":"2018-05-06","objectID":"/python/:36:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"base64 base64，base16、base32，base64，base85数据编码 该模块提供了将二进制数据编码为可打印的ASCII字符，并将这些编码解码回二进制数据的函数。 \r","date":"2018-05-06","objectID":"/python/:36:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"binhex binhex，编码和解码binhex4文件 \r","date":"2018-05-06","objectID":"/python/:36:7","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"binascii binascii，在二进制和ASCII之间进行转换 该模块包含了许多方法，用于转换在二进制和各种ASCII编码的二进制表示之进行转换的方法。 \r","date":"2018-05-06","objectID":"/python/:36:8","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"quopri quopri，编码和解码MIME引用打印数据 \r","date":"2018-05-06","objectID":"/python/:36:9","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"uu uu，编码和解码uuencode文件 该模块以uuencode格式对文件进行编码和解码，允许任意二进制数据仅通过ASCII连接进行传输。 \r","date":"2018-05-06","objectID":"/python/:36:10","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"结构化标记处理工具 Python支持用以处理各种形式的结构化数据标记的模块。 标准通用标记语言，SGML() 超文本标记语言，HTML 扩展标记语言，XML \r","date":"2018-05-06","objectID":"/python/:37:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"html html，支持超文本标记语言 该模块定义了用以操作HTML的实用程序。 \r","date":"2018-05-06","objectID":"/python/:37:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"html.parser html.parser，简单HTML和XHTML解析器 该模块提供了一个类，用来解析HTML和XHTML格式的文本文件的基础。 \r","date":"2018-05-06","objectID":"/python/:37:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"html.entities html.entities，HTML一般实体的定义 \r","date":"2018-05-06","objectID":"/python/:37:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"XML处理模块 用于处理XML的Python接口被分组到xml包 \r","date":"2018-05-06","objectID":"/python/:37:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"网络协议 本章介绍的模块，实现了网络协议并支持相关技术。 \r","date":"2018-05-06","objectID":"/python/:38:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"webbrowser webbrowser - Interfaces for launching and remotely controlling Web browsers. webbrowser，便利的web浏览器控制器 该模块提供了一个高级interface，允许向用户显示基于web的文档。 import webbrowser webbrowser.open('https://www.baidu.com') \r","date":"2018-05-06","objectID":"/python/:38:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"cgi cgi，通用网关接口支持 CGI 脚本的支持模块； 该模块定义了许多用Python编写的CGI脚本的实用功能。 \r","date":"2018-05-06","objectID":"/python/:38:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"cgitb cgitb，CGI脚本的追溯管理器 此模块为Python脚本提供了一个特殊的异常处理程序。 \r","date":"2018-05-06","objectID":"/python/:38:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"wsgiref wsgiref，WSGI功能和参考实现 Web服务器网关接口(WSGI)，是Web服务器软件和Web应用程序(Python编写)之间的标准接口。拥有标准接口可以轻松使用支持WSGI和多个不同Web服务器的应用程序。 \r","date":"2018-05-06","objectID":"/python/:38:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"urllb urllib模块，处理URL \r","date":"2018-05-06","objectID":"/python/:38:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"urllib.request urllib.request模块，用于打开URL的可扩展库 该模块定义了函数和类，用于在复杂的世界中打开URL——基本和身份认证，重定向，cookie等 \r","date":"2018-05-06","objectID":"/python/:38:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"urllib.response urllib.response，响应类 该模块定义了向接口这样的最小文件的函数和类。 \r","date":"2018-05-06","objectID":"/python/:38:7","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"urllib.parse urllib.parse，将URL解析为组件 此模块定义了一个标准接口，用于在组件中分解统一资源定位符(URL)字符串，将组件重新组合为URL，并将相对URL转换为基本URL的绝对URL。 \r","date":"2018-05-06","objectID":"/python/:38:8","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"urlllib.error urllib.error，由urllib.request引起的异常类 该模块定义了由urllib.request引发的异常类。 \r","date":"2018-05-06","objectID":"/python/:38:9","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"urllib.robotparser urllib.robotparser，解析robot.txt 此模块提供了一个RobotFileParser类，它回答了有关特定用户代理是否可以在发布robots.txt文件的Web站点上获取URL的问题。 \r","date":"2018-05-06","objectID":"/python/:38:10","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"http http，HTTP模块 \r","date":"2018-05-06","objectID":"/python/:38:11","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"http.client http.client，HTTP协议客户端 该模块定义了实现HTTP和HTTPS协议客户端的类。 \r","date":"2018-05-06","objectID":"/python/:38:12","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"ftplib ftplib，FTP协议客户端 此模块定义了FTP类和一些相关项。FTP类实现了FTP协议的客户端。 \r","date":"2018-05-06","objectID":"/python/:38:13","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"poplib poplib，POP3协议客户端 此模块定义了POP3类，它封装了一个到POP3服务器的连接，并实现了该协议。 \r","date":"2018-05-06","objectID":"/python/:38:14","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"imaplib imaplib，IMAP4协议客户端 此模块定义了三个类，封装一个到IMAP服务器的连接，并实现IAP4客户端协议的大部分子集。 \r","date":"2018-05-06","objectID":"/python/:38:15","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"nntplib nntplib，NNTP协议客户端 此模块定义了NNTP类，它实现网络新闻传输协议(NNTP)客户端。 ","date":"2018-05-06","objectID":"/python/:38:16","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"smtplib smtplib模块，SMTP协议客户端 此模块定义了一个SMTP客户端会话对象，可使用SMTP守护进程发送邮件给任一互联网计算机。 import smtplib #send = smtplib.STMP('smtp.example.com', port=xxx) send = smtplib.SMTP_SSL(‘smpt.exmail.qq.com’, 465) send.helo() #(250, b'smtp.qq.com') #登录需要提前设置邮箱授权码，使用授权码作为密码登录 send.login(user, passed) send.sendmail(from, to, message) send.quti() ","date":"2018-05-06","objectID":"/python/:38:17","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"smtpd smtpd，SMTP服务器 该模块提供了几个类来实现SMTP服务器。 \r","date":"2018-05-06","objectID":"/python/:38:18","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"telnetlib telnetlib，Telnet客户端 此模块提供了一个telnet类，用于执行Telnet协议。 \r","date":"2018-05-06","objectID":"/python/:38:19","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"uuid uuid，UUID对象 此模块提供了不可修改的UUID对象和uuid[1-5]函数。 \r","date":"2018-05-06","objectID":"/python/:38:20","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"socketserver socketserver，一个网络服务器的框架 此模块简化了编写网络服务器的任务。 \r","date":"2018-05-06","objectID":"/python/:38:21","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"http.server http.server，HTTP服务器 此模块定义了类，用于实现HTTP服务器。 \r","date":"2018-05-06","objectID":"/python/:38:22","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"http.cookie http.cookie，HTTP状态管理 此模块定义了类，用于抽象cookie概念(HTTP状态管理机制)。 \r","date":"2018-05-06","objectID":"/python/:38:23","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"http.cookiejar http.cookiejar，HTTP客户端的cookie处理 此模块定义了类，用于自动处理HTTPcookie。 \r","date":"2018-05-06","objectID":"/python/:38:24","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"xmlrpc xmlrpc，XMLRPC服务器和客户端模块 XML-RPC是一种远程过程调用方法，它使用通过HTTP传递的XML传输。 \r","date":"2018-05-06","objectID":"/python/:38:25","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"xmlrpc.client xmlrpc.client，XML-RPC客户端访问 \r","date":"2018-05-06","objectID":"/python/:38:26","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"xmlrpc.server xmlrpc.server，基本的XML-RPC服务器 \r","date":"2018-05-06","objectID":"/python/:38:27","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"ipaddress ipaddress，IPv4/IPv6操作库 此模块提供了创建、修改和操作IPv4和IPv6和网络的功能。 \r\r","date":"2018-05-06","objectID":"/python/:38:28","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"多媒体服务 本章介绍的模块，实现了用于多媒体应用的各种算法和接口。 \r","date":"2018-05-06","objectID":"/python/:39:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"audioop audioop，操作原始音频数据 此模块包含一些对声音片段有用的操作。 \r","date":"2018-05-06","objectID":"/python/:39:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"aifc aifc，读写AIFF和AIFC文件 此模块提供了对读写AIFF和AIFC文件的支持。 AIFF is Audio Interchange File Format 一种用于将数字音频样本存储在文件中的格式 AIFC是一种更新的格式，包括压缩音频数据 \r","date":"2018-05-06","objectID":"/python/:39:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"sunau sunau，读写Sun AU文件 此模块为Sun AU声音格式提供了一个便利的接口。 \r","date":"2018-05-06","objectID":"/python/:39:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"wave wave，读写WAV文件 此模块为WAV声音格式提供了一个便利的接口。 \r","date":"2018-05-06","objectID":"/python/:39:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"chunk chunk，读取IFF分块数据 此模块为读取使用EA IFF块的文件提供了接口。 \r","date":"2018-05-06","objectID":"/python/:39:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"colorsys colorsys，颜色系统之家的转换 此模块定义了计算机显示器RGB和其它三个坐标系统：YIQ, HLS, HSV中使用的RGB颜色空间中表示的颜色之间的颜色值的双向转换。 \r","date":"2018-05-06","objectID":"/python/:39:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"imghdr imghdr，确定图像类型 此模块确定文件或字节流中包含的图像类型。 \r","date":"2018-05-06","objectID":"/python/:39:7","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"sndhdr sndhdr，确定声音文件类型 此模块提供了实用功能，视图确定文件中的声音数据类型。 \r","date":"2018-05-06","objectID":"/python/:39:8","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"ossaudiodev ossaudiodev，访问与OSS兼容的音频设备 此模块允许你访问OSS(open sound system)音频接口。OSS是Linux和FreeBSD的标准音频接口。 \r\r","date":"2018-05-06","objectID":"/python/:39:9","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"语言环境 本章介绍的模块，可帮助你编写独立于语言和语言环境的软件。 \r","date":"2018-05-06","objectID":"/python/:40:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"gettext gettext，多语言国际化服务 此模块为你的Python模块和应用程序提供了国际化和本地化服务。 \r","date":"2018-05-06","objectID":"/python/:40:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"locale locale语言环境模块，打开对POSIX语言环境数据库和功能的访问。 \r\r","date":"2018-05-06","objectID":"/python/:40:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"程序框架 本章介绍的模块，是基本上决定程序结构的框架。 \r","date":"2018-05-06","objectID":"/python/:41:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"turtle turtle，乌龟图形 乌龟图形是向孩子们介绍编程的一种流行方式。 \r","date":"2018-05-06","objectID":"/python/:41:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"cmd cmd，支持面向行的命令解释器 此类为编写面向行的命令解释器提供了一个简单的框架。 \r","date":"2018-05-06","objectID":"/python/:41:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"shlex shlex，简单的词法分析 此类可以容易地编写词法分析器，以获得类似Unix shell的简单语法。 \r\r","date":"2018-05-06","objectID":"/python/:41:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"带有Tk的图形用户界面 Tk/Tcl是Python的一部分。它提供了一个强大且独立于平台的窗口工具包，可供Python程序员使用的tkinter包。 Tcl(Tool Command Language)，是一种脚本语言 Tk，是基于Tcl的图形界面开发工具箱 \r","date":"2018-05-06","objectID":"/python/:42:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"tkinter tkinter，与Tcl/Tk的Python接口 此包是到Tk GUI工具箱的标准Python接口。 \r","date":"2018-05-06","objectID":"/python/:42:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"tkinter.ttk tkinter.ttk，Tk主题小部件 此模块提供了对Tk主题小部件集的访问。 \r","date":"2018-05-06","objectID":"/python/:42:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"tkinter.tix tkinter，Tk扩展小工具 此模块提供了一组额外的小工具。 \r","date":"2018-05-06","objectID":"/python/:42:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"tkinter.scrolledtext 滚动(scrolled)文本工具 此模块提供了一个相同名称的类，它实现了基本的文本小部件，具有一个垂直滚动条，用于执行正确的事情。 \r","date":"2018-05-06","objectID":"/python/:42:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"IDEL IDEL是Python的集成开发和学习环境。 \r","date":"2018-05-06","objectID":"/python/:42:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"其它GUI包 PyGObject PyGTK PyQt PySide wxPython \r\r","date":"2018-05-06","objectID":"/python/:42:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"开发工具 本章介绍的模块可帮助你你编写软件。 开发高质量软件的一种方法是在开发过程中为每个函数编写测试，并在开发过程中频繁运行这些测试。 \r","date":"2018-05-06","objectID":"/python/:43:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"typing typing，支持类型提示 此模块支持PEP 484指定的类型提示。 \r","date":"2018-05-06","objectID":"/python/:43:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"pydoc pydoc，文档生成器和在线帮助系统 此模块从Python模块自动生成文档，文档可作为控制台上的文本页面呈现，提供个Web浏览器或保存到HTML文件。 \r","date":"2018-05-06","objectID":"/python/:43:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"doctest doctest模块，测试交互式Python示例 此模块搜索类似于交互式Python会话的文本片段，然后执行这些会话以验证它们是否完全安装所示工作。 \r","date":"2018-05-06","objectID":"/python/:43:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"unittest unittest，单元测试框架 \r","date":"2018-05-06","objectID":"/python/:43:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"2to3 2to3，自动翻译Python2-3代码 获取Python2源代码并应用一系列修复程序将其转换为有效的Python3代码。 \r","date":"2018-05-06","objectID":"/python/:43:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"test test，用于Python的回归测试包 此包包含了Python的所有回归测试。 \r","date":"2018-05-06","objectID":"/python/:43:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"test.support test.support，Python测试套件功能 \r\r","date":"2018-05-06","objectID":"/python/:43:7","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"调试和分析 调试器(Debugger)使你能遍历代码，分析堆栈并设置断点 分析器(Profiler)运行代码并给出执行时间的详细分类，使你识别程序中的瓶颈 \r","date":"2018-05-06","objectID":"/python/:44:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"bdb bdb，调试器框架 此模块处理基本的调试器功能。 \r","date":"2018-05-06","objectID":"/python/:44:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"faulthandler faulthandler，转储Python回溯(traceback) \r","date":"2018-05-06","objectID":"/python/:44:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"pdb pdb，Python调试器 此模块为Python程序定义了一个交互式源代码调试器。 \r","date":"2018-05-06","objectID":"/python/:44:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"Python分析器 cProfile和profile提供了Python程序的确定性分析。 \r","date":"2018-05-06","objectID":"/python/:44:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"timeit timeit模块，测量小代码片段的执行时间 此模块提供了一个简单的方法类计算一小段Python代码的时间。 \u003e\u003e\u003e from timeit import Timer \u003e\u003e\u003e Timer('a,b = b,a', 'a=1; b=2').timeit() 0.020318730967119336 \r","date":"2018-05-06","objectID":"/python/:44:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"trace trace，追踪Python语句的执行 此模块允许你追踪程序执行，生成带注释的语句覆盖列表，打印调用关系和在程序运行期间执行的函数列表。 \r","date":"2018-05-06","objectID":"/python/:44:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"tracemalloc tracemalloc，追踪内存分配 此模块是一个追踪由Python分配的内存块的调试工具。 \r\r","date":"2018-05-06","objectID":"/python/:44:7","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"软件打包和分发 这些库可帮助你发布和安装Python软件。这些模块被设计来与PyPi结合使用，但它们也可以与本地索引服务器一起使用，或根本不需要任何索引服务器。 \r","date":"2018-05-06","objectID":"/python/:45:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"distutils distutils，构建和安装Python模块 此软件包为构建和安装其它模块到Python提供支持。 \r","date":"2018-05-06","objectID":"/python/:45:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"ensurepip ensurepip，引导pip安装程序 此软件包支持将pip安装程序引导到现有的Python或虚拟环境中。 \r","date":"2018-05-06","objectID":"/python/:45:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"venv venv，创建虚拟环境 此模块为创建轻量虚拟环境提供支持，可选地域系统目录隔离。 \r","date":"2018-05-06","objectID":"/python/:45:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"zipapp zipapp，管理可执行的python zip归档 Python提供了管理创建包含Python代码的zip文件的工具。 \r\r","date":"2018-05-06","objectID":"/python/:45:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"Python服务组件 本章介绍的模块，提供了与Python解释器及其与环境交互相关的各种服务。 \r","date":"2018-05-06","objectID":"/python/:46:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"sys sys模块，系统特定的参数和功能 此模块提供了对解释器使用或维护的一些变量以及与解释器交互的函数非访问。 命令行参数 import sys print(sys.argv) 错误输出重定向和程序终止(termination) sys模块还具有stdin, stdout, stderr属性。 \u003e\u003e\u003e sys.stderr.write('Warning, log file not found starting a new one\\n') Warning, log file not found starting a new one \r","date":"2018-05-06","objectID":"/python/:46:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"sysconfig sysconfig，提供对Python配置信息的访问 此模块提供对Python配置信息的访问，如安装路径列表和当前平台相关的配置变量。 \r","date":"2018-05-06","objectID":"/python/:46:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"builtins builtins，内建对象 此模块提供了对Python所有内置标识符的直接访问。例如，builtins.open是内建函数open()的全名。 \r","date":"2018-05-06","objectID":"/python/:46:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"__main__ __main__，顶级脚本环境 __main__是顶级代码执行的范围的名称。从标准输入、脚本或交互式提示读取时，模块的__name__设置为等于__main__ \r","date":"2018-05-06","objectID":"/python/:46:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"warnings warnings，警告控制 警告信息通常在有用的情况下发出，以提醒用户程序中的某些条件，该条件不能保证引发异常并终止程序。 Python程序员通过调用此模块中的warn()函数来发出警告。 \r","date":"2018-05-06","objectID":"/python/:46:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"contextlib contextlib，with语句上下文实用程序 此模块为涉及with语句的常见任务提供使用程序。 \r","date":"2018-05-06","objectID":"/python/:46:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"abc abc，抽象基类(Abstract Base Classes) 此模块提供了在Python中定义抽象基类的基础结构。 \r","date":"2018-05-06","objectID":"/python/:46:7","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"atexit atexit，退出处理程序 此模块定义了注册和注销清理函数的函数。 \r","date":"2018-05-06","objectID":"/python/:46:8","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"traceback traceback，打印或取回堆栈回溯 该模块提供了一个标准接口，用来提取、格式化和打印Python程序的堆栈追踪。 \r","date":"2018-05-06","objectID":"/python/:46:9","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"__future__ __future__，未来的声明定义 \r","date":"2018-05-06","objectID":"/python/:46:10","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"gc gc，垃圾收集器接口(Garbage Collector interface) 此模块为可选的垃圾收集器提供了一个接口。 \r","date":"2018-05-06","objectID":"/python/:46:11","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"inspect inspect，检查活对象(Inspect live objects) 此模块提供了几个有用的功能来帮助获取有关活动对象的信息，如模块、类、函数、回溯、框架对象和代码对象。 \r","date":"2018-05-06","objectID":"/python/:46:12","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"site site，Site-specific configuration hook \r","date":"2018-05-06","objectID":"/python/:46:13","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"fpectl fpectl，浮点异常控制(Floating point exception control) \r\r","date":"2018-05-06","objectID":"/python/:46:14","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"自定义Python解释器 本章介绍的模块，允许编写类似于Python的交互式解释器接口。 \r","date":"2018-05-06","objectID":"/python/:47:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"code code，解释器基本类 此模块提供了一些工具，来实现Python的read-eval-print循环。 \r","date":"2018-05-06","objectID":"/python/:47:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"codeop codeop，编译Python代码 此模块提供了实用程序，用于模拟Python read-eval-print循环，像code模块中做的那样 \r\r","date":"2018-05-06","objectID":"/python/:47:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"导入模块 本章介绍的模块，提供了导入其它Python模块和以自定义导入进程的hook的新方法。 \r","date":"2018-05-06","objectID":"/python/:48:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"zipimport zipimport，从zip归档文件导入模块 此模块增加了从Zip格式的归档中导入Python模块和软件包的功能。 通常不需要明确使用zipimport模块，内置导入机制将自动使用zip归档文件的路径(sys.path)。 \r","date":"2018-05-06","objectID":"/python/:48:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"pkgutil pkgutil，包扩展程序 此模块为导入system提供实用程序，尤其是软件包的支持。 \r","date":"2018-05-06","objectID":"/python/:48:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"modulefinder modulefinder，查找脚本使用的模块 此模块可用于确定脚本导入的模块集。 \r","date":"2018-05-06","objectID":"/python/:48:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"runpy runpy，定位和执行Python模块 此模块用于定位和运行Python模块，而不必先导入它们。 \r","date":"2018-05-06","objectID":"/python/:48:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"importlib importlib，执行import 此软件包有两个目的： 在Python源代码中提供import语句的实现(__import__函数) 实现import组件暴露在此软件包中，使用户更容易创建它们自己的定制对象参与导入过程 \r\r","date":"2018-05-06","objectID":"/python/:48:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"Python语言服务 Python提供了许多模块来协助处理Python语言。包括： 标记 解析 语法分析 字节码反汇编 … \r","date":"2018-05-06","objectID":"/python/:49:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"parser parser，访问Python解析树 此模块为python内部解析器和字节码编译器提供了一个接口。 \r","date":"2018-05-06","objectID":"/python/:49:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"ast ast，抽象语法树(Abstract Syntax Trees) 此模块帮助Python应用程序处理Python抽象语法的树。 \r","date":"2018-05-06","objectID":"/python/:49:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"symtable symtable，访问编译器的符号 符号表由AST编译器在字节码生成之前生成。 \r","date":"2018-05-06","objectID":"/python/:49:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"symbol symbol，用于Python解析的常量 该模块提供了，表示解析树内部节点数值的常量。 \r","date":"2018-05-06","objectID":"/python/:49:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"token token，与Python解析树一起使用的常量 此模块提供了，表示解析树(终端令牌)的叶子节点数值的常量。 \r","date":"2018-05-06","objectID":"/python/:49:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"keyword keyword，测试Python关键字 此模块允许Python程序确定字符串是否为关键字。 \r","date":"2018-05-06","objectID":"/python/:49:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"tokenize tokenize，用于Python源代码的令牌器 此模块为Python源代码提供了一个用Python实现的语言扫描器。 \r","date":"2018-05-06","objectID":"/python/:49:7","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"tabnanny tabnanny，检查不明确的缩进(Detection of ambiguous indentation) \r","date":"2018-05-06","objectID":"/python/:49:8","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"pyclbr pyclbr，Python类浏览器支持 此模块可用于，确定有关模块中定义的类、方法和顶级函数的一些限制信息。 \r","date":"2018-05-06","objectID":"/python/:49:9","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"py_compile py_compile，编译Python源文件 此模块提供了功能，从源文件生成字节码文件，以及当模块源文件作为脚本被调用时使用。 \r","date":"2018-05-06","objectID":"/python/:49:10","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"compileall compileall，字节编译Python库 此模块提供了实用功能来支持安装Python库。 \r","date":"2018-05-06","objectID":"/python/:49:11","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"dis dis，用于Python字节码的反汇编器 此模块支持通过反汇编来支持CPython字节码的分析。 \r","date":"2018-05-06","objectID":"/python/:49:12","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"pickletools pickletools，pickle开发者的工具 此模块包含了各种常量，涉及到pickle模块的细节，一些关于实现的冗长的评论，一些用于分析pickle数据的有用函数。 \r\r","date":"2018-05-06","objectID":"/python/:49:13","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"杂项服务 本章介绍的模块，提供了在所有Python版本中可用的杂项(miscellaneous)服务。 ","date":"2018-05-06","objectID":"/python/:50:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"formatter formatter，通用输出格式 此模块支持两种接口定义，每种都有多种实现方式： 格式化接口 格式化接口所需的写入接口 \r\r","date":"2018-05-06","objectID":"/python/:50:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"Windows特定服务 本章介绍的模块仅可在MS windows平台上可获取。 \r","date":"2018-05-06","objectID":"/python/:51:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"msilib msillib，读写微软安装程序文件 此模块支持创建Microsoft Installer (.msi) 文件。 \r","date":"2018-05-06","objectID":"/python/:51:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"msvcrt msvcrt，MS VC++运行时的有用例程 此函数可访问Windows平台上的一些有用功能。 \r","date":"2018-05-06","objectID":"/python/:51:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"winreg winreg，Windows注册表访问 此模块将Windows注册表的API暴露给Python。 \r","date":"2018-05-06","objectID":"/python/:51:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"winsound winsound，Windows的声音播放接口 此模块提供了对Windows平台提供的基本声音播放机器的访问。 \r\r","date":"2018-05-06","objectID":"/python/:51:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"Unix特定服务 本章介绍的模块，提供了Unix操作系统(Unix-Like)特有的功能的接口。 \r","date":"2018-05-06","objectID":"/python/:52:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"posix posix，最基本的POSIX系统调用 此模块提供了对由C标准和POSIX标准 标准化的操作系统功能的访问。 \r","date":"2018-05-06","objectID":"/python/:52:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"pwd pwd， The password database 此模块提供了对Unix用户账户和密码数据库的访问。 import pwd pwd.getpwdnam('zhang') pwd.struct_passwd(pw_name='zhang', pw_passwd='x', pw_uid=1000, pw_gid=1000, pw_gecos='zhang', pw_dir='/home/zhang', pw_shell='/bin/bash') ","date":"2018-05-06","objectID":"/python/:52:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"spwd spwd，The shadow password database 此模块提供了对Unix shadow password database的访问。 \r","date":"2018-05-06","objectID":"/python/:52:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"grp grp，The group database 此模块提供了对Unix group database的访问。 \r","date":"2018-05-06","objectID":"/python/:52:4","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"crypt crypt，Function to check Unix passwords 此模块实现crypt(3)例程的接口，该例程是基于修改的DES算法的单向散列函数。 \r","date":"2018-05-06","objectID":"/python/:52:5","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"termios termios，POSIX风格的tty控件 此模块提供了一个接口，用于I/O控制的POSIX调用。 \r","date":"2018-05-06","objectID":"/python/:52:6","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"tty tty，终端控制函数 此模块定义了将tty置入cbreak和raw模式的函数。 \r","date":"2018-05-06","objectID":"/python/:52:7","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"pty pty，伪(Pseudo)终端程序 此模块定义了处理伪终端概念的操作： 启动另一个进程并以编程方式写入和读取其控制终端。 \r","date":"2018-05-06","objectID":"/python/:52:8","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"fcntl fcntl，The fcntl and ioctl system calls 此模块对文件描述符执行文件控制和I/O控制。 \r","date":"2018-05-06","objectID":"/python/:52:9","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"pipes pipes，shell pipelines的接口 此模块定义了一个类来抽象管道的概念——从一个文件到另一个文件的一系列转换器。 \r","date":"2018-05-06","objectID":"/python/:52:10","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"resource resource，资源使用信息 此模块提供了测量和控制程序使用系统资源的基本机制。 \r","date":"2018-05-06","objectID":"/python/:52:11","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"syslog syslog，Unix syslog library routines 此模块为Unix系统日志库例程提供了一个接口。 \r \r第三方库 基本上可将第三方库理解为开源库！ Awesome-Python: https://github.com/jobbole/awesome-python-cn PyPI: https://pypi.org/ \r","date":"2018-05-06","objectID":"/python/:52:12","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"系统管理 sh Watchdog \r\r","date":"2018-05-06","objectID":"/python/:53:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"数据库 PyMySQL pymongo redis \r","date":"2018-05-06","objectID":"/python/:54:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"PyMySQL PyMySQL：https://pypi.org/project/PyMySQL/ 首先创建数据库 CREATETABLE`users`(`id`int(11)NOTNULLAUTO_INCREMENT,`email`varchar(255)COLLATEutf8_binNOTNULL,`password`varchar(255)COLLATEutf8_binNOTNULL,PRIMARYKEY(`id`))ENGINE=InnoDBDEFAULTCHARSET=utf8COLLATE=utf8_binAUTO_INCREMENT=1; 连接 import pymysql connection = pymysql.connect( host='localhost', user='username', password='password', port=3306, db='DBname', charset='utf8', cursorclass=pymysql.cursors.DictCursor) try: with connection.cursor() as cursor: sql = \"INSERT INTO `users` (`email`, `password`) VALUES (%s, %s)\" cursor.execute(sql, ('webmaster@python.org', 'very-secret')) #commit to save connection.commit() with connection.cursor() as cursor: sql = \"SELECT `id`, `password` FROM `users` WHERE `email`=%s\" cursor.execute(sql, ('webmaster@python.org',)) result = cursor.fetchone() print(result) finally: connection.close() \r\r","date":"2018-05-06","objectID":"/python/:54:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"pyMongo pyMongo Docs: https://api.mongodb.com/python/current/ pyMongo是一个用于使用MongoDB的工具的Python发行版，并且是从Python工作于MongoDB的推荐方式。 依赖 mongodb pyMongo 连接 from pymongo import MongoClient #host and port client = MongoClient('localhost', 27017) #url format client = MongoClient('mongodb://localhost:27017') #认证 client = MongoClient(host='localhost', port=27017, username='user', password='pass') 获取数据库 db = client.${database} #or db = client['${database}'] 获取集合 collection = db.${collection} #or collection = db['${collection}'] 文档 import datetime post = { '_id': 'post01', 'author': 'Zhang21', 'text': 'My first post!', 'tags': [ 'mongodb', 'python', 'pymongo' ], 'date': datetime.datetime.now() } 插入文档 #新建集合 ${collection} = db.posts ${collection}.insert_one(post) #已有集合 collection.insert_one(post) 批量插入 new_post = [ { '_id': 'post02', 'author': 'Zhang02', 'text': '2nd post', 'tags': ['bulk', 'insert'], 'date': datetime.datetime.now() }, { '_id': 'post03', 'author': 'Zhang03', 'text': '3rd post', 'tags': ['bulk', 'insert'], 'date': datetime.datetime.now() } ] collection.insert_many(new_post) 获取文档 collection.find_one() collection.find_one({ '_id': 'post01'}) #or collection.find_one({'author': 'Zhang21'}) import pprint pprint.pprint(collection.find_one({ '_id': 'post01'})) 查询多个文档 for post in collection.find(): pprint.pprint(post) {'_id': 'post01', 'author': 'Zhang21', 'date': datetime.datetime(2018, 6, 14, 11, 13, 11, 372000), 'tags': ['mongodb', 'python', 'pymongo'], 'text': 'My first post!'} {'_id': 'post02', 'author': 'Zhang02', 'date': datetime.datetime(2018, 6, 14, 11, 34, 47, 93000), 'tags': ['bulk', 'insert'], 'text': '2nd post'} {'_id': 'post03', 'author': 'Zhang03', 'date': datetime.datetime(2018, 6, 14, 11, 34, 47, 93000), 'tags': ['bulk', 'insert'], 'text': '3rd post'} #or for post in collection.find({'tags': ['bulk', 'insert']}): pprint.pprint(post) {'_id': 'post02', 'author': 'Zhang02', 'date': datetime.datetime(2018, 6, 14, 11, 34, 47, 93000), 'tags': ['bulk', 'insert'], 'text': '2nd post'} {'_id': 'post03', 'author': 'Zhang03', 'date': datetime.datetime(2018, 6, 14, 11, 34, 47, 93000), 'tags': ['bulk', 'insert'], 'text': '3rd post'} 删除文档 collection.delete_one({\"_id\" : \"post01\"}) #删除多个 collection.delete_many({\"_id\" : \"post02\", \"_id\" : \"post03\"}) 计数 collection.count() 3 collection.count({'tags': ['bulk', 'insert']}) 2 **索引 result = db.profiles.create_index([('user_id', pymongo.ASCENDING)], unique=True) sorted(list(db.profiles.index_information())) [u'_id_', u'user_id_1'] \r\r","date":"2018-05-06","objectID":"/python/:54:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"redis The Python interface to the Redis key-value store. redis模块: https://pypi.org/project/redis/ redis模块提供两个类Redis和StrictRedis用于实现Redis的命令: redis.Strictredis(推荐) StrictRedis用于实现大部分官方的命令，并使用官方的语法和命令 help(redis.StrictRedis) __init__(self, host='localhost', port=6379, db=0, password=None, socket_timeout=None, socket_connect_timeout=None, socket_keepalive=None, socket_keepalive_options=None, connection_pool=None, unix_socket_path=None, encoding='utf-8', encoding_errors='strict', charset=None, errors=None, decode_responses=False, retry_on_timeout=False, ssl=False, ssl_keyfile=None, ssl_certfile=None, ssl_cert_reqs=None, ssl_ca_certs=None, max_connections=None) redis.Redis(不推荐) Redis是StrictRedis的子类，用于向后兼容旧版本的redis模块 连接 import redis r = redis.StrictRedis() #or r = redis.StrictRedis(host='localhost', port=6379, db=0, password='password') #字符串操作 r.set('name', 'Zhang21') r.get('name') r.type('name') r.delete('name') #列表操作 r.rpush('LIST', 'list-01', 'list-02') r.type('LIST') r.llen('LIST') #help(r.lrane) #lrange(name, start, end) lrange('LIST', 0, -1) #其它redis数据类型操作方法类同 Connection Pools 假设Redis服务器与客户端分处在异地，虽然基于内存的Redis数据库有着超高的性能，但是底层的网络通信却占用了一次数据请求的大量时间，因为每次数据交互都需要先建立连接，假设一次数据交互总共用时30ms，超高性能的Redis数据库处理数据所花的时间可能不到1ms，也即是说前期的连接占用了29ms，连接池则可以实现在客户端建立多个链接并且不释放，当需要使用连接的时候通过一定的算法获取已经建立的连接，使用完了以后则还给连接池，这就免去了数据库连接所占用的时间。 #help(redis.ConnectionPool) pool = redis.ConnectionPool() #or pool = redis.ConnectionPool(host='localhost', port=6379, db=0, passeord='password') r = redis.StrictRedis(connection_pool=pool) \r\r","date":"2018-05-06","objectID":"/python/:54:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"Web抓取 request BeautifulSoup selenium \r\r","date":"2018-05-06","objectID":"/python/:55:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"requests 从Internet上下载文件和网页。 import requests, pprint #help(requests) r = request.get('https://www.baidu.com') r.status_code r.headers r.url r.text pprint.pprint(r.text) \r\r","date":"2018-05-06","objectID":"/python/:55:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"beautifulsoup 解析HTML pip3 install beautifulsoup4 import bs4 栗子： import requests, bs4 r = request.get('https://www.baidu.com') soup = bs4.BeautifulSoup(r.text) type(soup) #soup.select() #soup.find() \r\r","date":"2018-05-06","objectID":"/python/:55:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"selenium 启动并控制一个Web浏览器。selenium能够填写表单，并模拟鼠标在此浏览器找那个点击 from selenium import webdriver browser = webdriver.Firefox() browser.get('https://www.baidu.com') \r\r","date":"2018-05-06","objectID":"/python/:55:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"文档处理 openpyxl PyPDF2 pytho-docx \r\r","date":"2018-05-06","objectID":"/python/:56:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"openpyxl openpyxl is a Python library to read/write Excel 2010 xlsx/xlsm/xltx/xltm files. 关于Excel电子表格： 一个Excel电子表格文档称为一个工作簿。一个工作簿保存在扩展名为.xlsx的文件中。每个工作簿可以包含多个表(工作表)。用户当前查看的表被称为活动表。 每个表有一些列(地址为从A开始的字母)，一些行(地址从1开始的数字)。在特定行和列的方格被称为单元格。单元格形成的网格和数据构成了表。 pip3 install openpyxl import openpyxl workbook = openpyxl.load_workbook('/tmp/test.xlsx') type(workbook) #\u003cclass 'openpyxl.workbook.workbook.Workbook'\u003e workbook.get_sheet_names() #['Sheet1', 'Sheet2', 'Sheet3'] sheet1 = workbook.get_sheet_by_name('Sheet1') type(sheet1) sheet1.title #'Sheet1' workbook.get_active_sheet() #\u003cWorksheet \"Sheet1\"\u003e sheet1['A1'].value #'1A' sheet1['A1'].row #1 sheet1['A1'].colume #A sheet1.cell(row=2, column=2).value #2B \r\r","date":"2018-05-06","objectID":"/python/:56:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"PyPDF2 PDF和Word文档是二进制文件，它们比文本文件要复制得多。 pip3 install PyPDF2 import PyPDF2 pdfFile = open('/tmp/test.pdf', 'rb') pdfReader = PyPDF2.pdfFileReader(pdfFile) pdfWriter = PyPDF2.pdfFileWriter() page = pdfReader.getPage() page.extractText() \r\r","date":"2018-05-06","objectID":"/python/:56:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"python-docx 利用python-docx模块，Python可创建和修改Word文档，它带有.docx文件扩展名。 pip3 insntall python-docx import docx doc = docx.Document('/tmp/test.docx') len(doc.paragraphs) #paragraphs和run属性 doc.paragraphs[0].text doc.paragraphs[0].run[0].text #写入 doc.add_paragraph('Add line01') doc.add_paragraph('Add line02').add_run('tail !') doc.save('/tmp/test.docx') #标题 doc.add_heading('Header 0', 0) doc.add_heading('Header 4', 4) #分页 doc.add_page_broke() #图像 doc.add_picture(xxx) \r\r","date":"2018-05-06","objectID":"/python/:56:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"图像处理 pillow(PIL) \r\r","date":"2018-05-06","objectID":"/python/:57:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"pillow PIL - the Python Imaging Library. 请了解RGB和CMYK颜色方式。 pip3 install pillow import PIL \r\r","date":"2018-05-06","objectID":"/python/:57:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"日志处理 elasticsearch \r\r","date":"2018-05-06","objectID":"/python/:58:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"elasticsearch Python Elasticsearch Client pypi: https://pypi.org/project/elasticsearch github: https://github.com/elastic/elasticsearch-py docs: https://elasticsearch-py.readthedocs.io 几个ES概念： index document type id 安装: pip3 install elasticsearch 栗子： from datetime import datetime from elasticsearch import Elasticsearch #curl localhost:9200/?pretty #default http://localhost:9200 es=Elasticsearch() es.info() #auth #es=Elasticsearch('https://url:port', http_auth=('elastic', 'passwd')) #es.info #ssl from ssl import create_default_context es = Elasticsearch('https://url:port', ssl_context=context, http_auth=('ealstic', 'passwd')) #es.index #es.create #es.update #es.delete #创建索引 es.indices.create(index='my-index') #{'acknowledged': True, 'shards_acknowledged': True, 'index': 'my-index'} #curl localhost:9200/_cat/indices #添加或修改某个索引的文档格式 es.index(index='my-index', doc_type='test-type', id=2018, body={'any': 'data', 'timestamp': datetime.now()}) #es.create(index='my-index', doc_type='test-type', id=2018, body={'any': 'data', 'timestamp': datetime.now()}) #{'result': 'created', '_primary_term': 1, '_index': 'my-index', '_shards': {'total': 2, 'failed': 0, 'successful': 1}, '_type': 'test-type', '_id': '2018', '_version': 1, '_seq_no': 0} #查看索引 es.get(index='my-index', doc_type='test-type', id=2018) #{'_index': 'my-index', '_source': {'timestamp': '2018-07-18T11:34:49.573721', 'any': 'data'}, '_type': 'test-type', 'found': True, '_id': '2018', '_version': 1} #不指定id，es会自动生成，但查询时候需要id data={ 'timestamp': datetime.now(), 'name': 'zhang21', 'msg': 'Hello' } es.index(index='my-index', doc_type='test-type', body=data) #{'result': 'created', '_primary_term': 1, '_index': 'my-index', '_shards': {'total': 2, 'failed': 0, 'successful': 1}, '_type': 'test-type', '_id': 'C_vnq2QBmuTERb-Wz39W', '_version': 1, '_seq_no': 0} es.get(index='my-index', doc_type='test-type', id='C_vnq2QBmuTERb-Wz39W') #{'_index': 'my-index', '_source': {'name': 'Zhang21', 'timestamp': '2018-07-18T13:40:04.005192', 'msg': 'Hello'}, '_type': 'test-type', 'found': True, '_id': 'C_vnq2QBmuTERb-Wz39W', '_version': 1} #查询 es.search(index='my-index') #批量操作 from elasticsearch import helper help(helper.bulk) #bulk()支持index, create, delete, upsate动作 package=[] for i in range(5): rom={ 'count': i, 'timestamp': datetime.now() } package.append(row) actions=[ { '_op_type': 'index', '_index': 'my-index', '_type': 'test-type', '_source': i } for i in package ] pprint(actions) helpers.bulk(es, actions) pprint(es.search(index='my-index')) 具体信息请查看文档！ \r\r\r","date":"2018-05-06","objectID":"/python/:58:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"数据分析 基于《Python Data Analysis》一书！ 强烈建议使用Anaconda安装Python和Jupyter。 ipython jupyter pandas numpy statsmodels matplotlib \r\r","date":"2018-05-06","objectID":"/python/:59:0","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"Anaconda site: \u003canaconda.com\u003e doc: \u003cdocs.anaconda.com/anaconda/\u003e 参考: \u003cwww.zhihu.com/question/58033789/answer/254673663\u003e Anaconda 是一种Python语言的免费增值开源发行版，用于进行大规模数据处理, 预测分析, 和科学计算, 致力于简化包的管理和部署。Anaconda使用软件包管理系统Conda进行包管理。 你可能已经安装了Python，那为什么还需要Anaconda？ Anaconda附带了一大批常用的数据科学包 Conda管理包 管理环境 安装 到官网下载不同平台的包进行安装。 wget https://repo.anaconda.com/archive/Anaconda3-5.2.0-Linux-x86_64.sh bash ./Anaconda3-5.2.0-Linux-x86_64.sh #之后可设置安装路径和环境变量 #查看 conda --version #更新所有包 conda upgrade --all 包管理 conda is a tool for managing and deploying applications, environments and packages. #它会自动安装依赖 #其实和pip差不多 conda install \u003cpackage\u003e conda install requests=1.10.0 conda install pandas numpy #卸载 conda remove \u003cpackage\u003e #更新 conda update \u003cpackage\u003e conda update \u003cpackage\u003e --all #列出 conda list #搜索 conda search 环境管理 为不同项目创建不同的运行环境。 #conda create -h #创建环境 #默认为 ~/.conda/envs/\u003cevn_name\u003e conda create -n \u003cenv_name\u003e \u003cpackage_names\u003e conda create -n py3 pandas #指定Python版本 conda create -n py3 python=3 conda create -n py2 python=2 conda create -n py36 python=3.6 #使用环境 source activate \u003cenv_name\u003e #或 conda activeate \u003cenv_name\u003e #关闭环境 source deactivate #或 conda deactivate #自定义目录 conda create -p /path/py2 python=2.7 #删除环境 conda env remove -n \u003cenv_name\u003e #列出环境 conda env list #查看环境库 conda list -n \u003cenv_name\u003e #环境变量 #导出 cond env export \u003e envName.yaml #或 pip freeze \u003e evnName.txt #导入 conda env update -f=/path/envName.yaml #或 pip install -r /path/envName.txt #列出 conda env list \r\r","date":"2018-05-06","objectID":"/python/:59:1","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"ipython site: \u003cipython.org\u003e github: \u003cgithub.com/ipython\u003e pypi: \u003cpypi.org/project/ipython/\u003e Python Shell有很多弊端，所以使用功能更强大的ipython。 ipython提供了丰富的工具包，可帮助你以交互的方式充分利用Python: 强大的交互式Shell Jupyter的内核 支持交互式数据可视化和GUI工具箱 灵活，可嵌入式的解释器，可加载到自己的项目中 使用方便，高性能的并行计算工具 安装: #bash sudo pip3 install ipython #使用Anaconda conda install ipython #启动 ipython Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 17:14:51) Type 'copyright', 'credits' or 'license' for more information IPython 6.5.0 -- An enhanced Interactive Python. Type '?' for help \r\r","date":"2018-05-06","objectID":"/python/:59:2","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["programming"],"content":"jupyter site: \u003cjupyter.org\u003e github: \u003cpypi.org/project/jupyter/\u003e pypi: \u003cpypi.org/project/jupyter/\u003e Jupyter notebook是一种Web应用，能让用户将说明文本、数学方程、代码和可视化内容全部组合到一个易于共享的文档中。 安装 #bash sudo pip3 install jupyter #Anaconda conda install jupyter #运行 jupyter notebook --no-browser --ip=0.0.0.0 #建议先设置密码 jupyter notebook password jupyter notebook --no-browser --ip=192.168.31.119 --notebook-dir=/tmp/notebook 打开浏览器访问，输入密码： Anaconda虚拟环境目录： 栗子： ","date":"2018-05-06","objectID":"/python/:59:3","tags":["python"],"title":"Python","uri":"/python/"},{"categories":["middleware"],"content":"参考： Elastic指南: https://www.elastic.co/guide/index.html Elasticsearch文档: https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html Logstash文档: https://www.elastic.co/guide/en/logstash/current/index.html Kibana文档: https://www.elastic.co/guide/en/kibana/current/index.html Filebeat文档: https://www.elastic.co/guide/en/beats/filebeat/index.html Metricbeat文档: https://www.elastic.co/guide/en/beats/metricbeat/current/index.html Lucence查询语法: https://wizardforcel.gitbooks.io/mastering-elasticsearch/content/chapter-1/114_README.html 环境： CentOS7.x86_64 Elastcisearch v6.2.3 Kibana v6.2.3 Logstash v6.2.3 Beats v6.2.3 \r 综述 开源的 Elastic Stack: 能够安全可靠地获取任何来源、任何格式的数据，并且能够实时地对数据进行搜索、分析和可视化。 Elastic指的是elastic公司下的几款产品： Elasticsearch Logstash Kibana Beats X-Pack \r","date":"2018-04-15","objectID":"/elastic/:0:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"Elasticsearch 开放源码且自由使用 License: Apache License 2.0 GitHub: https://github.com/elastic/elasticsearch Doc: https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html 搜索、分析和存储您的数据。 Elasticsearch 是基于 JSON 的分布式搜索和分析引擎，专为实现水平扩展、高可用和管理便捷性而设计。 Elasticsearch 是一个分布式的 RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。作为 Elastic Stack 的核心，它集中存储您的数据，帮助您发现意料之中以及意料之外的情况。 基于Lucene。Lucene是一套用于全文检索和搜寻的开放源码程式库，由Apache软件基金会支持和提供。 Lucene提供了一个简单却强大的应用程式介面，能够做全文索引和搜寻，在Java开发环境里Lucene是一个成熟的免费开放原始码工具；就其本身而论，Lucene是现在并且是这几年，最受欢迎的免费Java资讯检索程式库。 \r","date":"2018-04-15","objectID":"/elastic/:1:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"Logstash 开放源码且自由使用 GitHub: https://github.com/elastic/logstash Doc: https://www.elastic.co/guide/en/logstash/current/index.html 集中、转换和存储数据 Logstash 是动态数据收集管道，拥有可扩展的插件生态系统，能够与 Elasticsearch 产生强大的协同作用。 Logstash 是开源的服务器端数据处理管道，能够同时 从多个来源采集数据、转换数据，然后将数据发送到您最喜欢的 “存储库” 中。（我们的存储库当然是 Elasticsearch。） \r","date":"2018-04-15","objectID":"/elastic/:2:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"Kibana 开放源码且自由使用 GitHub: https://github.com/elastic/kibana Doc: https://www.elastic.co/guide/en/kibana/current/index.html 实现数据可视化 Kibana 让您能够可视化 Elasticsearch 中的数据并操作 Elastic Stack，因此您可以在这里解开任何疑问：例如，为何会在凌晨 2:00 被传呼，雨水会对季度数据造成怎样的影响。 \r","date":"2018-04-15","objectID":"/elastic/:3:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"Beats 开放源码且自由使用 GitHub: https://github.com/elastic/beats Doc: https://www.elastic.co/guide/en/beats/libbeat/current/index.html Beats 是轻量型采集器的平台，从边缘机器向 Logstash 和 Elasticsearch 发送数据。 Beats 平台集合了多种单一用途数据采集器。这些采集器安装后可用作轻量型代理，从成百上千或成千上万台机器向 Logstash 或 Elasticsearch 发送数据。 \r","date":"2018-04-15","objectID":"/elastic/:4:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"X-Pack Doc: https://www.elastic.co/guide/en/x-pack/current/index.html 一个程序包，带来丰富的可能性 单就其自身而言，Elastic Stack 就是一款值得考虑的强大工具。X-Pack 将诸多强大功能集合到一个单独的程序包中，更将它带上了一个新的层次。 X-Pack 是集成了多种便捷功能的单个插件 — security、alerting、monitoring、reporting、graph 探索和 machine learning — 您可以在 Elastic Stack 中放心地使用这些功能。 \r 使用Docker docker hub里面有ELK的镜像，可以直接拉取使用。推荐使用官方ELK镜像。 我自己做了一个ELK的image，上传到了我的docker hub里。我自己做这个镜像不推荐，因为使用了centos7，导致了镜像很大，这应该避免。 在docker中运行centos7 直接拉取的centos没有systemd的权限，需要在运行添加docker run -id --privileged \u003cimage-id\u003e /usr/sbin/init选项。 或者使用Docker Hub上CentOS提供的支持systemd的Dockerfile来构建centos: https://hub.docker.com/_/centos/ 其实Dockfile就是有这条命令CMD [\"/usr/sbin/init docker pull centos docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE centos latest e934aafc2206 2 weeks ago 199MB #运行docker #此处如果没有/bin/bash的话，生成的container立马就停止了 #端口映射什么的后面再弄 docker run -d -i \u003cimage-id\u003e /bin/bash #查看容器 docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 27b10f5015be e934aafc2206 \"/bin/bash\" About an hour ago Up About an hour ecstatic_boyd #进入docker docke exec -it \u003ccontainer-id\u003e /bin/bash #当然，你也可以运行SSHD，通过端口映射，连接到docker内 #[root@27b10f5015be /]# #在docker中安装各类需要的软件了 #可能需要设置一下/etc/resolv.conf 将安装了各类软件的容器构建为一个新的镜像 #从运行的容器中重构镜像 #docker commit -m \"centos7+elk\" \u003ccontainer-id\u003e user/repo:tag docker commit -m 'centos7+elk' 27b10f5015be zhang21/centos7:elk #查看新镜像 docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE zhang21/centos7 elk 0b22d93f7353 16 minutes ago 1.04GB centos latest e934aafc2206 2 weeks ago 199MB #运行新镜像 docker run -id -p 80:80 9200:9200 \u003cimage-id\u003e /bin/bash #此处遇到一个错，因为docker的网络是通过iptables来转发的，因此主机上不能关闭firewalld，不能无法启动容器 #进入新容器 docker exec -it \u003ccontainer-id\u003e /bin/bash #此处无法使用systemctl，原因已写到前面 #Failed to get D-Bus connection: Operation not permitted #获得systemd权限启动 docker run -id --privileged -p 80:80 \u003cimage-id\u003e /usr/sbin/init #进入 docker exec -it \u003ccontainer-id\u003e /bin/bash #启动Nginx systemctl start nginx 将新镜像上传到Hub 我用的是Docker Hub免费版，当然线上的话可能是阿里云或腾讯云。 docker login -u zhang21 #上传镜像到我的Hub docker push zhang21/centos7:elk #拉取镜像 docker pull zhang21/centos7:elk \r 安装 安装步骤： Elasticsearch Kibana Logstash Install X-Pack into Elasticsearch Install X-Pack into Kibana ","date":"2018-04-15","objectID":"/elastic/:5:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"安装ELKF 需要依赖JDK（java），请先安装。 我是直接使用的RPM包安装。 #安装Java yum install java-1.8.0-openjdk-headless-1.8.0.161-0.b14.el7_4.x86_64 -y #编写repo vim /etc/yum.repo.d/elk.repo [elasticsearch-6.x] name=Elasticsearch repository for 6.x packages baseurl=https://artifacts.elastic.co/packages/6.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=1 autorefresh=1 type=rpm-md #安装 yum install -y elasticsearch logstash kibana filebeat 由于elk默认将软件安装到/usr/share/下，因此我把它们的bin路径加入PATH。 vim /etc/profile export PATH=$PATH:/usr/share/elasticsearch/bin:/usr/share/kibana/bin:/usr/share/logstash/bin:/usr/share/elasticsearch/bin/x-pack:/usr/share/filebeat/bin #执行 source /etc/profile ELKF使用RPM安装的布局说明： 主目录 /usr/share/elasticsearch /usr/share/kibana /usr/share/logstash /usr/share/filebeat 二进制文件 /usr/share/elasticsearch/bin /usr/share/kibana/bin /usr/share/logstash/bin /usr/share/filebeat/bin 配置文件 /etc/elastcisearch /etc/kibana /etc/logstash /etc/filebeat 环境变量 /etc/sysconfig/elasticsearch 插件 /usr/share/elastcisearch/plugins /usr/share/kibana/plugins \r","date":"2018-04-15","objectID":"/elastic/:6:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"安装X-Pack 注意 由于自动升级到Elastic v6.3自带了X-Pack，不需要额外安装。之前安装的一些插件会导致Elastic无法运行，请卸载这些插件。 elasticsearch-plugin list elasticsearch-plugin remove x-pack kibana-plugin remove x-pack logstash-plugin remove x-pack 安装X-Pack前，请先安装ELK。 请安装匹配版本的X-Pack。 Install X-Pack on Elasticsearch Install X-Pack on Kibana Install X-Pack on Logstash \r启用或禁用X-Pack功能 有些功能默认开启，有些默认关闭。请在配置文件中查看详情。 添加某些功能可能导致软件无法启动，请注意查看日志。 在以下文件中配置它们： elasticsearch.yml kibana.yml logstash.yml filebeat.yml X-Pack功能： 功能 描述 xpack.graph.enabled X-Pack图形功能 xpack.ml.enabled X-Pack机器学习功能 xpack.monitoring.enabled X-Pack监视功能 xpack.reporting.enabled X-Pack报告功能 xpack.security.enabled X-Pack安全功能 xpack.watcher.enabled X-Pack观察器 在ELK中启动X-Pack monitoring功能 #xpack.graph.enabled #xpack.ml.enabled #xpack.monitoring.enabled #xpack.reporting.enabled #xpack.security.enabled #xpack.watcher.enabled #在Elasticsearch和kibana中禁用验证后，不用在logstash中输入，否则会报错。 xpack.security.enabled: false #启用验证 #具体可参考官方文档 #在logstash.yml中配置xpack.monitoring xpack.monitoring.enabled: true #xpack.monitoring.elasticsearch.url: \"http://127.0.0.1:9200\" #xpack.monitoring.elasticsearch.username: logstash_system #xpack.monitoring.elasticsearch.password: logstash #在Filebeat中添加monitoring xpack.monitoring: enabled: true #elasticsearch: #url: \"http://localhost:9200\" #usernaem: \"elastic\" #password: \"elastic\" 安装： 建议使用密码！ #Elastcisearch安装X-Pack elasticsearch-plugin install x-pack #启动 #9200, 9300端口 #elasticsearch不能使用root启动，所以我把elastic用户修改为/bin/bash su elasticsearch elasticsearch -d #elasticsearch #生成默认用户密码，此密码针对elastic和kibana用户 #/usr/share/elasticsearch/bin/x-pack #将此加入PATH setup-passwords auto #或手动输入密码 setup-passwords interactive elastic #elastic kibana #kibana logstash_system #logstash #Kibana安装X-Pack kibana-plugin install x-pack #对kibana.yml添加用户和密码 #此密码是前面默认生成的 vim /etc/kibana/kibana.yml` elasticsearch.username: \"elastic\" elasticsearch.password: \"elastic\" #修改监听地址 server.host: \"0.0.0.0\" logging.dest: /var/log/kibana/kibana.log #kibana日志默认是stdout #修改为/var/log/kibana/kibana.log mkdir /var/log/kibana #启动kibana #5601端口 #kibana可用root启动 kibana #或 systemctl start kibana #Logstash安装X-Pack logstash-plugin install x-pack \r","date":"2018-04-15","objectID":"/elastic/:7:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"启动ELK 建议给他们加上密码！ 不知道为什么，我的ElasticStack都能用systemd来管理了！ #最便捷 systemctl start elasticsearch logstash filebeat metricbeat heartbeat packetbeat auditbeat #Elasticsearch su elasticsearch #elasticsearch，查看输出 elasticsearch -d #kill -15 pid \u0026\u0026 elasticsearch -d #Kibana kibana\u0026 systemctl start kibana #kill -15 pid \u0026\u0026 kibana\u0026 #Logstash #logstash -f xxx.conf systemctl start logstash #Filebeat #filebeat -e -c filebeat.yml，查看输出信息 systemctl start filebeat 启动时可能遇到的问题 can not run elasticsearch as root 专门建立一个管理ELK的用户，切换到此用户后运行，注意修改ELK相关目录权限 或者修改ELK各自用户的/etc/passwd，切换到对应用户后运行。注意权限 – su elasticsearch \u0026\u0026 elasticsearch elasticsearch process is too low, increase to at least [65536] vim /etc/security/limits.conf * soft nofile 655350 * hard nofile 655350 ulimit -a 访问elasticsearch $ip:9200 #此处访问是需要用户名和密码的 #使用前面X-Pack生成的默认用户名和密码 elastic elastic #登录之后便可看到node，cluster相关信息 访问kibana #5601端口 http://0.0.0.0:5601 \r","date":"2018-04-15","objectID":"/elastic/:8:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"启用xpack注意事项 启用X-PACK后，请注意在kibana配置文件中认证Elasticsearch用户和密码，并且使用Elasticsearch的用户和密码登录Kibana的前端界面。 由于我使用kibana用户登录，导致很多地方访问Elasticsearch都没有权限。请注意。 这样使用Elasticsearch登录后，便可以之间在Dev Tools中通过REST API获取和更新相关信息，并且创建和管理相关用户和角色。 \r","date":"2018-04-15","objectID":"/elastic/:9:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"安装Filebeat 由于前面我们添加了ELK-repo，所以这里我们可以直接安装。 yum install -y filebeat #开启X-Pack monitor #默认关闭 vim /etc/filebeat/filebeat.yml xpack.monitoring.enabled: true \r","date":"2018-04-15","objectID":"/elastic/:10:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"修改ELK jvm内存大小 在此版本中，可直接在配置文件目录下的jvm.options里修改JVM 内存大小。 #最小 -Xms #最大 -Xmx vim /etc/elasticsearch/jvm.options -Xms4g -Xmx4g #其它如此 \r 与Nginx结合使用 将Kibana展现到Nginx上的话，便可以不对Kibana开放外网访问。 #安装Nginx vim /etc/yum.repo.d/nginx.repo [nginx] name=nginx repo baseurl=http://nginx.org/packages/centos/$releasever/$basearch/ gpgcheck=0 enabled=1 yum install -y nginx nginx-mod-stream #配置 vim /etc/nginx/conf.d/kibana.conf #可把IP换成kibana相应的域名 #再将域名解析到此IP server { listen 80; server_name 172.16.129.150; #Kibana location / { proxy_pass http://127.0.0.1:5601; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection 'upgrade'; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; } } 可能会遇到的问题 Nignx错误日志: Permission denied) while connecting to upstream sudo cat /var/log/audit/audit.log | grep nginx | grep denied #后来判断是SELinux的问题 getenforce setenforce 0 #修改SELinux vim /etc/selinux/config SELINUX=disabled \r Logstash文档 Logstash的pipeline有两个必须的元素： input 消耗来自source的数据 output 将修改后的数据写入destination 以及一个可选元素： filter 根据你的定义来修改数据 \r","date":"2018-04-15","objectID":"/elastic/:11:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"介绍 Logstash是一个具有实时流水线(pipeling)功能的开源数据收集引擎。它可以动态统一来自不同source的数据，并将数据正常化的你的destination。 任何类型的事件都可以通过大量的输入、过滤和输出插件进行丰富和转换，通过本地编解码器进一步简化了摄取过程。 \r","date":"2018-04-15","objectID":"/elastic/:12:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"Logstash的能量 具有强大的Elasticsearch和Kibana系统的水平可伸缩数据处理流水线。 \rLogstash喜欢的数据 所有数据来者不拒！ Logs and Metrics 处理所有类型的日志数据 Apache Nginx Syslog 使用Filebeat享受互补的安全日志转发功能 从Ganglia, JMx, NetFlow和TCP,UDP收集metrics Web 将http request转换为events 分析Web服务 支持Webhook 通过轮询HTTP endpoint创建事件 通过Web API捕获健康状况、性能和其它类型的数据 数据存储和流 从你已经拥有的数据中发现更多价值。 Sensors and IoT 探索广泛的其它数据。 \r","date":"2018-04-15","objectID":"/elastic/:12:1","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"轻松丰富一切 在摄取过程中清理并转换数据，以便在index或output时立即获得实时信息。Logstash具有许多聚合和突变以及模式匹配，地理映射和动态查找功能。 Grok是Logstash filter的金刚钻，用于从非结构化数据中派生出结构化数据 通过解析来自IP的地理坐标，标准化提起复杂性，简单K-V对和CSV数据，并通过本地查找或Elasticsearch查询进一步丰富你的数据，从而扩展你的视野 编解码器通常用于缓解JSON和多行事件等常见事件结构的处理 \r","date":"2018-04-15","objectID":"/elastic/:12:2","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"选择你的储藏室 将数据放在最重要的位置。通过存储，分析和对数据采取行动，解锁各种downstream分析和操作用例。 Analysis Elasticsearch Data stores(MongoDB, Redis) Archiving HDFS S3 Monitoring Nagios Zabbix Ganglia Alerting Watcher(Elasticsearch) Email \r","date":"2018-04-15","objectID":"/elastic/:12:3","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"入门 安装，储藏，解析，汇聚多个Input/Output。 \r","date":"2018-04-15","objectID":"/elastic/:13:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"储藏第一个事件 测试Logstash和运行一个基本的pipeline logstash -e 'input { stdin { } } output { stdout {} }' #等待启动，输入hello world #Logstash将时间戳和主机名添加到message #2018-04-13T08:17:51.702Z zhang22 helloworld 启动logstsh时的一个问题： WARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash 虽然通过RPM安装Logstash存在/etc/logstash文件，但是还是会报错。 cd /usr/share/logstash/bin ln -s /etc/logstash ./config \r","date":"2018-04-15","objectID":"/elastic/:13:1","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"通过Logstash解析Logs 前面我们创建了一个基本的Logstash pipeline来测试Logstash，但真正处理logs的Logstash pipeline不会这么简单，它可能会有多个input, filter, output。 本节利用一个Filebeat，将Nginx Web Logs作为Logstash pipeline的input，解析这些logs中创建的特定命名字段，并将解析的数据写入Elasticsearch集群。 配置Filebeat以发送Log Lines到Logstash 在创建Logstash pipeline之前，你将配置Filebeat以发送Log lines到Logstash。Filebeat从服务器上的文件收集日志，并将这些日志转发给Logstash实例进行处理。 Filebeat专为可靠性和低延迟而设计。它占用的资源极少，beats input插件(默认安装)最大限度地减少了Logstash实例的资源需求。任何Beat框架编写的beat都可以讲事件数据发送到Logstash。 在你的data source主机上安装Filebeat。安装之后，配置filebeat.yml文件: vim /etc/filebeat/filebeat.yml filebeat.prospectors: - type: log #需要处理的日志的路径，如Nginx paths: - /var/log/nginx/*.log output.logstash: hosts: [\"localhost:5044\"] #运行Filebeat Filebeat -e -c filebeat.yml -d \"publish\" #Filebeat将会尝试连接到5044端口，在Logstash以一个活动的beats plugin开始前，不会有任何应答。 为Filebeat Input配置Logstash 配置一个Logstash pipeline，使用beat input plugin接受来自beats的事件。 格式如下： cd /etc/logstash/conf.d vim ./first-pipeline.conf input { } #filter部分可选 filter { } output { } #实例 input { beats { port =\u003e \"5044\" } } output { stdout { codec =\u003e dubydebug } } #验证配置 logstash -f first-pipe.conf --config.tst_and_exit #消息 2018-04-17T14:15:46.187+0800 ERROR pipeline/output.go:74 Failed to connect: dial tcp [::1]:5044: getsockopt: connection refused 2018-04-17T14:15:46.607+0800 INFO log/harvester.go:241 File is inactive: /var/log/nginx/access.log. Closing because close_inactive of 5m0s reached. 2018-04-17T14:15:46.607+0800 INFO log/harvester.go:241 File is inactive: /var/log/nginx/error.log. Closing because close_inactive of 5m0s reached. 2018-04-17T14:15:46.923+0800 INFO log/harvester.go:241 File is inactive: /var/log/secure-20180409. Closing because close_inactive of 5m0s reached. 2018-04-17T14:15:51.096+0800 INFO log/harvester.go:241 File is inactive: /var/log/secure-20180401. Closing because close_inactive of 5m0s reached. 2018-04-17T14:15:52.687+0800 INFO log/harvester.go:241 File is inactive: /var/log/secure-20180415. Closing because close_inactive of 5m0s reached. #启动Logstash #修改配置后可动态载入 logstash -f first-pipe.conf --config.reload.automatic #消息 2018-04-17T14:18:41.542+0800 INFO [monitoring] log/log.go:124 Non-zero metrics in the last 30s {\"monitoring\": {\"metrics\": {\"beat\":{\"cpu\":{\"system\":{\"ticks\":150,\"time\":159},\"total\":{\"ticks\":450,\"time\":468,\"value\":450},\"user\":{\"ticks\":300,\"time\":309}},\"info\":{\"ephemeral_id\":\"84cbf5cd-dfff-4391-9631-2b8e77329696\",\"uptime\":{\"ms\":480009}},\"memstats\":{\"gc_next\":11030992,\"memory_alloc\":6588088,\"memory_total\":40882600}},\"filebeat\":{\"harvester\":{\"open_files\":5,\"running\":8}},\"libbeat\":{\"config\":{\"module\":{\"running\":2}},\"pipeline\":{\"clients\":8,\"events\":{\"active\":4118}}},\"registrar\":{\"states\":{\"current\":10}},\"system\":{\"load\":{\"1\":4.86,\"15\":4.41,\"5\":4.53,\"norm\":{\"1\":2.43,\"15\":2.205,\"5\":2.265}}}}}} 使用Grok filter plugin解析Web Logs 在某些时候，可能输出的日志信息的格式并不理想。你想要解析log以创建特定的命名字段。 grok过滤插件使你能够将非结构化的日志数据解析为结构化和可查询的内容。 由于grok过滤器插件在传入的日志数据中查找模式，因此配置插件需要你作出关于如何识别你的用例。 你可以使用%{COMBINEDAPACHELOG} grok模式，它从如下模式的日志中构建行： 信息 Field Name IP Add clientip User ID ident User Auth auth timestamp timestamp HTTP Verb verb Request body request HTTP Status code respone Referer URL referer User agent agent vim first-pipline.conf input { beats { port =\u003e \"5044\" } } filter { grok { match =\u003e { \"message\" =\u003e \"%{COMBINEDAPACHELOG}\" } } } output { stdout { codec =\u003e rubydebug } } #启动查看效果 通过Geoip过滤插件增强数据 除了解析日志数据以获得更好的搜索外，过滤插件还可从现有的数据中后去补充信息。 geoip插件查找IP地址，从IP地址获取地理位置信息，并将该位置信息添加到日志中。 配置Logstash实例来使用geoip过滤插件: vim first-pipeline.conf input { beats { port =\u003e \"5044\" } } filter { grok { match =\u003e { \"message\" =\u003e \"%{COMBINEDAPACHELOG}\"} } geoip { source =\u003e \"clientip\" } } output { stdout { codec =\u003e rubydebug } } #重启服务 索引数据到Elasticsearch 现在Web log已经被处理为指定的字段，现在Logstash pipeline便可以索引数据到一个Elasticsearch集群中。 vim first-pipeline.conf input { beats { port =\u003e \"5044\" } } filter { grok { match =\u003e { \"message\" =\u003e \"%{COMBINEDAPACHELOG}\"} } geoip { source =\u003e \"clientip\" } } output { elasticsearch { hosts =\u003e [ \"localhost:9200\" ] } } #重启服务 验证： 这里遇到一个错误： index_not_found_exception 这里要将logst","date":"2018-04-15","objectID":"/elastic/:13:2","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"拼接多个输入和输出插件 你需要管理的信息通常来自多个不同的source，并且可能需要多个不同的destination来存储数据。Lostash pipeline可以使用多个输入和输出插件来处理这些需求。 官方文档中使用Twitter and Filebeat这两者作为Logstash input，并将信息输出到Elasticsearch和file。 配置Logstash实例使用Filebeat input plugin 配置Logstash实例写入Elasticsearch多节点(cluster) 配置Logstash pipeline将数据写入file #配置Filebeat发送Log Line到Logstash vim /etc/filebeat/filebeat.yml filebeat.prospectors: - type: log paths: - /var/log/*.log fields: type: syslog output.logstash: hosts: [\"localhost:5044\"] ######################## cd /etc/logstash/conf.d vim 2nd-pipeline.conf input { twitter { consumer_key =\u003e \"enter_your_consumer_key_here\" consumer_secret =\u003e \"enter_your_secret_here\" keywords =\u003e [\"cloud\"] oauth_token =\u003e \"enter_your_access_token_here\" oauth_token_secret =\u003e \"enter_your_access_token_secret_here\" } beats { prot =\u003e \"5044\" } } output { elasticsearch { hosts =\u003e [\"hosts1:port1\", \"host2:port2\"...] } file { path =\u003e \"/path/to/target/file\" } } #重启服务 #测试，Replace $DATE with the current date, in YYYY.MM.DD format. curl -XGET 'localhost:9200/logstash-$DATE/_search?pretty\u0026q=fields.type:syslog' \r ","date":"2018-04-15","objectID":"/elastic/:13:3","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"Input 输入插件可以使特定的事件源由Logstash读取。 可用的输入插件： 我只列出了常见的，具体请参考: https://www.elastic.co/guide/en/logstash/current/input-plugins.html 插件 描述 beats 从Elastic框架接收事件 couchdb_changes 从CouchDB的_changesURI流式传输事件 dead_letter_queue 从Logstash的dead letter queue读取事件 elasticsearch 从Elasticsearch集群中读取查询结果 exec 抓取shell命令的输出作为事件 file 来自文件的流事件 github 从GitHub webhook读取事件 heartbeat 为测试生成心跳事件 http 通过HTTP/HTTPS接收事件 http_poller 解码HTTP API输出为事件 imap 从IMAP服务器读取邮件 jmx 通过JVM从java程序检索标准 kafka 从kafka中读取事件 log4j 通过TCP socket从Log4j对象读取事件 pipe 从长时间运行的命令管道中获取流事件 rabbitmq 从Redis实例读取事件 sqlite 基于SQLite数据库中的行创建事件 stdin 从标准输入中读取事件 syslog 读取系统日志作为事件 tcp 从TCP socket读取事件 udp 从UDP读取事件 unix 通过Unix socket读取事件 websocket 从一个websocket读取事件 **input filter通用选项: ** Setting Input type Required add_field hash No codec codec No enable_metric boolean No id string No tags array No type string No add_field 添加一个字段到一个事件，默认值为{} codec 用于输入数据的编解码器。默认值是plain enable_metric 为特定插件实例禁用或启用度量标准日志记录，默认值为true id 为插件配置添加一个唯一的ID，如果未指定，Logstash会自动生成一个 tags 为事件添加任意数量的任意标签 type 为所有input处理的事件添加一个type \r","date":"2018-04-15","objectID":"/elastic/:14:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"beats 此插件使Logstash能够从Elasticsearch框架中接收事件。 栗子： input { beats { port =\u003e 5044 } } output { elasticsearch { hosts =\u003e \"localhost:9200\" #hosts =\u003e [\"hosts1\", \"hosts2\", ...] manage_template =\u003e false index =\u003e \"%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}\" document_type =\u003e \"%{[@metadata][type]}\" } } Beats Input配置项： Setting Input_type Required cipher_suites array No client_inactivity_timeout number No host string No include_codec_tag boolean No port number Yes ssl boolean No ssl_certificate a valid filesystem path No ssl_certificate_authorities array No ssl_handshake_timeout number No ssl_key a valid filesystem path No ssl_key_passphrase password No ssl_verify_mode string, one of [none, peer,force_peer] No tls_max_version number No tls_min_version number No \r","date":"2018-04-15","objectID":"/elastic/:14:1","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"elasticsearch Elasticsearch Input配置项： Setting Input_type Required ca_file a valid filesystem path No docinfo boolean No docinfo_fields array No docinfo_target string No hosts array No index string No password password No query string No schedule string No scroll string No size number No ssl boolean No user string No 栗子： input { elasticsearch { hosts =\u003e \"es.production.mysite.org\" index =\u003e \"mydata-2018.09.*\" query =\u003e '{ \"query\": { \"query_string\": { \"query\": \"*\" } } }' size =\u003e 500 scroll =\u003e \"5m\" docinfo =\u003e true } } output { elasticsearch { index =\u003e \"copy-of-production.%{[@metadata][_index]}\" document_type =\u003e \"%{[@metadata][_type]}\" document_id =\u003e \"%{[@metadata][_id]}\" } } \r","date":"2018-04-15","objectID":"/elastic/:14:2","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"exec 定期运行shell命令，并抓取整个输出为事件。 栗子： input { exec { command =\u003e \"ls\" interval =\u003e 30 } } exec Input配置项： Setting Input_type Required command string Yes interval number No schedule string No 此调度表示方法如同Linux中定时任务* 5 * 1-3 *。 \r","date":"2018-04-15","objectID":"/elastic/:14:3","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"file 从文件读取流事件。 file input配置项： Setting Input_type Required close_older number No delimiter string No discover_interval number No exclude array No ignore_older number No max_open_files number No path array Yes sincedb_path string No sincedb_write_interval number No start_position string, one of [“beginning”, “end”] No stat_interval number No \r","date":"2018-04-15","objectID":"/elastic/:14:4","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"github github input配置项： Setting Input_type Required drop_invalid boolean No ip string No port number Yes secret_token string No \r","date":"2018-04-15","objectID":"/elastic/:14:5","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"kafka https://www.elastic.co/guide/en/logstash/current/plugins-inputs-kafka.html \r","date":"2018-04-15","objectID":"/elastic/:14:6","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"redis 从redis实例读取事件，它支持redis的channel和list类型。 redis input配置项： Setting Input_type Required batch_count number No data_type string, one of [list,channel,pattern_channel] Yes db number No host string No path string No key string Yes password password No port number No ssl boolean No threads number No timeout number No \r","date":"2018-04-15","objectID":"/elastic/:14:7","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"sqlite 栗子： input { sqlite { path =\u003e \"/tmp/example.db\" type =\u003e weblogs } } output { stdout { debug =\u003e true } } sqlite input配置项： Setting Input_type Required batch number No exclude_tables array No path string Yes \r","date":"2018-04-15","objectID":"/elastic/:14:8","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"stdin \r","date":"2018-04-15","objectID":"/elastic/:14:9","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"syslog 栗子： input { syslog { port =\u003e 12345 codec =\u003e cef syslog_field =\u003e \"syslog\" grok_pattern =\u003e \"\u003c%{POSINT:priority}\u003e%{SYSLOGTIMESTAMP:timestamp} CUSTOM GROK HERE\" } } syslog input配置项： Setting Input_type Required facility_labels array No grok_pattern string No host string No locale string No port number No proxy_protocol boolean No severity_labels array No syslog_field string No timezone string No use_labels boolean No \r","date":"2018-04-15","objectID":"/elastic/:14:10","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"tcp 栗子： input { tcp { port =\u003e 12345 codec =\u003e json } } tcp input配置项： Setting Input_type Required host string No mode string, one of [server, client] No port number Yes proxy_protocol boolean No ssl_cert a valid file system path No ssl_enable boolean No ssl_extra_chain_certs array No ssl_key a valid file system path No ssl_key_passphrase password No ssl_verify boolean No \r","date":"2018-04-15","objectID":"/elastic/:14:11","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"udp \r","date":"2018-04-15","objectID":"/elastic/:14:12","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"unix \r","date":"2018-04-15","objectID":"/elastic/:14:13","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"websocket \r","date":"2018-04-15","objectID":"/elastic/:14:14","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"Output 输出将事件数据发送到特定的目标。输出是事件管道的最后阶段。 输出列表： boundary circonus CSV datadog Elasticsearch email exec file gelf ganglia http/https influxdb irc kafka librato loggly lumberjack metriccatcher mongodb nagios opentsdb pipe rabbitmq redis redmine stdout syslog tcp udp websocket zabbix **output通用配置项： ** Setting Input type Required codec codec No enable_metric boolean No id string No codec 用于输出数据的编解码器，默认值是json_lines enable_metric 为特定插件实例启用或禁用度量日志记录，默认值是true id 为插件配置添加一个唯一的ID，如果未指定ID，Logstash会自动生成。 \r","date":"2018-04-15","objectID":"/elastic/:15:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"csv csv output配置选项： Setting Input_type Required create_if_deleted boolean No csv_options hash No dir_mode number No fields array Yes file_mode number No filename_failure string No flush_interval number No gzip boolean No path string Yes spreadsheet_safe boolean No \r","date":"2018-04-15","objectID":"/elastic/:15:1","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"elasticsearch Elasticsearch output配置项： Setting | Input type | Required | - | - action | string | No bulk_path | string | No cacert | a valid filesystem path | No doc_as upsert | boolean | No document_id | string | No document_type | string | No failure_type logging whitelist | array | No healthcheck_path | string | No hosts | uri | No http_compression | boolean | No index | string | No keystore | a valid filesystem path | No keystore_password | password | No manage_template | boolean | No parameters | hash | No parent | string | No password | password | No path | string | No pipeline | string | No pool_max | number | No pool_max per route | number | No proxy | uri | No resurrect_delay | number | No retry_initial interval | number | No retry_max_interval | number | No retry_on_conflict | number | No routing | string | No script | string | No script_lang | string | No script_type | string, one of [inline, indexed, file] | No script_var_name | string | No scripted_upsert | boolean | No sniffing | boolean | No sniffing_delay | number | No sniffing_path | string | No ssl | boolean | No ssl_certificate verification | boolean | No template | a valid filesystem path | No template_name | string | No template_overwrite | boolean | No timeout | number | No truststore | a valid filesystem path | No truststore_password | password | No upsert | string | No user | string | No validate_after inactivity | number | No version | string | No version_type | string, one of [internal, external, external gt, external gte, force] | No \r","date":"2018-04-15","objectID":"/elastic/:15:2","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"exec 栗子： output { if [type] == \"abuse\" { exec { command =\u003e \"iptables -A INPUT -s %{clientip} -j DROP\" } } } exec output配置项： Setting | Input type | Required | - | - command | string | Yes quiet | boolean | No \r","date":"2018-04-15","objectID":"/elastic/:15:3","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"file 栗子： output { file { path =\u003e ... codec =\u003e line { format =\u003e \"custom format: %{message}\"} } } file output配置项： Setting | Input type | Required | - | - create_if_deleted | boolean | No dir_mode | number | No file_mode | number | No filename_failure | string | No flush_interval | number | No gzip | boolean | No path | string | Yes write_behavior | string | No \r","date":"2018-04-15","objectID":"/elastic/:15:4","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"kafka 栗子： output { kafka { codec =\u003e json topic_id =\u003e \"mytopic\" } } kafka output配置项： Setting | Input type | Required | - | - acks | string, one of [0, 1, all] | No batch_size | number | No bootstrap_servers | string | No buffer_memory | number | No client_id | string | No compression_type | string, one of [none, gzip, snappy, lz4] | No jaas_path | a valid filesystem path | No kerberos_config | a valid filesystem path | No key_serializer | string | No linger_ms | number | No max_request size | number | No message_key | string | No metadata_fetch_timeout_ms | number | No metadata_max_age_ms | number | No receive_buffer_bytes | number | No reconnect_backoff_ms | number | No request_timeout_ms | string | No retries | number | No retry_backoff_ms | number | No sasl_kerberos_service name | string | No sasl_mechanism | string | No security_protocol | string, one of [PLAINTEXT, SSL, SASL PLAINTEXT, SASL SSL] | No send_buffer_bytes | number | No ssl_key_password | password | No ssl_keystore_location | a valid filesystem path | No ssl_keystore_password | password | No ssl_keystore_type | string | No ssl_truststore_location | a valid filesystem path | No ssl_truststore_password | password | No ssl_truststore_type | string | No topic_id | string | Yes value_serializer | string | No \r","date":"2018-04-15","objectID":"/elastic/:15:5","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"mongodb mongodb output配置项： Setting | Input type | Required | - | - bulk | boolean | No bulk_interval | number | No bulk_size | number | No collection | string | Yes database | string | Yes generateId | boolean | No isodate | boolean | No retry_delay | number | No uri | string | Yes \r","date":"2018-04-15","objectID":"/elastic/:15:6","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"redis 将Redis作为消息队列缓存能极大降低系统负载，减轻系统压力。 redis output配置项： Setting | Input type | Required | - | - batch | boolean | No batch_events | number | No batch_timeout | number | No congestion_interval | number | No congestion_threshold | number | No data_type | string, one of [list, channel] | No db | number | No host | array | No key | string | No password | password | No port | number | No reconnect_interval | number | No shuffle_hosts | boolean | No timeout | number | No \r","date":"2018-04-15","objectID":"/elastic/:15:7","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"redmine 栗子： output { redmine { url =\u003e \"http://redmineserver.tld\" token =\u003e 'token' project_id =\u003e 200 tracker_id =\u003e 1 status_id =\u003e 3 priority_id =\u003e 2 subject =\u003e \"Error ... detected\" } } redmine output配置项： Setting | Input type | Required | - | - assigned_to_id | number | No categorie_id | number | No description | string | No fixed_version_id | number | No parent_issue_id | number | No priority_id | number | Yes project_id | number | Yes ssl | boolean | No status_id | number | Yes subject | string | No token | string | Yes tracker_id | number | Yes url | string | Yes \r","date":"2018-04-15","objectID":"/elastic/:15:8","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"output 栗子： output { stdout { codec =\u003e json } } \r","date":"2018-04-15","objectID":"/elastic/:15:9","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"syslog syslog output配置： Setting | Input type | Required | - | - appname | string | No facility | string | No host | string | Yes message | string | No msgid | string | No port | number | Yes priority | string | No procid | string | No protocol | string, one of [tcp, udp, ssl-tcp] | No reconnect interval | number | No rfc | string, one of [rfc3164, rfc5424] | No severity | string | No sourcehost | string | No ssl_cacert | a valid filesystem path | No ssl_cert | a valid filesystem path | No ssl_key | a valid filesystem path | No ssl_key passphrase | password | No ssl_verify | boolean | No use_labels | boolean | No \r","date":"2018-04-15","objectID":"/elastic/:15:10","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"zabbix zabbix output配置项： Setting | Input type | Required | - | - multi_value | array | No timeout | number | No zabbix_host | string | Yes zabbix_key | string | No zabbix_server host | string | No zabbix_server port | number | No zabbix_value | string | No \r","date":"2018-04-15","objectID":"/elastic/:15:11","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"Filter https://www.elastic.co/guide/en/logstash/current/filter-plugins.html 过滤器插件对事件执行中介(intermediary)处理，过滤器通常根据事件的特征有条件的应用。 下面是Elastic支持的插件列表: 插件 描述 aggregate 汇总来自单个任务的多个事件的信息 alter 对mutate过滤器无法处理的字段进行常规更改 cidr 根据网络块列表检查IP地址 cipher 对事件应用或移除cipher(密码) clone 重复事件 csv 将csv(comma separated value)解析为单个字段 date 解析字段中的日期，以用作事件的Logstash timestamp de_dot Computationally expensive filter that removes dots from a field name dissect 使用分隔符将非结构化事件数据提取到字段中 dns 执行标准或反向DNS查询 drop 删除所有事件 elapsed 计算一对事件之间的经过时间 elasticsearch 将Elasticsearch中以前的日志事件的字段复制到当前事件中 environment 将环境变量存储为元数据子字段 extractnumbers 从字符串中提取数字 fingerprint 由一致的散列值的替换值的指纹字段 geoip 添加有关IP地址的地理信息 grok 将非结构化事件数据解析到字段中 i18n 从字段中删除特定字符 jdbc_static 使用从远程数据库预加载的数据来丰富事件 jdbc_streaming 用你的数据库数据丰富事件 json 解析JSON事件 json_encode 将字段序列化为JSON kv 解析键值对 metricize 处理包含多个度量标准的复杂事件并将它们分成多个事件，每个事件都包含一个度量标准 metrics 汇总指标(Aggregates metrics) mutate 对字段执行突变 prune 将基于字段列表的事件数据精简为黑名单或白名单 range 检查指定的字段是否在给定的大小或长度限制内 ruby 执行任意Ruby代码 sleep 休息一段指定的时间 split 将多行消息拆分成不同的事件 syslog_pri 解析syslog消息的优先字段 throttle 限制事件的数量 tld 用你在配置中指定的任何内容替换默认消息字段的内容 translate 根据散列或YAML文件，替换字段内容 truncate 截断长度超过给定长度的字段 urldecode 解码URL编码的字段 useragent 将用户代理字符串解析到字段中 uuid 为事件添加UUID xml 将XML解析到字段 所有过滤器都支持的配置选项： Setting Input_type Required add_field hash No add_tag array No enable_metric boolean No id string No periodic_flush boolean No remove_field array No remove_tag array No add_field 如果此过滤器成功，添加任意字段到此事件。字段名称可以是动态的，并使用%{field}包含事件的部分内容 add_tag 如果此过滤器成功，添加任意标签到此事件。标签可以是动态的，并使用%{field}语法包含事件的部分内容 enable_metric 为特定插件实例启用/禁用度量标准日志记录 id 为插件配置添加一个唯一的ID，如果没有指定ID，Logstash会生成一个。强烈建议在配置中设置此ID 当你有多个相同类型的插件时，这特别有用 periodic_flush 定期调用过滤器flush方法 remove_field 如果此过滤器成功，从事件中移除任意字段 remove_tag 如果此过滤器成功，从事件中移除任意标签 \r","date":"2018-04-15","objectID":"/elastic/:16:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"Aggregate 此过滤器的目的是聚合属于同一任务的多个事件(通常是日志行)中可用的信息，并将最终聚合信息推送到最终任务事件中。 **Aggregate Filter Configuration Options: ** Setting Input_type Required aggregate_maps_path string, a valid filesystem path No code string Yes end_of_task boolean No inactivity_timeout number No map_action string, one of [“create”, “update”, “create_or_update”] No push_map_as_event_on_timeout boolean No push_previous_map_as_event boolean No task_id string Yes timeout number No timeout_code string No timeout_tags array No timeout_task_id_field string No timeout_timestamp_field string No aggregate_maps_path Logstash停止时存储聚合地图的文件路径，以及Logstash启动时加载的路径。 如果未定义，聚合映射将不会存储在Logstash中，并且会丢失。 code 使用当前事件执行更新map的代码；或使用当前的map执行更新事件的代码 你将有一个可用的map variable 和 event variable end_of_task 告诉过滤器该任务已结束，因此在代码执行后删除聚合map inactivity_timeout 一个任务被认为已到期的秒数 当某个任务超时时，其聚合map将被逐出 必须小于timeout map_action create update create_or_update 告诉过滤器如何处理聚合map push_map_as_event_on_timeout 每次检测到任务超时时，它都会将任务集合映射推送为新的Logstash事件 push_previous_map_as_event 每次聚合插件检测到新任务ID时，它会将先前的聚合映射推送为新的Logstash事件，然后为下一个任务创建新的空映射 task_id 定义了关联日志的任务ID的表达式 该值必须唯一标识任务 timeout time_code timeout_tags 在生成超时事件添加的标记 timeout_task_id_field timeout_timestamp_field 默认情况下，使用系统时间计算超时 栗子： 给定日志: INFO - 12345 - TASK_START - start INFO - 12345 - SQL - sqlQuery1 - 12 INFO - 12345 - SQL - sqlQuery2 - 34 INFO - 12345 - TASK_END - end 过滤器: filter { grok { match =\u003e [ \"message\", \"%{LOGLEVEL:loglevel} - %{NOTSPACE:taskid} - %{NOTSPACE:logger} - %{WORD:label}( - %{INT:duration:int})?\" ] } if [logger] == \"TASK_START\" { aggregate { task_id =\u003e \"%{taskid}\" code =\u003e \"map['sql_duration'] = 0\" map_action =\u003e \"create\" } } if [logger] == \"SQL\" { aggregate { task_id =\u003e \"%{taskid}\" code =\u003e \"map['sql_duration'] += event.get('duration')\" map_action =\u003e \"update\" } } if [logger] == \"TASK_END\" { aggregate { task_id =\u003e \"%{taskid}\" code =\u003e \"event.set('sql_duration', map['sql_duration'])\" map_action =\u003e \"update\" end_of_task =\u003e true timeout =\u003e 120 } } } \r","date":"2018-04-15","objectID":"/elastic/:16:1","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"Alter alter filter允许对未包含在正常变异过滤器中的字段进行一般更改。 **安装: ** logstash-plugin install logstash-filter-alter **配置项: ** Setting Input type Required coalesce array No condrewrite array No condrewriteother array No coalesce 将file_name的值设置为其参数的第一个非空表达式 condrewrite 如果实际内容等于预期内容，则将字段内容更改为指定值 condrewriteother 如果另一个字段内容等于预期内容，则将字段内容更改为指定值 \r","date":"2018-04-15","objectID":"/elastic/:16:2","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"cidr CIDR filter用于检查时间中的IP地址与可能包含它的网络块列表。可以针对多个网络检查多个地址，任何匹配都可以成功。成功后，可将其它标记/字段添加到事件中。 **配置项: ** Setting Input_type Required address array No network array No network_path a valid filesystem path No refresh_interval number No separator string No address 要检查的IP地址 network 要检查的IP网络 network_path 包含过滤器应检查的网络的外部文件的完整路径 refresh_interval 检查外部文件的更新频率 seperator 从network_path指定的外部文件解析网络的分隔符 \r","date":"2018-04-15","objectID":"/elastic/:16:3","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"csv csv filter处理包含csv数据的事件字段，解析它，并将其存储为单个字段 此过滤器还可解析使用任何分隔符的数据，而不仅仅是逗号 **配置项: ** Setting Input_type Required autodetect_column_names boolean No autogenerate_column_names boolean No columns array No convert hash No quote_char string No separator string No skip_empty_columns boolean No skip_empty_rows boolean No skip_header boolean No source string No target string No autodetect_column_names 是否应该从标题列自动检测列名称，默认false autogenerate_column_names 是否应该自动生成列名，默认true。 如果设置为false，那么没有指定header的列将不会被解析 columns 列名称的列表 convert 应用于列的数据类型转换的集合，可能的转换: integer, float, date, date_time, boolean quote_char 用于引用csv字段的字符，默认\" separator 列分隔符值。默认值comma, skip_empty_columns 是否应该跳过空列，默认false skip_empty_rows 是否应该跳过空行，默认false skip_header 是否应该跳过header，默认false source 源字段值中的csv数据将被扩展为数据结构 target 放置数据的目标字段 \r","date":"2018-04-15","objectID":"/elastic/:16:4","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"date date filter从字段中解析日期，然后使用该日期或时间戳作为事件的Logstash时间戳。它对事件排序和回填旧数据尤其重要。 在没有此过滤器的情况下，如果timestamp尚未在事件中设置，则Logstash将根据首次查看事件是(input time)选择一个时间戳。 date filter配置项： Setting Input_type Required locale string No match array No tag_on_failure array No target string No timezone string No locale 使用POSIX语言标记指定用于日期解析的环境(locale)，如en,en_US 如果未指定，则将使用平台默认值 match 有字段名称和格式模式的数组，[ field, formats…] 如果时间字段有多种格式，你可这样做: match =\u003e [ \"filed-name\", \"MMM dd yyyy HH:mm:ss\", \"MMM d yyyy HH:mm:ss\", \"ISO8601\" ] 嵌套字段表示 [foo][bar] 有几个例外: ISO8601: 解析任何有效的ISO8601时间戳，如2011-04-19T03:44:01.103Z UNIX: 解析float/int Unix原子时间(s) UNIX_MS: 解析int Unix原子时间 TAI64N: 解析tai64n时间值 语法细节: 用于解析日期和时间文本的语法使用字母来指示时间值的种类，以及重复的字母来指示该值的形式。 以下是可用于解析日期和时间的内容： y year yyyy 完整年号，如2018 yy 两位数年份，如18 M month of the year M 最小数字月份,1-12 MM 两位数字月份，01-12 MMM 缩写的月份文本，Jan, Feb... MMMM 完整的月份文本，January, February... d day of the month d 最小数字日，1, 2... dd 两位数字日，01, 02... H hour of the day H 最小数字小时，0, 1... HH 两位数字小时，00, 01... m minutes of the hour m 最小数字分钟，0, 1... mm 两位数字分钟，00, 01... s seconds of the minute s 最小数字秒数，0, 1... ss 两位数字秒数，00, 01... S 秒的最大精度(毫秒)，附加零 S 十分之一秒 SS 百分之一秒 SSS 千分之一秒 Z time zone offset or identity Z 时区偏移量结构为HHmm(如上海)，+0800 ZZ 时区偏移量结构为HH:mm，+08:00 ZZZ 时区身份(如上海)，Asia/Shanghai z time zone names. Time zone names (z) cannot be parsed w week of the year w 最小数字周数，1, 2... ww 两位数字周数，01, 02... D day of the year e day of the week(number) E day of the week(text) E, EE, EEE 星期几的缩写，Mon, Tue, Wed, Thu, Fri, Sat, Sun EEEE 星期几的全文，Monday, Tuesday... 对于非格式化的语法，你需要在值的周围放置单引号字符。如\"yyyy-MM-dd’T’HH:mm:ss\" tag_on_failure 没有成功匹配时，将值附加到tag字段，默认值[\"_dateparsefailure\"] target 将匹配的timestamp存储到给定目标字段中。如果未提供，则默认更新事件的@timestamp字段 timezone 指定用于日期分析的时区标准ID，如Asia/Shanghai \r","date":"2018-04-15","objectID":"/elastic/:16:5","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"dissect dissect filter是一种拆分操作。与对整个字符串应用一个分隔符的常规拆分操作不同，此操作将一组分隔符应用于字符串值。dissect不使用正则表达式，所以速度非常快。 但是，如果文本结构因行而异，则Grok更适合。有一种混合的情况，dissect可用来结构可靠地重复部分，然后Grok用于余下的字段值，并具有更多的正则表达式可预测性和更少的整体工作。 一组字段和分隔符被称为dissection，它使用一组%来描述: field: %{a} delimiter: - %{a} - %{b} - %{c} dissect filter配置项 Setting Input type Required convert_datatype hash No mapping hash No tag_on_failure array No convert_datatype 可以指定int, float数据类型转换。这些将在mapping发生后完成，如果没有mapping部分，请自由使用此设置。 filter { dissect { convert_datatype =\u003e { cpu =\u003e \"float\" code =\u003e \"int\" } } } mapping A hash of dissections of field =\u003e value 不要在值中使用具有转移的\\n，它会被看做两个字符\\+n+而不是实际的换行符。 filter { dissect { mapping =\u003e { # using an actual line break \"message\" =\u003e '\"%{field1}\" \"%{field2}\" \"%{description}\"' \"description\" =\u003e \"%{field3} %{field4} %{field5}\" } } } tag_on_failure dissection失败时，将值添加到tag字段。默认值为[\"_dissectfailure\"] \r","date":"2018-04-15","objectID":"/elastic/:16:6","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"geoip geoip filter根据Maxmind GeoLite2数据库的数据，添加有关IP地址的地理位置信息。 此插件与GeoLite City Database数据库捆绑在一起。GeoLite2是免费的IP地址位置数据库，与MaxMind的GeoIP2数据库相比，不如其精确。 如果需要使用捆绑的DeoLite之外的数据库，可从MaxMind下载它: https://dev.maxmind.com/geoip/geoip2/geolite2/ 如果GeoIP返回查找到的经度(latitude)和纬度(longitude)，则会创建[geoip][location]字段。 Geoip Filter配置项 Setting Inpu_type Required cache_size number No database a valid filesystem path No default_database_type City or ASN No fields array No source string Yes tag_on_failure array No target string No cache_size 默认值为1000。GeoIP查询的成本非常高昂。缓存设置的越高，项目在缓存中的可能性就越大，并且此filter运行的越快。但是，如果设置得太高，则会耗费太多内存。如果缓存已满，则无法添加更多记录。尝试使用此选项的不同值来为数据集找到最佳性能。 这个值必须大于0。 database 地理数据库的文件路径，如果未指定，则默认为logstash自带的GeoLite2-City数据库。 default_database_type 默认值是City。唯一可接受的值是City和ASN。 fields 包含在事件中的geoip字段数组。可能的字段取决于数据库类型。 source 包含要通过geoip映射的IP地址或主机名的字段。 tag_on_failure 默认值为[\"_geoip_lookup_failure\"]. target 默认值为geoip.指定Logstash应该存储的geoip数据的字段。 \r","date":"2018-04-15","objectID":"/elastic/:16:7","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"grok Parse arbitrary text and structure it. Grok是将非结构化日志数据解析为结构化和可查询的好方法。 它非常适用于syslog, apache or webserver logs, mysql logs以及通常为人类而不是计算机编写的任何日志格式。 默认情况下，Logstash ship附带了大约120种模式。它们在这: https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns 要grok某类日志文件的时候，可以先到上面的地址查看有无对应的模式。然后复制对应内容到patterns_dir下，再在filter中使用。 当然，你也可以自定义模式来匹配你的日志。在这测试: http://grokdebug.herokuapp.com Grok filter配置项 Setting Input_type Required break_on_match boolean No keep_empty_captures boolean No match hash No named_captures_only boolean No overwrite array No pattern_definitions hash No patterns_dir array No patterns_files_glob string No tag_on_failure array No tag_on_timeout string No timeout_millis number No break_on_match Break on first match. grok的第一个成功的匹配将导致filter结束。如果你想grok尝试所有的模式，请将其设置为false。默认值为true。 keep_empty_captures 默认值为false。如果为true，则将空捕获保留为事件字段。 match field ⇒ value的散列匹配，默认值为{} filter { grok { match =\u003e { \"message\" =\u003e [ \"Duration: %{NUMBER:duration}\", \"Speed: %{NUMBER:speed}\" ] } } } named_captures_only 默认值为true。如果为true，只保存来自grok的命名捕获。 overwrite 要覆盖的字段，这使你可覆盖已存在的字段中的值。 filter { grok { match =\u003e { \"message\" =\u003e \"%{SYSLOGBASE} %{DATA:message}\" } overwrite =\u003e [ \"message\" ] } } pattern_definitions 默认值为{} 模式名称和模式元组的散列，用于定义当前过滤器要使用的自定义模式。匹配现用名称的模式将覆盖预先存在的定义。 patterns_dir 默认值为[] logstash默认提供了一堆模式，除非添加额外模式，否则不需要自定义模式。你可以使用此设置指向多个模式目录。grok将读取与patterns_files_glob匹配的目录汇总的所有文件，并假定它为模式文件。 patterns_dir =\u003e [\"/opt/logstash/patterns\", \"/opt/logstash/extra_patterns\"] patterns_files_glob 默认值为\"*\" Glob模式，用于从patterns_dir目录中选择模式文件。 tag_on_failure 默认值为[\"_grokparsefailure\"] 匹配没有成功时，将值添加到tags字段。 tag_on_timeout 默认值为\"_groktimeout\" 如果grok正则表达式超时，则应用此tag. timeout_millis 默认值为30000 尝试在这段时间后终止正则表达式。设置为0以禁用超时。 基础知识 Grok工作方式，将文本模式组合成与你的日志模式相匹配的内容。 Grok模式的语法为 %{SYNTAX:SEMANTIC} SYNTAX, 文本匹配的模式的名称 SEMANTIC, 正在匹配的文本的标识符 %{NUMBER:duration} %{IP:client} 你也可以将数据类型转换添加到Grok模式。默认情况下，所有的语义(semantic)都保存为字符串(strings)。 如果你想转换语义的数据类型，如将string转换为int。例如%{NUMBER:num:int}将num语义从string转换为integer。当前情况下，只支持转换为int和float. 日志格式 55.3.244.1 GET /index.html 15824 0.043 grok pattern grok { match =\u003e { \"message\" =\u003e \"%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}\" } } grok filter之后的格式 client: 55.3.244.1 method: GET request: /index.html bytes: 15824 duration: 0.043 正则表达式 Grok位于正则表达式之上，所以任何正则表达式在grok中都是有效的。 Regular Expression Library: https://github.com/kkos/oniguruma/blob/master/doc/RE 示例 grok处理nginx/access.log日志: 首先针对nginx.conf中日志格式来决定如何写logstash pattern mkdir /etc/logstash/patterns vim nginx NGINX_ACCESS %{IPORHOST:clientip} (?:-|(%{WORD}.%{WORD})) %{USER:ident} \\[%{HTTPDATE:timestamp}\\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} %{QS:forwarder} grok { patterns_dir =\u003e \"/etc/logstash/patterns\" match =\u003e { \"message\" =\u003e %{NGINX_ACCESS}} } grok debugger grok-patterns 这是grok官方写得patterns，当然，你也可以自己写。就像Nginx日志那样！ USERNAME [a-zA-Z0-9._-]+ USER %{USERNAME} EMAILLOCALPART [a-zA-Z][a-zA-Z0-9_.+-=:]+ EMAILADDRESS %{EMAILLOCALPART}@%{HOSTNAME} INT (?:[+-]?(?:[0-9]+)) BASE10NUM (?\u003c![0-9.+-])(?\u003e[+-]?(?:(?:[0-9]+(?:\\.[0-9]+)?)|(?:\\.[0-9]+))) NUMBER (?:%{BASE10NUM}) BASE16NUM (?\u003c![0-9A-Fa-f])(?:[+-]?(?:0x)?(?:[0-9A-Fa-f]+)) BASE16FLOAT \\b(?\u003c![0-9A-Fa-f.])(?:[+-]?(?:0x)?(?:(?:[0-9A-Fa-f]+(?:\\.[0-9A-Fa-f]*)?)|(?:\\.[0-9A-Fa-f]+)))\\b POSINT \\b(?:[1-9][0-9]*)\\b NONNEGINT \\b(?:[0-9]+)\\b WORD \\b\\w+\\b NOTSPACE \\S+ SPACE \\s* DATA .*? GREEDYDATA .* QUOTEDSTRING (?\u003e(?\u003c!\\\\)(?\u003e\"(?\u003e\\\\.|[^\\\\\"]+)+\"|\"\"|(?\u003e'(?\u003e\\\\.|[^\\\\']+)+')|''|(?\u003e`(?\u003e\\\\.|[^\\\\`]+)+`)|``)) UUID [A-Fa-f0-9]{8}-(?:[A-Fa-f0-9]{4}-){3}[A-Fa-f0-9]{12} # URN, allowing use of RFC 2141 section 2.3 reserved characters URN urn:[0-9A-Za-z][0-9A-Za-z-]{0,31}:(?:%[0-9a-fA-F]{2}|[0-9A-Za-z()+,.:=@;$_!*'/?#-])+ # Networking MAC (?:%{CISCOMAC}|%{WINDOWSMAC}|%{COMMONMAC}) CISCOMAC (?:(?:[A-Fa-f0-9]{4}\\.){2}[A-Fa-f0-9]{4}) WINDOWSMAC (?:(?:[A-Fa-f0-9]{2}-){5}[A-Fa-f0-9]{2}) COMMONMAC (?:(?:[A-Fa-f0-9]{2}:){5}[A-Fa-f0-9]{2}) ","date":"2018-04-15","objectID":"/elastic/:16:8","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"json 这是一个json解析过滤器。 Json Filter配置项 Setting Input_type Required skip_on_invalid_json boolean No source string Yes tag_on_failure array No target string No skip_on_invalid_json 默认值是false.允许跳过无效json上的过滤器。 source json filter的配置 如，从message字段中解析json filter { json { source =\u003e \"message\" } } target 定义放置解析数据的目标字段。如果目标字段已存在，则它会被覆盖。 filter { json { target =\u003e \"doc\" } } \r","date":"2018-04-15","objectID":"/elastic/:16:9","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"kv 此过滤器有助于自动解析key=value类型的消息。 这对于postfix, iptables和倾向于key=value语法类型的日志非常有用。 #before ip=1.2.3.4 error=REFUSED filter { kv {} } #after ip: 1.2.3.4 error: REFUSED kv filter配置项 Setting Input_type Required allow_duplicate_values boolean No default_keys hash No exclude_keys array No field_split string No include_brackets boolean No include_keys array No prefix string No recursive boolean No remove_char_key string No remove_char_value string No source string No target string No transform_key string, one of [“lowercase”, “uppercase”, “capitalize”] transform_value string, one of [“lowercase”, “uppercase”, “capitalize”] trim_key string No trim_value string No value_split string No allow_duplicate_values 默认值为true.用于删除重复 键/值对的布尔选项。 default_keys 默认值为{}.一个散列，用于指定在解析源字段中不存在的键时应添加到事件中的默认值及其值。 exclude_keys 默认值为[].一个数组，用于指定不应添加到事件中的解析键。默认情况下，没有键被排除。 field_split 默认值为\" \".用作解析出键值对后的单字符字段分隔符的字符串。 #栗子 name=zhang21\u0026age=25\u0026email=ab123@gamil.com filter { kv { field_split =\u003e \"\u0026\" } } field_split_pattern 一个正则表达式，用作字段分隔符来解析键值对。用于定义多字符字段分隔符。 它优先于field_split选项。 #栗子 k1=v1:k2=v2:::k3=v3::k4=v4 filter { kv { field_split_pattern =\u003e \":+\" } } include_brackets 默认值为true.一个布尔值，指定是否将 方括号[square bracket]，尖括号和括号(bracket) 视为的包装器(wrapper)，是否应该从值中删除。 #栗子 one=(o n e) two=[t w o] three=\u003ct h r e e\u003e filter { kv { include_brackets =\u003e tree } } #after one: o n e two: t w o three: t h r e e include_keys 默认值为[].一个数字，用于指定应该添加到解析的键。默认情况下，所有的键都会被添加。 prefix 默认值为空。预先添加到所有提取的键的字符串。 recursive 默认值为false.一个布尔值，执行是否向下提取值并递归获取更多的键值对。 remove_char_key 要从键中移除的字符串。 remove_char_value 要从值中移除的字符串。 source 默认值为message.要在其上执行key=value搜索的字段。 target 将所有键值对放入的容器的名称。 transform_key 将键转换为大写，小写。 transform_value 将值转换为大写，小写 trim_key 从键中修建的字符串。如果键包含在括号中或以空格开头，这很有用。 trim_value 从值中修建的字符串。如果你的值包含在括号中或以逗号结尾。这很有用。 value_split 默认值为=.一个非空字符串，用作解析出键值对的单字符分隔符。 value_split_pattern 用作值分隔符来解析出键值对的正则表达式。优先级高于value_split。 \r","date":"2018-04-15","objectID":"/elastic/:16:10","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"metrics metrics filter用于聚合度量(aggregating metrics). #计算每种http响应吗 filter { metrics { meter =\u003e [ \"http_%{response}\" ] add_tag =\u003e \"metric\" } } metrics filter配置项 Setting Input_type Required clear_interval number No flush_interval number No ignore_older_than number No meter array No percentiles array No rates array No timer hash No clear_interval 默认值为-1.清理间隔，所有的计数器都被重置。 flush_interval 默认值为5.刷新间隔，当metrics事件被创建时。此值必须是5的倍数。 ignore_older_than 默认值为0.不要跟着@timestamp超过某个秒数的事件。 meter 语法: meter =\u003e [ \"name of metric\", \"name of metric\" ] percentiles 默认值为percentiles.计时器值应该测量和发出的百分位数。 rates 默认值为[1, 5, 15].应该按分钟测量的比率。 timer 语法: timer =\u003e [ \"name of metric\", \"%{time_value}\" ] meter values meter =\u003e \"something\", 会收到如下字段: “[thing][count]” - the total count of events “[thing][rate_1m]” - the per-second event rate in a 1-minute sliding window “[thing][rate_5m]” - the per-second event rate in a 5-minute sliding window “[thing][rate_15m]” - the per-second event rate in a 15-minute sliding window timer values timer =\u003e { \"thing\" =\u003e \"%{duration}\"}, 会收到如下字段: “[thing][count]” - the total count of events “[thing][rate_1m]” - the per-second average value in a 1-minute sliding window “[thing][rate_5m]” - the per-second average value in a 5-minute sliding window “[thing][rate_15m]” - the per-second average value in a 15-minute sliding window “[thing][min]” - the minimum value seen for this metric “[thing][max]” - the maximum value seen for this metric “[thing][stddev]” - the standard deviation for this metric “[thing][mean]” - the mean for this metric “[thing][pXX]” - the XXth percentile for this metric (see percentiles) \r","date":"2018-04-15","objectID":"/elastic/:16:11","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"mutate mutate filter允许你在字段上执行常规突变。你可以重命名，删除，替换和修改事件中的字段。 mutate filter配置项 Setting Input_type Required convert hash No copy hash No gsub array No join hash No lowercase array No merge hash No coerce hash No rename hash No replace hash No split hash No strip array No update hash No uppercase array No capitalize array No convert 将字段的值转换为其它类型，如将string转换为int.如果只为数组，则所有成员都将转换；如果是散列，则不处理。 copy 将现有字段复制到另一个字段(会覆盖)。 gsub 将正则表达式与字段值进行匹配，并用替换字符替换所有匹配项。 只支持string或string array. filter { mutate { gsub =\u003e [ \"field1\", \"value\", \"replacement string\", ] } } join 加入一个带分隔符的数组。对非数组字段没有任何作用。 lowercase 将字符串转换为小写 merge 合并数组或散列的两个字段。字符串字段将被自动转换为数组。 filter { mutate { merge =\u003e { \"dest_field\" =\u003e \"added_field\"} } } coerce 为已存在但为空的字段设置默认值。 rename 重命名一个或多个字段。 replace 用新值替换一个字段。新值可以包含%{foo}字符串，以帮助你从事件的其它部分创建新值。 filter { mutate { replace =\u003e { \"message\" =\u003e \"%{source_host}: My new message\" } } } split 使用分隔符将字段拆分为数组。只适用于字符串字段。 strip 从字段剥离空白符。 update 用新值更新现有字段。 \r","date":"2018-04-15","objectID":"/elastic/:16:12","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"xml XML filter.获取包含XML的字段并将其展开为实际的数据结构。 XML Filter配置项 Setting Input_type Required force_array boolean No force_content boolean No namespaces hash No remove_namespaces boolean No source string Yes store_xml boolean No suppress_empty boolean No target string No xpath hash No force_array 默认值为true.过滤器强制单个元素为数组。将其设置为false防止在数组中存储单个元素。 force_content 默认值为false.过滤器将以不同于标签内的内容的方式展开属性。 namespace 默认值为{}.这允许配置所有命名空间声明来解析XML文档。 filter { xml { namespaces =\u003e { \"xsl\" =\u003e \"http://www.w3.org/1999/XSL/Transform\" \"xhtml\" =\u003e \"http://www.w3.org/1999/xhtml\" } } } remove_namespaces 从文档中的所有节点中删除所有命名空间。 source store_xml 默认为true.过滤器会将整个解析的XML存储在目标字段中。 suppress_empty 默认值为true.默认情况下，如果元素为空，这不输出。如果设置为false,则空元素将产生一个空的散列对象。 target 定义放置数据的目标。 \r","date":"2018-04-15","objectID":"/elastic/:16:13","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"条件判断 使用条件判断决定filter和output处理特定的事件。 Logstash条件类似于编程语言，条件语句，可以嵌套： if else if else 比较操作： == != \u003c \u003e \u003c= \u003e= =~ 匹配正则 !~ 不匹配正则 in 包含 not in 不包含 布尔操作： and or nand xor 一元运算符： ! 取反 () 复合表达式 栗子： output { if [path] == \"/var/nginx/access.log\" { elasticsearch { hosts =\u003e user =\u003e password =\u003e index =\u003e \"nginx-access-%{+YYYY.MM.dd}\" } } else if [path] == \"/var/nginx/error.log\" { elasticsearch { hosts =\u003e user =\u003e password =\u003e index =\u003e \"nginx-error-%{+YYYY.MM.dd}\" } } else { } } \r Filebeat文档 ","date":"2018-04-15","objectID":"/elastic/:17:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"概述 filebeat是一个beat，它基于libbeat框架。 Filebeat是一个本地文件的日志数据搬运(shipper)。作为Agent安装，filebeat监视日志目录或指定的日志文件，并将它们转发给Elasticsearch或logstash进行索引。 启动filebeat时，它会启动一个或多个prospectors(勘探者)，查看为日志指定的本地路径。对于prospectors所在的每个日志文件，filebeat启动harvester。每个harvester为新内容读取单一日志文件，并将新日志发送到filebeat配置的输出。 \r","date":"2018-04-15","objectID":"/elastic/:18:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"入门 开始filebeat前，请确保安装和配置了如下产品： Elasticsearch(存储和索引数据) Kibana(UI) Logstash(可选) ","date":"2018-04-15","objectID":"/elastic/:19:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"配置 filebeat module为常用日志格式提供了入门体验。 vim /etc/filebeat/filebeat.yml filebeat.prospectors: -type: log enabled: true paths: - /var/log/*.log output.elasticsearch: hosts: [ \"ip:9200\" ] #username #password setup.kibana: host: \"localhost:5601\" #username #password ","date":"2018-04-15","objectID":"/elastic/:19:1","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"配置filebeat使用logstash vim /etc/filebeat/filebeat.yml output.logstash: hosts: [ \"127.0.0.1:5044\" ] #logstash需要配置监听beats \r","date":"2018-04-15","objectID":"/elastic/:19:2","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"在Elasticsearch中载入索引模板 在Elasticsearch中，索引模板用于定义设置(setting)和映射(mapping)，以确定如何分析字段(fields)。 filebeat推荐的索引模板文件有filebeat软件包安装。在成功连接到Elasticsearch后，它会默认自动载入索引模板(fields.yml)。如果模板存在，它不会覆盖除，除非你配置要覆盖。 通过修改配置文件，你也可以禁用自动载入模板，或者载入你自己的模板。 配置模板载入 vim /etc/filebeat/filebeat.yml setup.template.name: \"template-name\" setup.template.fields: \"/path/xxx/xxx.yml\" #强制覆盖已存在模板 setup.template.overwrite: true #关闭自动载入模板 setup.template.enabled: false 修改索引名 filebeat的默认索引名为 filebeat-\u003cversion\u003e-yyyy.MM.dd 在output.elasticsearch设置选项 你指定的索引名称应该包含索引的根名、索引版本和日期信息 output.elasticsearch.index: \"customname-%{[version]}-%{+yyyy.MM.dd}\" setup.template.name: \"customname\" setup.template.pattern: \"customname-*\" setup.dashboards.index: \"customname-*\" 手动载入模板 filebeat setup --template 强制Kibana查看最新文件 curl -XDELETE 'http://localhost:9200/filebeat-*' ","date":"2018-04-15","objectID":"/elastic/:19:3","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"设置Kibana面板 Filebeat附带了实例的Kibana dashboards, visualization和可视化搜索。 在使用仪表板前，你需要创建索引filebeat-*，并将仪表板加载到Kibana中。你可使用setup命令或配置文件加载它。 ","date":"2018-04-15","objectID":"/elastic/:19:4","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"启动Filebeat systemctl start filebeat #前台启动并查看相关信息 filebeat -e -c filebeat.yml ","date":"2018-04-15","objectID":"/elastic/:19:5","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"查看示例Kibana仪表板 访问你的kibana web端(localhost:5601)，可用Nginx做反向代理，再加上域名解析。 ","date":"2018-04-15","objectID":"/elastic/:19:6","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"快速开始常见日志格式 filebeat提供了一套预构建模块，可使用它快速实施和部署日志监视方案。 先决条件： 安装和配置Elastic Stack 安装filebeat 安装Ingest Node GeoIP和User Agent plugins 验证Elasticsearch和Kibana能从filebeat接收数据 elasticsearch-plugin install ingest-geoip elasticsearch-plugin install ingest-user-agent 运行filebeat模块 #启用模块 filebeat modules enable nginx system #配置path cd /etc/filebeat/modules.d vim nginx.yml vim system.yml 最后就可以在Kibana中可视化查看日志。 查看dashboard时，遇到一个错误: Could not locate that index-pattern (id: filebeat-*) 解决办法： #重新载入索引模板 filebeat setup ","date":"2018-04-15","objectID":"/elastic/:19:7","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"output 我们可根据系统的负载情况将Filebeat的output到合适的地方，output只能有一个！ 如果有时候系统负载过高的话，可以考虑output到Redis或Elasticsearch。 redis和logstash都还需要logstash的pipeline转交给Elasticsearch，但你可以filter。而直接使用Elasticsearch便不能过滤。 Logstash Elasticsearch Redis vim /etc/filebeat/filebeat.yml #找到output #redis output.redis: hosts: \"localhost\" port: 6379 key: \"filebeat\" #自定义key-name #password: #db: #data_type: 'list' #logstash output.logstash: hosts: [ \"localhost:5044\" ] #Elasticsearch elasticsearch.output: hosts: [ \"localhost:9200\" ] #username: #name: ================== #redis对应的pipeline vim /etc/logstash/conf.d/redis-pipeline.conf input { redis { data_type =\u003e \"list\" key =\u003e \"filebeat\" host =\u003e \"localhost\" port =\u003e 6379 #password =\u003e #db =\u003e } } #filter{ } output { elasticsearch { hosts =\u003e [ \"localhost:9200\" ] #user #password index =\u003e \"filebeat-%{+YYYY.MM.dd}\" } } \r","date":"2018-04-15","objectID":"/elastic/:20:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"定义索引 为filebeat定义index: vim /etc/filebeat/filebeat.yml # Optional index name. The default is \"filebeat\" plus date # and generates [filebeat-]YYYY.MM.DD keys. # In case you modify this pattern you must update setup.template.name and setup.template.pattern accordingly. #index: \"filebeat-%{[beat.version]}-%{+yyyy.MM.dd}\" #写到事件中的索引名，默认 \"filebeat-%{[beat.version]}-%{+yyyy.MM.dd}\" #如果更改此设置，还需要配置setup.template.name和setup.template.pattern选项 #如果使用的是预先构建的kibana dashboard，还需要配置setup.dashboards.index选项 #定义索引 output.elasticsearch: hosts: [\"10.0.1.8:9002\", \"10.0.1.7:9002\", \"10.0.1.9:9002\"] loadbalance: true username: \"elastic\" password: xxx index: \"filebeat-publish-%{+yyyy.MM.dd}\" #添加这几项 setup.template.name: \"filebeat\" setup.template.pattern: \"filebeat-*\" setup.template.fields: \"fields.yml\" setup.template.overwrite: false \r\r","date":"2018-04-15","objectID":"/elastic/:20:1","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"配置 RPM安装的配置文件默认是/etc/filebeat/filebeat.yml，还有一个完整的示例配置文件/etc/filebeat/filebeat.reference.yml，显示了所有未弃用的选项。配置文件使用YAML语法。 \r","date":"2018-04-15","objectID":"/elastic/:21:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"指定运行module Specify which modules to run Filebeat module提供了一种快速处理常见日志格式的方法。它包含默认配置。 有几种不同方法来启用modules: 配置modules.d目录 filebeat命令启动 配置filebeat.yml文件 #modules.d filebeat modules list filebeat modules enable nginx #filebeat modules disable nginx #filebeat命令 ./filebeat -e --modules nginx #filebeat.yml filebeat.modules: - module: nginx - module: system \r\r指定变量设置 Specify variable settings 每个模块和文件集合都有变量，你可以设置这些变量来更改木块的默认行为。 - module: nginx access: var.path: [\"/var/log/nginx/access.log*\"] #or filebeat -M \"nginx.access.var.paths=[/var/log/access.log*]\" filebeat --modules nginx -M \"nginx.access.var.paths=[/var/log/nginx/access.log*]\" -M \"nginx.error.var.paths=[/var/log/nginx/error.log*]\" \r\r高级设置 在幕后，每个木块都会启动filebeat input。高级用户可以添加或覆盖任何input设置。 - module: nginx access: input: close_eof: true #or filebeat -M \"nginx.access.input.close_eof=true\" filebeat --modules nginx -M \"nginx.access.input.close_eof=true\" \r\r","date":"2018-04-15","objectID":"/elastic/:21:1","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"读取动态文件名 filbeat配置文件虽然可以将索引设置为: indexname-%{+yyyy.MM.dd} 的日志格式，但这个是发送给ES的，ES可以处理此配置，但filebeat是无法直接处理的，它会把它当做普通字符。 假如我要读取一个按日期取名的日志文件，如service_20180808.log，filebeat配置文件中是无法直接配置和处理。 后来想到，可以用sh写一个脚本来做此操作。 yesterday=`/bin/date +%Y%m%d --date='-1days'` today=`/bin/date +%Y%m%d` /bin/sed -i \"s/service_err_${yesterday}/service_err_${today}/\" /etc/filebeat/filebeat.yml /bin/filebeat test config if [ $? -eq 0 ] ;then /bin/systemctl restart filebeat else exit 0 fi \r\r","date":"2018-04-15","objectID":"/elastic/:21:2","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"input DEPRECATED: prospectors are deprecated, Use inputs instead. Will be removed in version: 7.0.0 要手动配置filebeat(而不是使用modules)，需要在filebeat.yml的filebeat.inputs部分指定输入列表(一个YAML 数据)。你可指定多个输入，并可多次指定相同的输入类型。 input types log stdin redis udp docker tcp syslog input 通用选项： #启用/禁用inputs enabled #增加tags字段 tags #向输出添加其他信息 fields filebeat.inputs: - type: log fields: author: zhang21 #自定义字段存储为输出文档中的顶级字段，而不是在字段子字典下分组。如果与filebeat冲突，则会覆盖源字段 fields_under_root #应用于inputs的处理器列表 #已被弃用 processors #为input生成的事件设置ingest node pipeline id pipeline \r\rlog 使用log input从日志文件中读取行。 filebeat.inputs:- type:logpaths:- /var/log/messages- /var/log/*.log 你可以将其它配置设置(fields, include_lines, exclude_lines, mutiline)应用于从日志文件获取的行。这里指定的选项将应用于input的所有文件。 将不同的配置应用于不同的文件，需要定义多个input sections: filebeat.inputs:- type:logpaths:- /var/log/1.log- /var/log/2.log- type:logpaths:- \"/var/log/appache/*\"fields:apache:truefields_under_root:true log input 配置项 paths#将读取的基于全局路径的列表recursive_glob.enabled#true允许扩展为递归模式encoding#读取数据的文件编码exclude_lines#正则表达式列表，用于匹配你希望filebeat排除的行filebeat.inputs:- type:log...exclude_lines:['^debug']include_lines#正则表达式列表，用于匹配你希望filebeat包含的行。#如果`exclude_lines`和`include_lines`都定义了，filebeat首先执行`include_lines`，之后才执行`exclude_lines`。filebeat.inputs:- type:log...include_lines:['^ERR','^WARN']harvester_buffer_size#每个收集器在获取文件时使用的buffer大小，默认 16 384Byte。max_bytes#单日志消息可以具有的最大字节数。默认 10MBjson#此选项使filebeat解码日志结构为json消息。filebeat逐行处理日志，因此每一行要有json对象才有效。json.keys_under_rootjson.overwrite_keysjson.add_error_keyjson.message_keyjson.ignore_decoding_errormutiline#控制filebeat如果处理跨越多行的日志消息。exclude_files#正则表达式列表，用于匹配你希望filebeat忽略的文件。默认无。filebeat.inputs:- type:log...exclude_files:['\\.gz$']ignore_older#如果启用此选项，filebeat将忽略在指定的事件跨度之前修改的所有文件。close_*#用于在某个标准或时间后关闭收集器。close_inactive#如果文件尚未在指定的时间内收获，则filebeat将关闭文件句柄。close_renamed#filebeat会在重命名文件时关闭文件处理程序，请注意日志轮询。close_removed#删除文件后，filebeat会关闭收集器。close_eof#一旦到达文件末尾，filebeat就会关闭文件。clean_*#用于清理注册表文件中的状态条目。clean_inactive#filebeat在指定的不活动事件段过去后删除文件的状态。clean_removed#如果在最后一个已知名称下无法在磁盘上找到文件，则filebeat会清除注册表中的文件。scan_frequency#filebeat检查指定路径文件的频率。官方不建议将此值设置为小于1s。默认 10s。tail_files#filebeat开始在每个文件的末尾而不是开头读取新文件。默认 falsesymlinks#允许filebeat收集符号链接，它读取符号链接的原始文件。由于此选项可能会导致数据丢失，默认 disabledbackoff#指定filebeat如何积极地抓取打开的文件以进行更新。max_backoff#在到达eof后再次检查文件之间filebeat等待的最长时间。backoff_factor#指定等待时间增加的速度。harvester_limit#限制一个input并行启动的收集器数量。 \r\rstdin 使用stdin input从标准输入读取事件。此输入不可与其它输入类型同时运行。 filebeat.inputs:- type:stdin stdin input 配置项： encodingexclude_linesinclude_linesharvester_buffer_sizemax_bytesjsonmultiline \r\rudp 使用 udp input通过udp读取事件。 filebeat.inputs:- type:udpmax_message_size:10KBhost:\"localhost:5678\" udp input 配置项： #通过udp接收的最大消息大小，默认 10KBmax_message_size#udp hosthost \r\rtcp 使用 tcp input 通过tcp读取事件。 filebeat.inputs:- type:tcpmax_message_size:10MBhost:\"localhost:5679\" tcp input 配置项： max_message_size#通过tcp接收的最大消息大小， 默认 10MB#host and tcp porthost#指定用于拆分事件的字符，默认 \\nline_delimiter#关闭连接前不活动的秒数， 默认 300stimeout \r\rdocker 使用docker input从docker container读取日志。 filebeat.inputs:- type:dockecontainers:path:\"/var/lib/docker/containers\"stream:\"all\"ids:- 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'#必须填写容器ID docker input 配置项： container.ids#默认 /var/lib/docker/containerscontainer.path#从指定stream读取: all/stdout/stderr，默认 allcontainer.streamencodingexclude_lineinclude_lineharvester_buffer_sizemax_bytesjsonmultilineexclude_filesignore_olderclose_*close_inactiveclose_renamedclose_removedclose_eofclose_timeoutclean_*clean_inactiveclean_removedsacn_frequencytail_filessymlinksbackoffmax_backoffbackoff_factorharvester_limit \r\rsyslog 使用 syslog input通过tcp/udp/读取事件。 修改syslog配置： vim /etc/rsyslog.d/filebeat.conf *.* @127.0.0.1:5678 #重启服务 systemctl restart rsyslog filebeat.inputs:- type:syslogprotocol.udp:host:\"localhost:5678\"max_message_size:100KB#定义索引setup.template.name:\"filebeat\"setup.template.pattern:\"filebeat-*\"setup.template.fields:\"fields.yml\"setup.template.overwrite:falseout.elastisearch：hosts:[\"localhost:9200\"]index:\"syslog-%{+yyyy.MM.dd}\" 它的配置项就是tcp/udp的配置项。 之后查看主机端口情况： netstat -nltup | grep 5678 udp 0 0 127.0.","date":"2018-04-15","objectID":"/elastic/:21:3","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"output 你可以通过在filebet.yml配置文件的output部分设置选项来配置filebeat以特定方式输出。只能定义一个输出。 filebeat支持如下输出： Elasticsearch Logstash Kafka Redis File Console \relasticsearch filebeat使用es http api将事务发送到es。 output.elasticsearch: hosts: [\"https://localhost:9200\"] username: \"filebeat_internal\" password: \"YOUR_PASSWORD\" index: \"filebeat-%{[beat.version]}-%{+yyyy.MM.dd}\" #ssl.certificate_authorities: [\"/etc/pki/root/ca.pem\"] #ssl.certificate: \"/etc/pki/client/cert.pem\" #ssl.key: \"/etc/pki/client/cert.key\" 配置项： #启用/禁用output，默认 trueenabledhosts#[\"hsot1:port1\", \"host2:port2\", \"host3:port3\"]username#建议为filebeat创建一个专门的用户用于发送事件，而不是使用es的用户passwordcompression_level#gzip压缩等级, 0-9，默认 0worker#每个配置主机向es发布事件的worker数，默认 1parameters#http 参数字典protocol#网络协议, http/httpspath#http api调用前面的http路径前缀headers#定义headersproxy_url#代理的urlindex#写到事件中的索引名，默认 \"filebeat-%{[beat.version]}-%{+yyyy.MM.dd}\"#如果更改此设置，还需要配置setup.template.name和setup.template.pattern选项#如果使用的是预先构建的kibana dashboard，还需要配置setup.dashboards.index选项indices#支持条件的索引选择器规则数组，基于格式字符串的字段访问和名称映射。indices.index:要使用的索引格式字符串indices.mapping： 映射indices.default： 如果映射找不到匹配项的默认字符串值indices.when： 成功的条件才执行当前规则output.elasticsearch:hosts:[\"http://localhost:9200\"]index:\"logs-%{[beat.version]}-%{+yyyy.MM.dd}\"indices:- index:\"critical-%{[beat.version]}-%{+yyyy.MM.dd}\"when.contains:message:\"CRITICAL\"- index:\"error-%{[beat.version]}-%{+yyyy.MM.dd}\"when.contains:message:\"ERR\"pipeline#与indices类似，管道选择器配置数组filebeat.inputs:- type:logpaths:[\"/var/log/app/normal/*.log\"]fields:type:\"normal\"- type:logpaths:[\"/var/log/app/critical/*.log\"]fields:type:\"critical\"output.elasticsearch:hosts:[\"http://localhost:9200\"]index:\"filebeat-%{[beat.version]}-%{+yyyy.MM.dd}\"pipelines:- pipeline:critical_pipelinewhen.equals:fields.type:\"critical\"- pipeline:normal_pipelinewhen.equals:fields.type:\"normal\"max_retriesbulk_max_size#单个es批量挨批索引请求中要批量处理的最大事件数，默认 50backoff.init#在网络错误之后尝试重连到es之前等待的秒数，默认 1sbackoff.max#在网络错误后尝试连接到es之前等待的最大秒数，默认 60stimeout#超时时间ssl \r\rlogstash \r\rkafka \r\rredis redis output将事件插入redis list或redis channel。 output.redis:hosts:\"localhost\"port:6379key:\"filebeat\"#自定义key-name#password:#db:#data_type: 'list' 配置项： #启用/禁用outputenabledhostsport#可将端口写在hosts里，默认6379usernamepassworddbkeydatatype#默认 listcodeckeyskeys.keykeys.mappingkeys.defaultkeys.whenoutput.redis:hosts:[\"localhost\"]key:\"default_list\"keys:- key:\"info_list\"# send to info_list if `message` field contains INFOwhen.contains:message:\"INFO\"- key:\"debug_list\"# send to debug_list if `message` field contains DEBUGwhen.contains:message:\"DEBUG\"- key:\"%{[fields.list]}\"mapping:\"http\": \"frontend_list\"\"nginx\": \"frontend_list\"\"mysql\": \"backend_list\"loadbalance#如果配置了多个主机，则输出插件会将已发布的事件负载均衡到所有redis主机上timeoutmax_retriesbulk_max_sizesslproxy_urlproxy_use_local_resolver \r\rfile file output将事务转储到文件中，每个事务都是json格式。 output.file:path:\"/tmp/filebeat\"filename:filebeat 配置项： enabledpathfilenamerotate_every_kb#默认 10 240KBnumber_of_files#路径下要保存的最大文件数permissions#创建的文件权限， 默认 0600codec \r\rconsole console output将事件以json格式输出到标准输出。 output.console:pretty:true 配置项： pretty#美化输出， 默认 falsecodecenabledbulk_max_size \r\r","date":"2018-04-15","objectID":"/elastic/:21:4","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"loadbalance filebeat提供配置项，用于将事件发送到多个主机时微调负载均衡。 loadbalance对redis, logstash, es output可用。 output.logstash:hosts:[\"localhost:5044\",\"localhost:5045\"]loadbalance:true \r Kibana文档 Kibana是一个开源分析和可视化平台，旨在与Elasticsearch合作。你可使用Kibana来检索(search)，查看(view)存储在Elasticsearch索引中的数据并与其进行交互(interact)。你可以很轻松地执行高级数据分析，并在各种图表、表格和地图中可视化你的数据。 Kibana可以很容易地理解大量的数据。基于浏览器的接口能够快速创建和分享动态仪表盘，实时显示Elasticsearch查询的变化。 \r","date":"2018-04-15","objectID":"/elastic/:21:5","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"入门 在开始前，请确保已安装Kibana并与Elasticsearch建立了连接。 \r","date":"2018-04-15","objectID":"/elastic/:22:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"载入示例数据 本节依赖如下示例数据： shakespeare.json: https://download.elastic.co/demos/kibana/gettingstarted/shakespeare_6.0.json accounts.zip: https://download.elastic.co/demos/kibana/gettingstarted/accounts.zip uzip accounts.zip logs.jsonl.gz: https://download.elastic.co/demos/kibana/gettingstarted/logs.jsonl.gz gunzip logs.jsonl.gz shakespeare按以下模式组织： { \"line_id\": INT, \"play_name\": \"String\", \"speech_number\": INT, \"line_number\": \"String\", \"speaker\": \"String\", \"text_entry\": \"String\" } accounts按以下模式组织： { \"account_number\": INT, \"balance\": INT, \"firstname\": \"String\", \"lastname\": \"String\", \"age\": INT, \"gender\": \"M or F\", \"address\": \"String\", \"employer\": \"String\", \"email\": \"String\", \"city\": \"String\", \"state\": \"String\" } 日志数据的模式有许多不同的字段，此例使用字段如下： { \"memory\": INT, \"geo.coordinates\": \"geo_point\", \"@timestamp\": \"date\" } 载入数据前，需要为字段设置映射。 映射将索引中的文档分成逻辑组，并指定字段特性。如可搜索性、标记化、分解为单独的单词。 在Kibana界面中的Dev Tools中输入如下命令，为shakespeare数据设置映射。 PUT /shakespeare { \"mappings\": { \"doc\": { \"properties\": { \"speaker\": {\"type\": \"keyword\"}, \"play_name\": {\"type\": \"keyword\"}, \"line_id\": {\"type\": \"integer\"}, \"speech_number\": {\"type\": \"integer\"} } } } } 日志数据集logs.jsonl需要映射才能将日志中的经纬度标记为地理位置。 PUT /logstash-2015.05.18 { \"mappings\": { \"log\": { \"properties\": { \"geo\": { \"properties\": { \"coordinates\": { \"type\": \"geo_point\" } } } } } } } PUT /logstash-2015.05.19 { \"mappings\": { \"log\": { \"properties\": { \"geo\": { \"properties\": { \"coordinates\": { \"type\": \"geo_point\" } } } } } } } PUT /logstash-2015.05.20 { \"mappings\": { \"log\": { \"properties\": { \"geo\": { \"properties\": { \"coordinates\": { \"type\": \"geo_point\" } } } } } } } accounts数据集不需要映射，这一点上使用Elasticsearch的bulk API去载入数据集： #这些命令要花一些时间 curl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/bank/account/_bulk?pretty' --data-binary @accounts.json curl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/shakespeare/doc/_bulk?pretty' --data-binary @shakespeare_6.0.json curl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/_bulk?pretty' --data-binary @logs.jsonl #验证 #在Kibana中的DevTools中运行 GET /_cat/indices?v \r","date":"2018-04-15","objectID":"/elastic/:22:1","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"定义你的索引模式 加载到Elasticsearch的每组数据集都有一个索引模式(index pattern)。索引模式是一个带有可匹配多个索引的可使用通配符的字符串。 在前面，Shakespeare数据集有一个名为: shakespeare 的索引；Account数据集有一个名为：bank 的索引。 如，在常见的日志文件中，一个典型的索引包含YYYY.MM.DD日期格式，类似于logstash-2015.05.*。 进入Kibana界面，点击Management， Index Patterns， Create Index Pattern 来创建一个索引模式。 shakespeare和account数据集不包含 time-series data。确保为此数据集创建索引模式时，不包含基于时间的事件。logs数据集包含了时序数据，因此索引需要包含基于时间的事件。 shakes* ba* logstash-2015* 定义索引模式时，与Elasticsearch匹配的索引必须存在。 在Kibana的DevTools中输入: GET _cat/indices 来查看索引。 \r","date":"2018-04-15","objectID":"/elastic/:22:2","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"数据发现 点击Kibana界面中的Discover以显示数据发现功能。 \r\r","date":"2018-04-15","objectID":"/elastic/:22:3","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"可视化 Visualize Visualize允许你在Elasticsearch索引中创建数据的可视化。然后可以构建显示相关可视化的仪表盘。 Kibana的可视化基于Elasticsearch查询。通过使用一系列Elasticsearch聚合来提取和处理你的数据。你可以创建图标来显示你需要了解的趋势。 \r","date":"2018-04-15","objectID":"/elastic/:23:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"创建可视化 \r Elasticsearch文档 ","date":"2018-04-15","objectID":"/elastic/:23:1","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"入门 Elasticsearch是一个高度可扩展的开源全文搜索和分析引擎。它允许你快速、近乎实时地存储、搜索和分析大量数据。 Elasticsearch的几个例子： 使用Elasticsearch来存储产品目录和库存，并为其提供搜索和建议 收集日志或交易数据，并分析和挖掘数据以便于查找趋势、统计数据、汇总或异常信息 价格提醒平台，允许顾客制定规则，收到相应规则信息 分析智能需求，快速调查、分析、可视化并对大量数据提出特别的问题 \r","date":"2018-04-15","objectID":"/elastic/:24:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"基本概念 Near Realtime(NRT) Elasticsearch是一个近乎实时的搜索平台。这意味着从索引文档到可搜索之间存在轻微的延迟(通常为1s) Cluster 集群是一个或多个节点(服务器)的集合，它们一起保存所有数据，并提供跨节点的联合索引和搜索功能。集群由默认名为elasticsearch的唯一名称标识，它很重要。 确保不要在不同的环境中重复使用相同集群名称，否则可能会导致节点加入错误的集群。 集群可以只有一个节点！你也可以拥有多个独立的集群，每个集群有自己唯一的集群名称。 \rNode 节点是属于集群一部分的单个服务器，存储数据并参与集群的索引和索引。 与集群一样，一个节点由一个名称来标识，启动时随机分配的UUID。你也可以自定义节点名。 配置节点通过集群名称加入特定的集群，默认加入elasticsearch集群。 在单集群中，你可以拥有任意数量的节点。 Index 索引是一些具有相似特征的文档集合。例如，客户数据的索引，产品目录的索引，订单数据的索引…… 索引由名称标识(必须全小写)，文档执行索引、搜索、更新和删除操作时引用索引。 在一个单集群中，你可以定义任何你想要的索引。 \rDocument 文档是可被索引的基本信息单位。例如，单个客户的文档，单个产品的文档，单个订单的文档… 文档以JSON格式表示。 一条记录就是一个文档。 Shards和Replicas 索引可潜在地存储大量数据，这些数据可能会超多单个节点的硬件限制。例如，占用1TB磁盘空间的十亿文档的单个索引可能不适合单个节点的磁盘，或者可能太慢而无法单独向单个节点提供搜索请求。 为了解决这个问题，Elasticsearch提供了将索引细分为称为分片的多个碎片上。当你创建索引时，你可以简单定义所需的分片数量。 每个分片本身都是一个功能齐全且独立的索引，可以在集群中的任何节点上进行托管。 分片重要的两个原因： 允许你水平分割/缩放内容量 允许分布和并行操作跨分片，从而提高性能和吞吐量(throughput) 在任何时候都可能出现的网络环境中，强烈建议使用故障切换机制，以防止分片/节点因任何原因而消失。为此，Elasticsearch允许你将索引分片制作为一个或多个称为副本分片的副本集。 副本集分片永远不会分配到与原始分片相同的节点上。 副本集重要的原因： 在分片/节点失效的情况下提供高可用性 因为搜索可以在所有副本上并行执行，它允许你扩展搜索量和吞吐量 总而言之，每个索引都可以分成多个分片，索引也可以被复制。一旦复制，每个索引将具有主分片和副本分片。在创建索引时，可为每个索引定义分片和副本数量。在索引创建之后，你可以动态更改副本的数量，但无法更改分片的数量。 默认情况下，Elasticsearch中的每个索引都分配了5个主分片和副本。 每个Elasticsearch分片都是一个Lucene索引。单个Lucene索引有最大文档数量限制。 \r","date":"2018-04-15","objectID":"/elastic/:24:1","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"探索你的集群 The REST API REST(Representational State Transfer)表现层状态转换，是一种万维网软件架构风格，目的是便于不同程序在网络中互相传递信息。REST通常使用HTTP, URI, XML和HTML这些协议和标准。 启动节点，下一步便是理解如何与它通信。幸运的是，Elasticsearch提供了一个非常全面(comprehensive)和强大的REST API，可以使用它与集群进行交互。 使用API可以完成如下几件事： 检查集群、节点和索引的健康、状态和统计信息 管理集群、节点、索引数据和元数据 执行CRUD(create, read, update, delete) 执行高级搜索操作(分页、排序、过滤、脚本、聚合…) ","date":"2018-04-15","objectID":"/elastic/:25:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"集群健康 基本健康检查，看看集群正在做什么。 使用_catAPI检查集群健康。可使用Kibana Console或curl等工具。 #Kibana GET /_cat/health?v #cmd curl -X GET \"localhost:9200/_cat/health?v\" -u elastic epoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent 1525330981 15:03:01 docker-elk yellow 1 1 32 32 0 0 6 0 - 84.2% 集群健康： green: 万事OK(集群功能齐全) yellow: 所有数据可用，但一些副本尚未分配(集群功能齐全) red: 一些数据因某种原因不可用(集群部分功能) 集群名称： 集群名称被修改为docker-elk 列出集群中的节点： GET /_cat/nodes?v ip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name 127.0.0.1 47 74 93 3.18 3.13 2.90 mdi * LGrAIE5 随机节点名： LGrAIE5 \r","date":"2018-04-15","objectID":"/elastic/:25:1","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"列出所有索引 GET /_cat/indicies?v health status index uuid pri rep docs.count docs.deleted store.size pri.store.size green open .monitoring-kibana-6-2018.04.27 bsKsurh7TKaCsnekwHs3yg 1 0 870 0 328.1kb 328.1kb green open .watcher-history-7-2018.04.28 zuq3rjI8S0OSS7vcZl7kSQ 1 0 954 0 1.4mb 1.4mb green open .kibana 8t_7lqq4TFSfelA7phgv5g 1 0 142 18 191.8kb 191.8kb green open .monitoring-es-6-2018.04.28 vtUSjqaITT28CMHArpfNoA 1 0 20436 0 9.6mb 9.6mb yellow open filebeat-6.2.4-2018.05.03 sK3lIvMXS8GoRbWYCjdgzg 3 1 568 0 348.6kb 348.6kb \r","date":"2018-04-15","objectID":"/elastic/:25:2","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"创建索引 创建一个名为customer的索引，然后列出索引 #pretty漂亮JSON显示 PUT /customer?pretty #或 curl -X PUT \"localhost:9200/zhang\" -u elastic:elastic GET /_cat/indices?v #pri主分片，rep副本 health status index uuid pri rep docs.count docs.deleted store.size pri.store.size yellow open customer WQ3qEnPQRW6FpVIHYVJ7yA 5 1 0 0 1.1kb 1.1kb yellow open zhang nkOUPOWERsS1PT_wEui67g 5 1 0 0 1.1kb 1.1kb 你可能注意到了，索引的健康状态是yellow，表明有一些副本尚未分配。 这个索引发生这种情况的原因是Elasticsearch默认为这个索引创建了一个副本。由于此刻我们只有一个节点在运行，因此只有在其它几点加入集群后才能分配一个副本。一旦副本分配到另外的节点，健康状态会变成green。 \r","date":"2018-04-15","objectID":"/elastic/:25:3","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"索引和查询文档 现在让我们把一些东西放入customer索引中。讲一个简单的customer文档放入customer索引中，ID为1： PUT /customer/_doc/1?pretty { \"name\": \"John Doe\" } #或 curl -X PUT -u elastic:elastic \"localhost:9200/customer/_doc/1?pretty\" -H 'Content-Type: application/json' -d' { \"name\": \"John Doe\" }' { \"_index\" : \"customer\", \"_type\" : \"_doc\", \"_id\" : \"1\", \"_version\" : 1, \"result\" : \"created\", \"_shards\" : { \"total\" : 2, \"successful\" : 1, \"failed\" : 0 }, \"_seq_no\" : 0, \"_primary_term\" : 1 } GET /customer/_doc/1?pretty { \"_index\": \"customer\", \"_type\": \"_doc\", \"_id\": \"1\", \"_version\": 1, \"found\": true, \"_source\": { \"name\": \"John Doe\" } } #name:John Doe _id:1 _type:_doc _index:customer _score:1 \r","date":"2018-04-15","objectID":"/elastic/:25:4","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"删除索引 DELETE /customer?pretty curl -X DELETE \"localhost:9200/customer?pretty\" -u elastic:elastic { \"acknowledged\": true } \r","date":"2018-04-15","objectID":"/elastic/:25:5","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"修改数据 Elasticsearch几乎提示提供数据操作和搜索功能。从索引、更新、删除数据时可能会有1s延迟。数据在事物完成后立即可用。 索引/替换 文档 PUT /customer/_doc/1?pretty { \"name\": \"John Doe\" } #如果我修改此处文档信息，则Elasticsearch会替换之前的文档 PUT /customer/_doc/1?pretty { \"name\": \"Zhang\" } #name:Zhang _id:1 _type:_doc _index:customer _score:1 #或者新增一个文档 PUT /customer/_doc/2?pretty { \"name\": \"Zhang\" } #name:Zhang _id:2 _type:_doc _index:customer _score:1 未指定ID： ID是可选的。如果未指定ID，Elasticsearch会生成随机ID。 注意，此时使用POST方法。 POST /customer/_doc?pretty { \"name\": \"Zhang\" } #name:Zhang _id:76xJJWMBddhqcmsO07A_ _type:_doc _index:customer _score:1 \r","date":"2018-04-15","objectID":"/elastic/:26:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"更新文档 除了能够索引和替换文档，我们还可以更新文档。 Elasticsearch实际上并没有在原地就地更新，它是先删除旧文档，然后一次性更新索引新文档。 更新同样能够使用简单的脚本。 Elasticsearch提供了通过查询条件(类似于SQL-UPDATE-WHERE)更细多个文档的能力。 POST /customer/_doc/1/_update?pretty { \"doc\": { \"name\": \"Jane Doe\" } } #继续更新 POST /customer/_doc/1/_update?pretty { \"doc\": { \"name\": \"Jane Doe\", \"age\": 20} } #简单脚本 #ctx._source指即将更新的当前源文档 POST /customer/_doc/1/_update?pretty { \"script\": \"ctx._source.age += 5\" } \r","date":"2018-04-15","objectID":"/elastic/:26:1","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"删除文档 也可通过API匹配查询，删除所匹配的文档。 DELETE /customer/_doc/2?pretty \r","date":"2018-04-15","objectID":"/elastic/:26:2","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"批量处理 Elasticsearch同样提供了使用_bulkAPI批量执行上述任何操作的功能。这是一种高效的机制，尽可能快地完成多项操作。 Bulk API不会因其中一个操作失败而停止，它将继续处理后面的动作。当它完成是，它会返回每个操作的状态，以便你可以检查是否失败。 POST /customer/_doc/_bulk?pretty { \"index\": { \"_id\": \"1\" } } { \"name\": \"John Doe\" } { \"index\": { \"_id\": \"2\" } } { \"name\": \"Jane Doe\" } #更新 POST /customer/_doc/_bulk?pretty {\"update\": { \"_id\": \"1\" } } { \"doc\": { \"name\": \"John Doe becomes Jane Doe\" } } { \"delete\": { \"_id\": \"2\" } } \r","date":"2018-04-15","objectID":"/elastic/:26:3","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"探索你的数据 简单数据集 准备一个更加真实的数据集。如下生成的JSON文档，每个文档都有如下要点： { \"account_number\": 0, \"balance\": 16623, \"firstname\": \"Bradshaw\", \"lastname\": \"Mckenzie\", \"age\": 29, \"gender\": \"F\", \"address\": \"244 Columbus Place\", \"employer\": \"Euron\", \"email\": \"bradshawmckenzie@euron.com\", \"city\": \"Hobucken\", \"state\": \"CO\" } 载入这个数据集 下载Elasticsearch提供的accounts.json curl -H \"Content-Type: application/json\" -u elastic:elastic -XPOST \"localhost:9200/bank/_doc/_bulk?pretty\u0026refresh\" --data-binary \"@accounts.json\" curl \"localhost:9200/_cat/indices?v\" health status index uuid pri rep docs.count docs.deleted store.size pri.store.size yellow open bank PGSvNwQwQIOhMDr1nmXIuw 5 1 1000 0 474.7kb 474.7kb 这样我们成功批量索引了1000个文档到bank索引。 \r","date":"2018-04-15","objectID":"/elastic/:27:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"Search API 现在让我们做一些简单的搜索(search)。有两种基本搜索方式： REST request URI REST request body 以可读的JSON格式定义你的搜索，推荐方式 搜索的REST API可从_search端点访问: #在bank索引下的_search端点搜索 #匹配所有文档，并以账户字段顺序排列 #最后以可读的JSON格式输出结果 GET /bank/_search?q=*\u0026sort=account_number:asc\u0026pretty { \"took\" : 63, \"timed_out\" : false, \"_shards\" : { \"total\" : 5, \"successful\" : 5, \"skipped\" : 0, \"failed\" : 0 }, \"hits\" : { \"total\" : 1000, \"max_score\" : null, \"hits\" : [ { \"_index\" : \"bank\", \"_type\" : \"_doc\", \"_id\" : \"0\", \"sort\": [0], \"_score\" : null, \"_source\" : {\"account_number\":0,\"balance\":16623,\"firstname\":\"Bradshaw\",\"lastname\":\"Mckenzie\",\"age\":29,\"gender\":\"F\",\"address\":\"244 Columbus Place\",\"employer\":\"Euron\",\"email\":\"bradshawmckenzie@euron.com\",\"city\":\"Hobucken\",\"state\":\"CO\"} }, { \"_index\" : \"bank\", \"_type\" : \"_doc\", \"_id\" : \"1\", \"sort\": [1], \"_score\" : null, \"_source\" : {\"account_number\":1,\"balance\":39225,\"firstname\":\"Amber\",\"lastname\":\"Duke\",\"age\":32,\"gender\":\"M\",\"address\":\"880 Holmes Lane\",\"employer\":\"Pyrami\",\"email\":\"amberduke@pyrami.com\",\"city\":\"Brogan\",\"state\":\"IL\"} }, ... ] } } took: Elasticsearch执行搜索花费的事件(ms) timed_out: 查询超时与否 _shards: 搜索了多少分片，包含成功和失败的次数 hits: 搜索结果 hits.total: 匹配搜索的文档数 hits.hits: 搜索结果数组(默认前十个文档) hits.sort: 结果的排序键 hits._score, max_score: 忽略的字段 REST request body方法 GET /bank/_search { \"query\": { \"match_all\": {} }, \"sort\": [ { \"account_number\": \"asc\" } ] } \r","date":"2018-04-15","objectID":"/elastic/:27:1","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"查询语法 Elasticsearch提供了可用于执行查询的JSON格式语言，这被称为 Query DSL #上一个查询栗子 GET /bank/_search { \"query\": { \"match_all\": {} } } 处理query参数，我们还可以传递其它参数来搜索结果: #size参数，返回从from开始多少个文档 #from未指定，就默认为0 GET /bank/_search { \"query\": { \"match_all\": {} }, \"size\": 1 } #from参数，指定从哪个文档索引开始 GET /bank/_search { \"query\": { \"match_all\": {} }, \"from\": 10, \"size\": 10 } #sort参数 GET /bank/_search { \"query\": { \"match_all\": {} }, \"sort\": { \"balance\": { \"order\": \"desc\" } } } \r","date":"2018-04-15","objectID":"/elastic/:27:2","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"执行搜索 搜索某些字段： GET /bank/_search { \"query\": { \"match_all\": {} }, \"_source\": [\"account_number\", \"balance\"] } 匹配查询： GET /bank/_search { \"query\": { \"match\": { \"account_number\": 20 } } } GET /bank/_search { \"query\": { \"match\": { \"address\": \"mill\" } } } GET /bank/_search { \"query\": { \"match_phrase\": { \"address\": \"mill lane\" } } } 布尔查询： must should must_not #must GET /bank/_search { \"query\": { \"bool\": { \"must\": [ { \"match\": { \"address\": \"mill\" } }, { \"match\": { \"address\": \"lane\" } } ] } } } #should GET /bank/_search { \"query\": { \"bool\": { \"should\": [ { \"match\": { \"address\": \"mill\" } }, { \"match\": { \"address\": \"lane\" } } ] } } } #must_not GET /bank/_search { \"query\": { \"bool\": { \"must_not\": [ { \"match\": { \"address\": \"mill\" } }, { \"match\": { \"address\": \"lane\" } } ] } } } #组合使用must,must_not,should GET /bank/_search { \"query\": { \"bool\": { \"must\": [ { \"match\": { \"age\": \"40\" } } ], \"must_not\": [ { \"match\": { \"state\": \"ID\" } } ] } } } \r","date":"2018-04-15","objectID":"/elastic/:27:3","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"过滤 前面我们跳过了称为文档分数的_score字段。它是文档与搜索查询匹配度相度量的一个数值。数值越大，与文档越相关。 但查询并不总是需要产生分数，特别是当它们仅用于过滤时。Elasticsearch检测这些情况并自动优化查询执行，以便不计算无用的分数。 range query: 通过一系列值来过滤文档 GET /bank/_search { \"query\": { \"bool\": { \"must\": { \"match_all\": {} }, \"filter\": { \"range\": { \"balance\": { \"gte\": 20000, \"lte\": 30000 } } } } } } 除了前面这些查询类型，还有很多其它类型。由于只是入门章节，所以并不会涉及太多太难。 \r","date":"2018-04-15","objectID":"/elastic/:27:4","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"聚合 聚合(Aggregation)提供了从数据中分组和提取统计的功能。 考虑聚合最简单方法是将其大致等同于SQL GROUP BY和SQL聚合函数。 在Elasticsearch中，你可以执行返回匹配的搜索，同时还可以在一个响应中返回与匹配不同的聚合结果。你可以运行查询和多个聚合，并一次性获得多个操作的结果。 GET /bank/_search { \"size\": 0, \"aggs\": { \"group_by_state\": { \"terms\": { \"field\": \"state.keyword\" } } } } #类似的SQL SELECT state, COUNT(*) FROM bank GROUP BY state ORDER BY COUNT(*) DESC #group, average GET /bank/_search { \"size\": 0, \"aggs\": { \"group_by_state\": { \"terms\": { \"field\": \"state.keyword\" }, \"aggs\": { \"average_balance\": { \"avg\": { \"field\": \"balance\" } } } } } } GET /bank/_search { \"size\": 0, \"aggs\": { \"group_by_age\": { \"range\": { \"field\": \"age\", \"ranges\": [ { \"from\": 20, \"to\": 30 }, { \"from\": 30, \"to\": 40 }, { \"from\": 40, \"to\": 50 } ] }, \"aggs\": { \"group_by_gender\": { \"terms\": { \"field\": \"gender.keyword\" }, \"aggs\": { \"average_balance\": { \"avg\": { \"field\": \"balance\" } } } } } } } } 还有很多其它聚合方法，请参考https://www.elastic.co/guide/en/elasticsearch/reference/6.2/search-aggregations.html。 \r\r","date":"2018-04-15","objectID":"/elastic/:27:5","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"elasticsearch-py Python可使用elasticsearch-py模块来操作Elasticsearch，具体文档请查看Python这篇文章的elasticsearch第三方模块。 \r \rLucene查询 ElasticSearch提供的一些查询方式(query types)能够被Lucene的查询解析器(query parser)语法所支持。可直接在Kibana的发现面板上直接使用。 ","date":"2018-04-15","objectID":"/elastic/:28:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"全文搜索 string “string1 string2” Kibana会匹配和展示对应的string。 ","date":"2018-04-15","objectID":"/elastic/:29:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"键值对 key:value: 全文搜索 \"key:value\"： 精确搜索 _exists_:key: 返回结果中需要有key字段 _missing__:key: 不能含有key字段 如:http.code:502，log-levle:warn ","date":"2018-04-15","objectID":"/elastic/:30:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"通配符 ? * 这两者都不能用作第一个字符，如?.txt, *.txt ","date":"2018-04-15","objectID":"/elastic/:31:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"正则表达式 它也支持性能较差的正则表达式。 ","date":"2018-04-15","objectID":"/elastic/:32:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"模糊搜索 ~: 在一个单词后面加上~启用模糊搜索 ~n： 设置编辑距离(整数)，指定需要多少相似度，越大越接近原始值 在短语后面加~，可以搜索到被隔开或顺序不同的单词 first~也可以匹配到frist \"hello world\"~5表示两者之间可以隔着5个单词 ","date":"2018-04-15","objectID":"/elastic/:33:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"范围搜索 数值/时间/IP/字符串 类型的字段可以对某一范围进行查询 length:[100 TO 200] sip:[\"172.24.20.110\" TO \"172.24.20.140\"] date:{\"now-6h\" TO \"now\"} tag:{b TO e} 搜索b到e中间的字符 count:[10 TO *] * 表示一端不限制范围 count:[1 TO 5} [ ] 表示端点数值包含在范围内，{ } 表示端点数值不包含在范围内，可以混合使用，此语句为1到5，包括1，不包括5 可以简化成以下写法： age:\u003e10 age:\u003c=10 age:(\u003e=10 AND \u003c20) ","date":"2018-04-15","objectID":"/elastic/:34:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"优先级 使用^使一个词语比另一个搜索优先级更高，默认为1。可以为0~1之间的浮点数，来降低优先级 ","date":"2018-04-15","objectID":"/elastic/:35:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"逻辑操作 AND OR NOT +: 搜索结果中必须包含此项 -: 不能包含此项 (a OR b) AND c host:(baidu OR qq OR google) AND host:(com OR cn) ","date":"2018-04-15","objectID":"/elastic/:36:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"转义字符 \\：使用转义字符来转移特殊字符 \r \rMetricbeat Metricbeat是一个轻量级的托运器(lightweight shipper), 你可从安装该软件的操作系统和服务器上定期收集指标信息。它可将收集到的指标信息或统计信息发送到指定的输出(如elasticsearch/Logstash)。 具体使用方法也和Filebeat差不多！ Metricbeat通过从服务器上运行的系统和服务收集指标来帮助你监控服务器。如： Apache Docker Kafka Kubernets HAProxy MongoDB MySQL Nginx PHP-FPM PostgreSQL Redis RabbitMQ System Zookeeper … \r \rPacketbeat Packetbeat是一个实时网络数据包分析器，可与Elasticsearch一起提供应用程序监控和性能分析。 Packetbeat通过捕获应用服务器之间的网络流量，解码应用层协议(HTTP, MySQL, Redis…)，将请求与响应关联起来，并记录每个事务感兴趣的字段。 Packetbeat可以帮助你轻松地注意到后端应用程序的问题，例如错误或性能问题，并且可以更快地排除故障并进行修复。 Packetbeat捕获服务器之间的流量，即时分析应用层协议，并将这些消息关联到事务中。并将这些事务插入到Elasticsearch或使用Redis和Logstash的队列中。 Packetbeat支持的协议如下: ICMP DNS HTTP AMQP Cassandra MySQL PostgreSQL Redis MongoDB Thrift-RPC TLS \r \rHeartbeat Heartbeat是一个轻量级守护进程，用以定期检查服务的状态并确定它们是否可用。与Metricbeat不同，Metricbeat只会告诉你服务器是down/up，而Heartbeat会告诉你服务是否可以访问(reached)。 当你需要验证是否满足服务级别协议的服务正常运行时间时，Heartbeat非常有用。当需要验证外部没有人能访问企私有服务器上的服务时，这也很有用。 你可以配置Heartbeat来ping指定主机名的所有DNS可解析的IP地址。这样，你可以检查所有负载均衡的服务，看他们是否可用。 配置Heartbeat时，你可以指定用于表示要检查的主机名的监视器(monitor)。每台监视器都根据你指定的时间表运行。 Heartbeat目前支持通过通过如下方式监控主机： ICMP 当你指向检查服务是否可用时，请使用icmp监视器。此功能需要root权限 TCP 支持SSL/TLS/proxy 你可以选择配置此监视器，通过发送 and/or 接收自定义有效内容来验证端点 HTTP 支持SSL/TLS/proxy 你可以选择配置此监视器，来验证该服务是否会返回预期的响应。如特定状态码，响应header或内容 \r \rAuditbeat Auditbeat是一个轻量化的托运器(shipper)，在系统上安装它，以审核(audit)系统上用户和进程的活动。 例如，你可以使用Auditbeat从Linux Audit Framework收集和集中审计事件。你还可以使用它来检查关键文件的改动，并识别潜在的安全策略违规。 \r \rTopbeat 在v5.0, Topbeat被Metricbeat取代！ Topbeat的版本与其它Elastic Stack组件不同步，ES是v6.2.4， 而Topbeat是v1.3。所以需要额外安装repo. Topbeat是一个轻量化的托运器(shipper)，来定期读取系统和每个进程的CPU和内存统计信息，然后为Elasticsearch中的统计信息编制索引。 Topbeat通过收集如下指标来帮助你监控你的服务器: ystem-wide statistics system load 1, 5, 15 system wide CPU usage user, system, idle, IOWait system wide memory uusage total, used, free system wide swap usage total, used, free Per-process statistics process name process parent pid process state process pid process CPU usage process Memory usage File system statistics avaliable disks name, type, mounted total, used, free, available \r \rAPM APM(Application Performance Monitoring)应用程序性能监控，自动收集应用程序内部的深入性能指标和错误。 它由三个组件组成: Agents Node.js Django Flask Ruby on Rails Rack JS Server UI \r \rElastAlert GitHub: https://github.com/Yelp/elastalert Docs: https://elastalert.readthedocs.io ElastAlert是一个简单灵活的用于Elasticsearch中数据异常的告警框架。它使用Python2.x编写，不支持Python3。 ElastAlert功能与Watcher类似，只不过Watcher是Elastic Enterprise中才支持，而ElastAlert是一个开源软件。 Kibana非常适合可视化和查询数据，但它需要一个配套工具来对数据进行告警，出于这种需要，ElastAlert诞生了。 如果你几乎实时地将数据写入Elasticsearch，并希望在数据与某些模式匹配时收到告警，则ElastAlert就是适合你的工具。 \r\r","date":"2018-04-15","objectID":"/elastic/:37:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"综述 ElastAlert被设计为可靠、高度模块化、易于设置和配置。 它使用两种类型的组件与Elasticsearch进行结合： rule type alerts 定期检查Elasticsearch并将数据传递给规则类型，它确定了何时找到匹配项。当匹配发生时，它触发一个或多个报警，而这些报警便采取具体行动。 每组规则定义了一个查询、一个规则类型和一组警报。 ElasAlert几种通用规则类型： frequency Match where there are X events in Y time spike Match when the rate of events increases or decreases flatline Match when there are less than X events in Y time blacklist/whitelist Match when a certain field matches a blacklist/whitelist any Match on any event matching a given filter change Match when a field has two different values within some time ElasAlert几种内建报警类型： Command Email JIRA OpsGenie SNS HipChat Slack Telegram Debug Stomp 你也可以导入和编写规则类型和报警类型。 除了这些基础用法外，还有许多其它功能: Alerts link to Kibana dashboards Aggregate counts for arbitrary fields Combine alerts into periodic reports Separate alerts by using a unique key field Intercept and enhance match data \r\r","date":"2018-04-15","objectID":"/elastic/:38:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"可靠性 Reliability ElasAlert有多种功能，可在restart或Elasticsearch不可用时使其更可靠: ElastAlert将其状态保存到Elasticsearch，并在启动时先恢复先前停止的状态 如果Elasticsearch没有响应，ElastAlert将等待它恢复，然后再继续 抛出错误的警报可能会在一段时间内自动重试 \r\r","date":"2018-04-15","objectID":"/elastic/:39:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"模块性 Modularity ElastAlert有3个主要组件，可作为模块导入或自定义。 rule types 规则类型负责处理从Elasticsearch返回的数据。 alerts 警报负责根据匹配采取行动。 enhancements 增强功能是一种拦截警报并以某种方式修改或增强警报的方法。 \r\r","date":"2018-04-15","objectID":"/elastic/:40:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"配置 ","date":"2018-04-15","objectID":"/elastic/:41:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"配置项 ElastAlert有一个全局配置文件config.yaml，它定义了几个操作方面: #ElastAlert将持续查询熊当前到buffer_time前的窗口 buffer_time #ES es_host es_port #可选 es_username es_password #URL prefix for the Elasticsearch endpoint es_url_prefix #Method for querying Elasticsearch，默认GET es_send_get_body_as #默认20 es_conn_timeout #可选配置 use_ssl verify_certs client_cert client_key ca_certs #规则配置文件目录 rules_folder #递归，默认true scan_subdirectories #查询频率，如 minutes: 5 run_every #elastalert将存储数据的索引名称 writeback_index #报警失败的重试窗口 alert_time_limit #单个查询中从es下载的最大文档数，默认10 000 max_query_size scroll_keepalive #聚合在一起的最大警报数，默认10 000 max_aggregation #ElastAlert从最近开始运行的查询开始的最长时间 old_query_limit #当抛出未知异常时，禁用rule。 默认true disable_rules_on_error #Email #接收通知的邮件 nottify_email #默认值ElastAlert from_addr smpt_host email_reply_to #Amazon Elasticsearch Service aws_region boto_profile profile #在将文档写入Elasticsearch前，ElastAlert使用下划线替换字段名中的任意一个点(.)。默认值False replace_dots_in_field_names #es中用于字符串多字段的子字段的后缀 string_multi_field_name \r\r","date":"2018-04-15","objectID":"/elastic/:41:1","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"运行ElastAlert 运行： python elastalert/elastalert.py 一些参数： --config --debug --verbose --start --end --rule --slience --es_debug --es_debug_trace --pin_rules \r\r","date":"2018-04-15","objectID":"/elastic/:42:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"首次运行ElastAlert Running ElastAlert for the First Time \r","date":"2018-04-15","objectID":"/elastic/:43:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"依赖 Requirements: es ISO8601 or Unxi timestamped data Python 2.7 python2-pip python-dev libffi-dev libssl-dev \r","date":"2018-04-15","objectID":"/elastic/:43:1","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"安装 #依赖 yum install python2-pip python-dev #setuptools \u003e= 11.3 pip2 install --upgrade setuptools #elasticsearch \u003e= 5.0 pip2 install elasticsearch pip2 install elastalert #or #git clone https://github.com/Yelp/elastalert.git #cd elastalert #python2 setup.py install 之后修改配置文件，我将ElastAlert目录移动到了/etc/下。 修改配置文件，并将ElastAlert的config.yaml.example配置保存为config.yaml。 \r","date":"2018-04-15","objectID":"/elastic/:43:2","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"设置es Setting Up Elasticsearch ElastAlert将有关其查询及报警的信息和元数据报错到Elasticsearch。这虽然不是必须的，但却强烈建议使用。 #创建一个用于ElastAlert写入的index elastalert-create-index #会有es主机，端口，用户，密码和索引相关信息 Enter Elasticsearch host: zhang21 Enter Elasticsearch port: 9200 Use SSL? t/f: f Enter optional basic-auth username (or leave blank): Enter optional basic-auth password (or leave blank): Enter optional Elasticsearch URL prefix (prepends a string to the URL of every request): New index name? (Default elastalert_status) Name of existing index to copy? (Default None) Elastic Version:6 Mapping used for string:{'type': 'keyword'} New index elastalert_status created Done! \r\r","date":"2018-04-15","objectID":"/elastic/:43:3","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"创建一个规则 Creating a Rule 每个规则定义要执行的查询，触发匹配的参数以及每个匹配要触发的报警列表。 cat ./example_rules/example_frequency.yaml es_host: elasticsearch.example.com es_port: 14900 #唯一的规则名 name: Example rule #规则类型 type: frequency #要查询的索引 index: logstash-* #触发报警的阈值 num_events: 50 #阈值的时间区间 timeframe: hours: 4 #过滤列表 filter: - term: some_field: \"some_value\" #报警列表 alert: - \"email\" #报警地址列表 email: - \"elastalert@example.com\" 栗子 elastalert: vim /etc/elastalert/example_rules/example_frequency.yaml es_host: \"192.168.1.11\" es_port: 9200 name: \"test rule\" type: \"frequency\" #此处我用python新建一个索引，用于测试 index: \"my-index\" num_events: 3 timeframe: hours: 1 filter: - query_string: query: \"log_level: ERROR\" #- term: # name: \"zhang21\" alert: - \"email\" email: - \"elastalert@example.com\" \r\r","date":"2018-04-15","objectID":"/elastic/:43:4","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"测试规则 运行elasticalert-test-rule工具将测试你的配置文件是否成功加载并在过去24h内以调试模式运行： elastalert-test-rule ./example_frequency.yaml 配置首选项将按如下方式加载： yaml文件中指定的配置 配置文件中指定的配置 默认配置 \r\r","date":"2018-04-15","objectID":"/elastic/:43:5","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"运行ElastAlert 有两种方式来调用ElastAlert： Supervisor Python 为了便于调试，下面将直接调用。 python2 -m elastalert.elastalert --verbose --rule /etc/elastalert/example_rules/example_frequency.yaml INFO:elastalert:Starting up #这里遇到一个错误 ERROR:root:Error running query: TransportError(400, u'search_phase_execution_exception', u'No mapping found for [@timestamp] in order to sort on') #解决方法，在规则文件example_frequency.yaml中添加 timestamp_field: timestamp 使用Python3创建索引： from datetime import datetime from elasticsearch import Elasticsearch es=Elasticsearch('http://192.168.1.11:9200') es.info() #写入文档 data = { # 由于ES接收UTC时间，因此需要使用UTC事件，不然会给我+8(CST) # 'timestamp': datetime.now(), 'timestamp': datetime.utcnow(), 'name': 'zhang21' } for i in range(1, 21): es.index(index='my-index', doc_type='test-type', id=i, body=data) \r\r","date":"2018-04-15","objectID":"/elastic/:43:6","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"规则类型和配置项 Rule Types and Configuration Options \r","date":"2018-04-15","objectID":"/elastic/:44:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"规则配置项 Rule Configuration Cheat Sheet 选项太多，自己去看: https://elastalert.readthedocs.io/en/latest/ruletypes.html \r","date":"2018-04-15","objectID":"/elastic/:44:1","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"通用配置项 每个在rules_folder下的.yaml文件默认都会被执行。 必须的配置 es_host es_port index name type alert 可选配置 自己去看。 \r\r","date":"2018-04-15","objectID":"/elastic/:44:2","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"规则类型 Rule Types 在elastalert/ruletypes.py中定义的各种RuleType class构成了ElastAlert的主要逻辑。每个规则都在内存中保存一个实例，传递通过给定过滤器查询es返回的所有数据，并根据该数据生成匹配。 any 任意规则都将匹配所有内容。查询返回的每个匹配都会生成一个警报。 blacklist 黑名单规则根据黑名单检查某个字段，如果它存在于黑名单中，则匹配。 黑名单规则需要两个额外项： compare_key——与黑名单进行比较的字段。如果为空，事件将被忽略。 blacklist——黑名单列表值或黑名单文件列表(\"!file ./blacklist.txt\") 栗子： blacklist: - value1 - value2 - \"!file /tmp/blacklist1.txt\" whitelist 白名单规则根据白名单检查某个字段，如果列表中不包含此字段，则匹配。 白名单规则需要三个额外项： compare_key——与白名单进行比较的字段 ignore_null——如果为true，则没有compare_key字段的事件将不匹配 whitelist——白名单列表值或白名单文件列表 栗子: whitelist: - value1 - value2 - \"!file /tmp/whitelist1.txt\" - \"!file /tmp/whitelist2.txt\" change 此规则将监视某个字段，如果此字段改变就匹配。 此规则需要三个额外项： compare_key——监控要改变的字段名。可以是一个列表，如果任意字段发生标号，都将触发警报。 ignore_null——如果为true，则没有compare_key字段的事件将不计为已更改。 query_key——此规则基于每个查询键应用。 一个可选字段： timeframe——改变之间的最大时间 frequency 此规则匹配在给定时间范围内至少一定数量的事件。 此规则需要两个额外项： num_events——将会触发报警的事件数 timeframe——上面事件的时间范围 spike(突增) 当给定时间段内的事件量的spike_height次数大于或小于前一个时间段时，此规则匹配。它使用两个滑动窗口(引用和当前)来比较。 此规则需要三个额外项： spike_height——上次时间段时间数与前时间段事件数的比率，将处罚告警 spike_type——up/down/both timeframe：时间段 flatline(脉波) 当一段时间内事件总数匹配给定阈值时，此规则匹配。 此规则需要两个额外项： threshold——不触发警报的最小事件数 timeframe——时间段 new term(术语) 当一个以前从未见过的新值出现在字段中时，此规则匹配。 此规则需要一个额外项： fields——要监控的新术语的字段列表 cardinality(基数) 在一个时间范围内，当某个字段的唯一值的总数高于或低于阈值时，此规则匹配。 此规则需要： timeframe——时间段 cardinality_field——计算基数的字段 最大或最小基数取一个 max_cardinality——数据的基数大于此报警 min_cardinality——数据基数小于此报警 metric aggregation 当计算窗口中的度量值高于或低于阈值时，此规则匹配。默认值为buffer_time。 此规则需要： metric_agg_key——计算度量标准的字段 metric_agg_type——字段的类型 doc_type——指定要搜索的文档类型 最大和最小至少需要一个 max_threshold——计算的度量标准大与此，报警 min_threshold——计算的度量标准小于此，报警 percentage match 当计算窗口内匹配桶(bucket)中的文档百分比高于或低于阈值时，此规则匹配。默认情况下，计算窗口为buffer_time。 此规则需要： match_bucket_filter—— ES filter DSL。为匹配桶定义了一个过滤器，它应用匹配查询过滤器并返回文档的子集。 doc_type——指定查询文档类型 最大和最小至少需要一个 min_percentage——匹配文档的百分比小于此，报警 max_percentage——匹配文档的百分比大于此，报警 \r\r","date":"2018-04-15","objectID":"/elastic/:44:3","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"Alerts 每条规则都可以附加任意数量的报警。Alerts是Alerter的子类，并从ElastAlert传递包含相关信息的字典或字典列表。与规则配置类似，它们在规则配置文件中配置。 alert: - email - jira - xxx 多个邮件： alert: - email from_addr: \"no-reply@example.com\" email: \"someone@example.com\" alert: - email: from_addr: \"no-reply@example.com\" email: \"someone@example.com\" - email: from_addr: \"xx\" email: \"xxx\" \r\rAlert Subject 可通过添加包含自定义摘要的alert_subject来自定义电子邮件主题。 alert_subject: \"Issue {0} ouccurreda at {1}\" alert_subject_args: - issue.name - \"@timestamp\" 如果规则匹配索引中的多个对象，则仅使用第一个匹配来填充格式化程序的参数。 \r\rAlert Content 有几种方法可以格式化给种类型事件的正文： rule_name = name alert_text = alert_text ruletype_text = Depends on type top_counts_header = top_count_key, \":\" top_counts_value = Value, \": \", Count top_counts = top_counts_header, LF, top_counts_value field_values = Field, \": \", Value 默认： body = rule_name [alert_text] ruletype_text {top_counts} {field_values} \r\rcommand 命令报警允许你执行任意命令并从匹配中传递参数或stdin。该命令的参数可以使用Python格式的字符串语法来访问匹配的部分内容。报警器将打开一个子进程并可选地传递匹配，或在聚合报警的情况下，将其作为json阿虎组匹配到进程的stdin。 此报警需要一个选项： command——要执行的参数列表或要执行的字符串。如果是列表格式，则第一个参数是要执行的程序名。如果传递了一个字符串，则该命令通过shell执行。 字符串可使用%或.format()进行格式化。这是Python的替换。 如果在命令中使用格式化数据，清泪建议使用args列表格式而不是shell字符串。 alert: - command command: [\"/bin/send_alert\", \"--username\", \"%(username)s\"] #command: [\"/bin/send_alert\", \"--username\", \"{match[username]}\"] \r\rEmail 此报警将会发送电子邮件。它默认连接到smtp_host服务器。 它需要一个选项： email——接收报警的地址 \r\rJira \r\rDebug 调试报警器经使用Python logger的info level记录报警信息。它被记录到名为elastalert的Python logger对象中，可以使用getLogger命令轻松访问该对象。 \r\rHTTP POST 此报警类型使用HTTP POST将结果发送到JSON ENDPOINT。默认情况下，json会包含所有匹配，除非你指定http_post_payload。 需要： http_post_url alert: post http_post_url: \"http://example.com/api\" http_post_payload: ip: clientip http_post_static_payload: apikey: abc123 \r\r","date":"2018-04-15","objectID":"/elastic/:44:4","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"ElastAlert元数据索引 ElastAlert Metadata Index ElastAlert使用Elasticsearch存储有关其状态的各种信息。这不仅允许对ElastAlert操作进行某种程度的审计和调试，而且还可以在ElastAlert关闭、重启或崩溃时避免数据丢失或重复报警。此集群和索引信息在全局配置文件中使用es_host, es_port, writeback_index定义。ElastAlert必须能够写入到此索引。elastalert-create-index将为你创建具有正确映射的索引，并可选择从现有的ElastAlert写回索引中复制文档。 ElastAlert将会在writeback index中创建三种不同类型的文档： elastalert_status elastalert elastalert_error \r\r","date":"2018-04-15","objectID":"/elastic/:45:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"elastalert_status elastalert_status是为给定规则执行查询的日志，包含： @timestamp rule_name starttime endtime hits： 查询的结果数 matches： 匹配数 time_taken： 查询所用秒数 \r\r","date":"2018-04-15","objectID":"/elastic/:45:1","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"elastalert elastalert是有关触发的每个报警的日志信息，包含： @timestamp rule_name alert_info alert_sent alert_time match_body alert_exception aggregate_id \r\r","date":"2018-04-15","objectID":"/elastic/:45:2","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"elastalert_error 当ElastAlert发生错误时，它将写入Elasticsearch和stderr。elastalert_error类型包含： @timestamp message traceback data \r\r","date":"2018-04-15","objectID":"/elastic/:45:3","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"silence silence是指由于重新设置或使用-silence而抑制给定规则的警报的记录。 @timestamp rule_name until：警报在此开始发送的时间戳 exponent：除非设置了exponential_realert，否则它将为0 \r\r","date":"2018-04-15","objectID":"/elastic/:45:4","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"添加一个新规则类型 Adding a New Rule Type \r\r","date":"2018-04-15","objectID":"/elastic/:46:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"添加一个新报警器 Adding a New Alerter \r\r \r","date":"2018-04-15","objectID":"/elastic/:47:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"为规则编写过滤器 Writing Filters For Rules \r\r","date":"2018-04-15","objectID":"/elastic/:48:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"增强功能 Enhancements 增强功能是一些模板，可让你在发送警报之前修改匹配项。 \r\r\r","date":"2018-04-15","objectID":"/elastic/:49:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"在容器内运行 构建基础镜像: # Docker-base FROM ubuntu:latest RUN apt-get update \u0026\u0026 apt-get upgrade -y \u0026\u0026 \\ apt-get -y install build-essential python-setuptools python2.7 python2.7-dev libssl-dev git tox python-pip vim \u0026\u0026 \\ pip install elastalert -i https://mirrors.aliyun.com/pypi/simple/ 以后只需将配置文件导入基础镜像就好: # Dockerfile FROM zhang21/base-elastalert:latest # config.yaml # rules/ # smtp_auth_file.yaml COPY . /opt/elastalert/ WORKDIR /opt/elastalert CMD [\"sh\", \"-c\", \"python -m elastalert.elastalert --verbose\"] \r\r","date":"2018-04-15","objectID":"/elastic/:50:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["middleware"],"content":"kibana-plugin elastalert kibana-plugin是一个第三方插件。 ElastAlert Kibana plugin repository: https://github.com/bitsensor/elastalert-kibana-plugin 注意，安装的时候要注意kibana的版本。具体信息见README。 ","date":"2018-04-15","objectID":"/elastic/:51:0","tags":["Elasticsearch","Logstash","Kibana","Filebeat","Metricbeat","Heartbeat","Packetbeat","Auditbeat"],"title":"Elatic Stack","uri":"/elastic/"},{"categories":["linux"],"content":"参考： http://www.supervisord.org 环境： Supervisor 3.3.4 CentOS7.x86_64 \r \r介绍 ","date":"2018-04-08","objectID":"/supervisor/:0:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"综述 Supervisor是一个C/S系统，允许用户在Unix-Like操作系统上控制许多进程。它受如下启发： Convenience Accuracy Delegation Process Group \r","date":"2018-04-08","objectID":"/supervisor/:1:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"特点 Simple Centralized(统一) Efficient Extensible Compatible Proven(久经考验) \r","date":"2018-04-08","objectID":"/supervisor/:2:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"Supervisor组件 supervisord Supervisor的服务器部分被命名为supervisord。负责启动子进程，响应客户端的子进程，重启奔溃或退出的子进程，记录其stderr和stdout，以及生成对应的事件 默认使用的配置文件为/etc/supervisord.conf——Windows-INI格式的文件，由于它包含了未加密的username和password，请保证它安全 supervisorctl Supervisor的客户端部分被命名为supervisorctl。用户可连接到不同的supervisord，status/stop/start子进程，获取supervisord中正在运行的进程列表 通过Unix domain socket或TCP socket与server通信，客户端在执行命令前应该先提供认证。客户端和服务端使用同一个配置文件 Web server Web界面，可通过它查看或控制进程状态 XML-RPC接口 用于询问和控制管理程序及其运行的程序 \r","date":"2018-04-08","objectID":"/supervisor/:3:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"平台要求 在Unix-Like系统上运行良好 不支持Windows系统 Supervisor运行在Python2.4或之后的版本，不支持Python3 \r 安装 安装方法取决于你的操作系统。 ","date":"2018-04-08","objectID":"/supervisor/:4:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"通过网络安装 推荐使用setuptools的easy_install 下载Supervisor包并调用一个命令 ","date":"2018-04-08","objectID":"/supervisor/:5:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"使用Setuptools的网络安装 如果Python解释器安装了Setuptools: easy_install supervisor ","date":"2018-04-08","objectID":"/supervisor/:5:1","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"不使用Setuptools的网络安装 如果系统上未安装Setuptools，那么你需要手动去下载Supervisor发行套件和安装它。 PYPI： https://pypi.python.org/pypi/supervisor wget https://pypi.python.org/pypi/supervisor/xxx.tar.gz tar -xzf xxx.tar.gz python setup.py install #它会自动通过网络下载依赖 \r","date":"2018-04-08","objectID":"/supervisor/:6:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"安装一个分发包 一些Linux发行版提供了可通过系统包管理工具安装Supervisor。这些包由第三方制作，包含了对特定发行版的一些修改。 yum info supervisor yum search supervisor yum install -y supervisor \r","date":"2018-04-08","objectID":"/supervisor/:7:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"通过pip安装 pip install supervisor \r","date":"2018-04-08","objectID":"/supervisor/:8:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"创建一个配置文件 由于我是通过yum安装，所以supervisor配置文件自动在/etc下自动生成： 默认配置文件： /etc/supervisord.conf 建议在此配置文件中加入[include]，默认已包含此配置 目录： /etc/supervisord.d 建议将每个配置单独写在此目录下 \r 运行Supervisor ","date":"2018-04-08","objectID":"/supervisor/:9:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"添加一个程序 在supervisord为你做任何有用的事情之前，你至少需要在配置文件中添加一个程序部分。program部分将定义在调用supervisord命令时如何运行和管理一个程序。 一个最简单的栗子： [program:foo] command=/bin/cat 上面的栗子只命名了一个命令，还有很多其它关于程序部分的设置。 \r","date":"2018-04-08","objectID":"/supervisor/:10:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"运行supervisord 使用supervisord命令启动supervisord，进程将自我守护，并从终端分离。并将操作日志默认放于$CWD/supervisor.log。 你可传递-n/--nodaemon标志来将进程放置于前台，这样对于debug很有帮助。 要更改supervisord控制的程序集，请编辑配置文件并kill- HUP，或以其它方式重新启动supervisord进程。 supervisord命令接受许多命令行选项。这些命令行选项中的每一个都会覆盖配置文件中的任何等效值。 详细选项： http://www.supervisord.org/running.html#supervisord-command-line-options \r","date":"2018-04-08","objectID":"/supervisor/:11:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"运行supervisorctl 使用supervisorclt命令启动supervisorctl客户端。如果需要验证supervisord调用，则系统会要求您提供验证凭据。 supervisorctl status all supervisorctl stop all ","date":"2018-04-08","objectID":"/supervisor/:12:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"supervisorctl Actions 如果在命令行中指定了-i或未指定任何操作(action)，则将启动交互式输入的shell解释操作。 supervisorctl help #查看可操作的action default commands (type help \u003ctopic\u003e): ===================================== add clear fg open quit remove restart start stop update avail exit maintail pid reload reread shutdown status tail version \r","date":"2018-04-08","objectID":"/supervisor/:12:1","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"Signals supervisord程序可能会发送某些actions，让它在运行时执行某些操作。你可将这些信号发送到一个单一的supervisord的PID。 ","date":"2018-04-08","objectID":"/supervisor/:13:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"信号处理程序 SIGTERM supervisord及其所有子进程都将关闭 SIGINT supervisord及其所有子进程都将关闭 SIGQUIT supervisord及其所有子进程都将关闭 SIGHUP supervisord将关闭所有进程，重新载入配置文件并启动所有进程 SIGUSR2 supervisord将关闭并重新打开主要活动日志和所有子日志文件 \r","date":"2018-04-08","objectID":"/supervisor/:13:1","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"运行安全 开发人员尽力确保以root身份运行的supervisord进程不会导致意外的权限升级。但supervisord允许在其配置文件中的任意路径规范写入数据，允许任意路径选择可能会造成符号链接工具的漏洞。 确保supervisord配置文件的权限安全，除此之外，确保Python PATH和标准库都有足够的文件权限保护。 \r","date":"2018-04-08","objectID":"/supervisor/:14:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"开机自启 由于我是yum安装，所以能够直接使用系统服务管理来设置开机自启。 \r 配置文件 Supervisor的配置文件通常命名为supervisord.conf。如果没有指定-c配置文件，应用程序会从以下位置去寻找配置文件： $CWD/supervisord.conf $CWD/etc/supervisord.conf /etc/supervisord.conf /etc/supervisor/supervisord.conf (since Supervisor 3.3.0) ../etc/supervisord.conf (Relative to the executable) ../supervisord.conf (Relative to the executable) \r","date":"2018-04-08","objectID":"/supervisor/:15:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"文件格式 supervisord.conf is a Windows-INI-style (Python ConfigParser) file. 它包含section（[header]）和section中的key/value对。 ","date":"2018-04-08","objectID":"/supervisor/:16:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"环境变量 使用Python字符串表达式语法%(ENV_X)%，可以在配置文件中使用环境中存在的环境变量 [program:example] command=/usr/bin/example --loglevel=%(ENV_LOGLEVEL)s \r","date":"2018-04-08","objectID":"/supervisor/:16:1","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"[unix_http_server] 在此section中应该插入在Unix domain socket上监听的HTTP server的配置参数。 如果没有配置此section，则Unix domain socket HTTP server将不会启动。 [unix_http_server] #supervisor监听HTTP/XML-RPC请求的Unix domain socket的路径 file #socket文件的权限模式 chmod #socket的用户和组 chown #访问HTTP server需要的认证 username #密码可以是明文，或使用SHA加密的字符串 password \r","date":"2018-04-08","objectID":"/supervisor/:17:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"[inet_http_server] 监听TCP(internet) socket 的HTTP server的配置参数。 如果此section未配置，inet HTTP server将不会启动。 #tcp host:port，supervisor监听HTTP/XML-RPC请求的地址 port #HTTP server认证 username #密码可以是明文，或SHA加密 passwd \r","date":"2018-04-08","objectID":"/supervisor/:18:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"[supervisord] 与supervisord进程有关的全局设置。 logfile logfile_maxbytes logfile_backps #critical, error, warn, info, debug, trace logevel pidfile umask nodaemon minfds minprocs #防止supervisord在启动时清除任何现有子日志文件 nocleanup childlogdir user directory strip_ansi enviroment identifier \r","date":"2018-04-08","objectID":"/supervisor/:19:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"[supervisorctl] supervisorctl交互式shell程序。 serverurl #与前面设置的验证账户一致 username password prompt history_file \r","date":"2018-04-08","objectID":"/supervisor/:20:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"[program:x] supervisord知道的应该启动和控制的程序。 #该程序启动时将运行的命令 command #进程名称 process_name #多个实例 numproc #用于计算numprocs开始的数量 numprocs_start #程序在启动和关闭顺序中的相对优先级 priority #当supervisord启动时，改程序将自动启动 autostart #程序在启动后需要保持运行以考虑启动成功的总秒数，设置为0表示不需要再任何特定的事件内保持运行 startsecs #允许失败的尝试次数，然后放弃并将进程置入fatal状态 startretries #自动重启进程 autorestart #异常退出码 exitcodes #请求停止时用于杀死程序的信号 stopsignal #发送停止信号后，等待系统将信号返回给supervisord的秒数 stopwaitsecs #将停止信号发送给整个进程组 stopagroup # killasgroup #以哪个用户运行该程序 user redirect_stderr stdout_logfile stdout_logfile_maxbytes stdout_logfile_backups stdout_capture_maxbytes stdout_events_enabled stderr_logfile stderr_logfile_maxbytes stderr_logfile_backups stderr_capture_maxbytes stderr_events_enabled environment directory umask serverurl \r","date":"2018-04-08","objectID":"/supervisor/:21:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"[include] 如果配置文件包含[include]部分，则它必须包含一个名为files的key。该key中的值包含了其它配置文件。 #文件空间的空格分隔序列，路径可以是相对或绝对。 files \r","date":"2018-04-08","objectID":"/supervisor/:22:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"[group:x] 将同质进程组组合成一个异质进程组通常很有用，所以它们可以作为supervisor各种控制器接口的一个单元进行控制。 #程序的逗号分隔列表 programs #优先级 priority \r","date":"2018-04-08","objectID":"/supervisor/:23:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"[fcgi-program:x] #程序的fastCGI socket或TCP或Unix domain socket socket #为socket指定特定user或group socket_owner #指定permission模式 socket_mode \r","date":"2018-04-08","objectID":"/supervisor/:24:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"[eventlistener:x] supervisor允许在配置文件中定义专门的同质进程组(event listener pools)。 buffer_size events result_handler \r","date":"2018-04-08","objectID":"/supervisor/:25:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["linux"],"content":"[rpcinterface:x] [rpcinterface:x]适用于希望通过自定义行为扩展supervisor的人们。 ","date":"2018-04-08","objectID":"/supervisor/:26:0","tags":["supervisor"],"title":"Supervisor","uri":"/supervisor/"},{"categories":["middleware"],"content":"参考： https://www.consul.io/intro/index.html https://www.consul.io/docs/ Consul Template: https://www.hashicorp.com/blog/introducing-consul-template 环境： CentOS7x86_64 Consul v1.2.0 \r \r简介 介绍consul是什么，它可以解决哪些问题，以及如何开始使用它。 ","date":"2018-04-05","objectID":"/consul/:0:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"Consul是什么 Consule有多个组件，但总体而言，它是发现(discovery)和配置(config)基础架构(infrastructure)服务的工具。它提供几个关键特点： 服务发现(service discovery) Consul客户端可提供一个服务，如API或mysql，其它客户端能够使用Consul来发现给定服务的提供者。使用DNS或HTTP，应用程序可以轻松找到他们所依赖的服务 健康检查(health checking) Consul可以提供任何数量的健康检查，既可以与给定服务相关联(webserver return 200)，也可与本地节点(内存使用率小于90%)相关联。操作人员可用此信息来监视集群运行状况，服务发现组件使用此信息将流量(traffic)从不健康的主机中引导出去 KV store 应用程序可将Consul的分层Key/Value用于存储任何目的，包括动态配置(dynamic configuration)、功能标记(feature flagging)、协调(coordination)、领导选举(leader election)…简单的HTTP API使其易于使用 多数据中心(Multi Datacenter) Consul支持多数据中心，这意味着Consul的用户不必担心构建额外的抽象层以扩展到多个区域 Consul旨在与DevOps和应用程序开发者保持友好，使其成为现代化 ，弹性基础架构的完美选择。 \r\r","date":"2018-04-05","objectID":"/consul/:1:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"Consul用例 服务发现(service ) 服务注册，集成健康检查，使用DNS或HTTP接口使得任何服务都能被其它服务发现。 服务分割(service segmentation) 通过自动TLS加密和基于身份的授权实现安全的服务到服务通信。 服务配置(service configuration) 功能丰富的 key/value 可轻易配置服务。 \r","date":"2018-04-05","objectID":"/consul/:2:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"Consul基础架构 Consul是一个分布式、高可用的系统。 每一个向Consul提供服务的节点都运行一个Consul agent。运行agent对于服务发现或get/set Key/Value不是必需的。agent负责健康检查节点上的服务和节点自身。 agent可与一个或多个Consul server交流。Consul server是数据存储和复制集所在之地。server之间选出一个leader。虽然Consul可以使用一台服务器，但推荐使用3-5台以避免数据丢失的故障情况。对每一个数据中心都推荐使用Consul server cluster。 需要发现其它服务或节点的基础架构组件 可以查询任何Consul server或Consul agent。agent自动将查询发送到server。 每个数据中心运行一组consul server cluster。当发生cross-datacenter服务发现或配置请求时，本地consul server将请求转发给远程数据中心并返回结果。 \r 快速开始 ","date":"2018-04-05","objectID":"/consul/:3:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"安装Consul 二进制包: https://www.consul.io/downloads.html 解压缩，得到一个consul二进制可执行文件，可将其放入系统路径 验证安装: consul \r","date":"2018-04-05","objectID":"/consul/:4:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"运行consul-agent 安装consul后请务必运行agent，agent可运行在server或client模式。每个datacenter必须至少有一台server，推荐3-5台做一个集群。单一server部署非常不安全，在故障情况下数据丢失就不可避免了。 所有其它agents都以client模式运行。client是一个非常轻量化的进程——它注册服务、运行健康检查、转发查询给server。agent必须运行在集群的每个节点上。 \r","date":"2018-04-05","objectID":"/consul/:5:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"启动agent 测试consul development模式，不建议在生产环境使用此方法，此处做测试。 consul agent -dev netstat -nltp #可根据日志看出agent已成为server，并成为集群leader \r","date":"2018-04-05","objectID":"/consul/:5:1","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"Consul成员 members命令基于gossip protocol并最终保持一致。 consul members #节点名称、监听地址、健康状态、集群角色、版本信息 Node Address Status Type Build Protocol DC Segment zhang22 127.0.0.1:8301 alive server 1.0.6 2 dc1 \u003call\u003e #使用HTTP API将请求转发给server以获取一致的view of world culr localhost:8500/v1/catalog/nodes #DNS interface也可以查询节点，默认端口8600 dig @127.0.0.1 -p 8600 zhang22.node.consul \r","date":"2018-04-05","objectID":"/consul/:5:2","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"停止agent 可使用Ctrl + C优雅地终止agent，你可以看到它离开集群并关闭。 优雅关闭，Consul会通知集群其它节点此节点的离开。如果你强制kill agent，则集群的其它节点将检测该节点失败。 当成员离开时，其服务和健康检查将从catalog中移除。当成员失败时，其健康状态被标记为critical，但不会从catalog中移除。 Consul会自动尝试重连失败的节点，允许它从当前网络条件中修复，知道离开的节点不在联系。 此外，如果agent正作为server在运行，那么优雅地离开对避免造成严重的影响有帮助。 \r","date":"2018-04-05","objectID":"/consul/:5:3","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"注册服务 注册(register)服务并查询(query)服务。 \r","date":"2018-04-05","objectID":"/consul/:6:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"定义一个服务 服务可以通过以下两种方法注册： 服务定义(service definition) 调用HTTP API 服务定义是注册服务最常见的方式，我们将构建前面agent的配置。 #创建一个consul配置目录 mkdir /etc/consul.d #编写服务定义配置文件 #假设有一个web服务运行在80端口，添加一个便于query的tag echo '{\"service\": {\"name: \"web\", \"tag\": [\"rails\"], \"port\": 80 }}' | tee /etc/consul.d/web.json #重启agent，指定配置目录 consul agent -dev -config-dir=/etc/consul.d 如果你想注册多个服务，你可以在配置目录下创建多个服务定义文件。 \r","date":"2018-04-05","objectID":"/consul/:6:1","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"查询服务 一旦agent启动并且服务已同步，我们可通过HTTP API或DNS查询(query)服务。 DNS API 使用DNS API(默认8600)查询服务 #DNS name(默认) -- NAME.service.consul #只有IP dig @127.0.0.1 -p 8600 web.service.consul #返回IP/Port dig @127.0.0.1 -p 8600 web.service.consul SRV 我们还可以用DNS API按tag来过滤service。基于标签的查询格式为tag.name.service.consul。 dig @127.0.0.1 -p 8600 rails.web.service.consul \rHTTP API 除了DNS API，HTTP API(默认8500)同样可用于查询服务。 #前面定义了web这个service curl http://localhost:8500/v1/catalog/service/web catalog API提供了给定服务的所有节点。 #仅仅健康实例的查询 curl 'http://localhost:8500/v1/health/service/web?passing' ","date":"2018-04-05","objectID":"/consul/:6:2","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"更新服务 服务定义可以通过更改配置文件并向agent发送SIGHUP来更新。这使得更新服务不会出现任何停机或查询服务不可达的情况。 另外，HTTP API能够用来动态地添加、移除、修改服务。 \r","date":"2018-04-05","objectID":"/consul/:6:3","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"Consul集群 具有多个成员的consul集群。 当consul节点启动时，它不知道任何其它节点，它是一个孤立的集群。为了了解到集群中的其它成员，agent必须要加入一个存在的集群。要加入一个现有的集群，只需知道一个现有成员。当加入集群后，agent将于其此成员闲聊，并迅速发现集群中的其它成员。一个agent可以加入任何其它agent，而不仅仅是server模式的agent。 ","date":"2018-04-05","objectID":"/consul/:7:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"启动agents #node1 consul agent -server -bootstrap-expect=1 \\ -data-dir=/tmp/consul -node=agent-one -bind=ip1 \\ -enable-script-checks=true -config-dir=/etc/consul.d #node2 consul agent -data-dir=/tmp/consul -node=agent-two \\ -bind=ip2 -enable-script-checks=true -config-dir=/etc/consul.d #两个独立的node #现在，我们有两个agent在运行中：一个server，一个client。但是他们两者并不知道对方，并仍然是一个单一节点的集群。 #查看节点 consul member \r","date":"2018-04-05","objectID":"/consul/:7:1","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"加入集群 由于我们在启动agent的时候便已指定server，所以从哪个节点加入都一样。 consul join ip #Successfully joined cluster by contacting 1 nodes. consul members Node Address Status Type Build Protocol DC Segment agent-one 172.16.129.141:8301 alive server 1.0.6 2 dc1 \u003call\u003e agent-two 172.16.129.150:8301 alive client 1.0.6 2 dc1 \u003cdefault\u003e ","date":"2018-04-05","objectID":"/consul/:8:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"在启动时自动加入集群 理想情况下，每当一个新节点出现在数据中心时，它应该自动加入集群而不需要人工干预。 \r","date":"2018-04-05","objectID":"/consul/:8:1","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"查询节点 就像查询服务，consul有一个API用于查询节点。 #NAME.node.consul或NAME.node.DATACENTER.conosul dig @localhost -p 8600 agent-one.node.consul dig @127.0.0.1 -p 8600 agent-two.node.consul ","date":"2018-04-05","objectID":"/consul/:8:2","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"离开集群 优雅的退出: Ctrl+C 强制kill \r","date":"2018-04-05","objectID":"/consul/:8:3","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"健康检查 对节点和服务添加健康检查(health check)。 健康检查是服务发现的关键组件，可以防止使用不健康的服务。 ","date":"2018-04-05","objectID":"/consul/:9:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"定义检查 与服务类似，一个检查能够通过定义检查或适当调用HTTP API来两种方式来注册。 定义检查是一个最基本和推荐的方法。 在consul配置目录中创建检查定义文件： #在基于脚本的健康检查上，它与consul进程使用同样的用户 #如果命令以非0状态码退出，则该节点会被标记为unhealthy echo '{\"check\": {\"name\": \"ping\", \"args\": [\"ping\", \"-c1\", \"baidu.com\"], \"interval\": \"30s\"}}' \u003e/etc/consul.d/ping.json echo '{\"service\": {\"name\": \"web\", \"tags\": [\"rails\"], \"port\": 80, \"check\": {\"args\": [\"curl\", \"localhost\"], \"interval\": \"10s\"}}}' \u003e/etc/consul.d/web.json consul reload ","date":"2018-04-05","objectID":"/consul/:9:1","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"检查健康状态 curl http://localhost:8500/v1/health/state/critical dig @127.0.0.1 -p 8600 web.service.consul \r","date":"2018-04-05","objectID":"/consul/:10:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"KV数据 Consul提供了一个易于使用的KV存储。这可以用来保存动态配置，协助服务协调，构建leader选举，并启用开发人员可以考虑构建的任何其它内容。 ","date":"2018-04-05","objectID":"/consul/:11:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"用法 有两种方法与Consul K/V交互的方式： HTTP API Consul KV CLI #CLI consul kv --help consul kv put name zhang consul kv get name #zhang consul kv get -detailed name consul kv puut -flags=42 who zhang21 #所有key都支持设置一个64位的整数标志值 #列出所有kv consul kv get -recurse #删除 consul kv delete name #使用 Check-And-Set 进行原子更新 consul kv put -cas -modify-index=112 NAME zhang #导出与导入 consul kv export \u003e xxx.json consul kv import $xxx.json \r","date":"2018-04-05","objectID":"/consul/:11:1","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"Web界面 Consul支持美观的Web界面。用户界面可以查看所有的服务和节点，查看所有健康检查和当前状态，读取和设置kv数据，并自动支持多数据中心。 consul agent -ui #localhost:8500/ui \r\r \r内部详情 Consul Internals 介绍Consul内部详情。 \r","date":"2018-04-05","objectID":"/consul/:12:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"架构 Architecture \r","date":"2018-04-05","objectID":"/consul/:13:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"词汇表 Glossary Agent Client Server Datacenter Consensus Gossip LAN Geossip WAN Geossip RPC \r\r","date":"2018-04-05","objectID":"/consul/:13:1","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"Consensus协议 Consul使用consensus(共识) protocol来提供一致性(consistency)，它基于Raft(In search of an Understandable Consensus Algorithm) ","date":"2018-04-05","objectID":"/consul/:14:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"Raft协议 Raft是基于Paxos的共识算法。 Raft的一些关键术语： Log The primary unit of work in a Raft system is a log entry. FSM(Finite State Machine) An FSM(有限状态机) is a collection of finite states with transitions between them. Peer set The peer set(对等集) is the set of all members participating in log replication. Quorum A quorum(仲裁) is a majority of members from a peer set: for a set of size n, quorum requires at least (n/2)+1 members. Committed Entry An entry is considered committed when it is durably stored on a quorum of nodes. Leader At any given time, the peer set elects a single node to be the leader. Raft节点总是处于如下三种状态之一： follower(追随者) candidate(候选者) leader(领导者) 所有节点最初都是作为follower开始的。在这种状态下，节点可接受leader的日志条目并投票。如果一段时间内没有收到任何条目，则节点会自我提升到candidate。 在candidate状态下，节点请求来自对等节点的投票。如果候选人获得仲裁(quorum)的票数，那么它将被提升为leader。 leader必须接受新的日志条目并复制给其它所有follower。另外，如果陈旧读取不可接受，则所有查询也必须在leader上执行。 一旦集群具有leader，它就能够接受新的日志条目。Client可以请求leader添加新的日志条目。然后，leader将条目持久化，并尝试复制到仲裁的follower。一旦日志条目被认为提交(committed)，它就可以应用于有限状态机(FSM)。 显然，允许复制日志以无限制的方式增长是不可取的。Raft提供了一种机制，可通过快照(snapshot)当前状态并压缩日志。 达成共识是容错的，直到法定人数可用。 建议为每个数据中心配置3-5台Consul Server。3个节点的Raft集群可以容忍单个节点故障，5个节点的Raft集群可以容忍2个节点故障。这可最大限制提高可用性。 ","date":"2018-04-05","objectID":"/consul/:14:1","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"Raft in Consul 只有Consul Server节点参与Raft，并且是对等集的一部分。所有的Client节点都将请求转发给Server。 当启动的时候，单个Consul Server进入bootstrap模式，此模式允许它进行自我选举为leader。leader选出后，可以以一致性和安全性的方式将其它Server添加到对等集，之后，就可以禁用bootstrap模式。 由于所有的Server作为对等集的一部分参与，因此他们都知道当前的leader。当一个RPC请求到达了non-leader Server时，请求被转发给leader。 如果RPC是查询(query)类型，意味着它是只读的，则leader根据FSM的当前状态生成结果 如果RPC是事务(transaction)类型，意味着它是可修改的，则leader生成新的日志条目并使用Raft应用它 提交日志条目并将其应用于FSM后，事务就完成了。 由于Raft副本的性质，性能对网络延迟很敏感。因此，每个数据中心选择一个独立的leader并维护一个不相交的对等集。数据由数据中心分区，每个leader仅负责其数据中心中的数据。 ","date":"2018-04-05","objectID":"/consul/:14:2","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"一致性模式 Consistency Modes 虽然对副本日志的所有写入都通过Raft，但读取却更加灵活。 Consul支持3种不同的读取一致性模式： default consistent stale ","date":"2018-04-05","objectID":"/consul/:14:3","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"部署表 Servers Quorum Size Failere Tolerance 1 1 0 2 2 0 3 2 1 4 3 1 5 3 2 6 4 2 7 4 3 \r\r","date":"2018-04-05","objectID":"/consul/:14:4","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"Gossip协议 Consul 使用gossip协议来管理成员并向集群发送广播信息。所有这些都通过Serf Library提供。 \r","date":"2018-04-05","objectID":"/consul/:15:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"Goossip in Consul Consul使用两个不同的gossip pools: LAN pool WAN pool \r\r","date":"2018-04-05","objectID":"/consul/:15:1","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"网络坐标 Network Coordinates Consul使用网络层层析系统来计算集群中节点的网络坐标。这些坐标允许使用非常简单的计算在任意两个节点之间估计网络往返时间。所有这些都通过使用Serf Library。 \r","date":"2018-04-05","objectID":"/consul/:16:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"Consul中的网络坐标 Network Coordinates in Consul 网络坐标在Consul中有多种表现方式： consul rtt Catalog/Health endpoints Prepared query Coordinate endpoint \r","date":"2018-04-05","objectID":"/consul/:16:1","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"使用坐标 一旦你有了两个节点的坐标，则计算它们间的往返时间是很简单的： \"Coord\": { \"Adjustment\": 0.1, \"Error\": 1.5, \"Height\": 0.02, \"Vec\": [0.34,0.68,0.003,0.01,0.05,0.1,0.34,0.06] } \r\r","date":"2018-04-05","objectID":"/consul/:16:2","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"会话 Sessions consul提供了一个用于构建分布式锁的会话机制。会话充当节点、健康检查和K/V数据之间的监听层。 \r","date":"2018-04-05","objectID":"/consul/:17:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"会话设计 \r\r \rAgent ","date":"2018-04-05","objectID":"/consul/:17:1","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"启动和停止 Consul Agent是Consul的核心进程。它维护成员关系信息，注册服务，运行检查，响应查询… Consul Agent必须运行在在Consul集群的每个节点上。 Agent有两种运行模式： server client Server节点承担了作为**consensus quorum(共识法人)**的额外责任，这些节点参与Raft，并在出现故障时提供强大的一致性和可用性。 Client节点构成了集群的大部分，它们非常轻便。因为它们与Server进行大部分操作，保持自己的状态则很少。 运行Agent 以下是一些重要信息： Node name Datacenter Server Client addr Cluster addr #直接指定配置项运行 consul agent -options #将配置项写入文件，指定配置目录运行 mkdir /etc/consul.d vim /etc/consul.d/consul.json consul agent -config-dir=/etc/consul.d 停止Agent 有两种停止方式： gracefully 发送中断信号ctrl+c或运行kill -INT。优雅地退出，Agent首先通知集群它要离开集群。这样，集群便会通知其它成员该节点已离开。 forcefully 通过kill signal来强制杀掉Consul。集群的其余部分最终会检测到该节点已死亡并通知集群节点已失效。 特别重要的是允许Server节点优雅地离开，以便对可用性产生最小的影响。 对于Client Agent来说，节点失效和节点离开的区别对用例并不是那么重要。 生命周期 Consul集群中的每个Agent都会经历一个生命周期(lifecycle)。 当Agent首次启动时，他并不知道集群中的其它任何节点。要发现它的同伴，它必须加入集群。这使用join命令或在配置文件中配置。一旦一个节点加入，这个信息就会传递给整个集群，这意味着所有节点最终都会意识到对方。 如果Agent是一个Server，则已经存在的Server就会开始复制(replicating)到新节点。 在网络故障的情况下，某些节点可能无法被其它节点访问。在这种情况下，无法访问的节点被标记为失败(failed)。无法区分网络故障和Agent崩溃，因此两种情况的处理方式都是相同的。该信息将在service catalog中被更新。 当一个节点离开时，它指定了它的意图，并且集群将该节点标记为已离开。与失败(failed)不同，节点提供的所有服务都立即注销(deregistered)。如果Agent是Server，则对其的复制(replication)将停止。 为了防止死亡(failed/left)节点的堆积，Consul会自动将死亡节点从目录中移除。这个过程被称为收割(reaping)。 \r\r","date":"2018-04-05","objectID":"/consul/:18:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"DNS接口 DNS接口允许应用程序利用服务发现，而无需与Consul进行高度整合。 有几个重要的配置项： client_addr ports.dns recursors domain dns_config 数据中心部分是可选的，如果没有提供，则默认为Agent自身的数据中心。 节点查找 为了解析名称(name)，Consul依赖于特定的查询格式。基本上有两种类型的查询： node lookup service lookup #node lookup \u003cnode\u003e.node[.datacenter].\u003cdomain\u003e node1.node.dc1.consul node1.node.consul dig @127.0.0.1 -p 8600 node1.node.consul 服务查找 服务查找用于查询你服务提供者。 有两种查询方式： 标准查询 DNS查询系统利用健康检查信息来防止路由到不健康的节点。为了实现简单的负载均衡，每次返回的节点集都是随机的。 [tag.]\u003cservice\u003e.service[.datacenter].\u003cdomain\u003e redis.service.consul postgresql.service.dc2.consul dig @127.0.0.1 -p 8600 redis.service.consul SRV RFC 2782查询 RFC 2782使用_下划线作为查询中服务和协议值的前缀，以防止DNS冲突。 _\u003cservice\u003e._\u003cprotocol\u003e[.service][.datacenter][.domain] dig @127.0.0.1 -p 8600 _rabbitmq._amqp.service.consul SRV Prepared Query Lookups The query or name is the ID or given name of an existing Prepared Query. \u003cquery or name\u003e.query[.datacenter].\u003cdomain\u003e 可连接的服务查找 Connect-Capable Service Lookups. \u003cservice\u003e.connect.\u003cdomain\u003e Caching 默认情况下，Consul服务的所有DNS结果都会设置一个为0的TTL。这会禁用DNS结果的缓存。但，很多情况下，缓存对性能和伸缩性都是可取的。 WAN地址转换 默认情况下，Consul DNS查询将会返回一个节点的本地地址。如果你需要外部地址，则可使用advertise-wan和translate_wan_addrs选项来配置此行为。 \r\r","date":"2018-04-05","objectID":"/consul/:19:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"配置 Agent有许多通过命令行或配置文件配置的配置项。配置优先级如下： 命令行参数 环境变量 配置文件 配置文件可以是HCL或JSON格式。 Consul可通过reload命令重新载入配置文件。 \r\r","date":"2018-04-05","objectID":"/consul/:20:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"端口 Consul默认使用的端口： 8300(tcp) Server RPC. Server用于处理来自其它Agent的传入请求。 8301(tcp/udp) Serf LAN. 用于处理LAN中的gossip，所有Agent都需要。 8302(tcp/udp) Serf WAN. Server用于处理WAN上gossip到其它Server。 8500(tcp) HTTP API. 8600(tcp/udp) DNS Interface. \r\r","date":"2018-04-05","objectID":"/consul/:20:1","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"可重新加载的配置 Reloadable Configuration 重新加载配置文件不会加载所有配置项，如下这些配置项是可重新载入的： log level checks services watches http client address node metadata metric prefix filter discard check output rpc rate limiting \r\r","date":"2018-04-05","objectID":"/consul/:20:2","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"配置文件 配置文件不仅用于设置代理，还用于提供检查和服务定义。 配置文件选项和命令行参数稍微有点不一样。 使用consul agent -h查看具体配置项。 栗子： #开始栗子 vim /etc/consul.d/single.json { \"bind_addr\": \"192.168.1.11\", \"bootstrap\": true, \"client_addr\": \"0.0.0.0\", \"datacenter\": \"zhang\", \"data_dir\": \"/var/lib/consul\", \"log_level\": \"WARN\", \"node_name\": \"zhang21\", \"server\": true, \"enable_syslog\": true, \"ui\": true } #集群配置 vim /etc/consul.d/cluster.json { \"bind_addr\": \"xxx\", \"bootstrap_expect\": 2, \"client_addr\": \"0.0.0.0\", \"datacenter\": \"zhang\", \"data_dir\": \"/var/lib/consul\", \"encrypt\": \"a1b8vAA2==@xyz\", \"log_level\": \"WARN\", \"node_name\": \"zhang21\", \"node_id\": \"zhang21\", \"server\": true, \"enable_syslog\": true, \"ui\": true, \"retry_interval\": 20s, \"retry_join\": [ \"consul.domain.internal\", \"10.0.1.2:8301\", \"[::1]:8301\" ] } \r\r","date":"2018-04-05","objectID":"/consul/:20:3","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"服务定义 服务发现的主要目标之一是提供可用服务的目录(catalog)。为此，Agent提供了一种简单的服务定义格式来声明服务的可用性，并可能将其与健康检查相关联。如果健康检查与服务关联，则认为它是应用程序级别。 ","date":"2018-04-05","objectID":"/consul/:21:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"服务定义 服务定义方式： 配置文件(推荐) HTTP API 一个服务定义包含的字段： name(必须) id(可选) tags(可选) address(可选) port(可选) check(可选) meta(可选) enable_tag_override(可选) token(可选) id必须唯一，如果未设置id，默认使用name。 服务可以关联健康检查，这是一个强大的功能。 检查必须是脚本、HTTP、TCP或TTL类型。 脚本类型，必须提供参数和间隔 HTTP类型，必须提供http和interval TCP类型，必须提供tcp和interval TTL类型，只能提供ttl 检查名称自动生成为: service:\u003cservice-id\u003e，如果有多个服务检查注册，生成的id为： service:\u003cservice:-id\u003e:\u003cnum\u003e，num是从1开始递增的数字。 栗子： vim /etc/consul.d/redis.json { \"service\": { \"name\": \"redis\", \"id\": \"redis01\", \"tags\": [ \"master\" ], \"address\": \"127.0.0.1\", \"port\": 6379, \"meta\": { \"meta\": \"service definition for redis\" }, \"enable_tag_override\": false, \"check\": { \"id\": \"redisTCP\", \"name\": \"redis service check\", \"tcp\": \"localhost:6379\", \"interval\": \"10s\", \"timeout\": \"1s\" } } } \r\r","date":"2018-04-05","objectID":"/consul/:21:1","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"多个服务定义 { \"services\": [ { \"id\": \"red0\", \"name\": \"redis\", \"tags\": [ \"primary\" ], \"address\": \"\", \"port\": 6000, \"checks\": [ { \"args\": [\"/bin/check_redis\", \"-p\", \"6000\"], \"interval\": \"5s\", \"ttl\": \"20s\" } ] }, { \"id\": \"red1\", \"name\": \"redis\", \"tags\": [ \"delayed\", \"secondary\" ], \"address\": \"\", \"port\": 7000, \"checks\": [ { \"args\": [\"/bin/check_redis\", \"-p\", \"7000\"], \"interval\": \"30s\", \"ttl\": \"60s\" } ] }, ... ] } \r\r","date":"2018-04-05","objectID":"/consul/:21:2","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"检查定义 Agent的主要角色便是管理系统级和应用级的健康检查。 一个检查的定义有两种方式： 配置文件 HTTP API 检查方式： Script + Interval HTTP + Interval TCP + Interval TTL Docker + Interval gRPC + Interval \r","date":"2018-04-05","objectID":"/consul/:22:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"定义检查 A script check: { \"check\": { \"id\": \"mem-util\", \"name\": \"Memory utilization\", \"args\": [\"/usr/local/bin/check_mem.py\", \"-limit\", \"256MB\"], \"interval\": \"10s\", \"timeout\": \"1s\" } } A HTTP check: { \"check\": { \"id\": \"api\", \"name\": \"HTTP API on port 5000\", \"http\": \"https://localhost:5000/health\", \"tls_skip_verify\": false, \"method\": \"POST\", \"header\": {\"x-foo\":[\"bar\", \"baz\"]}, \"interval\": \"10s\", \"timeout\": \"1s\" } } A TCP check: { \"check\": { \"id\": \"ssh\", \"name\": \"SSH TCP on port 22\", \"tcp\": \"localhost:22\", \"interval\": \"10s\", \"timeout\": \"1s\" } } A TTL check: { \"check\": { \"id\": \"web-app\", \"name\": \"Web App Status\", \"notes\": \"Web app does a curl internally every 10 seconds\", \"ttl\": \"30s\" } } A Docker check: { \"check\": { \"id\": \"mem-util\", \"name\": \"Memory utilization\", \"docker_container_id\": \"f972c95ebf0e\", \"shell\": \"/bin/bash\", \"args\": [\"/usr/local/bin/check_mem.py\"], \"interval\": \"10s\" } } A gRPC check: { \"check\": { \"id\": \"mem-util\", \"name\": \"Service health status\", \"grpc\": \"127.0.0.1:12345\", \"grpc_use_tls\": true, \"interval\": \"10s\" } } \r","date":"2018-04-05","objectID":"/consul/:22:1","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"检查脚本 使用enable_script_checks选项来启用脚本检查。 检查脚本的退出码(exit code)必须遵循如下约定： exit code o 检查通过 exit code 1 检查警告 any exit code 检查失败 \r","date":"2018-04-05","objectID":"/consul/:22:2","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"初始化健康检查状态 在某些情况下，可能需要指定健康检查的初始状态。 { \"check\": { \"id\": \"mem\", \"args\": [\"/bin/check_mem\", \"-limit\", \"256MB\"], \"interval\": \"10s\", \"status\": \"passing\" } } \r","date":"2018-04-05","objectID":"/consul/:22:3","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"绑定服务检查 健康检查可以选择性地绑定到特定服务。这可以确保健康检查的状态只会影响给定服务的健康状态，而不会影响整个节点。 服务绑定检查需要添加一个service_id字段： { \"check\": { \"id\": \"web-app\", \"name\": \"Web App Status\", \"service_id\": \"web-app\", \"ttl\": \"30s\" } } \r","date":"2018-04-05","objectID":"/consul/:22:4","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"定义多个检查 使用checks来定义多个服务检查。 { \"checks\": [ { \"id\": \"chk1\", \"name\": \"mem\", \"args\": [\"/bin/check_mem\", \"-limit\", \"256MB\"], \"interval\": \"5s\" }, { \"id\": \"chk2\", \"name\": \"/health\", \"http\": \"http://localhost:5000/health\", \"interval\": \"15s\" }, { \"id\": \"chk3\", \"name\": \"cpu\", \"script\": \"/bin/check_cpu\", \"interval\": \"10s\" }, ... ] } \r\r","date":"2018-04-05","objectID":"/consul/:22:5","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"加密 Encryption Consul Agent支持加密所有流量。有两个独立的加密系统： gossip流量 RPC ","date":"2018-04-05","objectID":"/consul/:23:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"gossip加密 启用geossip加密只需要你在启动Consul Agent时设置加密密钥(encryption key)。密钥是16Bytes的Base64编码。 consul keygen FDGDpW55oCYJlh555Es1gA== vim /etc/consul.d/cluster.json { \"encrypt\": \"FDGDpW55oCYJlh555Es1gA==\", } consul集群的所有节点必须共享相同的加密密钥！ ","date":"2018-04-05","objectID":"/consul/:23:1","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"RPC加密 Consul支持使用TLS来验证Server和Client之间的真实性。它们之间使用由证书机构颁发的密钥对，你可以自己生成CA。 \r\r","date":"2018-04-05","objectID":"/consul/:23:2","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"Telemetry Consul Agent收集有关不同库和子系统的各种运行时指标。这些指标以10s为间隔进行汇总，并保留1min。 查看这些数据，你需要向Consul进程发送信号： Unix: USR1 Windows: BREAK Consul收到信号后，它将当前的遥测(telemetry)信息转储到Agent’s STDERR。 #USR1 10 kill -10 ${consul-pid} 详情: https://www.consul.io/docs/agent/telemetry.html \r\r","date":"2018-04-05","objectID":"/consul/:24:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"Watches watches是一种指定检测更新的数据视图的方式。检测到更新，将调用外部处理程序。 watch使用HTTP API中的blocking query，Agent自动进行适当的API调用已检测更新，并在数据视图更新时通知处理程序。 watch可以配置为Agent configuration的一部分，watch也可以在Agent之外启动。 ","date":"2018-04-05","objectID":"/consul/:25:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"处理程序 监测配置指定要监测的数据视图，更新视图后，将调用指定的处理程序(Handler)。外部程序可为可执行程序(executable)或HTTP endpoint。 可执行程序 可执行处理程序从stdin读取json信息，此外CONSUL_INDEX环境变量将被设置为Consul Index写入stdout。 { \"type\": \"key\", \"key\": \"foo/bar/baz\", \"handler_type\": \"script\", \"args\": [\"/usr/bin/my-service-handler.sh\", \"-redis\"] } #在consul v1.0以后，args数组被添加，以便可在没有shell的情况下运行处理程序 HTTP endpoint 当watch被调用时发送HTTP请求给HTTP处理程序。 { \"type\": \"key\", \"key\": \"foo/bar/baz\", \"handler_type\": \"http\", \"http_handler_config\": { \"path\":\"https://localhost:8000/watch\", \"method\": \"POST\", \"header\": {\"x-foo\":[\"bar\", \"baz\"]}, \"timeout\": \"10s\", \"tls_skip_verify\": false } } \r","date":"2018-04-05","objectID":"/consul/:25:1","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"全局参数 Global Parameters datacenter token args handler \r","date":"2018-04-05","objectID":"/consul/:25:2","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"Watch类型 key keyprefix services nodes service checks event 栗子： consul watch -type service -service redis consul watch -type checks -service redis #key { \"type\": \"key\", \"key\": \"foo/bar/baz\", \"args\": [\"/usr/bin/my-service-handler.sh\", \"-redis\"] } #or consul watch -type=key -key=foo/bar/baz /usr/bin/my-key-handler.sh #keyprefix { \"type\": \"keyprefix\", \"prefix\": \"foo/\", \"args\": [\"/usr/bin/my-service-handler.sh\", \"-redis\"] } #or consul watch -type=keyprefix -prefix=foo/ /usr/bin/my-prefix-handler.sh #services { \"redis\": [] } #nodes [ { \"Node\": \"node1\", \"Address\": \"192.168.1.11\" }, { \"Node\": \"node2\", \"Address\": \"xxx\" } ] #service { \"type\": \"service\", \"service\": \"redis\", \"args\": [\"/usr/bin/my-service-handler.sh\", \"-redis\"] } #check [ { \"Node\": \"foobar\", \"CheckID\": \"service:redis\", \"Name\": \"Service 'redis' check\", \"Status\": \"passing\", \"Notes\": \"\", \"Output\": \"\", \"ServiceID\": \"redis\", \"ServiceName\": \"redis\" } ] #event { \"type\": \"event\", \"name\": \"web-deploy\", \"args\": [\"/usr/bin/my-service-handler.sh\", \"-web-deploy\"] } #or consul watch -type=event -name=web-deploy /usr/bin/my-deploy-handler.sh -web-deploy \r\r \r指南 Consul Guide 本节提供了Consul各种常见的操作指南。 如下： ACLs Consul访问控制列表，该功能用于控制对资源的访问。 Adding/Removing Servers 从集群中安全地添加和删除Consul Server，这应该小心操作。 Autopilot 为Consul Server提供自动友好操作的管理。 Bootstrapping 引导新的数据中心，包括安全地添加初始化Consul Server。 Consul with Container 在容器内运行Consul Cluster。 DNS Caching 为DNS查询缓存启用TTLS DNS Forwarding 从BIND转发DNS查询到Consul External Services 注册外部服务。允许在Consul框架内使用第三方服务。 Federation 配置Consul以支持多个数据中心。 Geo Failover 用准备好的查询来实现服务的地理故障转移。 Leader Election 使用Consul构建Client端的领导选举。 Network Segments 配置Consul使用网段-支持部分LAN连接。 Outage Recovery 恢复因Server故障而无法使用的集群。 Semaphore 使用KV存储实现一个信号量 Sentinel 使用哨兵模式在Consul中执行策略。 Server Performance Consul Server的最低要求以及生产环境中运行Consul Server的指南。 \r\r","date":"2018-04-05","objectID":"/consul/:25:3","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"ACLs Consul提供可选的访问控制列表系统，用于控制对数据和API的访问。它依赖于规则的token. 访问控制列表旨在提供易于使用，快速执行和灵活的新策略。 \r","date":"2018-04-05","objectID":"/consul/:26:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"概述 ACL Tokens 访问控制列表系统基于token(令牌)，由Consul操作者通过 Consul ACL API进行管理。 如果没有提供token，则会自动关联与特殊的可配置匿名令牌(anonymous token)的规则。 每个token具有： ID name type client management rule set(规则集) ACL Rules and Scope token绑定到一组规则，用于控制令牌可以访问的Consul资源。可在白名单(whitelist)/黑名单(blacklist)下定义策略，这取决于默认策略acl_default_policy的值。 构建规则的ACL策略： agent 用于Agent API event 用于Event API key 用于KV Store API keyring 用于Keyring API node 用于Catalog API, Health API, Prepare Query API, Network Coordinate API， Agent API operator 用于Operator API query 用于Prepared Query API service Catalog API, Health API, Prepared Query API, Agent API session 用于Session API 由于Consul snapshots实际上包含ACL token，因此Snapshot API需要一个管理token进行快照操作。 ACL策略不包括如下资源： Status API Catalog API ACL Datacenter 必须使用acl_datacenter配置所有节点(client/server)来启用ACL强制实施，但同时也是权威数据中心。Consul依靠RPC转发来支持多数据中心(multi-datacenter)。但是，由于可以跨数据中心边界发出请求，因此ACL令牌必须在全局范围内有效。为避免一致性问题，单个数据中心被视为具有权威性，并存储规范的令牌集。 \r\r","date":"2018-04-05","objectID":"/consul/:26:1","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"配置ACLs 使用多个配置项配置ACL： 配置项 Server Client 目的 acl_datacenter required required 为ACL定义权威Consul数据中心来启用ACL的主控制 acl_default_policy 可选 n/a 定义白名单或黑名单模式 acl_down_policy 可选 可选 定义ACL数据中心脱机时执行的操作 acl_ttl 可选 可选 定义缓存ACL的生存时间 配置特殊令牌，允许引导ACL系统或在特殊情况下访问Consul： 特殊令牌 Server Client 目的 acl_agent_master_token 可选 可选 当ACL数据中心不可用或Server脱机时，可用于访问Agent API acl_agent_token 可选 可选 用于Agent内部操作 acl_master_token required n/a 用于引导ACL系统 acl_token 可选 可选 用于未提供token的客户端请求的默认令牌。这通常配置为对服务的只读访问权限，以便在Agent上启用DNS发现 ACL Agent Master Token 由于acl_agent_master_token旨在Consul Server不可用时使用，因此其策略在Agent本地管理，并且不需要通过ACL API在Consul Server上定义token。 agent \"\u003cnode name of agent\u003e\" { policy = \"write\" } node \"\" { policy = \"read\" } ACL Agent Token acl_agent_token是一个特殊令牌，用于Agent的内部操作。用于Agent的如下操作： 使用Catalog API更新Agent的节点条目 执行反熵同步 执行consul_exec命令时，读写KV存储库的特殊_rexec部分 node \"node1\" { policy = \"write\" } service \"\" { policy = \"read\" } key \"_rexec\" { policy = \"write\" } 任何一个可在Agent上注册的服务，service策略需要读访问权限。 \r\r","date":"2018-04-05","objectID":"/consul/:26:2","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"引导ACLs Bootstrapping ACLs 在新集群上引导ACLs需要几个步骤： Enable ACLs on the Consul Servers 引导ACLs的第一步便是在ACL数据中心的Consul Server上启用ACLs，配置如下： { \"acl_datacenter\": \"dc1\", \"acl_master_token\": \"123abc!@#, \"acl_default_policy\": \"deny\", \"acl_down_policy\": \"deny\", \"acl_down_policy\": \"extend-cache\" } Create an Agent Token 使用ACL API和上一步中设置的ACL Master Token创建令牌： curl --request PUT --header \"X-Consul-Token: 123abc!@#\" --data \\ '{ \"Name\": \"Agent Token\", \"Type\": \"client\", \"Rules\": \"node \\\"\\\" { policy = \\\"write\\\"} service \\\"\\\" { policy = \\\"read\\\" }\" }' http://127.0.0.1:8500/v1/acl/create 返回的值便是新创建的token {\"ID\": \"xxxxxxxxxxxxxx\"} 返回的值便是新创建的token。将这个值添加到Consul Server配置中，并重启Server： { \"acl_datacenter\": \"dc1\", \"acl_master_token\": \"123abc!@#, \"acl_default_policy\": \"deny\", \"acl_down_policy\": \"deny\", \"acl_down_policy\": \"extend-cache\", \"acl_agent_token\": \"xxxxxxxxxxxxxxxx\" } 或使用API导入token： curl --request PUT --header \"X-Consul-Token: 123abc!@#\" --data \\ '{ \"Token\": \"xxxxxxxxxxxxx\" }' http://127.0.0.1:8500/v1/agent/token/acl_agent_token Enable ACLs on the Consul Clients 还需再Agent上配置ACL { \"acl_datacenter\": \"dc1\", \"acl_down_policy\": \"extend-cache\", \"acl_agent_token\": \"前面的acl_agent_token\" } #或使用API curl \\ --request PUT \\ --header \"X-Consul-Token: abc123!@#\" \\ --data \\ '{ \"Token\": \"xxxxxxxxxxxx\" }' http://127.0.0.1:8500/v1/agent/token/acl_agent_token 使用由Server创建的相同ACL Agent token，因为它不是特定于任何节点或前缀集。建议每个Client获取一个ACL agent token，该令牌具有对自己的节点名称前缀的节点有写入权限，以及针对预期在该Client上注册的服务前缀的读权限。 Set an Anonymous Policy (Optional) 此时，ACL已通过配置的ACL agent token进行引导，但还没有配置其它策略。 甚至像consul members这样的基本操作也会受到ACL默认策略deny的限制。 如果我们提供上面的Token，则能够看到具体信息： CONSUL_HTTP_TOKEN=xxxxxxxx consul members 匿名令牌： curl \\ --request PUT \\ --header \"X-Consul-Token: 123abc!@#\" \\ --data \\ '{ \"ID\": \"anonymous\", \"Type\": \"client\", \"Rules\": \"node \\\"\\\" { policy = \\\"read\\\" }\" }' http://127.0.0.1:8500/v1/acl/update 某个服务： curl \\ --request PUT \\ --header \"X-Consul-Token: 123abc!@#\" \\ --data \\ '{ \"ID\": \"anonymous\", \"Type\": \"client\", \"Rules\": \"node \\\"\\\" { policy = \\\"read\\\" } service \\\"consul\\\" { policy = \\\"read\\\" }\" }' http://127.0.0.1:8500/v1/acl/update Set Agent-Specific Default Tokens (Optional) 匿名令牌的替代方法是acl_token配置项。 Create Tokens for UI Use (Optional) 如果你使用具有限制性ACL策略的Consul UI，UI将无法使用匿名ACL令牌完整运行。 建议使用特定于UI的ACL令牌，可以在Web浏览器绘画期间在UI中设置该令牌对进口进行认证。 curl \\ --request PUT \\ --header \"X-Consul-Token: 123abc!@#\" \\ --data \\ '{ \"Name\": \"UI Token\", \"Type\": \"client\", \"Rules\": \"key \\\"\\\" { policy = \\\"write\\\" } node \\\"\\\" { policy = \\\"read\\\" } service \\\"\\\" { policy = \\\"read\\\" }\" }' http://127.0.0.1:8500/v1/acl/create \r\r","date":"2018-04-05","objectID":"/consul/:26:3","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"规则 Rule Specification ACL系统的和核心部分是规则语言，用于描述必须强制执行的策略。 使用基于前缀的规则，最具体的前缀匹配决定了操作。 使用HCL配置语言来指定规则，规则可定义多个策略。 ACL API运行使用HCL或JSON来定义规则部分的内容。 策略有以下集中处理方式： read write(读写) deny 栗子： # These control access to the key/value store. key \"\" { policy = \"read\" } key \"foo/\" { policy = \"write\" } key \"foo/private/\" { policy = \"deny\" } # This controls access to cluster-wide Consul operator information. operator = \"read\" Agent Rules Agent策略控制对Agent API中实用程序操作的访问。 Agent规则通过节点名称，使用欧冠最长前缀匹配规则。 Agent rules栗子： agent \"\" { policy = \"read\" } agent \"foo\" { policy = \"write\" } agent \"bar\" { policy = \"deny\" } 如上，对具有空前缀的任何节点可读，对以foo开头的节点名进行读写，拒绝以bar开头的节点名。 Event Rules 事件策略控制对事件API中事件操作的访问。 事件规则由它们事件名称的前缀，使用最长匹配规则。 Event rules栗子： event \"\" { policy = \"read\" } event \"deploy\" { policy = \"write\" } Key/Value Rules 键值策略控制对KV API中的键值存储操作的访问。 Key规则栗子： key \"\" { policy = \"read\" } key \"foo\" { policy = \"write\" } key \"bar\" { policy = \"deny\" } List Policy for Keys 一个新的键列表策略，只有在通过布尔配置参数acl_enable_key_list_policy选择时才会强制执行。 key \"\" { policy = \"deny\" } key \"bar\" { policy = \"list\" } key \"baz\" { policy = \"read\" } Kerring Rules keyring = \"write\" Node Rules node \"\" { policy = \"read\" } node \"app\" { policy = \"write\" } node \"admin\" { policy = \"deny\" } Operator Rules operator = \"read\" Prepared Query Rules query \"\" { policy = \"read\" } query \"foo\" { policy = \"write\" } \r\r","date":"2018-04-05","objectID":"/consul/:26:4","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"引导数据中心 Bootstrapping a Datacenter 在Consul集群可以开始为请求提供服务之前，必须选在Server节点作为leader。Bootstrapping是将这些初始Server节点加入集群的过程。 建议的引导方式是使用-bootstrap-expect配置项。此配置项告知Consul预期的Server节点数，并在有许多Server可用时自动引导。为了防止不一致和脑裂情况(多个Server认为自己是leader)，所有Server应该指定相同的-bootstrap-expect，或根本不指定任何值。只有指定值的Server才会尝试引导集群。为了防止脑裂情况，Server不会选举自己作为leader。 推荐每个数据中心使用3或5台Server。不建议使用单个服务器部署数据中心。 加入一个集群: #On NodeB consul join NodeA \r","date":"2018-04-05","objectID":"/consul/:27:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"创建集群 要触发选举leader，必须将这些机器连接在一起并创建一个集群。 使用-join和start_join选项手动指定机器列表 使用-retry-join选项手动指定机器列表 \r\r","date":"2018-04-05","objectID":"/consul/:27:1","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"leader选举 使用Consul构建客户端的领导选举。 有多种方式建立领导选举，我们将专注于Consul sessions。会话允许我们构建一个可以优雅地处理故障的系统。 协调节点 Contending Nodes 假设一组节点试图称为给定服务的领导者，参与的所有节点应该就给定的键进行协调。 servece/\u003cservice name\u003e/leader 首先创建会话： curl -X PUT '{ \"Name\": \"dbservice\" }' http://localhost:8500/v1/session/create 这回返回一个JSON对象的session ID 下一步是使用?acquirre=\u003csession\u003e查询参数的KV条目上的PUT方法从此节点获取给定键的会话。PUT的\u003cbody\u003e应该是表示本地节点的JSON对象。 curl -X PUT -d \u003cbody\u003e http://localhost:8500/v1/kv/\u003ckey\u003e?acquire=\u003csession\u003e 如果返回true，则已获得锁定，并且本地节点时领导者 如果返回false，则某个其它节点已获取锁定 通过对\u003ckey\u003e的阻塞查询来监视更改，如果注意到\u003ckey\u003e的session是空白的，那么就没有领导者，我们应该重新锁定获取。 如果领导是自愿下台，这应该通过简单地释放锁来完成： curl -X PUT http://localhost:8500/v1/kv/\u003ckey\u003e?release=\u003csession\u003e 发现一个领导者 Discovering a Leader 关于领导者选举的另一种常见做法是节点希望识别给定服务的领导者。 与领导者选举一样，所有参与的节点都应该同意用于协调的密钥(key)。 Client有一个非常简单的角色，它们只需阅读\u003ckey\u003e来发现当前的领导者是谁: curl http://localhost:8500/v1/kv/\u003ckey\u003e 如果密钥没有关联的话，就没有领导者。 你可查询/v1/session/info获取session详细信息： curl http://localhost:8500/v1/session/info/xxxxxxxxxxx Client还应使用阻塞查询来查看密钥的更改，如果领导者退出或失败将清除与密钥相关联的会话。当选出新的领导者时，密钥值也将更新。 \r\r \rAPI 文档链接: https://www.consul.io/api/index.html Consul的主要接口是RESTful HTTP API。API可对node，service，check，configuration…执行基本的CRUD操作。 版本前缀 Version Prefix 所有API路由都以/v1/为前缀，这适用于v1 API。 \r\r \rconsul-template Consul Template 查询consul instance，并更新文件系统上任意数量的指定模板。作为额外的奖励，Consul Template可以在模板更新完成时执行任意命令。 Consul Tempalte可以查询Consul中的服务条目，keys, key values。强大的抽象和模板查询语言是Consul Template非常适合创建动态配置。 如： Apache Nginx HAproxy \r\r","date":"2018-04-05","objectID":"/consul/:28:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"安装 下载地址: https://releases.hashicorp.com/consul-template/ 步骤： 下载 解压 添加PATH wget https://releases.hashicorp.com/consul-template/0.19.5/consul-template_0.19.5_linux_amd64.tgz tar -xzvf ./consul-template_0.19.5_linux_amd64.tgz mv ./consul-template /bin/ #or mv consul-template /usr/local/bin vim /etc/profile export PATH=$PATH:/usr/local/bin consul-template --version consul-template v0.19.5 (57b6c71) \r\r","date":"2018-04-05","objectID":"/consul/:29:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"用法 官方栗子： https://github.com/hashicorp/consul-template/tree/master/examples consul-template -h ","date":"2018-04-05","objectID":"/consul/:30:0","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"命令行 查询demo.consul.io这个consul实例。 渲染模板： consul-template \\ -template \"/tmp/nginx.ctmpl:/var/nginx/nginx.conf:nginx -s reload\" \\ -template \"/tmp/redis.ctmpl:/var/redis/redis.conf:service redis restart\" \\ -template \"/tmp/haproxy.ctmpl:/var/haproxy/haproxy.conf\" 监听Consul： consul-template -consul-addr=\"consul1:8500\" -consul-addr=\"consul2:8500\" \r","date":"2018-04-05","objectID":"/consul/:30:1","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"配置文件 配置文件使用 HashiCorp Configuration Language编写的。这意味着，配置也是JSON兼容的。 命令行指定的选项优先于配置文件！ mkdir /etc/consul-template vim consul-template.hcl consul-template -config='/etc/consul-template/consul-template.hcl' 配置文件详情： # This denotes the start of the configuration section for Consul. All values # contained in this section pertain to Consul. consul { # This block specifies the basic authentication information to pass with the # request. For more information on authentication, please see the Consul # documentation. auth { enabled = true username = \"test\" password = \"test\" } # This is the address of the Consul agent. By default, this is # 127.0.0.1:8500, which is the default bind and port for a local Consul # agent. It is not recommended that you communicate directly with a Consul # server, and instead communicate with the local Consul agent. There are many # reasons for this, most importantly the Consul agent is able to multiplex # connections to the Consul server and reduce the number of open HTTP # connections. Additionally, it provides a \"well-known\" IP address for which # clients can connect. address = \"127.0.0.1:8500\" # This is the ACL token to use when connecting to Consul. If you did not # enable ACLs on your Consul cluster, you do not need to set this option. # # This option is also available via the environment variable CONSUL_TOKEN. token = \"abcd1234\" # This controls the retry behavior when an error is returned from Consul. # Consul Template is highly fault tolerant, meaning it does not exit in the # face of failure. Instead, it uses exponential back-off and retry functions # to wait for the cluster to become available, as is customary in distributed # systems. retry { # This enabled retries. Retries are enabled by default, so this is # redundant. enabled = true # This specifies the number of attempts to make before giving up. Each # attempt adds the exponential backoff sleep time. Setting this to # zero will implement an unlimited number of retries. attempts = 12 # This is the base amount of time to sleep between retry attempts. Each # retry sleeps for an exponent of 2 longer than this base. For 5 retries, # the sleep times would be: 250ms, 500ms, 1s, 2s, then 4s. backoff = \"250ms\" # This is the maximum amount of time to sleep between retry attempts. # When max_backoff is set to zero, there is no upper limit to the # exponential sleep between retry attempts. # If max_backoff is set to 10s and backoff is set to 1s, sleep times # would be: 1s, 2s, 4s, 8s, 10s, 10s, ... max_backoff = \"1m\" } # This block configures the SSL options for connecting to the Consul server. ssl { # This enables SSL. Specifying any option for SSL will also enable it. enabled = true # This enables SSL peer verification. The default value is \"true\", which # will check the global CA chain to make sure the given certificates are # valid. If you are using a self-signed certificate that you have not added # to the CA chain, you may want to disable SSL verification. However, please # understand this is a potential security vulnerability. verify = false # This is the path to the certificate to use to authenticate. If just a # certificate is provided, it is assumed to contain both the certificate and # the key to convert to an X509 certificate. If both the certificate and # key are specified, Consul Template will automatically combine them into an # X509 certificate for you. cert = \"/path/to/client/cert\" key = \"/path/to/client/key\" # This is the path to the certificate authority to use as a CA. This is # useful for self-signed certificates or for organizations using their own # internal certificate authority. ca_cert = \"/path/to/ca\" # This is the path to a directory of PEM-encoded CA cert files. If both # `ca_cert` and `ca_path` is specified, `ca_cert` is preferred. ca_path = \"path/to/certs/\" # This sets the SNI server name to use for validation. server_name = \"my-server.com\" } } # This is the signal to listen for to trigger a reload event. The default # value is s","date":"2018-04-05","objectID":"/consul/:30:2","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["middleware"],"content":"模板语法 Consul Template解析文件以 Go Template创作。 Consul Template提供了如下函数： API函数 API函数与远程API进行交互，与Consul等外部服务进行通信。 datacenters 查询Consul目录中的所有数据中心。 {{ datacenters }} #栗子 {{ range datacenters }} {{ . }}{{ end }} #效果 dc1 dc2 ","date":"2018-04-05","objectID":"/consul/:30:3","tags":["consul","服务发现","配置中心"],"title":"Consul","uri":"/consul/"},{"categories":["cncf"],"content":"参考： Docker文档: https://docs.docker.com/ https://blog.csdn.net/sD7O95O/article/details/78623697 https://www.zhihu.com/question/22969309/answer/34030581 环境： CentOS7x86_64 Docker v18.03 \r \r\r概述 Docker是一个开发、shipping、运行应用程序的开放平台。Docker使你能够将应用程序与基础架构(infrastructure)分离开，从而可以快速交付软件。借助Docker，你可以像管理应用程序一样管理基础架构。利用Docker的方法快速进行运输、测试和部署代码，可以显著缩短编写代码和在生存环境中运行代码之间的延迟。 ","date":"2018-03-27","objectID":"/docker/:0:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"Docker平台 Docker提供了在称为容器的松散隔离(isolated)环境中 打包和运行应用程序的能力。隔离性和安全性允许你在给定的主机上同时运行多个容器。容器是轻量级(lightweight)的，因为它们不需要hypervisor的额外负载，而是直接使用主机的内核运行。这意味着，与使用虚拟机相比，你可以在给定的硬件组合上运行更多的容器。你甚至可以在虚拟主机中运行Docker容器。 Docker提供了工具和平台来管理容器的生命周期(lifecycle)： 使用容器开发应用程序及其支持组件 容器成为分发和测试你应用程序的单元 准备好后，将你的应用程序部署到生产环境中，作为容器协调服 ","date":"2018-03-27","objectID":"/docker/:1:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"Docker引擎 Docker引擎是一个包含如下部件的client-server应用程序： Server是称为守护进程的dockerd REST API是指定程序可用于与守护进程进行通信并指示其执行操作的接口 Client是command line interface(CLI) Docker的开源许可协议是Apache2.0 ","date":"2018-03-27","objectID":"/docker/:2:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"能用Docker做什么 快速、一致的交付应用程序 通过允许开发人员在 提供应用程序和服务的本地容器 的标准化环境 下工作，Docker简化了开发生命周期。容器非常适合**持续集成(continuous intergration,CI)和持续交付(continuous deliver,CD)**工作流程。 考虑如下示例场景： 开发者在本地编写代码，并使用Docker容器分享工作给他们的同事 使用Docker将应用程序push到测试环境，并自动执行和手动测试 当开发人员发现bug，他们能在开发环境中修复bug，并重新部署应用程序到测试环境进行测试和验证 测试完成后，向客户提供修补的应用程序 与将更新的image push到生产环境一样简单 响应式部署和伸缩 Docker的基于容器的平台支持高度可移植的工作负载。Docker container可以运行在笔记本、物理机、虚拟机、云平台… Docker的可移植性和轻量化特性也使得动态管理工作负载非常容易，可以近乎实时地按业务需求扩展或拆分应用程序和服务 在同一硬件上运行更多的工作负载 Docker轻量且快速。它为基于hypersior的虚拟机提供了一种可行、经济高效的替代方案，因此你可以使用更多计算容量来实现业务目标。Docker是高密度环境和中小型部署的理想选择，你需要用更小的资源做更多的事情。 ","date":"2018-03-27","objectID":"/docker/:3:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"Docker架构 Docker使用了client-server的体系架构。客户端向守护进程发送消息，守护进程负责构建、运行和分发 Docker容器。客户端和守护进程可以在同一系统上运行，也可将客户端连接到远程的Docker守护进程。客户端和守护进程使用REST API，通过Unix socket或network interface进程通信。 ","date":"2018-03-27","objectID":"/docker/:4:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"Docker daemon Docker daemon(dockerd)，监听Docker API请求并管理Docker对象——image、container、network、volume。 docker daemon还可与其它docker daemon通信来管理docker service。 ","date":"2018-03-27","objectID":"/docker/:4:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"Docker client Docker client(docker)是许多Docker用户与Docker进行交互的主要方式。客户端将命令发送给守护进程，守护进程执行命令。 Docker命令使用Docker API，Docker客户端可与多个守护进程进行通信。 ","date":"2018-03-27","objectID":"/docker/:4:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"Docker registry Docker registry存储Docker image。Docker Hub和Docker Cloud是任何人都可使用的public registry，你可以创建private registry。 docker pull或docker run需要的image便是从配置的registry中提取。docker push推送image到你配置的registry。 ","date":"2018-03-27","objectID":"/docker/:4:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"Docker对象 当你使用Docker时，你会创建和使用 image、container、network、volume、plugin和其它对象。 ","date":"2018-03-27","objectID":"/docker/:5:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"image 镜像是一个只读模板，带有创建Docker容器的说明。通常，镜像基于其它镜像，并具有一些额外的自定义功能。 例如，你可构建基于Ubuntu镜像的镜像，但会按照ApacheWeb服务器和应用程序，以及应用程序所需的配置。 你可能创建自己的镜像，或使用由别人创建并推送到registry上的镜像。构建自己的镜像，需要使用简单的语法创建一个Dockerfile，以定义创建镜像并运行它所需的步骤。 ","date":"2018-03-27","objectID":"/docker/:5:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"container 容器是镜像的可运行实例。可将容器连接到一个或多个网络，将存储器连接到它，还可根据当前状态创建新镜像。 默认情况下，容器与其它容器以及主机是相对隔离的。你可以控制容器的网络、存储、其它底层子系统与其它容器或主机的隔离程度。 容器由镜像定义，以及你在创建或启动时提供给它的任何配置选项。当一个容器被移除时，其未被存储在永久存储器中的状态会消失。 栗子： #运行一个Ubuntu镜像，交互地连接到本地命令会话 docker run -i -t ubuntu /bin/bash 以上命令会发生如下步骤: 如果本地没有Ubuntu镜像，docker会从registry拉取，就好像你手动运行 docker pull ubuntu Docker创建一个新容器，就好像你手动执行docker container create Docker分配一个读写文件系统给容器，作为它的最后一层 如果你没有指定任何网络选项，Docker会创建一个网络接口将容器连接到默认网络。 Docker开启容器并执行/bin/bash 发送exit到/bin/bash，容器停止但并未被移除 ","date":"2018-03-27","objectID":"/docker/:5:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"service 服务允许你伸缩多个Docker守护进程的容器，这些守护进程可以作为一个swarm与多个manager和worker一起工作。默认情况下，该服务在所有node之间进行负载均衡。 ","date":"2018-03-27","objectID":"/docker/:5:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"底层技术 Docker使用GO编写，利用Linux内核的几个特性来提供其功能。 namespace Docker使用一个称为namespace的技术来提供称为容器的独立工作空间。当你运行一个容器时，Docker会为该容器创建一组命名空间。 命名空间提供了一个隔离层。容器的每个方面都在单独namespace中运行，并且其访问权限仅限于该单独的namespace。 Docker引擎在Linux上使用如下namespace： pid namespace： 进程隔离 net namespace： 管理网络接口 ipc namespace： 管理对IPC(InterProcess Communication)资源的访问 mnt namespace： 管理文件系统挂载点 ust namespace： 隔离内核和版本标识符(Unix Timesharing System) control groups Linux上的Docker Engine也依赖与另一种称为控制组(cgroups)的技术。cgroup将应用程序限制为一组特定的资源。控制组允许Docker引擎将可用的硬件资源共享给容器，并可选地强制实施限制和约束。 例如，你可限制特定容器的内存是CPU使用率等。 union file systems union file systems(UnionFS)，是通过创建layer进行操作的文件系统，使得它们非常轻量和快速。Docker引擎使用UnioFS为容器提供构建block。Docker引擎可以使用多种UnionFS变体，包括AUFS, brrfs, vfs, DeviceMapper… container format Docker引擎将namespace、cgroup、UnionFS组合成一个名为容器格式的包装器。默认的容器格式为libcontainer。 \r 安装 Docker有两个可获取的版本： Community Edition(CE) 适合开始使用Docker并尝试基于容器的应用程序的开发人员和小型团队 Enterprise Edition(EE) 专为企业开发和IT团队而设计，可以在生产规模上构建，发布和运行关键业务应用程序 \r","date":"2018-03-27","objectID":"/docker/:5:4","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"CentOS7安装Docker CE ","date":"2018-03-27","objectID":"/docker/:6:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"OS要求 CentOS7.x centos-extras repository 推荐使用overlay2存储驱动 安装新版本Docker需卸载老版本Docker Docker CE包被称为docker-ce ","date":"2018-03-27","objectID":"/docker/:6:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"安装Docker CE https://download.docker.com/ 多种安装方法： Docker’s repository RPM package scripts \r使用repository安装： #安装依赖 yum install -y yum-utils device-mapper-persistent-data lvm2 #设置repository yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo #安装Docker CE yum install -y docker-ce #Docker安装但未启动，docker group会被创建，但没有用户添加到组中 #在生产环境中，你可能需要安装特定版本的Docker CE，而不是最新版 yum list docker-ce --showduplicates | sort -r yum search docker-ce --showduplicates #开启docker systemctl start docker #测试docker docker run hello-world #此命令下载一个测试image并将其运行到container中 #Hello from Docker! 使用package安装： #下载rpm包 https://download.docker.com/linux/centos/7/x86_64/stable/Packages/ #安装 yum install -y /path/docker-cexxx.rpm systemctl start docker docker run hello-world \r使用scripts安装： curl -fsSL get.docker.com -o get-docker.sh sh get-docker.sh #手动添加group合user usermod -aG docker your-user \r","date":"2018-03-27","objectID":"/docker/:6:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"卸载Docker CE yum remove docker-ce #默认文件 rm -rf /var/lib/docker #你还需要手动删除其它配置文件 \r 开始 \r","date":"2018-03-27","objectID":"/docker/:6:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"关于Docker Docker文档会有如下讲解： 设置你的Docker环境 在一个容器(container)中构建并运行一个镜像 延伸你的APP以便在多个容器中运行 在整个集群中分配你的APP 通过添加后端数据库来堆栈服务 将应用部署到生产 ","date":"2018-03-27","objectID":"/docker/:7:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"Docker的概念 Docker是开发人员，系统管理员使用容器来开发、部署和运行APP的平台。使用Linux容器来部署APP被称为集装箱化(containerzation) 集装箱受欢迎的几点原因： 灵活(flexible) 轻量(lightweight) 通用(Interchangeable) 可移植(portable) 延伸(scalable) 堆栈(stackable) ","date":"2018-03-27","objectID":"/docker/:7:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"镜像和容器 通过运行镜像(image)启动容器(container)。镜像是一个可执行包，包含运行APP所需的所有内容：代码，库，环境变量，配置文件… 容器是镜像的运行时(runtime)实例。在Linux上使用docker ps命令查看运行的容器列表。 ","date":"2018-03-27","objectID":"/docker/:7:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"容器和虚拟机 容器在Linux本地上运行，并与其它容器共享主机Kernel。它是一个独立的进程，不占其它可执行文件内存，使其轻量化。 虚拟机(VM)运行一个完整的访客操作系统，通过虚拟机管理程序访问主机资源。一般来说，虚拟机比大多数应用程序需要的资源更多。 \r","date":"2018-03-27","objectID":"/docker/:7:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"准备Docker环境 Docker版本： CE: Docker Community Edition EE: Docker Enterprise Edition Install Docker ","date":"2018-03-27","objectID":"/docker/:7:4","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"测试Docker docker --version #查看详细信息 docker info #测试安装工作是否正常 docker run hello-world #查看镜像 docker image ls #列出容器 docker container ls -all #docker命令 docker docker container --help ","date":"2018-03-27","objectID":"/docker/:8:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"小结 集装箱化使得CI/CD无缝： 持续集成(Continuous integration, CI) 持续部署(continuous deployment, CD) APP无系统依赖 更新能够推送到分布式APP的任何部分 资源密度可以被优化 使用Docker，扩展APP的过程就是启动新的可执行文件，而不是运行繁重的VM主机。 \r","date":"2018-03-27","objectID":"/docker/:8:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"容器 Container ","date":"2018-03-27","objectID":"/docker/:9:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"先决条件 docker run hello-world \r","date":"2018-03-27","objectID":"/docker/:9:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"介绍 是时候使用Docker方式来构建一个APP了。 从应用程序的层次结构底部开始，这是一个容器(container) 在此级别之上，是一个服务(service)，它定义了容器在生产中的表现 最后，顶层是堆栈(stack)，定义所有服务的交互(interaction) Like this: Stack Service Container ","date":"2018-03-27","objectID":"/docker/:9:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"新开发环境 在过去，如果你要开始编写一个Python APP，你的第一要务是在你的机器运行时安装Python。但是，这会造成你的计算机上的环境，需要如预期般完美适合你的APP，并且还需要与你的生产环境相匹配。 使用Docker，你可以将一个可移植的Python运行时作为一个image，无需安装。接着，你的构建可以将基础Python image与APP代码一起包含在内，确保你的APP，依赖项…都构建一起。 ","date":"2018-03-27","objectID":"/docker/:9:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"使用Dockerfile定义一个容器 Dockerfile定义了容器内环境中发生的事情。访问的网络接口(network interface)和磁盘驱动(disk driver)等资源是在此环境中虚拟化的(virtualized)，与系统其余部分隔离。因此你需要将端口映射(map port)到外部世界，并明确指定要将哪些文件复制到此环境中。但是，在完成这些后，你完全可以将它们看做一致 —— 在Dockerfile中定义的构建的APP的行为与它运行时的行为完全相同。 Dockerfile 创建一个空目录，并创建一个名叫Dockerfile的文件，复制以下内容： # Use an official Python runtime as a parent image FROM python:2.7-slim # Set the working directory to /app WORKDIR /app # Copy the current directory contents into the container at /app ADD . /app # Install any needed packages specified in requirements.txt RUN pip install --trusted-host pypi.python.org -r requirements.txt # Make port 80 available to the world outside this container EXPOSE 80 # Define environment variable ENV NAME World # Run app.py when the container launches CMD [\"python\", \"app.py\"] 注意代理服务器会阻断你与APP的连接！ 这个Dockerfile引用了一些我们还没有创建的文件，分别是app.py和requirements.txt。接下来创建它们。 ","date":"2018-03-27","objectID":"/docker/:9:4","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"APP自身 创建另外的文件，如上面的app.py和requirements.txt，并将它们与Dockerfile放置于同一目录下。这就完成了我们的APP，这看起来非常简单。当这个Dockerfile被构建成一个image时，由于Dockerfile的ADD命令，app.py和requirements.txt仍然存在，而且由于使用了EXPOSE命令，app.py的输出仍可以通过HTTP访问。 **requirements.txt: ** Flask Redis **app.py: ** from flask import Flask from redis import Redis, RedisError import os import socket # Connect to Redis redis = Redis(host=\"redis\", db=0, socket_connect_timeout=2, socket_timeout=2) app = Flask(__name__) @app.route(\"/\") def hello(): try: visits = redis.incr(\"counter\") except RedisError: visits = \"\u003ci\u003ecannot connect to Redis, counter disabled\u003c/i\u003e\" html = \"\u003ch3\u003eHello {name}!\u003c/h3\u003e\" \\ \"\u003cb\u003eHostname:\u003c/b\u003e {hostname}\u003cbr/\u003e\" \\ \"\u003cb\u003eVisits:\u003c/b\u003e {visits}\" return html.format(name=os.getenv(\"NAME\", \"world\"), hostname=socket.gethostname(), visits=visits) if __name__ == \"__main__\": app.run(host='0.0.0.0', port=80) 在容器内访问主机的名称将检索容器ID，这进程ID类似。 仅此而已，在你的系统中，你不需要任何Python或requirements.txt文件，也不需要在你的系统上安装 构建或运行的image。看起来你并没有真正用Python和Flask建立一个环境，但是你确实已经拥有了。 ","date":"2018-03-27","objectID":"/docker/:9:5","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"构建APP 我们准备去构建(build)APP。确保你仍在目录的顶层。 #查看是否还在顶层 ls Dockerfile app.py requirements.txt #在此目录运行build命令，这将创建一个Docker image，用 -t 命名 docker build -t friendlyhello . #查看你build的image docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE friendlyhello latest b24e21d7645f 13 minutes ago 150MB #运行APP docker run -p 4000:80 friendlyhello #测试 curl http://localhost:4000 links http://localhost:4000 #在后台运行 docker run -d -p 4000:80 friendlyhello #查看容器 docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 146662dca737 friendlyhello \"python app.py\" 16 seconds ago Up 16 seconds 0.0.0.0:4000-\u003e80/tcp goofy_chaplygin #停止 Ctrl + C docker container stop docker-ID docker container stop 146662dca737 端口重映射4000:80是为了证明Dockerfile中的EXPOSE与使用docker run -p发布的内容之间的区别。 在后续步骤中，我们只需将主机的80端口映射到容器的80端口就好。 ","date":"2018-03-27","objectID":"/docker/:9:6","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"分享你的image 为了演示刚才创建的image的可移植性(portability)，让我们上传build的image并在其它地方run它。毕竟，当你需要将container部署到生产环境时，你需要知道如何push注册。 注册表(registry)是一个repository的集合，而repository是image的集合——有点类似于GitHub repository，但代码是已经构建了的。 注册表上的账户可以创建许多repository。docker CLI 默认使用Docker’s public registry。你也可以选择其它注册表，或创建自己的注册表。 使用Docker ID登录： 如果没有Docker账户，请先注册 \u003ccloud.docker.com\u003e。 docker login docker login -u zhang21 #时候docker login认证过后，会有~/.docker/config.json文件，里面包含了docker认证信息 #k8s可使用此信息添加secret cat ~/.docker/config.json { \"auths\": { \"https://index.docker.io/v1/\": { \"auth\": \"base64encoding\" } }, \"HttpHeaders\": { \"User-Agent\": \"Docker-Client/18.03.1-ce (linux)\" } 标记image： 使用username/repository:tag将本地image与registry中的repository相关联。tag是可选的，但推荐使用tag。因为它是注册管理机构用于为Docker image提供版本的机制。为该内容提供一个有意义的repository和tag，例如get-started:part2。 docker tag image username/repository:tag #例子 docker tag friendlyhello zhang/test:tag-test #查看tag docker images ls 发布image： #上传你标记了的image到repository docker push username/repository:tag docker push zhang21/test:tag-test #完成后，此image便可以公开获取 从远处repository拉取并运行image： 无论在哪里执行docker run，它都会将你的image以及Python和所有依赖关系一起拉取下来，并运行你的代码。 docker run -p 4000:80 username/repository:tag docker run -p 80:80 zhang21/test:tag-test ","date":"2018-03-27","objectID":"/docker/:9:7","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"本节基础命令 #从Dockerfile创建image docker build -t image-name . #运行image docker run -p 4000:80 image-name #后台运行 docker run -d -p 4000:80 image-name #列出运行的容器 docker container ls #列出所有容器，包括未运行 docker container ls -a #优雅停止容器 docker container stop 容器ID #强制停止 docker container kill 容器ID #删除容器 docker container rm 容器ID #删除所有容器 docker container rm $(docker container ls -a -q) #列出镜像 docker image ls #列出所有镜像 docker image ls -a #删除镜像 docker image rm 镜像ID #删除所有镜像 docker image rm $(docker image ls -a -q) #登录 docker login #标记 docker tag 镜像 username/repository:tag #上传到注册表 docker push username/repository:tag #从注册表拉取 docker run username/repository:tag \r","date":"2018-03-27","objectID":"/docker/:9:8","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"服务 service ","date":"2018-03-27","objectID":"/docker/:10:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"先决条件 安装Docker 获取Docker Compose 阅读Orientation 阅读Container 确保已发布friendlyhello image到你的registry 确保你的image工作为一个部署的container。docker run -p 80:80 username/repo:tag ","date":"2018-03-27","objectID":"/docker/:10:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"介绍 在此，我们扩展(scale)APP并启用负载均衡(load balancing)。要做到这样，我们必须在分布式(distributed)应用程序的层次结构中升一级: 服务 Stack Service Container ","date":"2018-03-27","objectID":"/docker/:10:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"关于服务 在分布式应用程序中，应用程序的不同部分称为服务(service)。 例如，一个视频共享站点。那么它可能包含： 用于将应用程序数据 存储到数据库中的服务 用户上传后的视频转码服务 前端服务 … 服务是真正的生产环境中的容器。一个service只运行一个image，但它可修改image的运行方式 —— 哪个端口、容器应该运行多少个副本以便于服务所需的容量等. 伸缩服务会更改运行该软件的容器实例数量，从而为进程中的服务分配更多的计算资源。 在Docker平台上定义、运行和伸缩服务都是很简单的 —— 只需修改docker-compose.yml文件。 ","date":"2018-03-27","objectID":"/docker/:10:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"你的第一个docker-compose.yml文件 docker-compose.yml是一个YAML文件，它定义了Docker container在生产中的行为方式。 docker-compose.yml： 将如下信息保存为docker-compose.yml，确保你已经pushed the image到registry，并通过修改.yml文件的image detail来替换username/repo:tag。 version:\"3\"services:web:# replace username/repo:tag with your name and image detailsimage:username/repo:tagdeploy:replicas:5resources:limits:cpus:\"0.1\"memory:50Mrestart_policy:condition:on-failureports:- \"80:80\"networks:- webnetnetworks:webnet: docker-compose.yml文件告诉Docker之下如下操作： pull the image Run 5 instances of that image as a service called web 限制每个实例最多使用10%的CPU和50MB的RAM 如果一个失败，马上重启container 映射主机的80端口到web的80端口 指示web container通过称为webnet的负载均衡网络共享80端口 使用默认设置定义webnet网络 ","date":"2018-03-27","objectID":"/docker/:10:4","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"运行你的负载均衡APP docker swarm init #运行并设置APP名字 docker stack -c docker-compose.yml app-name docker stack -c docker-compose.yml LoadBalance #在一个主机上，单个服务栈通过部署的image运行5个container instance #获取service ID docker service ls ID NAME MODE REPLICAS IMAGE PORTS 3d1a48yse0t4 LoabBalance_web replicated 5/5 zhang21/test:tag-test *:80-\u003e80/tcp #查看服务中的任务 docker service ps app-name_web docker container ls -q #5个容器ID c7ce0075890e 52ba026bf28c 6d4381be438f bd297a42e89d 357b05cc38eb #访问的时候容器ID会在此5个负载中变化 在服务中运行的单个container称为任务(task)。任务是具有数字增量的唯一ID，最大数量是在docker-compose.yml中定义的副本数量。 ","date":"2018-03-27","objectID":"/docker/:10:5","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"伸缩APP 通过修改docker-compose.yml中replicas的值，并重新运行docker stack deploy -c xxx app-name来伸缩APP。 Docker执行就地更新，不需要stack down或kill any containers. 卸下APP和swarm： #app docker stack rm app-name docker stack rm LoadBalance #swarm docker swarm leave --force 使用Docker扩展APP非常简单。 ","date":"2018-03-27","objectID":"/docker/:10:6","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"本节命令 #列出栈或APP docker stack ls #运行指定配置文件 docker stack deploy -c \u003ccomposefile\u003e \u003cappname\u003e #列出与APP相关联的服务 docker service ls #列出与APP相关联的任务 docker service ps \u003cservice\u003e #检查任务 docker inspect \u003ctask or container\u003e #列出容器ID docker container ls -q #除掉APP docker stack rm \u003cappname\u003e #从管理中除掉一个单一节点swarm docker swarm leave --force \r","date":"2018-03-27","objectID":"/docker/:10:7","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"swarm ","date":"2018-03-27","objectID":"/docker/:11:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"先决条件 前面几个小节的内容 ","date":"2018-03-27","objectID":"/docker/:11:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"介绍 前面你将一个服务运行在生产环境，并扩展为5个副本进程。 在此，你将APP部署到到集群上，并在多台机器上运行它。通过将多台主机连接到成为swarm的Dockerized集群，使得多容器、多主机应用成为可能。 ","date":"2018-03-27","objectID":"/docker/:11:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"理解swarm集群 swarm是一组运行Docker并加入到集群中的机器。这样以后，你可以在集群的swarm manager上执行Docker命令。swarm中的机器可以是物理的或虚拟的，当他们加入swarm后，他们便被成为node。 swarm manager可以使用多种策略来运行容器，你可在compose file中指定相应的策略。 swarm manager是swarm中唯一可以执行命令、授权其他机器作为工作者加入swarm的机器。工作者(worker)只能在那提供能力(capacity)，并没有权力告诉任何机器能够做什么。 但目前为止，你已经在本机机器上以单主机(single host)模式使用Docker。但Docker也可以切换为swarm(集群)模式，这就是使用swarm的原因。立即启用swarm模式使得当前机器成为swarm manager。从此，Docker将运行在你管理的swarm上执行命令，而不仅仅是在当前机器上执行。 ","date":"2018-03-27","objectID":"/docker/:11:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"建立swarm 一个swarm由多个节点组成，不管它是虚拟机还是物理机。 基本概念很简单，运行docker swarm init来开启swarm模式并使得当前机器成为swarm manager 在其它机器上运行docker swarm join使他们作为worker加入swarm 栗子： 使用VM快速创建两台机器的集群，并将其变为swarm。 使用docker-machine创建一对VM: #CentOS7 #安装VirtualBox wget https://download.virtualbox.org/virtualbox/5.2.8/VirtualBox-5.2-5.2.8_121009_el7-1.x86_64.rpm \u0026\u0026 yum install -y Virtual.xx.rpm #安装docker-machine curl -L https://github.com/docker/machine/releases/download/v0.14.0/docker-machine-`uname -s`-`uname -m` \u003e/tmp/docker-machine \u0026\u0026 install /tmp/docker-machine /usr/local/bin/docker-machine #在BIOS中开启虚拟化支持 #在VMware中开启虚拟化支持(如果是VM) docker-machine create --driver virtual myvm1 docker-machine create --driver virtual myvm2 #列出虚拟机 docker-machine ls \r初始化swarm并添加node 第一台机器作为swarm manager，执行命令和join认证，后面的机器作为worker。 你可以使用docker-machine ssh发送命令到VM。在swarm mananger上执行docker swarm init初始化： docker-machine ssh \u003cswarm manager\u003e \"docker swarm init --advertise-assr \u003cmananger-IP\u003e\" #add worker docker swarm jion --toker \u003ctoken\u003e \u003cwroker-ip\u003e:\u003cport\u003e #添加manager docker swarm join-token manaer 由于我的虚拟的无法使用VT，因此我用的两台机器两个Docker来做swarm。 #初始化这台机器默认为manager docker swarm init #作为worker加入，ip是manager的 #以下信息会在manager初始化时生成 #注意防火墙，可能会阻碍加入 docker swarm join --toker \u003ctoker\u003e \u003cip:port\u003e docker swarm join --token token-xxxxxxxxxxxxxxxxxx 172.16.129.150:2377 #查看swarm docker node ls #离开swarm docker swarm leave \r","date":"2018-03-27","objectID":"/docker/:11:4","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"在swarm集群上部署APP 主需要记住，只有swarm manager才能执行docker命令，worker仅仅是容量(capacity)。 在swarm manager上使用docker-composr.yml和docker stack deploy命令来部署APP。使用docker service ps \u003cservice name\u003e来验证部署。 #在manager部署 docker stack deploy -c ./docker-compose.yml LoadBalance docker service ls docker stack ls #注意node名 docker stack ps LoadBalance ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS 6nrn4mwc6pvt LoadBalance_web.1 zhang21/test:tag-test zhang22 Running Preparing 2 minutes ago bpssrnzesl7n LoadBalance_web.2 zhang21/test:tag-test zhang22 Running Preparing 2 minutes ago kmhd8p5wkc12 LoadBalance_web.3 zhang21/test:tag-test zhang21 Running Running 2 minutes ago i0pkf4foms87 LoadBalance_web.4 zhang21/test:tag-test zhang22 Running Preparing 2 minutes ago rvtpjk781frn LoadBalance_web.5 zhang21/test:tag-test zhang21 Running Running 2 minutes ago #分别访问个主机的IP #创建的网络在它们之间共享并负载均衡 links ip1 links ip2 两个IP地址工作的原因是集群中的节点参与入口(ingress)路由网络(routing mesh)。这可以确保部署在swarm中某个端口的服务始终将该端口保留给自己，而不管实际运行容器的节点是什么。 ","date":"2018-03-27","objectID":"/docker/:11:5","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"清理并重启 docker stack rm LoadBalance \r","date":"2018-03-27","objectID":"/docker/:11:6","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"stack 先决条件，已完成前面的步骤。 ","date":"2018-03-27","objectID":"/docker/:12:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"介绍 你已到达分布式应用程序层次结构的顶端——stack。堆栈是一组相互关联的服务，它们可以共享依赖关系，并可以进行协调和缩放。单个堆栈能够定义和协调整个应用程序的功能(尽管非常复杂的应用程序可能需要使用多个堆栈)。 在前面使用的docker deploy——是运行在单主机上的单个服务堆栈，这通常不会发生在生产环境中。在这里，你会使用学到的东西使多个服务相互关联，并在多台机器上运行它们。 ","date":"2018-03-27","objectID":"/docker/:12:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"添加一个新服务并部署 docker-compose2.yml version: \"3\" services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 restart_policy: condition: on-failure resources: limits: cpus: \"0.1\" memory: 50M ports: - \"80:80\" networks: - webnet #可视化 visualizer: image: dockersamples/visualizer:stable ports: - \"8080:8080\" volumes: - \"/var/run/docker.sock:/var/run/docker.sock\" deploy: placement: constraints: [node.role == manager] networks: - webnet networks: webnet: 新增的东西使web对等服务，称为visualizer。注意两个事： volumes: 给予visualizer访问主机Docker的socket文件 placement： 确保服务运行在manager而不是worker上 docker stack deploy -c ./docker-compose2.yml stack-test Creating network stack-test_webnet Creating service stack-test_visualizer Creating service stack-test_web #查看visualizer，要等一会才能正常访问，别着急 访问 IP:8080 ","date":"2018-03-27","objectID":"/docker/:12:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"持久化数据 让我们再次通过相同的工作流程来添加用于存储应用程序数据的Redis数据库。 docker-compose3.yml，添加一个Redis服务器： version: \"3\" services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 restart_policy: condition: on-failure resources: limits: cpus: \"0.1\" memory: 50M ports: - \"80:80\" networks: - webnet visualizer: image: dockersamples/visualizer:stable ports: - \"8080:8080\" volumes: - \"/var/run/docker.sock:/var/run/docker.sock\" deploy: placement: constraints: [node.role == manager] networks: - webnet redis: image: redis ports: - \"6379:6379\" volumes: - \"/home/docker/data:/data\" deploy: placement: constraints: [node.role == manager] command: redis-server --appendonly yes networks: - webnet networks: webnet: #部署 docker stack deploy -c docker-compose3.yml redis-test #测试 访问 IP:port Redis是一个Docker library中的官方image，并被授予redis镜像名称。 redis规范中有几件事使数据在这个堆栈的部署之间持续存在： redis运行在manager，所以它总是使用相同的文件系统 redis将数据存储在上面的目录 确保redis服务始终使用相同的主机 确保存储的数据的连续性 如果没有创建，redis会将数据存储在容器文件系统的/data中，如果该容器被重新部署，则数据将被清除。 \r","date":"2018-03-27","objectID":"/docker/:12:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"部署APP 先决条件为前面的操作步骤。 ","date":"2018-03-27","objectID":"/docker/:13:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"介绍 compose file在生产环境中的效果与在您的计算机上的效果相同。 ","date":"2018-03-27","objectID":"/docker/:13:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"选择版本 我安装的是社区版(ce)。如果你在生产环境中使用docker-ce，则可以使用Docker Cloud帮助管理你的应用程序，如AWS、Aliyun、腾讯云。 docker cloud： \u003ccloud.docker.com\u003e, 可注册后建立、上传、管理自己的repo。 设置和部署： 连接Docker Cloud并授权它自动为你配置Dockerize VM 使用Docker Cloud创建你的计算资源和swarm 部署应用程序 ","date":"2018-03-27","objectID":"/docker/:13:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"连接DockerCloud 你可以标准模式或swarm模式运行Docker Cloud。 AWS配置指南 Aliyun配置指南 腾讯云配置指南 ","date":"2018-03-27","objectID":"/docker/:13:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"创建swarm 你可在Docker Cloud UI创建你的node，或docker swarm init|join命令。 ","date":"2018-03-27","objectID":"/docker/:13:4","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"在云提供商上部署应用程序 我觉得阿里云和腾讯云也有对应的平台。 运行部署命令: docker stack deploy -c xxx.yml \u003ccus_appname\u003e，现在你的APP就运行在云提供商上。 运行swarm命令来验证部署 docker node ls docker service ls docker service ps \u003cservice\u003e 在云提供商开放端口 service | type | protocol | port | - | - | - web | http | tcp | 80 visualizer | http | tcp | 8080 redis | tcp | tcp | 6379 具体操作参见各云提供商。 ","date":"2018-03-27","objectID":"/docker/:13:5","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"迭代和清理 改变*.yml文件伸缩应用程序 使用docker stack deploy部署应用程序 push和pull image 使用docker stack rm \u003cname\u003e清除stack \r","date":"2018-03-27","objectID":"/docker/:13:6","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"修改Docker默认路径 docker默认的目录为/var/lib/docker，但很多时候/var目录并没有单独挂载，可能导致空间不够。 前提是你已经把源配置目录对应的文件拷贝到替换的目录。 方法1： systemctl stop docker cd /etc/docker vim daemon.json { \"graph\": \"/opt/docker\" } systemctl start docker #systemctl reload docker #查看变更 docker info 方法2: systemctl stop docker cd /etc/sysconfig/ vim docker-storage DOCKER_STORAGE_OPTIONS=--graph=/opt/docker systemctl start docker #查看变更 docker info \r","date":"2018-03-27","objectID":"/docker/:14:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"容器服务自启动 在运行docker容器时可以加如下参数来保证每次docker服务重启后容器也自动重启: docker run --restart=always -d -p 80:80 \u003ccontainer-id\u003e #对于已启动的容器服务，更新它 docker update --restart=always \u003ccontainer-id\u003e \r","date":"2018-03-27","objectID":"/docker/:15:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"交互式容器 进入Docker容器以获得交互式体验。 docker exec -it \u003ccontainer\u003e /bin/bash docker exec -it \u003ccontainer\u003e /bin/sh \r\r","date":"2018-03-27","objectID":"/docker/:16:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"使用systemd 默认情况下，容器是不直接支持使用systemd的。可在运行容器时添加选项来使用systemd。 #centos:7 docker run -dit --privileged --name=centos7-systemd centos:7 init \r","date":"2018-03-27","objectID":"/docker/:17:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"日志 docker服务日志： journalctl -u docker.service docker容器日志： \u003cdocker-graph\u003e/containers/\u003ccontainer-id\u003e/\u003ccontainer-id\u003e-json.log 由于容器ID会变化，请注意提取容器ID 可使用ELK在此收集容器日志 \r","date":"2018-03-27","objectID":"/docker/:18:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"更新镜像 使用docker commit从改变的容器中生成一个新镜像。 更新镜像步骤： 备份镜像: docker tag 运行镜像 修改容器 生成新镜像: docker commit 推送镜像: docker push \r\r","date":"2018-03-27","objectID":"/docker/:19:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"动态映射端口 如何给运行中的容器添加映射端口。有两种方法: 将运行的容器生成一个新镜像，之后有这个镜像重新映射端口 通过iptables 第一种方法就相当于重新启动一个镜像，在启动时重新映射端口。实在是麻烦。 由于docker 命令设置端口映射其实也就是下发 iptables 规则，所以我们可以直接创建 iptables 规则进行端口流量转发。 #查看本机docker iptabels rules iptables-save #我的一个hexo镜像 #-A DOCKER -d 172.17.0.2/32 ! -i docker0 -o docker0 -p tcp -m tcp --dport 4000 -j ACCEPT #再它在添加一个端口 iptables -t nat -A DOCKER ! -i dokcer0 -p tcp -m tcp --dport 56789 -j DNAT --to-destination 172.17.0.2:56789 ","date":"2018-03-27","objectID":"/docker/:20:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"备份与恢复 ","date":"2018-03-27","objectID":"/docker/:21:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"备份容器 docker commit: 生成新镜像 docker save： 生成本地tar包 Usage: docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] docker commit -m \"Just a test\" -p ${container-id} Zhang21/test:01 docker image ls docker login docker push Usage: docker save [OPTIONS] IMAGE [IMAGE...] [flags] docker save -o /path/${image}.tar ${image} ls /path ","date":"2018-03-27","objectID":"/docker/:21:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"恢复容器 docker run ${image} docker load: 载入本地.tar镜像 Usage: docker load [OPTIONS] docker load -i /path/${image}.tar docker image ls \r","date":"2018-03-27","objectID":"/docker/:21:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"应用场景与注意事项 ","date":"2018-03-27","objectID":"/docker/:22:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"应用场景 本地依赖 搭建环境 微服务 自动测试 部署过程 CI/CD 多租户环境 一台机器的多个APP 弹性伸缩 资源隔离 ","date":"2018-03-27","objectID":"/docker/:22:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"注意事项 一个进程，一个容器 不推荐在Docker容器中运行多个进程！ 不要将数据存放到容器内 所以请使用挂在卷的方式映射到本地磁盘目录 使用磁盘进行数据存储 容器通信 每当一个Docker容器需要与另一个容器通信时，传递信息最好使用名称或环境变量。 以non-root用户运行Docker 默认情况下，Docker容器以root用户身份运行，众所周知，以root用户运行的容器完全可以控制主机系统。 注意容器的体积 选择一个容器的主要原因之一是它的体积小。但是，如果你把它做得更大，它的主要优势就没了。 制定控策略 开发和部署Docker容器不是你的工作的结束。您需要持续监控已部署的容器以及整个系统的运行状况。选择合适的工具并制定一个策略来有效地监控您的Docker容器，以确保最短的停机时间，从而使客户满意。 安全问题 安全补丁、防火墙… \r Dockerfile 参考: https://docs.docker.com/engine/reference/builder/ https://yeasy.gitbooks.io/docker_practice/content/image/build.html 将镜像每一层的修改、安装、配置、操作的命令写入Dockerfile，并用它来构建、定制镜像，那么镜像构建透明性问题便会得到解决。 Dockerfile是一个文本文件，包含了一条条指令(instrction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 \r","date":"2018-03-27","objectID":"/docker/:22:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"使用Dockerfile定制镜像 ","date":"2018-03-27","objectID":"/docker/:23:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"FROM 所谓指定镜像，就是以一个镜像为基础，在其上进行定制。基础镜像必须指定，而FROM就是指定基础镜像，因此一个Dockerfile中FROM是必备的指令，并且必须是第一条指令。 只有有可能，请使用当前官方repo作为你的基础镜像。我们推荐使用Alpine镜像，因为它严格控制，体积小(只有5MB)，同时也是完整的Linux发行版。 Docker Hub中有很多常用的官方镜像——常用软件、常用语言和常用系统镜像。 FROM nginx #特殊镜像，scratch，空白镜像 FROM scratch ","date":"2018-03-27","objectID":"/docker/:23:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"RUN 在多行中使用反斜杠\\或复杂的RUN语句，使Dockerfile更具可读性、易理解性和可维护性。 RUN指令是用来执行命令行命令的。有两种格式： shell格式 RUN \u003cCMD\u003e，就像直接在命令行中输入命令一样 exec格式 RUN [\"可执行文件\", \"参数\"]，这更像函数调用中的格式 FROM debian:jessie RUN apt-get update RUN apt-get install -y gcc libc6-dev make RUN wget -O redis.tar.gz \"http://download.redis.io/releases/redis-3.2.5.tar.gz\" RUN mkdir -p /usr/src/redis RUN tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 RUN make -C /usr/src/redis RUN make -C /usr/src/redis install Dockerfile中的每一个指令都会建立一层，RUN也不例外。每一个RUN的行为，就和手工建立镜像的过程一样 —— 新建立一层，在其上执行这些命令，执行结束后，commit这一层的修改，构成新的镜像。 上面这种写法，创建了7层镜像，这是完全没有意义的，而且很多运行时不需要的东西都被装进了镜像里，比如编译环境和更新的软件包等。结果就会产生非常臃肿、非常多层的镜像，不仅增加了构建部署的时间，也容易出错。这是很多初学Docker的人常犯的一个错误。 UnionFS是Linux、FreeBSD的文件系统服务，UnionFS是有最大层数限制的。 修改后的Dockerfile： FROM debian:jessie RUN buildDeps='gcc libc6-dev make' \\ \u0026\u0026 apt-get update \\ \u0026\u0026 apt-get install -y $buildDeps \\ \u0026\u0026 wget -O redis.tar.gz \"http://download.redis.io/releases/redis-3.2.5.tar.gz\" \\ \u0026\u0026 mkdir -p /usr/src/redis \\ \u0026\u0026 tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \\ \u0026\u0026 make -C /usr/src/redis \\ \u0026\u0026 make -C /usr/src/redis install \\ \u0026\u0026 rm -rf /var/lib/apt/lists/* \\ \u0026\u0026 rm redis.tar.gz \\ \u0026\u0026 rm -r /usr/src/redis \\ \u0026\u0026 apt-get purge -y --auto-remove $buildDeps 仅仅使用一个RUN指令，并使用\u0026\u0026将各指令串联起来。将之前的7层简化为1层。在编写Dockerfile时，要经常提醒自己，这并不是在写shell脚本，而是在定义每一层该如何构建。 Dockerfile支持shell类的换行\\、注释#等格式，良好的格式，如换行、缩进、注释等，会让维护、排障更为容易，这也是一个好习惯。 此外，还可看到命令最后添加了清理工作的命令，删除了为编译构建所需要的软件，清理了所有下载文件。这很重要，镜像是多层存储，每一层的东西并不会在下一层被删除，会一直跟随镜像。 因此，构建镜像时，一定要确保每一层只添加真正需要添加的东西，任何无关的东西都应该清理掉。 很多人初学docker制作出了很臃肿的镜像，原因之一就是顽疾了每一层构建的最后一定要清理无关文件。 ","date":"2018-03-27","objectID":"/docker/:23:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"构建镜像 在Dockerfile目录下执行： #docker build [OPTIONS] PATH | URL | - [flags] #Build an image from a Dockerfile #-t指定镜像名称 #.指的是上下文目录 docker build -t nginx:test . 构建上下文(content) 上面的.是在指定上下文路径。 当我们在进行镜像构建的时候，并非所有的定制都会通过RUN指令完成，经常会需要一些本地文件复制进镜像，比如通过COPY, ADD指令。而docker build命令并非是在本地构建镜像，而是在服务端，也就是Docker引擎dockerd中构建的。那么在这种C/S架构中，如何才能让服务端获得本地文件呢？ 这就引进了上下文的概念。当构建的时候，用户会指定构建镜像的上下文的路径，docker build命令得知这个路径后，会将路径下的所有内容打包，然后上传给Docker引擎。这样Docker引擎收到这个上下文包后，展开就会获得构建镜像所需的一切文件。 #复制上下文目录下的package.json COPY ./package.json /app/ 因此COPY这类指令中的源文件的路径都是相对路径，因为绝对路径已经超出了上下文的范围，Docker引擎无法获取这些位置的文件。如果真需要这些文件，请将它们复制到上下文目录中去。 理解构建上下文对于镜像构建很重要，避免犯一些不应该的错误。 一般来说，应将Dockerfile置于一个空目录下，或者项目根目录下。如果该目录下没有所需文件，则应该把所需文件复制一份过来。如果目录下有些东西不希望构建时传给Docker引擎，可以写一个.dockerignore文件，用于剔除不需要作为上下文传递给Docker引擎的。 实际上，Dockerfile的文件名并不要求必须为Dockerfile，也并不要求必须位于上下文目录中。可使用-f指定某个文件为Dockerfile。 其它docker build的用法 直接使用Git repo进行构建 #docker build URL docker build https://github.com/twang2218/gitlab-ce-zh.git#:8.14 #docker会自己去clone、切换分支、并进入指定目录开始构建 使用给定tar压缩包构建 docker build http://server/context.tar.gz #自动下载/解压缩 压缩包，以其作为上下文，开始构建 从标准输入中读取Dockerfile进行构建 docker build - \u003c Dockerfile cat Dockerfile | docker build - docker build - \u003c context.tar.gz \r","date":"2018-03-27","objectID":"/docker/:23:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"Dockerfile指令 Dockerfile提供了十多个指令供我们操作。 ","date":"2018-03-27","objectID":"/docker/:24:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"LABLE 你可以为你的镜像添加标签，以助于通过项目来组织镜像，记录相关信息。 # Set multiple labels at once, using line-continuation characters to break long linesLABEL vendor=ACME\\ Incorporated \\ com.example.is-beta= \\ com.example.is-production=\"\" \\ com.example.version=\"0.0.1-beta\" \\ com.example.release-date=\"2015-02-12\" ","date":"2018-03-27","objectID":"/docker/:24:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"COPY 尽管ADD和COPY在功能上相似，但一般来说，COPY是首选，因为它比ADD更透明。 COPY只支持将本地文件复制到容器中，而ADD具有一些功能(如提取tar文件和远程URL支持) COPY,复制文件。 从构建上下文目录中\u003c源路径\u003e的文件/目录复制到新的一层的镜像内的\u003c目标路径\u003e位置。 源路径可以是多个，或通配符(需满足Go的规则) 目标路径可是容器内的绝对路径，也可是相对于工作目录(WORKDIR)的相对路径。目标路径不需要事先创建。 使用COPY指令，源文件的各种元数据都会保留 —— 如读、写、执行权限、文件变更时间… COPY \u003csourch\u003e \u003cdestination\u003e #或 COPY [\"\u003csource1\u003e\", ... \"\u003cdestination\u003e\"] #栗子 COPY package.json /usr/src/app/ COPY hom* /mydir/ COPY hom?.txt /mydir/ #目录 COPY dir/ /dir/ #复制目录的错误用法 #COPY dir/* /dir/ ","date":"2018-03-27","objectID":"/docker/:24:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"ADD ADD是更高级的复制文件。 ADD和COPY的格式和性质基本一致，但增加了一些功能。ADD支持通过URL从远程服务器读取资源，但对远程的压缩包没有解压缩功能。 尽可能的使用COPY，因为COPY的语义很明确，就是复制文件而已，而ADD则包含了更复杂的功能，其行为也不一定很清晰。 最适合ADD的场合，就是所提及的需要自动解压缩的场合。 因此在COPY和ADD指令中选择的时候，可以遵循这样的原则，所有的文件复制均使用COPY指令，仅在需要自动解压缩或远程资源的场合使用ADD。 FROM scratch ADD ADD http://foo.com/bar.go /tmp/main.go ADD abc.tar.gz / \u0026\u0026 \\ http://example.com/big.tar.xz /usr/src/things/ \u0026\u0026 \\ RUN tar -xJf /usr/src/things/big.tar.xz -C /usr/src/things RUN make -C /usr/src/things all ","date":"2018-03-27","objectID":"/docker/:24:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"CMD CMD，容器启动命令。用于运行镜像中包含的软件以及任何参数。 也有两个格式： shell格式： CMD \u003ccommand\u003e shell格式，在实际中会被包装成sh -c的参数形式进行执行： CMD echo $HOME #转变为 CMD[\"sh\", \"-c\", \"echo $HOME\"] #-c string If the -c option is present, then commands are read from string. #这就是为什么我们可以使用环境变量的原因，因为这些环境变量会被 shell 进行解析处理 exec格式： CMD [\"可执行文件\", \"参数1\", \"参数2\" ...] CMD几乎总是以此格式使用。 Docker不是虚拟机，容器就是进程。既然是进程，那么在启动容器的时候，需要指定所运行的程序及参数。CMD指令就是用于指定默认的容器主进程的启动命令的。 `` 对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。 ","date":"2018-03-27","objectID":"/docker/:24:4","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"ENTRYPOINT ENTRYPOINT，入口点。指令格式同样分为shell格式和exec两种。 ENTRYPOINT和CMD一样，都是在指定容器启动程序及参数。 当指定了ENTRYPOINT后，CMD的含义就发生了改变，不再是直接的运行其命令，而是将CMD的内容作为参数传给ENTRYPOINT指令。即变为如下模式： \u003cENTRYPOINT\u003e \"\u003cCMD\u003e\" 有几大好处： 让镜像变成像命令一样使用 #可以从腾讯上拉取，快一些 #ccr.ccs.tencentyun.com/qcloud/ubuntu FROM ubuntu:16.04 RUN apt-get update \\ \u0026\u0026 apt-get install -y curl \\ \u0026\u0026 rm -rf /var/lib/apt/lists/* CMD [ \"curl\", \"-s\", \"http://ip.cn\" ] docker build -t myip docker run myip #当前 IP：182.150.x.xx 来自：四川省成都市 电信 不过命令总有参数，例如我想查看HTTP header，使用-i参数 docker run myip -i #这样会报错，-i替换了CMD命令，而不是-s参数，然而-i并不是命令 #重新完整输入命令 docker run myip curl -s http://ip.cn -i #这样又太麻烦 这时便可以使用ENTRYPOINT解决这个问题。 FROM ubuntu:16.04 RUN apt-get update \\ \u0026\u0026 apt-get install -y curl \\ \u0026\u0026 rm -rf /var/lib/apt/lists/* ENTRYPOINT [ \"curl\", \"-s\", \"http://ip.cn\" ] docker build it myip docker run myip #当前 IP：182.150.x.xx 来自：四川省成都市 电信 docker run myip -i #成功 当存在ENTRYPOINT后，CMD的内容将作为参数传递给ENTRYPOINT，而-i就是新的CMD，因此会作为参数传递给curl，从而达到预期效果。 应用运行前的准备工作 有时，在启动前需要做一些准备工作。 如MySQL，需要一些配置文件、初始化工作，这些工作需要在MySQL server运行前解决 避免使用root用户去启动服务，从而提高安全性 这些准备工作和CMD无关 ","date":"2018-03-27","objectID":"/docker/:24:5","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"ENV ENV，设置环境变量。 为了使新软件更容易运行，使用此命令为你的容器内安装的软件更新环境变量。 两种格式： ENV \u003ckey\u003e \u003cvalue\u003e ENV \u003ckey1\u003e=\u003cvalue1\u003e \u003ckey2\u003e=\u003cvalue2\u003e... ENV PATH $PATH:/root/bin \\ EMAIL abc@zhang21.cn \\ NAME=\"Zhang21\" 下列指令可以支持环境变量展开： ADD, COPY, ENV, EXPOSE, LABEL, USER, WORKDIR, VOLUME, STOPGIGNAL, ONBUILD。 通过环境变量，我们可以让一份Dockerfile制作更多的镜像，只需使用不同的环境变量即可。 ","date":"2018-03-27","objectID":"/docker/:24:6","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"ARG ARG，构建参数 格式： ARG \u003c参数名\u003e[=\u003c默认值\u003e] 构建参数和ENV的效果一样，都是设置环境变量。所不同的是，ARG所设置的构建环境的环境变量，在将来容器运行时是不会存在这些环境变量的。 ","date":"2018-03-27","objectID":"/docker/:24:7","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"VOLUME VOLUME，定义匿名卷。用于显示有docker容器创建的任何数据库存储区域，配置存储或文件/文件夹。 强烈建议将VOLUME用于镜像的任何可变部分和用户可用部分。 格式： VOLUME [\"\u003c路径1\u003e\", \"\u003c路径2\u003e\"...] VOLUME \u003c路径\u003e 容器运行时应该尽量保持容器存储层不发生写操作，对于数据库类需要保存动态数据的应用，其数据库文件应该保存于卷(volume)中。 为了防止运行时用户忘记将动态文件所保存目录挂载为卷，在Dockerfile中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会像容器存储层写入大量数据。 #在运行时自动挂载为匿名卷 VOLUME /data #覆盖挂载 docker run -d -v mydata:/data xxx ","date":"2018-03-27","objectID":"/docker/:24:8","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"EXPOSE EXPOSE，声明容器监听连接的端口。 格式： EXPOSE \u003c端口1\u003e [\u003c端口2\u003e...] EXPOSE指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。 在Dockerfile中写入这个声明有两个好处： 一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便映射 另一个用处则是在运行时使用随机端口映射(未定义时) 要将EXPOSE和在运行时使用-p \u003c宿主端口\u003e:\u003c容器端口\u003e区分开。EXPOSE仅仅声明容器打算使用哪些端口，并未包含端口映射。 ","date":"2018-03-27","objectID":"/docker/:24:9","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"WORKDIR WORKDIR，指定工作目录。为了清晰可靠，请使用绝对路径。 使用WORKDIR指令可以来指定工作目录，以后各层的当前目录就被改为指定的目录，如目录不存在，WORKDIR会帮你建立目录。 如果需要改变Dockerfile各层的工作目录的位置，那么应该使用WORKDIR指令。 格式： WORKDIR \u003c工作目录\u003e ","date":"2018-03-27","objectID":"/docker/:24:10","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"USER USER，指定当前用户。 如果服务可以在非特权模式下运行，请使用USER将其改为non-root用户。首先在Dockerfile中创建相应的用户和组: RUN groupadd -r group \u0026\u0026 \\ useradd -r -g group group USER和WORKDIR相似，都是改变环境状态并影响以后的层。WORKDIR是改变工作目录，USER则是改变之后的层执行RUN, CMD, ENTRYPOINT这类命令的身份。这个用户必须存在。 格式： USER \u003c用户名\u003e USER redis RUN [\"redis-server\"] ","date":"2018-03-27","objectID":"/docker/:24:11","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"HEALTHCHECK HEALTHCHECK，健康检查 HEALTHCHECK指令告诉docker应该如何进行判断容器的状态是否正常。 格式： HEALTHCHECK [选项] CMD \u003c命令\u003e， 设置检查容器健康状况的命令 HEALTHCHECK NONE， 如果基础镜像有健康检查，使用这行可以屏蔽其健康检查指令 当在一个镜像指定了HEALTHCHECK指令后，用其启动容器，初始状态会为starting，在HEALTHCHECK指令检查成功后变为healthy，如果连续一定次数失败，则会变为unhealthy。 和CMD, ENTRYPOINT一样，HEALTHCHECK 只可以出现一次，如果写了多个，只有最后一个生效。 ","date":"2018-03-27","objectID":"/docker/:24:12","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"ONBUILD ONBUILD，为他人做嫁衣。 ONBUILD是一个特殊的指令，它后面跟的是其它指令。而这些指令，在当前镜像构建时不会被执行。只有当以当前镜像为基础镜像(父镜像)，去构建下一级镜像(子镜像)的时候才会被执行。ONBUILD命令在子镜像的Dockerfile中任何命令之前执行。 Dockerfile中的其它指令都是为了定制当前镜像而准备的，唯有ONBUILD是为了帮助别人定制自己而准备的。 格式： ONBUILD \u003c其它指令\u003e \r","date":"2018-03-27","objectID":"/docker/:24:13","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"Dockerfile多阶段构建 全部放入一个Dockerfile 将所有的构建过程包含在一个Dockerfile中，包括项目及其依赖库的编译、测试、打包等流程。 这可能会带来一些问题： Dockerfile特别长，可维护性降低 镜像层次多，镜像体积较大，部署时间变长 源代码存在泄漏的风险 分散到多个Dockerfile 事先在一个Dockerfile将项目及其依赖库编译测试打包好后，再将其拷贝到运行环境中。这种方式需要编写两个Dockerfile和一些编译脚本才能将两个阶段自动整合起来。这种方式虽然可以很好避免全部写入一个Dockerfile的风险，但明显部署过程较复杂。 多阶段构建 使用多阶段构建我们就可以很容易解决前面提到的问题，并且只需要编写一个Dockerfile。 \r","date":"2018-03-27","objectID":"/docker/:25:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"Dockerfile最佳实践 一般性建议 容器应该是短暂的 使用.dockerignore文件 使用多阶段构建减少镜像大小 避免安装不必要的包 一个镜像只运行一个进程 镜像层数尽可能少 将多行参数排序 构建缓存 Dockerfile指令 FROM LABEL RUN CMD EXPOSE ENV ADD COPY ENTRYPOINT VOLUME USER WORKDIR \r\r \r\rBuildkit 注意 docker版本需要大于18.09 启动docker buildkit之后，我们可以使用几个新的Dockerfile指令来加快镜像构建。 RUN --mount=type=cache RUN --mount=type=bind RUN --mount=type=tmpfs RUN --mount=type=secret RUN --mount=type=ssh \r加快应用构建时依赖的缓存，便于每次构建无需重复下载依赖，加快构建时间。 一个示例的Dockerfile，需要在最前面加上# syntax=docker/dockerfile:1。 # syntax=docker/dockerfile:1# stage buildFROMnode:12.20.0-alpine as builderWORKDIR/appCOPY package.json /app/# 依赖缓存RUN --mount=type=cache,target=/app/node_modules,id=app_cache \\ --mount=type=cache,target=/root/.npm,id=npm_cache \\ npm install --registry=https://registry.npm.taobao.orgCOPY . /app/RUN npm run build# stage imageFROMnginx:1.20.0-alpineCOPY --from=builder /app/dist /usr/share/nginx/htmlEXPOSE80 构建命令: # 参考: https://yeasy.gitbook.io/docker_practice/buildx/buildkit DOCKER_BUILDKIT=1 docker build -t name:tag . \r \r\r多平台构建 参考: buildx: https://docs.docker.com/buildx/working-with-buildx/ qemu-uer-static: https://github.com/multiarch/qemu-user-static 版本: 大于Docker 19.03 linux kernel: 5.x 使用Docker新功能buildx构建多平台的镜像。 升级内核版本，不然使用qemu-user-static使会失败。 使用如下: # 开启此功能 export DOCKER_CLI_EXPERIMENTAL=enabled # 需要使用qemu-user # 注意内核版本，升级到5.x的内核大版本 docker run --rm --privileged multiarch/qemu-user-static --reset -p yes docker buildx create --name builder --driver docker-container --use docker buildx inspect --bootstrap # arm64，--load存放本地 docker buildx build -t xxx:arm64-tag --load --platform linux/arm64 . # amd64，--push推送 docker buildx build -t xxx:amd64-tag --push --platform linux/amd64 . # 多平台 docker buildx build --platform linux/arm64,linux/amd64 -t user/test:latest --push . 多平台构建的镜像支持运行在各自的架构上，使用同一个tag。多平台构建只能使用--push, --load只能对应单个平台。 Compose 使用docker-compose来编排和运行容器。 \r \r\r使用Docker进行开发 Develop with Docker \r\r","date":"2018-03-27","objectID":"/docker/:26:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"在Docker上开发应用程序 Develop new apps on Docker Learn to build an image from a Dockerfile Use multistage builds to keep your images lean Manage application data using volumes and bind mounts Scale your app as a swarm service Define your app stack using a compose file General application development best practices 了解有关Docker上特定语言的开发： Java node.js Ruby on Rails .Net ASP.Net \r","date":"2018-03-27","objectID":"/docker/:27:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"Docker开发最佳实践 Docker development best practices 如下开发模式已被证明有助于人么使用Docker构建应用程序。 如何保持较小的镜像 How to keep your images small 在启动容器或服务时，小图像可以更快速通过网络pull镜像并加载到内存中。有几条经验法则可保持较小的镜像： 从适当的基础镜像开始 例如，如果需要JDK，请考虑官方镜像，而不是从一个通用的Ubuntu/Centos镜像并将Openjdk作为Dockerfile的一部分安装开始。 使用多阶段构建 例如，你可以使用maven镜像构建java程序，然后重置到tomcat镜像，并将java构件复制到正确位置以部署应用程序，所有这些都位于相同的Dockerfile。这意味着你的最终镜像不包含构建时所引入的所有库和依赖项，仅包含运行它们所需的构件和环境。 如果你有多个共同的镜像，请考虑使用共享组件创建你的基本镜像，并在其上创建独特的镜像 Docker只要家在一次通用层，然后便会缓存。 保持生产环境镜像精简但允许调试(degub)，请考虑使用生产环境镜像作为调试镜像的基本镜像 在构建镜像时，应该始终使用有用的标签对其进行标记，如(test, prod)。不要依赖自动创建的latest标签 何处以及如何持久化应用程序数据 Where and how to persist application data 避免使用存储驱动(storge drivers)将应用程序的数据存储在容器的可写层(writeable layer)中 与使用卷(volume)或绑定挂载(bound mounts)相比，这增加了容器的大小，并且从I/O角度来看效率较低 使用卷存储数据 适合使用绑定挂载的一种情况是在开发过程中，对于生产环境，请改用卷 对于生产环境，使用secerts来存储服务使用的敏感的应用程序数据，使用config来存储不敏感的数据(如配置文件) 尽可能使用swarm服务 Use swarm services when possible 在可能的情况下，使用swarm服务进行伸缩的能力来设计你的应用程序 即使你只需运行单个实例，swarm服务也比standalone容器提供更多的优势 网络和卷可使用swarm服务连接和断开，并且docker可以以不中断的方式重新部署各个服务容器。standalone容器需要手动停止/移除/重新创建 一些功能仅适用于服务而不适用于standalone容器 让docker stack deploy处理任意镜像，而不是使用docker pull。通过这种方式，你的部署不会尝试从down的节点进行pull。此外，当新节点添加到集群时，镜像会自动pull 使用CI/CD进行测试和部署 Use CI/CD for testing and deployment CI(Continuous integration) CD(continuous deployment) 当更新源码库或创建拉取请求时，请使用CI/CD pipeline 自动构建并标记Docker镜像，并对其进行测试。也可将测试过的应用程序直接部署到生产环境中 \r\r","date":"2018-03-27","objectID":"/docker/:27:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"Develop images 编写Dockerfile的最佳实践 Best practices for writing Dockerfiles Docker通过读取Dockerfile(一个包含命令的文本文件)中的命令来自动构建镜像。 Dockerfile reference: https://docs.docker.com/engine/reference/builder/ Dockerfile由read-only layer组成，每层代表一个Dockerfile指令。如: FROM ubuntu:15.04 COPY . /app RUN make /app CMD python /app/app.py 每个命令创建一个层: FROM 从ubuntu:15.04 Docker image创建一个层 COPY 从Docker client的当前目录添加文件 RUN 使用make构建你的应用程序 CMD 指定在容器内运行的命令 当你运行镜像并生成容器时，会在基础层的顶部添加一个可写层(writable layer)，也称容器层(container layer)。对正在运行的容器所做的所有更改(增删改文件)都会写入此可写容器层。 \r一般准则和建议 General guidelines and recommendations 创建临时(ephemeral)容器 Create ephemeral containers 由Dockerfile定义的镜像应该生成尽可能临时的容器。临时的意思为容器可以被停止(stop)和销毁(destroy)，然后重建(rebuild)并使用绝对最小化的设置和配置来替代。 理解构建上下文 Understand build context 当你发出docker build命令时，当前的工作目录被称为构建上下文(build context)。默认情况下，假设Dockerfile位于此，但你也可以使用文件标志(-f)指定位置。无论Dockerfile位于何处，当前目录内的所有内容(除了.dockerignore中忽略的内容)都将作为构建上下文发送给Docker守护进程。 从stdin读取Dockerfile Pipe Dockerfile through stdin #local build-context docker build -t . -f-\u003c\u003cEOF FROM busybox RUN echo \"hello world\" COPY . /my-copied-files EOF #remote docker build -t foo https://github.com/thajeztah/pgadmin4-docker.git -f-\u003c\u003cEOF FROM busybox COPY LICENSE config_local.py /usr/local/lib/python2.7/site-packages/pgadmin4/ EOF 使用.dockerignore排除文件 Exclude with .dockerignore 要排除与构建无关的文件，请使用.dockerignore文件，这与.gitignore类似。 vim ./dockerignore file1 dir2 ... 使用多阶段构建 Use multi-stage builds 多阶段构建允许你大幅缩减镜像大小，而不需要减少中间层和文件数。 由于镜像是在构建过程的最后阶段构建的，因此可以通过利用构建缓存(build cache)来最小化镜像层 例如，如果你的版本博涵包含多个层，你可以从 不经常改动的版本到频繁改动的版本进行排序: 安装构建应用程序需要的工具 安装或更新依赖库 生成应用程序 A Dockerfile for Go application: FROM golang:1.9.2-alpine3.6 AS build # Install tools required for project # Run `docker build --no-cache .` to update dependencies RUN apk add --no-cache git RUN go get github.com/golang/dep/cmd/dep # List project dependencies with Gopkg.toml and Gopkg.lock # These layers are only re-built when Gopkg files are updated COPY Gopkg.lock Gopkg.toml /go/src/project/ WORKDIR /go/src/project/ # Install library dependencies RUN dep ensure -vendor-only # Copy the entire project and build it # This layer is rebuilt when a file changes in the project directory COPY . /go/src/project/ RUN go build -o /bin/project # This results in a single layer image FROM scratch COPY --from=build /bin/project /bin/project ENTRYPOINT [\"/bin/project\"] CMD [\"--help\"] 不要安装不必要的包 Don’t install unnecessary packages 为了减少复杂性、依赖性，文件大小和构建时间，避免安装额外的或不不必要的软件包。 分离应用程序 Decouple applications 每个容器应该只有一个问题。将应用程序分离到多个容器中可以更轻松地水平伸缩和重新使用容器。 例如，Web应用程序堆栈可能有三个独立的容器组成，每个容器都有其独特的镜像，以分离的方式管理Web应用程序、数据库和内存缓存。 将每个容器限制为一个进程是一个很好的经验法则，但不是硬性规定。(想想高可用和负载均衡)。 尽你最大的努力使容器干净和模块化。如果容器相互依赖，则可以使用Docker container network来确保容器间可进行通信。 最小化层数 Minimize the number of layers 在老版本的docker中，重要的是减少镜像的层数，以确保它们的性能。 对多行参数排序 Sort multi-line arguments 只要有可能，通过按字母数字排序多行参数来简化修改。这有助于避免软件包重复，并使列表更容易更新。 RUN apt-get update \u0026\u0026 apt-get install -y \\ bzr \\ cvs \\ git \\ mercurial \\ subversion Leverage build cache 在构建镜像时，Docker安装Dockerfile中的指令逐步执行，并按指定的顺序执行每个镜像。在检查每条指令时，docker会在其缓存中查找可重用的现有镜像，而不是创建新的(重复)镜像。 如果你不想使用缓存，可在docker build命令中使用--no-cache=true选项。如果让Docker使用了缓存，那么了解何时可以 找到/找不到 匹配的图像就很重要了。 Docker遵循的基本规则如下: 从已经在缓存中的父镜像开始，将下一条指令与该基本镜像派生的所有子镜像进行比较，以查看是否使用完全相同的指令构建了其中的一条。否则，缓存失效。 大多数情况下，只需将Dockerfile中的指令与其中一个子镜像进行比较久够了。但是，某些说明需要更多的检查和解释。 对于ADD和COPY指令，将检查镜像文件中的内容，并为每个文件计算校验和。在缓存查找过程中，将检验和与现有镜像中的校验和进行比较，如果文件中由任何内容已更改，如内容和元数据，则缓存将失效。 除了ADD和COPY指令，缓存检查将不会查看容器中的文件已确定缓存。 一旦缓存失效，所有后续的Dockerfile命令将生产新的镜像，并且不会使用缓存。 Dockerfile instruction 请参考: [Dockerfile](# Dockerfile) \r创建一个基镜像 Create a base image 大多数Dockerfile从父镜像开始，如果需要完全控制镜像的内容，则可能需要创建基镜像(base image)。区别: 父镜像是镜像的所基于的镜像 基镜像的Dockerfile中没有FROM行 \r使用多阶段构建 Use multi-stage builds 多阶段构建需要Docker v17.05及以上版本。多阶段构建对于优化Dockerfile来说非常有用，同时让它易读和维护。 构建之前 构建镜像最具挑战的事情是保持镜像的大小。Dockerfile中的每条指令都会为镜像添加一层，在移动到下一层前清理不需要的任何构件。为了编写一个高效的Dockerfile，需要尽可能减小图层，并确保每个层都具有上一层需要的构件，而不是其它东西。 使用多阶段构建 使用多阶段构建，你可以在Dockerfile中使用多个FROM语句。每条FROM命令可以使用不同的基镜像，并且每个指令都可是构建的新阶段。 FROM golang:1.7.3 WORKDIR /go/src/github.com/alexellis/href-counter/ RU","date":"2018-03-27","objectID":"/docker/:27:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"使用Docker Engine SDKs和API进行开发 Develop with Docker Engine SDKs and API \r","date":"2018-03-27","objectID":"/docker/:28:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"综述 Docker提供了一个用于与Docker daemon(称为Docker Engine API)交互的API，以及用于Go和Python的SDK。 SDK允许你款速轻松地构建和扩展Docker APP。 如果Go或Python不适合你，你可以直接使用Docker Engine API——它是由HTTP客户端(curl, wget)访问的RESTful API，或者是大多数现代编程语言的一部分HTTP库。 ","date":"2018-03-27","objectID":"/docker/:29:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"安装SDKs Go SDK Go SDK参考：https://godoc.org/github.com/docker/docker/client go get github.com/docker/docker/client Python SDK Python SDK参考: https://docker-py.readthedocs.io/en/stable/ pip install docker ","date":"2018-03-27","objectID":"/docker/:29:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"快速开始SDK和API Python: 运行一个容器 import docker client = docker.from_env() print (client.containers.run(\"alpine\", [\"echo\", \"hello\", \"world\"])) HTTP: $ curl --unix-socket /var/run/docker.sock -H \"Content-Type: application/json\" \\ -d '{\"Image\": \"alpine\", \"Cmd\": [\"echo\", \"hello world\"]}' \\ -X POST http:/v1.24/containers/create {\"Id\":\"1c6594faf5\",\"Warnings\":null} $ curl --unix-socket /var/run/docker.sock -X POST http:/v1.24/containers/1c6594faf5/start $ curl --unix-socket /var/run/docker.sock -X POST http:/v1.24/containers/1c6594faf5/wait {\"StatusCode\":0} $ curl --unix-socket /var/run/docker.sock \"http:/v1.24/containers/1c6594faf5/logs?stdout=1\" hello world \r\r","date":"2018-03-27","objectID":"/docker/:29:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"SDK和API栗子 链接: https://docs.docker.com/develop/sdk/examples/ \r \r网络配置 Configure networking ","date":"2018-03-27","objectID":"/docker/:29:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"综述 Docker容器和服务如此强大的原因之一是——你可以将它们连接在一起，或将它们连接到non-docker工作负载。Docker容器和服务甚至不需要知道它们是否部署在Docker上，或它们的对等端是否也是Docker工作负载。都可以使用Docker方式管理它们。 ","date":"2018-03-27","objectID":"/docker/:30:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"网络驱动 Network drivers 使用驱动程序，Docker的网络子系统是可插拔的(pluggable)。 集中驱动程序: brige 默认网络驱动。桥接网络通常用于你的应用程序运行在需要通信的独立容器中。 host 对于独立容器，删除容器和Docker主机之间的网络隔离，并直接使用主机的网络。 overlay overlay网络将多个docker daemon连接在一起，并使集群服务能够无相互通信。 macvlan macvlan网络允许你为容器分配MAC地址，使其成为你网络上的物理设备。docker daemon通过其MAC地址将流量路由到容器。 none 对于此容器，禁用所有网络。 network plugins 你可在Docker上安装和使用第三方网络插件，从Docker Store获取: https://store.docker.com \r网络驱动总结 User-defined bridge networks 当你需要多个容器在同一个Docker主机上进行通信时 Host networks 当网络堆栈不应与Docker主机隔离时，但希望容器的其它方面被隔离 Overlay networks 当你需要运行在不同Docker主机上的容器进行通信时，或多个应用程序使用集群服务进行工作时 Macvlan networks 当你从虚拟机迁移或需要你的容器看起来像物理主机时，每个都具有唯一的MAC地址 Third-party network plugins 允许你将Docker与专用网络堆栈集成 \r\r","date":"2018-03-27","objectID":"/docker/:30:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"bridge 就网络而言，桥接网络是一种链路层设备，用于转发网段之间的流量。桥接可以是硬件设备，或在主机内核中运行的软件设备。 就Docker而言，桥接网络允许连接到统一桥接网络的容器进行通信，同时提供与未连接到桥接网络的容器的隔离。Docker桥接驱动程序自动在主机上安装桥接规则，以便于不同桥接网络上的容器不能直接相互通信。 桥接网络适用于在同一个Docker daemon上运行的容器之间的通信。 当你启动Docker时，除非另有定义，否则将自动创建默认桥接网络，并且新启动的容器将连接到它。 你也可以创建用户自定义的桥接网络。 \r","date":"2018-03-27","objectID":"/docker/:31:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"bridge与user-defined bridges Differences between user-defined bridges and the default bridge 两者的差别： 用户自定义的桥接在集装箱化的应用程序之间提供了更好的隔离和互操作性 用户自定义的桥接提供了容器之间的自动DNS解析 容器可以在运行中与用户定义的网络进行连接(attach)和分离(detach) 每个用户定义的网络会创建一个可配置的桥接网络 在默认桥接网络上链接的容器共享环境变量 \r\r","date":"2018-03-27","objectID":"/docker/:31:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"管理user-defined bridge Manage a user-defined bridge docker network create --help #创建一个用户自定义桥接网络 #你还可以指定子网，范围，网关... docker network creat ${name} docker network creat my-net #删除 docker network rm ${name} \r\r","date":"2018-03-27","objectID":"/docker/:31:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"连接到自定义桥接网络 Connect a container to a user-defined bridge 当你创建一个新的容器时，你可以指定一个或多个--network标志。 #创建时 docker create --name my-nginx \\ --network my-net \\ --publish 8080:80 \\ nginx:latest #运行中的容器 docker network connect my-net my-nginx #断开连接 docker network disconnect my-net my-nginx \r\r","date":"2018-03-27","objectID":"/docker/:31:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"使用IPv6 需要修改docker daemon的配置项以支持使用IPv6，在创建自定义网络是指定--ipv6标志。 你不能有选择地禁用默认桥接网络上的IPv6支持。 \r\r","date":"2018-03-27","objectID":"/docker/:31:4","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"启用容器转发 Enable forwarding from Docker containers to the outside world 默认情况下，使用默认桥接网络的连接的容器的流量不会转发到外部世界。启用操作如下： #配置Linux内核 sysctl net.ipv4.conf.all.forwarding=1 #修改iptables FORWARD默认策略 iptables -P FORWARD ACCEPT #重启后无效，请写入配置文件 \r\r","date":"2018-03-27","objectID":"/docker/:31:5","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"默认桥接网络 Use the default bridge network 默认桥接网络被视为Docker的遗留细节，不建议用于生产环境。 连接容器到默认桥接网络 如果未指定网络，则默认使用默认桥接网络。 配置默认桥接网络 指定并配置daemon.json文件 { \"bip\": \"192.168.1.5/24\", \"fixed-cidr\": \"192.168.1.5/25\", \"fixed-cidr-v6\": \"2001:db8::/64\", \"mtu\": 1500, \"default-gateway\": \"10.20.1.1\", \"default-gateway-v6\": \"2001:db8:abcd::89\", \"dns\": [\"10.20.1.2\",\"10.20.1.3\"] } 使用IPv6 修改配置文件以支持IPv6，则默认桥接网络自动支持IPv6。 \r\r","date":"2018-03-27","objectID":"/docker/:31:6","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"overlay overlay网络驱动在多个docker daemon主机之间创建分布式网络。该网络位于特定主机网络之上，允许容器连接到此并安全地进行通信。 当初始化集群或将docker主机加入现有集群时，将在docker主机上创建两个新网络： 称为ingress的overlay网络 处理与集群服务相关的控制和数据流量。 当你创建集群服务并且不将其连接到用户自定义的网络时，它默认连接到ingress网络。 称为docker_gwbridge的桥接网络 将单独的docker daemon连接到集群的其它docker daemon。 与创建自定义桥接网络类似，你也可以使用docker network create来创建自动以的overlay网络。服务或容器一次可连接到多个网络，但只能通过连接的网络进行通信。 尽管可以将集群服务和独立容器连接到overlay网络，但默认行为和配置是不同的。 \r\r","date":"2018-03-27","objectID":"/docker/:32:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"所有overlay网络的操作 Operations for all overlay networks \r创建overlay网络 Create an overlay network 先决条件 使用overlay网络的docker daemon的防火墙规则 2377(tcp): 集群通信管理 7946(tcp/udp)： 节点通信 4789(udp)： overlay网络流量 创建overlay网络前，需要初始化docker daemon集群 docker network create -d overlay my-overlay #创建可供集群服务或独立容器与其它docker daemon上的独立容器进行通信 docker network create -d overlay --attachable my-attachable-overlay #你可以指定IP地址范围，子网，网关... \r加密overlay网络上的流量 Encrypt traffic on an overlay network Overlay network encryption is not supported on Windows！ 所有集群服务管理流量默认都是加密的，在GCM模式下使用AES算法。 要加密应用程序数据，在创建overlay网络时添加--opt encrypted。这种加密带来了不可忽视的性能问题，所以应该在生产环境使用前对其进行测试。 当启用overlay加密时，docker会在节点间创建IPsec tunnel，在这些节点上调度连接到overlay网络的服务的任务。 #SWARM MODE OVERLAY NETWORKS AND STANDALONE CONTAINERS docker network create --opt encrypted --driver overlay --attachable my-attachable-multi-host-network \r自定义默认ingress网络 如果自动选择的子网与已存在的网络冲突，或需要自定义其它低级网络设置(如MTU)，这次功能非常有用。 #显示详细信息 docker network inspect ingress #移除现有网络 docker network rm ingress #创建新网络 --ingress docker network create \\ --driver overlay \\ --ingress \\ --subnet=10.11.0.0/16 \\ --gateway=10.11.0.2 \\ --opt com.docker.network.driver.mtu=1200 \\ my-ingress \r自定义docker_gwbridge docker_gwbridge是一个虚拟桥接网络，它将overlay网路连接到单独的docker daemon的物理网络。当初始化集群或将主机加入集群时，docker会自动创建它，但它不是docker设备。啊存在于docker主机的内核之中。如果你需要自定义其设置，则必须在主机加入集群之前或将主机临时从集群中删除之后才执行此操作。 1. 停止docker 2. 删除已存在的docker_gwbridge ip link set docker_gwbridge doen ip link del dev docker_gwbridge 3. 启动docker，但不加入或初始化集群 4. 创建docker_gwbridge docker network create \\ --subnet 10.11.0.0/16 \\ --opt com.docker.network.bridge.name=docker_gwbridge \\ --opt com.docker.network.bridge.enable_icc=false \\ --opt com.docker.network.bridge.enable_ip_masquerade=true \\ docker_gwbridge 5. 集群初始化或加入集群 \r\r","date":"2018-03-27","objectID":"/docker/:32:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"swarm服务的操作 Operations for swarm services 在overlay网络上发布端口 Publish ports on an overlay network 连接到同一overlay网络的集群服务可有效地将所有端口暴露给对方。要是端口可在服务外可访问，必须使用-p或--publish标志暴露此端口。 两种方法： 传统的冒号:分隔语法 较新的逗号,分隔语法 Flag value Description -p 8080:80 or -p published=8080,target=80 Map TCP port 80 on the service to port 8080 on the routing mesh -p 8080:80/udp or -p published=8080,target=80,protocol=udp Map UDP port 80 on the service to port 8080 on the routing mesh -p 8080:80/tcp -p 8080:80/udp or -p published=8080,target=80,protocol=tcp -p published=8080,target=80,protocol=udp Map TCP port 80 on the service to TCP port 8080 on the routing mesh, and map UDP port 80 on the service to UDP port 8080 on the routine mesh \r绕过swarm的路由网格 Bypass the routing mesh for a swarm service 默认情况下，发布端口的集群服务使用路由网格来发布。当你连接到任何swarm节点上已发布的端口时，都会透明地将你重定向到正在运行服务的工作。实际上，docker充当集群服务的负载均衡器(Load-Balancer)。使用路由网格的服务以虚拟IP(vip)模式运行。即使在每个节点上运行服务也使用路由网格。使用路由网格时，不能保证那个docker node处理客户端请求。 要绕过路由网格，可使用DNS Round Robin(DNSRR)模式启动——--endpoint-mode dnsrr。你必须在服务前运行负载均衡器。docker主机上DNS查询服务名称会返回运行该服务的节点的IP地址列表。配置你的负载均衡器使用此列表并平衡各节点间的流量。 \r分离控制流量和数据流量 默认情况下，尽管集群控制流量是加密的，但集群管理和应用程序之间的控制流量运行在同一个网络上。你可以配置docker来使用单独的网络接口来处理来种不同类型的流量。 \r\r","date":"2018-03-27","objectID":"/docker/:32:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"overlay网络上独立容器的操作 Operations for standalone containers on overlay networks 将独立容器连接到overlay网络 Attach a standalone container to an overlay network 独立容器连接到ingress网络需添加--attachable标志。这使得运行在不同docker daemon上的独立容器能够进行通信，而无需在各个docker daemon主机上设置路由。 \r发布端口 Publish ports Flag value Desciption -p 8080:80 Map TCP port 80 in the container to port 8080 on the overlay network -p 8080:80/udp Map UDP port 80 in the container to port 8080 on the overlay network -p 8080:80/sctp Map SCTP port 80 in the container to port 8080 on the overlay network -p 8080:80/tcp -p 8080:80/udp Map TCP port 80 in the container to TCP port 8080 on the overlay network, and map UDP port 80 in the container to UDP port 8080 on the overlay network \r容器发现 Container discovery 对于大多数情况，应该连接到服务名称——它是负载均衡的，并支持服务的所有容器处理。要获取支持该服务的所有任务的列表，请执行DNS查找服务——tasks.\u003cservice-name\u003e。 \r\r","date":"2018-03-27","objectID":"/docker/:32:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"host 如果你对容器使用host网络驱动，则该容器的网络堆栈将不与docker主机隔离。例如，如果运行一个绑定在80端口并使用host网络的容器，则该容器的应用程序将在主机IP地址的80端口上可用。 host网络驱动只能运行在Linux主机上。 \r\r","date":"2018-03-27","objectID":"/docker/:33:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"Macvlan 一些应用程序，尤其是需要监视网络流量的应用程序，希望连接到物理网络上。在这种情况下，你可以使用macvlan驱动为容器的虚拟网络接口分配MAC地址，使其看起来像是直接连接到物理网络的物理网络接口。在这种情况下，你需要指定Docker主机上的物理接口用于macvlan，以及macvlan的子网和网关。 \r","date":"2018-03-27","objectID":"/docker/:34:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"创建一个macvaln网络 macvlan网络可处于 bridge mode 或 802.1q trunk mode: 在桥接模式下，macvlan流量通过主机上的物理设备 在802.1q主干桥接模式下，流量通过Docker在运行中创建的802.1q子接口。 这使你可以更细粒度地控制路由和过滤。 bridge mode 创建bridge macvlan: docker networkcreate --driver macvlan \\ --subnet=172.16.86.0/24 \\ --gateway=172.16.86.1 \\ -o parent=eth0 pub_net #--aux-addresses排除IP地址 docker networkcreate --driver macvlan \\ --subnet=172.16.86.0/24 \\ --gateway=172.16.86.1 \\ --aux-address=\"my-router=192.168.32.129\" \\ -o parent=eth0 pub_net 802.1q truk bridge mode 如果你指定了包含点.的接口名——如eth0.50，则Docker将其解释为eth0的子接口，并自动创建子接口。 docker network create --driver macvlan \\ --subnet=192.168.50.0/24 \\ --gateway=192.168.50.1 \\ -o parent=eth0.50 macvlan50 使用ipvlan替换macvlan docker network create -d ipvlan \\ --subnet=192.168.210.0/24 \\ --subnet=192.168.212.0/24 \\ --gateway=192.168.210.254 \\ --gateway=192.168.212.254 \\ -o ipvlan_mode=l2 ipvlan210 IPv6 docker network create -d macvlan \\ --subnet=192.168.216.0/24 --subnet=192.168.218.0/24 \\ --gateway=192.168.216.1 --gateway=192.168.218.1 \\ --subnet=2001:db8:abc8::/64 --gateway=2001:db8:abc8::10 \\ -o parent=eth0.218 \\ -o macvlan_mode=bridge macvlan216 \r\r","date":"2018-03-27","objectID":"/docker/:34:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"禁用容器网络 在启动容器时加上`–network none来禁用容器的网络堆栈，这样在容器内便仅仅创建loopback设备。 $ docker run --rm -dit \\ --network none \\ --name no-net-alpine \\ alpine:latest \\ ash \r\r","date":"2018-03-27","objectID":"/docker/:35:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"网络教程 Networking tutorials \r","date":"2018-03-27","objectID":"/docker/:36:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"bridge network default bridge network user-defined bridge network default bridge network 基本docker网络 docker network ls NETWORK ID NAME DRIVER SCOPE 8d3b84bfe5a0 bridge bridge local 3579d63da633 host host local f766b990db47 none null local 以上列出了默认的桥接网络，主机网络(启动直接连接到docker daemon的主机的网络堆栈的容器)，none(启动一个没有网络设备的容器)。 启动一个容器 docker run -dit --name alpine1 alpine ash 由于启动时没有指定网络，所以默认为桥接网络。 Inspect the bridge network，以查看哪个容器连接到它 docker network inspect bridge [ { \"Name\": \"bridge\", \"Id\": \"8d3b84bfe5a034c65d043af80976a1e6127011fc1ab312446252f562e221d351\", \"Created\": \"2018-05-24T18:38:35.538308064+08:00\", \"Scope\": \"local\", \"Driver\": \"bridge\", \"EnableIPv6\": false, \"IPAM\": { \"Driver\": \"default\", \"Options\": null, \"Config\": [ { \"Subnet\": \"172.17.0.0/16\", \"Gateway\": \"172.17.0.1\" } ] }, \"Internal\": false, \"Attachable\": false, \"Ingress\": false, \"ConfigFrom\": { \"Network\": \"\" }, \"ConfigOnly\": false, \"Containers\": { \"893903129d869f384bd78d63a382f1c9527d6979be0a6cf3c13ea4f45a1554d6\": { \"Name\": \"hardcore_rosalind\", \"EndpointID\": \"515d1435470c9f72d3b07680515d9c503457b8eb5bcaaaa915bb53901eac9424\", \"MacAddress\": \"02:42:ac:11:00:02\", \"IPv4Address\": \"172.17.0.2/16\", \"IPv6Address\": \"\" } }, \"Options\": { \"com.docker.network.bridge.default_bridge\": \"true\", \"com.docker.network.bridge.enable_icc\": \"true\", \"com.docker.network.bridge.enable_ip_masquerade\": \"true\", \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\", \"com.docker.network.bridge.name\": \"docker0\", \"com.docker.network.driver.mtu\": \"1500\" }, \"Labels\": {} } ] 连接到容器 docker attach alpine1 / # ip addr show 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 506: eth0@if507: \u003cBROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN\u003e mtu 1500 qdisc noqueue state UP link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever / # ping -c 2 www.baidu.com PING www.baidu.com (119.75.216.20): 56 data bytes 64 bytes from 119.75.216.20: seq=0 ttl=55 time=46.521 ms 64 bytes from 119.75.216.20: seq=1 ttl=55 time=45.189 ms ping其它容器 / # ping -c 2 172.17.0.2 PING 172.17.0.2 (172.17.0.2): 56 data bytes 64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.125 ms 64 bytes from 172.17.0.2: seq=1 ttl=64 time=0.075 ms \ruser-defined bridge networks 创建名为apline-net用户自定义网络 当然，你可以手动指定子网，网关这些。 docker network create --driver bridge alpine-net docket network ls NETWORK ID NAME DRIVER SCOPE 810fb1e02000 alpine-net bridge local 8d3b84bfe5a0 bridge bridge local 3579d63da633 host host local f766b990db47 none null local 查看alpine-net网络详情 注意网关和子网发生了变化。 docker network inspect alpine-net [ { \"Name\": \"alpine-net\", \"Id\": \"810fb1e020008c7c6598f3b830ca25896dde638b1190d383ee6a5214d284e77d\", \"Created\": \"2018-06-14T15:45:19.43941906+08:00\", \"Scope\": \"local\", \"Driver\": \"bridge\", \"EnableIPv6\": false, \"IPAM\": { \"Driver\": \"default\", \"Options\": {}, \"Config\": [ { \"Subnet\": \"172.18.0.0/16\", \"Gateway\": \"172.18.0.1\" } ] }, \"Internal\": false, \"Attachable\": false, \"Ingress\": false, \"ConfigFrom\": { \"Network\": \"\" }, \"ConfigOnly\": false, \"Containers\": {}, \"Options\": {}, \"Labels\": {} } ] 创建两种网络的容器 #alpine-net docker run -dit --name alpine1 --network alpine-net alpine ash #default bridge docker run -dit --name alpine2 alpine ash 显示两种网络情况 docker network inspect bridge [ { \"Name\": \"bridge\", \"Id\": \"8d3b84bfe5a034c65d043af80976a1e6127011fc1ab312446252f562e221d351\", \"Created\": \"2018-05-24T18:38:35.538308064+08:00\", \"Scope\": \"local\", \"Driver\": \"bridge\", \"EnableIPv6\": false, \"IPAM\": { \"Driver\": \"default\", \"Options\": null, \"Config\": [ { \"Subnet\": \"172.17.0.0/16\", \"Gateway\": \"172.17.0.1\" } ] }, \"Internal\": false, \"Attachable\": false, \"Ingress\": false, \"ConfigFrom\": { \"Network\": \"\" }, \"ConfigOnly\": false, \"Containers\": { \"893903129d869f384bd78d63a382f1c9527d6979be0a6cf3c13ea4f45a1554d6\": { \"Name\": \"hardcore_rosalind\", \"EndpointID\": \"515d1435470c9f72d3b07680515d9c503","date":"2018-03-27","objectID":"/docker/:36:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"host network host网络不存在隔离问题。 #默认主机上的80端口 docker run -rm -dit --network host --name my_nginx nginx #访问 http://localhost:80 Welcome to nginx! docker network inspect host [ { \"Name\": \"host\", \"Id\": \"3579d63da633adcc497417d39b8b1d270cf329a68b9222f6a75fae72086509d6\", \"Created\": \"2018-04-27T11:31:17.900886126+08:00\", \"Scope\": \"local\", \"Driver\": \"host\", \"EnableIPv6\": false, \"IPAM\": { \"Driver\": \"default\", \"Options\": null, \"Config\": [] }, \"Internal\": false, \"Attachable\": false, \"Ingress\": false, \"ConfigFrom\": { \"Network\": \"\" }, \"ConfigOnly\": false, \"Containers\": { \"f02a3b11fce7228ad6ee196771bd9cf0b64966bfc2aa7c27719bc120dbdc7189\": { \"Name\": \"my_nginx\", \"EndpointID\": \"4ee67fb4d0a0c1a357b5fdd141f856a70c205fad5c49b1cb6a4f5245df0318a8\", \"MacAddress\": \"\", \"IPv4Address\": \"\", \"IPv6Address\": \"\" } }, \"Options\": {}, \"Labels\": {} } ] \r\r","date":"2018-03-27","objectID":"/docker/:36:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"overlay network default overlay network user-defined overlay network overlay network for standalone containers Communicate between a container and a swarm service default overlay 依赖： swarm集群 集群节点 worker-1 worker-2 mananger docker network ls NETWORK ID NAME DRIVER SCOPE 495c570066be bridge bridge local 961c6cae9945 docker_gwbridge bridge local ff35ceda3643 host host local trtnl4tqnc3n ingress overlay swarm c8357deec9cb none null local 创建nginx-net的overlay的网络: docker network create -d overlay nginx-net $ docker service create \\ --name my-nginx \\ --publish target=80,published=80 \\ --replicas=5 \\ --network nginx-net \\ nginx \ruser-defined overlay docker network create -d overlay my-overlay $ docker service create \\ --name my-nginx \\ --network my-overlay \\ --replicas 1 \\ --publish published=8080,target=80 \\ nginx:latest \roverlay network for standalone containers \rCommunicate between a container and a swarm service \r\r","date":"2018-03-27","objectID":"/docker/:36:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"macvalan network 假设主机网络接口为eth0。 bridge 此模式下，流量通过eth0流动，docker使用其MAC地址就流量路由到容器。 创建名为my-macvlan-net的macvlan网络 $ docker network create -d macvlan \\ --subnet=172.16.86.0/24 \\ --gateway=172.16.86.1 \\ -o parent=eth0 \\ my-macvlan-net 查看网络 docker network ls NETWORK ID NAME DRIVER SCOPE 810fb1e02000 alpine-net bridge local 8d3b84bfe5a0 bridge bridge local 3579d63da633 host host local 6be80655739d my-macvlan-net macvlan local f766b990db47 none null local 以此网络运行容器 $ docker run --rm -itd \\ --network my-macvlan-net \\ --name my-macvlan-alpine \\ alpine:latest \\ ash 查看my-macvlan-net docker network inspect my-macvlan-net [ { \"Name\": \"my-macvlan-net\", \"Id\": \"6be80655739deffe204e087d098f97fc75072d95f9818e129cfd7d5667ed01f3\", \"Created\": \"2018-06-14T16:52:30.507647877+08:00\", \"Scope\": \"local\", \"Driver\": \"macvlan\", \"EnableIPv6\": false, \"IPAM\": { \"Driver\": \"default\", \"Options\": {}, \"Config\": [ { \"Subnet\": \"172.16.86.0/24\", \"Gateway\": \"172.16.86.1\" } ] }, \"Internal\": false, \"Attachable\": false, \"Ingress\": false, \"ConfigFrom\": { \"Network\": \"\" }, \"ConfigOnly\": false, \"Containers\": { \"8301b669b4b63afb20911b46243f11b70e5a9d0880beaafa922b52bcb8ab0477\": { \"Name\": \"my-macvlan-alpine\", \"EndpointID\": \"4f2971ba4bd92c34e2a299d301f739867d2b1b65d35566aef07d7a26b079662c\", \"MacAddress\": \"02:42:ac:10:56:02\", \"IPv4Address\": \"172.16.86.2/24\", \"IPv6Address\": \"\" } }, \"Options\": { \"parent\": \"ens160\" }, \"Labels\": {} } ] 查看容器网卡和路由 docker exec my-macvlan-alpine ip addr show eth0 517: eth0@if2: \u003cBROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN\u003e mtu 1500 qdisc noqueue state UNKNOWN link/ether 02:42:ac:10:56:02 brd ff:ff:ff:ff:ff:ff inet 172.16.86.2/24 brd 172.16.86.255 scope global eth0 valid_lft forever preferred_lft forever docker exec my-macvlan-alpine ip route default via 172.16.86.1 dev eth0 172.16.86.0/24 dev eth0 scope link src 172.16.86.2 802.1q trunked bridge network 此模式下，流量流经eth0的子接口(eth0.10)，docker使用其MAC地址将流量路由到容器。 创建名为my-8021q-macvlan-net的macvlan网络 docker network create -d macvlan \\ --subnet=172.16.87.0/24 \\ --gateway=172.16.87.1 \\ -o parent=eth0.10 \\ my-8021q-macvlan-net 查看此网络 docker network ls NETWORK ID NAME DRIVER SCOPE 2aeafd44fd67 my-8021q-macvlan-net macvlan local 6be80655739d my-macvlan-net macvlan local ifconfig eth0.10: flags=4163\u003cUP,BROADCAST,RUNNING,MULTICAST\u003e mtu 1500 inet6 fe80::20c:29ff:feaa:7e75 prefixlen 64 scopeid 0x20\u003clink\u003e ether 00:0c:29:aa:7e:75 txqueuelen 0 (Ethernet) 用此网络启动一个容器 docker run --rm -itd \\ --network my-8021q-macvlan-net \\ --name my-second-macvlan-alpine \\ alpine:latest \\ ash 查看my-8021q-macvlan-net docker network inspect my-8021q-macvlan-net [ { \"Name\": \"my-8021q-macvlan-net\", \"Id\": \"2aeafd44fd67e6ee937c82788745b1d45fb291efd61f545537528eafdff94e3d\", \"Created\": \"2018-06-14T17:06:33.426800076+08:00\", \"Scope\": \"local\", \"Driver\": \"macvlan\", \"EnableIPv6\": false, \"IPAM\": { \"Driver\": \"default\", \"Options\": {}, \"Config\": [ { \"Subnet\": \"172.16.87.0/24\", \"Gateway\": \"172.16.87.1\" } ] }, \"Internal\": false, \"Attachable\": false, \"Ingress\": false, \"ConfigFrom\": { \"Network\": \"\" }, \"ConfigOnly\": false, \"Containers\": { \"90103673d94915c3c7fb572eec8bd97b2aee1c3dab877c598d0a62e6d797b06d\": { \"Name\": \"my-second-macvlan-alpine\", \"EndpointID\": \"5c93f2ea1d29150ee57f099d42fc8e04a571efd0d1273a4f6bed755dc34f2e54\", \"MacAddress\": \"02:42:ac:10:57:02\", \"IPv4Address\": \"172.16.87.2/24\", \"IPv6Address\": \"\" } }, \"Options\": { \"parent\": \"ens160.10\" }, \"Labels\": {} } ] 查看容器网络接口 docker exec my-second-macvlan-alpine ip addr show eth0 519: eth0@if518: \u003cBROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN\u003e mtu 1500 qdisc noqueue state UNKNOWN link/ether 02:42:ac:10:57:02 brd ff:ff:ff:ff:ff:ff inet 172.16.87.2/24 brd 172.16.87.255 scope global eth0 valid_lft forever preferred_lft forever docker exec my-second-macvlan-alpine ip route default via 172.16.87.1 dev eth0 172.16.87.0/24 dev eth0 scope link src 172.16.87.2 \r\r","date":"2018-03-27","objectID":"/docker/:36:4","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"配置守护进程和容器 ","date":"2018-03-27","objectID":"/docker/:37:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"启用IPv6 启用IPv6前，请确保支持IPv6. 给docker daemon启用IPv6: /etc/docker/daemon.json { \"ipv6\": true } \r","date":"2018-03-27","objectID":"/docker/:37:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"iptables 所有Docker的iptables规则都被添加到DOKCER chain。不要手动操作此表。 如果你需要添加Docker规则，请将其添加到DOCKER-USER chain 栗子： iptables -I DOCKER-USER -m iprange -i ext_if ! --src-range 192.168.1.1-192.168.1.3 -j DROP \r","date":"2018-03-27","objectID":"/docker/:37:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"容器网络 容器使用的网络类型(无论是bridge，overlay，macvlan还是自定义网络)，在容器内都是透明的。从容器的角度来看，它有一个带有IP地址，网关，路由表，DNS服务和其它网络细节的网络接口。 publish port 默认情况下，创建容器时，它不会将任何端口发布的外部世界。要是端口可用于docker之外的服务，请使用--publish或-p标志。 -p 8080:80 -p 192.168.1.100:8080:80 -p 8080:80/udp -p 8080:80/tcp -p 8080:80/udp ip add and hostname 默认情况下，容器会为其连接的每个docker网络分配一个IP地址。IP地址是从分配给网络的地址池中分配的，因此docker daemon有效地充当了每个容器的DHCP服务器。每个网络也有一个默认的子网掩码和网关。 同样，一个容器的主机名也有docker daemon指定。 #指定运行网络 docker run xxx --network #运行的容器连接到其它网络 docker network connect #--ip，指定IP地址 docker network connect my-bridge --ip 172.18.0.111 #--hostname，指定主机名 docker run xxx --network xxx --hostname container-01 docker network connect my-bridge --hostname container-02 DNS 默认情况下，容器会继承docker daemon的DNS设置，包括/etc/hosts和/etc/resolv.conf。你也可以基于每个容器覆盖这些默认设置。 #DNS server --dns #DNS搜索域 --dns-search #表示DNS选项值的键值对 --dns-opt --hostname \r","date":"2018-03-27","objectID":"/docker/:37:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"Docker使用代理服务器 在启动docker容器的用户主目录下创建此文件： ~/.docker/config.json { \"proxies\": { \"default\": { \"httpProxy\": \"http://127.0.0.1:3001\", \"noProxy\": \"*.test.example.com,.example2.com\" } } } \r\r \r应用程序数据 Manage application data ","date":"2018-03-27","objectID":"/docker/:37:4","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"存储综述 Manage data in Docker 默认情况下，容器内创建的所有文件都被存储容器的可写层上： 当容器不在运行时，数据不是持续存在的。容器外的进程很难从容器中获取数据 容器的可写层与主机紧密耦合，你很难将数据移动到其他地方 向容器的可写入层写入数据，需要存储驱动(storage driver)管理文件系统才 存储驱动使用Linux kernel来提供一个union filesystem。与直接写入主机文件系统的数据卷相比，这种额外的抽象会降低性能。 Docker容器有两种选项将文件存储到主机上，这样即使容器停止之后这些文件也会被保留: volumes bind mounts tmpfs mount(Docker on Linux) ","date":"2018-03-27","objectID":"/docker/:38:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"选择正确的挂载方式 Choose the right type of mount 无论你选用哪种挂载方式，数据在容器内看起来都是相同的。它被公开为容器文件系统中的目录或单个文件。 一个简单的方法——考虑数据在docker主机上的位置，可以看出volumes, bind mounts, temfs之间的差异： Volumes volumes存储在由docker管理的主机文件系统的一部分中(如Linux上: /var/lib/docker/volumes/)。 non-docker进程不应该修改这部分文件系统。Volume是Docker中保存数据的最佳方式。 Bind mounts bind mounts可存储在主机系统上的任何地方。它们可能是最要的系统文件或目录。 docker主机或docker容器上的non-docker进程可以随时修改它们。 tmpfs 仅存储在主机系统的内存中，不会写入主机系统的文件系统。 volumes的好栗子 Good use cases for volumes Volemes是在docker容器和服务中持久化数据的首选方式: 在多个运行容器之间共享数据。如果你没有明确创建它，会在第一次挂载到容器时创建volume。当容器停止或删除时，volume仍然存在。多个容器可以挂载相同的volume，无论是read-write还是read-only。只有在你手动删除volume时它才会被删除。 当docker主机不能保证具有给定的目录或文件结构时，volume帮助你将docker主机的配置与运行时的容器进行分离。 当你想要将容器的数据存储在远程主机而不是本地的时候。 当你需要备份、还原或将数据从一台docker主机迁移到另一台时，volume时更好的选择。 bind mounts的好栗子 一般来说，你应该尽量使用volumes。bind mounts适合以下案例： 从主机共享配置文件到容器 这就是默认情况下，通过将主机的/etc/resolv.conf挂载到每个容器中，Docker为每个容器提供DNS解析。 在docker主机/容器的开发环境上共享源码或构建工件 当docker主机的文件或目录结构保证与容器所需的bind mounts一致时 tmpfs mounts的好栗子 当你不希望数据在主机上或容器内持久存储时，tmpfs mounts最合适。 这可能处于安全原因，或在应用于程序需要编写大量非持久性状态数据时保护容器的性能。 使用bind或volumes的提示 如果你要使用bind mounts 或 volumes，牢记以下事项： 如果你挂载一个空卷(empty volume)到存在文件或目录的容器中的目录上，则会将这些文件或目录赋值到卷中。同样，如果你启动容器并制定了一个尚不存在的卷，则会为你创建一个空卷。 如果你挂载一个bind mount或non-empty volume到存在文件或目录的容器中的目录上，则这些文件或目录会被挂载所遮蔽。就像在Linux上挂载卷一样。 \r\r","date":"2018-03-27","objectID":"/docker/:38:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"Volumes volumes是持久化Docker数据的首选机制，卷由docker完全管理。另外，由于卷不会增加使用它的容器的大小，并且该卷的内容存在于给定容器的周期之外，因此卷通产是比将容器的可写入层中的数据持久化更好的选择。 -v/--volume #此选项更详细和简单 #如果你需要指定volume driver，请使用此flag --mount docker service create \\ --mount 'type=volume,src=\u003cVOLUME-NAME\u003e,dst=\u003cCONTAINER-PATH\u003e,volume-driver=local,volume-opt=type=nfs,volume-opt=device=\u003cnfs-server\u003e:\u003cnfs-path\u003e,\"volume-opt=o=addr=\u003cnfs-address\u003e,vers=4,soft,timeo=180,bg,tcp,rw\"' --name myservice \\ \u003cIMAGE\u003e --volume 由三个由冒号:分割的字段组成。这些字段必须按照正确的顺序排列，每个字段的含义并不明显。 第一个字段是卷的名称，并且在给定主机上是唯一的。对于匿名卷，第一个字段被省略。 第二个字段是文件或目录在容器中的挂载路径。 第三个字段是可选的，是由一个逗号`,分隔的选项列表。 --mount 由多个键值对组成，以逗号,分隔。--mount的语法比--volume更冗长，但键的顺序并不重要，并且标志的值更易于理解。 挂载的类型(type)有bind, volume, tmpfs。 挂载的来源(source, src)为卷的名称，对于匿名卷该字段可被省略。 目的地(destination, dst, target)的值是安装在容器中的文件或目录的路径。 只读(readonly)选项将导致bind mount以只读方式挂载到容器中。 volume-opt选项可以多次指定，它是由选项名称和值组成的键值对组成。 \r","date":"2018-03-27","objectID":"/docker/:39:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"创建和管理卷 docker volume create my-vol docker volume ls DRIVER VOLUME NAME local my-vol docker volume inspect my-vol [ { \"CreatedAt\": \"2018-06-15T17:19:02+08:00\", \"Driver\": \"local\", \"Labels\": {}, \"Mountpoint\": \"/opt/docker/volumes/my-vol/_data\", \"Name\": \"my-vol\", \"Options\": {}, \"Scope\": \"local\" } ] docker volume rm my-vol \r","date":"2018-03-27","objectID":"/docker/:39:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"启动用卷的容器 Start a container with a volume 包括两种卷： 已存在的卷 未存在的卷 会自动创建 #--mount docker run -d \\ --name devtest \\ --mount source=myvol2,target=/app \\ nginx:latest #--volume docker run -d \\ --name devtest \\ --volume myvol2:/app \\ nginx:latest docker volume ls DRIVER VOLUME NAME local my-vol local myvol2 docker inspect devtest #找到挂载 \"Mounts\": [ { \"Type\": \"volume\", \"Name\": \"myvol2\", \"Source\": \"/opt/docker/volumes/myvol2/_data\", \"Destination\": \"/app\", \"Driver\": \"local\", \"Mode\": \"z\", \"RW\": true, \"Propagation\": \"\" } ] \r","date":"2018-03-27","objectID":"/docker/:39:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"启动用卷的服务 Start a service with volumes docker服务不支持使用--volume标志，请使用--mount标志。 docker service create -d \\ --replicas=4 \\ --name devtest-service \\ --mount source=myvol2,target=/app \\ nginx:latest \r","date":"2018-03-27","objectID":"/docker/:39:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"在机器间共享数据 Share data among machines 在构建容错应用程序时，可能需要配置同一服务的多个副本能访问相同的文件，而这些副本可能分布于不同的节点上。 卷驱动程序(volume driver)允许你从应用程序逻辑中抽象出底层存储系统。 \r","date":"2018-03-27","objectID":"/docker/:39:4","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"使用卷驱动 Use a volume driver 在创建卷或启动带卷的容器时，你可以指定卷驱动。如vieux/sshfs卷驱动程序。 初始化 docker plugin install --grant-all-permissions vieux/sshfs 使用卷驱动创建卷 #操作node2 docker volume create --driver vieux/sshfs \\ -o sshcmd=test@node2:/home/test \\ -o password=testpassword \\ sshvolume 启动一个带用卷驱动程序创建的卷的容器 docker run -d \\ --name sshfs-container \\ --volume-driver vieux/sshfs \\ --mount src=sshvolume,target=/app,volume-opt=sshcmd=test@node2:/home/test,volume-opt=password=testpassword \\ nginx:latest 备份，还原或迁移数据卷 使用--volumes-from标志创建一个挂载该卷的新容器。 #备份 docker run --rm --volumes-from dbstore -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /dbdata #从备份还原 docker run -v /dbdata --name dbstore2 ubuntu /bin/bash docker run --rm --volumes-from dbstore2 -v $(pwd):/backup ubuntu bash -c \"cd /dbdata \u0026\u0026 tar xvf /backup/backup.tar --strip 1\" \r\r","date":"2018-03-27","objectID":"/docker/:39:5","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"bind mounts 与volumes相比，bind mounts功能有限。当你使用bind mounts时，主机上的文件或目录(绝对路径或相对路径)被挂载到容器内。相比之下，当你使用volumes时，会在主机上的Docker存储目录中创建一个新目录，并且Docker会管理该目录的内容。 该文件或目录不需要已经存在于Docker主机上。如果它尚未存在，它会根据需求创建。bind mounts非常高效，但是它们依赖于具有特定目录结构的主机文件系统。如果你正在开发新的Docker Application，请考虑使用volumes。你不能使用Docker CLI直接管理bind mounts。 你可以使用--volume或--mount(语法更详细)flag。具体区别参考volumes的介绍。 ","date":"2018-03-27","objectID":"/docker/:40:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"启动用bind mount的容器 Start a container with a bind mount #--mount docker run -d \\ -it \\ --name devtest \\ --mount type=bind,source=\"$(pwd)\"/target,target=/app \\ nginx:latest #--volume docker run -d \\ -it \\ --name devtest \\ -v \"$(pwd)\"/target:/app \\ nginx:latest 挂载到容器内非空目录 如果挂载在容器内非空目录上，则该目录的已有内容将被隐藏。 #--mount docker run -d \\ -it \\ --name broken-container \\ --mount type=bind,source=/tmp,target=/usr \\ nginx:latest #--volume docker run -d \\ -it \\ --name broken-container \\ -v /tmp:/usr \\ nginx:latest \r","date":"2018-03-27","objectID":"/docker/:40:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"只读bind mount Use a read-only bind mount 某些时候，容器可能只需要只读权限。 #--mount docker run -d \\ -it \\ --name devtest \\ --mount type=bind,source=\"$(pwd)\"/target,target=/app,readonly \\ nginx:latest #--volume docker run -d \\ -it \\ --name devtest \\ -v \"$(pwd)\"/target:/app:ro \\ nginx:latest ","date":"2018-03-27","objectID":"/docker/:40:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"bind propagation 对于bind mounts和volumes，bind propagation(传播)默认为rprivate。它只能对Linux主机上的bind mounts进行配置。它是一个高级话题，许多用户并不需要配置它。 bind propagation(传播)是指在给定的bind-mounts或named volume中创建的挂载是否可以传播(propagation)到该挂载(mount)的副本(replicas)。 考虑一个挂载点/mnt，挂载在/tmp上。传播设置控制/tmp/a上的挂载点是否也可用于/mnt/a。每个传播设置都有一个递归对应点。在递归的情况下，考虑/tmp/a也被挂载到/foo。传播设置控制是否存在/mnt/a和/tmp/a。 传播设置 描述 shared 原始mount的sub-mount会暴露给replica mounts，并且replica mounts的sub-mount同样传播给原始mount。也就是双向 slave 类似于shared，但仅限于单方向。 private 私有挂载 rshared 与shared相同，但传播也扩展到嵌套在任何原始或副本挂载点内的挂载点 rslave 与slave相同，但传播也扩展到嵌套在任何原始或副本挂载点内的挂载点 rprivate 默认值。与private相同，这意味着原始或副本挂载点内的任何位置的挂载点都不会沿任一方向传播 在设置bind propagation之前，主机文件系统需要已经支持bind propagatin: https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt #--mount docker run -d \\ -it \\ --name devtest \\ --mount type=bind,source=\"$(pwd)\"/target,target=/app \\ --mount type=bind,source=\"$(pwd)\"/target,target=/app2,readonly,bind-propagation=rslave \\ nginx:latest #--volume docker run -d \\ -it \\ --name devtest \\ -v \"$(pwd)\"/target:/app \\ -v \"$(pwd)\"/target:/app2:ro,rslave \\ nginx:latest \r","date":"2018-03-27","objectID":"/docker/:40:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"selinux label 如果你使用selinux，你可以添加z或Z选项来修改挂载到容器内的主机文件或目录的selinux标签。这户影响主机本身的文件或目录，并可能导致Docker范围之外的后果。 z bind mount的内容在多个容器之间共享。 Z bind mount的内容是私有和非共享的。 #不支持--mount docker run -d \\ -it \\ --name devtest \\ -v \"$(pwd)\"/target:/app:z \\ nginx:latest \r\r","date":"2018-03-27","objectID":"/docker/:40:4","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"tmpfs mounts tmpfs: https://docs.docker.com/storage/tmpfs/#limitations-of-tmpfs-mounts tmpfs mounts只支持运行在Linux上的Docker。 \r\r","date":"2018-03-27","objectID":"/docker/:41:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"Troubleshoot troubleshoot: https://docs.docker.com/storage/troubleshooting_volume_errors/ \r\r","date":"2018-03-27","objectID":"/docker/:42:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"将数据存储到容器内 Store data within containers ","date":"2018-03-27","objectID":"/docker/:43:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"关于存储驱动 为了有效地使用存储驱动(storage driver)，了解Docker如何构建和存储镜像，以及容器如何使用镜像是很重要的。你可以使用这些信息作出明智的选择，以便找到应用程序数据持久化的最佳方式，并避免出现性能问题。 存储驱动允许你在容器的可写入层创建数据。在容器停止后，这些文件将不会被保留，并且读写速度都很低。 \r镜像和层 Images and layers Docker镜像由一系列层(layer)构建而成。每个层代表镜像的Dockerfile中的指令，除最后一层外的每个层都是只读的。 考虑如下Dockerfile: FROM ubuntu:15.04 COPY . /app RUN make /app CMD python /app/app.py 此Dockerfile包含4个命令，每个命令创建一个层。 当你创建一个新容器时，你在底层之上添加了一个新的可写入层——它通常被称为容器层(container layer)。 对运行中的容器所做的所有更改(增删改文件)都会写入此可写容器层。 存储驱动处理有关这些层相互交互的详细信息。有几个不同的驱动程序，在不同的情况下具有相应的优点和缺点。 \r容器和层 Container and layers 容器和镜像之间的主要区别是最高的可写入层。当容器删除时，可写入层也被删除。但底层镜像保持不变。 由于每个容器都有自己的可写入容器层，并且所有的更改都存储在此容器中，因此多个容器可以共享相同的基础镜像的访问权限，并拥有自己的数据状态。 Docker使用存储驱动来管理镜像层和可写入容器层的内容。每个存储驱动程序都已不同方式实现，但所有驱动程序都是用可堆叠(stackable)的镜像层和写入时复制(copy-on-write)策略。 \r容器大小 Container size on disk 使用docker ps -s(--size)命令查看正在运行的容器的大小。有两个大小: size 每个容器的可写入层的数据量(在磁盘上的) virtual size 容器使用的只读镜像的数据量加上容器可写入层大小 \r\r写入时复制 The copy-on-write (CoW) strategy 写入时复制是一种共享和复制文件以实现最高效率的策略。如果文件或目录存在于镜像的较低层中，而另外的层(包括可写入层)需要对其进行读取访问，则它只是用已有文件。第一次需要修改文件时，该文件将被复制到该层并进行修改。这最大限度减少了每个后续层的I/O和大小。 共享促进了较小的容器 Sharing promotes smaller images 当你创建和拉取镜像时，它们通常存储于本机的/var/lib/docker下。每层都存储在主机存储区内的特定目录下/var/lib/docker/\u003cstorage-driver\u003e/layers。 ls /var/lib/docker/aufs/layers 1d6674ff835b10f76e354806e16b950f91a191d3b471236609ab13a930275e24 5dbb0cbe0148cf447b9464a358c1587be586058d9a4c9ce079320265e2bb94e7 bef7199f2ed8e86fa4ada1309cfad3089e0542fec8894690529e4c04a7ca2d73 ebf814eccfe98f2704660ca1d844e4348db3b5ccc637eb905d4818fbfb00a06a 复制使容器高效 Copying makes containers efficient 容器不会更改的任何文件都不会被复制到此可写入层中。这意味着可写入层尽可能小。 当容器中存在的文件被修改时，存储驱动之赐你个写入时复制操作(CoW)。涉及的具体步骤取决于具体的存储驱动。 aufs, overlay, overlay2存储驱动 遵循的基本顺序: 通过镜像层搜索要更新的文件 对找到的文件的第一个副本执行copy_up操作，将文件复制到容器的可写入层 任何修改应用于此复制的文件，并且该容器不能看到存在于较低层中的文件的只读副本 \r\r","date":"2018-03-27","objectID":"/docker/:43:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"选择存储驱动 Select a storage driver 理想情况下，将很少的数据写入容器的可写入层，并且使用Docker volume写入数据。但某些工作负载要求你能够写入容器的可写入层，这就是存储驱动进来的地方。 存储驱动控制镜像和容器在Docker主机上的存储和管理方式。 考虑三个高层次因素： 如果你的Kernel支持多个存储驱动，在没有指定存储驱动的情况下，Docker会列出要使用拿个存储驱动程序的优先级列表 如果可能，将使用配置最少的存储驱动。如brrfs, zfs 否则，请尝试在最常见的情况下使用具有最佳整体性能和稳定性的存储驱动程序 overlay2是首选(Docker CE的默认选择)，其次是overlay。这些都不需要额外的配置。 devicemapper居次，但需要direc-lvm用于生产环境，因为loopback-lvm的性能很差。 你的选择会受限于Docker版本、操作系统和发行版 某些存储驱动要求你为文件系统使用特定格式 你的选择还取决于工作负载和所需的稳定级别 \rLinux发行版支持的存储驱动 Docker CE Linux distribution Recommended storage drivers Docker CE on Ubuntu aufs, devicemapper, overlay2 (Ubuntu 14.04.4 or later, 16.04 or later), overlay, zfs, vfs Docker CE on Debian aufs, devicemapper, overlay2 (Debian Stretch), overlay, vfs Docker CE on CentOS devicemapper, vfs Docker CE on Fedora devicemapper, overlay2 (Fedora 26 or later, experimental), overlay (experimental), vfs \r存储驱动支持的文件系统 Storage driver Supported backing filesystems overlay, overlay2 ext4, xfs aufs ext4, xfs devicemapper direct-lvm btrfs btrfs zfs zfs \r查看存储驱动 docker info Server Version: 18.03.1-ce Storage Driver: overlay2 \r","date":"2018-03-27","objectID":"/docker/:43:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"AUFS存储驱动 AUFS is a union filesystem. aufs存储驱动用于管理Ubuntu上Docker的镜像和层。 我的发行版是Centos，此驱动针对Ubuntu。注意 \r使用aufs存储驱动配置Docker 判断kernel是否支持aufs grep aufs /proc/filesystems 查看Docker存储驱动 docker info 配置存储驱动 vim /etc/docker/daemon.json #或 --storage-driver \raufs存储驱动如何工作 AUFS是一个联合文件系统，这意味着它在单个Linux主机上对多个目录进行分层并将它们呈现为单个目录。这些目录在AUFS术语中称为分支，在Docker术语中称为层。统一过程被称为联合安装。 \r容器如何使用aufs进行读写 读取文件 \r","date":"2018-03-27","objectID":"/docker/:43:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"Btrfs存储驱动 Use the BTRFS storage driver \r","date":"2018-03-27","objectID":"/docker/:43:4","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"Device Mapper存储驱动 Use the Device Mapper storage driver Device Mapper是基于kernel的框架，支持Linux上的许多高级卷管理技术。Docker的devicemapper存储驱动利用此框架的精简配置和快照功能进行镜像和容器管理。 对于支持它的系统，devicemapper支持包含在Linux内核中。但是，需要特定配置才能将其用于Docker。devicemapper驱动使用专用于Docker的块设备，并在块级(block level)而不是文件级(file level)运行。这些设备可通过在Docker主机添加物理设备来扩展，并且它们比咋子操作系统级别使用文件系统更好。 依赖 Docker EE Docker CE 更改存储驱动会使已创建的容器在本地系统上都无法访问 配置devicemapper存储驱动 loop-lvm #loop-lvm模式 /etc/docker/daemon.json { \"storage-driver\": \"devicemapper\" } #查看 docker info direct-lvm 生产环境的devicemapper存储驱动必须使用direct-lvm模式。此模式使用块设备创建精简池。这比使用loopback设备更快，更高效地使用系统资源，并且块设备可以根据需求进行扩展。 \r Option Description Required Default Example dm.directlvm_device The path to the block device to configure for direct-lvm. Yes - dm.directlvm_device=\"/dev/xvdf\" dm.thinp_percent The percentage of space to use for storage from the passed in block device. No 95 dm.thinp_percent=95 dm.thinp_metapercent The percentage of space to for metadata storage from the passed-in block device. No 1 dm.thinp_metapercent=1 dm.thinp_autoextend_threshold The threshold for when lvm should automatically extend the thin pool as a percentage of the total storage space. No 80 dm.thinp_autoextend_threshold=80 dm.thinp_autoextend_percent The percentage to increase the thin pool by when an autoextend is triggered. No 20 dm.thinp_autoextend_percent=20 dm.directlvm_device_force Whether to format the block device even if a filesystem already exists on it. If set to false and a filesystem is present, an error is logged and the filesystem is left intact. No false dm.directlvm_device_force=true #安装依赖 RHEL / CentOS: device-mapper-persistent-data, lvm2, and all dependencies Ubuntu / Debian: thin-provisioning-tools, lvm2, and all dependencies #创建物理卷(physical volume) pvcreate /dev/cvdf #创建卷组(volume group) vgcreat docker /dev/xvdf #创建逻辑卷(logical volume) lvcreate --wipesignatures y -n thinpool docker -l 95%VG lvcreate --wipesignatures y -n thinpoolmeta docker -l 1%VG #转换卷为精简池 lvconvert -y \\ --zero n \\ -c 512K \\ --thinpool docker/thinpool \\ --poolmetadata docker/thinpoolmeta #配置lvm配置文件精简池自动扩展 /etc/lvm/profile/docker-thinpool.profile #指定thin_pool_autoextend_threshold 和 thin_pool_autoextend_percent的值 activation { thin_pool_autoextend_threshold=80 thin_pool_autoextend_percent=20 } #应用LVM profile lvchange --metadataprofile docker-thinpool docker/thinpool #启用监控LV lvs -o+seg_monitor #配置devicemapper存储驱动 /etc/docker/daemon.json { \"storage-driver\": \"devicemapper\", \"storage-opts\": [ \"dm.thinpooldev=/dev/mapper/docker-thinpool\", \"dm.use_deferred_removal=true\", \"dm.use_deferred_deletion=true\" ] } #查看 docker info 管理devicemapper #查看LVM logs journalctl -fu dm-event.service pvdisplay vgdisplay/vgextend lvdisplay/lvextend/lvchange \r","date":"2018-03-27","objectID":"/docker/:43:5","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"OverlayFS存储驱动 Use the OverlayFS storage driver \r","date":"2018-03-27","objectID":"/docker/:43:6","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"ZFS存储驱动 Use the ZFS storage driver \r","date":"2018-03-27","objectID":"/docker/:43:7","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"VFS存储驱动 Use the VFS storage driver VFS存储驱动不是联合文件系统，相反，每层都是磁盘上的一个目录，它不支持CoW。要创建一个新层，先前的层会进行深层复制(deep copy)。与其它驱动相比，这导致磁盘性能下降和占用更多磁盘空间。但是，它强大，稳定，适用于各种环境。 配置VFS存储驱动 vim /etc/docker/daemon.json { \"storage-driver\": \"vfs\" } #控制大小 { \"storage-opts\": [\"size=256M\"] } #查看 docker info \r\r \r在生产环境运行应用程序 Run your app in production ","date":"2018-03-27","objectID":"/docker/:43:8","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"配置对象 Configure all objects ","date":"2018-03-27","objectID":"/docker/:44:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"自定义原数据 Apply custom metadata to objects Docker object label 标签(label)是一种将原数据(metadata)应用于docker object的机制，包含: image container local daemon volume network node service label key and value 标签是一组键值对，以字符串形式存储。可以为对象指定多个标签，但每个键值对必须唯一。如果一个键有多个值，则最新写入的值会覆盖以前的值。 key格式建议 label key是可能包含字母，数字，.，-组成的字符串。 第三方工具的作者给每个label key加上前缀域，如com.example.some-label 未经允许，不得使用他人域 com.docker.*, io.docker.*, org.dockerproject.*命名空间保留给Docker内部使用 以小写字母开头和结尾 用.分割命令空间字段 value 指南 label value可以包含任何可表示为字符串的数据类型，包括JSON, XML, CSV, YAML…唯一的要求是，首先使用特定于结构类型的机制将该值序列化为字符串。 \r\r","date":"2018-03-27","objectID":"/docker/:44:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"清理未使用的对象 Prune unused Docker objects Docker采取保守的方法来清理未使用的对象(通常称为垃圾回收)，通常它不会删除这些对象，除非你明确要求Docker这样做。对于每个类型的对象，docker提供了prune命令。你也可以使用docker system prune命令一次清理多种类型的对象。 #prune image docker image prune docker image prune -a --filter \"until=24h\" #prune container docker container prune #prune volume docker volume prune docker volume prune --filter \"label!=keep\" #prune everything docker system prune docker system prune --volumes \r\r","date":"2018-03-27","objectID":"/docker/:44:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"格式化输出 Format command and log output #join docker inspect --format '{{join .Args \" , \"}}' container #json docker inspect --format '{{json .Mounts}}' container #lower docker inspect --format \"{{lower .Name}}\" container #split docker inspect --format '{{split .Image \":\"}}' #title docker inspect --format \"{{title .Name}}\" container #upper docker inspect --format \"{{upper .Name}}\" container #printIn docker inspect --format='{{range .NetworkSettings.Networks}}{{println .IPAddress}}{{end}}' container \r\r","date":"2018-03-27","objectID":"/docker/:44:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"配置daemon Configure the daemon \r","date":"2018-03-27","objectID":"/docker/:45:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"配置和运行Docker 配置docker daemon 使用json配置文件 使用dockerd --flag /etc/docker/daemon.json { \"debug\": true, \"tls\": true, \"tlscert\": \"/var/docker/server.pem\", \"tlskey\": \"/var/docker/serverkey.pem\", \"hosts\": [\"tcp://192.168.59.3:2376\"] } #或 dockerd --debug \\ --tls=true \\ --tlscert=/var/docker/server.pem \\ --tlskey=/var/docker/serverkey.pem \\ --host tcp://192.168.59.3:2376 docker daemon目录 docker daemon将所有数据保存在一个目录中。你可以手动修改它。 默认目录: Linux： /var/lib/docker Windows: C:\\ProgramData\\docker \r\r","date":"2018-03-27","objectID":"/docker/:45:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"使用systemd控制docker Control Docker with systemd cat /usr/lib/systemd/system/docker.service #or cat /etc/systemd/system/docker.service systemctl enable/start/stop/status docker 自定义docker daemon选项 vim /etc/docker/daemon.json { \"data-root\": \"/mnt/docker-data\", \"storage-driver\": \"overlay\" } http/https proxy Docker daemon使用HTTP_PROXY，HTTPS_PROXY和NO_PROXY环境变量来配置代理行为。无法使用daemon.json文件来配置环境变量。 mkdir -p /etc/systemd/system/docker.service.d #/etc/systemd/system/docker.service.d/http-proxy.conf [Service] Environment=\"HTTP_PROXY=http://proxy.example.com:80/\" #/etc/systemd/system/docker.service.d/https-proxy.conf [Service] Environment=\"HTTPS_PROXY=https://proxy.example.com:443/\" systemctl daemon-reload systemctl restart docker systemctl show --property=Environment docker \r\r","date":"2018-03-27","objectID":"/docker/:45:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"收集Docker指标 Collect Docker metrics with Prometheus Promethus: https://prometheus.io/ Prometheus是一个开源的系统监控和报警工具包。你可以将Docker配置为Prometheus target。设置Prometheus作为Docker容器运行，并使用Prometheus监控Docker实例。 配置Docker 配置docker daemon作为Prometheus target，你需要指定metrics-address。最佳方式是通过daemon.json。 { \"metrics-addr\" : \"127.0.0.1:9323\", \"experimental\" : true } 配置和运行Prometheus /tmp/prometheus.yml # my global config global: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s). # Attach these labels to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: monitor: 'codelab-monitor' # Load rules once and periodically evaluate them according to the global 'evaluation_interval'. rule_files: # - \"first.rules\" # - \"second.rules\" # A scrape configuration containing exactly one endpoint to scrape: # Here it's Prometheus itself. scrape_configs: # The job name is added as a label `job=\u003cjob_name\u003e` to any timeseries scraped from this config. - job_name: 'prometheus' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. static_configs: - targets: ['localhost:9090'] - job_name: 'docker' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. static_configs: - targets: ['localhost:9323'] docker service create --replicas 1 --name my-prometheus \\ --mount type=bind,source=/tmp/prometheus.yml,destination=/etc/prometheus/prometheus.yml \\ --publish published=9090,target=9090,protocol=tcp \\ prom/prometheus 访问: http://localhost:9090/targets/ \r\r","date":"2018-03-27","objectID":"/docker/:45:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"配置容器 Configure containers ","date":"2018-03-27","objectID":"/docker/:46:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"自动启动容器 Start containers automatically Docker提供了重启策略，以控制容器在退出或重启时自动启动。重启策略可确保链接的容器以正确的书序启动。Docker建议你使用重启策略，并避免使用进程管理器(如supervisor)来启动容器。 重启策略与docker xxx --live-restart标志不同，后者可以让你在Docker upgrage期间保持容器运行。 重启策略 使用docker run xxx --restart标志来配置重启策略，--restart的值如下： 标志 描述 no 不要自动重启容器(默认值) on-failure 如果容器由于错误(非零退出码)退出，则重启容器 unless-stopped 除非明确停止或docker本身停止或重启，则重启容器 always 如果停止，则始终重启容器 #栗子 docker run -dit --restart unless-stopped redis 重启策略注意事项 重启策略尽在容器成功启动后才生效——这意味着容器已启动至少10s，并且Docker已开始监视它。 这可以防止根本不启动的容器进入重启循环。 如果你手动停止容器(状态码为0)，则在重启Docker daemon或手动启动容器之前，其重启策略将会被忽略。 这是另一个防止重启循环的尝试。 重启策略仅适用于容器。集群服务的重启策略与此不同。 \r\r","date":"2018-03-27","objectID":"/docker/:46:1","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"在daemon停机期间保持容器活着 Keep containers alive during daemon downtime 默认情况下，当Docker daemon终止时，它会关闭正在运行的容器。从Docker Engine 1.12开始，你可配置守护进程，以便在守护进程不可用时容器保持运行。这个功能被称为实时恢复(live restore)。 它不支持Windows container。 实时恢复 有两种方式来启用live restore，只启用其中一个就好。 实时恢复仅适用于独立容器，不适用于集群服务。 修改配置文件 /etc/docker/daemon.json { \"live-restore\": true } --live-restore标志 不推荐 dockerd xxx --live-restore \r\r","date":"2018-03-27","objectID":"/docker/:46:2","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"在一个容器中运行多个服务 Run multiple services in a container 容器的主要运行进程是Dockerfile末尾的ENTRYPOINT或CMD指令。通常建议你通过每个容器运行一项服务来分割关注区域。这些服务可能会分成多个进程(如Nginx的worker processe)。你可以使用用户定义的network和shared volumes来连接多个容器。 容器的主进程负责管理它启动的所有进程。在某些情况下，主进程设计不好，在容器退出时无法正常处理停止子进程。如果你的进程属于这个类别，你可在容器运行时使用--init选型。--init标志将一个微小的inti-process作为主进程插入到容器中，并在容器退出时处理所有进程的停止。以这种方式处理这些进程优于使用完整的初始化进程。 如果你需要在一个容器中运行多个服务，则可通过几种不同方式来完成此操作。 将所有命令封装进一个脚本中，并附带测试和调试信息。以封装脚本作为你的CMD vim my_wrapper.sh #!/bin/bash xxxxx xxx vim Dockerfile FROM ubuntu:latest COPY my_first_process my_first_process COPY my_second_process my_second_process COPY my_wrapper_script.sh my_wrapper_script.sh CMD ./my_wrapper_script.sh 使用如supervisord这样的进程管理器 FROM ubuntu:latest RUN apt-get update \u0026\u0026 apt-get install -y supervisor RUN mkdir -p /var/log/supervisor COPY supervisord.conf /etc/supervisor/conf.d/supervisord.conf COPY my_first_process my_first_process COPY my_second_process my_second_process CMD [\"/usr/bin/supervisord\"] \r\r","date":"2018-03-27","objectID":"/docker/:46:3","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"容器运行指标 Container runtime metrics docker stats docker stats redis1 redis2 CONTAINER CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O redis1 0.07% 796 KB / 64 MB 1.21% 788 B / 648 B 3.568 MB / 512 KB redis2 0.07% 2.746 MB / 64 MB 4.29% 1.266 KB / 648 B 12.4 MB / 0 B Control groups Linux Container依赖于control group，这些组不仅跟踪进程组，还公开有关CPU，mem，block I/O的使用情况和度量标准。你可以访问这些指标并判断容器运行状况。 control group通过为文件系统(pseudo-fs)公开，你应该可在/proc/fs/cgroup中找到它。 查看cgroup子系统： grep cgroup /proc/mounts #or mount -l | grep cgroup #进程 /proc/\u003cpid\u003e/cgroup #/表示进程尚未分配给group cat /proc/1/cgroup 11:devices:/ 10:cpuset:/ 9:hugetlb:/ 8:memory:/ 7:blkio:/ 6:net_prio,net_cls:/ 5:pids:/ 4:perf_event:/ 3:cpuacct,cpu:/ 2:freezer:/ 1:name=systemd:/ 查找给定容器的cgroup 对于每个容器，每个层次结构中创建一个cgroup。 /sys/fs/cgroup/memory/docker/\u003cdocker-longid\u003e/ cd /sys/fs/cgroup/memory/docker/893903129d869f384bd78d63a382f1c9527d6979be0a6cf3c13ea4f45a1554d6 cat memory.stat cache 36282368 rss 196608 rss_huge 0 mapped_file 1077248 swap 0 pgpgin 212904 pgpgout 205531 pgfault 314692 pgmajfault 204 inactive_anon 131072 active_anon 65536 inactive_file 18223104 active_file 18059264 unevictable 0 hierarchical_memory_limit 9223372036854771712 hierarchical_memsw_limit 9223372036854771712 total_cache 36282368 total_rss 196608 total_rss_huge 0 total_mapped_file 1077248 total_swap 0 total_pgpgin 212904 total_pgpgout 205531 total_pgfault 314692 total_pgmajfault 204 total_inactive_anon 131072 total_active_anon 65536 total_inactive_file 18223104 total_active_file 18059264 total_unevictable 0 #其它信息类似 \r\r","date":"2018-03-27","objectID":"/docker/:46:4","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"限制容器的资源 Limit a container’s resources 默认情况下，容器没有资源限制，可以使用主机内核调度程序允许给定的资源。Docker提供了一些方法来控制容器可以使用的CPU、memory、block I/O。 许多这些功能需要内核的支持。使用docker info命令检查是否支持。如果内核禁用了某功能，则可能会有如下警告: WARNING: No swap limit support memory 你需要了解内存耗尽(out of memory)的风险 不要让正在运行的容器消耗太多的主机内存，这很重要。在Linux主机上，如果内核检测到没有足够的内存来执行重要的系统功能，它会抛出一个OOME(out of memory exception)，并开始killing process以释放进程。任何进程都会是killing objects，包括Docker和其它重要应用程序。 docker尝试通过调整docker daemon的OOM优先级来降低这些风险，从而使其比系统上的其它进程更小(less)可能的被killing。容器的OOM优先级不进行调整，这使得单个容器被killing的可能性要大于docker或其它进程。你不应该给docker daemon的--oom-score-adj或container的--oom-kill-disable标志来绕过这些安全措施。 你可以通过以下方式减轻由OOM引起的系统不稳定的风险: 在上线之前，进行测试以了解应用程序的内存需求 确保应用程序仅在拥有足够资源的主机上运行 限制容器可使用的内存量 在主机上配置swap时请注意。swap比内存更慢，性能更低，但可以提供缓冲区以防系统内存耗尽 考虑将容器转换为服务，并使用服务级别约束和节点标签来确保应用程序仅在具有足够内存的主机上运行 限制容器对内存的 Limit a container’s access to memory Docker可以强制hard limit，允许容器使用不超过给定数量的用户/系统内存，或soft limit。这允许容器使用尽可能多的内存。 如下这些选项具有这样一些效果，注意内存单位b, k, m, g： 选项 描述 -m/--memory= 容器可使用的最大内存量。如果你设置此选项，则允许的最小值为4m --memory-swap 容器允许使用的swap量。只有在--momery设置时才有意义 --memory-swappiness 默认情况下，容器可使用的主机内核可交换的匿名页面的百分比\u003c0-100\u003e --memory-reservation 允许你指定一个小于--memory的soft limit。当docker检测到内存不足时，此会被激活 --kernel-memory 容器可以使用的最大kernel memory。内核内存不能够被swap out，因此内核内存不足的容器可能会阻塞主机资源，这会对主机和其它容器产生副作用 --oom-kill-disable 默认情况下，如果发生内存溢出(OOM)，内核会杀死容器中的进程。使用此选项改变此行为 \rcpu 默认情况下，每个容器对主机CPU周期的访问是无限制的。你可以设置各种约束来限制给定容器访问主机的CPU周期。 CFS scheduler CFS是用于普通Linux进程的Linux kernel CPU调度器，一些运行时标志用于配置容器的CPU资源访问量。 选项 描述 --cpu=\u003cvalue\u003e 指定容器可以使用的CPU资源，如--cpu=\"1.6\" --cpu-period=\u003cvalue\u003e 指定CFS调度器周期，它与--cpu-quota一起使用。默认100ms。Docker1.13以后，使用--cpus替代 --cpu-quota=\u003cvalue\u003e 在容器上条件CFS配额。在Docker1.13以后，使用--cpus替代 --cpuset-cpus 限制容器可以使用的特定CPU或CORE。如果有多个CPU，请使用逗号,分割。如0,2 --cpu-shares 将此标志设置为大于/小于1024(默认值)的值，以增加或减少容器的重量，并使其能够访问更大或更小比例的主机CPU周期。这仅在CPU周期受到限制时才会执行。 如果你只有1 CPU，如下命令可保证容器每秒最多有50%的CPU——docker run -it --cpus=\".5\" xxx realtime scheduler 在Docker1.13及更高版本，对于无法使用CFS的任务，你可以使用realtime scheduler。 在你配置docker daemon和container之前，请正确地配置主机内核。 注意： CPU调度和优先级是高级内核功能。大多数用户不需要修改它。错误地设置将导致主机系统不稳定或不可用。 配置主机内核 通过运行zcat /proc/config.gz | grep CONFIG_RT_GROUP_SCHED或检查/sys/fs/cgroup/cpu.rt_runtime_us来验证内核是否启用了CONFIG_RT_GROUP_SCHED。有关配置内核实时调度器的指导，请参考相关文档。 配置docker daemon 运行docker daemon时使用--cpu-rt-runtime标志设置每个运行时间段的实时任务保留的最大微秒数。可使用systemd的docker.service进行配置。 配置独立容器 当使用docker run启动容器时，可以传递多个标志来控制容器CPU的优先级。 选项 描述 --cap-add=sys_nice 授予容器CAP_SYS_NICE功能，允许容器提升进程的nice值，设置实时调度策略，设置CPU关联和其它操作 --cpu-rt-runtime=\u003cvalue\u003e Docker实时调度器期间，容器可以以实时优先级运行的最大微秒数。需要--cap-add=sys_nice标志 --ulimit rtprio=\u003cvalue\u003e 容器允许的最大实时优先级，需要--cap-add=sys_nice标志 栗子： docker run --it --cpu-rt-runtime=950000 \\ --ulimit rtprio=99 \\ --cap-add=sys_nice \\ debian:jessie \r\r","date":"2018-03-27","objectID":"/docker/:46:5","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"Logging 查看容器日志 记录的信息和日志格式取决于容器的端点命令。 docker logs命令显示正在运行的容器记录的信息。 docker service logs命令显示参与服务的所有容器记录的信息。在swarm模式下。 在某些情况下，docker logs可能不会显示有用的信息，除非你采取其它措施。 如果将日志发送到文件、主机、数据库或其它日志驱动程序，则docker logs可能不会显示有用的信息 如果你的镜像运行non-interactive进程(如数据库)，则该应用程序可能会将output发送到日志文件而不是stdout/stderr \r配置日志驱动 Configure logging drivers docker提供了多种日志记录机制(logging mechanisms)来帮助你从运行的容器和服务中获取信息。这些机制被称为日志驱动(logging driver)。 每个docker daemon都有一个默认日志驱动，每个容器也默认使用该驱动。除非你给容器配置了其它日志驱动。 除了使用docker附带日志驱动，在Docker v17.05之后，你还可以使用日志驱动插件(logging driver plugin)。 配置默认日志驱动 默认的日志驱动是json-flie。 可在daemon.json文件里通过log-driver选项匹配置日志驱动。 /etc/docker/daemon.json #设置为syslog { \"log-driver\": \"syslog\" } 如果日志驱动存在可配置选项： /etc/docker/daemon.json { \"log-driver\": \"json-file\", \"log-opts\": { \"labels\": \"production_status\", \"env\": \"os,customer\" } } #查看 docker info | grep 'Loggin Driver' Logging Driver: json-file 为容器配置日志驱动 启动容器时，可使用--log-driver标志为其配置不同于docker daemon的日志驱动。 docker run -it --log-driver none alpine ash #查看容器日志驱动 docker inspect -f '{{.HostConfig.LogConfig.Type}}' \u003cCONTAINER\u003e 配置从容器到日志驱动的log message的交付模式 Docker为从容器到日志驱动的日志消息提供了两种交付(delivery）模式： 直接阻塞(blocking)从容器到驱动的交付(默认) 非阻塞交付(non-blocking)，将日志消息存储在中间每个容器的环形缓冲区中供驱动使用 非阻塞消息交付模式可防止应用程序因日志反压而被阻塞。当STDERR或STDOUT流阻塞时，应用程序可能会以意想不到的方式失败。 注意：当缓冲区已满且新消息排入队列时，内存中最早的消息将被丢弃。丢弃消息通常首选阻止应用程序的日志写入过程。 docker run -it --log-opt mode=non-blocking --log-opt max-buffer-size=4m alpine ping 127.0.0.1 日志驱动使用环境变量或label 一些日志驱动将容器的--env/-e或--label标签的值添加到容器的日志中。 docker run -dit --label production_status=testing -e os=ubuntu alpine sh 支持的日志驱动 如下是受支持的日志驱动。 驱动 描述 none No logs are available for the container and docker logs does not return any output. json-file The logs are formatted as JSON. The default logging driver for Docker. syslog Writes logging messages to the syslog facility. The syslog daemon must be running on the host machine. journald Writes log messages to journald. The journald daemon must be running on the host machine. gelf Writes log messages to a Graylog Extended Log Format (GELF) endpoint such as Graylog or Logstash. fluentd Writes log messages to fluentd (forward input). The fluentd daemon must be running on the host machine. splunk Writes log messages to splunk using the HTTP Event Collector. logentries Writes log messages to Rapid7 Logentries. 云日志系统 各类云服务商提供的云日志系统 docker logs命令不适用于除json-file和journald之外的其它日志驱动。 \r日志驱动插件 日志驱动插件允许你扩展和定制docker的日志记录功能，超越了内置的日志驱动的功能。 安装日志驱动插件 docker plugin install \u003corg/image\u003e docker plugin ls 将插件配置为docker daemon默认日志驱动 /etc/docker/daemon.josn #or --loggin-driver 将插件配置为容器日志驱动 docker run xxx --log-driver \r定制日志驱动输出 Customize log driver output 日志选项tag指定如何格式化表示容器日志消息。默认情况下，系统使用容器ID的前12个字符。你可以指定tag选项来覆盖此行为： docker run --log-driver=fluentd \\ --log-opt fluentd-address=myhost.local:24224 \\ --log-opt tag=\"mailer\" 在指定tag时，Docker支持的一些特殊模板标记： {{.ID}} The first 12 characters of the container ID {{.FullID}} The full container ID {{.Name}} The container name {{.ImageID}} The first 12 characters of the container’s image ID {{.ImageFullID}} The container’s full image ID {{.ImageName}} The name of the image used by the container {{.DaemonName}} The name of the docker program (docker) --log-opt tag=\"{{.ImageName}}/{{.Name}}/{{.ID}}\" Aug 7 18:33:19 HOSTNAME hello-world/foobar/5790672ab6a0[9103]: Hello from Docker. \r日志驱动 介绍如下日志驱动！ Logentries Logentries日志驱动将容器日志发送到Logentries server。 --log-opt: logentries-token: 指定Logentries log设置的token line-only: 仅发送原始有效载荷 docker daemon: dockerd --log-driver=logentries #可在docker.service中设置 docker container: docker run --log-driver=logentries ... 在使用此日志驱动之前，你需要在Logentries web界面中创建一个新的日志集，并将该日志集的令牌传递给docker： docker run --log-driver=logentries --log-opt logentries-token=abcd1234-12ab-34cd-5678-0123456789ab \rjson file 默认情况下，docker捕获所有容器的STDOUT和STDERR，并使用json格式将它们写入文件。每个文件包含仅包含一个容器的信息。 /etc/docker/daemon.json { \"log-driver\": \"json-file\", \"log-opts\": { \"max-size\": \"10m\" } } #or docker run \\ --log-driver json-file --log-opt max-size=10m \\ alpine echo hello world #栗子 docker run -it --log-opt max-size=10m --log-opt ma","date":"2018-03-27","objectID":"/docker/:46:6","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"安全 \r\r \r\rCGroup 参考: wiki DOCKER基础技术：LINUX CGROUP CGroup 介绍、应用实例及原理描述 linux cgroup 简介 Linux资源管理之cgroups简介 \r\r","date":"2018-03-27","objectID":"/docker/:46:7","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"简介 CGroup(Linux Control Groups)，是Linux内核的一个功能，用来限制、控制与分离一个进程组群的资源(CPU, Mem, Disk I/O…)。你可以监控你配置的CGroup，拒绝CGroup访问某些资源，甚至在运行的系统中动态配置CGroup。 CGroup的一个设计目标是为不同的应用情况提供统一的结构，从控制单一进程(nice)到操作系统层虚拟化(OpenVZ, Linux-VServer, LXC)。CGroup提供: 资源限制(Resource limitation)：限制资源使用； 优先级(Prioritization)：控制优先级； 结算(Accounting)：用来衡量系统确实把多少资源用到适合的目的上； 控制(Control)：冻结组或检查点和重启动。 使用CGroup，系统管理员可更具体地控制对系统资源的分配、优化顺序、拒绝、管理和监控。可更好地根据任务和用户分配硬件资源，提高总体效率。 \r\r\r","date":"2018-03-27","objectID":"/docker/:47:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"核心概念 CGroup需要考虑如何抽象进程和资源这两种概念，同时如何组织自己的结构。它有几个非常重要的核心概念: 任务(task)：系统中运行的实体，一般指进程； 子系统(subsystem)：具体的资源控制器，控制某个特定的资源使用； blkio(Block IO)：限制块设备的I/O速率； cpu：限制调度器分配的CPU使用率； cpuacct(CPU Accounting)：生成cgroup中任务使用CPU的报告； cpuset(CPU Set)：为cgroup中的进程分配单独的cpu节点或者内存节点，也就是哪些CPU和MEM上； devices：允许或者拒绝cgroup中任务对设备的访问； freezer：挂起或者恢复cgroup中的任务； hugetlb：主要针对于HugeTLB系统进行限制，这是一个大页文件系统； memory：限制cgroup中任务使用内存的量，并自动生成任务当前内存的使用情况报告； net_cls(Network Classifier)：为cgroup中的报文设置特定的classid标志，这样Linux流量控制(traffic control)程序可对其数据包进行控制； ns(namespace)：可使不同cgroups下面的进程使用不同的 namespace； net_prio(Network Priority)：对每个网络接口设置报文的优先级； perf_event：识别任务的 cgroup 成员，可以用来做性能分析； 控制组(CGroup)：一组任务和子系统的关联关系，表示对这些任务进行怎样的资源管理策略。 层级(hierarchy)：一系列CGroup组成的树形结构。每个节点都是一个CGroup，CGroup可以有多个子节点，子节点默认会继承父节点的属性。 相互关系: 每次在系统中创建新层级时，该系统中的所有任务都是那个层级的默认cgroup(称为根(root))的初始成员； 一个子系统最多只能附加到一个层级； 一个层级可以附加到多个子系统； 一个任务可以是多个CGroup的成员，但是这些CGroup必须在不同的层级； 系统中的进程(任务)创建子进程(任务)时，该子任务自动成为其父进程所在CGroup的程序，也就是继承。 \r\r\r","date":"2018-03-27","objectID":"/docker/:48:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"文件系统 Linux使用了多种数据结构在内核中实现了CGroup的配置，关联了进程和CGroups节点。CGroup提供了一个CGroup虚拟文件系统(VFS, Virtual File System)，作为进行分组管理和各子系统设置的用户接口。要使用CGroup，必须挂载CGroup文件系统。这时通过挂载选项指定使用哪个子系统。 VFS通用文件模型中包含的四中元数据结构: 超级块对象(superblock object)：用于存放已经注册的文件系统的信息。比如ext2，ext3等这些基础的磁盘文件系统，还有用于读写socket的socket文件系统，以及当前的用于读写cgroups配置信息的 cgroups 文件系统等； 索引节点对象(inode object)：用于存放具体文件的信息。对于一般的磁盘文件系统而言，inode 节点中一般会存放文件在硬盘中的存储块等信息；对于socket文件系统，inode会存放socket的相关属性，而对于cgroups这样的特殊文件系统，inode会存放与 cgroup 节点相关的属性信息。这里面比较重要的一个部分是一个叫做 inode_operations 的结构体，这个结构体定义了在具体文件系统中创建文件，删除文件等的具体实现； 文件对象(file object)：一个文件对象表示进程内打开的一个文件，文件对象是存放在进程的文件描述符表里面的。同样这个文件中比较重要的部分是一个叫 file_operations 的结构体，这个结构体描述了具体的文件系统的读写实现。当进程在某一个文件描述符上调用读写操作时，实际调用的是 file_operations 中定义的方法。 对于普通的磁盘文件系统，file_operations 中定义的就是普通的块设备读写操作；对于socket文件系统，file_operations 中定义的就是 socket 对应的 send/recv 等操作；而对于cgroups这样的特殊文件系统，file_operations中定义的就是操作 cgroup 结构体等具体的实现； 目录项对象(dentry object)：在每个文件系统中，内核在查找某一个路径中的文件时，会为内核路径上的每一个分量都生成一个目录项对象，通过目录项对象能够找到对应的 inode 对象，目录项对象一般会被缓存，从而提高内核查找速度。 CGroup支持的文件类型: 文件 R/W 用途 Release_agent RW 删除分组时执行的命令，这个文件只存在于根分组 Notify_on_release RW 设置是否执行release_agent，为1时执行 Tasks RW 属于分组的线程TID列表 Cgroup.procs R 属于分组的进程PID列表 Cgroup.event_control RW 监视状态变化和分组删除事件的配置文件 \r\r \r\rNamespace 参考: docker 容器基础技术：linux namespace 简介 DOCKER基础技术：LINUX NAMESPACE \r\r","date":"2018-03-27","objectID":"/docker/:49:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["cncf"],"content":"介绍 Linux Namespace是Linux提供的一种内核级别环境(资源)隔离机制，用来让运行在同一个操作系统上的进程互相不会干扰。 Namespace的目的就是隔离。某个Namespace里面的进程就只能看到该Namespace的信息，无法看到该Namespace之外的信息，无法看到其它Namespace里面的信息。各个Namespace中的进程根本感觉不到对方的存在。 Linux内核提供的Namespace: Namespace clone()使用的flag 隔离的资源 CGroup CLONE_NEWCGROUP CGroup根目录 IPC CLONE_NEWIPC System V IPC，POSIX 消息队列 Network CLONE_NEWNET 网络设备、协议栈、端口等 Mount CLONE_NEWNS 挂载点 PID CLONE_NEWPID 进程 ID User CLONE_NEWUSER 用户和组 ID UTS CLONE_NEWUTS 主机名和域名 主要是三个子系统调用: clone()：实现线程的系统调用，用来创建一个新的进程，并可以通过设计上述参数达到隔离。 unshare()：使某进程脱离某个namespace setns()：把某进程加入到某个namespace 每个进程都有一个/proc/${pid}/ns目录，里面保存了该进程所在对应Namespace的链接。 sudo ls -l /proc/8734/ns total 0 lrwxrwxrwx. 1 root root 0 4月 24 10:49 ipc -\u003e ipc:[4026531839] lrwxrwxrwx. 1 root root 0 4月 24 10:49 mnt -\u003e mnt:[4026531840] lrwxrwxrwx. 1 root root 0 4月 24 10:49 net -\u003e net:[4026531956] lrwxrwxrwx. 1 root root 0 4月 24 10:49 pid -\u003e pid:[4026531836] lrwxrwxrwx. 1 root root 0 4月 24 10:49 user -\u003e user:[4026531837] lrwxrwxrwx. 1 root root 0 4月 24 10:49 uts -\u003e uts:[4026531838] 每个文件对应于Namespace的文件描述符，方括号里的值是Namespace的inode。如果两个进程所在的Namespace一样，那么它们列出来的inode也是一样的。 inode是指在许多Unix-Like系统中的一种数据结构。每个inode保存了文件系统中的一个文件系统对象（包括文件、目录、设备文件、socket、管道, 等等）的元信息数据，但不包括数据内容或者文件名。 inode这个命名的来源可能是文件系统的存储组织为一个扁平数组，分层目录信息使用一个数作为文件系统这个扁平数组的索引值（index）。 ","date":"2018-03-27","objectID":"/docker/:50:0","tags":["cncf","docker"],"title":"Docker","uri":"/docker/"},{"categories":["web"],"content":"参考： 《网站运维：保持数据实时的秘籍》(Web Operations: Keeping the Data on Time) \r作为职业的运维 互联网变化如此之快，以至于几乎没有时间认真思考一下我们在做什么，以及为什么做。我们奋力拼搏，才避免被淘汰出局，哪里还敢谈论什么引领潮流呢！这种高压、过度刺激的环境使得所有努力都只是为了一份工作，而没有职业的概念了。 职业是指占去你人生大部分时光的事业，并能够逐步晋升。工作只是拿钱干活儿，换句话说，工作就只是工作而已。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:0:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"为什么运维如此艰难 运维对如下领域都有深入的理解：网络、路由、交换、防火墙、负载均衡、高可用性、灾难恢复、TCP与UDP服务、网络运维中心管理、硬件规范、各种Unix、各种Web服务器技术、高速缓存技术、数据库技术、存储基础架构、密码学、算法、趋势分析、容量规划… 运维要求广博，可以说几乎是不可接受的。 运维领域成为一个合格的人选，需要具备三点素质：扎实的计算背景、娴熟的决断力、沉稳的性格。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:1:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"扎实的计算背景 运维要求理解架构中的各个组成部分，在理解计算系统的来龙去脉时，扎实的计算背景对你会有莫大的帮助。具有扎实的基础，对于理解为什么及如何架构解决方案，以及识别出问题所在，是非常重要的。毕竟，计算是架构我们的智能系统的基础。此外，工程师的思维方式和对物理定律的基本理解，也是一个很大的优势。 运维会经常遇到随意的、不切实际的期望。 运维，就是理解理论和实践在哪里发生冲突，并发明适当的方法，以便在发生事故时减少损失。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:1:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"娴熟的决断力 虽然优柔寡断在任何领域都不算是一个优点，但在运维中却几乎不能容忍。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:1:2","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"沉稳的性格 一个沉稳与可控的思维过程是非常关键的，需要保持自己是清醒的一方。 在运维领域，目标很简单，使所有事情在所有时间正常运转。一个简单的定义，但却是一个不可能的期望。或许在这个领域成为一名工程师的更大挑战是组织内的同事对你的不切实际的期望。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:1:3","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"从学徒到师傅 掌握任何知识领域都需要四项基本要求：知识、工具、经验和纪律。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:2:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"知识 互联网行业的一个独特之处就是几乎所有的东西都是公开的，事实上，有专有权的东西也是极少的，而更为独特的是，几乎所有规范文档都是免费的。 在你走在从从学徒到师傅的路途中，尽可能多滴占有信息是你的职责，这样你的大脑才能将那些细微之处进行排序、过滤、关联，使其成为一幅简明、精确的图画，从而有助于你的决策——不管是长期的架构设计的关键决策，还是临时的排除故障的决策。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:2:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"工具 虽然工具各有优缺点，然而人们使用这些工具都取得了成功。制造和使用工具使我们人类的本性。 所有的工具归根结底都只是人类肢体和感觉器官的延长。 师傅不适用工具炼成的。在互联网应用的环境中，你会看得更清楚，五花八门的语言、平台、技术都能够成功地结合在一起，将这些成功地构建为一个架构的，不是Java或PHP，而是设计与实现它的工程师——那些师傅们。 工具上的一个真理是，不管在用的工具是什么，要了解你的工具，这是在这个行业登堂入室的前提。灵巧地运用工具的能力，比工具本身的质量要重要的多。话虽如此，有经验的工程师还是应该手边备一件合适的高质量的工具。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:2:2","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"经验 从最本质的意义上来说，经验意味着良好的判断力，而良好的判断力却是从很多失败中取得的。 经验与知识是紧密相关的，知识可以认为是他人经验的总结。 经验既是一个名词，也是一个动词。获得经验与应用经验，同样容易也同样困难。 一名资深工程师最大的特点是其一致与可靠的良好判断力。很显然，这要在需要做出判断的场合经受锻炼。 对进入运维这个领域而没有什么经验的工程师，我的忠告是：耐心。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:2:3","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"纪律 通过尽可能正确而高效地做事，从而为解决同样问题，而尽可能地少做工作。 \r 如何应用云计算(Elastic Compute) 云服务器(ECS, Elastic Compute Service) ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:2:4","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"什么地方适合云计算 灵活性和一定程度上的自由是云服务器的特点，当然，本地服务器同样有这个特点。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:3:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"混合计算 混合计算=云计算+本地计算 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:3:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"什么地方不适合云计算 当然，最先考虑的肯定是经济层面。 服务层与数据库是紧密耦合的，所以使它们之间的网络延迟最小化是很重要的。这意味着它们要么全在云里，要么全在云外。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:4:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"结语 尽管有大量广告吹嘘完整托管在云里，但从运维角度来说，混合应用架构模式或许是最有趣的。有些事情在云里做的不一定好。脚踏两只船，你才会游刃有余。 混合应用还强调一点，就是传统运维中的最佳时间仍然是成功的公司的云应用所必须的。 \r 基础架构与应用程序测量 任何规模的运维，采集测量数据就像将服务器连接到网络上一样重要，对于一个规模不断增长的基础架构来说，或许更加重要。 我们不光讨论你要采集并监视的测量数据的种类，还要讨论为了应对各种情况，你能利用这些数据做些什么。 测量数据的采集和带有报警(alerting)功能的监控有明显的区别。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:5:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"时间刷新率和存留时间的考虑 随着采集的数据不断增长，确保这些数据能够一直可查询和移动，这是很明智的。 如Zabbix中——获取数据的时间刷新率和数据保存时间。历史数据保留时长和趋势数据存储时间。 比如有的数据要30s获取一次，而有的信息只需要1h获取一次。 测量数据真正出彩的地方： 对于某个特定的资源，每天的峰值是哪些？每周的峰值日是哪些？每年的峰值月是哪些？ 有季节性模式吗？ 如夏时日和节假日会高一些 最大(波峰)值与最小(波谷)值比较起来怎么样？ 在用户分布广泛的情况下，波峰与波谷是否发生变化？ \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:6:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"测量数据采集与存储的地点 无论使用什么采集工具，易于采集和便于得出结果都是必须要考虑的。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:7:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"测量数据的层次 不同层次的数据存储在不同的数据库中。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:8:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"高层业务或功能特定的测量数据 有了这些高层数据之后，面向产品的那些人对这些数据也抱有极大的兴趣，你一点都不用感到惊讶。 对于应用层面的数据，最有用的是能够跟踪用户的交互情况。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:8:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"系统及服务层面的测量数据 这些是在运维工程师电脑上以图形方式显示的数据。 测量数据的层次： | 例子 | 测量项目 | - | - 应用层 | 网页或API | 故障：类型、延迟、发生率… 服务层 | Nginx, MySQL, MongoDB… | Nginx: 请求频率、响应时间、忙碌的工作进程… MySQL/MongoDB：导致故障的查询类型、慢查询、连接数… 物理层 | CPU、内存、网络、硬盘 | 内存：繁忙程度 内存：空闲内存 硬盘：可用空间，I/O速率 网络：网络I/O带宽情况 有了这些数据，就能够回答如下问题： 平均的Web请求时间 CPU时间 调用最多的数据库查询 数据库慢查询 文件系统缓存 最大的页面响应 … \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:8:2","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"为异常检测和报警提供环境 在本地采集的测量数据的主要理由，就像油表一样，有了这些数据，就可以明白基础架构正在发生什么，以及正在驶向何方。 知道哪里的资源在增长或缩减，能够进行预测。使用预测对基础架构的容量需求进行预报，称为容量规划。 观察网站运行是否有异常时，测量数据就派上用场了。 发生异常是，测量数据回味报警提供相关信息。报警的信息要尽量简明，告知检测到了什么，以及何时检测到。而测量数据会告诉你报警都发生了什么。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:9:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"日志记录也是测量数据 应用程序的日志文件也提供了测量数据和使用情况的信息。这些信息用于追踪过去发生的事件。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:10:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"将变化管理和事件的时间线建立关联 更新生产系统会带来风险。 记录更新发生的时间，从而保留更新的踪迹，这在发生问题需要进行追踪时是非常有价值的。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:11:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"给测量数据加入报警机制 Zabbix、Nagios等就是一个测量数据采集系统配合使用的监控/报警工具。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:12:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"使用测量数据建立加载-反馈机制 采集时序数据的另一个好处，就是能够通过编程使你的应用生成测量数据，从而可以建立安全、精密的反馈循环。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:13:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"结语 测量数据的采集、存储、显示，可以认为是web基础架构的关键部分。不论是及时排查错误，预测容量、规划产品的发布，还是建立应用的反馈机制，如果没有正确的测量数据为你提供一个基础架构运行的全景图的话，你会损失惨重。 设计数据如何经过系统时，要考虑安全问题，而且数据要易于导出到其它应用。一旦运维部门采集了测量数据，你会发现，追踪数据是一件多么有趣的事情，同时也能使工作更加轻松。 \r 连续部署 软件应该以小批量的方式进行设计、编写和部署。 批量大小是产品在开发过程的各个阶段转移的单位。对于软件而言，最容易看到的批量是代码。每次工程师检入代码，都是在提交一定量的工作。有很多技术用来控制这些批量，从连续部署所需的最小批量到更为传统的分支开发，在分支开发中，多个开发者工作数周或数月产生的所有代码将被成批处理，并集中到一起。 结果证明，以远小于传统做法的建议的批量工作，有极大的好处。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:14:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"小批量意味着更快的反馈 工作转移到下一阶段越快，则也就能越快地发现下一个阶段是如何接纳你的工作的。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:15:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"小批量意味着问题即刻被本地化 问题发现得越快，则解决的也越快。 每次部署，都只有少量代码有变化，所以导致回归或料想不到的性能问题的任何变化，都能够快速识别出来，并进行改正。当然，由于需要改正或回滚的变化数量不仅是确定的，也是很小的，所以解决问题的平均时间也就很低了。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:16:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"小批量能够减少风险 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:17:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"小批量可以降低总开销 大多数机构都会降低自己的批量大小，以降低总的开销。 大批量导致的瓶颈经常是隐含的，是这些隐含的瓶颈显现出来，是需要开销的，甚至要投入更多的工作才能修正这些瓶颈。 连续部署的目标，是在减小批量的同时，帮助开发团队清除开发过程中的垃圾，加快工作步伐。这样就能使各个团队处于持续的流动状态，这种状态使得团队的创新、试验变得非常容易，从而形成可持续发展的良性循环。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:18:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"质量卫士的挽歌 产生开发过程中的垃圾的一个很大原因是重复检查。 连续集成，有助于加快缺陷反馈流程；故事卡和看板，用于降低批量大小；日站，有助于加快步伐；连续部署也是这样的技术，有能力是开发团队更有活力。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:19:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"为什么连续部署能行 连续部署区分了发布的两种不同的定义： 一个是工程师使用的，指的是将代码完全集成到生产环境中的过程； 另一个是市场部门使用的，指的是客户看到的东西 使用连续部署，代码一旦写完，就在去往生产环境的路上了。 连续部署也起着速度调节器的作用。 这种速度调节，对于习惯于通过个体效率来度量其进步的团队来说，是一种技巧性的调整。在这种团队中，每个工程师的头等大事就是保持忙碌。不幸的是，这种观点忽略了团队的整体生产能力。对于有些情形，大家坐下来讨论，找出协调方法，从而不需要做重复工作，这时候才是有效率的。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:19:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"让我们开始吧 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:20:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"步骤1：连续集成服务器 这是连续部署的脊梁。我们需要一个中心服务器，运行所有的自动化测试，并监控每一次的提交。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:20:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"步骤2：源代码控制提交检查 下一个需要的基础框架是源代码控制服务器，并带有能进行提交检查的甲苯。如CVS、SVN、Git等。 作为一个团队，我们的目标是在能够可靠地生产高质量代码的前提下，尽可能快地工作，但不要过快。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:20:2","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"步骤3：简单的部署脚本 建立一个关键的部署脚本，用于逐台机器进行增量备份，与此同时，监控集群和业务的运行情况。这样一旦出现异常，就可以快速恢复。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:20:3","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"步骤4：实时报警 无论部署过程多么完美，缺陷仍然会通过部署而进入生产环境。需要一个监控平台，以便事情一旦偏离正常，能够进行提醒，并找到人来调试。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:20:4","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"步骤5：根本原因分析 无论问题多小，都要做些投资，而且各个级别都要做。 小的改进，经过经年累月，非常像复利。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:20:5","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"连续部署用于关键应用 连续部署要求的第一个心态转移是：如果一个更新假设是无副作用的，马上发布。不要再等着与其它相关的更新捆绑在一起，否则，一旦发生副作用，就很难确定到底是哪个更新产生的。 第二个是心态转移是把市场发布的概念和工程发布的概念区分开。 更快更好的反馈 更多的自动化 对真实环境测量数据的监控 更好地处理间歇性错误 更小的批量 \r 作为代码的基础架构 只需要源代码库、应用程序数据备份、硬件裸机就能够把整个业务重建起来。 理想情况下，重组业务的最大制约是还原应用程序数据所需要的时间，应用程序数据是真正的业务价值所在。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:21:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"面向服务体系结构 将系统的每个组件都分解为可通过网络访问的服务，这些服务集成在一起就构成了一个功能性应用程序。 通过将每个基本组件都呈现为服务、应用开发者可自由组装的新的应用，结果就是重用更为容易、封装更为清洁、错误排查更为简单。 应该是模块化的 做一件事，并且做好 在SOA中，每个服务都很小——只做一件事，并允许其它服务调用。每个服务都很简单，但应用程序员要做很多集成工作。每个服务都专注于自己的狭小领域，则管理、开发、测试都会很容易。 基础架构服务也是一样的，缩小每个服务的操作范围，就可以降低复杂性，从而他人也就易于理解其行为。 应该是协作的 让我们团结起来 在构建通过网络API呈现的基本服务时，要鼓励别人和你协作，而不是重复实现相同的功能。每个服务都要设计成与其它服务协作的，尽量少假设服务的使用方式。 服务的协作本性决定了用的人越多，则服务本身就越有用。对于基础架构服务而言，这种本性是至关重要的——随着基础架构的每个部分都成为可集成的服务，服务之间相互协作的方式会呈指数增长。 应该是可组合的 应该一切准备就绪 理想情况下，每个服务都应该通过易于访问的网络API呈现自己的配置和功能，实际情况是：大部分都没有。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:22:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"配置管理 配置管理是一种管理活动，从技术和管理两个方面作用于产品和生命周期、配置项，以及相关的产品配置信息。 配置管理是指对所有那些事情的跟踪，那些事情是把一个系统从裸机(baremetal)转变成做自己的事时必须要做的。系统管理员手工配置系统，并将笔记贴到wiki上时，他就是在实践着最基本的配置管理。软件开发者写了一个脚本来自动部署自己的应用程序，她就是在实践着自动化的配置管理。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:22:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"配置管理是策略驱动的 把问题和解决方案的最终结果记入文档(设立策略)； 写出在策略中要执行的代码(执行策略)； 确认最终结果是正确的(审计策略)； 重复这个过程，确保以后呢能够可靠的执行(测试策略) ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:22:2","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"系统自动化就是用代码实现配置管理策略 自动化几乎总是使用高级语言，自动化方式展现了三个原则： 应该是灵活的 无论需要什么，都应该有能力做 应该是可扩展的 遇到新情况时，要易于扩展 应该是可重复的 不管重复做了多少次，结果都一样 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:22:3","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"系统管理中的配置管理 配置管理工具应该有如下思想： 描述的 说明做什么，而不是怎么做 抽象的 让工具为你操心细节 幂等的 旨在需要时才采取行动 聚合的 只关心自己，并信赖其他服务亦然 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:22:4","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"系统集成 系统集成是指将各个组件整合为一个功能正常的、完全自动化的系统。系统集成侧重于广度，能否成功则依赖于对两个方面的理解： 系统中的每个组件是如何工作的 这些组件是如何相关的 应该遵循这两个步骤将基础架构构建为代码，这两个恰好也是系统集成阶段使用的步骤。系统集成就是将所有的东西整合在一起。 将基础架构分解为可重用的，可通过网络访问的服务 良好基础架构的十大核心原则： 应该是模块化的 启动过程将只处理这样的任务：使资源成为网络可访问 应该是协作的 启动服务应该能够将启动后的工作传给其他服务 应该是可组合的 能够从不同的服务中调用启动服务 应该是灵活的 足够灵活以应付不同类型的物理系统 应该是可扩展的 易于扩展，义启动新的资源类型 应该是可重复的 每次启动，都要生产相同的系统 应该是描述的 应该描述需要的系统类型，而不是如何安装和构建这些系统的细节 应该是抽象的 应该隐藏底层机制 应该是幂等的 应该是聚合的 应该尽快将每个系统都启动起来，并为随后的操作系统做好准备，而不用担心其他系统的状态 将服务集成在一起 现在，你已经创建了一个如何引导和配置系统的策略，你知道接收标准是什么、能够列出实现步骤、能够对策略进行测试。这种做系统集成的方式类似于做一个多层蛋糕：每一层都建立在前一层的美味基础上，使得整个蛋糕更为诱人。 \r \r监控 我以前假定服务器资源是无限的，实际情况却是服务器正在为获得必要的内存而努力挣扎着。操作系统开始进行交换，CPU开始过载，从而响应时间开始变糟。 技术人员的观点和最终用户/业务的观点并不一致。 监控并不是设置一个系统，它是用来支持业务运转的，是用来保证系统中各个部分都在各司其职地工作着。能够正常工作也可以表述为保持网站的可用性。 可用性(A)可表述为： A = Uptime/(Uptime + Downtime) 网站可用性受如下4个参数的影响： MTTD(平均故障诊断时间) 诊断该问题所花费的平均时间 MTTR(平均修复时间) 用于修复问题所花费的平均时间 MTTF(平均无故障时间) 正常运行的平均时间 MTBF(平均故障间隔时间) 两次故障间隔的平均时间 A = MTTF/MTBF = MTTF/(MTTF+MTTD+MTTR) 并不是说你的业务需要接近90%或更高的可用性，业务要求的可能性只是一种期望值，如果宕机发生在周末，即使发生在工作日，只要还能工作，用户也不会说什么。你的目标是应该通过降低MTTD和MTTR，以及增加MTTF来增加可用性。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:22:5","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"理解你在监控什么 技术组件的依赖项： 组件 | 依赖关系 | - 应用程序 | 应用程序服务器、Web服务器、邮件服务器、缓存服务器、队列服务器 Mail服务器 | Mail服务进程、网络、主机、存储 DNS服务器 | DNS服务进程、网络、主机、存储 应用程序服务 | 应用程序服务进程、网络、主机、存储 Web服务器 | Web服务器进程、网络、主机、存储 数据库 | 数据库服务进程、网络、主机、存储 主机 | 设备、OS设备进程 网络 | 设备、网络设备进程 存储 | 设备、磁盘、RAID控制器、接口 通用设备 | 磁盘、内存、CPU、接口、房屋 房屋 | UPS、电源、温度 依赖项常常不受你控制，相反，它是由公司内不同的组管理的。从你自己的筒子里走出来，到其他部门获取相关信息，并不是很容易。正是因为你依赖于他们，所以更好地理解他们的就很关键了。这样你就不用在讯早问题的原因上浪费时间，在用户访问服务所依赖的那些组件上也就不会存在盲点。 不同部门之间的边界： 企业部门 | 依赖项 | - 支援部门 | 能影响浏览器、桌面设置、防病毒/间谍软件 开发组 | 专注于应用程序更新 中间件组 | 经常运行数据库、Web服务器、应用程序服务器、邮件服务器、缓存服务器队列服务器 系统组 | 操作系统、DNS、DHCP、虚拟化、集群 网络组 | 交换机、路由器、VPN、代理服务器 存储组 | SAN、NAS、备份、恢复 数据中心组 | 电缆、电力、UPS 安全小组 | 防火墙、安全策略 这样划分责任，在不清楚问题的真正原因时，会显著增加修复问题的时间。大量精力会花在努力证明自己部门的清白上面，从而延长了解决问题的时间。这份额外时间称为平均清白时间(Mean Time to Innocence)。 为了减少这种相互推诿的时间，良好的合作与协调很重要。持续的知识共享有助于增加这种共同应对问题的责任感。 组织边界到防火墙哪里就停止了，但Internet服务比内部控制的服务有更多的依赖项，这些外部依赖项有ISP、广告商、RSS信息、Internet邮件、DNS服务器、ISP连接等，内部依赖项和外部依赖项的主要区别在于，对于外部依赖项，你不知道这些服务是如何提供的。即使如此，也不能在监控这些服务上止步不前，毕竟它们仍然是你的服务的依赖项。 在无冗余的系统中，一个组件失效，整个服务就会失效。当一个组件的失效会影响整个服务时，这种失效就称为单点故障。这种影响既指服务完全中断，也指对服务质量的影响。 为了避免单点故障，通常是在架构中的多个位置增加冗余，这些冗余是你的环境的安全卫士，而不是对问题的某种补偿方式。通常，增加冗余会增加复杂性，所以不要掉进过度设计的陷阱。 一些冗余机制： 服务/组件 | 冗余机制 | - 应用程序 | 负载均衡器、状态复制 Mail服务器 | 一个域名多条MX记录 DNS服务器 | 一个域名多条NS记录 应用程序服务器 | 会话复制、多实例安装 Web服务器 | Web服务器服务进程 数据库 | 集群服务、水平区分 主机 | 虚拟化、集群 网络 | 多网关、BGP、VRRP、多ISP 存储 | RAID、镜像、多重路径技术 通用设备 | 多网卡、CPU、内存 数据中心 | BGP任播、GSLB 不要忘了检查监控服务的依赖项，如果监控都挂了，那还监控什么呢。 各种检查： 检查种类 | 例子 | - 可用性 | 能访问80端口吗？HTTP进程在运行吗？数据库能访问吗？ 功能/既时 | 应用程序在请求数据库，OS在进行DNS查询，控制器在进行磁盘写入，负载均衡器在请求Web服务器 功能/模拟 | 模拟HTTP请求、DNS请求、发送邮件 质量/利用 | CPU、内存、磁盘等硬件信息使用情况，可以知道机器是否有足够的处理能力 质量/效率 | Squid缓存命中率 质量/吞吐 | 订阅数、登录数、请求数、进/出请求数，用户数，数据库连接数，活动连接数，实例数 环境 | 配置监控，安全监控，备份监控 可信性 | 邮件域的垃圾邮件防范级别，SSL证书 不同层级的检查： 层级 | 例子 | - 业务 | 内部网管理站点 交易 | 登录、增加文档、分享链接、注销 服务 | Mail、DNS、Web服务器、数据库、路由、防火墙 机器 | 服务器、CPU、内存、交换机 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:23:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"理解正常行为 即使你了解所有依赖项，但设计一个好的监控解决方案仍是要花时间的。需要根据业务实际需求和变化对监控实施改变。 一些监控中的主要问题： 如果多次报警基于同一个原因，应该只发送一次报警； 夜间，备份可能会在生产网络上产生很高的负载，这样由于响应时间的变慢而导致多个ping失败和其它可能的误报，从而产生起起伏伏的报警； 如果我们想要随时待命的支持人员，必须尽可能降低报警和误报的次数。 加入的检查越多，消耗的生产系统的资源也就越多，这些资源可以是传送数据的带宽、计算结果的CPU… 你需要找到正确的平衡：监控太多只会浪费资源，从而降低对整个状况的了解；监控不足将导致不能及时报警。越靠近业务层的检查越有机会检测出问题，而越底层的检查越能够对发生的问题进行定位。 监控被认为是运维环境的一部分，通常是由系统或网络管理员来管理的。开始时是一个很小的系统，在后台运行。随着监控环境的扩大，需要执行更多的配置和定制。虽然运维人员常常是第一个对要部署的新软件进行仔细检查的人，他们的标准却往往并不应用到自己的监控系统上。监控系统是你的关键应用之一，请一视同仁。 监控的最佳实践： 实践 | 说明 | - 版本 | 对你的检查进行版本华，并把他们放入版本控制库中 不同环境 | 使用不同环境开发、测试新的检查 测试 | 将检查作为通常代码对待，在代码功能中加入测试 可使用性 | 创建一个所有组件及其关系的可视化总览图，指出失效和组件的关系对工程师很有帮助，只需要看一下仪表板就能明白问题出在哪里 信息架构 | 使用不同的数据表示法，将数据组织为层次结构以便于导航，同时还要避免信息过载 代码重用 | 如果能够重用所监控的应用程序中的业务逻辑，就不要自己写 无硬编码 | 避免将参数编码在脚本中，使用配置文件，这也易于脚本在不同环境中的迁移 部署 | 要易于部署和分发新的检查 备份/还原 | 备份监控数据，并了解在什么情况下需要还原 监控 | 监控你的监控系统 冗余 | 在监控上，使用高可用性的功能做维护工作 应用的安全规则 | 监控账号与其它事务账号分开 是用最小特权级 不要将密码保存为明文 限制对系统的访问，不要将其用于其它的测试 将监控系统用防火墙或代理系统保护起来，避免来自易受攻击的主机的访问 所有信息一旦采集和存储，接下来做的就是分析检查结果。服务或系统的状态有可用(Up)和不可用(Down)，某些监控系统还增加了两个状态，一个用于系统不可达(Unreachable)，一个用于系统/服务尚未检查(Pending)。 有的时候，在位新服务建立环境时，预先定义的阈值很困难——实际使用可能会超过预期，或者相反。所以，对阈值进行不断的调优就有意义了。先根据理论上的假设定义一组阈值，然后在测试环境中模拟预期的行为，并翻译为技术化的组件使用情况。因为系统及使用情况的复杂性，对系统、应用程序、用户行为建立精确的模型是很困难的。所以，对阈值只能持续不断地研究与改进。趋势分析确实有助于定义阈值，大部分监控软件都可以让你对监控的值做趋势分析，而不产生报警，根据历史数据得出阈值之后，再启动报警设置。 管理报警并不仅仅是状态变化时发出报警信息。所有报警如果一直打开着的话，工程师将无法安心做系统支持，因为报警信息太多了，可能要被报警轰炸。同样，如果有太多假设报警，也会导致同样的问题，这可以看成是你的监控系统存在技术缺陷。 警报应该产生行动。如果一条警报可以忽略或不需要人工干预，这条报警就是一种浪费。然而，消除噪音却是真正的挑战。警报太多会导致狼来了效应，由于警报过载而忽略了正在重要的警报。 为了使网站可以忍受而限制报警是好的，但假如与业务需求不一致的话，就不行了。反之也是对的，如果业务不需要的话，为了显示网站运行正常而发送很多报警信息，也是毫无意义的。使监控保持正确的平衡，这很重要。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:24:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"有备而学 一个人不可能在每个方面都是专家，有一个清晰定义的升级路径，从而把问题提交给更为专业的人员去处理是明智的。 对紧急报警进行跟踪和趋势分析，有助于提出架构和过程的改进建议。 故障时间本身并不仅仅有功能失效引起的，也可能是由于维护活动产生的。维护活动产生的故障时间被描述为维护窗口。在这种情况下，业务部门是认可默写故障时间的。为了避免不必要的报警，监控系统可能会在这段时间关闭报警。这会导致丢失一些与此次维护无关的系统/服务故障。所以，应该只关掉与维护相关的报警，而不是整个报警系统。然后，一旦服务运行稳定了，就要打开报警。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:25:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"结语 监控并不是要保持服务器运行正常，也要保持业务运行正常。理解了技术组件和业务行为，你就会有相当的把握减少和修复问题上的时间。错误总是会发生的，但要为此做好准备。万一系统失效，一定要将反馈信息发送给每一个希望听到的人，并对事情做出改进，避免再发生新的错误。愿监控的力量与你同在。 \r \r复杂系统是如何失败的 所有复杂系统失败时，都有共同点。Web运维就是这样一个领域。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:26:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"复杂系统是如何失效的 复杂系统本质上都是灾难系统 复杂系统都被重重地然而也是成功地防护着 灾难要求多点失效——单点失效是不够的 复杂系统包含潜藏在其中的缺陷的变化混合物 复杂系统以降级模式运行 灾难随时会发生 事后归结为”根本原因“是错误的 幕后认识对人类行为的时候评估存在偏见 人类操作员有双重角色：作为生产者，以及作为失效防护者 所有操作者的行为都是赌博 最为困难的行动解决了所有的模糊性 人类操作者是复杂系统的可调整因素 复杂系统中人类专门处理知识处于不断变化中 变化会引入新的失效 “原因”观点限制了对未来事件的有效防护 安全是系统的特性，而不是系统的组件 持续创造安全的是人 无事故的运维需要经历事故的历练 针对Web运维而言： 了解系统失效很困难 了解哪部分失效很困难 有意义的响应会被延迟 沟通会产生紧张，而脾气会冒火 维护会成为新的失效的主要源头 从备份中恢复本身就很困难，而且还有潜在的危险 创建测试过程，一线人员用来验证系统状态 对运维进行例行的每日管理 控制维护 定期对性能进行评估 要成为(独一无二)的用户 \r \r社区管理与Web运维 运行一个大型且广为人知的网站，意味着会有大批人依赖于网站快速而稳定的服务。这些人会形成一个社区，以各种有趣新颖的方式进行交流，并彼此关照。 社区起着一个交流、沟通、反馈的渠道作用。 \r \r处理非预期的访问量激增 有些时候，因为某种原因，Web的访问量会急剧增加(是正常用户访问而不是遭受攻击)，我们的服务器就会遭受严重的考验。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:27:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"一切是如何开始的 开能由于某个原因，导致Web流量激增，而我们服务器却无法应付这么高的并发和流量，所以导致Web瘫痪。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:28:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"警报连连 监控软件(如nagios, zabbix)警报连连。Web请求太多导致响应很慢或奔溃。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:29:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"扑灭烈火 查找是哪些环节导致Web响应很慢或奔溃，对之做相应的优化。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:30:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"未雨绸缪 当我们经历了非预期的流量激增，并处理优化之后，下一步就需要对整个基础架构进行加固，或转向新的架构。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:31:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"救命稻草CDN 解决带宽问题要靠内容分发网络(CDN)——在多个地点存储文件，为客户提供最近最快的响应。 大部分静态资源适合移动到CDN上，以减轻原始服务器的负担。 但CDN也有一些不足。对于移动到CDN上的数据，你就失去了控制。对于短时间的静态内容，CDN的效果并不好。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:32:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"代理服务器 代理服务器处于我们系统的最前沿，尽可能让代理服务器转发请求，而不使用任何其它资源。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:33:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"围剿踩踏 如何避免缓存踩踏？ 一个是对数据库进行优化 一个是搭建数据库集群 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:34:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"将代码基流水化 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:35:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"怎么知道它能否工作 确保系统能够处理负载的唯一途径是在流量汹涌而来时，对其进行现场测试。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:36:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"真实测试 必须要在真实的生产环境中查看其负载效果，才能确保其能正常工作。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:37:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"教训 总要为未来几年做一个规划——问问你自己：“当前的架构方案能够用于未来几年吗？” 要测试生产环境，经过适当的测试规划，很多问题是可以避免的。 当一个架构方案已经明显不能工作的时候，必须要有重新考虑整个方案的勇气。 重新思考代码、硬件、网络、数据库模式，为可见的未来创建一个伸缩性更好的系统。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:38:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"改进 针对遭受的问题，之后对系统的改进。 \r \r开发者与运维者的协调与合作 很多网站都将其开发和运维分为两个独立的团队，开发负责开发新功能和对现有功能进行改进，运维负责网站的正常运行。 两个团队有不同的目标，工作方式的要求也是迥然有别。 这种设置很常见，但也是保证网站稳定性或及时推出新功能的最糟糕的设置。 这在种情形下，开发人员没有动力将网站做得更易于运维支持，开发团队交付的代码通常是一个黑盒子，一旦发生意外，运维团队没有办法及时去修复问题。这种结构也抑制了新的功能的开发、构建和部署网站的新版本，不仅耗时，成本高，还涉及很多不同团队之间的协调。对运维来说，部署是存在风险的，而且也是造成很多宕机事故的原因。 传统的运维和开发，两者之间存在着很多对彼此很有用的信息。对很多网站来说，性能瓶颈都出在应用程序代码上：开发团队最适合修正这些问题，但运维团队有测量数据，要想找出问题出在哪，是需要这些数据的。关于什么地方可能会出问题，以及如何修复，开发团队有很多很好的想法，但这些却很少会记录在文档里面。 所以，重新评估运维跟开发之间的关系！ ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:39:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"部署 以合适的方式进行移交，则不同团队之间就能更好地共同工作，而改变过程这是困难的，需要协助以及每个人的认可。 一项服务之所以受人欢迎，频繁部署也是重要原因之一。小批量代码更新。 用户报告问题后，极短时间内就得到修复，这一做法会彻底征服用户。有了这种响应凡是，则将来有了问题，用户也会很乐意报告给你，这样产品就会越做越好，特别是你能够一直这样快速反应的话。对关键的数据损失或安全缺陷能够在短时间内而不是几周响应的话，用户的数据就会安全得多。 然而最重要的是，频繁部署并不比周部署或月部署风险更大。很多小的更新，每个都单独测试和检查过，比起一次大的更新来说，导致严重宕机的事故的可能性要小很多。 这是因为小更新的影响能够提前单独进行复审和测试，从而错误造成的影响也易于量化及应对。定位代码中的缺陷，复审10行的更新比起10000行来，会容易得多，而且只测试那些受更新影响的功能，比起测试整个系统，也要快得多。而且能够确保每次部署都只是更新一个区域，从而避免同时更新的两个组件之间发生预料不到的交互作用。小部署意味着更容易预言更新对基础架构的影响，而这也就意味着未雨绸缪更加有的放矢。 如果只是部署30行代码，缺陷通常是自明的。如果缺陷不自明，其影响也会非常小，即使回滚也非常容易。 只有在遵循以下三条规则的情形下，频繁的小更新才起作用： 构建与部署系统必须能够完全重复且自动地工作 具有几近完美的预演环境 部署必须尽可能快，理想情况是小于5min 大多数构建和部署系统在某种程度上都是自动化的，少数团队走得更远，把构建和部署做成了一键操作。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:40:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"共享、开放的基础架构 很多情形下，运维和工程都分为不同的小组，你会发现支持的基础架构也会一分为二。 共享基础架构是在团队之间进行协作的最容易的方式。 为了有效地工作，你需要了解系统的其它方面目前是如何运转的。为了建立信任，你需要使你的工作变得透明。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:41:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"信任 信任是开发和运维之间最常见的紧张关系之一。多数运维团队对开发团队多少都有点怀疑，开发人员通常也好不到哪去。团队之间的不信任是不健康的，也是不合适的。 信任最终是建立在一种尊敬的感觉之上的。如果你尊敬某人，就很容易信任此人能够做好他的事情。反之，如此人交往便会带有偏见、不满等情绪。 运维和开发之间的许多问题都是由于对两个团队不同角色的重要性认识不同而造成的。 充分尊重你的同事，而不是事后指责他们。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:42:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"随叫随到的开发人员 只有在开发人员对修正生产系统代码中的问题肩负起责任的情况下，才是有意义的，而这就意味着开发人员随叫随到。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:43:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"现场调试工具 很多代码对于运维团队来说都是黑盒子。 要想办法在运行时调用额外的调试信息，技术团队的每个人在用管理账号登录系统之后，都可以开启额外的调试信息。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:43:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"功能标识 禁掉某些依赖于问题架构的功能，而保持网站的其他部分正常运行，功能标识能够实现这一点。 单个标识，用来禁掉每个非核心的基础架构 只要这些服务出现问题，我们都可以暂时并优雅地禁止掉这些功能 如果生产系统出现新的错误场景，也可增加新的标识 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:43:2","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"避免职责 在很多团队中，没有人愿意成为搞坏所有事情的傻瓜。发生问题时，人们都会将责任推卸给别人。 每个人都有貌似合理的理由将指责转嫁给别人，却没有挺身而出，实实在在地修复问题，组织良好的团队深切地了解，在将问题修复之前，争论到底是谁的责任是没有意义的，为保护自己而浪费的每一分钟，由于问题没有修复，都会成为给用户带来损失的一分钟。用户会尝试各种可能性，知道他们发现系统出问题了。 多数生产环境都有足够的冗余，也足够复杂，任何问题都不太可能存在单一的根本问题。很多问题都是由两个或多个系统发生意料之外的交互作用而引起的。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:44:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"结语 网站的稳定性是每一个人的责任，而不仅仅是某种应该交给运维团队去处理的东西。 让人人都拥有对网站的主人翁感觉，确实意味着能够减轻运维团队的工作负担。他们不用再花费大量时间呼吁采取防护性措施，一旦发生问题，也能够花更小的时间修复。这非常了不起，因为这意味着网站的宕机时间会减少很多。这也释放了运维团队，让他们能够把精力放在更为重要的任务上，即对基础架构的长期增长进行管理。 \r 你的访问者感觉怎么样：面向用户的测量 对于网站的成功而言，终端用户的测量也就变得和后台测量一样至关重要。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:45:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"为何要采集面向用户的测量数据 采集数据，从而就可以对业务的健康状况进行分析。 如： 每秒请求数/发布数 带宽 响应时间 HTTP错误率 记入日志的异常数 进程重启次数 队列大小 服务器的平均负载和进程数 数据库负载 内存 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:46:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"成功的创业公司所学到的以及必须适应的 创业公司的一大优势就是敏捷，即快速反应的能力。要真正做到敏捷，创业公司需要了解终端用户真正体验到的是什么。 任何网站想要成功，就必须向用户学习，而且必须适应用户的需求。很多Internet巨头，它们现在的业务，都与其当初设定的相比有很大的不同。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:46:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"性能问题 响应越快的应用程序越好！ 响应级别： 加入事情的响应时间在10ms内，我们的大脑就会认为这是真实的 如点击桌面系统上的按钮 如果谈话有100ms左右的延迟，我们不会感觉到这种延迟 如国际长途电话 如果应用程序的响应时间在1s之内，我们的感觉就是仍然在与应用程序互动，仍然在工作 应用程序的响应时间要是明显长于1s的话，我们就会抓狂 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:46:2","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"研究量化了这种关系 Web应用的速度越快，其Web业务员的优势就越明显！ 如果你的网站很慢，你将得到： 更少的用户搜索 更少的精度搜索 更少的每访客收入 更少的点击，更低的满意度 更少的每日搜索 等待访客点击的时间更长 更低的搜索引擎排名 更差的用户体验 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:46:3","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"是什么使网站变得很慢 简单来说，由以下三点原因造成： 服务器花在处理用户请求上的时间 网络花在传输请求和响应上的时间 用户花在组装并显示结果内容上的时间 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:47:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"服务发现 开始访问网站，用户都需要先找到服务器。 对于带有很多组件的网站——这是一个日渐普遍的模式——都会迫使用户去解析很多网站，并且页面加载的时间也延长了。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:47:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"发送请求 网络再快，用户与服务器之间的往返也是需要时间的。 请求包含的内容越多，则网络用来传输的时间就越长。加入是一个安全页面的话，还会有另外的延迟，用来在客户与服务器之间进行加密协商。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:47:2","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"响应 请求到达服务器之后，另一个导致延迟的罪魁祸首就登场了——主机。不论是从内存中检索静态对象，还是利用后台的第三方服务来完成一个复杂的请求，主机延迟都会对性能造成影响。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:47:3","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"发送响应 响应内容一旦准备就绪，服务器就可以通过HTTP协议发送这些请求对象——大多数页面包含多个对象(如html,css,js,gif,png,jpg…)，正是这些对象的发送造成了访客体验到的延迟。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:47:4","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"异步通信与刷新 某些应用包括一些客户与服务器之间的通信，这些通信是独立于页面进行的。 包含某种异步更新或刷新的应用，有不同的延迟测量指标。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:47:5","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"渲染时间 随着客户端越来越复杂，浏览器做的也就越来越多。有可能是启动富互联网应用(RIA)，这些RIAs都是构建在Flash、Flex、HTML5、Java、JS…之上的，也可能是运行QuickTime或Windows媒体播放器等这样的插件，甚至决定如何对复杂页面进行布局也是需要花费时间的。 所以，对于大量依赖客户端进行渲染的网站，就必须考虑这种延迟。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:47:6","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"测量延迟 有两种测量方法： 综合监控 实际用户监控(RUM) ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:48:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"综合监控 综合监控是通过从多个地点对网站进行一系列正规的校本化测试，对网站的性能进行监控。 要记住，综合测试也是要消耗服务器资源的。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:48:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"真实用户监控 RUM的工作名副其实：它观察的是网站的真实访客，记录访客打开页面的速度，然后生成报表。 从这点来看，RUM会告诉你系统是否出问题了，因为你可以通过RUM发现问题以及速度变慢的情况，这些情况你没有进行测试，从而也就不知道是否存在。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:48:2","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"编写SLA Web运维收集终端用户的数据的一个主要理由就是用来编写SLA，哪怕与客户之间没有正式的SLA，但对于正常工作时间及页面延迟，也应该有内部的目标，因为网站速度对用户体验有直接的影响。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:49:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"访客结果：分析 对于成功的Web运维来说，监控就是了解存在哪些不利因素。而当进入Web业务时，这些测量就要让位于Web分析了。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:50:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"市场营销如何定义成功 对市场营销的最好描述——“更经常、更有效地卖出更多的东西给更多的人，从而得到更多的钱。” 或许应该将成功的在线营销更精确地定义为“让人们有效地去做你要他们做的事情。” ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:50:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"网站的四种类型 交易性网站 协作型网站 作为服务(saas)网站 媒体网站 很多流行网站都是上述模式的混合。 网站分析就是对每种类型网站的成功因素进行追踪，从中识别出使这些因素得以增长的背后动因——不管是广告活动、性能的提升、社会网络上的关注、特殊的定价模式还是某个引人注目的内容。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:50:2","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"分析一个简单的模型 有一个简单方式来考虑网站分析，就是做一次访问。 网站分析的目标，就是通过优化网站，将访客的转变最大化，通常是对网站进行试验，并针对各种内部和外部区段，对这些试验结果进行分析。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:50:3","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"市场营销关心的其他测量数据 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:51:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"Web交互分析 分析查看的是用户对多个页面的整体访问情况，Web交互分析集中在单个页面的可用性交互上。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:51:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"用户之声 用户之声工具用来询问客户在想什么。这些工具从网站的访问性中征求反馈，通过请求客户参与调查，或者在页面上提供一个反馈按钮。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:51:2","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"用户体验如何影响Web运维 随着新建公司对终端用户体验的关注，Web运维的角色正在发生变化。对线上事务的兴趣越来越浓，而且通过追踪分析，网站的所有事情都能够和业绩联系起来。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:52:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"将监控作为生命周期的一部分 网站现在已经有了很大的变化，随着敏捷和精简产品开发的流行，监控也需要跟上。所以来的综合监控脚本以及RUM配置也需如此。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:52:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"Web监控的未来 终端用户体验的监控正在兴起，变化很快。这是业务中最能进行分析、量化的部分，每周都能涌现出新的技术。 从系统转向用户 以服务为中心的架构 云与监控 APIs与RSS消息 \r 将关系数据库用于Web的战略战术 如何为产品或应用程序设计一个良好的关系数据库架构，如何构建良好的互联网数据库架构？ \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:53:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"Web数据库需求 其实，大多数网站，相对而言，都只是小型数据库。 一些大型公司，可能才是一个大型数据库。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:54:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"一直在线 数据库通常要7x24小时运行。 一直在线意味着维护和运维任务是很难做的，你不能简单地等到人们回家了然后将服务器卸下来，给硬件升级或备份。必须在不停机的情况下做这些事，而且很多情况下还不能给应用程序增加额外的负载。 话虽这么说，还是极少看到没有峰值时间的数据库。所以，还是有很好的机会，在数据库活动的间歇期来做备份或对数据库产生干扰工作。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:54:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"事务最多的工作负载 很多互联网应用都匹配以下模式： 应用程序读远大于写 一次读一行和一次读多行是混合出现的 一般，写每次只影响一行 这就是称之为的事务型负荷。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:54:2","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"简单数据，简单查询 网站的流量很大程度上决定了数据库的流量。 查询通常会满足下面的模式： 读写用户表，一次一行 以区域或集合方式读取用户自己的数据 以区域或集合方式读取其他用户的数据 从该用户到其他用户的关联表中读取区域行 对该用户和其他用户的数据进行汇总与计数 特别低，很多数据可以分区存储的事实说明了为什么**分片(sharded)**架构是可能的。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:54:3","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"可用性胜过一致性 从业务的角度看，最重要的事情是应用程序对用户的可用性。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:54:4","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"快速开发 传统应用极少以天或周为周期构建和部署，但对于大量Web应用来说却是常态，这些Web应用是永远的Beta版。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:54:5","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"在线部署 模式和数据的更新都做成代码形式，而且也有这样的框架，部署这些代码或将其回滚都很容易。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:54:6","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"由开发人员构建 大量的应用程序都是由开发人员做的，都没有一个高水平的DBA。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:54:7","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"典型的Web数据库是如何增长的 大多数Web数据库的增长，都经历了一些列的架构变动。这些架构变动，在应用程序的整个生命周期中，相对而言都是可预知的。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:55:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"单台服务器 一般应用程序都是从单台服务器开始起步的。使用单台服务器有很多好处： 数据只有一份拷贝，不存在你的数据是否正确或不同的问题 易于配置 便宜 当然，缺点就是只有一台服务器！假如发生问题，没有冗余机器做故障转移。性能也会受影响。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:55:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"主服务器与单复制从服务器 各数据库的复制技术都不一样，但一般而言，发生在主服务器上的数据修改，都要在从服务器上重复一遍，所以从服务器是主服务器数据的只读拷贝。依赖于数据库、系统负载以及执行的查询类型，从服务器不一定时刻与主服务器的数据完全一致(异步复制)。 增加一个复制从服务器有很多好处。数据库读请求可以在主、从指间分担，这称为读写分离。可以在从服务器上执行那些效率不高的查询、备份以及其它有可能对网站造成破坏的任务。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:55:2","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"主服务器与多复制从服务器 大多数复制技术对两台或多台从服务器都没问题。 这样确实不错，而且随着从服务器越来越多，系统的数据库读取能力也越来越强。但这种增长不是无限制的，在很多层面上都会遇到收益递减的拐点。 第一个层面就是应用程序中读对写的比例 第二个方式表示主服务器的写操作有多忙，其中你会看到收益递减的情况 第三个限制是操作成本和复杂性 管理一群服务器，比管理单台服务器，要难得多也昂贵得多 最后一个不足是应用的复杂性 从单一数据源走向两个数据源，对于大多数应用程序而言，都是一个重大转移。应用程序不得不连接多个位置来进行查询。连接池、负载均衡器以及类似技术会在一定程度上保护你不受这种复杂性的困扰，但最终应用程序仍然要面对某种程度的复杂性 复杂性的一个最大来源是异步复制。异步意味着写操作先在主服务器上完成，随后送往从服务器执行。结果就是，从服务器总是拖后于主服务器某段时间，即时这段时间很短，但由此而造成的问题却很大。这可能会导致用户体验的不一致到数据完整性等一系列问题。 一般而言，不存在修复这个问题的神奇方法，应用程序必须自己处理这种延迟复制。 一种不错的简单技术是基于会话的分裂。用户做了更新之后，一段时间之内，该用户的所有查询都导向到主服务器。认为能够安全地查询从服务器所需的时间戳通常都存储在会话里。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:55:3","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"功能分区 复制只对读有伸缩，对写没有。随着应用的规模越来越大，写操作的负载最终会大到系统无法处理。 功能分区(functional partitioning)，假如将某些部分与其余部分分开，则这些部分可以独立增长。 如，对于博客服务，可将评论功能分离到它自己的服务器中。 从运维角度来看，不同部分处在不同位置，则应用程序的功能也就能够单独对待。比起网站宕机，将评论改为只读模式，用户的反感可能要小得多。 这种做法的不利之处是增加了复杂性。应用程序需要从多个位置获取数据，而运维团队必须保持这些服务器正常运行。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:55:4","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"分片 分片(sharding)，是将单一逻辑数据划分为多个片段并发布在多台服务器上的一种方式。所有的片段在逻辑上和功能上都是相同的，虽然这些片段分别包含数据的不同子集。 分片架构的主要设计目标和优势都是双重的。第一是允许写伸缩，因为负值无法实现写伸缩，假如应用程序的写操作草果了任何单台服务器能承受的程度，就必须要分片以减少写操作的负载，写操作的负载必须分担到完全隔离的服务器上，对一个分片的服务器的写操作不能复制到另一个分片服务器上。第二个目标和优势是，随着数据集的增长，能够增加更多容量的能力。 在分片架构中，许多查询也变得困难或不可能了。例如，需要访问所有客户数据的查询，通常都要在每个分片上分别执行，然后在应用程序代码中在聚合在一起。 分片架构还存在很多其他的不足和复杂性。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:55:5","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"缓存层 缓存层的目的是阻止查询到达数据库。 标准的例子是：memcached，redis 缓存层的主要优势是极为容易，并且简单。 从运维的立场来看，需要考虑缓存服务器的冗余和可用性，就像为其他服务器所做的一样。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:55:6","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"对集群的渴望 在应用程序出现某种问题，或关于可用性或伸缩性的困难问题来的时候，人们的思想就会转向集群(cluster)，就像年轻人的思想转向春天和爱情一样。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:56:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"CAP定理以及ACID和BASE CAP原理： 一致性(Consistency)、可用性(Availability)、分区容错性(Partition Tolerance)。你可以具有两者，但不能三者皆具备。 ACID： 原子性(Atomicity)、一致性(Consisitency)、分离性(Isolation)、持续性(Durability)。 BASE: 根本可用性(basically available)、软状态(soft state)、最终一致性(eventual consistency)。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:56:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"MySQL集群的状态 MySQL Cluster是将MySQL服务器作为一个完全不相干的、称为NDB的软件的前端。NDB的意思是网络数据库，这是一个极快、分布式、无共享、高可用的数据库。 DRDB和Heartbeat DRDB在服务器之间对块设备进行复制，将修改的块通过网络复制给备机。如果主服务器失效了，则Heartbear激活备机。 从运维的角度来说，DRDB非常棒，装上就能工作，但却不能满足在线用户的需求。它不是为满足典型Web应用的高可用性而设计的。相反，它非常适合用户保证你不丢失数据的情况，也就是说，它关注的焦点是一致性而不是可用性。 另一个问题就是基于DRDB的集群不能改进性能。Web应用需要的是正常工作时间和性能，而基于DRDB的集群是以性能为代价来提供一致性，而一旦失效，宕机时间就会很长。 主服务器到主服务器的复制管理器(MMM) MMM是一系列的Perl脚本，管理复制和虚拟IP地址，从而为MySQL提供一个伪集群(pseudocluster)。 应用程序连接到虚拟IP而不是服务器的真实IP。服务器发生问题时，MMM将该服务器的虚拟IP移动到另外的可用服务器上。它也可以将复制从服务器从失效的主服务器移动到正常的主服务器上。MMM允许手工将服务器离线执行维护任务。 带复制的Heartbeat 如果MMM无法完美地管理复制和虚拟IP地址，heartbeat考虑以下？ 不管怎么说，复制延迟仍然是一个复杂的问题。必须在应用程序层解决这一部分问题。 基于代理的解决方案 有一种可供选择的方案，基于代理(proxy)，需要人工介入，MySQL Proxy位于前端。HAProxy是另一个流行的方案。 MySQL Proxy，事实上能够理解MySQL的协议，并且拦截、解释以及传递消息 HAProxy，只是传递TCP流，并不对内部进行窥探 基于代理的解决方案仍然没有入人们所愿的那样解决复制延迟问题，而且还引入了单点故障，并且影响性能。 小结 前面讨论这么多，简而言之，就是没有一个完美的、万能的答案。 最好的数据库架构是为了应用而建的，期待集群所承担的指责分布在数据库、网络以及应用程序上，有运维的适度介入，以及起粘合作用的软件，就能把各部分整合在一起。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:56:2","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"数据库战略 如何选择一个对于大量的互联网架构来说都能够运转良好的架构。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:57:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"架构需求 最好定义你的需求，特别是，把那些超出你的范围从而成为别人的问题的内容写成文档。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:57:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"有把握的架构 以下数据库架构，是比较有把握的。 单主服务器，多从服务器 这种主-从架构很难自动实现主服务器的故障转移，因为主服务器和从服务器的配置是不一样的，所以，一旦主服务器失效，则必须手动进行失效转移。 主服务器-主服务器复制，外加从服务器 这种方式实际上与一台主服务器加多台从服务器的架构一样，但有时候主服务器本身也成为从服务器。这种架构的优点是，在协同的主服务器之间更容易实现失效转移和失效转回。缺点是，向两台主服务器进行写入存在风险，会导致数据库存在某种不一致性，也很难解决。 功能分区 随着应用的增长，将应用中某些部分转移到特定的服务器或特定集群上。 失效转移和负载均衡 使用负载均衡器，或者浮动的虚拟IP地址。 ACID仍然是有意义的 高可用性要求快速而可靠的灾难恢复。 使用正确的工具 不要使数据库处于关键路径上，不要讲应用程序的静态信息放入数据库中。数据库应该存储数据，而非应用程序本身。将数据库简单化，因为这是最难于伸缩，也是最昂贵的资源。但是，对于Web应用，还是应该分离应用程序和数据库，将数据库仅用来存储和检索数据。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:57:2","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"有风险的架构 建议不要使用这些架构 分片 除非不得已，不要分片。 对于一个中等规模的应用，将其构建在数百台低档机器的分片架构上，试图提供无线伸缩能力，是非常愚蠢的。其实，只需购买几台足够好的机器，在工程上多做一些考虑就足够了。 分片架构比你预想要昂贵的多，甚至在短期内也是如此，长期则一定如此 分片问题设计过度设计的风险 写入多台主服务器 不要将多台服务器配置为可写，这会造成数据一致性问题。非常麻烦。 多级复制 尽量不要使用多级复制。 使用一主多从而不是从的从的从服务器，要简单的多。孙子辈的从服务器和重孙辈的从服务器很难管理。 环形复制 避免使用环形复制，其失效情形，不管是数量还是复杂度，都打得超乎想象。 依赖于DNS DNS很脆弱，依赖DNS最终会自食苦果。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:57:3","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"数据库战术 数据库战术，即为保持数据库基础架构的可靠性而做的日常运维任务。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:58:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"在从服务器上做备份 一些小提示： 在备份上不要拖延，做备份其实并不难 做事不要追求完美，而要追求可恢复 至少对于可接受的数据损失、可接受的宕机时间、数据持续策略以及安全需求要形成文档 对恢复过程要进行练习并形成文档，恢复比备份要重要的多 对于备份成功与否，要进行外部验证，不要依赖于作业自身对你的提示 可以专门配置一台复制(备份)从服务器，将复制延迟一段时间——如30min，以避免主服务器上的某些误操作——如DROP table。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:58:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"在线模式修改 将表做的小一点是很有好处的。 一般的想法是设置主-主复制对，但只有一台服务器可写。在只读上执行更新，但不要复制到可写服务器上。更新一旦完成，则用正常方式使应用程序实现失效转移。这样，读和写便实现了角色转换。然后在另一台服务器上重复执行风险。这就实现了对应用程序隐含宕机时间的目的。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:58:2","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"监控和图示 构建用于测量和监控的系统是很值得做的事情，这些系统是基础架构非常重要的核心内容。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:58:3","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"性能分析 一般步骤是，在产生麻烦的时间内手机详细的诊断数据，消除掉可能的原因，集中在问题的现象上。 问题往往是服务器产生大量负载，而这通常是由于糟糕的查询产生的。 MySQL所谓的慢查询日志(slow query log)可以回答这个问题，不仅是因为日志收集了慢查询的信息，而且对于每个查询还有时间信息。 加入性能问题不是查询引起的，则需要对MySQL本身进行性能测试。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:58:4","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"归档和删除数据 从一开始就要规划归档和删除不活动或不需要的数据，这样有助于减小“工作集”的大小。 将极不活跃的用户数据移动到慢速服务器，或仅仅将用户设置为过期。当用户登录或重新激活时，在倒回到正常表中 另外一类可归档或删除的数据是陈旧的历史数据，或将历史数据移到另外的服务器上 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:58:5","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"结语 尽最大可能将数据库架构建立在逻辑的基础上，而不是做一些看起来很酷的事情。 努力使系统保持小巧，不要大——而当不得不变大时，也要保持在能够掌控的范围内。要确定应用程序的真正需求，尽可能满足这些需求。要尽早及经常做缓存，但不要尽早及经常做分片。 最重要的，请记住：做备份。 \r \r如何优雅地失败：事后处理的艺术与科学 宕机意味着实际的金钱损失。 客户才不会管这些故障，他们要的就是可靠性。互联网已经变得非常重要，宕机成本也越来越高。 但正如一个刚毕业的年轻人一样，只是知道你需要成长，但并没有告诉你如何去成长。我们需要将失败转化为学习经验。 保证网站稳定的首要事情，就是建立一个系统化的事后分析过程。通过阻止事故的重现以及改进处理事故的方法，使得系统稳定之后，事后分析能够让你全面地理解事故的本性。 例行的时候分析，是对运维的复杂问题进行科学分析的最贴近的方法。通过收集实际证据，可将有限的资源集中于解决产生问题的实际原因上。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:59:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"什么是事后分析 事后分析至少要包含这些内容： 事故描述 根本原因描述 事件是如何修复的 用于解决事故的行动的时间表 事故是如何影响用户的 纠正或改正动作 事后分析时，与事故明显有关的人员都要同时到场，对事故的真实情况作出共同的描述，从而正确地采取行动。 减少事故的修复时间，就跟消除事故本身一样重要。 对问题赋予严重级别，将帮助你按照轻重缓急来处理纠正项，而且对于活跃事件的评估也是有用的。 事故严重级别： 严重影响大批用户 网站降级运行、性能问题或很难应对的功能故障 对客户影响不大或易于应对 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:60:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"什么时候引入事后分析 在事故处理完成之后，就应该进行事故分析。事后分析过程应该最终使用户获益，而不应该在恢复服务的过程中进行。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:61:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"进行事后分析 开始事后分析时，要明确基本规则，要明确告知参与事后分析的相关各方，事后分析不是指责谁(人们害怕这样的会议变成政治迫害)，主要目的是为了使类似事件不在重复发生。问题不可避免，重要的是我们能够从错误中学到教训。 事情一旦清楚之后，就可以开始讨论为了使类似事情不在发生，需要做些什么。确保相关各方对各自领域都能得出补救的办法。但切记不可矫枉过正！ 一旦有了一套纠正措施，要将其记录在案，包括执行人员和完成日期。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:62:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"事后分析的后续工作 对纠正措施必须进行追踪，直到执行完成。 一些网站可操作性： 消除单点故障 容量规划 监控 发布管理 运维架构复审 配置管理 随时待命和提升过程 不稳定的组件 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:63:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"结语 最后，对于避免事故的发生，事后分析是最有用的方法。在一个快速变化的环境中，发生问题时可以理解的，但问题重复发生却是不能原谅的。花些时间高清楚问题的实质，从而确定、记录以及实施高强度的纠正措施，就可以避免事故的重复发生。 \r存储 数据是一项最重要、不可替代的商业资产。 ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:64:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"数据资产的库存 在开始一项新的存储工作时，首要的事情是要知道数据存在哪里。 对于不了解的数据，你是无法进行保护的。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:65:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"数据的保护 数据保护对所有系统都是很重要的。 良好的数据保护实践有助于处理范围广泛的情形，从还原被用户偶然删除的文件，到从灾难事件中恢复。 为了对数据中心问题提供完全的防护，重要的是将关键数据复制到不同的地点。 如今大多数的存储系统都有某种类型的复制技术。复制通常有两种形式：同步和异步。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:66:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"容量规划 在确保有效的的数据保护之后，作为一名存储专业人员，容量规划就是第二项最重要的职责。 规划在前，确保应用和服务有足够的资源来运行和成长，不至于碰到天花板，这是必须的。 总是确保有足够的空间以应对突然的爆炸性增长，以及软件开发方面出现的延迟。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:67:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"存储大小的变化 存储是很昂贵的，这是现代基础框架中成本最高的组件。正是由于这个原因，对于存储上的开支进行明智地规划是很重要的。 存储需求要点： 应用是什么 应用位于哪里 存储的是什么类型的数据 需要共享存储吗 是否需要特殊的访问协议 典型的文件大小是多少 数据是压缩的吗 如果描述工作负载 需要批处理操作吗 工作负荷是大部分用于读、写、读写 工作负荷是大部分顺序、还是大部分随机、还是两者 快照是怎么安排的 快照的一致性问题 存储容量在6个月、12个月、18个月的计划是什么 工作负荷在6个月、12个月、18个月的计划是什么 复制策略是什么 业务连续性规划是什么 可用性需求是什么 备份的频度是什么 备份保持的计划是什么样的 归档策略是什么 综合性需求是什么 加密需求是什么 … \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:68:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"结语 数据是最宝贵的业务资产，且是不可替换的。 \r \r非关系数据库 应用的数据存储层的伸缩是很难的。不管用的是什么数据库技术，随着数据量和事务数量的增长，就需要做出改变以适应新的负荷。 SQL数据库的可伸缩性通常归结为四件事：缓存、查询优化、购买新硬件、数据库分片。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:69:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"NoSQL数据库概览 NoSQL共生系统，可将数据库划分为5大类： 纯粹的键值 数据结构 图 面向文档 高度分布 每种类别的数据库都面向不同的应用情况，每个类别也都做了不同的这种。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:70:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"纯粹的键值 如： Tokyo Cabinet、 Kyoto Cabinet、MemcacheDB 正是它们的简单性定义了这组数据库。向数据库存入一个键和一个值，然后用同一个键查询数据库，则会得到相同的值。没有结构或类型系统——通常所处理的只是字节或字符串。因为这种简单性，这些数据库的开销极小，所以非常块。事实上，这些数据库通常都是实现为磁盘上的B树或哈希表。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:70:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"数据结构 数据结构数据库对键值数据库做了些修改，数据结构数据库将其存储为特定的数据结构，如**列表、集合、哈希表等。**有了这些附加的结构，就可以对值执行一些原子操作。可以对数据库执行在应用程序中对数据结构进行的各种操作。 Redis默认是在内存中(in memory)存储其全部内容，只是周期性地将内容的快照存储到磁盘。这使得Redis出奇的快，但假如数据库奔溃了，就会对数据造成一些损失，同时也意味着必须有足够的RAM存储这个数据库。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:70:2","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"图 图数据库几乎就是数据结构数据库的一个特定实现，因为图本就是一种数据库。区别是图数据库不再是基于键值，数据是作为图的节点和边存储的。图数据库不是用键来查询值，而是给出根节点的句柄，然后就可以遍历整个图以找到需要的节点或边。 图数据库的优势：存储图或树形的数据。如一个社交图(social graph)。 常见图数据库包含：Neo4j、HyperGraphDB、InfoGrid、VertexDB。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:70:3","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"面向文档 面向文档的数据库又类似于键值数据库，但值不再是字节、字符串、列表、集合，而是文档。 文档作为JSON(BSON)对象存储，本质上是一种哈希表或字典。这些值都想相同的结构，意味着可以用查询来探测这种结构，并只返回所需要的文档。这种查询能力是建立在通过键来查找文档的能力之上的。 常见面向文档数据库： MongoDB、CouchDB。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:71:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"高度分布 高度分布的数据库多少有些不同——有些本质上更接近于键值存储，其它则像大型的多维哈希图。 HBase、Cassandra是高度分布式数据库。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:71:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"某些细节 注意这些数据库之间的一些相似性，以及所做决策是如何影响系统可操作性的。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:72:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"Cassandra Cassandra是一个高度分布数据库。 它有一些关键概念： 认为写比读更难于伸缩，所以它专门为写操作做了大量优化 认为不应该存在单一故障点 任何数据可以写入到集群内的任何一个节点，而且读也一样。任何接收到请求的节点都可以，并且将会吧请求转发到合适的节点。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:72:1","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"HBase HBase选择一致性和可用性作为自己的核心价值。这样的结果，导致了在某些网段、集群无法实现优雅的恢复。作为这种牺牲的补偿，HBase有很强的一致性，保证写入一结束，写入的值就立即可以读取。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:72:2","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"Riak Riak实现了向量时钟(vector clocks)，一些高度分布的数据库都没有实现——这些数据库选择了依赖于更为简单的基于时间戳的技术。 向量时钟是一种分布式系统中的机制，用于生成偏序事件。使用向量时钟，解决发生在两个独立的不同节点中的相同值的冲突就变得非常简单。从Riak客户端的角度来看，每个客户实例在Riak集群中执行一个动作时，都应该有一个唯一的标识(token)(连同其接收到的向量时钟一起)。然后，客户读取数据时，就可以看到向量时钟和数据值，使用包含的信息连接两个结果，从而将正确的版本写会数据库。 Riak也不存在单一故障点。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:72:3","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"CouchDB CouchDB对世界的看法是一致的：所有东西都是文档，而且都通过RESTful HTTP来访问。 CouchDB可以在数据库中直接存储静态媒体，它实际上是允许将整个应用程序都存储在数据库中的。 CouchDB的数据模型很新颖，即数据以一种只附加的B树进行存储。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:72:4","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"MongoDB MongoDB是一个面向文档的数据库，文档格式使用BSON——一种类似于JSON对象的二进制规范。MongoDB是用C++写的，因而有很高的性能。 所有能用SQL做的事情也能用MongoDB查询表达式来做。 MongoDB与以SQL数据库相同的方式支持索引，同时这些索引也强制了唯一性。 MongoDB有一个mongostat命令来查看数据库状态。 有好几种MongoDB备份方式： 停掉数据库，复制数据文件 锁定数据库写入，复制数据文件，解除锁定 使用mongodump，将数据库转存到一个二进制文件中 可以设置一个从服务器，在从服务器上进行备份，而不是主服务器上 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:72:5","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"Redis Redis(remote dictionary server)，远程字典服务器。通过INFO可查看相关信息。 不管你将Redis运行在快照模式(rdb)还是只附加模式(aof)上，都可以简单地调用rsync实现备份。 \r \r如何高枕无忧 企业持续规划(Business Continuity Planning)BCP。 BCP简单最简单来说，就是什么都是两份。当然，两套设备间的失效转移必须完全自动化。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:72:6","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"术语 集中于BCP计划的高可用部分：保证站点正常工作。即使在高可用性领域，也有各种各样的技术，从热/热(Hot/Hot)、热/暖(Hot/Warm)、热/冷(Hot/Cold)到灾难恢复。 热/热是高可用性的最高级别。用户可以从任意的数据中心使用全部的应用程序。读和写可以发生在任何地方。折让自动的故障转移变得非常简单，但它不是万能的。你想必须思考如何处理数据一致性的问题。 热/暖是一种很好的方式，如果你不能容忍数据的不一致性的话。很多应用有大量的读操作，仅偶尔写一下(但很重要)。在这种情况下，区别处理这两种操作是有意义的。 热/冷让我害怕。这种架构将读写流量送到单一地点，而让另一个相同的部署在遥远的地平线上闲置。它容易建立，但价值很低。 灾难恢复是最差的技术，本质上是雾件(vaporware)。它的本意不是在平常的时候保护你，而是在大的灾难发生时给你提供重建的选项。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:73:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"影响持续时间对事件持续时间 当灾难来袭时，所有你需要考虑的是将用户流量以最快速度转移，离开问题区域。你需要立即降低影响。不要过于担心根源问题的修复，一旦将影响制止住，会有很多时间来解决这次事故。 怎样才能将流量从问题站点转出呢？通常方案是使用全局负载均衡(Global Server Load Balancing)GSLB。这实际是一个动态的授权DNS服务器，他能够根据相关因素对同一域名给出不同的IP地址。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:74:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"数据中心数量 我们知道数据中心会失效，所以你至少需要两个。这就够了吗？三个或更多是不是会好一些？这取决于三个因素，成本、复杂性和性能。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:75:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"逐渐失效 当数据中心出现局部问题(partial problem)时，不要等它解决从而希望你不需要撤离，立即导出复制数据！ \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:76:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"不信赖任何人 正如最可靠的数据中心也会时不时宕机，你可以预期即使最好的第三方供应商，偶尔也会有问题。就是你不能完全信赖一个服务提供商。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:77:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"故障测试转移 通过早期和经常的测试，获取经验，以便当灾难袭来时，不会手忙脚乱，而是立即做出正确的事情。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:78:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"监控和历史模式 你要知道日、周、月的流量模式。如果清楚正常流量中的不寻常处，你就不会在切换、迁移或升级时感到惊讶。确保监控包括周对周的图形和趋势。 \r","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:79:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["web"],"content":"高枕无忧 如果你能够事先有计划，能够解决大的问题，并且在日常工作中操练故障转移，则平台任何部分的失效将会变成容易处理的事件，而不是危机。 \r March 25, 2018 11:32 AM ","date":"2018-03-05","objectID":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/:80:0","tags":["Operations","Database"],"title":"网站运维","uri":"/%E7%BD%91%E7%AB%99%E8%BF%90%E7%BB%B4/"},{"categories":["economics"],"content":"参考： 《经济学原理-微观/宏观》 曼昆： https://book.douban.com/subject/26435630/ \r\r 学习指南图 微观经济学: 第1篇到第7篇，即第1章到第22章。 第1篇： 导言 第1章： 经济学十大原理 第2章： 像经济学家一样思考 第3章： 相互依存性和贸易的好处 第2篇： 市场如何运行 第4章： 供给与需求的市场力量 第5章： 弹性及其应用 第6章： 供给、需求和政府策略 第3篇： 市场和福利 第7章： 消费者、生产者与市场效率 第8章： 应用： 赋税的代价 第9章： 应用： 国际贸易 第4篇： 公共部门经济学 第10章： 外部性 第11章： 公共物品和公共资源 第12章： 税制的设计 第5篇： 企业行为与产业组织 第13章： 生产成本 第14章： 竞争市场上的企业 第15章： 垄断 第16章： 垄断竞争 第17章： 寡头 第6篇： 劳动市场经济学 第18章： 生产要素市场 第19章： 收入与歧视 第20章： 收入不平等与贫困 第7篇： 深入研究的论题 第21章： 消费者选择理论 第22章： 微观经济学前沿 宏观经济学： 从第8篇到第13篇，即第23章到第36章。 第8篇： 宏观经济学的数据 第23章： 一国收入的衡量 第24章： 生活费用的衡量 第9篇： 长期中的真实经济 第25章： 生产与增长 第26章： 储蓄、投资和金融体系 第27章： 金融学的基本工具 第28章： 失业 第10篇： 长期中的货币与物价 第29章： 货币制度 第30章： 货币增长与通货膨胀 第11篇： 开放经济的宏观经济学 第31章： 开放经济的宏观经济学基本概念 第32章：开放经济的宏观经济理论 第12篇： 短期经济波动 第33章： 总需求与总供给 第34章： 货币政策和财政政策对总需求的影响 第35章： 通货膨胀与失业之间的短期权衡和取舍 第13篇： 最后的思考 第36章： 宏观经济政策的六个争论问题 阿尔弗雷德·马歇尔在《经济学原理》中写道经济学是一门研究人类一般生活事务的学问。 应当学习经济学的原因如下： 有助于你理解你所生活在其中的世界 使你更加精明的参与经济 使你更好地理解经济政策的潜力与局限性 经济学原理可以运用到生活中的方方面面 经济学领域的伟大洞见，如亚当·斯密的看不见的手的概念、大卫·李嘉图的比较优势原理，以及约翰·梅纳德·凯恩斯的总需求理论 \r\r \r\r导言 ","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:0:0","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"经济学十大原理 **经济(economy)**这个词来源于希腊语oikonomos，意思是“管理一个家庭的人”。 一个家庭面临着许多决策，同样，一个社会也面临着许多决策。 由于资源是稀缺的，社会资源的管理就尤为重要。 稀缺性(scarcity): 社会资源的有限性 经济学(economics): 研究社会如何管理自己的稀缺资源 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:1:0","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"人们如何做出决策 由于一个经济的行为反映了组成这个经济的个人的行为，所以个人就需要做出决策。 \r人们面临权衡取舍 效率(efficiency): 社会能从其稀缺资源中得到最大利益的特性 平等(equlity): 经济成果在社会成员中平均分配的特性 作出决策就是要求我们在一个目标与另一个目标之间进行权衡取舍。 当人们组成社会时，他们会面临不同的权衡取舍。经典的权衡取舍是在大炮与黄油之间。 社会面临的另一种权衡取舍是在效率与平等之间。 然而，认识到人们面临权衡取舍本身并没有告诉我们人们将会或应该做出什么决策。 \r\r某种东西的成本是为了得到这种东西所放弃的东西 机会成本(opportunity cost): 为了得到某种东西所必须放弃的东西 由于人们面临着权衡取舍，所以做决策就需要比较可供选择的行动方案的成本与收益。 \r\r理性人考虑边际量 理性人(rational people): 系统而有目的地尽最大努力实现其目标的人 边际变动(marginal change): 对行动计划的微小增量调整 边际成本(marginal cose): 对行动计划调整所带来的成本 边际收益(marginal benefit): 对行动计划调整所带来的的收益 边际决策(marginal decision): 选择哪种决策 \r\r人们会对激励做出反应 激励(incentive): 引起一个人做出某种行为的某种东西 在经济学研究中，激励起着中心作用。 市场上的高价格提供了买者少消费而卖者多生产的激励。 价格对消费者和生产者行为的影响对于市场经济如何配置稀缺资源是至关重要的。 政府决策者决不能忘记激励，因为许多政策改变了人们面临的成本或收益，从而也改变了人们的行为。 在分析任何一种政策时，我们不仅应该考虑它的直接影响，而且还应该考虑它通过激励产生的不太明显的间接影响。如果政策改变了激励，那就会使人们改变自己的行为。 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:1:1","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"人们如何互相影响 我们的许多决策不仅影响了我们自己，还会影响其他人。 \r贸易可以使每个人的状况都变得更好 思考国家之间的竞争的想法很容易产生误导。美国与中国之间的贸易并不像体育比赛一样，一方赢而另一方输。实际上，事实正好相反：两国之间的贸易可以使两个国家的状况都变得更好。 贸易使每个人都可以专门从事自己最擅长的活动，无论它是耕种、做衣服还是盖房子。通过与其他人的贸易，人们可以以较低的成本获得各种各样的物品和服务。 国家和家庭一样，也能从相互贸易中获益。贸易可以使各国可以专门从事自己最擅长的活动，并享有种类更多的物品与服务。美国人和英国人、法国人一样，在世界经济中既是我们的竞争对手，又是我们的伙伴。 \r\r市场通常是组织经济活动的一种好方法 市场经济(market economy): 当许多企业和家庭在物品与服务市场上相互交易时，通过他们的分散决策配置资源的经济 看不见的手(invisible hand): 利己心(self-interest): 中央计划经济国家运行的前提假设是，政府官员能够最佳地配置经济中稀缺资源。这些中央计划者决定，生产什么物品与服务、生产多少，以及谁生产和消费这些物品与服务。支撑中央计划经济的理论是，只有政府才能以促进整个社会经济福利的方式组织经济活动。 大部分曾经是中央计划经济的国家已经放弃了这个制度，代之以发展市场经济。在市场经济中，中央计划者的决策被数千百万企业和家庭的决策所取代。 在市场经济中，没有一个人追求整个社会的经济福利。自由市场包括大量物品与服务的许多买者与卖者，而所有的人都主要关心自己的福利。 经济学家亚当·斯密在《国富论》中提出了全部经济学中最著名的观察结果：“家庭和企业在市场上相互交易，他们仿佛被一只看不见的手所指引，并导致了合意的市场结果。” 价格就是看不见的手用来指引经济活动的工具。作为买者与卖者决策的结果，市场价格既反映了一种物品的社会价值，也反映了生产该物品的社会成本。斯密的重要洞察是，价格会自发调整，指引这些单个买者和卖者达到某种结果，该结果在大多数情况下会实现整个社会福利的最大化。 斯密的观点有一个重要的推论：当政府阻止价格根据供求状况自发调整时，它就限制了看不见的手对组成经济的千百万家庭和企业的决策进行协调的能力。这个推论解释了为什么税收对资源配置有不利的影响：由于税收扭曲了价格，从而也扭曲了家庭和企业的决策。这个推论还解释了像租金控制这类直接控制价格的政策所引起的巨大危害。而且，这个推论解释了中央计划经济的失败。在中央计划经济国家，价格并不是在市场上决定的，而是由中央计划者规定的。这些计划者缺乏关于消费者爱好和生产者成本的必要信息，而在市场经济中这些信息都反映在价格上。中央计划者之所以失败，是因为他们在管理经济时把市场这只看不见的手绑起来了。 亚当·斯密描述了市场经济中人们如何相互影响： 人类几乎随时随地都需要同胞的协助，要想仅仅依赖他人的恩惠，那是绝对不行的。他如果能够刺激他人的利己心，使其有利于他，并告诉其他人，给他做事是对他们自己有利的，那么他要达到目的就容易得多了。··· ···请给我们我所要的东西吧，同时，你也可以获得你所要的东西：这句话是交易的通义。我们所需要的相互帮助，大部分是依照这个方法取得的。 我们每天所需的食物和饮料，不是出自屠户、酿酒师或面包师的恩惠，而是出自他们利己的打算。我们不说唤起他们利他心的话，而说唤起他们利己心得话。我们不说自己有需要，而说对他们有利。社会上，除乞丐外，没有一个人愿意全然靠别人的恩惠过活… … 每一个人··· ···既不打算促进公共的利益，也不知道自己是在何种程度上促进那种利益··· ···他所盘算的也只是他自己的利益。在这种场合下，像在其他许多场合一样，他受着一只看不见的手的引导，去尽力达到一个并非他本意想要达到的目的。也并不因为不是出于本意，就对社会有害。他追求自己的利益，往往使他能比在真正处于本意的情况下更有效地促进社会的利益。 斯密是说，经济参与者受利己心所驱动，而市场上这只看不见的手指引这种利己心去促进总体的经济福利。 \r\r政府有时可以改善市场结果 产权(property rights): 个人拥有并控制稀缺资源的能力 市场失灵(market failure): 市场本身不能有效的配置资源的情况 外部性(externality): 一个人的行为对旁观者福利的影响 外部性的经典例子是污染 市场势力(market power): 单个经济活动者(或某个经济活动小群体)对市场价格有显著影响的能力 我们需要政府的原因之一是：只有在政府实施规则并维持对市场经济至关重要的制度时，看不见的手才能施展其魔力。最重要的是，市场经济需要实施产权制度，以便个人可以拥有和控制稀缺资源。 我们都依靠政府提供的警察和法律来实施我们对自己生产出来的东西的权利——而看不见的手依靠我们实施自己权利的能力。 然而，我们需要政府的另一个原因是：看不见的手是强有力的，但并不是无所不能的。政府干预经济并改变人们自己选择的资源配置的原因有两类：促进效率和促进公平。这就是说，大多数政策的目标要么是把经济蛋糕做大，要么是改变这个蛋糕的分割方式。 在存在外部性或市场势力的情况下，设计良好的公共政策可以提高经济效率。 即使看不见的手带来了有效率的产出，他也不能消除经济福利上巨大的不对称。根据某种政治哲学，这种不平等要求政府进行干预。实际上，许多公共政策，例如所得税和福利制度的目标就是要实现更平等的经济福利分配。 我们说政府有时可以改善市场结果并不意味着它总会这样。公共政策并不是天使制定的，而是由不完善的政治程序制定的。有时所设计的政策只是为了有利于政治上有权势的人；有时政策是由动机良好但信息不充分的领导人制定的。 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:1:2","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"整体经济如何运行 决策和相互影响共同组成了经济。 一国的生活水平取决于它生产物品与服务的能力 生产率(productivity): 每单位劳动投入所生产的物品与服务数量 世界各国生活水平的差别是惊人的。 随着时间的推移，生活水平的变化也是巨大的。 几乎所有的生活水平的差别都可以归因于各国生产率的差别。 生产率和生活水平之间的基本关系是简单的，但它的意义却是深远的。如果生产率是生活水平的首要决定因素，那么，其他因素就应该是次要的。 \r\r当政府发行了过多货币时，物价上升 通货膨胀(inflation): 经济中物价总水平的上升 在大多数严重或持续通货膨胀的情况下，罪魁祸首是货币量的增长。 当一国政府发行了大量本国货币时，货币的价值就下降了。 由于高通货膨胀会让社会付出各种成本，所以世界各国的经济政策制定者都把保持低通货膨胀作为目标之一。 \r\r社会面临通货膨胀与失业之间的短期权衡取舍 经济周期(business cycle): 就业和经济生产的波动 虽然在长期中，物价水平上升主要是货币增加的结果，但短期中，问题就变得更为复杂更具争议性。 大多数经济学家这样描述货币注入的短期效应： 经济中货币量增加刺激了社会的整体支出水平，从而增加了对物品与服务的需求 需求的增量随着时间的推移，会引起企业提高物价，但同时，它也鼓励企业雇佣更多的工人，并生产更多的产品与服务 服用更多的工人意味着更少的失业 你知道，支出链将以乘数扩大，并带来更高的收入和就业。人们看到了发生了的活动，但他们没有看到本来会发生的活动。 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:1:3","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"结论 经济学十大原理： 人们如何做出决策 人们面临权衡取舍 某种东西的成本是为了得到它所放弃的东西 理性人考虑边际量 人们会对激励做出反应 人们如何相互影响 贸易可以使每个人的状况都变得更好 市场通常是组织经济活动的一种好方法 政府有时可以改善市场结果 整体经济如何运行 一国的生活水平取决于它生产物品与服务的能力 当政府发行了过多的货币时，物价上升 社会面临通货膨胀与失业之间的短期权衡取舍 \r\r \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:1:4","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"像经济学家一样思考 每个研究领域都有自己的语言和思考方式。经济学家也一样。 供给、需求、弹性、比较优势、消费者剩余和无谓损失——这些术语也是经济学家语言的一部分。 \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:2:0","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"作为科学家的经济学家 先提出理论，再收集数据，然后分析数据，以努力证明或否定他们的理论。 \r科学方法：观察、理论和进一步观察 在经济学研究中，进行实验往往是不可能的。通常不得不使用这个世界向他们提供的数据。 为了寻找实验室实验的替代品，经济学家十分关注历史所提供的自然实验。 \r\r假设的作用 当我们在研究政策变动在长短不同时间中的影响时，就会做出不同的假设。 \r\r经济模型 经济学家也用模型来了解世界，但不是塑料模型，而通常是由图形和方程组成的模型。 \r\r第一个模型：循环流量图 循环流量图(circular-flow diagram): 一个说明货币如何通过市场在家庭与企业之间流动的直观经济模型 生产要素(production factors): 劳动、土地、资本等投入品被称为生产要素 企业用生产要素来生产产品和服务，家庭则拥有生产要素并消费企业生产的物品与服务。家庭与企业之间相互交易。 \r\r第二个模型：生产可能性边界 生产可能性边界(production possibilities frontier)： 表示在可得到的生产要素与生产技术既定时，一个经济所能生产的产品数量的各种组合的图形。 由于资源是稀缺的因此并不是每一种想象的结果都是可行的。 生产可能性边界表明了社会所面临的一种权衡取舍。 生产可能性边界表明在某一特定时期内生产不同物品之间的权衡取舍，但随着时间的推移，这种权衡取舍可以改变。 生产可能性边界简化了复杂的经济，以便强调一些基本但极为重要的思想： 稀缺性、效率、权衡取舍、机会成本和经济增长。 \r\r微观经济学与宏观经济学 尽管微观经济学和宏观经济学之间存在固有的联系，但这两个领域仍然是不同的。 微观经济学(micro economics)： 研究家庭和企业如何做出决策，以及它们如何在市场上相互交易的学科。 宏观经济学(macro economics)： 研究整体经济现象，包括通货膨胀、失业和经济增长的学科。 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:2:1","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"作为政策顾问的经济学家 当经济学家试图去解释世界时，他们是科学家；当经济学家试图去帮助改变世界时，他们是政策顾问。 \r实证分析与规范分析 一般来说，关于世界的表述有两种类型： 实证表述(positive statements)： 试图描述世界是什么样子的观点。 规范表述(normative statements)： 试图描述世界应该是什么样子的观点。 确定什么是好策略或什么是坏策略不仅仅是一个科学问题，它还涉及我们对伦理、宗教和政治哲学的看法。 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:2:2","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"经济学家意见分歧 有两个基本原因： 经济学家可能对世界如何运行的不同实证理论的正确性看法不一致 经济学家可能有不同的价值观，因此对政策应该努力实现的目标有不同的规范观点 \r\r \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:2:3","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"相互依存性与贸易的好处 人们向你和其他消费者提供他们生产的物品与服务，是因为他们也得到了某种回报。 \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:3:0","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"一个现代经济寓言 每个人都可以通过专门从事自己最擅长的活动并从相互叫中获益。 但是，当某个人在生产每一种物品上都较为擅长时，贸易的好处就不那么明显了。 \r生产可能性 专业化和贸易 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:3:1","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"比较优势： 专业化的动力 绝对优势 绝对优势(absolute advantage)： 一个生产者用比另一个生产者更少的投入生产某种物品的能力。 \r\r机会成本与比较优势 机会成本(opportunity cost)： 为了得到某种东西所必须放弃的东西。 比较优势(comparative advantage)： 一个生产者以低于另一个生产者的机会成本生产某种物品的能力。 尽管一个人有可能在两种物品的生产上都具有绝对优势，但一个人却不可能在两种物品的生产上都具有比较优势。 \r\r比较优势与贸易 专业化和贸易的好处不是基于绝对优势，而是基于比较优势。当每个人专门生产自己有比较优势的物品时，经济的总产量就增加了，经济蛋糕的变大可用于改善每个人的状况。 贸易可以使社会上的每个人都获益，因为它使人们可以专门从事他们具有比较优势的活动。 \r\r贸易的价格 对从贸易中获益的双方而言，他们进行贸易的价格在两种机会成本之间。 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:3:2","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"比较优势的应用 美国应该与其他国家进行贸易吗 进口品(imports)： 在国外生产而在国内销售的物品。 出口品(exports)： 在国内生产而在国外销售的物品。 每个国家都有许多具有不同利益的居民。即使国际贸易可以使国家作为一个整体的状况变好，但也会使一些人的状况变坏。 但国际贸易并不像战争，在战争中有些国家是胜利者，而其他国家是失败者。贸易使所有国家都可以实现更大的繁荣。 \r\r \r\r市场如何运行 \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:3:3","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"供给与需求的市场力量 供给与需求是经济学家最经常——而且有充分的理由使用的两个词。供给与需求是使市场经济运行的力量。它们决定了每种物品的产量及其出售的价格。 \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:4:0","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"市场与竞争 市场(market)： 由某种物品或服务的买者与卖者组成的一个群体。 竞争市场(competitive market)： 有许多买者与卖者，以至于每个人对市场价格的影响都微乎其微的市场。 我们假设市场是完全竞争的。为了达到此竞争的最高形式，一个市场必须具备两个特征： 可供销售的物品时完全相同的 买者与卖者人数众多，以至于没有任何一个买者或卖者可以影响市场价格 但是，并不是所有物品与服务都在完全竞争市场上出售。一些市场可能只有一个买者，而且这个卖者决定价格。这样的卖者被称为垄断者 还有一些市场介于完全竞争和垄断这两种极端形式之间。 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:4:1","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"需求 \r价格与需求量之间的关系 需求量(quantity demanded)： 买者愿意斌企鹅能够购买的一种物品的数量。 需求定理(law of demand)： 认为在其他条件不变时，一种物品的价格上升，对该物品的需求量减少的观点。 需求表(demand schedule)： 表示一种物品的价格与需求之间的关系的表格。 需求曲线(demand curve)： 表示一种物品的价格与需求量之间关系的图形。 正常物品(normal good)： 在其他条件相同时，收入增加引起需求量增加的物品。 低档物品(inferior good)： 在其他条件相同时，收入增加引起需求量减少的物品。 替代品(substitutes)： 一种物品价格的上升引起另一种物品需求量的增加的两种物品。 互补品(complements)： 一种物品价格的上升引起另一种物品需求量的减少的两种物品。 影响买者的变量： 收入 价格 爱好 预期 其它 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:4:2","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"供给 \r价格与供给量之间的关系 供给量(quantity supplied)： 卖者愿意并且能够出售的一种物品的数量。 供给定理(law of supply)： 认为在其他条件不变时，一种物品的价格上升，该物品的供给量增加的观点。 供给表(supply schedule)： 表示一种物品的价格与供给量之间的关系的表格。 供给曲线(supply curve)： 表示一种物品的价格与供给量之间关系的图形。 使供给曲线移动的一些变量： 价格 技术 预期 卖者的数量 其它 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:4:3","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"供给与需求的结合 均衡(equilibrium)： 市场价格达到使供给量与需求量相等的水平时的状态。 均衡价格(equilibrium price)： 使供给与需求平衡的价格。 均衡数量(equilibrium quantity)： 均衡价格下的供给量与需求量。 过剩(surplus)： 供给量大于需求量的状态。 短缺(shortage)： 需求量大于供给量的状态。 供求定力(law of supply and demand)： 认为任何一种物品的价格都会自发调整，使该物品的供给与需求达到平衡的观点。 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:4:4","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"价格如何配置资源 在市场经济中，价格是配置稀缺资源的机制。 \r\r \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:4:5","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"弹性 假设某件事情使得汽油价格上升，那么消费者将少买汽油。那么汽油的消费量会减少多少呢？——这个问题可以用弹性的概念来回答。 \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:5:0","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"需求弹性 弹性(elasticity)： 衡量需求量或供给量对某种决定因素的变动的反应程度的指标。 需求价格弹性(price elasticity of demand)： 衡量一种物品需求量对其价格变动反应程度的指标，用需求量变动百分比除以价格变动百分比来计算。 总收益(total revenue)： 一种物品的买者支付而卖者得到的量，用该物品的价格乘以销售量来计算。 需求收入弹性(income elasticity of demand)： 衡量一种物品需求量对消费者收入变动反应程度的指标，用需求量变动百分比除以收入变动百分比来计算。 需求交叉价格弹性(cross-price elasticity of demand)： 衡量一种物品需求量对另一种物品价格变动的反应程度的指标，用第一种物品需求量变动百分比除以第二种物品价格变动百分比来计算。 富有弹性 缺乏弹性 单位弹性 完全无弹性 完全有弹性 替代品 必需品 奢侈品 市场的定义 时间范围 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:5:1","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"供给弹性 供给价格弹性(price elasticity of supply)： 衡量一种物品供给量对其价格变动反应程度的指标，用供给量变动百分比除以价格变动百分比来计算。 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:5:2","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"供给、需求和弹性的应用 农业的好消息可能对农民来说是坏消息吗 为什么石油输出国组织不能保持石油的高价格 禁毒增加了还是减少了毒品相关的犯罪 \r\r \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:5:3","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"供给、需求与政府政策 当决策者认为一种物品或服务的市场价格对买者或卖者不公平时，通常会实施价格控制。但这些控制政策本身也会引起不公平。 决策者用税收为公共目标筹集资金并影响市场结果。 \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:6:0","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"价格控制 价格上限(price ceiling)： 出售一种物品的法定最高价格 价格下限(price floor)： 出售一种物品的法定最低价格 由于任何一种物品的买者总希望价格更低，而卖者总希望价格更高。所以，这两个群体的利益就会产生冲突 当政府对竞争市场实行限制性价格上限时，就产生了物品的短缺，而且，卖者必须在大量潜在买者中配给稀缺物品。 与此相比，一个自由竞争市场中的配给机制既有效率又是客观的。 价格有平衡供求从而协调经济活动的关键作用。当决策者通过法令确定价格时，他们就模糊了正常情况下指引社会资源配置的信号。 价格控制的目标往往是帮助穷人。但价格控制往往损害了那些它本想要帮助的人。可以用除了控制价格以外的其他方法来帮助那些需要帮助的人(如补贴或减税)。但是，税收也是有成本的。 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:6:1","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"税收 税收归附(塔下 incidence)： 税收负担在市场参与者之间进行分配的方式。 当政府对一种物品征税时，谁实际承担了税收负担？ 无论税收是向买者征税还是想卖者征税，这一买者价格与卖者价格之间的楔子都是相同的。在这两种情况下，这个楔子都使供给曲线和需求曲线的相对位置移动。在新均衡时，都是买者与卖者分摊税收负担。 无论向谁征税，一旦市场达到新均衡，都是买者与卖者分摊税收负担。 经济受两种规则体系支配： 供求规律和政府制定的法规。 \r\r \r\r市场和福利 ","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:6:2","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"消费者、生产者与市场效率 买者总想少付些钱，而卖者总想多买些钱。 福利经济学(welfare economics) 研究资源配置如何影响经济福利的一门学问。 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:7:0","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"消费者剩余 支付意愿(willingness to pay) 买者愿意为某种物品支付的最高量。 消费者剩余(consumer surplus) 买者愿意为一种物品支付的量减去其为此实际支付的量。 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:7:1","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"生产者剩余 成本(cost) 卖者为了生产一种物品而必须放弃的所有东西的价值。 生产者剩余(producer surplus) 卖者出售一种物品得到的量减去其生产成本。 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:7:2","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"市场效率 总剩余 消费者剩余和生产者剩余的总和，称为总剩余。 效率(efficiency) 资源配置使社会所有成员得到的总剩余最大化的性质。 平等(equality) 在社会成员中平均地分配经济成果的性质。 市场势力 影响价格的能力，如市场上一小群能够控制市场价格的买卖者。 外部性 市场的副作用，如污染。 在本质上，从市场贸易中获取的利益就像一块要在市场参与者间分配的蛋糕。效率问题涉及的是蛋糕是否尽可能地做大了。平等问题涉及的是如何把这块蛋糕切成小块，以及如何在社会成员中进行分配。 市场失灵是指一些不受管制的市场不能有效地配置资源。当出现市场失灵时，公共政策有可能纠正这些问题并提高经济效率。 \r\r \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:7:3","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"赋税的代价 买者和买者因税收遭受的损失大于政府筹集到的收入。 \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:8:0","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"赋税的无谓损失 无谓损失(deadweight loss) 市场扭曲(如税收)引起的总剩余减少。 税收引起的无谓损失是因为它使买者和卖者不能实现某些贸易的好处。 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:8:1","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"决定无谓损失的因素 供给和需求的价格弹性越大，税收的无谓损失也就越大。 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:8:2","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"税收变动时无谓损失和税收收入 税收很少长期保持不变。 当政府对一种商品的买者或卖者征税时，社会就损失了某些市场效率的好处。税收给市场参与者带来了损失，不仅是因为税收将资源从市场参与者手中转到政府手中，还因为税收改变了激励，并扭曲了市场结果。 \r\r \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:8:3","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"国际贸易 许多企业发现，由于面临可以以低成本生产高质量物品的外国竞争者，要通过生产某种产品获得利润已经越来越困难了。因此，他们迁移或关闭了工厂。 \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:9:0","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"决定贸易的因素 世界价格(world price) 一种物品在世界市场上通行的价格。 如果某种物品的世界价格高于国内价格，那么，一旦允许贸易，此国就会变成此物品出口国；反之，则变为此物进口国。 各国之间的贸易最终要建立在比较优势的基础之上。 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:9:1","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"贸易的赢家与输家 关税(tariff) 对在国外生产而在国内销售的物品征收的一种税。 当一国允许贸易并成为一种物品的出口国时，国内该物品的生产者的状况变好了，而国内该物品消费者的状况变坏了。 从赢家收益超过了输家损失的意义上说，贸易使一国的经济福利增加了。 当一国允许贸易并成为一种物品的进口国时，国内该物品消费者的状况变好了，而国内该物品生产者的状况变坏了。 从赢家收益超过了输家损失的意义上说，贸易使一国的经济福利增加了。 国际贸易的其它好处： 增加了物品的多样性 通过规模经济降低了成本 增加了竞争 加强了思想交流 关税减少了进口量，并使国内市场向没有贸易时的均衡移动 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:9:2","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"各种限制贸易的观点 工作岗位论 贸易反对者会说，与其他国家进行贸易消灭了国内的一些工作岗位。 但自由贸易在消灭了一些工作岗位的同时，也创造了一些工作岗位。 国家安全论 一些行业收到来自其他国家的竞争威胁时，贸易反对者会说，该行业对国家安全是至关重要的。 处于对国家安全的合理考虑，保护关键行业可能是合理的。但也应该由国家机构所提出。 幼稚产业论 会说，应实行暂时性贸易限制，以有助于该产业的成长。 这也难以实施。如何确定哪个产业是新兴的幼稚产业？ 不公平竞争论 一种常见的观点是，如果不同国家的企业服从于不同的法律和管制，那么，让企业在国际市场上进行竞争就是不公平的。 作为讨价还价筹码的保护论 当与自己的贸易伙伴讨价还价时，贸易限制可能还是有用的。 大多数经济学家支持自由的国际贸易，他们认为自由贸易是一种有效配置生产的方法，并提高了两国的生活水平。 \r\r \r\r公共部门经济学 \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:9:3","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"外部性 外部性(externality) 一个人的行为对旁观者福利的无补偿的影响 正外部性 这种影响是有利的 负外部性 这种影响是不利的 栗子： 汽车尾气 修复历史建筑 狂吠的狗 新技术的研究 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:10:0","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"外部性和市场无效率 外部性内在化(internalizing the externality) 改变激励，以使人们考虑到自己行为的外部效应 政府可以通过对负外部性的物品征税和给予有正外部性的物品补贴来使外部性内在化 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:10:1","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"针对外部性的公共政策 管制 政府可以通过规定或禁止某些行为来解决外部性。 矫正税 旨在引导私人决策者考虑负外部性引起的社会成本的税收 补贴 可交易的污染许可证 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:10:2","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"外部性的私人解决方法 科斯定理(Coase theorem) 认为如果私人各方面可以无成本地就资源配置进行协商，那么，他们就可以自己解决外部性问题的观点 交易成本(transaction cost) 各方在达成协议与遵守协议过程中所发生的成本 \r\r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:10:3","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"公共物品和公共资源 \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:11:0","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"不同类型的物品 排他性(excludability) 一种物品具有的可以阻止一个人使用该物品的特性 消费品中的竞争性(rivalry in consumption) 一个人使用一种物品将减少其他人对该物品的使用的特性 私人物品(private goods) 既有排他性又有消费竞争性的物品 公共物品(public goods) 即无排他性又无消费竞争性的物品 公共资源(common resources) 有消费竞争性但无排他性的物品 俱乐部物品(club goods) 有排他性但无消费竞争性的物品 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:11:1","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"公共物品 产权的重要性 搭便车者(free rider) 得到一种物品的利益但避免为此付费的人 一些重要的公共物品 国防 基础研究 反贫困 成本收益分析(cost-benefit analysis) 比较提供一种公共物品的社会成本与社会收益的研究 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:11:2","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"公共资源 公共悲剧(Tragedy of the Commons) 一个说明从整个社会的角度看，为什么公共资源的使用大于合意的水平的寓言 一些重要的公共资源 清洁的空气和水 拥堵的道路 野生动物 \r\r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:11:3","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"税制的设计 在这个世界上除了死亡和税收以外，没有什么事情是确定无疑的。 \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:12:0","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"政府的财政状况 政府的税收占国民收入的多少？ 预算赤字(budget deficit) 政府支出大于政府收入 预算盈余(budget surplus) 政府收入大于政府支出 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:12:1","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"税收和效率 税收会引起两个成本，良好的税收政策正是要使其最小化： 当税收扭曲了人们做出的决策时引起的无谓损失 纳税人在遵照税法纳税时承担的管理负担 收入税 消费税 平均税率(average tax rate) 支付的总税收除以总收入 边际税率(marginal tax rate) 增加1美元收入所支付的额外税收 定额税(lump-sum tax) 对每个人等量征收的税收 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:12:2","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"税收和平等 受益原则(benefit principle) 认为人们应该根据他们从政府服务中得到的利益来纳税的思想 支付能力原则(ability-to-pay principle) 认为应该根据一个人可以承当的负担来对这个人征税的思想 纵向平等(vertical equity) 主张支付能力更强的纳税人应该缴纳更多税收的思想 横向平等(horizontal equity) 主张有相似支付能力的纳税人应该缴纳等量税收的思想 比例税(proportional tax) 高收入纳税人和低收入纳税人缴纳收入中相同比例的税收 累进税(progressive tax) 高收入纳税人缴纳的税收在收入中的比例高于低收入纳税人的这一比例 累退税(regressive tax) 高收入纳税人缴纳的税收在收入中的比例低于低收入纳税人的这一比例 \r\r \r\r企业行为与产业组织 \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:12:3","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"生产成本 经济是由成千上万个生产你每天享用的物品与服务的企业(大型或小型)组成的。 产业组织研究企业有关价格和数量的决策如何取决于它们所面临的市场条件。 企业成本是其生产和定价决策的一个关键决定因素。 \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:13:0","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"生么是成本 总收益、总成本和利润 总收益(total revenue) 企业出售其产品所得到的货币量 总成本(total cost) 企业用于生产的投入品和市场价值 利润(profit) 总收益减去总成本 \r作为机会成本的成本 显性成本(explicit costs) 需要企业支出货币的投入成本 隐性成本(implicit costs) 不需要企业支出货币的投入成本 \r作为一种机会成本的资本成本 \r经济利润与会计利润 经济利润(economic profit) 总收益减去总成本，包括显性成本与隐性成本 会计利润(accounting profit) 总收益减总显性成本 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:13:1","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"生产与成本 \r生产函数 生产函数(production function) 用于生产一种物品的投入量与该物品产量之间的关系 边际产量(marginal product) 增加一单位投入所引起的产量增加 边际产量递减(diminishing marginal product) 一种投入的边际产量随着投入量增加而减少的特征 \r从生产函数到总成本曲线 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:13:2","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"成本的各种衡量指标 \r固定成本与可变成本 固定成本(fixed costs) 不随着产量变动而变动的成本 可变成本(variable costs) 随着产量变动而变动的成本 \r平均成本与边际成本 平均总成本(average total cost) 总成本除以产量 平均固定成本(average fixed cost) 固定成本除以产量 平均可变成本(average variable cost) 可变成本除以产量 边际成本(marginal cost) 额外一单位产量所引起的总成本的增加 \r成本曲线及其形状 有效规模(efficient scale) 使平均总成本最小的产量 只要边际成本小于平均总成本，平均总成本就下降；反之，则上升。 边际成本曲线与平均总成本曲线在平均总成本曲线的最低点处相交。 \r典型的成本曲线 三个特征： 随着产量增加边际成本最终会上升 平均总成本曲线是U形的 边际成本曲线与平均总成本曲线在平均总成本曲线的最低点处相交 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:13:3","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"短期成本与长期成本 \r短期与长期平均总成本之间的关系 \r规模经济与规模不经济 规模经济(economics of scale) 长期平均总成本随产量增加而减少的特性 规模不经济(diseconomics of scale) 长期平均总成本随产量增加而增加的特性 规模收益不变(constant returns to scale) 长期平均总成本在产量变动时保持不变的特性 \r实际上，运用专业化实现规模经济是现代社会之所以这样繁荣的原因之一。 \r\r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:13:4","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"竞争市场上的企业 如果每个买者和卖者与市场规模相比都微不足道，从而没有什么能力影响市场价格那么该市场就是竞争性的。于此相反，如果一个企业可以影响它出售的物品的市场价格，我们就说该企业有市场势力。 \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:14:0","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"什么是竞争市场 \r竞争市场的含义 竞争市场(competitive market)有时又称为完全竞争市场。有几个特征： 市场上有许多买者和许多卖者 各个卖者提供的物品大体上是相同的 企业可以自由地进入或退出市场 \r竞争企业的收益 平均收益(average revenue) 总收益除以销售量 对所有企业而言，平均收益等于物品的价格 边际收益(marginal revenue) 增加一单位销售量引起的总收益变动 对竞争企业而言，边际收益等于物品的价格 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:14:1","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"利润最大化与竞争企业的供给曲线 \r利润最大化 \r边际成本曲线和企业的供给决策 利润最大化的一般规律： 如果边际收益大于边际成本，企业应该增加其产量 如果边际成本大于边际效益，企业应该减少其产量 在利润最大化的产量水平时，边际收益和边际成本正好相等 \r企业的短期停止营业决策 如果生产能得到的收益小于生产的可变成本，企业就停止营业。 \r覆水难收和其他沉没成本 沉没成本(sunk cost) 已经发生而且无法收回的成本 在做个人决策时，沉没成本的无关性也是很重要的。 \r企业退出或进入一个市场的长期决策 如果从生产中得到的收益小于它的总成本，企业就应该退出市场。 竞争企业的长期供给曲线是边际成本曲线位于平均总成本曲线之上的那一部分。 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:14:2","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"竞争市场的供给曲线 两种情况： 考察有固定数量企业的市场； 考察企业数量会随着老企业退出和新企业进入而变动的市场 \r\r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:14:3","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"垄断 可以说微软在Windows软件市场上拥有垄断地位。 像微软这样的垄断者没有与之相近的竞争者，因此，它拥有影响其产品的市场价格的力量。竞争企业是价格接受者，而垄断企业是价格决定者。 竞争企业接受市场给定的其产品的价格，并选择供给量，以使价格等于边际成本。与此相比，垄断者收取高于其边际成本的价格。 垄断者对其产品收取高价格并不令人奇怪。垄断者的顾客似乎除了一个支付垄断者收取的价格之外别无选择。 一个垄断企业可以控制它出售的物品的价格，但由于高价格会减少其顾客的购买量，因此垄断利润并不是无限的。 由于垄断企业不受竞争限制，有垄断的市场结果往往不符合社会的最佳利益。 但政府有时可以改善市场结果。 \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:15:0","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"为什么会产生垄断 垄断企业(monopoly) 作为一种没有相近替代品的产品的唯一卖者的企业。 有三个主要形成原因： 垄断资源： 生产所需要的关键资源由单个企业所拥有 政府管制： 政府给予单个企业排他性地生产某种物品或服务的权利 生产流程： 某个企业能以低于大量企业的成本生产产品 专利法或版权法是两个重要的例子。 自然垄断(natural monopoly) 由于一个企业能以低于两个或更多企业的成本向整个市场供给一种物品或服务而产生的垄断 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:15:1","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"垄断者如何做出生产与定价策略 \r垄断与竞争 垄断者的收益 利润最大化 垄断者的利润 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:15:2","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"垄断的福利代价 \r无谓损失 可以在需求曲线与边际成本曲线相交之处找出社会有效率的产量。 垄断者生产的产量小于社会有效率的产量。 垄断利润：是一种社会代价吗 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:15:3","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"价格歧视 价格歧视(price discrimination) 以不同的价格向不同顾客出售同一种物品的经营做法。 套利 在一个市场上以低价购买一种商品，而在另一个市场上以高价出售，以便从价格差中获利的过程。 价格歧视的例子 电影票 飞机票 折扣券 财务援助 数量折扣 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:15:4","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"针对垄断的公共政策 政府决策者应对垄断： 努力使垄断行业更有竞争性 用反托拉斯法增强竞争。反托拉斯法是一部全面的经济自由宪章，其目的在于维护作为贸易的自由和不受干预的竞争。 管制 管制垄断者的行为 公有制 政府自己经营自然垄断的企业 不作为 do nothing \r\r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:15:5","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"垄断竞争 \r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:16:0","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"在垄断和完全竞争之间 很多行业介于完全竞争和垄断的极端情况之间的某个位置，经济学家称这种情况为不完全竞争。 寡头(oligopoly) 只有少数几个提供相似或者相同产品的卖者的市场结构。 垄断竞争(monopolistic competition) 存在许多出售相似但不相同的产品的企业的市场结构。 垄断竞争和寡头一样，也是介于竞争和垄断这两种极端情况之间的一种市场结构。 垄断竞争具有以下特征的市场： 许多卖者： 有许多企业争夺相同的顾客群体 产品存在差别： 每个企业生产的一种产品至少与其他企业生产的这种产品略有不同 自由进入和退出：企业可以无限制地进入或退出一个市场 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:16:1","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"差别产品的竞争 \r短期中的垄断竞争企业 长期均衡 垄断竞争与完全竞争 垄断竞争与社会福利 \r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:16:2","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"广告 在现代经济中，几乎每一天都伴随着铺天盖地的广告。 这种行为是垄断竞争(以及某些寡头企业)的一个自然特征。 \r关于广告的争论 作为质量信号的广告 品牌 \r垄断竞争，顾名思义，是垄断和竞争的混合。 由于垄断竞争企业生产有差别的产品，因此，每个企业都要靠做广告打出自己的品牌来吸引顾客。在某种程度上，广告操纵了消费者的偏好，促成了非理性的品牌忠诚，并抑制了竞争。在更大程度上，广告提供了信息，建立了具有可靠质量的品牌，并促进了竞争。 \r\r\r","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:16:3","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["economics"],"content":"寡头","date":"2018-02-23","objectID":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/:17:0","tags":["Economics","经济学"],"title":"经济学原理","uri":"/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"categories":["linux"],"content":"参考： 《鸟哥的Linux私房菜》 正则表达式维基百科 \r正则表达式介绍 正则表达式，又称正规表示式、正规表示法、正规表达式、规则表达式、常规表示法(Regular Expression, 在代码中常简写为regex、regexp或RE）。 是计算机科学的一个概念。正则表达式使用单个字符串来描述、匹配一系列匹配某个句法规则的字符串。在很多文本编辑器里，正则表达式通常被用来检索、替换那些匹配某个模式的文本。 \r正则表达式的POSIX规范，分为两大流派： 基本型正则表达式（Basic Regular Expression，BRE） grep、vi、sed都属于BRE，是历史最早的正则表达式，因此元字符必须转译之后才具有特殊含义 扩展型正则表达式（Extended Regular Express，ERE） egrep、awk则属于ERE，元字符不用转译 \r正则表达式基本语法 一个正则表达式通常被称为一个模式（pattern），用来描述或者匹配一系列匹配某个句法规则的字符串。 大部分正则表达式有如下结构： 选择 |竖线符代表选择(或)，具有最低优先级 数量限定 字符后的数量限定符用来限定前面这个字符允许出现的个数 不加数量限定则代表仅出现一次 常见的数量限定符包括 +、?、* +加号代表前面的字符必须至少出现一次 ( $$$\u003e=1$$$ ) ?问号代表前面的字符最多只可出现一次 ( $$$1\u003e=?\u003e=0$$$ ) *星号代表前面的字符可不出现，也可出现一次或多次 ($$$\u003e=0$$$) 匹配 ()圆括号可以定义操作符的范围和优先度 \r\r PCRE表达式全集 正则表达式有多种不同的风格。 PCRE（Perl兼容正则表达式，Perl Compatible Regular Expression）。适用于Perl或者Python编程语言（grep或者egrep的正则表达式文法是PCRE的子集） \r基础正则表达式 字符 | 描述 | - \\ | 转义字符 zhang | 匹配文本字符串值zhang . | 匹配除\\r,\\n之外的任何单个字符 竖线l | 匹配竖线两边某一个 ^ | 匹配输入字符串的开始位置 $ | 匹配输入字符串的结束位置 | 匹配前面的子表达式零次或多次 | 匹配前面的子表达式一次或多次 ? | 匹配前面的子表达式零次或一次 {n} | n是一个非负整数。匹配n次 {n,} | n是一个非负整数。至少匹配n次 {n,m} | m和n均为非负整数，匹配n-m次 [xyz] | 字符集合（character class）。匹配所包含的任意一个字符 [^xyz] | 排除型字符集合（negated character classes）。匹配未列出的任意字符 [a-z] | 字符范围。匹配指定范围内的任意字符 [^a-z] | 排除型的字符范围。匹配任何不在指定范围内的任意字符 [:name:] | 增加命名字符类（named character class） [=elt=] | 增加当前locale下排序（collate）等价于字符“elt”的元素 [.elt.] | 增加排序元素（collation element）elt到表达式中。这是因为某些排序元素由多个字符组成 元字符 元字符(meta character)，是一种Perl风格的正则表达式，只有一部分文本处理工具支持它。 字符 | 描述 | - \\b | 匹配一个单词边界，也就是指单词和空格间的位置 \\B | 匹配非单词边界。“er\\B”能匹配“verb”中的“er”，但不能匹配“never”中的“er” \\cx | 匹配由x指明的控制字符 \\d | 匹配一个数字字符。等价于[0-9]。注意Unicode正则表达式会匹配全角数字字符 \\D | 匹配一个非数字字符。等价于[^0-9] \\f | 匹配一个换页符。等价于\\x0c和\\cL \\n | 匹配一个换行符。等价于\\x0a和\\cJ \\r | 匹配一个回车符。等价于\\x0d和\\cM \\s | 匹配任何空白字符，包括空格、制表符、换页符等等 \\S | 匹配任何非空白字符。等价于[^ \\f\\n\\r\\t\\v] \\t | 匹配一个制表符。等价于\\x09和\\cI \\v | 匹配一个垂直制表符。等价于\\x0b和\\cK \\w | 匹配包括下划线的任何单词字符。等价于“[A-Za-z0-9_]”。注意Unicode正则表达式会匹配中文字符 \\W | 匹配任何非单词字符。等价于“[^A-Za-z0-9_]” \\ck | 匹配控制转义字符。k代表一个字符。等价于“Ctrl-k”。用于ECMA语法 \\xnn | 十六进制转义字符序列。匹配两个十六进制数字nn表示的字符 \\num | 向后引用（back-reference）一个子字符串（substring），该子字符串与正则表达式的第num个用括号围起来的捕捉群（capture group）子表达式（subexpression）匹配。其中num是从1开始的十进制正整数，其上限可能是9[注 2]、31、[注 3]99甚至无限。[注 4]例如：“(.)\\1”匹配两个连续的相同字符 \\n | 标识一个八进制转义值或一个向后引用。如果\\n之前至少n个获取的子表达式，则n为向后引用。否则，如果n为八进制数字（0-7），则n为一个八进制转义值 \\nm | 3位八进制数字，标识一个八进制转义值或一个向后引用。如果\\nm之前至少有nm个获得子表达式，则nm为向后引用。如果\\nm之前至少有n个获取，则n为一个后跟文字m的向后引用。如果前面的条件都不满足，若n和m均为八进制数字（0-7），则\\nm将匹配八进制转义值nm \\nml | 如果n为八进制数字（0-3），且m和l均为八进制数字（0-7），则匹配八进制转义值nml \\un | Unicode转义字符序列。其中n是一个用四个十六进制数字表示的Unicode字符 \r扩展正则表达式 字符 | 描述 | - ? | 非贪心量化（Non-greedy quantifiers）：当该字符紧跟在任何一个其他重复修饰符（*,+,?，{n}，{n,}，{n,m}）后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串 (pattern) | 匹配pattern并获取这一匹配的子字符串。该子字符串用于向后引用。所获取的匹配可以从产生的Matches集合得到，在VBScript中使用SubMatches集合，在JScript中则使用$0…$9属性。要匹配圆括号字符，请使用“(”或“)” (?:pattern) | 匹配pattern但不获取匹配的子字符串（shy groups)，也就是说这是一个非获取匹配，不存储匹配的子字符串用于向后引用 (?=pattern) | 正向肯定预查（look ahead positive assert），在任何匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用 (?!pattern) | 正向否定预查(negative assert)，在任何不匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用 (?\u003c=pattern) | 反向(look behind)肯定预查，与正向肯定预查类似，只是方向相反 (?\u003c!pattern) | 反向否定预查，与正向否定预查类似，只是方向相反 \r\r POSIX字符组 POSIX字符类(POSIX character class),是一个形如[:…:]的特殊元序列，它用于匹配特定的字符范围。 POSIX字符组 | 说明 | ASCII环境 | Unicode环境 | - [:alnum:] | 字母字符和数字字符 | [a-zA-Z0-9] | [\\p{L\u0026}\\p{Nd}] [:alpha:] | 字母 | [a-zA-Z] | \\p{L\u0026} [:ascii:] | ASCII字符 | [\\x00-\\x7F] | \\p{InBasicLatin} [:blank:] | 空格字符和制表符 | [ \\t] | [\\p{Zs}\\t] [:cntrl:] | 控制字符 | [\\x00-\\x1F\\x7F] | \\p{Cc} [:digit:] | 数字字符 | [0-9] | \\p{Nd} [:graph:] | 空白字符之外的字符 | [\\x21-\\x7E] | [^\\p{Z}\\p{C}] [:lower:] | 小写字母字符 | [a-z] | \\p{Ll} [:print:] | 类似[:graph:]，但包括空白字符 | [\\x20-\\x7E] | \\P{C} [:punct:] | 标点符号 | }~-] | [\\p{P}\\p{S}] [:space:] | 空白字符 | [ \\t\\r\\n\\v\\f] | [\\p{Z}\\t\\r\\n\\v\\f] [:upper:] | 大写字母字符 | [A-Z] | \\p{Lu} [:word:] | 字母字符 | [A-Za-z0-9_] | [\\p{L}\\p{N}\\p{Pc}] [:xdigit:] | 十六进制字符 | [A-Fa-f0-9] | [A-Fa-f0-9] \r优先级 优先权 | 符号 | - 最高 | 高 | ( )、(?: )、(?= )、 中 | *、+、?、{n}、{n,}、{m,n} 低 | ^、$、中介字符 次最低 | 串接，即相邻字符连接在一起 最低 | l ","date":"2018-02-08","objectID":"/regularexpression/:0:0","tags":["RegularExpression","正则表达式"],"title":"正则表达式","uri":"/regularexpression/"},{"categories":["database"],"content":"参考: 《Redis官方文档》: http://www.redis.cn/documentation.html 《Redis命令大全》: http://www.redis.cn/commands.html 环境: CentOS7x86_64 Redis 3.2 \r 简介 ","date":"2018-02-05","objectID":"/redis/:0:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"Redis是什么 Redis是一个使用ANSI C编写的开源、支持网络、基于内存、可选持久性的、非关系型,键值对存储数据库。 Redis是一个开源(BSD许可)的,内存中的数据结构存储系统,它可以用作数据库、缓存和消息中间件。 毫无疑问,Redis开创了一种新的数据存储思路,使用Redis,我们不用在面对功能单调的数据库时,把精力放在如何把大象放进冰箱这样的问题上,而是利用Redis灵活多变的数据结构和数据操作,为不同的大象构建不同的冰箱。希望你喜欢这个比喻。 Remote Dictionary Server(Redis)是由一个Salvatore Sanfilippo写的key-value储存系统。Redis提供了一些丰富的数据结构,包括lists,sets,ordered sets,hashes,当然还有和Memcached一样的string结构,所以常被称为是一款数据结构服务器(data structure server)。Redis当然还包括了对这些数据结构的丰富操作。 你可以在这些类型上面运行原子操作,例如,追加字符串,增加哈希中的值,加入一个元素到列表,计算集合的交集、并集和差集,或者是从有序集合中获取最高排名的元素。 \r","date":"2018-02-05","objectID":"/redis/:1:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"Redis的优点 为了满足性能,Redis采用内存(in-memory)数据集(dataset)。根据你的使用场景,你可以通过每隔一段时间转储数据集到磁盘,或者追加每条命令到日志来持久化。持久化也可以被禁用,如果你只是需要一个功能丰富,网络化的内存缓存。 性能极高,Redis能支持超过100K+每秒的读写频率 丰富的数据类型,Redis支持二进制案例的Strings,Lists,Hashes,Sets及Ordered Sets数据类型操作 原子,Redis的所有操作都是原子性的,同时Redis还支持对几个操作全并后的原子性执行 丰富的特性,Redis还支持publish/sucscribe,通知,key过期等特性 Redis还支持主从异步复制,非常快的非阻塞初次同步、网络断开时自动重连局部重同步 \r安装 直接通过yum安装: yum install -y redis 启动redis-server的两种方式: redis-server: standalone模式 systemctl redis start: daemon模式 需要在配置文件中开启daemonize 启动redis-cli: redis-cli redis-cli -a passwd 配置 redis配置文件(/etc/redis.conf)常用参数: 参数 | 说明 | - daemonize | 以守护进程启动,放置于后台 bind | 监听地址,建议只对本地127.0.0.1开放 protect-mode | redis的保护模式 requirepass | 设置密码 timeout | 超时 tcp-keepalive | 在Linux上,指定值(秒)用于发送ACKs的时间,关闭连接需要双倍的时间,默认为0 loglevle | 指定日志记录的级别。有四个级别:debug(记录很多信息,用于开发测试)、notice(常用于生产环境)、warning(严重的信息)、verbose(有用的信息) logfile | 日志文件,默认为stdout databases | 可用数据库,范围在0-(database-1) save | 保存数据到磁盘(.rdb) stop-writes-on-bgsave-error | 后台储存错误停止写 rdbcompression | 储存到本地数据库时(持久化到rdb文件)是否压缩 dbfilename | 本地持久化数据库文件名,默认dump.rdb dir | 数据库文件路径,是目录 salveof | 设置从库 masterauth | 设置主库认证的密码 slave-read-only | 设置slave是否只读 slave-serve-stale-data | 从库同主库失去连接或复制正在进行时,从库是否继续响应客户端请求 repl-disable-tcp-nodelay | tcp-nodelay slave-priority | slave优先级,master不能工作后,从众多slave中选出优先值最小的slave提升为master,优先值为0表示不能为master appendonly | 是否开启AOF数据备份,redis会把所接收到的每一次写操作请求都追加到appendonly.aof文件,当此文件很大 appendsync | AOF文件同步策略,后台会进行大量I/O no-appendfsync-on-rewrite | - auto-aof-rewrite-percentage | aof自动重写 auto-aof-rewrite-min-size | 指定最小大小用于aof重写 slowlog-log-slower-than | 慢日志,记录超过特定执行时间的命令,不包括I/o slowlog-max-len | 慢日志记录的长度,超过大小,最先进入队列的记录会被踢出 hash-max-zipmap-entries | hash将以一种特殊的编码方式(大大减少内存使用)来储存,这是其中一个临界值 hash-max-zipmap-value | 另一个临界值 list-max-ziplist-entries | 多个list以特定的方式编码来节省空间 activerehashing | Redis将在每100ms时使用1ms的CPU时间来对redis的hash表进行重新hash,可降低内存的使用 hz | 不是所有任务都以相同的频率执行,但redis按照指定的“hz”值执行检查任务 aof-rewrite-incremental-fsync | 当一个子节点重写AOF文件时,则文件每生产32m数据进行同步 官方文档对VM的使用建议: 当KEY很小而VALUE很大时,使用VM的效果会比较好,因为这样节约内存比较大 当key不小时,可以考虑使用一些非常方法将很大的key变成value,比如将key,value组合成一个新的value \r数据类型 Redis不仅仅是简单的key-value存储器,同时也是一种data structure server。传统的key-value是指支持使用一个key字符串来索引value字符串的储存。而Redis中,value不仅仅支持字符串,还支持更多的复杂结构,包括列表、集合、哈希表等。Redis采用二进制安全,这就意味着你可以使用任何二进制序列作为重点。 ","date":"2018-02-05","objectID":"/redis/:2:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"字符串(strings) 字符串 是一种最基本的Redis值类型。Redis字符串是二进制安全的,这意味着一个Redis字符串能包含任意类型的数据。 只关心二进制化的字符串,不关心具体格式。只会严格的按照二进制的数据存取。不会妄图已某种特殊格式解析数据。 ","date":"2018-02-05","objectID":"/redis/:3:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"列表(lists) Redis列表是简单的字符串列表,按照插入顺序序列,你可以添加一个或多个元素到列表的头部或者尾部。 ","date":"2018-02-05","objectID":"/redis/:4:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"散列(hash) Redis Hashes是字符串字段和字符串值之间的映射,因此他们是展现对象的完美数据类型。如一个有姓、名、年龄等属性的用户。一个带有一些字段的hash仅仅需要一块很小的空间储存,因此你可以储存数以百万计的对象在一个小的Redis实例中。 哈希主要用来表现对象,他们有能力储存很多对象,因此你可以将哈希用于许多其他的任务。 ","date":"2018-02-05","objectID":"/redis/:5:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"无序集合(unorder set) Redis集合(Set)是一个无序的字符串集合。可以用O(1)的时间复杂度(无论集合中有多少元素时间复杂度都是常量)完成添加、删除、测试元素是否存在。 Redis集合拥有令人满意的不允许包含相同成员的属性。多次添加相同的元素,最终在集合里只会有一个元素。实际上就是添加元素时无序检测元素是否存在。 一个Redis集合有趣的事情是它支持一些服务端的命令从现有的集合出发去进行集合运算,因此你可以在非常短的时间内进行合并(unions)、交集(intersections)、找出不同的元素(difference of sets)。 ","date":"2018-02-05","objectID":"/redis/:6:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"有序集合(order set) Redis有序集合与普通集合非常相似,也是一个没有重复项的字符串集合。不同之处是有序集合的每一个成员都关联了一个评分,这个评分被用来按照从最低分到最高分的方式排序集合中的成员。集合的成员是唯一的,但是评分可以是重复了。 使用有序集合可以以非常快的速度(O(log(N)))添加,删除和更新元素。可以很快根据评分(score)或者次序(position)来获取一个范围的元素。访问有序集合的中间元素也是很快的,因此能够使用有序集合作为一个没有重复成员的智能列表。在有序集合中,你可以很快捷的访问一切你需要的东西。 简而言之,使用有序的集合你可以做完许多对性能有极端要求的任务,而那些任务使用其他类型的数据库真的是很难完成。 \r命令 ","date":"2018-02-05","objectID":"/redis/:7:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"常用命令 exists key #判断一个key是否存在 del key #删除某个或一系列key type key #返回某个key元素的数据类型,key不存在返回空 keys key-pattern #返回匹配的key列表 randomkey #随机获取一个已经存在的key rename oldname newname #改key的名字,如果存在将会覆盖 dbsize #返回当前数据库的key的总和 expire key time #设置某个key的过期时间(秒),到期后自动删除 ttl #查询key剩余存活时间 flushdb #清空当前数据库中的所有键 flushall #清空所有数据库中的键 ","date":"2018-02-05","objectID":"/redis/:8:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"设置相关 config get #用来读取Redis服务器的配置参数 config set #用于更改运行Redis服务器的配置参数 config resetstat #重置数据统计报告,通常返回OK ","date":"2018-02-05","objectID":"/redis/:9:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"连接操作 quit #关闭连接 auth #密码认证 help command #帮助 ","date":"2018-02-05","objectID":"/redis/:10:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"持久化 save #将数据同步保存到磁盘 bgsave #将数据异步保存到磁盘 lastsave #返回上次成功将数据保存到磁盘的Unix时戳 \r","date":"2018-02-05","objectID":"/redis/:11:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"远程服务 info #服务器信息统计,基本所有信息 monitor #实时转储收到的请求 slaveof #改变复制策略 shutdown #将数据同步保存到磁盘,然后关闭服务 server #Redis server的常规信息 clients #Client的连接选项 memory #存储占用相关信息 persistence #RDB and AOF 相关信息 stats #常规统计 replication #Master/slave请求信息 cpu #CPU占用信息统计 cluster #Redis 集群信息 keyspace #数据库信息统计 all #返回所有信息 default #返回常规设置信息 \r","date":"2018-02-05","objectID":"/redis/:12:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"值(value)操作 exists key #判断一个key是否存在 del key #删除一个key type key #返回值的类型 keys pattern #返回满足给定模式的所有key randomkey #随机返回key空间的一个 rename oldname newname #改key的名字,如果存在将会覆盖 dbsize #返回当前数据库中key的数目 expire #设定一个key的活动时间(s) ttl #获得一个key的活动时间 select index #按索引查询 move key dbindex #移动当前数据库中的key到dbindex数据库 flushdb #删除当前选择的数据库中的所有key flushall #删除所有数据库中的所有key \r","date":"2018-02-05","objectID":"/redis/:13:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"字符串(string)操作 set key value #给数据库中名称为key的string赋值value get key #返回数据库中名为key的string的value getset key value #给名称为key的string赋予上一次的value mget key1 key2 ... key N #返回库中多个string的value setnx key value #添加string 名称为key 值为value setex key time value #向库中添加string 设定过期时间time mset key 1 value 1 ... key N value N #批量设置多个string的值 msetnx key 1 value 1 ... key N value N #如果所有名称为 key N的string都不存在 则向库中添加string 名称为 key N赋值value N incr key #名称为key的string加 1 操作 incrby key integer #名称为key的string增减integer decr key #名称为key的string减1操作 decrby key integer #名称为key的string的值附加value append key value #名称为key的值附加value substr key start end #返回名称为key的string的value的子串 \r","date":"2018-02-05","objectID":"/redis/:14:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"列表(list)操作 rpush key value #在名称为key的list尾部添加一个值为value的元素 lpush key value #在名称为key的list首部添加一个值为value的元素 llen key #返回名称为key的list的长度 lrange key start end #返回名称为key的list中start至end之间的元素 下表从0开始 ltrim key start end #截取名称为key的list 保留start至end之间的元素 lindex key index #返回名称为key的list中index位置的元素 lset key index value #给名称为key的list中index位置的元素赋值value lrem key count value #删除count个名称为key的list中值为value的元素 brpop key1 key2 ... keyN #rpop的block版本 rpoplpush srckey dstkey #返回并删除名为srckey的list尾元素 并将该元素添加到名为dstkey的list的头部 \r","date":"2018-02-05","objectID":"/redis/:15:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"集合(set)操作 sadd key member #向名为key的set中添加元素member srem key member #删除名为key的set中元素的member spop key #随机返回并删除名为key的set中的一个元素 smove srckey dstkey member #将member元素从名为srckey的集合移动到名为dstkey的集合 scard key #返回名为key的set的基数 sismember key member #测试member是否是名称为key的set的集合 sinter key1 key2 ... key N #求交集 sinterstore dstkey key1 ... key N #求交集并将交集保存到dstkey的集合 sunion key1 ... key N #求并集 sunionstore dstkey key 1 ... key N #求并集并将并集保存到dstkey的集合 sdiff key1 ... key N #求差集 sdiffstore dstkey key 1 ... key N #求差集并将差集保存到dstkey的集合 smembers key #返回名为key的set的所有元素 srandmember key #随机返回名为key的set的一个元素 \r","date":"2018-02-05","objectID":"/redis/:16:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"有序集合(sorted set)操作 zadd key score member #向名为key的zset中添加元素member score用于排序 如果该元素已经存在 则根据 score更新该元素的顺序 zrem key member #删除名为key的zset中的元素member zincrby key increment member #如果在名为key的zset中已经存在元素member 则该元素的score增加increment 否则向集合中添加该元素 其score的值为increment zrank key member #返回名为key的zset 顺序 zrevrank key member #返回名为key的zset 倒序 zrange key start end #返回名为key的zset score顺序按index从start到end返回所有元素 zrevrange key start end #返回名为key的zset score倒序按index从start到end返回所有元素 zrangebyscore key min max #返回名为key的zset中score大于等于min 小于等于max的所有元 \r","date":"2018-02-05","objectID":"/redis/:17:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"hash操作 hset key field value #向名为key的hash中添加元素filed----value hget key field #返回名为key的hash中field对应的value hmset key field1 value1 ... field N value N #向名为key的hash中添加元素field----value hmget key field1 ... field N #返回名为key的hash中filed对应的value hincrby key field integer #将名为key的hash中field的value增加integer hexists key field #名为key的hash中是否存在键为field的域 hdel key field #删除名为key的hash中键为field的域 hlen key #返回名为key的hash中元素个数 hkeys key #返回名为key的hash中所有键 hvals key #返回名为key的hash中所有键对应的value hgetall key #返回名为key的hash中所有的键 field 及其对应的value \r高级应用 Redis高级应用包括安全性设置、主从复制、事务处理、持久化机制和虚拟内存的使用。 \r","date":"2018-02-05","objectID":"/redis/:18:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"安全性 由于redis速度相当快，一秒钟可以150K次密码尝试，所以需要设置一个密码强度很强大的密码。 设置密码的两种方法： config set requirepass \"passwd\"，通过命令设置密码 直接在配置文件中requirepass属性后加上密码 认证登录的两种方式： redis-cli -a passwd redi-cli –\u003e auth passwd ","date":"2018-02-05","objectID":"/redis/:19:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"主从复制 Redis的主从复制的配置和使用都比较简单。 master server slave server Redis主从复制特点： 一主多从 当master宕机后，优先级值小的那台slave server自动转变为master 主从复制不同阻塞master，在同步数据时master可以继续处理client的请求 提高了系统的可伸缩性 Redis主从复制过程： slave与master建立连接，发送sync同步命令 master会启动一个后台进程，将数据库快照保存到文件中，同时master主进程会开始收集新的写命令并缓存 后台完成保存后，就将此文件发送给slave slave将文件保存在磁盘上 ","date":"2018-02-05","objectID":"/redis/:20:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"主从复制栗子 Redis主从配置，一主多从。 注意：由于redis吃内存，可能会由于内存过小而无法正常启动redis，可查看/var/log/message。 配置master： vim /etc/redis_master.conf daemon yes bind 127.0.0.1 ip1 port 6379 requirepass fuza_mima protect-mode yes datebases 100 logfile /var/log/redis/redis_master.log dir /var/lib/redis_master mkdir /var/lib/redis_master chown redis:redis /var/lib/redis_master systemctl start redis 配置slave： vim /etc/redis_slave.conf daemon yes bind 127.0.0.1 port 6379 protect-mode yes logfile /var/log/redis/redis_slave.log dir /var/lib/redis_slave slaveof \u003cmaster-ip\u003e \u003cmaster-port\u003e masterauth \u003cmaster-passwd\u003e slave-read-only yes slave-priority 100 #master挂掉后，从slave中选出优先级最小的作为master ······ #其他具体主从参数自己配置 mkdir /var/lib/redis_slave chown redis:redis /var/lib/redis_slave systemctl start redis \r测试master： redis-cli -a xxx set name zhang get zhang 测试slave： redis-cli auth('passwd') key * get zhang \r注意： 由于Redis只是主从，并不像MongoDB的集群功能。当Redis master挂掉以后，虽然优先级较小的slave成为了master，但从库是无法更新数据的。这点也可以从Redis从的配置文件中看出，连接到Redis主的IP：PORT，并通过主的密码来认证。 \r","date":"2018-02-05","objectID":"/redis/:20:1","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"高可用 Redis的主从模式，并不支持高可用。 不过，Redis引进了哨兵模式(sentinel)，提供Redis实时监控和故障检测恢复的功能。 Redis Sentinel 是 Redis 的官方高可用解决方案，是设计用来帮助管理 Redis 实例的系统。 运行 Sentinel 强制使用配置文件，这个文件被系统用来保存当前状态，在重启时能重新加载。如果没有指定配置文件，或者配置文件的路径不可写，Sentinel 将拒绝启动。 Sentinel 运行时默认监听 TCP 端口 26379，所以为了让 Sentinel 正常运行，你的服务器必须开放 26379 端口，以接受从其他 Sentinel 实例 IP 地址的连接。否则，Sentinel 间就没法通信，没法协调，也不会执行故障转移。 Redis Sentinel 是一个分布式系统，这意味着，你通常想要在你的基础设施中运行多个 Sentinel 进程，这些进程使用 gossip 协议来判断一台主服务器是否下线(down)，使用 agreement 协议来获得授权以执行故障转移，并更新相关配置。 The redis-sentinel command is a symbolic link to the redis-server command which imply the --sentionel option. redis-server [ configuration_file ] [ options ] --sentinel redis-sentinel [ configuration_file ] [ options ] Redis Sentinel用于完成如下4个任务： 监控(Monitoring) Sentinel 不断检查你的主从实例是否运转正常。 通知(Notification) Sentinel 可以通过 API 来通知系统管理员，或者其他计算机程序，被监控的Redis实例出了问题。 自动故障转移(Automatic failover) 如果一台主服务器运行不正常，Sentinel 会开始一个故障转移过程，将从服务器提升为主服务器，配置其他的从服务器使用新的主服务器，使用 Redis 服务器的应用程序在连接时会收到新的服务器地址通知。 配置提供者(Configuration provider) Sentinel 充当客户端服务发现的权威来源：客户端连接到 Sentinel 来询问某个服务的当前 Redis 主服务器的地址。当故障转移发生时，Sentinel 会报告新地址。 ","date":"2018-02-05","objectID":"/redis/:21:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"配置文件 Redis Sentinel示例配置文件： 只需要指定需要监控的主服务器，并给主服务器去一个名字； 没有必要指定从服务器，因为它们会被自动发现； 每一次故障转移时，将一台从服务器提升为主服务器都会重写配置文件； 无论你指定多少个同意来检测实例是否正常工作，Sentinel 需要系统中已知的大多数 Sentinel 的投票才能开始故障转移，并且在故障转移之后获取一个新的配置纪元(configuration Epoch) 赋予新的配置； #默认26379端口 #sentinel \u003coption_name\u003e \u003cmaster_name\u003e \u003coption_value\u003e #仲裁数为2 sentinel monitor mymaster 127.0.0.1 6379 2 #哨兵认为实例不可达的毫秒数 sentinel down-after-milliseconds mymaster 60000 # sentinel failover-timeout mymaster 180000 #在一次故障转移之后，被配置为同时使用新主服务器的从服务器数量 sentinel parallel-syncs mymaster 1 # master 有密码就要使用, #sentinel auth-pass mymaster **** sentinel monitor resque 192.168.1.3 6380 4 sentinel down-after-milliseconds resque 10000 sentinel failover-timeout resque 180000 sentinel parallel-syncs resque 5 \r","date":"2018-02-05","objectID":"/redis/:21:1","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"事务处理 Redis的事务处理比较简单。只能保证client发起的事务中的命令可以连续的执行，而且不会插入其他的client命令。 当一个client在连接中发出multi命令时，这个连接就进入一个事务的上下文，该连接后续的命令不会执行，而是存放在一个队列中，当执行exec命令时，redis会顺序的执行队列中的所有命令。如果其中执行出现错误，执行正确的不会回滚，不同于关系型数据库的事务。 ","date":"2018-02-05","objectID":"/redis/:22:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"持久化机制 持久化就是把数据从内存保存到硬盘。 Redis是一个支持持久化的内存数据库，Redis需要经常将内存中的数据同步到磁盘来保证持久化。 Redis支持两种持久化方式： snapshotting(快照) 将数据存放到文件里，默认方式。默认写入dump.rdb二进制文件中 可配置redis在n秒内超过m个key被修改就自动做快照 save 500 10 –\u003e 500s内超过10个key被修改，则保存快照 由于快照方式在一定间隔时间做一次保存， 如果Redis意外down掉的话，就会丢失最后一次快照后的所有修改。 AOF比快照方式有更好的持久化性，是由于使用aof时，redis会将每一个收到的写命令都通过write函数写入到文件中当redis启动时会通过重新执行文件中保存的写命令在内存中重新建立整个数据库的内容。 appendonly file(AOF) aof方式redis会将每一次的函数都追加到文件中，当redis重启时会重新执行文件中保存的命令 配置文件参数： #启用aof持久化方式 appendonly yes #每秒写入磁盘一次，在性能和持久化方面做了很好的折中 appendonly everysc #将数据写入磁盘 save 900 1 save 300 10 save 60 10000 \r","date":"2018-02-05","objectID":"/redis/:23:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"虚拟内存 Redis的虚拟内存是暂时把不经常访问的数据从内存交换到磁盘中，从而腾出内存空间用于其它的访问数据。 对于redis这样的内存数据库，内存总是不够用的。 在配置文件(/etc/redis.conf)中配置VM: #开启vm功能 vm-enableyes #交换出来的value保存的文件路径 vm-swap-file /tmp/redis.swap #redis使用的最大内存上线 vm-max-memory 10000000 #每个页面的大小32字节 vm-page-size 32 #最多使用多少个页面 vm-pages 123217729 #用于执行value对象换入的工作线程数量 vm-max-threads 4 \r\r","date":"2018-02-05","objectID":"/redis/:24:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"批量删除 #删除库中所有Key SELECT 0 FLUSHDB #删除所有库中Key FLUSHALL #默认为db0 #批量删除keys redis-cli KEYS \"test\" | xargs redis-cli DEL #通配符 redis-cli KEYS \"test*\" | xargs redis-cli DEL #指定数据库 redis-cli -n 1 KEYS \"test*\" | xargs redis-cli -n 1 DEL #指定主机，密码 redis-cli -h xxx -a xx KEYS \"test*\" | xargs redis-cli -h xxx -a xx DEL \r\r","date":"2018-02-05","objectID":"/redis/:25:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["database"],"content":"bigkeys #对redis中的key进行采样，寻找较大的Key redis-cli --bigkeys #之后对结果进行分析 \r 注意 Redis监听地址bind： x.x.x.x，强烈建议只对本地127.0.0.1开放。不建议对外网开放，有安全隐患 防火墙，最简单就是关闭防火墙，另一个就是开放redis的监听端口 开启守护进程，让redis可以在后台运行而不必通过redis-server的方式来启动，将配置文件里的deamonize no改为yes 关闭redis的保护模式(protect-mode)，这里的保护模式是指是否允许其他IP的设备访问redis。如果开启的话就只能允许本机访问。如果是生产开发的实际运行环境，请一定开启保护模式 设置redis数据库密码！不仅仅是redis，任何数据库都应该设置密码，否则对外网开放的数据库就成了活靶子。 \r 多数据库 Redis支持多个数据库 类似于其它数据库，不同的数据存储在不同的数据库中 Redis下，数据库是由一个整数索引标识，而不是数据库名称。默认情况下，客户端连接到数据库0 Redis不支持自定义数据库名称，所以需要开发者记录那些数据库存储了哪些数据 Redis不支持为每个数据库设置不同的访问密码，因为密码是在配置文件中设置的。所以一个用户可对所有数据库进行访问 Redis默认支持16个数据库，但可在配置文件中修改 使用SELECT命令切换数据库 FLUSHALL命令或清除所有数据库，请注意 cat /etc/redis.conf # Set the number of databases. The default database is DB 0, you can select # a different one on a per-connection basis using SELECT \u003cdbid\u003e where # dbid is a number between 0 and 'databases'-1 databases 16 ","date":"2018-02-05","objectID":"/redis/:26:0","tags":["redis"],"title":"Redis","uri":"/redis/"},{"categories":["infrastructure"],"content":"参考： 《老男孩Linux运维》 《服务器集群系统各概念》: https://segmentfault.com/a/1190000009923581 《WEB的负载均衡、集群、高可用解决方案》： https://zhuanlan.zhihu.com/p/23826048 计算机集群维基百科 \r计算机集群 计算机集群简称集群(Clusters)，是一种计算机系统。它通过一组散列集成的软件或硬件 连接起来高度紧密地协作完成计算工作。在某种意义上，他们可以被看做是一台计算机。 集群就是指一组（若干）相互独立的计算机，利用高速通信网络组成的一个较大的计算机服务系统，每个集群结点都是运行各自服务的独立服务器。这些服务器之间可以彼此通信，协同向用户提供应用程序、系统资源和数据，并以单一系统的模式加以管理。 当客户机请求集群系统时，集群给用户的感觉就是一个单一独立的服务器，而实际上用户请求的是一组集群服务器。 集群系统中的单个计算机通常称为节点，通常通过内网连接，但也有其它的可能连接方式。集群计算机通常用来改进单个计算机的计算速度和可靠性。 \r","date":"2018-02-03","objectID":"/computercluster/:0:0","tags":["nginx","cluster"],"title":"计算机集群","uri":"/computercluster/"},{"categories":["infrastructure"],"content":"服务器集群概念 集群、冗余、负载均衡、主从复制、读写分离、分布式、分布式计算、分布式计算平台、并行计算…… 实际生产环境中常有的问题： 当数据库性能遇到问题时，是否能够横向扩展，通过添加服务器的方式达到更高的吞吐量，从而充分利用现有的硬件实现更好的投资回报率; 是否拥有实时同步的副本，当数据库面临灾难时，可以短时间内通过故障转移的方式保证数据库的可用性。此外，当数据丢失或损坏时，能否通过所谓的实时副本（热备）实现数据的零损失; 数据库的横向扩展是都对应用程序透明，如果数据库的横向扩展需要应用程序端进行大量修改，则所带来的后果不仅仅是高昂的开发成本，同时也会带来很多潜在和非潜在的风险. ","date":"2018-02-03","objectID":"/computercluster/:1:0","tags":["nginx","cluster"],"title":"计算机集群","uri":"/computercluster/"},{"categories":["infrastructure"],"content":"集群和冗余 集群和冗余并不对立，多台服务器做集群（不是主从），本身就有冗余和负载均衡的效果。 狭义上来说，集群就是把多台服务器虚拟成一台服务器，而冗余的每台服务器都是独立的。 集群的侧重点在于协同，多台服务器系统分担工作，提升效率； 冗余的侧重点在于防止单点故障，一主多备的架构，也就是主从复制； 数据冗余==高可用性==主从 主从一定程度上起到了负载均衡的作用，但主要目的还是为了保证数据冗余和高可用性 主从只提供一种成本较低的数据备份方案加上不完美的灾难和负载均衡，由于复制存在时间差，不能同步读，所以只是不完善的负载均衡和有损灾备 主从显然达不到集群的严格度，不论是 HA 还是 AA（多活并行集群），主从都达不到数据一致性的集群要求 \r","date":"2018-02-03","objectID":"/computercluster/:1:1","tags":["nginx","cluster"],"title":"计算机集群","uri":"/computercluster/"},{"categories":["infrastructure"],"content":"为什么要使用集群 高性能（Performance） 大型网站谷歌、淘宝、百度等，都不是几台大型机可以构建的，都是上万台服务器组成的高性能集群，分布于不同的地点。 只有当并发或总请求数量超过单台服务器的承受能力时，服务器集群的优势才会体现出来。 价格有效性（Cost-effectiveness） 在达到同样性能的需求下，采用计算机集群架构比采用同等运算能力的大型计算机具有更高的性价比。 可伸缩性（Scalability） 当服务负载、压力增长时，针对集群系统进行较简单的扩展即可满足需求，且不会降低服务质量。 高可用（Availability） 单一计算机发生故障时，就无法正常提供服务；而集群架构技术可以是得系统在若干硬件设备发生故障时仍可以继续工作。 集群系统在提高系统可靠性的同时，也大大减小了系统故障带来的业务损失，目前几乎100%的网站都要求7x24h提供服务。 透明性（Transparency） 多个独立计算机组成的耦合集群系统构成一个虚拟服务器。用户访问集群系统时，就像访问一台高性能、高可用的服务器一样，集群中一部分服务器的上线、下线不会中断整个系统服务，这对用户也是透明的。 可管理性（Manageability） 这个系统可能在物理上很大，但其实很容易管理，就像管理一个单一映像系统一样。 可编程性（Programmability） 在集群系统上，容易开发及修改各类应用程序。 \r集群分类 集群分为同构和异构，他们区别在于 “组成集群系统的计算机之间的体系结构是否相同”。 集群计算机按功能和结构可以分为以下几类： 均衡集群（Load balancing clusters） 用性集群（High-availability clusters） 能计算集群（High-performance cluster） 计算集群（Grid computing） 负载均衡集群（LB）和高可用性集群（HA）是互联网行业常用的集群架构模式 ","date":"2018-02-03","objectID":"/computercluster/:2:0","tags":["nginx","cluster"],"title":"计算机集群","uri":"/computercluster/"},{"categories":["infrastructure"],"content":"负载均衡集群 负载均衡集群用于抗并发。 负载均衡集群典型的开源软件包括：LVS、Nginx、Haproxy 等。 负载均衡集群可以把很多客户集中的访问请求负载压力尽可能平均分摊在计算机集群中处理。 集群中每个节点都可以一定的访问请求负载压力，并且可以实现访问请求在各节点之间动态分配，以实现负载均衡。 负载均衡集群运行时，一般是通过一个或多个前端负载均衡器（Director）将客户访问请求分发到后端的一组服务器上，从而达到整个系统的高性能和高可用性。 一般高可用性集群和负载均衡集群会使用类似的技术，或同时具有高可用性与负载均衡的特点。 Linux虚拟服务器（LVS）项目 在Linux操作系统上提供最常用的负载均衡软件。 负载均衡的作用： 用户访问请求及数据流量（负载均衡） 业务连续性，即7x24h服务（高可用） 于Web业务及数据库从库等服务器的业务 ","date":"2018-02-03","objectID":"/computercluster/:3:0","tags":["nginx","cluster"],"title":"计算机集群","uri":"/computercluster/"},{"categories":["infrastructure"],"content":"高可用性集群 高可用性集群用于避免单点故障。 高可用性集群常用开源软件包括：Keepalived、Heartbeat 等。 一般是指集群中任意一个节点失效的情况下，该节点上的所有任务会自动转移到其他正常的节点上。此过程不会影响整个集群的运行。 当集群中的一个节点系统发生故障时，运行着的集群服务器会迅速做出反应，将该系统的服务分配到集群中其他正在工作的系统上运行。考虑到计算机硬件和软件的容错性，高可用性集群的主要目的是使局群的整体服务尽可能可用。 如果高可用集群中的主节点发生了故障，那么这段时间内将由备节点代替它。备节点通常是主节点的镜像。当它代替主节点时，它可以完全接管主节点（包括Ip和其他资源）提供服务，因此，使集群系统环境对系统环境来说是一致的，既不会影响用户的访问。 高可用性集群使服务器系统的运行速度和响应速度会尽可能的快。它们经常利用在多台机器上运行的冗余节点和服务来相互跟踪。 如果某个节点失败，它的替补者将在几秒钟或更多时间内接管它的职责。因此，对于用户来说，集群里的任意一台机器宕机，业务都不会受影响。 高可用性集群的作用： 当一台机器宕机后，另外一台机器接管宕机的机器的Ip资源和服务资源，提供服务； 常用于不易实现负载均衡的应用，如负载均衡器、主数据库、主存储对之间； \r","date":"2018-02-03","objectID":"/computercluster/:4:0","tags":["nginx","cluster"],"title":"计算机集群","uri":"/computercluster/"},{"categories":["infrastructure"],"content":"高性能计算集群 高性能计算集群也称并行计算。通常，高性能计算集群涉及为集群开发的并行应用程序，以解决复杂的科学问题。 高性能计算集群对外就好像一个超级计算机，这种超级计算机内部由数万个独立服务器组成，并且在公共消息传递层上进行通信以运行并行应用程序。 \r","date":"2018-02-03","objectID":"/computercluster/:5:0","tags":["nginx","cluster"],"title":"计算机集群","uri":"/computercluster/"},{"categories":["infrastructure"],"content":"高可用与负载均衡有什么区别 HA偏重于备用资源，切机时会有业务的断开的，保证了数据的安全，但造成资源的浪费； LB侧重于资源的充分应用，没有主备的概念，只有资源的最大限度的加权平均应用，基本不会业务的中断； HA的目的是不中断服务，LB的目的是为了提高接入能力。虽然经常放一起用，但确实是两个不同的领域； HA在一条路不通的时候提供另一条路可走，而 LB 就类似于是春运时的多个窗口； \r 集群软硬件 企业运维中常见集群产品： 开源集群软件： + Nginx, LVS, Haproxy, Keepalived, Heartbear… 商业集群硬件： + F5， Netscaler,Radware, A10… 如何选择开源集群软件： 网站在并发访问和总访问量不是很大的情况下，建议首选Nginx负载均衡，Nginx配置简单使用方便安全稳定。 另一个实现负载均衡的产品为Haproxy 如果要考虑Nginx负载均衡的高可用功能，建议首选Keepalived软件，因为安装配置简单方便稳定。类似高可用软件还有Heartbeat，但比较复杂 如果是大型企业，负载均衡可以使用 LVS+Keepalived 在前端做四层转发，后端使用Nginx或Haproxy做七层转发，再后面是应用服务器。如果是数据库与存储的负载均衡和高可用，可选用LVS+Heartbeat \r负载均衡 所谓负载均衡，就是把大访问量分发给不同的服务器，也就是分流请求。 ","date":"2018-02-03","objectID":"/computercluster/:6:0","tags":["nginx","cluster"],"title":"计算机集群","uri":"/computercluster/"},{"categories":["infrastructure"],"content":"HTTP重定向协议实现负载均衡 HTTP 重定向就是应用层的请求转发，用户的请求其实已经到了HTTP重定向负载均衡服务器，服务器根据算法要求用户重定向，用户收到重定向请求后，再次请求真正的集群. 优点：简单 缺点：性能较差 ","date":"2018-02-03","objectID":"/computercluster/:7:0","tags":["nginx","cluster"],"title":"计算机集群","uri":"/computercluster/"},{"categories":["infrastructure"],"content":"DNS域名解析负载均衡 DNS域名解析负载均衡就是在用户请求DNS服务器，获取域名对应的IP地址时，DNS服务器直接给出负载均衡后的服务器IP。 优点：交给DNS，不用我们去维护负载均衡服务器 缺点：当一个应用服务器挂了，不能及时通知DNS，而且DNS负载均衡的控制权在域名服务商那里，网站无法做更多的改善和更强大的管理 ","date":"2018-02-03","objectID":"/computercluster/:8:0","tags":["nginx","cluster"],"title":"计算机集群","uri":"/computercluster/"},{"categories":["infrastructure"],"content":"反向代理负载均衡 在用户的请求到达方向代理服务器时（已到达网站机房），由于反向代理服务器根据算法转发到具体的服务器，常用的Apache，Nginx都可以充当反向代理服务器。 优点：部署简单 缺点：代理服务器可能成为性能的瓶颈，特别是一次上传大文件 ","date":"2018-02-03","objectID":"/computercluster/:9:0","tags":["nginx","cluster"],"title":"计算机集群","uri":"/computercluster/"},{"categories":["infrastructure"],"content":"IP负载均衡(LVS-NAT) LVS集群中实现的三种IP负载均衡技术。 在请求到达负载均衡器后，负载均衡器通过修改请求的目的IP地址，从而实现请求的转发，做到负载均衡。 优点：性能更好 缺点：负载均衡器的带宽称为瓶颈 ","date":"2018-02-03","objectID":"/computercluster/:10:0","tags":["nginx","cluster"],"title":"计算机集群","uri":"/computercluster/"},{"categories":["infrastructure"],"content":"直接路由负载均衡(LVS-DR) 数据链路层负载均衡，在请求到达负载均衡器后，负载均衡器通过修改请求的Mac地址，从而做到负载均衡，与IP负载均衡不一样的是，当请求访问完服务器之后，直接返回客户，而无需在经过负载均衡器。 \r","date":"2018-02-03","objectID":"/computercluster/:11:0","tags":["nginx","cluster"],"title":"计算机集群","uri":"/computercluster/"},{"categories":["infrastructure"],"content":"IP隧道负载均衡(LVS-TUN) 主从复制 主从是一种用于数据容错和灾备的高可用解决方案，而不是一种处理高并发压力的解决方案（负载均衡是用来抗并发的）。 如MySQL主从复制，MongoDB主从复制(副本集) 主机负责查询，从机负责增删改 可以在从机上执行备份，以避免备份期间影响主机的服务 主从复制后，也可以在从机上查询，以降低主机的访问压力。但是，只有更新不频繁的数据或者对实时性要求不高的数据可以通过从服务器查询，实时性要求高的数据仍需在主服务器查询（因为主从复制有同步延迟，所以不能保证强数据一致性） ","date":"2018-02-03","objectID":"/computercluster/:11:1","tags":["nginx","cluster"],"title":"计算机集群","uri":"/computercluster/"},{"categories":["infrastructure"],"content":"主从复制和读写分离 主从复制是实现读写分离的技术之一，也是实现读写分离的前提条件 做读写分离时最重要的就是确保 读库 和 写库 的数据统一，而主从复制是实现数据统一最简单的方法（并不能够保证强数据的一致性） 读写分离，顾名思义，就是一个表只负责向前台页面展示数据，而后台管理人员对表的增删改在另一个表中，把两个表分开，就是读写分离 主从复制则是一个表数据 增删改 之后会及时更新到另一个表中，保证两个表的数据一致 ","date":"2018-02-03","objectID":"/computercluster/:12:0","tags":["nginx","cluster"],"title":"计算机集群","uri":"/computercluster/"},{"categories":["infrastructure"],"content":"主从类型 双机热备=主机+备机 主要应用运行在主机，备机即备用机器。备机不工作，主机出现故障时备机接管主机的所有工作 双机互备=主机（备机） + 备机（主机） 互为主备，部分应用运行于主机，部分应用运行于备机，主机备机同时工作 双机双工=主机+主机 两台主机同时运行应用，主机备机同时工作 分布式 广义上的分布式是指，将不同的服务分布在不同的服务器上 集群是指，将几台服务器集中在一起，实现同一业务 分布式中的每一个节点都可以做集群，而集群并不一定是分布式的 ","date":"2018-02-03","objectID":"/computercluster/:13:0","tags":["nginx","cluster"],"title":"计算机集群","uri":"/computercluster/"},{"categories":["database"],"content":"参考： MySQL5.7参考文档： https://dev.mysql.com/doc/refman/5.7/en/ MySQL必知必会 \r环境： CentOS7.x86_64 MySQL5.7 \r\r \r\r序言 MySQL官网： https://www.mysql.com/ 由于MySQL5.7和以前版本之间的许多功能和其他差异，因此此手册不太适用于之前的老版本。之前的版本请参考MySQL相关版本的手册。 \r\r \r\r综述 General information MySQL™ software提供了一个快速、多线程、多任务和健壮的SQL(结构化查询语言)的数据库服务器。MySQL server是为关键服务(mission-critical)、重负荷(heavy-load)生产系统以及嵌入式(embedding)大规模部署的软件而设计。 MySQL是Oracle Corporation的商标(trademark)。 MySQL software是双重许可的(dual license)： Open Source product of the GNU General Public License A Standard commercial License from Oracle \r","date":"2018-01-16","objectID":"/mysql/:0:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"关于此手册 该手册作为一个参考，它不提供关于SQL或关系型数据库概念的一般指令； MySQL Database Software正在不断发展，所以参考手册也经常更新。可在此 \u003c http://dev.mysql.com/doc/\u003e 获取最新版的手册； 参考手册(Reference Manual)的源文件使用DocBook XML格式书写的，其他版本(如HTML)等是自动生成的； 如果在使用过程中有任何问题或建议，请发邮件给我们； 手册由MySQL Documentation Team维护。 \r","date":"2018-01-16","objectID":"/mysql/:1:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL数据库管理系统 MySQL Database Management System ","date":"2018-01-16","objectID":"/mysql/:2:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL介绍 MySQL是最流行的开源的SQL数据库管理系统，由Oracle Corporation开发、分发和支持。 MySQL is a database management system 数据库是一个结构化的数据集合。它可能是从简单的购物清单到图片库，或是公司网络中的大量信息。若要添加、访问和处理存储在计算机数据库中的数据，你需要一个像MySQL Server这样的数据库管理系统。由于计算机非常擅长处理大量的数据，数据库管理系统在计算机中扮演这一个重要的角色。 MySQL databases are relational 关系型数据库将数据存储在单独的表(table)中，而不是将所有数据放入一个大的库房中。数据库结构被组织成针对速度优化的物理文件。具有数据库(database)，表(table)，视图(view)，行(row)，列(column)等物理对象的逻辑模型提供了灵活的编程环境。你设置了管理不同数据字段之间关系的规则，如一对一，一对多，唯一，必须和可选关系，以及不同表之间的指针(pointer)。数据库强制执行这些规则，这样在设计良好的数据库中，应用程序就不会看到不一致、重复、孤立、过时或丢失的数据。 MySQL也是代表SQL(Structure Query Language)的一部分。SQL是访问数据库最常用的标准化语言。你可以直接使用SQL语句，或者将SQL语法隐藏到语言特定的API中。 MySQL software is Open Source MySQL software使用GPL(GNU General Public License)，开源意味着任何人都可以下载、转发、使用和修改软件，而不需要支付任何费用。 MySQL database server is very fast,reliable,scalabe and easy to use MySQL server works in Client/Server or embedded system MySQL Database Server是一个由多线程(multi-threaded)SQL Server组成的客户/服务器系统。它支持不同的后端，多个不同的客户程序和库、管理工具和广泛的APIs。 还提供MySQL Server作为一个嵌入式多线程库以便链接到你的产品，以获得一个更小，更快，更容易管理的独立产品。 A large amount of contributed MySQL software is available \r","date":"2018-01-16","objectID":"/mysql/:2:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL主要特点 Internals and Portability 由C和C++写成 适用于许多不同的平台 为了可移植性，使用CMake 采用独立(independent)模块的多层(layer)服务器设计 设计为使用内核线程的完全多线程，如果有多核CPU，能够轻松使用它们 提供了事务性(transactional)和非事务性(notransactional)存储引擎 使用非常快速的带有索引压缩的B-tree磁盘表 添加其他存储引擎相对容易 使用非常快速的基于线程的内存分配系统 使用优化的嵌套循环(nested-loop)连接执行非常快的联结 实现内存中的hash table，这些表用作临时表 使用高度优化的类库实现SQL函数 数据类型 1,2,3,4和8byte的有无符号(signed/unsigned)的整数(integers) FLOAT DOUBLE CHAR, VARCHAR BINARY, VARBINARY TEXT BLOB DATE, TIME, DATETIME TIMESTAMP YEAR SET ENUM OpenGIS 状态和功能 statement and function SELECT和WHERT中包含了所有支持的操作符和函数 SQL中的GROUP BY和ORDER BY也全部支持 GROUP functions(COUNT(), AVG(), STD(), SUM(), MAX(), MIN(), GROUP_CONCAT()) 支持LEFT OUTER JOIN和ROGHT OUTER JOIN 按照SQL标准支持table和columns的别名 支持DELETE,INSERT,REPLACE,UPDATE，以返回受影响的行数 支持MySQL特定的SHOW显示语句 一个EXPLAIN语句显示优化器如何解析查询 安全 security 权限(privilege)和密码系统，非常灵活和安全，并且支持基于主机的验证 当连接到Server时，通过加密(encryption)所有密码通信量来确保密码安全 \r扩展性和限制 Scalability and Limits 支持大型数据库。包含五千万条记录，二十万个表，五十亿行 每个表最多支持64个索引，每个索引可以由1到16个列组成 \r####　连通性 Conectivity 客户端使用如下几种协议连接到MySQL Server TCP/IP sockets –enable-named-pipe on Windows Unix domain socket files on UNIX MySQL客户端可用多种语言编写 APIs对于多数语言是可用的 \r本地化 Localization Server可以向多种语言的客户端提供错误信息 完全支持几个不同的字符集(character sets) 所有数据都被保存在选取的字符集(chracter set) 排序和比较是根据默认的字符集和排序规则完成 服务器时区(time zone)可动态更改，个客户端也可修改自己的时区 \r客户端和工具 Clients and Tools MySQL包含几个客户机和使用程序 command-line： mysqldump, mysqladmin graphical: MySQL Workbench MySQL Server内置了对SQL语句的支持来检查、优化和修复表 MySQL程序可使用--help或-?来获取帮助 \r","date":"2018-01-16","objectID":"/mysql/:2:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL历史 History of MySQL MySQL is named after co-founder Monty Widenius’s daughter, My. The name of the MySQL Dolphin (our logo) is “Sakila,” which was chosen from a huge list of names suggested by users in our “Name the Dolphin” contest. \r\r","date":"2018-01-16","objectID":"/mysql/:2:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL5.7新特色 What Is New in MySQL 5.7 ","date":"2018-01-16","objectID":"/mysql/:3:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL5.7新功能 Features Added in MySQL 5.7 \r","date":"2018-01-16","objectID":"/mysql/:3:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL5.7中过期的功能 Features Deprecated in MySQL 5.7 \r","date":"2018-01-16","objectID":"/mysql/:3:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL5.7中移除的功能 Features Removed in MySQL 5.7 \r","date":"2018-01-16","objectID":"/mysql/:3:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"Server and Status Variables and Options Added, Deprecated, or Removed in MySQL 5.7 \r","date":"2018-01-16","objectID":"/mysql/:4:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL信息源 MySQL Information Sources 本章节将列出有关MySQL的帮助信息。 ","date":"2018-01-16","objectID":"/mysql/:5:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL站点 MySQL Websites MySQL Documentation is https://dev.mysql.com/doc \r\r \r\r术语 MySQL Glossary 这些术语通常用于有关MySQL的信息中。 \r .ARM文件 ARCHIVE表的metadata。由MySQL Enterprise Backup产品的mysqlbackup命令生成的备份中。 .ARZ文件 ARCHIVE表的数据。由MySQL Enterprise Backup产品的mysqlbackup命令生成的备份中。 ACID 代表原子性(atomic)，一致性(consistency)，隔离性(isolation)和持久性(durability)的首字母缩略词。 事务是可以提交(commit)或回滚(rollback)的原子工作单位。当事务对数据库进行多次更改时，要么在提交事务时所有更改都成功，要么在事务回滚时撤消所有更改。 数据库始终保持一致性状态 - 每次提交或回滚后，以及事务正在进行中。如果跨多个表更新相关数据，查询将查看所有旧值或所有新值，而不是旧值和新值的混合。 交易在进行过程中受到保护（隔离），它们不能互相干扰或看到彼此未提交的数据。这种隔离是通过锁定机制(locking mechanism)实现的。经验丰富的用户可以调整隔离级别，在保证事务确实不会相互干扰的情况下，减少保护，转而提高性能和并发。 事务的结果是持久的：一旦提交操作成功，该事务所做的更改就可以避免电源故障，系统崩溃，竞争条件或许多非数据库应用程序易受攻击的其他潜在危险。耐用性通常涉及写入磁盘存储，具有一定的冗余以防止写入操作期间的电源故障或软件崩溃。 adaptive flushing An algorithm for InnoDB tables that smooths out the I/O overhead introduced by checkpoints.MySQL不会一次将所有修改过的页面从缓冲池(buffer pool)刷新(flush)到数据文件，而是定期刷新一小组修改过的页面。自适应刷新(adaptive flushing)算法通过基于刷新率和生成重做信息的速度来估计执行这些周期性刷新的最佳速率来扩展该过程。 adaptive hash index InnoDB表的优化，通过在内存中构造hash index，可使用=和IN操作符加速查找。MySQL监控InnoDB表的索引搜索，如果查询可从哈希索引中受益，它会自动为经常访问的索引页创建一个。从某种意义上来说，自适应哈希索引在运行时配置MySQL以利用充足的主内存，更接近主内存数据库的体系结构。此功能由innodb_adaptive_hash_index配置项控制。 AIO 异步(asynchronous)I/O的缩写。 Antelope 原始InnoDB文件格式的代码名称。它支持REDUNDANT和COMPACT行格式，但不支持较新的DYNAMIC和COMPRESSED行格式。 API 一组功能或程序。 apply 当MySQL Enterprise Backup产品生成的备份不包括备份进行时发生的最新更改时，更新备份文件以包含这些更改的过程称为apply步骤。 asynchronous I/O 一种I/O操作，允许在I/O完成前继续进行其它处理。也称为非阻塞(nonblocking)I/O，缩写为AIO。 atomic 在SQL上下文中，事务是完全成功(commited)或根本没有效果(rollback)的工作单元。 atomic DDL atomic DDL语句将数据字典更新，存储引擎操作和DDL操作关联的二进制日志写入组合到单个原子事务中。即使服务器在操作期间暂停，事务也可以完全提交或回滚。MySQL 8.0中添加了Atomic DDL支持。 atomic instruction CPU提供的特殊指令。确保关键的低级操作不会被中断。 auto-increment(自增) 表的列的属性(由AUTO_INCREMENT关键字指定)，在自动在列中添加值的升序。 auto-increment locking 自动增量主键的便利性涉及一些与并发的权衡。 autocommit 在每个SQL语句之后导致COMMIT的设置。建议不要将此模式用于具有跨多个语句的事务的InnoDB表。它可以帮助InnoDB表上的只读事务的性能，从而最大限度地减少锁定和生成撤消数据的开销。 availability 能够对应于主机上的故障，并在必要时从中恢复故障。 B-tree 一种在数据库索引中很常用的树数据结构。结构始终保持排序，从而能够快速查找完全匹配(=)和让位(\u003e, \u003c, BETWEEN)。这种索引类型适用于大多数索引类型。 因为B树有很多子节点(children)，所以B树与二叉树(binary tree)不同，二叉树每个节点限制为2个子节点。 与哈希索引(hash index)形成对比，HASH仅在MEMORY存储引擎中可使用，MEMORY存储引擎中也可使用B树索引。如果某些查询使用范围运算符，则应为MEMORY表选择B树索引。 backticks(反引号) 如果MySQL SQL语句中的标识符包含特殊字符或保留字，则必须使用反引号(```)。 backup 从MySQL实例复制部分或全部表数据和原数据的过程，以便妥善保管。 Barracuda InnoDB文件格式的编码名称，它支持启用InnoDB表压缩的COMPRESSED行格式，以及改进长度可变长度列的存储布局的DYNAMIC行格式。 base column 存储生成的列或虚拟生成列多所基于的非生成表列。换句话说，基本列是非生成的表列，它是生成的列定义的一部分。 binary log 包含尝试更改表数据的所有语句的记录的文件。可以重播(replayed)这些语句，以便在副本集方案中是Slave Server保持最新，或者在从备份中还原表数据使数据库保持最新。建议开启此功能。 你可使用mysqlbinlog命令检查二进制日志的内容，以及重播这些内容。 binlog 二进制日志文件的非正式名称。 blind query expansion 由WITH QUERY EXPANSION子句启用的特殊全文搜索(full-text search)模式。它执行两次搜索，其中第二次搜索的搜索短语是与第一次搜索的少数最高度相关的文档连接的原始搜索短语。该技术主要适用于短搜索短语，可能只有一个单词。它可以发现文档中未出现精确搜索词的相关匹配。 bottleneck(瓶颈) 系统的一部分，其大小或容量受到限制，具有限制总吞吐量的效果。 bounce 关机(shutdown)操作后立即重启(restart)。 buddy allocator 一种管理InnoDB缓冲池(buffer pool)不同大小页面(pages)的机制。 buffer 用于临时存储的内存或磁盘区域。 buffer pool 保存表和索引的缓存InnoDB数据的内存区域。为了提高大容量读取操作的效率，缓冲池被分成可以容纳多行的页面。在具有大内存的系统上，可以通过将缓冲池划分为多个缓冲池实例来提高并发性。 几个InnoDB状态变量，INFORMATION_SCHEMA和performance_schema有助于监视缓冲池的内部工作。 buffer pool instance 可以划分缓冲池的多个区域中的任何一个，由innodb_buffer_pool_instances配置项控制。innodb_buffer_pool_size指定的总内存大小在所有缓冲池实例之间划分。通常，具有多个缓冲池实例适用于为InnoDB缓冲池分配多个GigaBytes的系统，每个实例为1GigaByte或更大。 built-in MySQL内置的InnoDB存储引擎是存储引擎的原始分发形式。 .cfg文件 与InnoDB可传输表空间功能一起使用的元数据(metadata)文件。它由命令FLUSH TABLES...FOR EXPORT生成，将一个或多个表置于可以复制到另一个Server的一致状态。 cache 存储区域的通用术语，用于存储频繁或高速检索的数据副本。在InnoDB中，主要的缓存结构就是缓冲池(buffer pool)。 cardinality 表列中的不同值的数量。当查询引用具有关联索引的列时，每列的基数会影响哪种访问方法最有效。 change buffer 一种特殊的数据结构，用于记录二级(secondary)索引中页面的更改。 change buffering 涉及change buffer功能的通用术语，包括insert buffering, delete buffering, pure buffering。 checkpoint 当对缓冲池(buffer pool)中缓存(cached)的数据也进行更改时，这些更改将在稍后某个时间写入数据文件，这个过程称为刷新(flushing)。检查点是已成功写入数据文件的最新更改(LSN值)的记录。 checksum 在InnoDB中的一种验证机制，用于在将表空间中的页面从磁盘读入InnoDB缓冲池时检测损坏。 child table 在外键(foreign key)中，子表是其行引用另一个表中具有相同值的特定列的行的表。这是包含FOREIGN KEY...REFERENCES子句和可选ON UPDATE和ON DELETE子句的表。子表创建之前，父表中的相应行必须存在。 clean page ","date":"2018-01-16","objectID":"/mysql/:5:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"通用安装指南 General Installation Guidance \r","date":"2018-01-16","objectID":"/mysql/:6:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"安装哪个发行版和MySQL版本 Which MySQL Version and Distribution to Install 在准备安装MySQL时，请决定使用哪种版本(version)和发行(distribution)格式(binary or source) 首先，决定安装开发版还是稳定版。 Development release 具有新功能，但不推荐用于生产环境 General Availability(GA) release 也称为稳定版(stable release)，推荐为生产环境使用 MySQL命名方案(naming scheme)， 例如MySQL5.7.1： 5为主版本号(major) 7为次版本号(minor) 1为发行(release)系列版本号 系列号描述了稳定的功能集。对于每个新的修补程序，这都会增加。 在选择要安装的MySQL版本之后，决定要为操作系统安装哪个发行版格式。 二进制(binary) RPM, DMG 源码(source) tar, zip 在某些情况下，最好使用源码安装MySQL： 想在某个明确的位置安装MySQL 希望使用二进制发行版中未包含的特性配置mysqld 希望配置mysqld，而不需要二进制发行版中包含的一些功能 你希望读取或修改组成MySQL的C、C++源代码 源码发行版比二进制发行版包含更多的测试和示例 \r\r","date":"2018-01-16","objectID":"/mysql/:6:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"如何获取MySQL How to Get MySQL MySQL当前版本下载页： https://dev.mysql.com/downloads/ 完整的MySQL镜像： https://dev.mysql.com/downloads/mirrors/ 基于RPM的Linux平台，MySQL Yum Repository： https://dev.mysql.com/downloads/repo/yum/ 基于Debian的Linux平台，MySQL APT Repository： https://dev.mysql.com/downloads/repo/apt/ SUSE Linux平台，MySQL SUSE Repository： https://dev.mysql.com/downloads/repo/suse/ \r\r","date":"2018-01-16","objectID":"/mysql/:6:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用MD5校验和或GnuPG验证程序完整性 Verifying Package Integrity Using MD5 Checksums or GnuPG 下载好MySQL包并在安装它之前，请确保它是完整的并未被篡改。有如下三种方法： MD5 checksums Cryptographic signatures using GnuPG, the GNU Privacy Guard For RPM packages, the built-in RPM integrity verification mechanism \r\r验证MD5校验和 Verifying the MD5 Checksum 应确保下载的MySQL包的MD5校验和与MySQL官方提供的校验和相匹配。 md5sum mysql-standard-5.7.22-linux-i686.tar.gz #aaab65abbec64d5e907dcd41b8699945 mysql-standard-5.7.22-linux-i686.tar.gz 使用GnuPG进行签名检查 Signature Checking Using GnuPG 要验证软件包的签名，首先需要我们的公共GPG密钥的副本。可从http://pgp.mit.edu/下载。 你想要获得的密钥名为mysql-build@oss.oracle.com，如下: -----BEGIN PGP PUBLIC KEY BLOCK----- Version: GnuPG v1.4.5 (GNU/Linux) mQGiBD4+owwRBAC14GIfUfCyEDSIePvEW3SAFUdJBtoQHH/nJKZyQT7h9bPlUWC3 RODjQReyCITRrdwyrKUGku2FmeVGwn2u2WmDMNABLnpprWPkBdCk96+OmSLN9brZ fw2vOUgCmYv2hW0hyDHuvYlQA/BThQoADgj8AW6/0Lo7V1W9/8VuHP0gQwCgvzV3 BqOx后面还有很多，省略 -----END PGP PUBLIC KEY BLOCK----- 使用gpg --import将密钥导入到个人公共GPG密钥环中。如公共密钥为mysql_pubkey.asc： gpg --import ./mysql_pubkey.asc #或使用public key id下载公共密钥 gpg --recv-keys $pub-key-id 在rpm包中验证: rpm --import ./mysql_pubkey.asc 确保两个文件都放置于同一目录下，然后运行命令验证签名： gpg --verify package_name.asc gpg --verify mysql-standard-5.7.22-linux-i686.tar.gz.asc gpg: Signature made Tue 01 Feb 2011 02:38:30 AM CST using DSA key ID 5072E1F5 gpg: Good signature from \"MySQL Release Engineering \u003cmysql-build@oss.oracle.com\u003e\" 使用RPM进行签名检查 Signature Checking Using RPM \r rpm --checksig package_name.rpm [zhang@zabbix ~]$ rpm --checksig mysql-community-server-5.7.20-1.el7.x86_64.rpm mysql-community-server-5.7.20-1.el7.x86_64.rpm: (sha1) dsa sha1 md5 gpg OK rpm还支持从URL加载密钥: rpm --import http://dev.mysql.com/doc/refman/5.7/en/checking-gpg-signature.html \r\r","date":"2018-01-16","objectID":"/mysql/:6:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"安装布局 Installation Layouts \r不同的安装类型(native packages, binary tarballs, and source tarballs)有不同的安装布局，这样可能会导致混淆。 \r\r","date":"2018-01-16","objectID":"/mysql/:6:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"在Unix/Linux上使用通用二进制文件安装MySQL Installing MySQL on Unix/Linux Using Generic Binaries 包括以压缩的tar文件形式的通用二进制发行版，以及针对特定平台封装格式的二进制文件。 MySQL压缩tar文件二进制发行版具有** mysql-VERSION-OS.tar.gz**的文件格式。 MySQL依赖于libaio Library： yum install -y libaio 默认地，tar文件二进制发行版，解压后安装于/usr/local/mysql目录。会在目录下生产 通用Unix/Linux二进制包的MySQL安装布局目录 目录 | 内容 | - bin | mysqld server, client and utility programs docs | MySQL manual in Info format man | Unix manual pages include | Include (header) files lib | Libraries share | Error messages, dictionary, and SQL for database installation support-files | Miscellaneous support files 大致命令如下： shell\u003e groupadd mysql shell\u003e useradd -r -g mysql -s /bin/false mysql shell\u003e cd /usr/local shell\u003e tar zxvf /path/to/mysql-VERSION-OS.tar.gz shell\u003e ln -s full-path-to-mysql-VERSION-OS mysql shell\u003e cd mysql shell\u003e mkdir mysql-files shell\u003e chown mysql:mysql mysql-files shell\u003e chmod 750 mysql-files shell\u003e bin/mysqld --initialize --user=mysql shell\u003e bin/mysql_ssl_rsa_setup shell\u003e bin/mysqld_safe --user=mysql \u0026 # Next command is optional shell\u003e cp support-files/mysql.server /etc/init.d/mysql.server #添加环境变量 export PATH=$PATH:/usr/local/mysql/bin \r\r","date":"2018-01-16","objectID":"/mysql/:7:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"在Linux上安装MySQL Installing MySQL on Linux Linux支持多种方法来安装MySQL。建议使用Oracle提供的一个发行版： Apt Yum Zypper RPM DEB Generic Source Docker Oracle Unbreakable Linux Network 作为一个选择，你可以使用系统中的包管理工具自动下载和安装MySQL。 ","date":"2018-01-16","objectID":"/mysql/:8:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"在Linux上使用Yum Repository安装MySQL Installing MySQL on Linux Using the MySQL Yum Repository 安装一个全新的MySQL的步骤： 添加MySQL Yum Repository 首先，添加MySQL Yum repository到你的系统仓库列表 选择和下载对应平台的release 或者 手动添加repository文件 安装release package #yum localinstall platform-and-version-specific-package-name.rpm yun install http://repo.mysql.com/yum/mysql-5.7-community/el/7/x86_64/mysql57-community-release-el7-10.noarch.rpm yum repolist enabled | grep \"mysql.*-community.*\" 选择一个release series 默认是最新的GA series，当前最新是MySQL5.7。 查看所有的MySQL Yum repository: yum repolist all | grep mysql 安装最新MySQL不需要配置，而安装先前的版本则需要指定GA series。disable最新的GA series并且enable需要的GA series。 yum-config-manager --disable mysql57-community yum-config-manager --enable mysql56-community 或者手动创建repo，可直接定义版本 [mysql57-community] name=MySQL 5.7 Community Server baseurl=http://repo.mysql.com/yum/mysql-5.7-community/el/7/$basearch/ enabled=1 gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql 安装MySQL 在安装MySQL过程中出现错误，请务必查看日志文件。 yum install -y mysql-community-server mysql-community-client #也可不安装客户端 开启MySQL Server service mysqld start #Starting mysqld:[ OK ] service mysqld status 在服务器初始启动时，如果服务器的数据目录为空，则会发生一下情况： 服务器已初始化 SSL certificate and key files 在数据目录中生成 validate_password已安装并启用 超级用户账户’root'@‘localhost’被创建，超级用户密码被设置并被存储在error log files 这一点和以前版本有很大区别，我被坑惨了 注意： ValidPassword的默认密码策略要求包含大写字母、小写字母、数字和特殊字符，并且密码长度至少为8个字符 #查看初始密码 grep 'temporary password' /var/log/mysqld.log #无法使用mysqladmin修改密码，需要登录mysql后修改 mysql -uroot -p #重置密码 ALTER USER 'root'@'localhost' IDENTIFIED BY 'NewPass4!; #如果找不到初始密码 vim /etc/my.cnf #在[mysqld]最后行加上skip-grant-tables实现无认证登录 #重启MySQL UPDATE mysql.user SET authentication_string =PASSWORD('新密码') WHERE USER='xxx'; #修改默认密码策略 #更改密码强度 set global validate_password_policy=0; #设置密码最小长度 set global validate_password_length=4; 使用Yum安装额外的MySQL产品和组件 你可使用Yum安装和管理MySQL的个别组件。 yum --disablerepo=\\* --enablerepo='mysql*-community*' list available yum install package-name #栗子 yum install mysql-community-libs \r\r","date":"2018-01-16","objectID":"/mysql/:8:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"在Linux上使用Oracle提供的RPM包安装MySQL Installing MySQL on Linux Using RPM Packages from Oracle MySQL Community Edition的rpm包如下： 包名 | 描述 | - mysql-community-server | Database server and related tools mysql-community-client | MySQL client applications and tools mysql-community-common | Common files for server and client libraries mysql-community-server-minimal | Minimal installation of the database server and related tools mysql-community-devel | Development header files and libraries for MySQL database client applications mysql-community-libs | Shared libraries for MySQL database client applications mysql-community-libs-compat | Shared compatibility libraries for previous MySQL installations mysql-community-embedded | MySQL embedded library mysql-community-embedded-devel | Development header files and libraries for MySQL as an embeddable library mysql-community-test | Test suite for the MySQL server #rpm -qpl mysql-community-server-version-distribution-arch.rpm #yum install mysql-community-{server,client,common,libs}-* wget http://repo.mysql.com/yum/mysql-5.7-community/el/7/x86_64/mysql-community-server-5.7.20-1.el7.x86_64.rpm wget http://repo.mysql.com/yum/mysql-5.7-community/el/7/x86_64/mysql-community-client-5.7.20-1.el7.x86_64.rpm yum install -y mysql-community-server-5.7.20-1.el7.x86_64.rpm mysql-community-client-5.7.20-1.el7.x86_64.rpm Linux RPM包MySQL开发区的安装布局： 文件或资源 | 位置 | - Client programs and scripts | /usr/bin mysqld server | /usr/sbin configuration file | /etc/my.cnf data directory | /var/lib/mysql error log file | /var/log/mysqld.log Value of secure_file_priv | /var/lib/mysql-files System V init script | /etc/init.d/mysqld Systemd service | mysqld pid file | /var/run/mysql/mysqld.pid socket | /var/lib/mysql/mysql.sock Keyring directory | /var/lib/mysql-keyring Unix manual pages | /usr/share/man include (header) files | /usr/include/mysql Libraries | /usr/lib/mysql Miscellaneous support files (for example, error messages, and character set files) | /usr/share/mysql The installation also creates a user named mysql and a group named mysql on the system. 注意 安装MySQL会在系统上生成一个名为mysql的用户和群组 安装以前的MySQL版本可能会创建my.cnf配置文件。强烈建议先将my.cnf进行迁移，然后删除它。之后才安装MySQL \r\r","date":"2018-01-16","objectID":"/mysql/:8:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"用systemd管理MySQL Server Managing MySQL Server with systemd systemd综述 Overview of systemd systemd提供了MySQL Server的自动开启和关闭，使用systemctl命令进行管理。 或者，使用system V系统兼容的service命令。 systemctl {start|stop|restart|status} mysqld service mysqld {start|stop|restart|status} 对systemd的支持包括这些文佳： mysqld.service systemd服务单元配置文件，以及有关MySQL服务的详细信息 mysqld@.service 用于管理多个MySQL实例 mysqld.tmpfiles.d 包含支持临时文件功能的信息 mysqld_pre_systemd 支持单元文件的脚本 为MySQL配置systemd Configuring systemd for MySQL 为MySQL添加或修改systemd选项，参考如下方法： 使用一个本地化的systemd配置文件 安排systemd为MySQL Server进程设置环境变量 设置MYSQLD_OPTS systemd变量 创建/etc/systemd/system/mysqld.service本地化systemd配置文件，这里讨论的是将此文件名作为override.conf： [Service] LimitNOFILE=max_open_files PIDFile=/path/to/pid/file Nice=nice_level LimitCore=core_file_limit Environment=\"LD_PRELOAD=/path/to/malloc/library\" Environment=\"TZ=time_zone_setting\" #LimitNOFILE: 文件描述符数量 #LimitCore: 最大核心文件大小 #Nice: 优先级 #LD_PRELOAD: 特定内存分配库 #TZ: 指定时区 修改mysqld: systemctl edit mysqld 重新加载systemd配置，然后重启MySQL service： systemctl daemon-reload systemctl restart mysqld 可在override.conf中设置如下参数： [Service] PIDFile=/var/run/mysqld/mysqld-custom.pid ExecStart= ExecStart=/usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld-custom.pid $MYSQLD_OPTS 在/etc/sysconfig/mysql下指定值： LD_PRELOAD=/path/to/malloc/library TZ=time_zone_setting systemctl restart mysqld 使用systemd配置多个MySQL实例 Configuring Multiple MySQL Instances Using systemd 由于systemd具有在平台上管理多个MySQL实例的能力，而不必须需要mysqld_multi和mysqld_multi.server。 若要使用多实例(multiple-instance)功能，请修改/etc/my.cnf文件以包含每个实例的关键选项配置。 例如，管理replication01和replication02两个实例： vim /etc/my.cnf [mysqld@replica01] datadir=/var/lib/mysql-replica01 socket=/var/lib/mysql-replica01/mysql.sock port=3307 log-error=/var/log/mysqld-replica01.log [mysqld@replica02] datadir=/var/lib/mysql-replica02 socket=/var/lib/mysql-replica02/mysql.sock port=3308 log-error=/var/log/mysqld-replica02.log 这里的名称使用@作为分隔符(delimiter)，因为这个是systemd支持的唯一分隔符。 管理两个实例: systemctl start mysqld@replica01 systemctl start mysqld@replica02 systemctl enable mysqld@replica01 systemctl enable mysqld@replica02 #使用通配符 systemctl status 'mysqld@replica*' systemctl stop mysqld@replica0{1,2} 对于同一个机器上的不同MySQL实例，systemd自动使用不同的单元文件。 在unit file中，%I和%i用于@标记后传入参数，用于管理特定实例。 #像这样 mysqld --defaults-group-suffix=@%I ... systemctl status mysqld@replica01 # mysqld@replica01.service - MySQL Server # Loaded: loaded (/usr/lib/systemd/system/mysqld@.service; disabled; vendor preset: disabled) # Active: active (running) since Tue 2018-02-27 12:18:34 CST; 1min 6s ago # Docs: man:mysqld(8) # http://dev.mysql.com/doc/refman/en/using-systemd.html # Process: 3927 ExecStart=/usr/sbin/mysqld --defaults-group-suffix=@%I --daemonize --pid-file=/var/run/mysqld/mysqld-%i.pid $MYSQLD_OPTS (code=exited, status=0/SUCCESS) # Process: 3845 ExecStartPre=/usr/bin/mysqld_pre_systemd %I (code=exited, status=0/SUCCESS) #Main PID: 3930 (mysqld) # CGroup: /system.slice/system-mysqld.slice/mysqld@replica01.service # `-3930 /usr/sbin/mysqld --defaults-group-suffix=@replica01 --daemonize --pid-file=/var/run/mysqld/mysqld-replica01.pid # #eb 27 12:18:27 zabbix.me systemd[1]: Starting MySQL Server... #eb 27 12:18:34 zabbix.me systemd[1]: Started MySQL Server. \r从mysqld_safe迁移到systemd Migrating from mysqld_safe to systemd 因为mysqld_safe没有安装在使用systemd管理MySQL的平台上，所以以前需要为该程序指定选项：[mysqld_safe] 一些[mysqld_safe]的选项也能被[mysqld]支持 一些[mysqld_safe]的选项类似于[mysqld]选项 \r\r","date":"2018-01-16","objectID":"/mysql/:8:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"从源码安装MySQL Installing MySQL from Source 从源代码构建MySQL使我们能够自定义构建参数(parameter)、编译器优化(compiler optimization)和安装位置(installation location)。 在使用源码安装前，请检查Oracle是否为你的平台生成预编译的二进制发行版，以及是否适合你。Oracle付出了很多努力确保提供的二进制文件具有最佳的性能选择。 源码安装系统需求： 使用源码安装MySQL需要多种开发工具。 使用源码安装MySQL，必须满足一下系统需求： CMake, which is used as the build framework on all platforms A good make program A working ANSI C++ compiler The Boost C++ libraries are required to build MySQL The ncurses library Sufficient free memory Perl is needed if you intend to run test scripts 使用standard source distribution安装MySQL，需要以下工具来unpack分发文件： For a .tar.gz compressed tar file: tar For a .zip Zip archive: zip For an .rpm RPM package: rpmbuild \r\r","date":"2018-01-16","objectID":"/mysql/:9:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"用于源码安装的MySQL布局 MySQL Layout for Source Installation 默认地，再从源码编译后安装MySQL时，安装步骤会将文件安装在/usr/local/mysql下。 \r\r","date":"2018-01-16","objectID":"/mysql/:9:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用标准源码发行版安装MySQL Installing MySQL Using a Standard Source Distribution 从一个标准源码发行版安装MySQL： 确保系统满足工具需求 获取发行文件 配置、构建和安装 执行安装后程序 如果是source RPM: rpmbuild --rebuild --clean MySQL-VERSION.src.rpm 如果是compressed tar file 或 zip archive source: # Preconfiguration setup shell\u003e groupadd mysql shell\u003e useradd -r -g mysql -s /bin/false mysql # Beginning of source-build specific instructions shell\u003e tar zxvf mysql-VERSION.tar.gz shell\u003e cd mysql-VERSION shell\u003e mkdir bld shell\u003e cd bld shell\u003e cmake .. shell\u003e make shell\u003e make install # End of source-build specific instructions # Postinstallation setup shell\u003e cd /usr/local/mysql shell\u003e mkdir mysql-files shell\u003e chown mysql:mysql mysql-files shell\u003e chmod 750 mysql-files shell\u003e bin/mysqld --initialize --user=mysql shell\u003e bin/mysql_ssl_rsa_setup shell\u003e bin/mysqld_safe --user=mysql \u0026 # Next command is optional shell\u003e cp support-files/mysql.server /etc/init.d/mysql.server /sbin/nologin和/bin/false的区别 /bin/false是最严格的禁止login选项，一切服务都不能用 mongod❌996:994:mongod:/var/lib/mongo:/bin/false /sbin/nologin只是不允许系统login，可以使用其他服务 ftp❌14:50:FTP User:/var/ftp:/sbin/nologin 执行预配置(preconfiguration)设置 在Unix上，设置MySQL用户和组，用于运行和执行MySQL服务器和数据库目录。 获得和解包distribution 选择要解压分发的目录，并将位置更改到其中。 tar zxvf mysql-VERSION.tar.gz #gunzip \u003c mysql-VERSION.tar.gz | tar xvf - #cmake -E tar zxvf mysql-VERSION.tar.gz \r\r","date":"2018-01-16","objectID":"/mysql/:9:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用开发源码树安装MySQL Installing MySQL Using a Development Source Tree install MySQL from the latest development source codew hich is hosted on GitHub: https://github.com/mysql/mysql-server 设置一个MySQL git repository 克隆MySQL git repository到本机 git clone https://github.com/mysql/mysql-server.git 查看 cd mysql-server 使用git branch -r查看远程MySQL分支 cd mysql-server git branch -r 查看分支 cd mysql-server git branch 切换分支 cd mysql-server git checkout 5.7 获取远程MySQL git repository更新 cd mysql-server git pull 检查提交历史 cd mysql-server git log #也可在MySQL GitHub上查看commit history 在克隆MySQL git repository并切换到需要的分支后，便可以从源代码构建MySQL Server。 在生产机器上从分发源码树安装构件时要小心，安装命令可能会覆盖您的实时发行版安装。 \r\r","date":"2018-01-16","objectID":"/mysql/:9:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL源码配置选项 MySQL Source-Configuration Options \rCMake程序提供了一个强大的如何配置MySQL源码发行版的控制。 具体链接参考: https://dev.mysql.com/doc/refman/5.7/en/source-configuration-options.html \r\r","date":"2018-01-16","objectID":"/mysql/:9:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"处理MySQL编译问题 Dealing with Problems Compiling MySQL 如果CMake先前已经运行过，那么现在运行的CMake可能使用先前的调用过程中收集到的信息。这些信息存储在 CMakeCache.txt。在CMake启动时，它会寻找和读取此文件。 每次运行CMake，必须再次运行make才能重新编译。 防止使用old object file或配置文件: make clean rm CMakeCache.txt \r\r","date":"2018-01-16","objectID":"/mysql/:9:5","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"安装之后的设置和测试 Postinstallation Setup and Testing 在安装MySQL后你应该做的事： 如有必要，初始化数据目录并创建MySQL授权表 开启Server并确保它可以正常访问 将密码分配给授权表中的root用户 可选地，设置Server自启动 可选地，填写时区表，以便识别时区 ","date":"2018-01-16","objectID":"/mysql/:10:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"初始化数据目录 Initializing the Data Directory 安装MySQL之后，必须初始化数据目录，包括mysql系统数据库中的表。有些安装方法会自动初始化，有些则需要手动初始化。 当然，如果修改了默认数据目录位置，那么也是需要手动初始化的。 初始化数据库目录，主要是包含了初始MySQL授权表(grant table)的MySQL服务器，这些表确定了如何允许用户连接到服务器。 但是，初始化数据目录是不会覆盖(overwrite)任何现有权限表，因此在任何情况下运行都是安全的。 数据目录初始化会在MySQL数据库汇总创建time zone，但不会填充它，所以它是空的。 cd /usr/local/mysql mkdir mysql-files chown mysql:mysql ./mysql-files chmod 750 ./mysql-files #--user #使数据库目录文件属于mysql用户，以确保Server有读取权限 /usr/local/mysql/bin/mysqld --initialize --user=mysql #开启安全连接 /usr/local/mysql/bin/mysql_ssl_rsa_setup 使用mysqld手动初始化数据目录 Initializing the Data Directory Manually Using mysqld cd /usr/local/mysql/bin #使数据库目录文件属于mysql用户，以确保Server有读取权限 #默认是secure，会生成root初始密码 ./mysqld --initialize --user=mysql #不生成root初始密码 ./bin/mysqld --initialize-insecure --user=mysql #指定目录 --basedir=/usr/local/mysql --datadir=/var/lib/mysql #或者将其写入配置文件 vim /etc/my.cnf [mysqld] basedir=/usr/local/mysql datadir=/var/lib/mysql #指定配置文件初始化 ./mysqld --defaults-file=/etc/mysql.cnf --initialize --user=mysql 使用mysql_install_db初始化数据目录 Initializing the Data Directory Manually Using mysql_install_db cd /usr/local/mysql/bin #mysql_install_db命令会创建数据目录，并在数据目录下创建mysql数据库和授权表 ./mysql_install_db --user=mysql #指定目录是必须的 --basedir=/usr/local/mysql --datadir=/var/lib/mysql ./mysqld_safe --user=mysql \u0026 #systemctl start mysqld mysql -u root -p xxx mysql\u003eSET PASSWORD FOR 'root'@'localhost' = PASSWORD('new_password'); \r\r","date":"2018-01-16","objectID":"/mysql/:10:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"Starting the Server Start the MySQL server like this if your installation includes mysqld_safe /usr/local/mysql/binmysqld_safe --user=mysql \u0026 Start the server like this if your installation includes systemd support systemctl start mysqld 使用non-root用户运行MySQL服务很重要 如有错误请查看日志 \r","date":"2018-01-16","objectID":"/mysql/:10:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"Testing the Server 执行一些简单测试以保证Server正常工作。 #使用mysqladmin验证Server正在运行 mysqladmin --help mysqladmin -uuser -ppasswd version mysqladmin -uuser -ppasswd variables mysqladmin -user -ppasswd shutdown # 使用mysqlshow查看数据库 mysqlshow -uuser -ppasswd #查看指定数据库信息 mysqlshow -uuser -ppasswd mysql #读取信息 #-e,Execute command and quit mysql -uuser -ppasswd -e \"SELECT user, host from mysql.user\" \r\r","date":"2018-01-16","objectID":"/mysql/:10:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"保护初始化MySQL账户 Securing the Initial MySQL Accounts 在安装MySQL后，root账户密码可能已经被分配。 mysql.user授权表定义了初始化MySQL用户账户和它们的访问权限。 MySQL5.7只创建了一个'root'@'localhost'账户，但早期的版本可能有多个用户。 请务必为每一个MySQL账户创建密码。 查看用户： #存储在authentication_string列中的密码可能包含无法正常显示的二进制数据 #所以将其转换为十六进制 mysql\u003e SELECT user, host, hex(authentication_string) FROM mysql.user; mysql\u003e SELECT user, host, authentication_string FROM mysql.user; #或 mysql -uuser -ppasswd -e \"SELECT user, host, hex(authentication_string) FROM mysql.user;\" #5.7以前的版本 mysql\u003e mysql\u003e SELECT user, host, password FROM mysql.user; #或 mysql -uuser -ppasswd -e \"SELECT user, host, password FROM mysql.user;\" 为root账户分配密码 #5.7.6 mysql\u003e ALTER USER user IDENTIFIED BY 'new_passwd'; mysql\u003e ALTER USER 'root'@'localhost' IDENTIFIED BY 'new_passwd'; #5.7.6前 mysql\u003e SET PASSWORD FOR username = PASSWORD('new_passwd'); mysql\u003e SET PASSWORD FOR 'root'@'localhost' = PASSWORD('new_passwd'); 给anonymous账户分配密码 mysql\u003e SET PASSWORD FOR ''@'localhost' = PASSWORD('new_passwd'); 移除匿名账户 mysql\u003e DROP USER ''@'localhost'; \r\r","date":"2018-01-16","objectID":"/mysql/:10:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"升级或降级MySQL Upgrading or Downgrading MySQL 升级是一个常见的过程。请在测试系统上确保运行正常后再实施到生产环境 降级不太常见。一般是由于新版本在生产环境上发生某些兼容性或性能问题，并且是在测试环境中没有发现的情况下，从而需要降级。请现在测试系统上运行正常后再实施到生产环境。 \r\r","date":"2018-01-16","objectID":"/mysql/:11:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"升级MySQL 请使用有管理权限的MySQL账户执行升级相关命令。(如root账户) MySQL升级策略 MySQL Upgrade Strategies 升级方法 直接升级(In-Place Upgrade) 包含关闭旧版MySQL，替换为新的MySQL版本，在现有数据目录上重启MySQL，运行mysql_upgrade 逻辑升级(Logical Upgrade) 包含使用mysqldump导出现有数据文件，安装新版MySQL，导入数据文件到新版MySQL，运行mysql_upgrade 升级路径 只支持GA release之间 这是一个发行系列的升级 如5.6.x到5.6.y 升级到下一个版本之前，建议先升级到最新版本 如先升级到5.6最新版，再升级到5.7 不支持跳版本升级 如5.5到5.7 升级之前 升级之前，请一定备份数据 查看新版本的Release Note 删除和增加了什么功能 新版本依赖什么 如果在InnoDB中使用XA事务，则在升级之前运行XA恢复以检查未提交的XA事务 如果MySQL数据量很大，就地升级以后可能需要很长的时间才能进行转换 你可能会发现创建一个\"dummy\"数据库实例是很有用的，以及评估可能需要哪些转换以及执行这些转换所涉及的工作 无论在你安装或升级到一个MySQL新版本，建议重建和重装MySQL language interface 如PHP MySQL扩展 \r直接升级 配置MySQL执行slow shutdown innoDB在关闭前执行一个完整的清除和更改缓冲区合并，这确保数据文件在不同的版本的文件格式做好充分准备。 mysql -u root -p --execute=\"SET GLOBAL innodb_fast_shutdown=0\" 关闭MySQL Server mysql -uroot -p shutdown 升级MySQL 开启新版MySQL 运行mysql_upgrade mysql_upgrade检查所有数据库中的所有表与当前版本MySQL的不兼容性。 mysql_upgrade -uroot -p #Upgrade process completed successfully. #Checking if update is needed. 关闭和重启MySQL Server来确保改变生效 mysqladmin -uroot -p shutdown systemctl start mysqld 逻辑升级 导出所有数据 mysqldump -uroot -p --all-databases --force \u003e mysqldb_backup.sql #-f, --force Continue even if we get an SQL error #Use the --routines and --events options if your databases include stored programs #--add-drop-database Add a DROP DATABASE before each create. mysqldump -uroot -p --add-drop-table --routines --events --all-databases --force \u003e mysqldb_backup.sql 关闭MySQL Server mysqladmin -uroot -p shutdown 安装新版MySQL 初始化MySQL并启动 载入数据文件 mysql -uroot -p --force \u003c ./mysqldb_backup.sql 运行mysql_upgrade mysql_upgrade -uroot -p #Upgrade process completed successfully. #Checking if update is needed. 关闭并重启MySQL Server以确保更改生效 通过MySQL Yum Repository进行升级 Upgrading MySQL with the MySQL Yum Repository 选择一个target series 默认情况下，MySQL Yum Repository会将MySQL升级到该release系列的最新版本。如5.7.1升级到5.7.10。 如果要升级到其他release(如5.6到5.7)，就必须要先禁用此subrepository，并选择和启用新的subrepository。 As a general rule, to upgrade from one release series to another, go to the next series rather than skipping a series. 升级MySQL yum update mysql-server mysql-client 重启MySQL MySQL Server总是在Yum更新之后重启，一旦重启，请运行mysql_upgrade来检查旧数据与升级软件之间的任何不兼容问题。 mysql_upgrade -uroot -p #Upgrade process completed successfully. #Checking if update is needed. 升级Shared Client Libraries 所以说，用yum repository安装软件是很方便的。不管是在管理还是升级等方面… \r通过直接下载RPM包升级MySQL 直接下载mysql相应组件的rpm进行升级。 建议备份好配置文件。 wget http://repo.mysql.com/yum/mysql-5.7-community/el/7/x86_64/mysql-community-server-5.7.20-1.el7.x86_64.rpm wget http://repo.mysql.com/yum/mysql-5.7-community/el/7/x86_64/mysql-community-client-5.7.20-1.el7.x86_64.rpm yum install mysql-community-server-5.7.20-1.el7.x86_64.rpm mysql-community-client-5.7.20-1.el7.x86_64.rpm \r","date":"2018-01-16","objectID":"/mysql/:11:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"mysql降级 MySQL降级类似于MySQL升级。也包含有直接降级和逻辑降级。 \r\r","date":"2018-01-16","objectID":"/mysql/:11:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"重建或修复表或索引 Rebuilding or Repairing Tables or Indexes MySQL处理数据类型和字符集的方式的更改 表维修或升级(mysqlcheck, mysql_upgrade) 重建表的方法： Dump and Reload ALTER TABLE REPAIR TABLE Dump and Reload Method 由于MySQL升级/降级之后，不同版本的MySQL无法处理这些表，则需要转储和重载的方法来重建表。 mysqldump -uroot -p --all-databases --force \u003e mysql_backdb.sql mysql -uroot -p --force \u003c mysql_backdb.sql #某个库或表 mysqldump -uroot -p --databases test --force \u003e db_test.sql mysql -uroot -p test \u003c db_test.sql mysqldump -uroot -p --databases test --tables table222 \u003e table222.sql mysql -uroot -p test \u003c table222.sql ALTER TABLE Method 更改表以使用它已经拥有的存储引擎。 ALTER TABLE test ENGINE = InnoDB; REPAIR TABLE Method REPAIR TABLE仅适用于MyISAM， ARCHIVE和 csv 表。 mysqlcheck --repair提供了对REPAIR TABLE的命令行访问。 REPAIR TABLE t1; mysqlcheck --repair --databases db_name ... mysqlcheck --repair --all-databases \r","date":"2018-01-16","objectID":"/mysql/:11:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"复制MySQL数据库到其他机器 Copying MySQL Databases to Another Machine 在需要为不同体系架构之间传输MySQL数据库时，可使用mysqldump创建包含SQL语句的.sql文件，然后复制到另外的计算机上，将其作为输入提供给MySQL客户端。 不要忘记复制mysql数据库，因为这个存储授权表的地方。 mysqldump --host 'remote-host' -uxxx -p --compress --all-databases | mysql -uxxx -p mysqldump --host 'remote-host' -uxxx -p --compress db_name | mysql -uxxx -p db_name mysqladmin -uxxx -p flush-privileges \r\r \rTutorial 如何使用MySQL client程序来创建和使用数据库。 ","date":"2018-01-16","objectID":"/mysql/:11:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"连接和断开服务器 Connecting to and Disconnecting from the Server Like this: 不建议把密码直接写在命令行上 host表示了MySQL Server运行在的机器 某些MySQL允许匿名用户连接 -ppassword, not as -p password mysql --host host --user username -p #maybe not default port mysql --host host --user username -p --port port #匿名用户连接 mysql #退出 mysql\u003e QUIT #Unix mysql\u003e Ctrl+D \r\r","date":"2018-01-16","objectID":"/mysql/:12:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"输入查询 Entering Queries #简单查询mysql\u003eSELECTVERSION(),CURRENT_DATE;#简单计算SELECTSIN(PI()/2),(4+1)*5;#一行中输入多个语句SELECTVERSION();SELECTNOW();#多行输入一个命令mysql\u003eSELECT-\u003eUSER()-\u003e,-\u003eCURRENT_DATE; 这QUERY说明了有关MySQL的几件事： MySQL查询通常由一个SQL statement和;组成 MySQL将查询发送给服务器并返回结果，然后打印下一个mysql\u003e提示 MySQL以表格形式(rows and columns)显示查询输出 MySQL显示返回多少行，以及执行查询花费了多长时间 MySQL查询不区分大小写，但建议使用大写 MySQL支持在一行中输入多个语句 MySQL支持一个命令多行输入 MySQL提示符： Prompt | Meaning | - mysql\u003e | 准备新查询 -\u003e | 等待多行查询的下一行 '\u003e | 等待下一行，等待单引号开头的字符串的完成 \"\u003e | 等待下一行，等待双引号字开头的字符串的完成 \\\u003e | 等待下一行，等待以反引号开始的标识符的完成\r/\u003e | 等待下一行，等待以/开头的注释的完成--\u003e/comments/` \r","date":"2018-01-16","objectID":"/mysql/:13:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"创建和使用数据库 Creating and Using a Database 大致操作： Create a database Create a table Load data into the table Retrieve data from the table in various ways Use multiple tables #显示数据库#不能显示你没有权限的数据库mysql\u003eSHOWDATABASES;#mysql数据库描述用户访问权限#test数据库通常作为用户尝试使用工作区#访问数据库mysql\u003eUSEtest;#USE和QUIT一样可以不使用分号，使用也无妨#USE只能是一个单行#授权#GRANTALLONda_name.tableTO'username'@'host';mysql\u003eGRANTALLONtest.*TO'test'@'127.0.0.1'; \r","date":"2018-01-16","objectID":"/mysql/:14:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"创建和选择数据库 Creating and Selecting a Database Unix是区分大小写的(case-sensitive)，这与SQL keyword不一致。请注意。 mysql\u003eCREATEDATABASEdb01;mysql\u003eUSEdb01;#也可在mysql连接时直接指定数据库mysql-uusername-pdb01#查看当前选择的数据库mysql\u003eSELECTDATABASE(); \r\r","date":"2018-01-16","objectID":"/mysql/:14:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"创建表 Creating a Table 困难的部分是决定数据库的结构应该是什么： 你需要哪些表以及每个表中应该包含哪些列。 VARCHAR对于name，owner，species来说是一个不错的选择，因为column值的长度有所不同。 DATE对于出生和死亡column来说很不错。 如果以后你发现你需要更长的字段，MySQL提供了一个ALTER TABLE语句来修改。 #创建一个宠物表mysql\u003eCREATETABLEpet(nameVARCHAR(20),ownerVARCHAR(20),-\u003especiesVARCHAR(20),sexCHAR(1),birthDATE,deathDATE);mysql\u003eSHOWTABLES;#验证表格#如果你忘记了表中列的名称或类型，使用DESCRIBEmysql\u003eDECRIBEpet;+---------+-------------+------+-----+---------+-------+ |Field|Type|Null|Key|Default|Extra|+---------+-------------+------+-----+---------+-------+ |name|varchar(20)|YES||NULL|||owner|varchar(20)|YES||NULL|||species|varchar(20)|YES||NULL|||sex|char(1)|YES||NULL|||birth|date|YES||NULL|||death|date|YES||NULL||+---------+-------------+------+-----+---------+-------+ 6rowsinset(0.00sec) \r\r","date":"2018-01-16","objectID":"/mysql/:14:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"将数据载入表格 Loading Data into a Table 假设pet表信息如下： name | owner | species | sex | birth | death | - | - | - | - PetA | Aa | cat | f | 1993-02-04 | PetB | Bb | cat | m | 1994-03-17 | PetC | Cc | dog | f | 1989-05-13 | PetD | Aa | dog | m | 1979-08-25 | 1995-02-21 PetE | Cc | bird | | 1991-02-17 | 你可以创建一个pet.txt文本文件，每行包含一个记录，值由制表符分割，并按照CREATE TABLE语句中列出的顺序给出。 vim pet.txt PetA Aa cat f 1993-02-04 \\N PetB Bb cat m 1994-03-17 \\N PetC Cc dog f 1989-05-13 \\N PetD Aa dog m 1979-08-25 1995-02-21 PetE Cc bird \\N 1991-02-17 \\N 将pet.txt载入pet表中： mysql\u003eLOADDATALOCALINFILE'/path/file.txt'INTOTABLEtable_name;mysql\u003eLOADDATALOCALINFILE'/home/zhang/pet.txt'INTOTABLEpet;QueryOK,5rowsaffected,0warnings(0.00sec)Records:5Deleted:0Skipped:0Warnings:0mysql\u003eSELECT*FROMpet;+-------+-------+---------+------+------------+------------+ |name|owner|species|sex|birth|death|+-------+-------+---------+------+------------+------------+ |PetA|Aa|cat|f|1993-02-04|NULL||PetB|Bb|cat|m|1994-03-17|NULL||PetC|Cc|dog|f|1989-05-13|NULL||PetD|Aa|dog|m|1979-08-25|1995-02-21||PetE|Cc|bird|NULL|1991-02-17|NULL|+-------+-------+---------+------+------------+------------+ 5rowsinset(0.00sec)#通过命令行载入mysql\u003eINSERTINTOpet-\u003eVALUES('PetF','Ff','hamster','f','1999-03-21',NULL)-\u003e;QueryOK,1rowaffected(0.00sec) \r\r","date":"2018-01-16","objectID":"/mysql/:14:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"从表中检索信息 Retrieving Information from a Table SELECT语句用于从表中提取信息： SELECTwhat_to_selectFROMwhich_tableWHEREcondition; 查询所有数据 Selecting All Data mysql\u003eSELECT*FROMpet;mysql\u003eDELETEFROMpet;mysql\u003eUPDATEpetSETbirth='1989-06-17'WHEREname='PetC'; 查询特定行 Selecting Particular Rows 当一个表很大时，你通常不想看到整个表。 #条件查询mysql\u003eSELECT*FROMpetWHEREname='PetA';mysql\u003eSELECT*FROMpetWHEREowner='Cc';mysql\u003eSELECT*FROMpetWHEREbirth\u003e='1990-01-01';#ANDmysql\u003eSELECT*FROMpetWHEREspecies='dog'ANDsex='f';#ORmysql\u003eSELECT*FROMpetWHEREspecies='dog'ORspecies='bird';#AND和OR也可以混合使用mysql\u003eSELECT*FROMpetWHERE(species='cat'ANDsex='m')OR(species='dog'ANDsex='f'); 查询特定列 Selecting Particular Columns mysql\u003eSELECTnameFROMpet;mysql\u003eSELECTname,speciesFROMpet;#获取唯一结果mysql\u003eSELECTDISTINCTspeciesFROMpet;+---------+ |species|+---------+ |cat||dog||bird|+---------+ 3rowsinset(0.00sec)mysql\u003eSELECTname,species,birthFROMpetWHEREspecies='dog'ORspecies='cat'; 行排序 Sorting Rows 使用ORDER BY语句对结果进行排序。默认排序顺序是升序。 mysql\u003eSELECTname,birthFROMpetORDERBYbirth;+------+------------+ |name|birth|+------+------------+ |PetD|1979-08-25||PetC|1989-06-17||PetE|1991-02-17||PetA|1993-02-04||PetB|1994-03-17|+------+------------+ 5rowsinset(0.00sec)#倒序mysql\u003eSELECTname,birthFROMpetORDERBYbirthDESC; 可对多列进行排序，也可按不同的方向对不同的列进行排序。 mysql\u003eSELECTname,species,birthFROMpet-\u003eORDERBYspecies,birthDESC;+------+---------+------------+ |name|species|birth|+------+---------+------------+ |PetE|bird|1991-02-17||PetB|cat|1994-03-17||PetA|cat|1993-02-04||PetC|dog|1989-06-17||PetD|dog|1979-08-25|+------+---------+------------+ 5rowsinset(0.00sec)mysql\u003eSELECTname,species,birthFROMpet-\u003eORDERBYspeciesDESC,birthDESC 日期计算 Date Calculations MySQL提供了几个函数用于日期计算。如计算年龄或提取日期一部分等。 TIMESTAMPDIFF() 使用TIMESTAMPDIFF()函数计算pet的年龄。它的两个参数为两个相隔的日期 mysql\u003eSELECTname,species,birth,CURDATE(),-\u003eTIMESTAMPDIFF(YEAR,birth,CURDATE())ASage-\u003eFROMpet-\u003eORDERBYageDESC;+------+---------+------------+------------+------+ |name|species|birth|CURDATE()|age|+------+---------+------------+------------+------+ |PetD|dog|1979-08-25|2018-03-01|38||PetC|dog|1989-06-17|2018-03-01|28||PetE|bird|1991-02-17|2018-03-01|27||PetA|cat|1993-02-04|2018-03-01|25||PetB|cat|1994-03-17|2018-03-01|23|+------+---------+------------+------------+------+ 5rowsinset(0.00sec)#死去的pet的agemysql\u003eSELECTname,species,birth,death,-\u003eTIMESTAMPDIFF(YEAR,birth,death)ASage-\u003eFROMpet-\u003eWHEREdeathISNOTNULL-\u003eORDERBYage;+------+---------+------------+------------+------+ |name|species|birth|death|age|+------+---------+------------+------------+------+ |PetD|dog|1979-08-25|1995-02-21|15|+------+---------+------------+------------+------+ 1rowinset(0.00sec) YEAR() 年 MONTH() 月 DAYOFMONTH() 日 mysql\u003eSELECTname,birth,-\u003eYEAR(birth)ASbir_year,-\u003eMONTH(birth)ASbir_month,-\u003eDAYOFMONTH(birth)ASbir_day-\u003eFROMpet;+------+------------+----------+-----------+---------+ |name|birth|bir_year|bir_month|bir_day|+------+------------+----------+-----------+---------+ |PetA|1993-02-04|1993|2|4||PetB|1994-03-17|1994|3|17||PetC|1989-06-17|1989|6|17||PetD|1979-08-25|1979|8|25||PetE|1991-02-17|1991|2|17|+------+------------+----------+-----------+---------+ 5rowsinset(0.00sec)#查找生日是2月的petmysql\u003eSELECTname,birthFROMpetWHEREMONTH(birth)=2;+------+------------+ |name|birth|+------+------------+ |PetA|1993-02-04||PetE|1991-02-17|+------+------------+ DATE_ADD() 将日期间隔添加到给定日期 mysql\u003eSELECTname,birthFROMpet-\u003eWHEREMONTH(birth)=MONTH(DATE_ADD(CURDATE(),INTERVAL1MONTH)); 使用NULL值 Working with NULL Values 从概念上讲，NULL value意味着一个缺失的未知值，它与其它值在某种程度上是不同的。 使用IS NULL和IS NOT NULL操作符 不能对NULL value使用算术运算符(arithmetic cpmparison operators) 如：=, \u003c, \u003e, \u003c\u003e 任何对NULL value的算术运算符的结果也是NULL value，所以无法得到有意义的结果 在MySQL中，0或NULL表示false，其他任何值都意味着true 两个NULL在GROUP BY中被认为是相等的 NULL在ORDER BY正向排序中首先显示。反之，最后显示 mysql\u003eSELECT1ISNULL,1ISNOTNULL;+-----------+---------------+ |1ISNULL|1ISNOTNULL|+-----------+---------------+ |0|1|+-----------+---------------+ 因此，完全可以将一个zero或empty string插入到一个NOT NULL的column中，因为这些值NOT NULL。 模式匹配 Pattern Matching MySQL提供标准的SQL模式匹配以及基于扩展正则表达式的模式匹配形式。类似于Unix实用程序(vi, grep, sed…) S","date":"2018-01-16","objectID":"/mysql/:14:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"获取数据库和表的信息 Getting Information About Databases and Tables 查看当前数据库 mysql\u003e SELECT DATABASE(); 查看当前数据库下的表 mysql\u003e SHOW TABLES; 查看表的结构 mysql\u003e DESCRIBE pet; 创建数据库 mysql\u003e CREATE DATABASE db_01; 创建表 mysql\u003e CREATE TABLE table_01 {c1 VARCHAR(10), c2 INT, ...}; 查看索引(如果存在) SHOW INDEX FROM table_01; \r\r","date":"2018-01-16","objectID":"/mysql/:15:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"在批处理下使用mysql Using mysql in Batch Mode 在前面，我们都是使用MySQL交互式(interactively)输入命令并查看结果。但还可在批处理模式下运行MySQL。 我们可以创建一个脚本文件，然后以这种方式执行脚本文件。 mysql \u003c batch-file msyql -h host -u user -p \u003c /path/batch-file #出现错误也继续运行 msyql -h host -u user -p --force \u003c /path/batch-file 为什么要使用脚本： 如果需要反复(repeat)执行查询，将其写入脚本以避免每次执行时重新输入查询 通过复制和修改脚本文件从现有查询中生成新的查询 批处理模型在开发查询时也很有用，特别是对于多行语句。写错了直接修改脚本就好，而不必重新输入 如果查询产生大量输出，可通过传呼机而不是翻滚到屏幕的最上方 mysql \u003c batch-file | more 可以把输出捕获到一个文件中 mysql \u003c batch-file \u003e mysql.out 可将脚本文件分发给其他人 批处理模式下的MySQL输出更简洁 可使用mysql -t获得交互式数据格式 使用mysql -v将执行语句回显 在mysql命令行中载入脚本 mysql\u003e source filename; 或’mysql\u003e . filename; \r","date":"2018-01-16","objectID":"/mysql/:16:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"常见查询 Examples of Common Queries \r 在命令行使用mysql并选择数据库 mysql db_name -u user -p 创建和填充表 CREATETABLEshop(articleINT(4)UNSIGNEDZEROFILLDEFAULT'0000'NOTNULL,dealerCHAR(20)DEFAULT''NOTNULL,priceDOUBLE(16,2)DEFAULT'0.00'NOTNULL,PRIMARYKEY(article,dealer));INSERTINTOshopVALUES(1,'A',3.45),(1,'B',3.99),(2,'A',10.99),(3,'B',1.45),(3,'C',1.69),(3,'D',1.25),(4,'D',19.95); 查看表内容 SELECT*FROMshop; 列的最大值(maximum) SELECTMAX(article)ASarticleFROMshop;SELECTarticle,MAX(price)ASpriceFROMshopGROUPBYarticle; 使用用户定义的变量(user-defined variables) mysql\u003eSELECT@min_price:=MIN(price),@max_price:=MAX(price)FROMshop;mysql\u003eSELECT*FROMshopWHEREprice=@min_priceORprice=@max_price; 使用外键(Foreign Keys) 在MySQL中，InnoDB表支持检查外键约束。 外键约束不仅仅需要连接两个表。 CREATETABLEperson(idSMALLINTUNSIGNEDNOTNULLAUTO_INCREMENT,nameCHAR(60)NOTNULL,PRIMARYKEY(id));CREATETABLEshirt(idSMALLINTUNSIGNEDNOTNULLAUTO_INCREMENT,styleENUM('t-shirt','polo','dress')NOTNULL,colorENUM('red','blue','orange','white','black')NOTNULL,ownerSMALLINTUNSIGNEDNOTNULLREFERENCESperson(id),PRIMARYKEY(id));INSERTINTOpersonVALUES(NULL,'Antonio Paz');SELECT@last:=LAST_INSERT_ID();INSERTINTOshirtVALUES(NULL,'polo','blue',@last),(NULL,'dress','white',@last),(NULL,'t-shirt','blue',@last);INSERTINTOpersonVALUES(NULL,'Lilliana Angelovska');SELECT@last:=LAST_INSERT_ID();INSERTINTOshirtVALUES(NULL,'dress','orange',@last),(NULL,'polo','red',@last),(NULL,'dress','blue',@last),(NULL,'t-shirt','white',@last); 在两个键上查找(Searching on Two Keys) SELECTfield1_index,field2_indexFROMtest_tableWHEREfield1_index='1'ORfield2_index='1' 使用自动增量 AUTO_INCREMENT属性能够为新行生成一个唯一的标识符。 CREATETABLEanimals(idMEDIUMINTNOTNULLAUTO_INCREMENT,nameCHAR(30)NOTNULL,PRIMARYKEY(id));INSERTINTOanimals(name)VALUES('dog'),('cat'),('penguin'),('lax'),('whale'),('ostrich');#设置指定增量开始值mysql\u003eALTERTABLEtblAUTO_INCREMENT=100; \r \rMySQL程序 ","date":"2018-01-16","objectID":"/mysql/:17:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL程序概述 Overview of MySQL Programs MySQL安装中有多个不同的程序： mysqld SQL daemon, MySQL Server, mysqld是执行大部分工作的主要程序 mysqld_safe 服务器启动脚本 mysqld_safe尝试去启动mysqld mysql.server 服务器启动脚本 此脚本用于System V系统，包含启动特定运行级别的系统服务脚本 它调用mysqld_safe来启动MySQL Server mysql_multi 可启动和关闭安装在系统上的多个服务器的启动脚本 comp_err 在MySQL build/installation过程中使用 从错误源文件中编译错误消息文件 mysql_install_db 初始化MySQL(数据目录，授权表，并设置InnoDB系统表空间) 通常用于首次安装MySQL时 mysql_plugin 配置MySQL Server插件 mysql_secure_installation 能够提高MySQL安装的安全性 mysql_ssl_rsa_setup 如果这些文件丢失，该程序会创建支持安全连接所需的SSL证书和密钥文件以及RSA密钥对文件 mysql_tzinfo_to_sql 从mysql数据库中加载时区表 mysql_upgrade 在MySQL升级操作后使用 它检查表的不兼容性并在必要时修复它们，并用更新版的MySQL的任何更改来更新授权表 mysql 交互式输入SQL语句的命令行工具 或执行一个批处理模式的文件 mysqladmin 执行管理操作的客户端 如创建或删除数据库，重新加载授权表，刷新表的磁盘… 也可用获取服务器版本、状态、进程信息 mysqlcheck 表格客户端 用于检查、修复、分析和优化表格 mysqldump 将MySQL数据库转储为SQL、文本或XML文件的客户端 mysqlimport 使用LOAD DATA INFILE将文本文件导入各自表格的客户端 mysqlpump 将MySQL数据库转转储为SQL文件的客户端 mysqlsh 用于MySQL Server的高级命令行客户端和代码编辑器 除了SQL外，MySQL Shell还为JS和Python提供了脚本功能 mysqlshow 显示有关数据库、表、列和索引的信息的客户端 mysqlslap 用于模拟MySQL Server的客户端负载并报告每个阶段的时间 MySQL管理和实用程序： innochecksum InnoDB脱机文件校验和程序 myisam_ftdump 在MyISAM表中显示有关全文索信息 myisamchk 描述，检查，优化和修复MyISAM表 myisamlog 处理MyISAM日志文件 myisampack 压缩MyISAM表以生成更小的只读表 mysql_config_editor 能够将认证凭证存储在名为安全的加密登录路径文件中 mysqlbinlog 从二进制日志中读取语句 mysqldumpslow 读取和总结慢查询日志内容 MySQL程序开发实用程序： mysql_config 一个shell脚本，用于在编译MySQL程序是生产所需的选项值 my_print_defaults： 显示选项文件的选项组中存在哪些选项 resolve_stack_dump 将数值堆栈跟踪转储解析为符号 杂项(Miscellaneous)工具： lz4_decompress 解压缩使用LZ4压缩格式的mysqldump输出 perror 显示系统或MySQL错误代码含义 replace 再输入文本中执行字符串替换 resolveip 将主机名解析为IP地址，反之亦然 zlib_decompress 解压缩使用ZLIB压缩格式的mysqldump输出 Oracle公司还提供了MySQL Workbench GUI工具，用于管理、创建、知悉和评估查询，以及从其它关系数据库管理系统迁移到MySQL系统。 MySQL Client和Server间的通信使用如下环境变量： Environment Variable Meaning MYSQL_UNIX_PORT The default Unix socket file; used for connections to localhost MYSQL_TCP_PORT The default port number; used for TCP/IP connections MYSQL_PWD The default password, insecure MYSQL_DEBUG Debug trace options when debugging TMPDIR The directory where temporary tables and files are created \r\r","date":"2018-01-16","objectID":"/mysql/:18:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用MySQL程序 ","date":"2018-01-16","objectID":"/mysql/:19:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"调用MySQL程序 从命令行调用一个MySQL程序，输入程序名称和选项及参数。 $ mysql --user=root test $ mysqladmin extended-status variables $ mysqlshow --help $ mysqldump -u root personnel \r\r","date":"2018-01-16","objectID":"/mysql/:19:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"连接到MySQL Server 介绍如何连接到MySQL Server。 MySQL程序环境变量的优先级最低，命令行选项最高。你可在配置文件中指定程序的默认值，同时你又可以使用命令行选项覆盖它。 MySQL选项按顺序处理，所以如果多次指定选型，则最后一个选项优先。 mysql --hostname xx --port xx --user xx --password ${dbname} --protocol=TCP mysql -h -P -u -p ${dbname} --protocol值： TCP(all) SOCKET(Unix) PIPE(windows) MEMORY(windows) 你可以在选项文件的[client]部分指定连接参数: [client] host=xxx port=xxx user=xxx password=xxx mysqladmin -u user -p --count=1k --sleep=10 ping mysql -u user -pxxx --execute=\"DESCRIBE db.table\" #执行多个语句 mysql -u root -p -e 'SELECT VERSION(); SELECT NOW()' \r\r","date":"2018-01-16","objectID":"/mysql/:19:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"配置文件 大多数MySQL程序都可从选项文件中读取启动选项。 MySQL不保证配置文件的读取顺序。 Unix和Unix-Like平台的MySQL配置文件： 文件 描述 /etc/my.cnf 全局选项 /etc/mysql/my.cnf 全局选项 $SYSCONFDIR/my.cnf 全局选项 $MYSQL_HOME/my.cnf MySQL Server Only ~/.my.cnf 特定用户选项 ~/.mylogin.cnf 特定用户登录选项，Client Only default-extra-file 使用--defaults-extra-file指定的文件 配置文件解释： 空行被忽略 #号表示注释 前后空格将自动从选项名称和值中删除 [group] 为其设置配置项的程序名或组名。在此之后，任何选项设置都会应用到指定组，知道给出结尾。选项组名称不区分大小写。 你可在选项值中使用转义序列 \\b, \\t, \\n, \\r, \\\\, \\s !include来包含其它配置文件 DATADIR mysqld --datadir [mysqld] port=3306 socket=/tmp/mysql.sock key_buffer_size=16M max_allowed_packet=8M [mysql] port=3306 socket=/tmp/mysql.sock no-auto-rehash [mysqldump] quick !include /home/mysql/myopt.cnf 影响配置文件的命令行选项 --print-defaults --defaults-extra-file --defaults-file --defaults-group-suffix --login-path --no-defaults 使用选项指定环境变量 [mysql] max_allowed_packet=16M [mysqld] key_buffer_size=512M mysql --max_allowed_packet=16M shell\u003e mysql --max_allowed_packet=16*1024*1024 mysql\u003e SET GLOBAL max_allowed_packet=16*1024*1024; \r\r","date":"2018-01-16","objectID":"/mysql/:19:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL Server mysqld The MySQL Server mysql_safe MySQL Server Startup Script mysql.server MySQL Server Startup Script mysqld_multi Manage Multiple MySQL Servers \r","date":"2018-01-16","objectID":"/mysql/:20:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"mysqld mysqld，也被称为MySQL服务器，是执行MySQL大部分工作的主要程序。MySQL服务器管理对包含数据库和表的MySQL数据目录的访问。 查看帮助： mysqld --verbose --help \r","date":"2018-01-16","objectID":"/mysql/:20:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"mysql_safe 对于某些Linux平台，从RPM或DBP包安装的MySQL包括了用于管理MySQL服务启动和管理的systemd支持。在这些平台上，mysqld_safe不会被安装，因为它不是必须的。 mysql_safe是Unix上启动mysqld服务器的推荐方式。它添加了一些安全特性，如发生错误是重启服务器并将运行时的错误记录到日志。 mysqld_safe尝试启动一个名为mysqld的可执行程序。它会读取配置文件中[mysqld], [server], [mysqld_safe]部分的所有选项。 mysqld_safe选项： --basedir --core-file-size --datadir --defaults-extra-file --defaults-file --ledir --log-error --mallocl-lib --mysqld --mysqld-safe-login-timestamps --mysql-version --nice --no-defaults --open-files-limit --pid-file --plugin-dir --plugin-dir --port --skip-kill-mysqld --skip-syslog --socket --syslog-tag --timezone --user \r\r","date":"2018-01-16","objectID":"/mysql/:20:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"mysql.server 对于某些Linux平台，从RPM和DPG包安装的MySQL包括了用于管理MySQL Server启动和关闭的systemd支持。在这些平台上，没有安装mysql.server和mysqld_safe，因为它们不是必须的。 Unix和Unix-Like平台上的MySQL发行版包含一个名为mysql.server的脚本，该脚本使用mysqld_safe启动MySQL Server。 \r\r","date":"2018-01-16","objectID":"/mysql/:20:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"mysqld_multi 对于某些Linux平台，从RPM和DPG包安装的MySQL包括了用于管理MySQL Server启动和关闭的systemd支持。在这些平台上，没有安装mysqld_multi，因为它们不是必须的。 mysqld_multi设计用于管理多个监听不同Unix socket文件和TCP/IP port上连接的mysqld进程。 \r\r","date":"2018-01-16","objectID":"/mysql/:20:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL安装相关程序 这些程序用于安装或升级MySQL！ com_err Compile MySQL Error Message File mysql_install_db Initialize MySQL Data Directory mysql_plugin Configure MySQL Server Plugins mysql_secure_installation Improve MySQL Installation Security mysql_ssl_rsa_setup Create SSL/RSA Files mysql_tzinfo_to_sql Load the Time Zone Tables mysql_upgrade Check and Upgrade MySQL Tables \r","date":"2018-01-16","objectID":"/mysql/:21:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"com_err comp_err创建errmsg.sys文件，mysqld使用此文件来确定为不同错误代码(error code)显示错误消息。通常，在构建MySQL时，comp_err会自动运行。它从位于MySQL源发行版sq;/share/errmsg-utf8.txt文本文件汇编errmsg.sys文件。 comp_err同样会生成mysqld_error.h, mysqld_ername.h, sql_state.h头文件。 \r\r","date":"2018-01-16","objectID":"/mysql/:21:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"mysql_install_db 在MySQL5.7中，由于mysql_install_db的功能已经被集成到mysqld中，因此不推荐使用它。 在MySQL5.7.5之前，mysql_install_db是一个Perl脚本并依赖于Perl。在此之后，它是由C++写的可执行二进制文件。还有一些选项的更迭。 mysqld --initailize #or mysqld --initialize-insecure mysql_install_db处理在MySQL Server(mysqld)准备好使用之前，必须执行的初始化任务： 初始化MySQL数据目录，创建它包含的系统表 初始化管理InnoDB表所需的system tablespace和相关数据结构 加载服务器端help表 安装sys schema 创建一个管理员账户 老版本的mysql_install_db可能会创建匿名账户。 如果mysql_install_db生成了一个随机管理员密码，它将把此密码写入文件并显示此文件名。密码包含一个时间戳以指示它的写入时间。 默认情况下，该文件是用户主目录中的.mysql_secret文件。 \r\r","date":"2018-01-16","objectID":"/mysql/:21:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"mysql_plugin 从MySQL5.7.11开始，不推荐使用mysql_plugin，并会在MySQL8.0中移除此功能。 使用如下命令替代： --plugin-load --plugin-load-add #或 mysql\u003e INSTALL PLUGIN mysql\u003e UNINSTALL PLUGIN mysql_plugin功能允许MySQL管理员管理由MySQL Server载入的插件。 \r\r","date":"2018-01-16","objectID":"/mysql/:21:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"mysql_secure_installation mysql_secure_installation通过以下方式来提高MySQL安装的安全性： 为root用户设置密码 删除可从本机外部访问的root账户 删除匿名账户 删除test数据库(默认情况下可由任何用户访问，包括匿名用户) 删除允许任何人访问以test_开头的数据库的权限 \r\r","date":"2018-01-16","objectID":"/mysql/:21:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"mysql_ssl_rsa_setup mysql_ssl_rsa_setup创建SSL证书和key文件和RSA key-pair文件，用于支持使用SSL进行安全连接。它生成的整数是自签名的，不太安全。请考虑从注册机构申请CA证书。 mysql_ssl_rsa_setup使用opensll命令，所以请安装OpenSSL。 \r\r","date":"2018-01-16","objectID":"/mysql/:21:5","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"mysql_tzinfo_to_sql mysql_tzinfo_to_sql加载MySQL数据库中的zone table。它使用系统上的zoneinfo信息。 \r\r","date":"2018-01-16","objectID":"/mysql/:21:6","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"msyql_upgrade mysql_upgrade检查数据库中的所有表与当前版本的MySQL Server的不兼容，它还升级系统表，以便你可以利用新权限和功能。 如果mysql_upgrade发现表有可能的不兼容性，它会执行检查表，如果发现问题，则会尝试修复表。 每次升级MySQL时都应该执行mysql_upgrade。 在执行upgrade之前，你应该始终备份你的MySQL。 \r\r","date":"2018-01-16","objectID":"/mysql/:21:7","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL客户端程序 mysql The MySQL Command-Line Tool mysqladmin Client for Administering a MySQL Server mysqlcheck A Table Maintenance Program mysqldump A Database Backup Program mysqlimport A Data Import Program mysqlpump A Database Backup Program mysqlsh The MySQL Shell mysqlshow Display Database, Table, and Column Information mysqlslap Load Emulation Client \r","date":"2018-01-16","objectID":"/mysql/:22:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"mysql mysql是一个具有输入编辑功能的SQL shell。 mysql--host= --port= --user= --password db_name #SQL文件#SQL语句以;或\\g或\\G结束mysqldb_name\u003cscript.sql\u003eoutput.tab \r","date":"2018-01-16","objectID":"/mysql/:23:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"mysql选项 MySQL支持很多选项。这些选项可以写入配置文件的[mysql]和[client]组中。 mysql --help \r\r","date":"2018-01-16","objectID":"/mysql/:23:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"mysql命令 mysql将你发出的每个SQL语句发送到要执行的Server。如下为mysql自己解释的命令： mysql\u003e help; List of all MySQL commands: Note that all text commands must be first on line and end with ';' ? (\\?) Synonym for `help'. charset clear (\\c) Clear the current input statement. connect (\\r) Reconnect to the server. Optional arguments are db and host. delimiter (\\d) Set statement delimiter. edit (\\e) Edit command with $EDITOR. ego (\\G) Send command to mysql server, display result vertically. exit (\\q) Exit mysql. Same as quit. go (\\g) Send command to mysql server. help (\\h) Display this help. nopager (\\n) Disable pager, print to stdout. notee (\\t) Don't write into outfile. pager (\\P) Set PAGER [to_pager]. Print the query results via PAGER. print (\\p) Print current command. prompt (\\R) Change your mysql prompt. quit (\\q) Quit mysql. rehash (\\#) Rebuild completion hash. source (\\.) Execute an SQL script file. Takes a file name as an argument. status (\\s) Get status information from the server. system (\\!) Execute a system shell command. tee (\\T) Set outfile [to_outfile]. Append everything into given outfile. use (\\u) Use another database. Takes database name as argument. charset (\\C) Switch to another charset. Might be needed for processing binlog with multi-byte charsets. warnings (\\W) Show warnings after every statement. nowarning (\\w) Don't show warnings after every statement. resetconnection(\\x) Clean session context. 修改MySQL提示符 #shell export MYSQL_PS1=\"(\\u@\\h) [\\d]\u003e \" #mysql mysql --prompt=\"(\\u@\\h) [\\d]\u003e \" #配置文件 [mysql] prompt=(\\\\u@\\\\h) [\\\\d]\u003e\\\\_ #mysql prompt mysql\u003e prompt (\\u@\\h) [\\d]\u003e\\_ \r\r","date":"2018-01-16","objectID":"/mysql/:23:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"mysql服务端帮助 mysql Server-Side Help 如果给help命令提供一个参数，mysql将其用作搜索字符串，以从MySQL参考手册的内容访问服务端帮助。 mysql\u003e help me mysql\u003e help contents mysql\u003e help logs mysql\u003e help rep% \r\r","date":"2018-01-16","objectID":"/mysql/:23:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"从文本文件执行SQL语句 mysql忽略文件开头的Unicode字节顺序标记(BOM)字符。BOM的存在不会导致MySQL更改其默认字符集(charset)。因此，请使用--default-char-set选项。 #shell mysql db_name \u003c test_file mysql\u003e source file_name mysql\u003e \\. file_name #显示进度信息 SELECT '\u003cinfo_to_display\u003e' AS ' '; \r\r","date":"2018-01-16","objectID":"/mysql/:23:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL管理和实用程序 inochecksum Offline InnoDB File Checksum Utility myisam_ftdump Display Full-Text Index information myisamchk MyISAM Table-Maintenance Utility myisamlog Display MyISAM Log File Contents myisampack Generate Compressed, Read-Only MyISAM Tables mysql_config_editor MySQL Configuration Utility mysqlbinlog Utility for Processing Binary Log Files mysqldumpslow Summarize Slow Query Log Files \r\r","date":"2018-01-16","objectID":"/mysql/:24:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"mysql开发实用程序 mysql_config Display Options for Compiling Clients my_print_defaults Display Options from Option Files resolve_stack_dump Resolve Numeric Stack Trace Dump to Symbols \r\r","date":"2018-01-16","objectID":"/mysql/:25:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"杂项程序 Miscellaneous Programs lz4_decompress Decompress mysqlpump LZ4-Compressed Output perror Explain Error Codes replace A String-Replacement Utility resolveip Resolve Host name to IP Address or Vice Versa zlib_decompress Decompress mysqlpump ZLIB-Compressed Output \r\r","date":"2018-01-16","objectID":"/mysql/:26:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL环境变量 这些环境变量直接或间接的被MySQL使用。 Variable Description AUTHENTICATION_LDAP_CLIENT_LOG Client-side LDAP authentication logging level. AUTHENTICATION_PAM_LOG PAM authentication plugin debug logging settings. CC The name of your C compiler (for running CMake). CXX The name of your C++ compiler (for running CMake). CC The name of your C compiler (for running CMake). DBI_USER The default user name for Perl DBI. DBI_TRACE Trace options for Perl DBI. HOME The default path for the mysql history file is $HOME/.mysql_history. LD_RUN_PATH Used to specify the location of libmysqlclient.so. LIBMYSQL_ENABLE_CLEARTEXT_PLUGIN Enable mysql_clear_password authentication plugin; see Section 6.5.1.6, “Client-Side Cleartext Pluggable Authentication”. LIBMYSQL_PLUGIN_DIR Directory in which to look for client plugins. LIBMYSQL_PLUGINS Client plugins to preload. MYSQL_DEBUG Debug trace options when debugging. MYSQL_GROUP_SUFFIX Option group suffix value (like specifying –defaults-group-suffix). MYSQL_HISTFILE The path to the mysql history file. If this variable is set, its value overrides the default for $HOME/.mysql_history. MYSQL_HISTIGNORE Patterns specifying statements that mysql should not log to $HOME/.mysql_history, or syslog if –syslog is given. MYSQL_HOME The path to the directory in which the server-specific my.cnf file resides. MYSQL_HOST The default host name used by the mysql command-line client. MYSQL_OPENSSL_UDF_DH_BITS_THRESHOLD Maximum key length for CREATE_DH_PARAMETERS(). See Section 12.18.2, “Enterprise Encryption Usage and Examples”. MYSQL_OPENSSL_UDF_DSA_BITS_THRESHOLD Maximum DSA key length for CREATE_ASYMMETRIC_PRIV_KEY(). See Section 12.18.2, “Enterprise Encryption Usage and Examples”. MYSQL_OPENSSL_UDF_RSA_BITS_THRESHOLD Maximum RSA key length for CREATE_ASYMMETRIC_PRIV_KEY(). See Section 12.18.2, “Enterprise Encryption Usage and Examples”. MYSQL_PS1 The command prompt to use in the mysql command-line client. MYSQL_PWD The default password when connecting to mysqld. Using this is insecure. See Section 6.1.2.1, “End-User Guidelines for Password Security”. MYSQL_TCP_PORT The default TCP/IP port number. MYSQL_TEST_LOGIN_FILE The name of the .mylogin.cnf login path file. MYSQL_TEST_TRACE_CRASH Whether the test protocol trace plugin crashes clients. See note following table. MYSQL_TEST_TRACE_DEBUG Whether the test protocol trace plugin produces output. See note following table. MYSQL_UNIX_PORT The default Unix socket file name; used for connections to localhost. MYSQLX_TCP_PORT The X Plugin default TCP/IP port number. MYSQLX_UNIX_PORT The X Plugin default Unix socket file name; used for connections to localhost. PATH Used by the shell to find MySQL programs. PKG_CONFIG_PATH Location of mysqlclient.pc pkg-config file. See note following table. TMPDIR The directory in which temporary files are created. TZ This should be set to your local time zone. See Section B.5.3.7, “Time Zone Problems”. UMASK The user-file creation mode when creating files. See note following table. UMASK_DIR The user-directory creation mode when creating directories. See note following table. USER The default user name on Windows when connecting to mysqld. \r\r \rMySQL Server管理 ","date":"2018-01-16","objectID":"/mysql/:27:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL Server mysqld is the MySQL Server. 并非所有的MySQL Server二进制文件和配置都支持所有的存储引擎。 #查看帮助 mysqld --verbose --help #运行Server的环境变量 mysql\u003e SHOW VARIABLES; #运行Server的状态 mysql\u003e SHOW STATUS; \r\r","date":"2018-01-16","objectID":"/mysql/:28:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL数据目录 由MySQL管理的信息存储在称为数据目录的目录下。 数据目录子目录：每个子目录都是数据库目录对应于Server管理的数据库 mysql performance_schema sys 数据库 日志文件由Server写入 innoDB表空间和日志文件 自动生成的SSL/RSA证书和密钥文件 Server PID \r\r","date":"2018-01-16","objectID":"/mysql/:29:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"mysql数据库 The mysql System Database The mysql database is the system database.它的表中存储了MySQL Server运行时需要的信息。 授权系统表 如下这些系统表包含了用户账户和权限的授权信息。 user User accounts, global privileges, and other non-privilege columns. db Database-level privileges. tables_priv Table-level privileges. columns_priv Column-level privileges. procs_priv Stored procedure and function privileges. proxies_priv Proxy-user privileges. 对象信息系统表 如下这些系统表包含了存储程序，用户定义函数和服务器端插件的信息。 event 关于Event Scheduler事件的信息 func 用户定义函数的信息 plugin 服务器端的插件的信息 proc 有关存储过程和函数的信息 日志系统表 Server使用如下系统表记录日志。日志表使用CSV存储引擎。 general_log 一般查询日志表 slow_log 慢查询日志表 服务器端帮助系统表 如下系统表包含了服务器端帮助信息。 help_category Information about help categories. help_keyword Keywords associated with help topics. help_relation Mappings between help keywords and topics. help_topic Help topic contents. 时区系统表 如下系统表包含了时区信息。 time_zone Time zone IDs and whether they use leap seconds. time_zone_leap_second When leap seconds occur. time_zone_name Mappings between time zone IDs and names. time_zone_transition, time_zone_tansition_type Time zone descriptions. 副本系统表 Server使用如下这些系统表来提供副本服务。这些表使用InnoDB存储引擎。 gtid_executed Table for storing GTID values. ndb_binlog_index Binary log information for NDB Cluster replication. slave_master_info, slave_relay_log_info, slave_worker_info Used to store replication information on slave servers. 优化器系统表 如下系统表用于优化。 innodb_index_stats, innodb_table_stats Used for InnoDB persistent optimizer statistics server_cost, engine_cost The optimizer cost model uses tables that contain cost estimate information about operations that occur during query execution. 杂项系统表 audit_log_filter, audit_log_user firewall_users, firewall_whitelist servers \r\r","date":"2018-01-16","objectID":"/mysql/:30:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL Server Logs MySQL Server提供如下几种日志： Error log 启动、运行或停止mysqld遇到的问题 General query log 建立Client连接和从Client收到的语句 Binary log 更改数据的语句 Relay log 从replication master server收到的数据更改 Slow query log 执行时间超过long_query_time秒的查询 DDL(Metadata) log 由DDL语句执行的元数据操作 默认情况下，不启用任何日志。 如果启用了这些日志，MySQL Server可以灵活地控制一般查询日志和慢查询日志的输出目的地——它可为日志文件或mysql数据库中的general_log和slow_log表。 #--log-output #它的值可为TABLE/FILE/NONE #--general-log, --slow-query-log #TABLE和FILE mysqld --log-output=TABLE,FILE --general-log=msyql.general_log --slow-query-log=mysql.slow_log #or [mysqld] log_output= general_log= slow_query_log= 查看两个日志表的标准格式： SHOW CREATE TABLE mysql.general_log; SHOW CREATE TABLE mysql.slow_log; \r\r","date":"2018-01-16","objectID":"/mysql/:31:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"错误日志 The Error Log 错误日志包含mysqld启动和关闭时间的记录。它还包含诊断信息。 Unix/Unix-Like OS 使用mysqld --log-error选项来将错误日志写入控制台(stderr)或文件。 如果未指定文件名，则默认为数据目录下的host_name.err文件。 YUM或APT包安装，则配置的错误日志文件为--log-error=/var/log/mysqld.log。 将错误日志记录到系统日志 Error Logging to the System Log 使用如下系统变量： log_syslog 启用此变量将错误日志发送到系统日志 log_syslog_facility syslog消息的默认设置时daemon。设置此变量以指定其它工具。 log_syslog_include_pid 是否在syslog输出中包含Server的PID。 log_syslog_tag 在syslog消息中添加一个tag。 msyqld --log_syslog= 错误日志过滤 Error Log Filtering log_error_verbosity变量控制错误日志的详细程度。值如下： 1 error only 2 errors, warning 3(默认) errors, warnings, notes 错误日志消息格式 Error Log Message Format 错误日志中包含的ID是mysqld中负责编写消息的线程的ID。这表示Server的哪部分生成了消息。 log_timestamps变量控制写入错误日志的时区和时间格式。 mysqld --log-timestamps= 错误日志文件刷新 Error Log File Flushing and Renaming 如果你使用FLUSH_ERROR_LOGS, FLUSH_LOGS或mysqladmin flush-logs刷新日志，Server将关闭并重新打开它正在写的任何错误日志文件。 mv host_name.err host_name.err-old mysqladmin flush-logs \r\r","date":"2018-01-16","objectID":"/mysql/:31:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"一般查询日志 The General Query Log 一般查询日志是mysqld执行操作的记录。当Client连接或断开时，Server将此信息写入日志，并记录从Client收到的每个SQL语句。 mysqld按照接收的顺序而不是执行顺序将语句写入日志。 默认情况下，一般查询日志是禁用的。 指定初始化查询日志状态--general_log={0|1}。1启用，0禁用。 指定日志文件名--general-log-file=file-name.如果未指定，默认为数据目录下host_name.log，除非指定了其它路径。 指定日志文件位置--log-output=. mysqld --log-output='/var/log/mysql' --general-log=1 --general-log-file='general.log' shell\u003e mv host_name.log host_name-old.log shell\u003e mysqladmin flush-logs \r\r","date":"2018-01-16","objectID":"/mysql/:31:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"二进制日志 The Binary Log \r\r \r安全 Security 当考虑MySQL安装中的安全性时，你应该考虑各种可能的主题以及他们如何影响MySQL Server和相关应用程序的安全性: 影响安全性的一般因素。包括选择好的密码，不向用户授予不必要的权限，防止SQL注入和数据损坏来确保应用程序的安全性… 安装本身的安全性。应保护数据文件，日志文件和安装的所有应用程序文件，以确保未经授权方无法读写这些文件… 数据库系统本身的访问控制和安全性。包括允许访问数据库中使用的数据库，视图和存储应用程序的用户和数据库… 安全相关插件提供的功能… MySQL和你的系统的网络安全性。安全性还与用户的授权有关，但你可能希望限制MySQL，使其仅在本地主机上可用，或者在一组有限的其它主机上可用… 确保你备份了足够和适当的数据库文件，配置和日志文件。还要确保你已准备好恢复解决方案，并测试是否能够从备份种恢复信息… \r","date":"2018-01-16","objectID":"/mysql/:31:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"一般安全问题 General Security Issues 本节介绍了要注意的一般安全问题，以及如何使MySQL安装更安全，防止攻击或滥用。 \r","date":"2018-01-16","objectID":"/mysql/:32:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"安全指南 Security Guidelines 在连接了Internet的计算机上使用MySQL的任何人都应阅读本节，以避免最常见的安全错误。 在讨论安全性时，有必要考虑完全保护整个服务器主机免受所有类型的攻击：窃听，更改，拒绝服务… MySQL使用基于访问控制列表(ACL)的安全性，来处理用户可以尝试执行的所有连接、查询和其它操作。MySQL Client和Server之间SSL加密连接。 当运行MySQL时，遵循以下准则： 不要让任何人(root除外)访问mysql.user数据表，这很关键。 了解MySQL访问权限系统的工作原理。使用GRANT和REVOKE语句来控制对MySQL的访问。不要授予超出必要的权限，永远不要授予所有主机权限。 如果你能够在不被要求输入密码的情况下成功连接到MySQL Server，则任何人都可以以具有完全权限的root用户身份连接到MySQL Server。请重新查看MySQL安装说明，特别注意有关设置root密码的信息。 检查哪些账户拥有访问权限，并移除不必要的权限。 #测试 mysql -u root #访问权限 SHOW GRANTS; #移除权限 #help REVOKE REVOKE 不要在数据库中存储明文密码。如果计算机被攻击，入侵者可以获得完整的密码列表并使用他们。相反，使用一些HASH函数并存储散列值。 不要从字典中选择密码，即不要使用简单和常规密码。存在某些破解密码的程序能计算你的密码。 启用防火墙。这可以保护你免受大部分漏洞攻击。将MySQL放在防火墙后面或DMZ。 使用端口扫描软件(如nmap)扫描主机端口。MySQL默认使用3306端口。不应从不受信任的主机访问此端口。测试你的端口安全性： [zhang@zhang21 ~]$ telnet zhang21 3306 Trying 192.168.31.119... Connected to zhang21. Escape character is '^]'. @Host 'zhang21' is not allowed to connect to this MySQL serverConnection closed by foreign host. [zhang@zhang21 ~]$ telnet localhost 3306 Trying ::1... Connected to localhost. Escape character is '^]'. J 5.7.22 [cqo3I @kX@n#I\\mysql_native_password 访问MySQL的应用程序不应该信任用户输入的任何数据，应该使用适当的防御性编程技术编写。 不要通过Internet传输普通数据(未加密)。请使用SSL或SSH加密协议。MySQL支持内部SSL连接；或是使用SSH端口转发为通信创建加密隧道。 学习使用tcpdump和strings使用程序。 可使用如下命令来检查MySQL数据流是否加密: tcpdump -l -i eth0 -w - src or dst port 3306 | strings \r\r","date":"2018-01-16","objectID":"/mysql/:32:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"密码安全 Keeping Passwords Secure 密码出现在MySQL的多个上下文中。此解提供了一些准则，使用户和管理员能够保护这些密码的安全性，并避免暴露这些密码。还讨论了MySQL如何在内部使用密码散列以及可用来强制执行更严格密码的插件。 \r密码安全用户指南 End-User Guidelines for Password Security MySQL用户应使用以下准则来保证密码安全。当运行Client连接到MySQL server时，不建议以公开的方式来指定你的密码。 使用mysql_config_editor实用程序，它可将身份认证凭据存储在名为.mylogin.cnf的加密登录路径文件中。 使用-pPASSWD或--password=PASSWD选项 使用-p或--password选项不指定值 将密码存储到配置文件 将密码存储到MYSQL_PWD环境变量 #强烈不推荐 #这虽然方便却不安全 mysql -u user -pPASSWD db_name #推荐 #但这适用于交互式 mysql -u user -p db_name Enter password: xxx #写入配置文件 chmod 600 ~/.my.cnf vim ~/.my.cnf [client] password=xxx mysql --defaults-file=~/.my.cnf #指定MySQL密码环境变量的方法非常不安全，不应该使用 在Unix上，MySQL Client将执行语句的记录写入历史文件。默认情况下，此文件为~/.mysql_history。密码可以在SQL语句中以纯文本形式写入(如CREATE USER, ALTER USER)，如果使用了这些语句，它们将被记录到历史文件中。要保证此文件的安全，请使用限制访问模式。 如果命令解释器程序配置为维护历史记录，则保存命令的任何文件都将包含在命令行中输入的MySQL密码。如bash下的~/.bash_history。 \r\r密码安全管理员指南 Administrator Guidelines for Password Security MySQL数据库管理员应使用以下准则来保证密码安全： MySQL在mysql.user表中存储用户账户密码。永远不要向任何非管理账户授予此表的访问权限 账户密码可以过期，以便用户必须重置密码 validate_password插件可用于对可接受的密码强制实施策略 应该保护可能写入密码的日志文件等文件 \r\r密码和日志 Passwords and Logging 密码可在SQL语句中以纯文本形式写入，如CREATE USET, GRANT, SET PASSWORD和调用PASSWORD()函数的语句。如果MySQL Server记录了这些语句，那么访问日志的任何人都可以看到密码。 语句记录避免以明文形式为以下语句编写密码： CREATEUSER...IDENTIFIEDBY...ALTERUSER...IDENTIFIEDBY...GRANT...IDENTIFIEDBY...SETPASSWORD...SLAVESTART...PASSWORD=...CREATESERVER...OPTIONS(...PASSWORD...)ALTERSERVER...OPTIONS(...PASSWORD...) 对于常规查询日志，可通过使用--log-raw选项启动Server来抑制密码重写。出于安全原因，此选项不建议用于生产环境。处于诊断目的，查看Server收到的语句的确切文本可能很有用。 审计日志插件生成的审计日志文件的内容未加密。出于安全原因，应将此文件写入只有MySQL Server和用户才能访问的目录，并且有正当理由查看目录。 只有在需要纯文本密码时才会进行密码重写，对于具有期望密码散列语法的语句，不会发生重写。 要保护日志文件免受不必要的暴露，请将他们放在限制访问Server和管理员的目录中。 副本集slave将复制副本集master的密码存储在主信息存储库中，它可以是文件或表。确保只能由管理员访问此库。 使用受限的访问模式来保护包含日志表或密码的日志文件的数据库备份。 \r\r密码散列 Password Hashing in MySQL MySQL在mysql.user数据表中列出用户账户。可以为每个MySQL账户分配一个密码，尽管用户表不存储明文密码，而是存储密码的散列值。 MySQL在Client/Server通信的两个阶段中使用密码： 当客户端尝试连接到Server时，有一个初始身份认证步骤，其中客户端必须提供密码，该密码的散列值与mysql.user用户表中存储的散列值相匹配 客户端连接之后，它可以(如果有足够权限)设置或更改mysql.user用户表中账户的密码的散列值。客户端可通过使用PASSWORD()函数来生成密码散列，或使用密码生成语句(CREATE USER, GRANT, SET PASSWORD)来完成此操作。 换句话说，Server在客户端首次尝试连接时在身份认证期间检查散列值。如果连接的客户端调用PASSWORD()函数，或使用密码生成语句来设置/更改密码，则Server会生成散列值。 help PASSWORD; #This function is deprecated as of MySQL 5.7.6 and will be removed in a future MySQL release #The Original (Pre-4.1) Hashing Method #原始散列方法产生一个16Byte的字符串 mysql\u003e SELECT PASSWORD('mypass'); +--------------------+ | PASSWORD('mypass') | +--------------------+ | 6f8c114b58f2ce9e | +--------------------+ #The 4.1 Hashing Method #MySQL4.1引入了密码散列，提供了更好的安全性并降低了密码被截获的风险 #生成更长的41Byte的散列值 mysql\u003e SELECT PASSWORD('mypass'); +-------------------------------------------+ | PASSWORD('mypass') | +-------------------------------------------+ | *6C8989366EAF75BB670AD8EA7A7FC1176A95CEF4 | +-------------------------------------------+ 散列方法的兼容性问题 Compatibility Issues Related to Hashing Methods \r\r","date":"2018-01-16","objectID":"/mysql/:32:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使MySQL安全抵御攻击者 Making MySQL Secure Against Attackers 连接到MySQL server时，应使用密码。密码在连接时不会以明文形式传输。所有其它信息都以文本形式传输，对任何能够看到连接的人都可读。如果连接通过不信任的网络，则可以使用压缩协议使流量更难以解密。你还可以使用MySQL的内部SSL支持来使连接更安全。或者，使用SSH在MySQL server和client之间获得加密的TCP/IP连接。 要使得MySQL系统安全，你应该强烈考虑以下建议： 要求所有MySQL账户都有密码 确保只有Unix用户账户对数据库目录具有读写权限，它是用于运行mysqld的账户 永远不要以root用户运行MySQL server，应该使用普通的非特权用户运行 MySQL用户账户和Unix系统账户没有关联 不要对非管理员用户授予FILE权限，具有此权限的用户都可使用mysqld daemon的权限在文件系统的任何位置编写文件，同样也可读取文件，并将文件载入数据库 不要对非管理员用户授予PROCESS或SUPER权限(可用于终止连接，修改系统变量…) 不允许对表使用符号链接 安全地存储程序和视图 如果不信任DNS，则应在授权表中使用IP地址而非主机名 如果想要限制单个账户的连接数，可在mysqld中配置max_user_connection变量 如果插件目录对server可写，这可修改它为只读 #服务 cat /usr/lib/systemd/system/mysqld.service [Service] User=mysql Group=mysql #或配置文件 /etc/my.cnf [mysqld] user=mysql #查看当前正在执行的语句 msyql\u003e SHOW PROCESSLIST; +----+------+-----------+-------+---------+------+----------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +----+------+-----------+-------+---------+------+----------+------------------+ | 18 | root | localhost | mysql | Query | 0 | starting | SHOW PROCESSLIST | +----+------+-----------+-------+---------+------+----------+------------------+ # Disabling symbolic-links is recommended to prevent assorted security risks cat /etc/my.cnf symbolic-links=0 \r\r","date":"2018-01-16","objectID":"/mysql/:32:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"安全相关的mysqld选项和变量 Security-Related mysqld Options and Variables 下表显示了影响安全性的mysqld的选项和系统变量: Name Cmd-Line Option File System Var Status Var Var Scope Dynamic allow-suspicious-udfs Yes Yes automatic_sp_privileges Yes Global Yes chroot Yes Yes des-key-file Yes Yes local_infile Yes Global Yes old_passwords Yes Both Yes safe-user-create Yes Yes secure-auth Yes Yes Global Yes - Variable: secure_auth Yes Global Yes secure-file-priv Yes Yes Global No - Variable: secure_file_priv Yes Global No skip-grant-tables Yes Yes skip-name-resolve Yes Yes Global No - Variable: skip_name_resolve Yes Global No skip-networking Yes Yes Global No - Variable: skip_networking Yes Global No skip-show-database Yes Yes Global No - Variable: skip_show_database Yes Global No \r\r","date":"2018-01-16","objectID":"/mysql/:32:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"以普通用户运行MySQL How to Run MySQL as a Normal User 在Linux上，使用MySQL-repo、RPM包、Debian包来安装MySQL。MySQL server mysqld默认是由操作系统的mysql用户来启动。 对于使用.tar.gz包进行的安装，你需要修改为non-root用户。 chown -R user_name /path/to/mysql/datadir vim /etc/my.cnf [mysqld] user=user_name \r\r","date":"2018-01-16","objectID":"/mysql/:32:5","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"LOAD DATA LOCAL的安全问题 LOAD DATA语句可以载入主机上的文件。 这有两个潜在的安全问题： 从Client到Server的文件传输是由MySQL server启动。理论上，server可告诉client传输server选择的文件而不是LOAD DATA语句中client指定的文件。这样，server可以访问client端用户可访问的任何文件。 在client从web server连接的Web环境中，用户可使用LOAD DATA LOCAL来读取Web server进程具有访问权限的任何文件。 为了避免LOAD DATA问题，客户端应该避免使用LOCAL。为避免连接到不受信任的Server，Client可通过--ssl-mode=xxx选项和相应的CA证书建立安全的连接。 要是管理员和应用程序能够管理本地数据加载功能，LOCAL配置的工作方式如下： On the server side local_infile系统变量控制服务器端的LOCAL功能。默认启用local_infile。 On the client side ENABLED_LOCAL_INFILE CMake选项控制MySQL Client Library的已编译的默认LOCAL功能。 使用C API的客户端程序可通过调用mysql_options()来启用/禁用MYSQL_OPT_LOCAL_INFILE。 对于mysql Client，默认禁止本地数据载入。使用--local-infile=1/0 对于mysqlimport client，默认禁用本地数据载入。使用--local=1/0 \r\r","date":"2018-01-16","objectID":"/mysql/:32:6","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"客户端程序安全指南 Client Programming Security Guidelines 访问MySQL的应用程序不应该信任用户输入的任何数据，用户可以尝试通过在Web表单，URL或构建的任何应用程序中输入特殊字符序列来欺骗你。如果用户输入DROP DATABASE mysql;类似语句，请确保你的应用程序保持安全，这是一个极端栗子。 有时人们会认为，如果数据库只包含公开可用的数据，则无需受到保护。这是不正确的。即使允许在数据库中显示任何行，你仍应该防止拒绝服务攻击。 检查清单： 启用更严格的SQL模式以告知server对其接收的数据做更多限制 注意单/双引号 通过添加%22(\"), %23(\"), %27(')来修改动态URLs 动态修改URL中的数据类型 尝试输入字符、空格和特殊符号，而不是 数字 将数据传递给MySQL前检查数据大小 使用不同于管理员的用户将应用程序连接到数据库 \r\r\r","date":"2018-01-16","objectID":"/mysql/:32:7","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"访问权限系统 The MySQL Access Privilege System MySQL权限系统的主要功能就是对从给定主机连接的用户进行身份认证，并将用户与数据库的权限(SELECT, INSERT, UPDATE, DELETE)相关联。其它功能包含匿名用户(anonymous user)和MySQL特定功能的授权。 有些事情你无法使用MySQL权限系统： 你无法明确指定拒绝给定用户访问 你无法指定用户创建/删除表的权限，但不能指定创建/删除数据库自身 适用于账户全局性的密码 MySQL权限系统的用户接口(user interface)由： CREATE USER, GRANT, REVOKE语句组成。 在内部，Server将权限信息存储在mysql数据库的授权表中。MySQL server在启动时将这些表内容读入内存，并根据授权表的内存中的副本建立访问控制决策。 MySQL权限系统确保所有用户只能执行允许的操作。作为用户，当你连接到MySQL server时，你的身份由你连接的主机和你指定的用户名决定。在连接后，系统会根据你的身份和要执行的操作授予权限。 MySQL会识别你的主机名和用户名，因为没有理由认为给定的用户名属于所有主机上的同一个人。 SHOW GRANTS; SHOW GRANTS FOR 'joe'@'office.example.com'; SHOW GRANTS FOR 'joe'@'home.example.com'; 当运行客户端程序连接到server时，MySQL访问控制包含两个阶段： server根据你的身份来接受/拒绝连接，以及你是否可通过提供正确的密码来验证你的身份 假设你可以连接，server会检查你发出的每个语句，以确定是否有足够的权限来执行它 \r\r","date":"2018-01-16","objectID":"/mysql/:33:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL提供的权限 Privileges Provided by MySQL 授予MySQL账户的权限决定了账户可以指定的操作。MySQL权限在它们适用的上下文和不同操作级别上有所不同： 管理员权限(Administrative privileges)允许用户管理MySQL Server的操作。这些权限是全局的，因为它们不是特定于特定数据库 数据库权限(privileges for database)适用于数据库及其中的所有对象。可以为特定数据库或全局赋予这些权限，以便它们适用于所有数据库 数据库对象权限(privileges for database object)，如表，索引，视图… \r\r可用权限 Summary of Available Privileges 下表显示了GRANT和REVOKE语句中使用的权限名称，以及每个权限关联的列名和权限适用的上下文: Privilege Grant Table Column Context ALL [PRIVILEGES] Synonym for “all privileges” Server administration ALTER Alter_priv Tables ALTER ROUTINE Alter_routine_priv Stored routines CREATE Create_priv Databases, tables, or indexes CREATE ROUTINE Create_routine_priv Stored routines CREATE TABLESPACE Create_tablespace_priv Server administration CREATE TEMPORARY TABLES Create_tmp_table_priv Tables CREATE USER Create_user_priv Server administration CREATE VIEW Create_view_priv Views DELETE Delete_priv Tables DROP Drop_priv Databases, tables, or views EVENT Event_priv Databases EXECUTE Execute_priv Stored routines FILE File_priv File access on server host GRANT OPTION Grant_priv Databases, tables, or stored routines INDEX Index_priv Tables INSERT Insert_priv Tables or columns LOCK TABLES Lock_tables_priv Databases PROCESS Process_priv Server administration PROXY See proxies_priv table Server administration REFERENCES References_priv Databases or tables RELOAD Reload_priv Server administration REPLICATION CLIENT Repl_client_priv Server administration REPLICATION SLAVE Repl_slave_priv Server administration SELECT Select_priv Tables or columns SHOW DATABASES Show_db_priv Server administration SHOW VIEW Show_view_priv Views SHUTDOWN Shutdown_priv Server administration SUPER Super_priv Server administration TRIGGER Trigger_priv Tables UPDATE Update_priv Tables or columns USAGE Synonym for “no privileges” Server administration \r\r授权指南 Privilege-Granting Guidelines 最好只向账户授权它所需要的权限，在授予FILE和管理权限时应特别小心: FILE： 可在MySQL Server主机上读取的任何文件读入数据库表 GRANT OPTION： 使用户能够将其权限授权其他用户。具有不同权限且具有GRANT OPTION权限的两个用户可以组合权限 ALTER: 可通过重命名表来破坏权限系统 SHUTDOWN： 通过终止Server完全拒绝向其它用户提供服务 PROCESS： 用于查看当前正在执行的语句的纯文本，包括设置和更改密码的语句 SUPER： 用于终止其它会话或更改服务器的运行方式 为mysql系统数据本自身授予的权限可用于更改密码和其它访问权限信息： 密码以加密方式存储，因此恶意用户无法简单地读取明文密码。然而，具有对mysql.user表authentication_string列具有写权限的用户可以更改账户密码，然后进行登录 为mysql系统数据库授予INSERT或UPDATE权限允许用户添加或修改现有权限 mysql系统数据库的DROP权限使用户能够访问远程权限表，甚至是数据库本身 \r\r","date":"2018-01-16","objectID":"/mysql/:33:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"授权表 Grant Tables mysql系统数据库包含多个授权表，其中包含有关用户账户及其拥有的权限信息。 mysql数据库表包含的授权信息： user: 用户账户，全局权限，其它非权限列 db: 数据库级别权限 tables_priv：表级别权限 columns_priv： 列级别权限 procs_priv： 存储过程和功能权限 proxies_priv： 代理用户权限 每个授权表包含的列范围和列权限： 列范围确定表中每行的范围 列权限指示表中行授予的权限 Server以下列方式使用授权表： user表范围列确定是拒绝还是允许传入连接 db表范围列确定哪些用户可以从哪些主机上访问数据库 tables_priv和columns_priv表更精细，它们适用于表级别和列级别 procs_priv表用于存储的例程 proxies_priv表指示哪些用户可以充当其它用户的代理，以及用户是否可以将PROXY权限授予其它用户 \r\r","date":"2018-01-16","objectID":"/mysql/:33:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"指定账户名 Specifying Account Names MySQL账户名由用户名和主机名组成。这样可以为具有相同名称且可以从不同主机连接的用户创建账户。 在SQL语句中，账户名称遵循以下规则： 账户名语法为: username@hostname 仅包含用户名的账户相当于username@% 注意反引号、单引号、双引号 引号的正确用法: 'username'@'hostname' MySQL使用单独的用户名和主机名部分将账户名称存储到mysql系统数据库的授权表中： user表包含每个账户的一行，user.User，user.Host列存储用户名和主机名，此表还指示了账户具有哪些全局权限 其它授权表指示账户对数据库和库中对象的权限，这些表也有User, Host列来存储用户名和主机名 处于访问检查的目的，User value区分大小写，Host value不区分大小写 用户名和主机名还具有某些特殊值或通配符约定，如下: 账户名的用户名部分是非空白值，或者是与任何用户名匹配的空值。具有空白用户名的账户是匿名用户(anonymous user)。在SQL语句中指定一个匿名用户，使用带引号的空用户名，如''@'localhost'。 账户名的主机名部分可以采用多种形式，并允许使用通配符： host value可以是主机名或IP地址(ipv4, ipv6) 主机名或IP地址值中允许使用%和_通配符。 例如，主机值%匹配任何主机名，如%.mysql.com匹配mysql.com域中的任何主机。 对于IPv4地址，可以给出网络掩码以指示用于网络号的地址位数 CREATE USER 'test'@'198.51.100.0/255.255.255.0； Server使用系统DNS解析程序为客户端主机名或IP地址返回的值，意味着你应该使用DNS使用的相同格式指定的账户主机值。 \r\r","date":"2018-01-16","objectID":"/mysql/:33:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"访问控制 Access Control \r连接验证 Access Control, Stage 1: Connection Verification 当你连接到MySQL Server，它会根据以下条件接受或拒绝连接： 身份和密码 账户是否被锁定 Server首先检查凭据，然后检查账户锁定状态。任一步骤失败都会导致Server完全拒绝你的访问权限。使用mysql.user表中的三个范围列：Host, User, authentication_string执行凭据检查。 SELECTUser,HostFROMmysql.user;+-----------+----------+- |Host|User|...+-----------+----------+- |%|root|...|%|jeffrey|...|localhost|root|...|localhost||...+-----------+----------+- #内存中排序的表+-----------+----------+- |Host|User|...+-----------+----------+- |localhost|root|...|localhost||...|%|jeffrey|...|%|root|...+-----------+----------+- %： 表示任意主机 空用户名： 表示任意 当可能存在多个匹配时，Server必须确定要使用安歇匹配项： 只要Server将用户表读入内存，它就会对行进行排序 当用户尝试连接时，Server按排序顺序查看行 Server使用与客户端host和username匹配的第一行 \r\r请求认证 Access Control, Stage 2: Request Verification 通过连接发出的每个请求，Server确定你要执行的操作，然后检查你是否具有足够的权限来执行此操作。这就是授权表中权限列生效的地方。这些权限可以来自任何user, db, table, column, procs。 全局权限(global) 适用于全局范围内 数据库权限 空用户名匹配匿名用户，用户名中没有通配符 通配符%和_可在Host和Db列中使用，与LIKE操作符执行的模式匹配类似。如果要使用原字符，请使用反斜杠对其转义 %或空白Host值表示任意主机 %或空白Db值表示任意数据库 表、列、proc权限 通配符%, _ 以布尔术语表示，总结用户权限： global privileges OR (database privileges AND host privileges) OR table privileges OR column privileges OR routine privileges \r\r","date":"2018-01-16","objectID":"/mysql/:33:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"权限更改生效时 When Privilege Changes Take Effect 启动msyqld时，它读取所有授权表到内存中，内存中的表在此时对访问控制有效。 如果使用GRANT, REVOKE, SET PASSWORD, RENAME USER账户管理语句间接修改了授权表，则Server会注意到这些更改并立即在此将授权表加载到内存中。 如果直接使用INSERT, UPDATE, DELETE语句修改授权表，则在重启Server或指示重新加载表之前，对权限的更改没有影响。也就是说，直接修改授权表但没有重新加载它的话，更改时无效的。 告诉Server重新加载授权表，有几种方式： mysql\u003e FLUSH PRIVILEGES #或 $ mysqladmin flush-privileges #或 $ mysqladmin reload 如果使用--skip-grant-tables选项启动Server，则它不会读取授权表或实现任何访问控制。任何人都可以连接并做任何事情，这是不安全的。 \r\r","date":"2018-01-16","objectID":"/mysql/:33:5","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"连接MySQL的一些问题 Troubleshooting Problems Connecting to MySQL 链接: https://dev.mysql.com/doc/refman/5.7/en/problems-connecting.html \r\r\r","date":"2018-01-16","objectID":"/mysql/:33:6","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"用户账户管理 MySQL User Account Management 本节介绍如何为MySQL Server的客户端设置账户： MySQL中使用的账户名和密码的含义，与操作系统使用的名称和密码的比较 如何设置新账户和删除现有账户 如何修改密码 密码使用安全指南 \r","date":"2018-01-16","objectID":"/mysql/:34:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"用户名和密码 User Names and Passwords 有两种方式创建MySQL账户： 使用创建账户(CREATE USER)和建立权限(GRANT)的账户管理语句。这些语句使Server对基础授权表进行适当的修改 直接操作MySQL授权表，如INSERT, DELETE, UPDATE命令 推荐使用账户管理语句，因为它们比直接操作授权表更简洁，更不容易出错。 栗子： mysql --user=root mysql 创建账户： CREATEUSER'finley'@'localhost'IDENTIFIEDBY'passwd';GRANTALLPRIVILEGESON*.*TO'finley'@'localhost'WITHGRANTOPTION;CREATEUSER'finley'@'%'IDENTIFIEDBY'passwd';GRANTALLPRIVILEGESON*.*TO'finley'@'%'WITHGRANTOPTION;CREATEUSER'admin'@'localhost'IDENTIFIEDBY'password';GRANTRELOAD,PROCESSON*.*TO'admin'@'localhost';#查看SHOWGRANTSFOR'admin'@'localhost';#特定权限CREATEUSER'reader'@'localhost'INDENTIFIEDBY'passwd';GRANTSELECTONreaddb.*TO'reader'@'localhost'; \r\r","date":"2018-01-16","objectID":"/mysql/:34:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"删除账户 Removing User Accounts 使用DROP USER语句删除用户账户。 DROPUSER'reader'@'localhost'; \r\r","date":"2018-01-16","objectID":"/mysql/:34:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"保留账户 Reserved User Accounts MySQL安装过程中的数据目录初始化期间，MySQL会创建应被视为保留的用户账户： 'root'@'localhost'： 用于管理，拥有一切权限，可执行任何操作 'mysql.sys'@'localhost'： 用作sys模式对象的DEFINER。可避免DBA重命名或删除root账户时出现的问题 'mysql.session@'localhost'：由插件在内部使用以访问Server \r\r","date":"2018-01-16","objectID":"/mysql/:34:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"账户资源限制 Setting Account Resource Limits 限制Client使用MySQL Server资源的一种方式是将全局max_user_connections系统变量设置为非零值。这限制了任何账户(缺乏单个用户)可以进行同时连接的数量，但是对连接后Client可以执行的操作没有限制。 为了解决这些问题，MySQL允许限制单个账户的资源： 账户每小时可以发出的查询数 账户每小时可以发出的更新数 账户每小时可以连接到Server的次数 账户与Server同时连接的数量 要在创建账户时设置资源限制，使用CREATE USER语句；要修改现有账户的限制，使用ALTER USER语句。使用WITH字句，命名每个要限制的资源。 每个限制的默认值为零，即无限制。 限制类型不必全部在WITH字句中命名，每个小时的限制值应该是一个整数。 Server在该账户对应的user表的行中存储账户的资源限制。当任何账户对其使用任何资源具有非零限制时，将进行资源使用计数。如果超过其连接次数，则Server会拒绝该账户的其它连接，直到该小时结束为止。在所有这些情况下，Server都会发出相应的错误消息。 CREATEUSER'francis'@'localhost'IDENTIFIEDBY'frank'WITHMAX_QUERIES_PER_HOUR20MAX_UPDATES_PER_HOUR10MAX_CONNECTIONS_PER_HOUR5MAX_USER_CONNECTIONS2;ALTERUSER'francis'@'localhost'WITHMAX_QUERIES_PER_HOUR100; 假设全局变量max_user_connections值为10： ALTERUSER'user1'@'localhost'WITHMAX_USER_CONNECTIONS0;ALTERUSER'user2'@'localhost'WITHMAX_USER_CONNECTIONS5;ALTERUSER'user3'@'localhost'WITHMAX_USER_CONNECTIONS20; 可以为单个账户、所有账户全局重置当前的计数： 使用FLUSH USER RESOURCES语句，将所有账户当前的计数重置为零 将单个账户的限制值重新设置，可以将账户的计数重置为零 每小时计数重置不会影响MAX_USER_CONNECTIONS限制。所有计数从零开始，计数不会通过Server重启而延续。 \r\r\r","date":"2018-01-16","objectID":"/mysql/:34:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"分配账户密码 Assigning Account Passwords MySQL会自动散列(hash)指定的密码。 #在创建用户是使用INDENTIFIEDBY字句分配密码CREATEUSER'jeffrey'@'localhost'IDENTIFIEDBY'password';#修改密码ALTERUSER'jeffrey'@'localhost'IDENTIFIEDBY'password';#修改连接账户的密码ALTERUSERUSER()IDENTIFIEDBY'password'; 或者使用mysqladmin修改密码，出于安全问题，不推荐使用。 mysqladmin -u user_name -h host_name password \"password\" \r\r\r","date":"2018-01-16","objectID":"/mysql/:34:5","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"密码管理 Password Management MySQL使数据库管理员可以手动使帐户密码过期，并建立自动密码过期的策略。可以在全局建立到期策略，并且可以将个人帐户设置为遵循全局策略或使用特定的每帐户行为覆盖全局策略。 使用ALTER USER语句设置密码过期： ALTERUSER'jeffrey'@'localhost'PASSWORDEXPIRE; 密码过期策略是自动的，并且基于密码的年龄和最近密码的更改日期和时间进行评估。mysql.user表上有上次更改密码的时间。 要全局地建立自动密码过期策略，请使用default_password_lifetime系统变量。默认值为零，表示禁用自动密码过期。如果将值设置为正整数N，则表示允许的密码生存期，因此密码必须每N天更改一次。 栗子： vim /etc/my.cnf [mysqld] default_password_lifetime=365 或者在MySQL中设置全局变量： SETGLOBALdefault_password_lifetime=365; 或者在创建账户时设置： CREATEUSER'jeffrey'@'localhost'PASSWORDEXPIREINTERVAL90DAY;ALTERUSER'jeffrey'@'localhost'PASSWORDEXPIREINTERVAL365DAY;#禁用CREATEUSER'jeffrey'@'localhost'PASSWORDEXPIRENEVER;ALTERUSER'jeffrey'@'localhost'PASSWORDEXPIRENEVER;#默认CREATEUSER'jeffrey'@'localhost'PASSWORDEXPIREDEFAULT;ALTERUSER'jeffrey'@'localhost'PASSWORDEXPIREDEFAULT; Client成功连接后，Server将确定账户密码是否已过期： Server检查密码是否手动过期 否则，Server根据自动密码过期策略检查密码年龄是否大于其允许的生存期 \r\r\r","date":"2018-01-16","objectID":"/mysql/:34:6","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"密码过期和沙箱 Password Expiration and Sandbox Mode 对于使用具有过期密码的账户的连接，Server要么断开连接，要么将Client限制为沙箱模式。 沙箱模式允许这些操作： Client可使用ALTER USER或SET PASSWORD重置账户密码。重置密码后，Server恢复回话的正常访问 \r\r\r","date":"2018-01-16","objectID":"/mysql/:34:7","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"代理用户 Proxy Users MySQL Server使用身份验证插件验证客户端连接。验证给定连接的插件可以请求将外部连接用户视为不同的用户以进行特权检查。这就使外部用户成为第二个用户的代理。也就是说，假设第二个用户的权限： 外部用户是代理用户 第二个用户是被代理的用户 代理用户支持的要求 Requirements for Proxy User Support 对于给定身份认证的插件的代理，必须满足一下条件： 必须通过插件本身或代表插件的MySQL Server服务器来支持代理 必须将代理用户账户设置为由插件进行身份验证(CREATE USER和ALTER USER语句) 必须创建代理用户账户并授予相关权限(CREATE USER和GRANT语句) 代理用户账户必须具有代理账户的proxy权限(GRANT语句) 对于连接到代理账户的Client将被视为代理用户，身份验证插件必须返回与客户端用户名不同的用户名，以指示代理账户的用户名，该用户名定义代理所承担的权限用户。 代理机制允许将客户端用户名映射到代理用户名，没有规定映射主机名。当连接Client与代理账户匹配时，Server会尝试使用身份验证插件返回的用户名和代理账户的主机名来查找账户的匹配项。 考虑如下账户定义： -- create proxy account CREATEUSER'employee_ext'@'localhost'IDENTIFIEDWITHmy_auth_pluginAS'my_auth_string';-- create proxied account and grant its privileges CREATEUSER'employee'@'localhost'IDENTIFIEDBY'employee_pass';GRANTALLONemployees.*TO'employee'@'localhost';-- grant PROXY privilege to proxy account for proxied account GRANTPROXYON'employee'@'localhost'TO'employee_ext'@'localhost'; 当Client从localhost使用employee_ext连接时，MySQL使用名为my_auth_plugin的插件来执行身份验证。假设my_auth_plugin根据my_auth_string的内容向Server返回employee的用户名，并可能通过咨询某些外部身份验证系统。employee与employee_ext不同，因此返回employee作为请求，Server将employee_ext视为employee本地用户，以便进行权限检查。 Server通过检查employee_ext是否具有employee的PROXY权限来验证employee_ext是否可以对employee进行代理身份验证。 在此例中，employee_ext是代理用户，employee是被代理用户。 发生代理时，USER()和CURRENT_USER()函数可用于查看连接用户(代理用户)与当前会话账户(被代理的用户)之间的区别： SELECTUSER(),CURRENT_USER();+------------------------+--------------------+ |USER()|CURRENT_USER()|+------------------------+--------------------+ |employee_ext@localhost|employee@localhost|+------------------------+--------------------+ \r\r授予代理权限 Granting the Proxy Privilege 需要PROXY权限才能使外部用户连接并拥有其他用户的权限。要授予此权限，请使用GRANT语句。 GRANTPROXYON'proxied_user'TO'proxy_user';GRANTPROXYON'a'TO'b','c','d';GRANTPROXYON'a'TO'd'WITHGRANTOPTION;GRANTPROXYON'a'TO''@'';REVOKEPROXYON'a'FROM'b','c','d'; \r\r默认代理用户 Default Proxy Users 要制定某些或所有用户应使用给定的身份验证进行连接，请创建一个空白MySQL账户(''@'')，将其与该插件关联，然后让插件返回真实身份验证的用户名。 栗子： -- create default proxy account CREATEUSER''@''IDENTIFIEDWITHldap_authAS'O=Oracle, OU=MySQL';-- create proxied accounts CREATEUSER'developer'@'localhost'IDENTIFIEDBY'developer_pass';CREATEUSER'manager'@'localhost'IDENTIFIEDBY'manager_pass';-- grant PROXY privilege to default proxy account for proxied accounts GRANTPROXYON'manager'@'localhost'TO''@'';GRANTPROXYON'developer'@'localhost'TO''@''; \r\r默认代理用户和匿名用户冲突 Default Proxy User and Anonymous User Conflicts 如果打算创建默认代理用户，请检查其他现有的匹配任何用户账户，这些账户优先于默认代理用户，因为他们可以阻止该用户按预期工作。 在前面的讨论中，默认代理账户在主机部分具有''，与任何主机匹配。如果你设置了默认代理用户，请注意检查非代理账户是否存在相同的用户部分和主机部分中的%，因为%也匹配任何主机，但优先于''，Server用于在内部对账户进行排序。 要避免此问题，请使用以下策略之一： 删除匿名用户，使其不与默认代理用户冲突 使用在匿名用户之前匹配的更具体的默认代理用户，如''@localhost 创建多个代理用户。用于本地连接和远程连接 \r\rServer支持代理用户映射 Server Support for Proxy User Mapping 一些身份验证插件为自身实现代理用户映射(如PAM)。默认情况下，其他身份验证插件不支持代理用户。 如果启用了check_proxy_users系统变量，则Server会对发出此类请求的任何身份认证插件执行代理用户映射： 默认情况下，check_proxy_users被禁用。因此即使对请求Server支持代理用户的身份验证插件，Server也不执行用户代理映射。 如果启用了check_proxy_users，则可能还需要启用特定于插件的系统变量以利用Server代理用户映射支持： 对于mysql_native_password插件，请启用mysql_native_proxy_users 对于sha256_password插件，请启用sha256_password_proxy_users Server执行的代理用户映射受以下限制： 即使授权了关联的PROXY权限，Server也不会代理匿名用户(FROM)或从匿名用户代理(TO) 如果单个账户授予了多个代理账户的代理权限，则Server代理用户是不确定的。因此，不鼓励为多个被代理账户授予单个账户代理权限 \r\r代理用户系统变量 Proxy User System Variables 两个系统变量有助于追踪代理登录过程： proxy_user 如果未使用代理，则此值为NULL。否则，它表示代理用户账户。 external_user 有时，身份验证插件可能会使用外部用户对MySQL Server进行身份验证。 \r\r\r","date":"2018-01-16","objectID":"/mysql/:34:8","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"用户账户 User Account Locking 从MySQL v5.7.6开始，MySQL支持使用ACCOUNT LOCK和ACCOUNT UNLOCK子句为CREATE USER和ALTER USER语句锁定和解锁用户账户： 与CREATE USER一起使用时，这些子句指定新账户的初始锁定状态。如果没有任何一个子句，则账户将以未锁定状态创建。 与ALTER USER一起使用时，这些子句指定现有账户的新锁定状态。如果没有任何一个子句，则账户锁定状态保持不变。 账户锁定状态记录在mysql.user系统表的account_locked列中。使用SHOW CREATE USER显示账户锁定状态。 如果Client尝试连接到已锁定的账户，则会失败。返回错误消息，并将错误写入日志。 锁定账户不会影响能够使用承担锁定账户身份的代理用户进行连接。她也不会影响执行存储程序和试图的能力，这些程序或视图具有命名锁定账户的DEFINER子句。也就是说，锁定账户，不会影响使用代理账户或存储的程序或视图的能力。 要从旧版本升级到MySQL 5.7.6以及更高版本，请运行mysql_upgrade以确保此列存在。对于没有account_locked列的非升级安装，Server会将所有账户视为已解锁。 \r\r","date":"2018-01-16","objectID":"/mysql/:34:9","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"基于SQL的MySQL账户活动审计 SQL-Based MySQL Account Activity Auditing 应用程序可以使用以下准则来执行基于SQL的审计，该审计将数据库活动与MySQL账户联系起来。 MySQL账户对应于mysql.user系统表中的行。当Client连接成功后，Server会将Client验证到此表中的特定行。此行中的User和Host列的值唯一标识该账号，并对应于user@host格式，其中账户名称在SQL语句中写入。 用于验证Client的账户确定Client具有哪些权限。通常，可以调用CURRENT_USER()函数来确定这对于Client用户来说是哪个账户。其值有账户的用户表行的User和Host列构成。 但是，在某些情况下，CURRENT_USER()值不对应于客户端用户，而是对英语不同的账户。当权限检查不基于客户端账户时，会发生这种情况： 使用 SQL SECURITY DEFINER特性定义的存储例程 使用 SQL SECURITY DEFINER特性定义的视图 触发器和事件 在这些上下文中，权限检查是针对DEFINER账户完成的，而CURRENT_USER()是指该账户，而不是指调用存储例程或视图的Client或导致触发器激活的账户。 如果应用程序必须调用USER()进行用户审计，但是还必须能够将USER()值与用户表中的账户相关联，则必须避免使用在User或Host列中包含通配符。具体来说，不允许User为空，并且不允许Host值中使用模式字符或网络掩码表示法。所有账户必须具有非空用户值和文字主机值。 更改账户用户主机： RENAMEUSER''@'localhost'TO'user1'@'localhost';RENAMEUSER'user2'@'%.example.com'TO'user2'@'remote.example.com';-- 如果user2必须能够从example.com域中的多个主机进行连接，则每个主机应该有一个独立的账户 要从CURRENT_USER()或USER()函数中提取用户名或主机名，请使用SUBSTRING_INDEX()函数： SELECTSUBSTRING_INDEX(CURRENT_USER(),'@',1);+---------------------------------------+ |SUBSTRING_INDEX(CURRENT_USER(),'@',1)|+---------------------------------------+ |user1|+---------------------------------------+ SELECTSUBSTRING_INDEX(CURRENT_USER(),'@',-1);+----------------------------------------+ |SUBSTRING_INDEX(CURRENT_USER(),'@',-1)|+----------------------------------------+ |localhost|+----------------------------------------+ \r\r\r","date":"2018-01-16","objectID":"/mysql/:34:10","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用加密连接 Using Encrypted Connections MySQL Client和Server之间的未加密连接，有权访问网络的人可以监视你的所有流量和C/S之间发送和接受的数据。 要使任何类型的在网络中数据不可读，请使用加密。加密算法必须包含安全元素，以抵御多种已知的攻击。 MySQL支持使用TLS协议在C/S之间建立加密连接。TLS有时被称为SSL，但MySQL实际上并不使用SSL协议进行加密，因为它的加密很弱。 TLS使用加密算法来确保可以信任通过公共网络接收的数据。它具有检测数据更改、丢失、重放的机制。TLS还包含使用X.509标准提供的身份验证的算法。 X.509可以识别互联网上的某个人。在基本术语中，有一些被称为**证书颁发机构(CA)**的实体，它将电子证书分配给需要它们的任何人。证书依赖于两个加密密钥(公钥和私钥)的非对称加密算法。证书所有者可以将证书提供给另一方作为身份证明。证书由其所有者的公钥组成，使用该公钥加密的任何数据只能使用有该证书的私钥来解密。 可以使用OpenSSL和yaSSL编译MySQL以获得加密连接支持。 默认情况下，如果Server支持加密连接，MySQL将尝试使用加密连接。如果无法建立加密连接，则会回退到未加密的连接。 MySQL基于每个连接执行加密，并且对给定用户使用加密可以是可选的或强制的。这使你可以根据各个应用程序的要求选择加密或未加密的连接。 加密连接同样可用于Master和Slave的副本集之间。 也可以通过MySQL C API获得加密连接。 也可以使用SSH连接内的加密连接到MySQL Server。 \r\r","date":"2018-01-16","objectID":"/mysql/:35:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"配置MySQL以使用加密连接 Configuring MySQL to Use Encrypted Connections 有几个选项用于指示是否使用加密连接，以及制定适当的证书和密钥文件。它包括： Server端 Client端 \r\rS端加密连接配置 Server-Side Configuration for Encrypted Connections 在S端，--ssl选项指定Server允许但不需要加密连接。默认情况下启用此选项。 Server端的这些选项标识了Server在允许Client建立加密连接时使用的证书和密钥文件： --ssl-ca CA颁发的证书文件的路径名 ssl-cert Server公钥证书文件的路径名。可以发送到Client端，并根据它具有的CA证书进行身份验证 ssl-key Server私钥文件的路径名 启用加密连接，修改my.cnf的栗子： [mysqld] ssl-ca=ca.pem ssl-cert=server-cert.pem ssl-key=server-key.pem \r\rC端加密连接配置 Client-Side Configuration for Encrypted Connections 默认情况下，如果Server支持加密连接，MySQL Client将尝试建立加密连接，并通过--SSL-mode选项进一步控制： 如果没有ssl-mode选项 Client将尝试使用加密连接，如果无法建立加密连接，则会回退到未加密的连接。这等同于--ssl-mode=PREFFERED --ssl-mode=REQUIRED Client需要加密连接，如果无法建立，则会失败 --ssl-mode=DISABLED Client使用未加密连接 --ssl-mode=VERIFY_CA或--ssl-mode=VERIFY_IDENTITY 客户端需要加密连接，并且还要针对Server CA证书和对其他证书中的Server主机名进行验证 Client以下几个选项类似于Server端的几个选项，标识C/S加密连接时使用的证书和密钥文件： --ssl-ca --ssl-cert --ssl-key \r\r\r","date":"2018-01-16","objectID":"/mysql/:35:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"加密连接的命名选项 Command Options for Encrypted Connections 本节介绍使用加密连接的选项。 --skip-ssl Do not use encrypted connection --ssl Enable encrypted connection --ssl-ca File that contains list of trusted SSL Certificate Authorities --ssl-capath Directory that contains trusted SSL Certificate Authority certificate files --ssl-cert File that contains X.509 certificate --ssl-cipher List of permitted ciphers for connection encryption --ssl-crl File that contains certificate revocation lists --ssl-crlpath Directory that contains certificate revocation list files --ssl-key File that contains X.509 key --ssl-mode Security state of connection to server 5.7.11 --ssl-verify-server-cert Verify host name against server certificate Common Name identity --tls-version Protocols permitted for encrypted connections 5.7.10 \r\r\r","date":"2018-01-16","objectID":"/mysql/:35:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"创建SSL/RSA证书和密钥 Creating SSL and RSA Certificates and Keys 可以使用MySQL自身提供的工具或直接调用openssl命令来创建所需文件。 \r\r使用MySQL创建 Creating SSL and RSA Certificates and Keys using MySQL MySQL提供了这些方法来创建SSL证书和密钥文件以及使用SSL支持加密连接所需的RSA密钥对文件，以及使用RSA通过未加密连接进行安全密码交换。如果缺少这些文件： 对于使用OpenSSL编译的MySQL发行版，Server可在启动时自动生成这些文件 用户可以手动调用mysql_ssl_rsa_setup实用程序 对于某些发行版(如RPM包)，在数据目录初始化期间会调用mysql_ssl_rsa_setup。在这种情况下，只要openssl命令可用，就不需要使用OpenSSL编译MySQL发行版 自动SSL和RSA文件生成 Automatic SSL and RSA File Generation 对于使用OpenSSL编译的MySQL发行版，MySQL Server能够在启动时自动生成缺少的SSL和RSA文件。auto_generate_certs和sha256_password_auto_generate_rsa_keys系统变量控制这些文件的自动生成。默认情况下启用这两个变量，它们可以在启动时启用并检查，但不能在运行时设置。 启动时，如果启用了auto_generate_certs系统变量，则Server会自动在数据目录中生成S端和C端的SSL证书和密钥文件。 Server检查数据目录下的SSL文件： ca.pem server-cert.pem server-key.pem 如果存在，则不创建。反之，则创建 ca.pem Self-signed CA certificate ca-key.pem CA private key server-cert.pem Server certificate server-key.pem Server private key client-cert.pem Client certificate client-key.pem Client private key 如果Server自动生成了RSA文件，它将使用其名称来设置相应的系统变量 启动时，如果满足以下条件(sha256_password_auto_generate_rsa_keys系统变量已启用；没有指定RSA选项；数据目录中缺少RSA文件)，则Server会自动在数据目录中生成RSA私钥/公钥对文件。 Server检查数据目录下的RSA文件 private_key.pem Private member of private/public key pair public_key.pem Public member of private/public key pair 如果存在，则不创建。反之，则创建 如果Server自动生成了RSA文件，它将使用其名称来设置相应的系统变量 手动生成 Manual SSL and RSA File Generation Using mysql_ssl_rsa_setup MySQL发行版包含此实用程序，但它需要openssl命令可用。 SSL/RSA文件特性 SSL and RSA File Characteristics 它们具有以下特性： SSL/RSA密钥大小为2048bits SSL CA证书是自签名的 SSL Server/Client的CA证书和密钥对，使用sha256WithRSAEncryption签名算法 创建的SSL文件自生成之日起有效期为十年 RSA文件不会过期 SSL文件对于每个证书/密钥对具有不同的序列号(1 for CA, 2 for Server, 3 for Client) 创建的文件由运行程序执行创建的用户拥有 Unix/Unix-Like上，证书文件权限为644，密钥文件权限为600 查看SSL证书内容： openssl x509 -text -in ca.pem openssl x509 -text -in server-cert.pem openssl x509 -text -in client-cert.pem 使用SQL语句查看SSL证书过期时间： SHOWSTATUSLIKE'Ssl_server_not%';+-----------------------+--------------------------+ |Variable_name|Value|+-----------------------+--------------------------+ |Ssl_server_not_after|Apr2814:16:392027GMT||Ssl_server_not_before|May114:16:392017GMT|+-----------------------+--------------------------+ \r\r使用openssl创建SSL证书和密钥 Creating SSL Certificates and Keys Using openssl 创建栗子： # Create clean environment rm -rf newcerts mkdir newcerts \u0026\u0026 cd newcerts # Create CA certificate openssl genrsa 2048 \u003e ca-key.pem openssl req -new -x509 -nodes -days 3600 \\ -key ca-key.pem -out ca.pem # Create server certificate, remove passphrase, and sign it # server-cert.pem = public key, server-key.pem = private key openssl req -newkey rsa:2048 -days 3600 \\ -nodes -keyout server-key.pem -out server-req.pem openssl rsa -in server-key.pem -out server-key.pem openssl x509 -req -in server-req.pem -days 3600 \\ -CA ca.pem -CAkey ca-key.pem -set_serial 01 -out server-cert.pem # Create client certificate, remove passphrase, and sign it # client-cert.pem = public key, client-key.pem = private key openssl req -newkey rsa:2048 -days 3600 \\ -nodes -keyout client-key.pem -out client-req.pem openssl rsa -in client-key.pem -out client-key.pem openssl x509 -req -in client-req.pem -days 3600 \\ -CA ca.pem -CAkey ca-key.pem -set_serial 01 -out client-cert.pem 验证： openssl verify -CAfile ca.pem server-cert.pem client-cert.pem \r\r使用openssl创建RSA密钥 Creating RSA Keys Using openssl 创建： openssl genrsa -out private_key.pem 2048 openssl rsa -in private_key.pem -pubout -out public_key.pem chmod 400 private_key.pem chmod 444 public_key.pem \r\r\r","date":"2018-01-16","objectID":"/mysql/:35:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"安全插件 Security Plugins MySQL包括几个实现安全功能的插件： 用于MySQL C/S 连接尝试的插件 用于实施密码强度策略和评估潜在密码强度的密码验证插件 用于敏感信息安全存储的密钥环(keyring)插件 MySQL企业版插件 ","date":"2018-01-16","objectID":"/mysql/:36:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"身份认证插件 Authentication Plugins 原生可插拔认证 Native Pluggable Authentication MySQL包含两个实现原生身份认证的插件。在引入可插拔身份验证之前，基于密码散列的方法的身份验证。 本级密码验证的插件和库名称： Plugin or File Plugin or File Name Server-side plugin mysql_native_password Client-side plugin mysql_native_password Library file None (plugins are built in) 安装本机可插拔认证 Installing Native Pluggable Authentication mysql_native_password插件存在于Server和Client的表单中： S端插件内置于Server，无需显式加载，也无法通过卸载来禁用 C端插件内置于libmysqlclient库中，可用于链接到此库的任何程序 使用本机可插拔认证 Using Native Pluggable Authentication MySQL Client程序默认使用mysql_native_password。 \r\r旧的本机可插拔认证 Old Native Pluggable Authentication MySQL version 4.1机之前。 \r\r从旧的插件迁移到新的插件 Migrating Away from Pre-4.1 Password Hashing and the mysql_old_password Plugin \r\rSHA-256可插拔认证 SHA-256 Pluggable Authentication \r\r \r\r备份和恢复 Backup and Recovery 数据备份非常重要！ MySQL提供了各种备份策略，你可以从中选择最适合安装要求的方法。本章讨论几个你应该熟悉的备份和恢复的主题： 备份类型： 逻辑与物理，全量和增量… 创建备份的方法 恢复方法，包括时间点(point-in-time)恢复 备份调度，压缩和加密 表维护，以便恢复损坏的表 \r","date":"2018-01-16","objectID":"/mysql/:36:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"备份和恢复类型 Backup and Recovery Types \r","date":"2018-01-16","objectID":"/mysql/:37:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"物理与逻辑备份 Physical (Raw) Versus Logical Backups 物理备份由目录的原始副本和存储数据库内容的文件组成。 此类备份适用于需要在出现问题时快速恢复的大型重要数据库。 逻辑备份保存表示为逻辑数据库结构的信息(CREATE DATABASE, CREATE TABLE语句)和内容(INSERT语句和分割文本文件)。 此类备份适用于较少量的数据，你可以在其中编辑数据值或表结构，或在不同计算机体系结构上重新创建数据。 物理备份方法具有以下特征： 此备份包含数据库目录和文件的精确副本。通常，这是MySQL数据目录的全部或部分副本 物理备份比逻辑备份更快，因为它们只涉及文件复制而不进行转换 输出比逻辑备份更紧凑(compact) 由于备份速度和紧凑性对于繁忙、重要的数据库很重要，因此MySQL Enterprise执行物理备份 备份和还原粒度范围从整个数据目录的级别到单个文件的级别。这可能会/也可能不会提供表级别的粒度，具体取决于存储引擎 除数据库外，此备份还可以包括任何相关文件(如日志和配置) 来自MEMORY表的数据很难以这种方式备份，因为它们的内容不存储在磁盘上 备份仅可移植到具有相同或类似硬件特征的其它计算机 可以在MySQL Server未运行时执行备份。如果Server正在运行，则必须执行适当锁定(lock)，以便Server在备份期间不会更改数据库内容。MySQL Enterprise备份会自动为它需要的表执行锁定 物理备份工具包括用于InnoDB或任何其它表的mysqlbackup，或用于MyISAM表的文件系统级别命令(cp, scp, tar, rsync) 对于恢复 MySQL Enterprise备份恢复InnoDB和备份的其它表 ndb_restore恢复NDB表 可使用文件系统级别的命令将文件复制回其原始位置 逻辑备份方法具有以下特性： 通过查询MySQL Server来获取数据库结构和内容信心来完成备份 此备份比物理备份慢，因为Server必须访问数据库信息并将其转换为逻辑格式 输出大于物理备份，特别是以文本格式保存时 备份和还原可在Server级别，数据库级别或表级别，而无论存储引擎如何 备份不包括日志和配置文件，或其它不属于数据库的相关文件 以逻辑格式的备份与机器无关，请具有高度可移植性 在MySQL Server运行时执行逻辑备份 逻辑备份工具包括mysqldump程序和SELECT ... INTO OUTFILE语句。这适用于任何存储引擎，甚至是MEMORY 要恢复逻辑备份，可使用mysql客户端处理SQL格式转储文件。要加载分割文本文件，使用LOAD DATA INFILE语句或mysqlimport客户端 \r\r","date":"2018-01-16","objectID":"/mysql/:37:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"在线与离线备份 Online Versus Offline Backups 在MySQL Server运行时进行在线备份，以便可以从Server获取数据库信息。Server停止时进行离线备份。 这种区别也可描述为热备(hot)与冷备(cold)，热备是Server保持允许但在外部访问数据库时锁定表以防止修改数据 在线备份具有以下特性： 此备份对其它客户端的干扰较小，其它客户端可在备份期间连接到MySQL Server，并且可以根据需要执行的操作来访问数据库 必须小心施加适当的锁定，以便不会发生损害备份完整性的数据修改。MySQL Enterprise会自动执行锁表 脱机备份方法有以下特性： 客户端可能会受到不利影响，因为备份期间Server不可用。因此，此类备份通常发生于Slave Server，可以脱机而不会损害可用性 备份过程简单，因为不会受到客户端活动的干扰 在线和离线之间的区别适用于恢复操作，并且适用于类似的特征。但是，由于恢复需要更强的锁定，因此客户端更有可能受到在线恢复的影响而不是在线备份。在备份期间，客户端可能能够在备份时读取数据；而恢复数据不仅仅是读取数据，因此必须防止客户端在恢复数据时访问数据。 \r\r","date":"2018-01-16","objectID":"/mysql/:37:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"本地与远程备份 Local Versus Remote Backups 本地备份是在运行MySQL Server的统一主机上执行，而远程备份则从其它主机执行。 mysqldump能连接到本地或远程Server。对于SQL输出，既可在本地也可在远程；对于分割文件输出，将在Server上创建数据文件 SELECT ... INTO OUTFILE可从本地或远程启动，但输出文件是在Server上创建 物理备份通常在Server上启动，以便Server可以脱机 \r\r","date":"2018-01-16","objectID":"/mysql/:37:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"快照备份 Snapshot Backups 某些文件系统可以实现快照，它们在给定时间点提供文件系统的逻辑副本，而不需要整个文件系统的物理副本。MySQL本身并未提供此功能，可通过Veritas, LVM或ZFS… \r\r","date":"2018-01-16","objectID":"/mysql/:37:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"全量与增量备份 Full Versus Incremental Backups 全量备份包括MySQL Server在给定时间点管理的所有数据；增量备份包括在给定时间点跨度内（从一个时间点到另一个时间点）对数据所做的更改。 \r\r","date":"2018-01-16","objectID":"/mysql/:37:5","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"全量与增量恢复 Full Versus Point-in-Time (Incremental) Recovery 全量恢复可从完整备份恢复所有数据。这会将Server实例还原到备份时的状态。 增量恢复是恢复在给定时间点跨度内所做的更改，这也称为时间点恢复。它基于二进制日志，通常在备份文件完全恢复之后，将备份文件还原到备份时的状态。然后，在二进制日志文件中写入的数据更改将作为增量恢复应用于重做数据修改，并使Server达到所需的时间点。 \r\r","date":"2018-01-16","objectID":"/mysql/:37:6","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"表维护 Table Maintenance 如果表损坏，数据完整性可能会受到影响。 \r\r","date":"2018-01-16","objectID":"/mysql/:37:7","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"备份调度，压缩和加密 Backup Scheduling, Compression, and Encryption 备份调度对于自动化备份过程很有价值；压缩备份输出可减少空间需求；输出加密可提供更好的安全性，防止未经授权访问备份数据。 MySQL本身不提供这些功能，可使用第三方方案。 \r\r\r","date":"2018-01-16","objectID":"/mysql/:37:8","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"数据库备份方法 Database Backup Methods \r","date":"2018-01-16","objectID":"/mysql/:38:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用MySQL Enterprise进行热备 \r\r","date":"2018-01-16","objectID":"/mysql/:38:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用mysqldump进行备份 Making Backups with mysqldump mysqldump程序可以进行备份，它可以备份各种表。 \r\r","date":"2018-01-16","objectID":"/mysql/:38:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"通过复制表文件进行备份 Making Backups by Copying Table Files 对于使用自己的文件表示每个表的存储引擎，可通过复制这些文件来备份表。要获得一致性的备份，请停止服务器或锁定并刷新相关表： FLUSHTABLEStbl_listWITHREADLOCK; 你只需要一个读锁，这使得其它客户端可以在你复制数据库目录中的文件时继续查询表。需要刷新以确保在开始备份之前将所有活动索引页写入磁盘。 只要Server没有更新，你也可以通过复制所有表文件来创建二进制备份。 \r\r","date":"2018-01-16","objectID":"/mysql/:38:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"通过分隔文本文件备份 Making Delimited-Text File Backups 要创建包含表数据的分隔文本文件，可使用SELECT * INTO OUTFILE ‘filename’ FROM tablename语句进行创建。 此方法适用于任何类型的数据文件，但仅保存表数据，而不保存表结构。 要载入分隔文本文件，请使用LOAD DATA INFILE或mysqlimport。 \r\r","date":"2018-01-16","objectID":"/mysql/:38:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"通过启用二进制日志进行增量备份 Making Incremental Backups by Enabling the Binary Log MySQL支持增量备份，必须使用--log-bin选项启动Server以支持二进制日志记录。 二进制日志文件为你提供了在执行备份之后副本数据库所需的信息。目前，你希望进行增量备份，你应该使用FLUSH LOGS轮换二进制日志。完成此操作后，你需要将所有二进制日志复制到备份位置，这些日志的范围从上次完全备份或增量备份到最后一个备份之一。 \r\r","date":"2018-01-16","objectID":"/mysql/:38:5","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"通过使用副本集Slaves进行备份 Making Backups Using Replication Slaves 如果在进行备份时Master Server出现性能问题，可在Slave Server上进行复制和备份。 \r\r","date":"2018-01-16","objectID":"/mysql/:38:6","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"恢复损坏的表 Recovering Corrupt Tables 如果必须还原已损坏的MyISAM表，请尝试首先使用REPAIR TABLE或myisamchk -r恢复它们。这应该在99.9％的情况下有效。 \r\r","date":"2018-01-16","objectID":"/mysql/:38:7","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用文件系统快照进行备份 Making Backups Using a File System Snapshot VXFS文件系统操作步骤，其它文件系统类似： 客户端程序执行FLUSH TABLES WITH READ LOCK 从shell执行mount vxfs snapshot 解锁UNLOCK TABLES 从快照复制文件 umount快照 \r\r\r","date":"2018-01-16","objectID":"/mysql/:38:8","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"备份和恢复栗子 Example Backup and Recovery Strategy 请注意磁盘问题，万一是磁盘不可用那就… \r","date":"2018-01-16","objectID":"/mysql/:39:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"建立备份策略 Establishing a Backup Policy 为了有用，必须定期进行备份。可使用多种工具在MySQL中完成全量备份。 #备份之前锁表 mysqldump --single-transaction --all-databases \u003e bacup.sql 全量备份是必要的，但创建它们并不总是方便。生成大型备份文件要话费大量时间和空间，它并非最佳。所以，进行初始化全量备份，然后进行增量备份更有效。增量备份更小，时间更短。 要进行增量备份，需要保存增量更改。在MySQL中，这些更改在二进制日志中表示，因此应始终使用--log-bin选项启动MySQL Server已启动二进制日志。启用它之后，Server会在更新数据时将每个数据更改写入文件。 每次重启时，MySQL Server都会使用序列中的下一个数字创建创建一个新的二进制日志文件。在Server运行时，你还可以告诉它关闭当前的二进制日志文件并通过FLUSH LOGS语句或mysqladmin flush-logs命令手动开始新的二进制日志文件。mysqldump还有一个刷新日志的选项，数据目录中的.index文件包含目录中所有MySQL二进制日志的列表。 xxx-bin.000001 xxx-bin.000002 xxx-bin.000003 xxx-bin.000004 xxx-bin.index MySQL二进制日志对于恢复非常重要，因为它们构成了一组增量备份。如果确保在进行全量备份时刷新日志，则之后创建的二进制日志文件将包含自备份以来所做的所有数据的更改。 mysqldump --single-transaction --flush-logs --master-data=2 \\ --all-databases \u003e backup.sql #之后便会创建一个新的二进制日志文件 MySQL二进制日志占用磁盘空间，可不时删除它们。 mysqldump --single-transaction --flush-logs --master-data=2 \\ --all-databases --delete-master-logs \u003e backup.sql #在副本集中，使用mysqldump --delete-master-logs删除MySQL二进制日志可能会很危险，因为可能Slave Server尚未处理完二进制日志的内容 #可使用 PURGE BINARY LOGS语句删除 \r\r","date":"2018-01-16","objectID":"/mysql/:39:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用备份进行恢复 Using Backups for Recovery #全量恢复 mysql \u003c backup.sql #增量恢复 mysqlbinlog xxx-bin.000007 xxx-bin.000008 | mysql \r\r","date":"2018-01-16","objectID":"/mysql/:39:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"备份策略摘要 Backup Strategy Summary 不怕一万，就怕万一。InnoDB本身可以完成恢复数据的所有工作。但为了确保高枕无忧，请遵守以下准则： 始终使用--log-bin选项运行MySQL Server 使用mysqldump定期进行全量备份 使用FLUSH LOGS或mysqladmin flush-logs刷新日志来定期进行增量备份 \r\r\r","date":"2018-01-16","objectID":"/mysql/:39:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"mysqldump备份 Using mysqldump for Backups 本节介绍如何使用mysqldump生产转储文件，以及如何重新加载转储文件。转储文件可通过多种方式使用： 作为备份，在数据丢失的情况下启用数据恢复 作为设置副本集的数据源 作为实验数据源 mysqldump处理两种类型的输出，具体取决于有无-tab选项： 没有--tab选项，mysqldump将SQL语句写入标准输出。 输出包含用于创建转储对象(db, table, sotred routines)的CREATE语句，以及用于将数据加载到表中的INSERT语句。输出可保存到文件中。 带有--tab选项，mysqldump为每个转储的表生成两个输出文件。 Server将一个文件写为制表符(tab)分隔的文本，每个表的行(row)为文本的一行，输出名为table_name.txt。Server还将创建表的CREATE TABLE语句发送到mysqldump，mysqldump将其写为输出目录中名为table_name.sql的文件。 \r","date":"2018-01-16","objectID":"/mysql/:40:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用mysqldump以SQL格式转储数据 Dumping Data in SQL Format with mysqldump mysqldump [args] \u003e file_name #all db mysqldump --all-databases \u003e dbs.sql #specific db mysql --databases test \u003e testDB.sql mysqldump test \u003e testDB.sql mysqldump --databases db1 db2 db3 \u003e db123.sql mysqldump db1 db2 db3 \u003e db123.sql 关于有无--databases选项的区别： 转储输出不包含CREATE DATABASE或USE语句 重新加载转储文件时，必须指定默认数据库名称，以便Server知道要重新加载的数据库 对于重新加载，你可以指定与原始名称不同的数据库名，这使你可将数据重新加载到其它数据库中 如果要重载的数据库不存在，则必须先创建它 由于输出不包含CREATE DATABASE语句，因此--add-drop-database选项无效 \r\r","date":"2018-01-16","objectID":"/mysql/:40:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"只备份数据库表结构 mysqldump使用-d(--no-data)选项，可以只备份数据库中表结构，而不备份数据。 栗子： #-d(--no-data) #某个库中的所有表的结构 mysqldump -h xxx --port 3306 -u xxx -p -d 数据库名 \u003e 数据库名.sql #之后再导入 #某个表的结构 mysqldump -h xxx -u xxx -p -d --databases=xxx --tables xxx \u003e 表.sql \r\r","date":"2018-01-16","objectID":"/mysql/:40:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"重载SQL格式备份 Reloading SQL-Format Backups 要重载由mysqldump备份的包含SQL语句的转储文件，使用mysql客户端输入。 如果使用了--databases选项，则它包含了CREATE DATABASE和USE语句，就没有必要指定默认数据库。 mysql \u003c dump.sql #或 mysql\u003e source dump.sql #未使用--databases选项 mysqladmin create db1 mysql db1 \u003c dump.sql \r\r","date":"2018-01-16","objectID":"/mysql/:40:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用mysqladmin以分隔文本格式转储数据 Dumping Data in Delimited-Text Format with mysqldump 本节介绍如何使用mysqldump创建分隔文本转储文件。 mysqldump --tab=/tmp db1 #db1.txt #其它选项： --fields-terminated-by=str --fields-enclosed-by=char --fields-optionally-enclosed-by=char --fields-escaped-by=char --lines-terminated-by=str #栗子 mysqldump --tab=/tmp --fields-terminated-by=, --fields-enclosed-by='\"' --lines-terminated-by=0x0d0a db1 \r\r","date":"2018-01-16","objectID":"/mysql/:40:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"重载分隔文本格式的备份 Reloading Delimited-Text Format Backups mysql db1 \u003c t1.sql mysqlimport db1 t1.txt USEdb1;LOADDATAINFILE`t1.txt`INTOTABLEt1; \r\r","date":"2018-01-16","objectID":"/mysql/:40:5","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"mysqldump小技巧 本节介绍使用mysqldump解决特定问题的技术： 如何复制数据库 如何将数据库从一个Server复制到另一个Server 如何转储存储的程序 如何单独转储定义和数据 \r复制数据库 Making a Copy of a Database mysqldump db1 \u003e dump.sql mysqladmin create db2 mysql db2 \u003c dump.sql \r将数据库从一个Server复制到另一个Server Copy a Database from one Server to Another #Server1 mysqldump --databases db1 \u003e dump.sql #Server2 mysql \u003c dump.sql #无--databases mysqldump db1 \u003e dump.sql mysqladmin create db1 mysql db1 \u003c dump.sql \r转储存储的程序 Dumping Stored Programs 几个选项控制mysqldump如何处理存储的程序： --events: Dump Event Scheduler events --routines: Dump stored procedures and functions --triggers: Dump triggers for tables --skip-events --skip-routines --skip-triggers. \r转储表定义和 Dumping Table Definitions and Content Separately #--no-data，不转储表数据，导致转储文件只包含用于创建表的语句 #--no-create-info, 从输出中抑制CREATE语句，以便转储文件包含表数据 mysqldump --no-data test \u003e dump-defs.sql mysqldump --no-create-info test \u003e dump-data.sql mysqldump --no-data --routines --events test \u003e dump-defs.sql \r使用mysqldump测试升级不兼容性 Using mysqldump to Test for Upgrade Incompatibilities #old mysqldump --all-databases --no-data --routines --events \u003e dump-defs.sql #new mysql \u003c dump-defs.sql \r\r\r","date":"2018-01-16","objectID":"/mysql/:40:6","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用二进制日志进行增量恢复 Point-in-Time (Incremental) Recovery Using the Binary Log 时间点恢复是指恢复自给定时间点以来所做的数据更改。通常，在还原全量备份之后执行此类恢复。 时间点恢复基于以下原则： 时间点恢复的信息源是由全量备份操作之后生成的二进制日志文件表示增量备份集，请开启--bin-log选项 要从二进制日志还原数据，你必须知道二进制日志文件的名称和位置，默认情况下，它在数据目录中。 SHOWBINARYLOGS;--确定当前binary log file名称 SHOWMASTERSTATUS; mysqlbinlog实用程序将二进制日志文件中的事件从二进制格式转换为文本，以便可以执行或查看它们 mysqlbinlog具有根据日志中事件时间或事件位置选择二进制日志部分的选项。 从二进制日志执行事件会导致重做它们所代表的数据修改，这样可以恢复给定时间段内的数据更改。 #从二进制日志中执行事件 mysqlbinlog binlog_files | mysql -u root -p 当需要确定事件时间或位置以在执行事件之前选择部分日志内容时，查看日志内容很有用 #查看binary log mysqlbinlog binlog_file | more #或 mysqlbinlog binlog_file \u003e tmpfile 将输出保存在文件中非常有用，可以在删除某些事件时执行日志内容 mysql -u root -p \u003c tmpfile 如果要在MySQL Server上执行多个二进制日志，安全的方法是使用与Server的单个连接来处理它们 #unsafe #可能导致某些问题 mysqlbinlog binlog.000001 | mysql -u root -p # DANGER!! mysqlbinlog binlog.000002 | mysql -u root -p # DANGER!! #safe mysqlbinlog binlog.000001 binlog.000002 | mysql -u root -p #或 mysqlbinlog --skip-gtids binlog.000001 \u003e /tmp/statements.sql mysqlbinlog --skip-gtids binlog.000002 \u003e\u003e /tmp/statements.sql mysql -u root -p -e \"source /tmp/statements.sql\" \r\r","date":"2018-01-16","objectID":"/mysql/:41:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用事件时间进行时间点恢复 Point-in-Time Recovery Using Event Times 要指示恢复的开始和结束时间，请以DATATIME格式指定mysqlbinlog的--start-datetime和--stop-datetime选项。 请先查看binary log的时间区间。 #恢复数据直到停止时间 mysqlbinlog --stop-datetime=\"2005-04-20 9:59:59\" \\ /var/log/mysql/bin.123456 | mysql -u root -p #恢复数据从开始时间 mysqlbinlog --start-datetime=\"2005-04-20 10:01:00\" \\ /var/log/mysql/bin.123456 | mysql -u root -p \r\r","date":"2018-01-16","objectID":"/mysql/:41:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用事件位置进行时间点恢复 Point-in-Time Recovery Using Event Positions mysqlbinlog的--start-position和--stop-position选项可用于指定日志位置，它的工作方式与指定时间类似。使用位置可以更准确地了解要恢复的日志部分，尤其是在许多事务与破坏性语句同时发生的情况下。 要确定位置编号，请在执行不需要的事物的时间附近运行mysqlbinlog一段时间，但将结果重定向到文本文件以供检查: mysqlbinlog --start-datetime=\"2005-04-20 9:55:00\" \\ --stop-datetime=\"2005-04-20 10:05:00\" \\ /var/log/mysql/bin.123456 \u003e /tmp/mysql_restore.sql 位置编号以log_pos数字进行标记，查看并找到相应的位置标号，之后便可使用它们。 mysqlbinlog --stop-position=368312 /var/log/mysql/bin.123456 \\ | mysql -u root -p mysqlbinlog --start-position=368315 /var/log/mysql/bin.123456 \\ | mysql -u root -p \r\r\r","date":"2018-01-16","objectID":"/mysql/:41:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MyISAM表维护和崩溃恢复 MyISAM Table Maintenance and Crash Recovery 本节讨论了如何使用myisamchk检查或修复MyISAM表——具有用于存储数据和索引的.MYD和.MYI文件。 你可以使用myisamchk来检查、修复、优化数据库表。 尽管使用myisamchk进行表修复十分安全，但在进行修复或任何可能对表进行大量更改的维护操作之前进行备份总是一个好主意。 影响索引的myisamchk操作可能导致使用与MySQL Server使用的值不兼容的全文参数重建MyISAM FULLTEXT索引。 MyISAM表也可以使用类似于myisamchk操作的SQL语句来完成： 检查MyISAM表，CHECK TABLE 修复MyISAM表，REPAIR TABLE 优化MyISAM表，OPTIMIZE TABLE 分析MyISAM表，ANALYZE TABLE 这些语句可以直接使用，也可通过mysqlcheck客户端程序使用。这些语句相对于myisamchk的一个优点是Server可以完成所有工作。使用myisamchk，你必须确保Server不会同时使用这些表，以便myisamchk和Server之间不会发生不需要的交互。 \r","date":"2018-01-16","objectID":"/mysql/:42:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用myisamchk进行崩溃恢复 Using myisamchk for Crash Recovery 如果在禁用外部锁定(default)的情况下运行mysqld，则当mysqld使用同一个表时，你无法可靠地使用myisamchk来检查表。如果你可以确定在运行myisamchk时没有人会通过mysql访问表，你只需要在开始检查表之前执行mysqladmin flush-tables。如果你不能保证这一点，你必须在检查表时停止mysqld。如果你运行myisamchk来检查mysqld同时更新的表，你可能会收到一个警告，即使表没有也如此。 如果Server启用了外部锁定(external locking)，则可以随时使用myisamchk检查表。在这种情况下，如果Server尝试更新myisamchk正在使用的表，Server将等待myisamchk完成后再继续。 如果要使用myisamchk来修复或优化表，则必须始终确保mysqldServer未使用该表(或外部锁定)。如果没有停止mysqld，你应该在运行myisamchk之前至少做一个mysqladmin flush-tables。如果Server和myisamchk同时访问表，你的表可能会损坏。 执行崩溃恢复时，请务必了解数据库中每个MyISAM表table_name都对应于下面现实的数据库目录中的三个文件: #数据文件和索引文件最常出问题 tbl_name.frm Definition (format) file tbl_name.MYD Data file tbl_name.MYI Index file myisamchk的工作原理时逐行创建.MYD数据文件的副本。它通过删除旧的.MYD文件并将新文件重命名为原始文件名来结束修复阶段。 如果使用--quick选项，myisamchk不会创建临时的.MYD文件，而是假定.MYD文件正确并且只生成新的索引文件而不触及.MYD文件。这是安全的，因为myisamchk会自动检查.MYD文件是否已损坏，如果存在则终止修复。 \r\r","date":"2018-01-16","objectID":"/mysql/:42:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"如何检查MyISAM表是否存在错误 How to Check MyISAM Tables for Errors 使用以下命令检查MyISAM表： myisamchk tbl_name 这能发现99.99%的错误，它找不到的是仅涉及数据文件的损坏。 myisamchk -m tbl_name 这能发现99.999%的错误。它首先检查所有索引条目是否有错，然后读取所有行。它计算行中所有键值的校验和，并验证校验和是否与索引树种键的校验和匹配。 myisamchk -e tbl_name 这可以对所有数据进行全面彻底的检查。 myisamchk -e -i tbl_name 打印更多统计信息 \r\r","date":"2018-01-16","objectID":"/mysql/:42:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"如何修复MyISAM表 How to Repair MyISAM Tables 你同样可使用CHECK TABLE和REPAIR TABLE语句来检查和修复MyISAM表。 损坏的表的症状： tbl_name.frm被锁定以防止修改 找不到文件tbl_name.MYI(Errorcode: nnn) 意外的文件结束 记录文件崩溃 从表处理获得error nnn 获取更多有关错误的信息： #perror nnn perror 126 127 132 134 135 136 141 144 145 MySQL error code 126 = Index file is crashed MySQL error code 127 = Record-file is crashed MySQL error code 132 = Old database file MySQL error code 134 = Record was already deleted (or record file crashed) MySQL error code 135 = No more room in record file MySQL error code 136 = No more room in index file MySQL error code 141 = Duplicate unique key or constraint on write or update MySQL error code 144 = Table is crashed and last repair failed MySQL error code 145 = Table was marked as crashed and should be repaired 如果要从命令行修复表，则必须先停止mysqld Server。请注意，当你在远程Server执行mysqladmin shutdown时，mysqld Server在mysqladmin返回后仍然可用一段时间，直到所有语句处理并已停止并且所有索引更改都已刷新到磁盘。 步骤1： 检查表 myisamchk *.MYI #myisamchk -e *.MYI #如果mysqld已停止，使用--update-state告诉myisamchk将表标记为已检查 myisamchk --update-state *.MYI 步骤2： 简易修复表 #尝试修复索引，而不触及数据 myisamchk -r -q table_name #数据 1. 数据备份 2. myisamchk -r table_name #这将删除不正确的行和以排除的行，并重构索引文件 3. 如果上一步失败，请使用 myisamchk --safe-recover tbl_name 4. 如果遇到意外错误，查看第3步 步骤3： 难以修复 #只有当索引文件中的第一个16KB块被销毁或包含不正确的信息，或索引文件丢失时，才应该到达此阶段。 #这种情况系，需要创建一个新的索引文件 1. 将数据移动到安全的地方 2. 创建空数据和新索引 mysql db_name mysql\u003e SET autocommit=1; mysql\u003e TRUNCATE TABLE table_name; mysql\u003e QUIT 3. 将旧的数据文件复制回新创建的数据文件 4. 重新执行步骤2 步骤4： 很难修复 #仅当.frm描述文件也崩溃时才应该到达此阶段 #这应该永远不会发生，因为创建表后描述文件不会发生更改 1. 从备份还原描述文件并回到步骤3 2. 如果没有备份，但确切知道如何创建表，请在另一个数据库中创建该表的副本。删除新数据文件，然后将.frm和.MYI移动到崩溃的数据库。返回步骤2尝试重建索引文件 \r\r","date":"2018-01-16","objectID":"/mysql/:42:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"优化MyISAM表 MyISAM Table Optimization 要合并碎片行并消除因删除或更新行而导致的浪费空间，请在恢复模式下运行myisamchk: myisamchk -r table_name 你也可以通过OPTIMIZE TABLE的SQL语句进行表优化。此语句执行表修复和Key 分析，并对索引数进行排序，以便Key查找更快。 myisamchk有许多其它选项可用于提高表的性能： --analyze or -a 执行Key分析。这可通过使连接优化器更好地选择连接表的顺序自己应该使用的索引来提高连接性能。 --sort-index or -S 排序索引块。这可优化搜索并使表扫描更快地使用索引。 --sort-records=index_num or -R index_num 根据给定索引对数据行进行排序。这可使数据更加本地化，并可以加速使用此索引的基于范围的SELECT和ORDER BY操作 \r\r","date":"2018-01-16","objectID":"/mysql/:42:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"配置MyISAM表维护计划 Setting Up a MyISAM Table Maintenance Schedule 最好定期执行检查表，而不是等着问题发生。 启用自动检查MyISAM表也是一个好主意。 还应该在正常系统操作期间定期检查你的表。 #栗子 35 0 * * 0 /path/to/myisamchk --fast --silent /path/to/datadir/*/*.MYI myisamchk -r -s --sort-index --myisam_sort_buffer_size=16M */*.MYI \r\r \r\r优化 Optimization 本章介绍如何优化MySQL性能并提供示例。优化涉及多个级别配置，调整和测量性能。根据你的工作角色(Developer、DBA、both)，你可在单个SQL语句、整个应用程序、单个数据库Server、多个网络数据库Server的级别进行优化。 有时你可以主动并提前计划性能，而有时可能会在出现问题后解决配置或代码问题。优化CPU和内存使用还可以提供伸缩性，允许数据库处理更多负载而不会降低速度。 \r","date":"2018-01-16","objectID":"/mysql/:42:5","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"优化概述 Optimization Overview 数据库性能取决于数据库级别的几个因素，如表、查询、配置设置。这些软件结构导致硬件级别的CPU和I/O操作，你必须尽可能降低这些操作并使其尽可能高效。在处理数据库性能时，首先要了解软件方面的高级规则和指南，并使用**挂钟时间(wall-clock time)**来衡量性能。当你成为专家后，你将了解更多内部发生的信息，并开始测量CPU周期和I/O操作… 典型用户的目标是从现有的软件和硬件配置中获取最佳的数据库性能；高级用户寻找改进MySQL软件本身的机会，或者开发自己的存储引擎或硬件设备来扩展MySQL生态系统。 \r\r","date":"2018-01-16","objectID":"/mysql/:43:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"数据库级别的优化 Optimizing at the Database Level 使数据库应用程序快速运行的最重要的因素是其基本设计： 表结构是否合适？ 特别是，列(columns)是否具有正确的数据类型，并且每个表是否具有适合工作类型的列？ 例如，更新频繁的应用程序通常具有少量列的许多表；而分析大量数据的应用程序通常具有大量列的少量表。 是否有适当的索引来提高查询效率？ 是否为每个表使用了适当的存储引擎，并利用使用的每个存储引擎的优势和功能？ 特别是，诸如InnoDB之类的事务性(transactional)存储引擎或诸如MyISAM之列的非事务性(nontransactional)存储引擎的选择，对于性能和伸缩性非常重要。 InnoDB是新表的默认存储引擎。实际上，先进的InnoDB性能特征意味着InnoDB表通常优于更简单的MyISAM表，尤其是对于繁忙的数据库。 是否每个表都使用了适当的行格式？ 这取决于表所使用的数据库。 特别是，压缩的表使用较少的磁盘空间，因此需要较少的磁盘I/O来读取和写入数据。压缩适用于InnoDB表的各种工作负载，以及只读(read-only)MyISAM表。 是否应用程序使用了适当的锁定策略？ 例如，通过允许共享访问，以便数据库操作可以并发运行，并在适当时请求独占访问，以便关键操作成为首要任务。 同样，存储引擎的选择也很重要。InnoDB存储引擎可以处理大多数锁定问题而无需你的参与，从而在数据库中实现更好的并发性，并减少代码的实验和调优。 是否正确使用了用于缓存的所有内存区域？ 也就是说，足够大以容纳频繁访问的数据，但不能太大以至于它们会超载物理内存并导致分页。要配置的主缓存区域是：InnoDb缓冲池，MyISAM key缓存、MySQL查询缓存。 \r\r","date":"2018-01-16","objectID":"/mysql/:43:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"硬件级别的优化 Optimizing at the Hardware Level 随着数据库变得越来越繁忙，任何数据库应用程序最终都会达到硬件限制。DBA必须评估是否可以调整应用程序或重新配置Server以避免这些瓶颈(bottlenecks)，或者是否需要更多硬件资源？ 系统瓶颈通常来自于这些来源： 磁盘需求 磁盘需要一段时间才能找到一段数据。对于现代磁盘，平均时间通常低于10ms。优化搜索时间的方法是将数据分发到多个磁盘上。 磁盘读写 当磁盘位于正确位置时，我们需要读写数据。可以从多个磁盘并行读取。 CPU周期 当数据在主存储器中时，我们必须处理它们以获得我们想要的结果。 内存带宽 当CPU需要的数据量超过了CPU缓存容量时，主存带宽就成了瓶颈。 \r\r","date":"2018-01-16","objectID":"/mysql/:43:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"平衡移植性和性能 Balancing Portability and Performance 要在可移植的MySQL程序中使用面向性能的SQL扩展，你可在语句中包含MySQL特定关键字/* ... */评论分隔符(或--注释) \r\r\r","date":"2018-01-16","objectID":"/mysql/:43:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"优化SQL语句 Optimizing SQL Statements 数据库应用程序的核心逻辑是通过SQL语句执行的，无论是直接通过解释器还是通过API在幕后提交。 \r","date":"2018-01-16","objectID":"/mysql/:44:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"优化SELECT语句 Optimizing SELECT Statements 查询以SELECT语句的形式执行数据库中的所有查找操作。调整这些语句的首要任务就是缩短响应时间。 除了SELECT语句外，查询的调优技术也适用于DELETE语句中的CREATE TABLE ... AS SELECT, INSERT INTO ... SELECT和WHERE等构造子句。这些语句具有额外的性能考虑因素，因为它们将写操作与面向读操作的查询相结合。 优化查询的主要考虑因素有： 要使一个慢的SELECT ... WHERE查询更快，首先要检查是否可以添加索引。在WHERE字句中使用的列上设置索引，以加快评估、过滤和结果的最终检索。为避免浪费磁盘空间，请构建一小组索引，以加速应用程序中使用的许多相关查询。索引对于引用不同表的查询尤其重要，使用连接(joins)和外键(foreign keys)等功能。 隔离并调整查询的任何部分，例如函数调用，这会占用过多时间。根据查询的结构，可以为结果集中的每一行调用一次函数，甚至可以为表中的每一行调用一次函数，从而大大减轻任何低效率。 最大限度地减少查询中的全表扫描次数，尤其是对于大型表。 定期使用ANALYZE TABLE语句使表统计信息保持最新，因此优化程序具有构建有效执行计划所需的信息。 了解特定于每个表的存储引擎的调优技术，索引技术和配置参数。InnoDB和MyISAM都有一套指导方针，可以在查询中实现和维持高性能。 你可以优化InnoDB表的单查询事务。 避免以难以理解的方式转换查询。 如果其中一个基本准则无法轻松解决性能问题，请通过阅读EXPLAIN计划并调整索引、WHERE子句、JOIN子句等来调查特定查询的内部详细信息。 调整MySQL用于缓存区域的大小和属性。通过有效使用InnoDB buffer pool、MyISAM key cache、MySQL query cache，重复查询运行的更快，因为在第二次及以后的时间内都是从内存中检索结果 即使对于使用高速缓存存储区快速运行的查询，你仍可以进一步优化，以便它们需要更少的高速缓存，从而使你的应用程序更具可伸缩性。可伸缩性意味着你的应用程序可以处理更多的并发用户，更大的请求…，而不会出现性能大幅下降的情况 处理锁定问题，其中查询的速度可能会受到同时访问表的其它回话的影响 \r\rWHERE子句优化 WHERE Clause Optimization 你可能想要重写查询以更快地进行过算数运算，同时牺牲可读性。因为MySQL会自动执行类似的优化，所以通常可以避免这种工作，并使查询保持更容易理解和可维护的形式。 移除不必要的括号 ((aANDb)ANDcOR(((aANDb)AND(cANDd))))--\u003e (a AND b AND c) OR (a AND b AND c AND d) 恒量折叠 (a\u003cbANDb=c)ANDa=5--\u003e b\u003e5 AND b=c AND a=5 恒量条件去除 (B\u003e=5ANDB=5)OR(B=6AND5=5)OR(B=7AND5=6)--\u003e B=5 OR B=6 索引使用的常量表达式仅计算一次 早期检测无效常量表达式 如果不使用GROUP BY或聚合函数(COUNT(), MIN()...)，HAVING将与WHERE合并 对于连接中的每个表，构造一个更简单的WHERE以获得对表的快速平均，并且还尽快跳过行 在查询中的任何其它表之前，首先读取所有常量表： 一个空表或只有一行的表 与主键或唯一索引上的WHERE子句一起使用的表，其中所有索引部分都与常量表达式进行比较并定义为NOT NULL 以下所有表都用作常量表： SELECT*FROMtWHEREprimary_key=1;SELECT*FROMt1,t2WHEREt1.primary_key=1ANDt2.primary_key=t1.id; 通过尝试所有可能性，可以找到加入表格的最佳连接组合。如果ORFER BY和GROUP BY子句中的所有列都来自同一个表，则在加入时首先选择该表 如果存在ORDER BY子句和不同的GROUP BY子句，或者ORDER BY或GROUP BY包含连接队列中第一个表以外的表中的列，则会创建临时表 如果使用SQL_SMALL_RESULT修饰符，MySQL将使用内存中的临时表 查询每个表索引，并使用最佳索引，除非优化程序认为使用表扫描更有效。 在某些情况下，MySQL甚至无需查阅数据文件即可从索引中读取行。 在输出每一行之前，将跳过与HAVING子句不匹配的行。 一些非常快的查询示例： SELECTCOUNT(*)FROMtbl_name;SELECTMIN(key_part1),MAX(key_part1)FROMtbl_name;SELECTMAX(key_part2)FROMtbl_nameWHEREkey_part1=constant;SELECT...FROMtbl_nameORDERBYkey_part1,key_part2,...LIMIT10;SELECT...FROMtbl_nameORDERBYkey_part1DESC,key_part2DESC,...LIMIT10; MySQL使用索引数解析一下查询，假设索引列是数字： SELECTkey_part1,key_part2FROMtbl_nameWHEREkey_part1=val;SELECTCOUNT(*)FROMtbl_nameWHEREkey_part1=val1ANDkey_part2=val2;SELECTkey_part2FROMtbl_nameGROUPBYkey_part1; 以下查询使用索引来按排序顺序检索行，而不使用单独的排序传递： SELECT...FROMtbl_nameORDERBYkey_part1,key_part2,...;SELECT...FROMtbl_nameORDERBYkey_part1DESC,key_part2DESC,...; \r\r范围优化 Range Optimization range访问方法使用单个索引来检索包含在一个或多个索引值间隔内的表行的子集。他可用于单部分(single-part)或多部分(multiple-part)索引。 \r单部分索引的范围访问方法 Range Access Method for Single-Part Indexes 对于单部分索引，索引值间隔可以方便地由WHERE子句中相应条件表示，表示为范围条件而不是间隔。 单部分索引的范围索引条件的定义如下： 对于BTREE和HASH索引，使用=, \u003c=\u003e, IN(), IS NULL, IS NOT NULL运算符时，关键部分与常量值的比较是范围条件 另外，对于BTREE索引，关键部分与常量值的比较是使用\u003e, \u003c, \u003e=, \u003c= between, !=, \u003c\u003e运算符时的范围条件，或者LIKE比较时的LIKE比较是一个不以通配符开头的常量字符串 对于所有索引类型，多个范围条件与OR或AND组合形成范围条件 常量值表示一下之一： 来自查询字符串中的常量 来自同一连接(join)的const或system表的列 不相关子查询的结果 由前面类型的子表达式组成的任何表达式 WHERE子句中带有范围条件的查询的栗子： SELECT*FROMt1WHEREkey_col\u003e1ANDkey_col\u003c10;SELECT*FROMt1WHEREkey_col=1ORkey_colIN(15,18,20);SELECT*FROMt1WHEREkey_colLIKE'ab%'ORkey_colBETWEEN'bar'AND'foo'; MySQL尝试从每个可能索引的WHERE子句中提取范围条件。在提取过程期间，丢弃不能用于构建范围条件的条件，组合产生重叠范围的条件，并且去除产生空范围的条件。 通常，用于范围扫描的条件比WHERE子句的限制性更小。MySQL执行额外的检查以过滤掉满足范围条件但不满足完整WHERE子句的行。 MySQL不支持合并空间索引的范围方法的多个范围。要解决此限制，可以使用具有相同SELECT语句的UNION，但将每个空间谓词放在不同的SELECT中。 \r多部分索引的范围访问方法 Range Access Method for Multiple-Part Indexes 多部分索引的范围条件是单部分索引范围条件的扩展。多部分索引上的范围条件将索引行限制在一个或多个关键元组上定义关键元组间隔。 例如，考虑定义为key1(key_part1, key_part2, key_part3)的多部分索引： key_part1 key_part2 key_part3 NULL 1 'abc' NULL 1 'xyz' NULL 2 'foo' 1 1 'abc' 1 1 'xyz' 1 2 'abc' 2 1 'aaa' 条件key_part1 = 1定义此间隔：(1,-inf,-inf) \u003c= (key_part1,key_part2,key_part3) \u003c (1,+inf,+inf) 此间隔覆盖前面数据集中的第4、第5、第6个元组，并且可以由范围访问方法使用。 相反，条件key_part3 = 'abc'不定义单个间隔，并且不能由方位访问方法使用。 以下描述详细地说明了范围条件如何适用于多部分索引： 对于HASH索引，可使用包含相同值的每个间隔。 --const1, const2, ...都是常量 ---cmp指的是=, \u003c=\u003e, IS NULL比较运算符 --条","date":"2018-01-16","objectID":"/mysql/:44:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"优化和索引 Optimization and Indexes 提高SELECT操作性能的最佳方法是在查询中测试的一个或多个列上创建索引。索引条目的作用类似于表行的指针，允许查询快速确定哪些行与WHERE字句中的条件匹配，并检索这些行的其它列值。 所有MySQL数据类型都可被索引。 尽管为查询中每个可能使用的列创建索引很有诱惑力，但不必要的索引会浪费空间并浪费时间让MySQL确定要使用的索引。索引还会增加insert, update, delete的成本，因为必须更新每个索引。 你必须找到适当的平衡，以使用最佳索引集实现快速查询。 \r","date":"2018-01-16","objectID":"/mysql/:45:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL如何使用索引 How MySQL Uses Indexes 索引用于快速查找具有特定列值(column value)的行(row)。如果没有索引，MySQL必须从第一行开始，然后读取整个表以查找相关行。表越大，成本越高。如果表中有相关列的索引，MySQL可以快速确定要在数据文件中间寻找的位置，而无需查看所有数据。这比按顺序读取每一行要快得多。 大多数MySQL索引(PRIMARY KEY, UNIQUE, INDEX, FULLTEXT)都存储在**B树(B-trees)**中。有几个例外： 空间数据类型的索引使用R树(R-trees) MEMORY表同样支持hash索引 InnoDB对FULLTEXT使用反转列表(inverted lists) MySQL使用索引进行这些操作： 快速查找与WHERE子句匹配的行 出于消除行的考虑。如果在多个索引之间有选择，MySQL通常使用找到最小行数的索引 如果表具有多列索引，则优化程序可以使用索引的任何左前缀来查找行 在执行join时从其它表中检索行。如果声明它们的类型和大小相同，MySQL可以更有效地使用列上的索引。如VARCHAR(10)和CHAR(10)的大小相同。 对于非二进制字符串之间的比较，两列应使用相同的字符集。 查找特定索引列key_col的MIN()和MAX()值，这是由预处理器优化的，它检查是否在索引中key_col之前出现的所有关键部分上使用WHERE key_part_N = 常量。在这种情况下，MySQL对每个MIN()或MAX()表达式执行单个键查找，并用常量替换它。如果所有表达式都替换为常量，则查询立即返回。 SELECTMIN(key_part2),MAX(key_part2)FROMtbl_nameWHEREkey_part1=10; 如果对可用索引的最左前缀进行排序或分组，则对表进行排序或分组。 在某些情况下，可以优化查询以在不咨询数据行的情况下检索值。 对于小型表的查询，或大型表所有行的查询，索引不太重要。当查询要访问大多数行时，顺序读取比通过索引更快。顺序读取可以最大限度地减少磁盘搜索，即使查询不需要所有行也是如此。 \r\r","date":"2018-01-16","objectID":"/mysql/:45:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"主键优化 Primary Key Optimization 表的主键(primary key)表示你在最重要的查询中使用的列或列的集合。它具有关联的索引，以实现快速查询优化。查询性能受益于NOT NULL，因为它不能包含任何NULL值。使用InnoDB存储引擎，表格数据在物理化上进行组织，以根据主键或列进行超快速查找和排序。 如果你的表又大又重要，但没有明显的列或列的集合作为主键，则可创建一个单独的列，其中包含自动增量值以用作主键。当你使用外键(foreign key)联接(join)表时，这些唯一ID可用于指向其它表中相应行的指针。 \r\r","date":"2018-01-16","objectID":"/mysql/:45:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"外键优化 Foreign Key Optimization 如果一个表有很多列，并且你查询了许多不同的列组合，那么将频率较低的数据拆分为每个都有几列的单独表可能会很有效，并通过从主表中复制数字ID列将它们与主表相关联。这样，每个小表都可以有一个主键来快速查找器数据，并且你可以使用连接操作仅查询所需的列集。根据数据的分布方式，查询可能会执行较少的I/O并占用较少的高速缓存，因为相关列在磁盘上打包在一起。 为了最大限度地提高性能，查询尝试从磁盘中读取尽可能少的数据块；只有几列的表可以在每个数据块中容纳更多行。 \r\r","date":"2018-01-16","objectID":"/mysql/:45:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"列索引 Column Indexes 最常见的索引类型涉及单个列，在数据结构中存储该列的值的副本，允许快速查找具有相应列值的行。**B树(B-tree)**数据结构允许索引在WHERE子句中快速查找特定值，一组值或一系列值。 索引前缀(Index Prefixes) 使用字符串列的索引规范中的col_name(N)语法，可以创建使用列的前N个字符的索引。以这种方式仅索引列值的前缀，可以使索引文件更小。当索引BLOB或TEXT列，必须为索引指定前缀长度。 前缀最长可达1000 Byte，InnoDB表为767Byte(除非你设置了innodb_larger_prefix) CREATETABLEtest(blob_colBLOB,INDEX(blob_col(10))) 全文索引(FULLTEXT Indexes) 全文索引用于全文搜索。只有InnoDB和MyISAM存储引擎支持FULLTEXT索引，并且仅支持CHAR, VARCHAR, TEXT列。索引始终发生在整个列上，并且不支持前缀索引。 空间索引(Spatial Indexes) 你可以在空间数据类型上创建索引。MyISAM和InnoDB支持空间类型的R树(R-trees)索引。其它存储引擎使用B树来索引空间类型。 MEMORY存储引擎中的索引 MEMORY存储引擎默认使用HASH索引，但也支持B树索引。 \r\r","date":"2018-01-16","objectID":"/mysql/:45:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"多列索引 Multiple-Column Indexes MySQL可以创建复合索引(composite indexes)——即多列上的索引，索引最多包含16列。对于某些数据类型，你可以索引列的前缀。 MySQL可以对测试索引中的所有列的查询使用多列索引，或者只测试第一列，前几列等的查询。如果在索引定义中以正确的顺序指定列，则单个复合索引可以加速同一表上的多种查询。 多列索引可被视为排序数组，其行包含通过连接索引列的值创建的值。 假设某表如下： CREATETABLEtest(idINTNOTNULL,last_nameCHAR(30)NOTNULL,first_nameCHAR(30)NOTNULL,PRIMARYKEY(id),INDEXname(last_name,first_name));/* name索引是一个包含两列的索引，它可用于查询中的查询。 可组合last_name和first_name的值进行查询，还可仅指定该索引的最左前缀last_name的值进行查询 */--因此，name索引可用于以下查询 SELECT*FROMtestWHERElast_name='Widenius';SELECT*FROMtestWHERElast_name='Widenius'ANDfirst_name='Michael';SELECT*FROMtestWHERElast_name='Widenius'AND(first_name='Michael'ORfirst_name='Monty');SELECT*FROMtestWHERElast_name='Widenius'ANDfirst_name\u003e='M'ANDfirst_name\u003c'N';--然而，name索引无法用于以下查找 SELECT*FROMtestWHEREfirst_name='Michael';SELECT*FROMtestWHERElast_name='Widenius'ORfirst_name='Michael'; \r\r","date":"2018-01-16","objectID":"/mysql/:45:5","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"验证索引使用 Verifying Index Usage 始终检查所有查询是否确实使用你在表中创建的索引，使用EXPLAIN语句。 \r\r","date":"2018-01-16","objectID":"/mysql/:45:6","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"InnoDB和MyISAM索引统计 InnoDB and MyISAM Index Statistics Collection 存储引擎收集有关表的统计信息，供优化器使用。表统计信息基于值组(value group)，其中值组是具有相同键(key)前缀值的一组行。优化器的目的，一个重要统计信息是值组大小的平均值。 MySQL使用值组大小的平均值的方式如下： 估计每个ref访问必须读取多少行 估计一个部分联接将产生多少行，即此表单的操作将产生的行数： (...) JOIN tbl_name ON tbl_name.key = expr \r\r","date":"2018-01-16","objectID":"/mysql/:45:7","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"B树和Hash索引的比较 Comparison of B-Tree and Hash Indexes 了解 **B树(B-Tree)和哈希(Hash)**数据结构有助于预测不同查询在索引中使用这些数据结构的不同存储引擎上的执行情况，特别是MEMORY存储引擎。 \rB树索引 B-Tree Index Characteristics B树索引可用于 =, \u003c, \u003e, \u003c=, \u003e=, BETWEEN运算符的表达式中的列比较。如果LIKE的参数是不以通配符开头的常量字符串，则它也可用于LIKE比较。 #SELECT使用索引的栗子SELECT*FROMtbl_nameWHEREkey_colLIKE'Patrick%';SELECT*FROMtbl_nameWHEREkey_colLIKE'Pat%_ck%';#SELECT没有使用索引SELECT*FROMtbl_nameWHEREkey_colLIKE'%Patrick%';SELECT*FROMtbl_nameWHEREkey_colLIKEother_col;#WHERE使用索引...WHEREindex_part1=1ANDindex_part2=2ANDother_column=3/* index = 1 OR index = 2 */...WHEREindex=1ORA=10ANDindex=2/* optimized like \"index_part1='hello'\" */...WHEREindex_part1='hello'ANDindex_part3=5/* Can use index on index1 but not on index2 or index3 */...WHEREindex1=1ANDindex2=2ORindex1=3ANDindex3=3;#WHERE没有使用索引/* index_part1 is not used */...WHEREindex_part2=1ANDindex_part3=2/* Index is not used in both parts of the WHERE clause */...WHEREindex=1ORA=10/* No index spans all rows */...WHEREindex_part1=1ORindex_part2=10 有时MySQL不使用索引，及时有索引也是如此。发生这种情况的一种情况是，优化器估计使用索引将需要MySQL访问表中非常大比例的行。但是，如果此类查询使用LIMIT仅检索某些行，则MySQL仍会使用索引，因为它可以更快地找到要在结果中返回的几行。 \r\r哈希索引 Hash Index Characteristics 哈希索引与B树索引的特征有些不同: 仅使用=,\u003c=\u003e运算符来比较(速度飞快)，不使用比较符找到一系列值。依赖于这种类型的单值查找的系统被称为键值存储。要将MySQL应用于此类应用程序，请尽可能使用哈希索引 优化器无法使用哈希索引来加速ORDER BY MySQL无法确定两个值之间大约有多少行。如果将MyISAM或InnoDB表更改为哈希索引的MEMORY表，则可能会影响某些查询 只有整个键可用于搜索行 \r\r","date":"2018-01-16","objectID":"/mysql/:45:8","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"索引扩展 Use of Index Extensions InnoDB通过将主键列附加到它来自动扩展每个二级索引。考虑如下表定义: CREATETABLEt1(i1INTNOTNULLDEFAULT0,i2INTNOTNULLDEFAULT0,dDATEDEFAULTNULL,PRIMARYKEY(i1,i2),INDEXk_d(d))ENGINE=InnoDB; 此表定义了i1, i2两个主键。它还在列(d)上定义了二级索引k_d, 但内部InnoDB扩展了该索引并将其视为列(d, i1, i2)。 在确定如何以及是否使用该索引时，优化程序会考虑扩展二级索引的主键列。这可以带来更高效的查询执行计划和更好的性能。 \r\r","date":"2018-01-16","objectID":"/mysql/:45:9","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"优化器使用生成的列索引 Optimizer Use of Generated Column Indexes MySQL支持生成列的索引: CREATETABLEt1(f1INT,gcINTAS(f1+1)STORED,INDEX(gc)); 生成的列gc定义为表达式f1 + 1.该列也被索引，优化器可以在执行计划构建期间考虑该索引。 \r\r\r\r","date":"2018-01-16","objectID":"/mysql/:45:10","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"优化数据库结构 Optimizing Database Structure 作为数据库设计者的角色中，寻找组织 schemas, tables, columns最有效的方法。在调整应用程序代码时，您可以最小化I/O，将相关项目保持在一起，并提前计划，以便在数据量增加时性能保持较高。从高效的数据库设计开始，团队成员可以更轻松地编写高性能的应用程序代码，并使数据库可以随着应用程序的发展和重写而持久。 \r","date":"2018-01-16","objectID":"/mysql/:46:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"优化数据大小 Optimizing Data Size 设计表以最小化磁盘空间。这可以通过 减少磁盘写入和读取的数据量 来实现巨大的改进。当在查询执行期间被主动处理时，较小的表通常需要较少的内存。表数据的任何空间缩减也会导致较小的索引可以更快地处理。 MySQL支持许多不同的存储引擎(表类型)和行格式。对于每个表，你可以决定使用哪种存储和索引方法。为你的应用程序选择合适的表格式可以为你带来巨大的性能提升。 通过使用此处列出的技术，你可以获得更好的表性能并最大限度地减少存储空间: Table Columns Row Format Indexes Joins Normalization \r列 尽可能使用最有效(最小)的数据类型。MySQL有许多专门的类型可以节省磁盘空间和内存。例如，如有可能，请使用较小的整数类型(integer types)来获取较小的表。MEDIUMINT 通常是比 INT 更好的选择，因为 MEDIUMINT 列使用的空间减少了 25%。 如果可能，将列声明为NOT NULL。它通过更好地使用索引并消除测试每个值是否为 NULL 的开销，使SQL操作更快。你同样节省了一些存储空间，每列1bit。如果你确实需要表中的 NULL 值，请使用它们。只需避免在每列中允许 NULL 值得默认设置。 \r\r行格式 默认情况下，使用 DYNAMIC 行格式创建 InnoDB 表。要使用 DYNAMIC 以外的行格式，请配置 innodb_default_row_format， 或在 CREATE TABLE 或 ALTER TABLE 语句中显示指定 ROW_FORMAT 选项。 要通过以压缩格式存储表数据来进一步减少空间，请在创建 InnoDB 表时指定 ROW_FORMAT=COMPRESSED，或在现有 MyISAM 表上运行 myisampack 命令。 对于 MyISAM 表，如果没有任何可变长度列(VARCHAR, TEXT, BLOB列)，则使用固定大小的行格式。这更快，等可能浪费一些空间。 \r\r索引 表的主索引应该尽可能短。这使得每行的识别变得简单有效。对于 InnoDB 表，主键列在每个辅助索引条目中都是重复的，因此如果你有许多辅助索引，则短主键可以节省大量空间。 仅创建你需要提高查询性能的索引。索引适用于检索，但会降低插入和更新操作的速度。如果你主要通过搜索列的组合来访问表，请在它们上创建单个复合索引，而不是为每列创建单独的索引。索引的第一部分应该是最常用的列。如果从表中选择时总是使用多列，则索引中的第一列应该是具有最多重复的列，以获得更好地索引压缩。 如果长字符串列很可能在第一个字符数上有唯一的前缀，那么最好只索引此前缀，使用MySQL支持在列的最左边部分创建索引。较短的索引更快，不仅因为它们需要更少的磁盘空间，而且因为它们还会在索引缓存中为你提供更多命中，从而减少磁盘搜索次数。 \r\r联结 在某些情况下，分成两个经常扫描的表可能是有益的。如果它是动态格式的表，则尤其如此，并且可以使用较小的静态格式表，该表可用于在扫描表时查找相关行 在具有相同数据类型的不同表中声明具有相同信息的列，以基于相应列加速连接。 保持列名简单，以便你可以在不同的表中使用相同的名称并简化联结查询。例如，在名为 customer 的表中，使用名称 name 而不是 customer_name。要使你的名称可以知道其它SQL服务器，请考虑将它们保持为小于18个字符。 \r\r规范化 通常，尽量保持所有数据不冗余重复(这不是指的高可用的冗余，而是不要重复存储数据)。为了取代重复的名称、地址和长值，为它们分配唯一的ID，在多个较小的表中根据需要重复这些ID，并通过 join 子句中的 ID 来联接查询中的表。 如果速度比磁盘空间更重要，并且保留多个数据副本的维护成本，你可以放宽规范化规则，复制信息或创建汇总表以获得更快的速度。 \r\r","date":"2018-01-16","objectID":"/mysql/:46:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"优化数据类型 Optimizing MySQL Data Types \r优化数字数据 Optimizing for Numeric Data 对于唯一ID或可以表示为字符串或数字的其它值，首选数字列(prefer numeric columns to string columns)。由于较大的数值可以存储在比相应于字符串更少的字节中，因此传输和比较的速度更快，占用的内存更小。 如果你使用数字数据，在许多情况下从数据库访问信息比访问文本文件更快。数据库中的信息可能以比文本文件更紧凑的格式存储，因此访问它涉及更少的磁盘访问。您还可以在应用程序中保存代码，因为您可以避免解析文本文件以查找行和列边界。 \r\r优化字符和字符串类型 Optimizing for Character and String Types 对于 character and string columns，请遵循一下准则: 当您不需要特定于语言的整理(collation)规则功能时，请使用二进制排序顺序进行快速比较和排序操作。你可以使用 BINARY 运算符在特定查询中使用二进制整理规则。 比较不同列的值时，请尽可能声明具有相同字符集和整理规则的列，以避免在运行查询时进行字符串转换。 对于小于8KB的列值，请使用二进制 VARCHAR 而不是 BLOB。GROUP BY 和 ORDER BY 子句可以生成临时表，如果原始表不包含任何 BLOB 列，这些临时表可以使用 MEMORY 存储引擎。 如果表中包含的字符串列(如名字和地址)，但许多查询不检索这些列，请考虑将字符串拆分为单独的表，并在必要时使用带有外键的连接查询。当MySQL从一行中检索任何值时，它会都包含改行的所有列的数据块。仅使用最常用的列保持每行较小，允许更多行适合每个数据块。这种紧凑的表减少了常见查询的磁盘I/O和内存使用。 当你使用随机生成的值作为 InnoDB 表中的主键时，请在其前面加上一个升序(asce)值，如当前的日期和时间。当连续的主值物理存储在彼此附近是，InnoDB可以更快地插入和检索它们。 \r\r优化BLOB类型 Optimizing for BLOB Types 存储包含文本数据的大型 BLOB 时，请考虑先压缩它。当压缩整个表时，请勿使用此技术。 对于具有多个列的表，要减少不使用的 BLOB 列的查询的内存要求，请考虑将 BLOB 列拆分为单独的表，并在需要时使用连接查询它。 由于检索和显示 BLOB 值得性能要求可能与其它数据类型有很大不同，因此你可以将 特定的BLOB表放在不同的存储设备上，甚至是单独的数据库实例上。 可以讲列值的哈希值存储在单独的列中，索引该列，并在查询中测试哈希值，而不是针对非常长的文本字符串测试相等性。 \r\r\r","date":"2018-01-16","objectID":"/mysql/:46:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"优化表 Optimizing for Many Tables 用于快速保持个别查询的一些技术设计在多个表之间拆分数据。当表的数量达到上万，甚至是上百万时，处理所有这些表的开销成为新的性能考虑问题。 \r如何打开和关闭表 How MySQL Opens and Closes Tables 当你执行mysqladmin status命令时，你应该看到如下内容: Uptime: 426 Running threads: 1 Questions: 11082 Reloads: 1 Open tables: 12 # 如果你的表少于12个，则这个值会有些令人费解 MySQL是多线程，因此可能有许多C端同时为给定的表发出查询。为了最大限度地减少同一个表上具有不同状态的多个C端回话的问题，该表由每个并发回话独立打开。对于MyISAM表，每个打开表的C端数据文件都需要一个额外的文件描述符。 table_open_cache和max_connections系统变量会影响Server保持打开的最大文件数。如果增加这些值中的一个或两个，则可能会遇到操作系统对每个进程的打开文件描述符数量施加的限制。许多操作系统允许你增加打开文件限制，该方法因系统而异。 table_open_cache与max_connections有关。例如，对于200个并发运行的连接，请指定表缓存大小至少为200 * N，其中N是执行的任何查询中每个连接的最大表数。你还必须为临时表和文件保留一些额外的文件描述符。 请确保操作系统可以处理table_open_cache设置隐含的打开文件描述符的数量。如果table_open_cache设置的太高，MySQL可能会用完文件描述符(file descriptors)并出现拒绝连接或无法执行查询等症状。 还有考虑到MyISAM存储引擎需要为每个唯一打开的表提供两个文件描述符。对于分区的MyISAM表，打开的表的每个分区都需要两个文件描述符。 （当MyISAM打开分区表时，它会打开此表的每个分区，无论是否实际使用给定分区。要增加MySQL可用的文件描述符，请设置open_files_limit系统变量。 打开表的缓存保持在table_open_cache条目的级别上，Server在启动时自动调整缓存大小。要显式设置大小，请在启动时设置table_open_cache系统变量。MySQL可能临时打开许多表来执行查询。 在以下情况，MySQL会关闭一个未使用的表并将其从表缓存中删除: 当缓存已满并且线程尝试打开不在缓存中的表时 当缓存包含多个table_open_cache条目并且任何线程都不再使用缓存中的表时 当table-flushing操作发生。这有可能在FLUSH TABLES语句、执行mysqladmin flush-tables或mysqladmin refresh命令 当表缓存填满时，Server使用以下过程来定位要使用的缓存条目: 从最近最少使用的表开始，发布当前未使用的表 如果必须打开新表，但缓存已满且无法释放表，则会根据需要临时扩展缓存。当缓存处于临时扩展状态并且表从已使用状态变为未使用状态时，表将关闭并从缓存中释放。 为每个并发访问打开MyISAM表。这意味着如果两个线程访问同一个表，或一个线程在同一个查询中两次访问该表，则需要打开两次表。每个并发打开都需要表缓存中的条目。在任何MyISAM表的第一次打开都需要两个文件描述符: 一个用于数据文件，一个用于索引文件。对表的每次额外使用仅为数据文件提供一个文件描述符。索引文件描述符在所有线程之间共享。 如果要使用HANDER tbl_name OPEN语句打开表，则会为该线程分配专用的表对象。此表对象不由其它线程共享，并且在线程调用HANDLER tbl_name CLOSE或线程终止之前不会关闭。发生这种情况时，表将被放回表缓存中（如果缓存未满）。 要确定表缓存是否太小，请检查Opened_tables状态变量，该变量指示自Server启动以来的表的打开操作数: SHOWGLOBALSTATUSLIKE'Opened_tables';+---------------+-------+ |Variable_name|Value|+---------------+-------+ |Opened_tables|2741|+---------------+-------+ 如果值非常大或快速增加，及时你没有发出许多FLUSH TABLES语句，也请在Server启动时增加table_open_cache的值。 \r\r在同一数据库中创建多个表的缺点 Disadvantages of Creating Many Tables in the Same Database 如果在同一个数据库目录中有许多MyISAM表，则打开(open)、关闭(close)和创建(create)操作很慢。如果在许多不同的表上执行SELECT语句，则表缓存已满时会有一些开销，因为对于每个必须打开的表，必须关闭另一个表。您可以通过增加表缓存中允许的条目数来减少此开销。 \r\r\r","date":"2018-01-16","objectID":"/mysql/:46:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"内部临时表 Internal Temporary Table Use in MySQL 在某些情况下，Server在处理语句时创建内部临时表。用户无法直接控制何时发生这种情况。 Server在以下条件下创建临时表: 评估UNION语句，稍后描述一些异常 评估某些视图(view) 评估派生的表 为实现子查询或半连接创建的表 评估包含ORDER BY和GROUP BY子句的语句，或它们包含连接队列中第一个表以外的表中的列的语句 评估DISTINCT结合ORDER BY可能需要临时表 对于使用SQL_SMALL_RESULT修饰符的查询，MySQL使用内存临时表，除非查询还包含需要磁盘存储的元素 为了评估从同一个表中选择和插入的INSERT ... SELECT语句，MySQL创建一个临时表来保存SELECT中的行，然后将这些行插入到目标表中 评估多表UPDATE语句 评估GROUP_CONCAT()或COUNT (DISTNCT)表达式 要确定语句是否需要临时表，请使用EXPLAIN并检查Extra列以查看是否显示Using temporary。 当Server创建内部临时表(无论是内存还是磁盘上)时，它会增加Created_tmp_tables状态变量。 某些查询条件会阻止使用内存中的临时表，在这种情况下，Server会使用磁盘上的表: 表中存在BLOB或TEXT列，这包括具有字符串值的用户定义的变量，因此它们被视为BLOB或TEXT列，具体取决于它们的值分别是二进制字符串还是非二进制 如果使用UNION或UNION ALL，则SELECT列表中存在最大长度大于512的字符串列 SHOW COLUMNS和DESCRIBE语句使用BLOB作为某些列的类型，因此用于结果的临时表是磁盘上的表 Server不对具有某些限定条件的UNION语句使用临时表。相反，它仅从临时表创建中执行结果列类型转换所必须的数据结构。该表未完全实例化，并且没有写入和读取行，行直接发送到C端。结果是减少了内存和磁盘要求，并且在第一行发送到客户端之前的延迟较小，因为Server不需要等到最后一个查询块执行。EXPLAIN和优化程序输出反映了此执行策略：UNION RESULT查询不存在，因此该块对应于从临时表中读取的部分。 这些条件使UNION无需临时表即可进行评估: The union is UNION ALL, not UNION or UNION DISTINCT 没有全局ORDER BY子句 The union is not the top-level query block of an {INSERT | REPLACE} … SELECT … statement \r内部临时表存储引擎 Internal Temporary Table Storage Engine 内部临时表可以保存在内存中(由MEMORY存储引擎处理)，或由InnoDB或MyISAM存储引擎存储在磁盘上。 如果将内部临时表创建在内存中，但变得很大，MySQL会自动将其转换为磁盘表。内存临时表的最大大小由tmp_table_size或max_heap_table_size的值定义，以较小者为准。这与使用CREATE TABLE显式创建的MEMORY表不同。对于此类表，只有max_heap_table_size变量确定表可以增长的大小，并且没有转换为磁盘格式。 internal_tmp_disk_storage_engine变量定义Server用于管理磁盘内部临时表的存储引擎。允许的值是：INNODB(默认)和MyISAM。 \r内部临时表存储格式 Internal Temporary Table Storage Format 内存临时表由MEMORY存储引擎管理，该引擎使用固定长度的行格式。VARCHAR和VARBINARY列值填充到最大列长度，实际上将它们存储为CHAR和BINARY列。 磁盘临时表由InnoDB或MyISAM存储引擎管理。两个存储引擎都使用动态宽度行格式存储临时表。与使用固定长度行的磁盘相比，列只占用所需的存储空间，从而减少磁盘I/O，空间要求和处理时间。 对于最初在内存中创建内部临时表的语句，然后将其转换为磁盘表，可以通过跳过转换步骤并在磁盘上创建表开始来实现更好的性能。big_tables变量可用于强制内部临时表的磁盘存储。 \r\r\r\r","date":"2018-01-16","objectID":"/mysql/:46:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"优化InnoDB表 Optimizing for InnoDB Tables InnoDB是MySQL客户通常在生产环境中使用的存储引擎，其中可靠性和并发性非常重要。它是默认的MySQL存储引擎。本节介绍如何优化InnoDB表的数据库操作。 \r","date":"2018-01-16","objectID":"/mysql/:47:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"优化InnoDB表的存储布局 Optimizing Storage Layout for InnoDB Tables 一旦数据达到稳定大小，或者增长的表增加到上百兆字节(MB)，请考虑使用OPTIMIZE TABLE语句重新组织并压缩任何浪费的空间。重组的表需要较少的磁盘I/O来执行全表扫描(full table scan)。这是一个简单的技术，可在其它技术不切实际时提高性能。 OPTIMIZE TABLE复制表的数据部分并重建检索。其好处改进了索引中数据的打包，减少了表空间和磁盘上的碎片。好处取决于每个表中的数据。如果表很大或者正在重建的索引不适合缓冲池，则此操作可能很慢。向表中添加大量数据后的第一次运行通常比以后的运行慢得多。 在InnoDB中，具有long PRIMARY KEY(具有冗长值的单个列或形成长度复合值的多个列)浪费了大量磁盘空间。在指向同一行的所有辅助索引(secondary index)记录中，行的主键值重复。如果主键很长，则创建AUTO_INCREMENT列作为主键，或者索引long VARCHAR列的前缀而不是整个列。 使用VARCHAR数据类型而不是CHAR来存储可变长度(variable-length)字符串或具有许多NULL值的列。即使字符串较短或其值为NULL，CHAR(N)的列也始终使用N个字符(character)来存储数据。较小的表更适合缓冲池并减少磁盘I/O。 当使用COMPACT行格式(默认的InnoDB格式)和可变长度字符串(如utf8)时，CHAR(N)列占用可变的空间量，但仍至少占用N个字节。 对于大型表或包含大量重复文本(repetitive text)或数字(nemeric)数据的表，情考虑使用COMPRESSED行格式。将数据放入缓冲池(buffer pool)或执行全表扫描需要较少的磁盘I/O。在作出永久性决策之前，请使用COMPRESSED与COMPACT行格式测量可以实现的压缩量。 \r\r\r","date":"2018-01-16","objectID":"/mysql/:47:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"优化InnoDB事务管理 Optimizing InnoDB Transaction Management 要优化InnoDB事务处理，请在事务功能的性能开销(performance overhead)和Server的工作负载(workload)之间找到理想的平衡点。例如，如果应用程序每秒提交数千次，则可能会遇到性能问题， 默认的MySQL设置AUTOCOMMIT=1可以对繁忙的数据库Server施加性能限制。在可行的情况下，通过发出SET AUTOCOMMIT=0或START TRANSACTION语句，然后在进行所有更改后发出COMMIT语句，将多个相关数据更改操作包装到单个事务中。 如果该事务对数据库进行了修改，InnoDB必须在每次事务提交时将日志刷新到磁盘。当每次更改后都提交时，存储设备的I/O吞吐量会限制每秒潜操作的数量。 对于仅包含单个SELECT语句的事务，启用AUTOCOMMIT可帮助InnoDB识别只读事务并对其进行优化。 INSERT, DELETE, UPDATE大量行后，避免执行行回滚。如果大型事务正在降低Server性能，则将其回滚可能会使问题变得更糟，可能需要花费几倍的时间来执行原始数据更改操作。杀死数据库进程没有帮助，因为Server启动时会再次启动回滚。 为了尽量减少此问题发生的可能性： 增加缓冲池的大小，以便可以缓存所有数据更改，而不是立即写入磁盘 设置innodb_change_buffering=all，以便缓冲除INSERT之外的UPDATE, DELETE操作 考虑在大数据更改操作期间定期发出COMMIT语句，可能会破坏单个删除或更新为较少行数进行操作的多个语句 要在发生失控回滚后摆脱它，请增加缓冲池使回滚变为CPU限制并快速运行，或杀死Server并使用innodb_force_recovery=3选项来启动它。 预计此问题很少发生，默认设置innodb_change_buffering=all，他允许将UPDATE和DELETE操作缓存在内存中，从而使它们可在第一时间更快地执行，并且如果需要还可以更快地回滚。确保在处理具有许多INSERT, UPDATE, DELETE操作的长时间运行事务的Server上使用此参数设置。 如果发生奔溃时，如果你可以承受丢失一些最新提交的事务，则可以设置 innodb_flush_log_at_trx_commit=0。InnoDB无论如何都会尝试每秒刷新(FLUSH)一次日志，尽管无法保证。此外，设置innodb_support_xa=0将减少磁盘数据和BINLOG同步而导致到磁盘刷新次数。 修改或删除行时，不会立即删除行和关系链的undo log，甚至在事务提交后。旧数据将保留，直到先前或同时启动的事务完成，以便这些事务可以访问已修改或已删除的行的先前状态。因此，长时间运行的事务可以阻止InnoDB清除由不同事务更改的数据。 在长时间运行的事务中修改或删除行时，使用READ COMMITTED和REPEATABLE READ隔离级别的其它事务必须执行更多工作，以便在读取相同行时重建旧数据。 当长时间运行的事务修改表时，从其它事务对该表的查询不会使用covering index technique。通常可从二级索引检索所有结果列的查询，而不是从表数据中查找适当的值。 如果发现二级索引页面的PAGE_MAX_TRX_ID太新，或二级索引中的记录被删除标记，则InnoDB可能需要使用clustered index来查找记录。 \r\r\r","date":"2018-01-16","objectID":"/mysql/:47:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"优化InnoDB只读事务 Optimizing InnoDB Read-Only Transactions InnoDB可以避免与已知为只读的事务设置事务ID(TRX_ID字段)相关的开销。只有可能执行写操作或锁定读取的事务(如SELECT…FOR UPDATE)才需要事务ID。消除不必要的事务ID会减少每次查询或数据更改语句构造读取视图时所咨询的内部数据结构的大小。 \r\r \r\r语言结构 Language Structure 本章讨论在使用MySQL时编写SQL语句的以下元素的规则： 文字值，如字符串和数字 标识符，如数据库、表和列名 关键词与保留词 用户定义变量和系统变量 评论 \r","date":"2018-01-16","objectID":"/mysql/:47:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"文字值 Literal Values 本节描述如何在MySQL中写入文字值。这包含了字符串、数字、十六进制、位值、布尔值、NULL。还将介绍在MySQL中处理这些基本类型时可能遇到的各种细微差别。 \r","date":"2018-01-16","objectID":"/mysql/:48:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"字符串 String Literals 字符串时字节(Byte)或字符(character)序列，包含在单引号(')或双引号(\")中。 栗子： 'a string' 'a' ' ' 'string' \"another string\" 注意 如果启用了ANSI_QUOTES SQL模式，字符串只能在单引号中引用，因为双引号的字符串被解释为标识符。 二进制字符串(binary string)是一串字节(Bytes)。每个二进制字符串都有一个名为binary的字符集(character set)和排序规则。非二进制字符串是一串字符(characters)，它具有二进制以外的字符集和与字符集兼容的排序规则。 对于两种类型的字符串，比较是基于字符串单元的数值。对于二进制字符串，单位是字节(byte)，使用数字字节值比较；对于非二进制字符串，单位是字符(character)和支持多字节字符的字符集，使用数字字符码值比较。字符码排序是字符串排序的函数。 字符串文字可以有一个可选的字符集导入器和排序字句，将其指定为使用特定字符集和排序的字符串：[_charset_name]'string' [COLLATE collation_name] 栗子: SELECT_latin1'string';SELECT_binary'string';SELECT_utf8'string'COLLATEutf8_danish_ci;SELECTN'some text';SELECTn'some text';SELECT_utf8'some text'; 在字符串中，某些序列具有特俗含义，除非启用了No_BACKSLASH_ESCAPES SQL模式。如转义字符每个序列都以反斜线(backslash)(\\)开始。 特殊字符转义序列： Escape Sequence Character Represented by Sequence \\0 An ASCII NUL (X'00’) character \\' A single quote (') character \\\" A double quote (\") character \\b A backspace character \\n A newline (linefeed) character \\r A carriage return character \\t A tab character \\Z ASCII 26 (Control+Z); see note following the table \\\\ A backslash () character \\% A % character; see note following the table \\_ A _ character; see note following the table 在字符串中包含引号字符有几种方法： 两个引号 引号包含引号 转义引号 栗子： SELECT'hello','\"hello\"','\"\"hello\"\"','hel''lo','\\'hello'; +-------+---------+-----------+--------+--------+ | hello | \"hello\" | \"\"hello\"\" | hel'lo|'hello | +-------+---------+-----------+--------+--------+ SELECT \"hello\", \"'hello'\", \"''hello''\", \"hel\"\"lo\", \"\\\"hello\"; +-------+---------+-----------+--------+--------+ | hello | 'hello' | ''hello'' | hel\"lo | \"hello | +-------+---------+-----------+--------+--------+ SELECT 'This\\nIs\\nFour\\nLines'; +--------------------+ | This Is Four Lines | +--------------------+ SELECT 'disappearing\\backslash'; +------------------------+ | disappearing backslash | +------------------------+ 要将二进制数据插入字符串列中，应该使用转义序列表示某些字符。在某些特定的Client环境下，可能还需要转换NUL或Ctrl + Z。 在编写应用程序时，必须将包含特殊字符正确的转义发送给MySQL。 \r\r\r","date":"2018-01-16","objectID":"/mysql/:48:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"数字 Numeric Literals 数字包括精确值(整数和小数)和近似值(浮点数)。 整数用数字序列表示。数字可能包括., -, +，科学表示法E等。 #精确值，定点数 2.34 #近似值，浮点数 2.34E0 ","date":"2018-01-16","objectID":"/mysql/:48:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"日期和时间 Date and Time Literals 日期和时间可以用几种格式表示。如'2015-07-21', '20150721', 20150721都可解释为日期。 标准SQL和ODBC日期和时间： 标准SQL允许使用type关键字和字符串指定时态文字。 --空格可选 DATE'str'TIME'str'TIMESTAMP'str' ODBC语法： { d 'str' } { t 'str' } { ts 'str' } MySQL使用type关键字，这些结构分别包含DATE, TIME, DATETIME值，如果指定的话，好包括后面的小数秒部分。TIMESTAMP语法在MySQL中生成一个DATETIME值，因为DATETIME的范围与标准SQL TIMESTAMP类型更接近，后者年限为0001-9999。而MySQL的TIMESTAMP范围是1970-2038年。 日期和时间上下文中的字符串和数字： MySQL可以识别以下格式的DATE值： 'YYYY-MM-DD'或'YY-MM-DD'字符串格式。允许宽松的语法——即任何标点字符都可作为日期之间的分隔符。如'2012-12-31', '2012/12/31/', '2012@12@31'... 'YYYYMMDD'或'YYMMDD'没有分隔符的字符串格式，前提是该字符作为日期有意义。如'20121231', '121231'... YYYYMMDD或YYMMDD数字格式，前置是该数字作为日期有意义。如20121231, 121231... MySQL可以识别以下格式的DATETIME和TIMESTAMP： 'YYYY-MM-DD HH:MM:SS'或'YY-MM-DD HH:MM:SS'字符串格式。允许宽松的语法。如2012/12/31 00*01*02... 日期和时间部分可以用T分隔，而不是空格。如2012-12-31 00:01:02, 2012-12-31T01:02:03 'YYYYMMDDHHMMSS'或'YYMMDDHHMMSS'没有分隔符的字符串格式，前提是该字符作为日期有意义 YYYYMMDDHHMMSS或YYMMDDHHMMSS数字格式，前提是该数字作为日期有意义 DATETIME和TIMESTAMP值可以包含一个精度不超多微秒(6位)的小数部分。小数部分应该始终使用小数点.与其他部分跟开，无法识别分数秒分隔符。 MySQL使用以下规则解释两位数的年值： 70-99转换为1970-1999 00-69转换为2000-2069 MySQL可以识别以下格式的TIME值： 'D HH:MM:SS'字符串格式，D表示天数(0-34)。可以使用放松的语法。 'HHMMSS'没有分隔符字符串格式，前提是作为时间有意义。 HHMMSS数字格式，前提是作为时间有意义。 小数秒部分在'D HH:MM:SS.fraction'时间格式中识别，其中小数是精度最高可达微秒(6位)的小数部分，小数部分使用小数点.与其它部分分隔开，无法识别其它小数秒分隔符。 \r\r\r","date":"2018-01-16","objectID":"/mysql/:48:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"十六进制 Hexadecimal Literals \r\r \r字符集和编码 Character Sets, Collations, Unicode \r\r \r数据类型 Data Type MySQL支持多种类型的SQL数据类型： numeric date/time string character byte JSON 数据类型描述使用如下约定： M表示整数类型的最大显示宽度 D适用于浮点和定点类型，并指示小数点后面的位数 fsp适用于TIME, DATATIME, TIMESTAMP类型，表示小数点的秒精度 方括号[]表示类型定义的可选部分 \r\r","date":"2018-01-16","objectID":"/mysql/:48:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"数字 Numberic type 如果为数字列指定ZEROFILL，MySQL会自动将UNSIGNED属性添加到列中。 数字数据类型允许UNSIGNED(无符号)属性，也允许SIGNED(符号)。默认情况下，这些数据类型是SIGNED，因此SINGED属性不起作用。 BIT A bit-value type.(1-64) TINYINT A very small integer. 有符号范围: -128 to 127, 无符号范围: 0-255 BOOL SMALLINT A small integer. 有符号范围: -32768 to 32767, 无符号范围: 0-65535 MEDIUMINT A medium-sized integer. 有符号范围: -8388608 to 8388607, 无符号范围: 0-16777215 INT A normal-size integer. 有符号范围: -2147483648 to 2147483647, 无符号范围: 0- 4294967295 INTERGER 此类型是INT的同义词。 BIGINT A large integer. 符号范围: -9223372036854775808 to 9223372036854775807, 无符号范围: 0 to 18446744073709551615 SERIAL是BIGINT UNSIGNED NOT NULL AUTO_INCREMENT UNIQUE的别名。 DECIMAL/DEC FLOAT A small(单精度) floating-point number. 允许的值为: -3.402823466E+38 to -1.175494351E-38, 0, and 1.175494351E-38 to 3.402823466E+38 DOUBLE A normal-size(双精度) floating-point number. 允许值为: -1.7976931348623157E+308 to -2.2250738585072014E-308, 0, and 2.2250738585072014E-308 to 1.7976931348623157E+308 FLOAT A floating-point number. \r\r","date":"2018-01-16","objectID":"/mysql/:49:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"日期和时间 Date and Time Type MySQL允许的TIME, DATETIME, TIMESTAMP值的小数，精度高达微秒(小数点后6位)。 DATE A date. 支持范围: 1000-01-01到9999-12-31。 MySQL以YYYY-MM-DD格式显示DATE值，但允许使用字符串或数字将值分配给DATE列。 DATETIME A date and time combination. 支持范围: 1001-01-01 00:00:00.000000到9999-12-31 23:59:59.999999。 MySQL以YYYY-MM-DD HH:MM:SS.[fraction]的格式显示DATETIME值，同样允许字符串或数字将值分配给DATETIME列。 TIMESTAMP A timestamp. 支持范围: 1970-01-01 00:00:01.000000UTC到2038-01-19 03:14:07.999999UTC TIMESTAMP值存储为自纪元1970-01-01 00:00:01.000000 UTC以来的秒数，这也叫原子时间。 TIME A time. 支持范围: -838:59:59.000000 to 838:59:59.000000 MySQL以HH:MM:SS[.fraction]的格式显示TIME值，但允许使用字符串或数字将值分配给TIME列。 YEAR A year in four-digit format. MySQL以YYYY格式显示YEAR值，但允许使用字符串或数字将值分配给YEAR列。 \r\r \r","date":"2018-01-16","objectID":"/mysql/:50:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"字符串 String Type 在某些情况下，MySQL可能会使用CREATE TABLE或ALTER TABLE语句更改字符串的类型。 CHARACTER SET/CHARSET 指定字符集 CREATETABLEt(c1VARCHAR(20)CHARACTERSETutf8,c2TEXTCHARACTERSETlatin1COLLATElatin1_general_cs); CHAR 一个固定长度的字符串，在存储时使用用空格填充指定长度。 VARCHAR的有效最大长度取决于最大行大小(65535字节)和使用的字符集。 VARCHAR 一个可变长度的字符串。 BINARY BINARY类似于CHAR，但存储二进制字节字符串而不是非二进制字符串。 VARBINARY TINYBLOB A BLOB column with a maximum length of 255 (2^8 − 1) bytes. TINYTEXT A TEXT column with a maximum length of 255 (2^8 − 1) characters. BLOB A BLOB column with a maximum length of 65,535 (2^16 − 1) bytes. TEXT A TEXT column with a maximum length of 65,535 (2^16 − 1) characters. MEDIUMBLOB A BLOB column with a maximum length of 16,777,215 (2^24 − 1) bytes. MEDIUMTEXT A TEXT column with a maximum length of 16,777,215 (2^24 − 1) characters. LONGBLOB A BLOB column with a maximum length of 4,294,967,295 or 4GB (2^32 − 1) bytes. LONGTEXT A TEXT column with a maximum length of 4,294,967,295 or 4GB (2^32 − 1) characters. ENUM An enumeration. SET A set. \r\r \r\r必知必会 MySQL Crash Course \r","date":"2018-01-16","objectID":"/mysql/:51:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"了解SQL \r","date":"2018-01-16","objectID":"/mysql/:52:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"数据库基础 在学习MySQL以及SQL之前，应该对数据库及数据库技术的概念有所了解。 \r什么是数据库 数据库是一种以某种有组织的方式存储的数据集合。 人们通常用数据库这个术语来代表他们使用的数据库软件。这是不正确的，它是引起混淆的根源。确切地说，数据库软件应该成为DBMS(数据库管理系统). \r\r表 在文件柜中创建文件，然后将相关的资料放入特定的文件中。 在数据库领域，这种文件成为表(table)，表是一种结构化的文件，可用来存储某种特定类型的数据。 绝不应该将顾客的清单与订单的订单存储在同一个数据库表中。这样讲使以后的检索和访问很困难。应该创建两个表，每个清单一个表。 模式(schema)，关于数据库和表的布局及特征的信息。 有时，模式用作数据库的同义词。 \r\r列和数据类型 表由列组成。列中存储着表中某部分的信息。 列(column)，表中的一个字段。 数据库中的每个列都有相应的数据类型。 正确地将数据分解为多个列极为重要。如城市、省、邮编应该是独立的列。通过将它们分隔开，才有可能对其进行组合操作。 数据类型(datatype)，所容许的数据的类型。每个表列都有相应的数据类型。 \r\r行 表中的数据是按行存储的，所保存的每个记录存储在自己的行内。 行(row)，表中的一个记录。 \r\r主键 表中每一行都应该有可以表示自己的一列(一组列)。 主键(primary key)，一列(一组列)，其值能够唯一区分表中的每个行。 唯一标识表中的每行的这个列(这组列)称为主键，主键用来表示一个特定的行。 应该总是定义主键。虽然并不总是都需要主键，但数据库设计人员都应该保证他们创建的每个表都具有一个主键，以便于以后的数据操作和管理。 表中的任何列都可作为主键，只要它满足一下条件: 任意两行都不具有相同的主键值； 每行都必须具有一个主键值(主键值不允许NULL值)。 主键通常定义在表的一列上，但这并不是必须的，也可以一起使用多个列作为主键。所有列值的组合必须是唯一的(但单个列的值可以不唯一)。 主键的好习惯: 不更新主键列中的值； 不重用主键列的值； 不在主键列中使用可能会更改的值。 \r\r","date":"2018-01-16","objectID":"/mysql/:52:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"什么是SQL SQL（发音为字母S-Q-L或sequel）是结构化查询语言（Structured Query Language）的缩写。 SQL有以下优点: SQL不是为某个特定数据库供应商专有的语言。几乎所有的DMS都支持SQL。 SQL简单易学。它的语句全都是由描述性很强的英语单词组成。 SQL尽管看上去很简单，但它实际上是一种强有力的语言，可进行非常复杂和高级的数据库操作； SQL不区分大小写，但建议对SQL关键字使用大写，表列等使用小写，这样方便阅读和调试； 在处理SQL语句时，所有空格都将被忽略。 \r\r","date":"2018-01-16","objectID":"/mysql/:52:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"SQL注释 单行注释 # -- 多行注释 /* */ #sqlsinglelinecomment-- single line comment -- 注意，有空格 /* line1 comment line2 comment ... */ \r\r\r","date":"2018-01-16","objectID":"/mysql/:52:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL简介 \r","date":"2018-01-16","objectID":"/mysql/:53:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"什么是MySQL MySQL是一种DBMS，即它是一种数据库管理软件。 众多开发者和公司使用MySQL的原因: 成本，MySQL是开源的； 性能，MySQL执行很快； 可信赖，大公司也使用它； 简单，MySQL易于安装和使用。 \r\rC-S DBMS可分为两类: 基于共享文件系统，如Microsoft Access，通常用于桌面用途； 基于C-S，如MySQL、Oracle、SQL Server。 \r\r","date":"2018-01-16","objectID":"/mysql/:53:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL工具 工欲善其事必先利其器。有3个工具需要提及: msyql命令行使用程序 MySQL Administrator MySQL Query Browser \r\r\r","date":"2018-01-16","objectID":"/mysql/:53:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"条件判断语句 IF语句 CASE语句 \r","date":"2018-01-16","objectID":"/mysql/:54:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"IF IF FUNCTION IF STATEMENT HELPIFSTATEMENT;IFsearch_conditionTHENstatement_list[ELSEIFsearch_conditionTHENstatement_list]...[ELSEstatement_list]ENDIF-- 栗子 CREATEPROCEDUREtest1BEGINIFscore\u003e=90THENSELECTscore,'A';ELSEIFscore\u003c90ANDsocre\u003e=80THENSELECTscore,'B'ELSEIFsocre\u003c80ANDscore\u003e=70THENSELECTscore,'C'ELSEIFscore\u003c70ANDscore\u003e=60THENSELECTsocre,'D'ELSESELECTscore,'E'ENDIF;END;HELPIFFUNCTION;IF(expr1,expr2,expr3)-- 栗子 SELECTIF(1\u003e2,2,3);+-------------+ |IF(1\u003e2,2,3)|+-------------+ |3|+-------------+ \r\r","date":"2018-01-16","objectID":"/mysql/:54:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"CASE CASE OPERATOR CASE STATEMENT HELPCASEOPERATOR;CASEvalueWHEN[compare_value]THENresult[WHEN[compare_value]THENresult...][ELSEresult]ENDCASEWHEN[condition]THENresult[WHEN[condition]THENresult...][ELSEresult]END-- 栗子 SELECTCASE1WHEN1THEN'one'WHEN2THEN'two'ELSE'more'END;-- one HELPCASESTATEMENT;CASEcase_valueWHENwhen_valueTHENstatement_list[WHENwhen_valueTHENstatement_list]...[ELSEstatement_list]ENDCASE-- 或 CASEWHENsearch_conditionTHENstatement_list[WHENsearch_conditionTHENstatement_list]...[ELSEstatement_list]ENDCASE-- 栗子 CREATEPROCEDUREp()BEGINDECLAREvINTDEFAULT1;CASEvWHEN2THENSELECTv;WHEN3THENSELECT0;ELSEBEGINEND;ENDCASE;END; \r\r\r","date":"2018-01-16","objectID":"/mysql/:54:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"循环语句 WHILE语句 REPEAT语句 LOOP语句 \r","date":"2018-01-16","objectID":"/mysql/:55:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"WHILE HELPWHILE;[begin_label:]WHILEsearch_conditionDOstatement_listENDWHILE[end_label]-- 栗子 CREATEPROCEDUREdowhile()BEGINDECLAREv1INTDEFAULT5;WHILEv1\u003e0DOSETv1=v1-1;ENDWHILE;END; \r\r","date":"2018-01-16","objectID":"/mysql/:55:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"REPEAT HELPREPEAT;[begin_label:]REPEATstatement_listUNTILsearch_conditionENDREPEAT[end_label]-- 栗子 CREATEPROCEDUREdorepeat(p1INT)BEGINSET@x=0;REPEATSET@x=@x+1;UNTIL@x\u003ep1ENDREPEAT;END; \r\r","date":"2018-01-16","objectID":"/mysql/:55:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"LOOP HELPLOOP;[begin_label:]LOOPstatement_listENDLOOP[end_label]-- 栗子 CREATEPROCEDUREdoiterate(p1INT)BEGINlabel1:LOOPSETp1=p1+1;IFp1\u003c10THENITERATElabel1;ENDIF;LEAVElabel1;ENDLOOPlabel1;SET@x=p1;END; \r\r\r","date":"2018-01-16","objectID":"/mysql/:55:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用MySQL \r","date":"2018-01-16","objectID":"/mysql/:56:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"连接 在执行命令之前需要登录到DBMS。为了连接到MySQL，需要以下信息: hostname port username passwd(可选) \r\r","date":"2018-01-16","objectID":"/mysql/:56:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"选择数据库 选择数据库有两种方式: 在连接是指定数据库名 登录后选择数据库 # 1 mysql -h xxx -P xxx -u xxx -p dbName # 2 mysql\u003e USE dbName; \r\r","date":"2018-01-16","objectID":"/mysql/:56:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"了解数据库和表 数据库、表、列、用户、权限等的信息被存储在数据库和表中。不过，内部表一般不直接访问，可用SHOW命令来显示这些信息。 HELPSHOW;SHOWDATABASES;SHOWTABLES;SHOWCOLUMNSFROMtableName;#显示服务器信息SHOWSTATUS;#显式创建SHOWCREATEDATABASExxx;SHOWCREATETABLExxx;#查看权限SHOWGRANTS;#显示Server错误或警告信息SHOWERRORS;SHOWWARNINGS; \r\r\r","date":"2018-01-16","objectID":"/mysql/:56:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"检索数据 \r","date":"2018-01-16","objectID":"/mysql/:57:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"SELECT语句 SQL语句有简单的英语单词构成，这些单词称为关键字，每个SQL语句由一个或多个关键字构成。 大概，最常用的SQL语句就是SELECT语句了，它从一个或多个表中检索信息。 \r\r","date":"2018-01-16","objectID":"/mysql/:57:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"检索单个列 SELECTcolumnNamefromtableName; \r\r","date":"2018-01-16","objectID":"/mysql/:57:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"检索多个列 选择列名时，一定要在列名之间加上逗号，但最后一个列名不加。 SELECTcolumnName1,columnName2FROMtableName; \r\r","date":"2018-01-16","objectID":"/mysql/:57:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"检索所有列 一般，除非你确定表中的每个列，否则最好不要使用*通配符。 SELECT*FROMtableName; \r\r","date":"2018-01-16","objectID":"/mysql/:57:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"检索不同的行 你不想要每个值每次出现，使用DISTINCT关键字以指示MySQL只返不同(唯一)的值。 DISTINCT关键字必须放在列名的前面。 DISTINCT关键字应用于所有列，而不仅是前置它的列。 SELECTDISTINCTcolumnNameFROMtableName; \r\r","date":"2018-01-16","objectID":"/mysql/:57:5","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"限制结果 SELECT返回所有匹配的行，为了返回一个或多个行，可使用LIMIT子句。 SELECTcolumnNameFROMtableNameLIMIT10;#LIMITa,b指示MySQL返回从行a开始的b行#第一个数为开始位置，第二个数为要检索的行数#行数是从0开始计算的SELECTcolumnNameFROMtableNameLIMIT10,5;#行数不够时，MySQL只返回它能返回的行 \r\r","date":"2018-01-16","objectID":"/mysql/:57:6","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用完全限定的表名 迄今为止使用的SQL栗子只通过列名引用列。也可能会使用完全限定的名字来引用列(同时使用表名和列名)。 SELECTtableName.columnNameFROMtableName;#表名也可以是完全限定的SELECTtableName.columnNameFROMdbName.tableName; \r\r\r","date":"2018-01-16","objectID":"/mysql/:57:7","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"排序检索数据 本章讲解如何使用SELECT语句的ORDER BY子句，根据需要排序检索出的数据。 \r","date":"2018-01-16","objectID":"/mysql/:58:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"排序数据 关系数据库设计理论认为，如果不明确规定排序顺序，则不应该假定检索出的数据的顺序有意义。 子句(clause)，SQL语句有子句构成，有些子句是必须的，而有的是可选的。 为了明确排序SELECT语句检索出的数据，可使用ORDER BY子句。 #默认为升序SELECTcolumnNameFROMtableNameORDERBYcolumnName;SLECTcolumnName1,columnName2FROMtableNameORDERBYcolumnName2; \r\r","date":"2018-01-16","objectID":"/mysql/:58:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"按多个列排序 经常需要按不止一个列进行排序。多列排序，只要指定列名，列名之间用逗号分隔开即可。 #先按列1排序，再按列2排序SELECTcolumnName1,columnName2,columnName3FROMtableNameORDERBYcolumnName1,columnName2; \r\r","date":"2018-01-16","objectID":"/mysql/:58:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"排序指定方向 升序(默认): 从A-Z，关键字AESC。因为是默认，所以无需指定。 降序: 从Z-A，使用DESC关键字。 SELECTcolumnName,columnName1FROMtableNameORDERBYcolumnName1DESC;#多序列，需要对每个列指定关键字SELECTcolumnName,columnName1,columnName2FROMtableNameORDERBYcolumnName1DESC,columnName2iDESC;#ORDERBY和LIMIT的组合SELECTcolumnNameFROMtableNameORDERBYcolumnNameDESCLIMIT10; \r\r\r","date":"2018-01-16","objectID":"/mysql/:58:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"过滤数据 本章讲解如何使用SELECT语句的WHERE子句指定搜索条件。 \r","date":"2018-01-16","objectID":"/mysql/:59:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"WHERE子句 数据库一般包含大量的数据，很少需要检索表中所有行。通常只会根据特定操作或报告的需要提取表数据的子集。 只检索所需数据需要指定搜索条件(也称为过滤条件)。 在SELECT语句中，数据根据WHERE子句中指定的搜索条件进行过滤。 在同时使用ORDER BY和WHERE子句时，应该让ORDER BY位于WHERE之后，否则将产生错误。 SELECTcolumnNameFROMtableNameWHEREid=1001; \r\r","date":"2018-01-16","objectID":"/mysql/:59:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"WHERE子句操作符 MySQL支持如下条件操作符: 操作符 说明 = 等于 \u003c\u003e 不等于 != 不等于 \u003c 小于 \u003c= 小于等于 \u003e 大于 \u003e= 大于等于 BETWEEN 在指定的两个值之间 \r检查单个值 SELECTcolumn1,column2FROMtable1WHEREname='zhang';SELECTcolumn1,column2FROMtable1WHEREprice\u003c=10; \r\r不匹配检查 SELECTcolumn1,column2FROMtable1WHEREid\u003c\u003e1002;SELECTcolumn1,column2FROMtable1WHEREid!=1003; \r\r范围值检查 为了检查某个范围的值，可使用BETWEEN操作符。它需要两个值，即范围的开始值和结束值。 SELECTcolumn1,column2FROMtable1WHEREpriceBETWEEN2AND10; \r\r空值检查 在创建表时，可指定列是否可以不包含值。在一个列不包含值时，称其为空值NULL。 NULL， 无值(no value)，它与字段包含0、空字符串或仅仅包含空格㓊。 有一个特殊的WHERE子句ISNULL，用来检测具有NULL值的列。 SELECTcolumn1FROMtable1WHEREpriceISNULL; \r\r","date":"2018-01-16","objectID":"/mysql/:59:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"组合WHERE子句 使用组合的WHERE子句，以AND和OR子句(逻辑操作符)的方式，进行更强的数据控制。 \rAND操作符 SELECTcolumn1,column2FROMtable1WHEREname='zhang'ANDprice\u003c=10;\u003e \r\rOR操作符 SELECTcolumn1,column2FROMtable1WHEREname='zhang'ORname='abc'; \r\r计算次序 WHERE可包含任意数目的AND和OR操作符，允许两者结合已进行复杂和高级的过滤。 由于逻辑操作符存在优先级，所以请记得使用括号。 SELECTcolumn1,column2FROMtable1WHERE(id=1001ORid=1003)ANDprice\u003e=10; \r\r","date":"2018-01-16","objectID":"/mysql/:59:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"IN操作符 IN操作符用来指定条件范围，范围中的每个条件都可以进行匹配。 SELECTcolumn1,column2FROMtable1WHEREidIN(1001,1002)ORDERBYcolumn2;#WHEREid=1001ORid=1002 其实这里的IN和OR操作符完成相同的功能。为什么要使用IN操作符: 在使用长的合法选项清单时，IN操作符的语法更清楚且更直观 在使用IN时，计算的次序更容易管理 IN操作符一般比OR操作符清单执行更快 IN的最大优点是可以包含其他SELECT语句，使得能够更动态地建立WHERE子句 \r\r","date":"2018-01-16","objectID":"/mysql/:59:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"NOT操作符 WHERE子句中的NOT操作符有且只有一个功能，那就是否定它之后所跟的任何条件。 SELECTcolumn1,column2FROMtable1WHEREidNOTIN(1001,1002)ORDERBYcolumn2; \r\r\r","date":"2018-01-16","objectID":"/mysql/:59:5","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"通配符过滤 本章介绍什么是通配符、如何使用通配符以及怎样使用LIKE操作符进行通配搜索，以便对数据进行负载过滤。 通配符(wildcard)，用来匹配一部分的特殊字符。 搜索模式(search pattern)，由字面值、通配符或两者组合构成的搜索条件。 \r","date":"2018-01-16","objectID":"/mysql/:60:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"LIKE操作符 通配符本身本身实际是SQL的WHERE子句中有特殊含义的字符，SQL支持几种通配符: 百分号(%)通配符 下划线(_)通配符 为了在搜索子句中使用通配符，必须使用LIKE操作符。LIKE只是MySQL，后跟搜索模式利用通配符，而不是直接相等匹配进行比较。 \r\r百分号通配符 注意，除了一个或多个字符，%还能匹配0个字符(也就是\u003e=0); %通索配符不能匹配NULL; 在搜索中，%通配符表示任何字符出现任何次数(类似Linux中的星号*); %通配符可在搜索模式的任意位置使用，并且可以使用多个通配符(这点Linux的星号不支持); 通配符也可以出现在搜索模式的中间，虽然这样并不太有用; 根据MySQL的配置方式，搜索可以是区分大小写的。 SELECTid,nameFROMtable1WHEREnameLIKE'%zhang%';SELECTnameFROMtable1WHEREnameLIKE'a%z'; \r\r下划线通配符 下划线(_)通配符只匹配单个字符 SELECTid,nameFROMtable1WHEREnameLIKE'zhan_'; \r\r","date":"2018-01-16","objectID":"/mysql/:60:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用通配符的技巧 如上所见，MySQL通配符很有用。但这种功能是有代价的: 通配符搜索的处理一般要比前面讨论的其它搜索所花时间更长。 这里给出一些使用通配符要记住的技巧： 不要过度使用通配符。如果其它操作符能达到相同的目的，应该使用其它操作符； 在确实需要使用通配符时，除非绝对有必要，否则不要把它们用在搜索模式的开始处(这样太慢了)； 请注意通配符的放置位置，不要乱放。 \r\r\r","date":"2018-01-16","objectID":"/mysql/:60:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"正则表达式搜索 本章介绍如何在MySQL WHERE子句内使用正则表达式(RE)来更好地控制数据过滤。 \r","date":"2018-01-16","objectID":"/mysql/:61:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"正则表达式介绍 正则表达式用来匹配文本的特殊的串(字符集)。 所有种类的程序设计语言、文本编辑器、操作系统…都支持正则表达式。 正则表达式用正则表达式语言来建立，它是一种特殊语言。 \r\r","date":"2018-01-16","objectID":"/mysql/:61:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"MySQL正则表达式 MySQL用WHERE子句中的REGEXP关键字对正则表达式提供了初步的支持。 MySQL中的正则表达式默认不缺分大小写；如果要区分，可使用BINARY关键字。 \r基本字符匹配 SELECTnameFROMtable1WHEREscoreREGEXP'100';#这里使用的正则效果还没有LIKE好，因为它并不复杂，这里仅做栗子参考-- 下面看一个复杂点的 -- 特殊字符.表示匹配任意一个字符 SELECTscoreFROMtable1WHEREsocreREGEXP'.0' \r\rOR匹配 使用|进行或匹配。 SELECTnameFROMtable1WHEREnameREGEXP'111|222|333'; \r\r匹配多个字符之一 利用一组括号[]来完成。 SELECTnameFROMtable1WHEREnameREGEXP'[zhang|li|song]'; \r\r匹配范围 集合可用来定义要匹配的一个或多个字符。 /* [0123456789] [0-9] [a-z] [a-zA-Z] */SELECTnameFROMtable1WHEREnameREGEXP'[a-zA-z]hang'; \r\r转义字符 MySQL中的正则表达式使用两个反斜线(\\\\)做转义。 SELECTscoreFROMtable1WHEREscoreREGEXP'[8|9]0\\\\.0'; \r\r匹配字符类 为了更方便的工作，可以使用预定义的字符集，称为字符类(character class)。 类 说明 [:alnum:] 任意字母和数字（同[a-zA-Z0-9]） [:alpha:] 任意字符（同[a-zA-Z]） [:blank:] 空格和制表（同[\\t]） [:cntrl:] ASCII控制字符（ASCII 0到31和127） [:digit:] 任意数字（同[0-9]） [:graph:] 与[:print:]相同，但不包括空格 [:lower:] 任意小写字母（同[a-z]） [:print:] 任意可打印字符 [:punct:] 既不在[:alnum:]又不在[:cntrl:]中的任意字符 [:space:] 包括空格在内的任意空白字符（同[\\f\\n\\r\\t\\v]） [:upper:] 任意大写字母（同[A-Z]） [:xdigit:] 任意十六进制数字（同[a-fA-F0-9]） \r\r匹配多个实例 重复元字符: 元字符 说明 * 0个或多个匹配 + 1个或多个匹配（等于{1,}） ? 0个或1个匹配（等于{0,1}） {n} 指定数目的匹配 {n,} 不少于指定数目的匹配 {n,m} 匹配数目的范围（m不超过255 SELECTnameFROMtable1WHEREnameREGEXP'\\\\([0-9] zhang?\\\\)'; \r\r定位符 匹配特定位置的文本。 元字符 说明 ^ 文本的开始 $ 文本的结尾 [[:\u003c:]] 词的开始 [[:\u003e:]] 词的结尾 SELECTnameFROMtable1WHEREnameREGEXP'^[0-9\\\\.]'; \r\r\r","date":"2018-01-16","objectID":"/mysql/:61:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"创建计算字段 本章介绍什么是计算字段，如何创建计算字段以及怎样从应用程序中使用别名引用它们。 \r","date":"2018-01-16","objectID":"/mysql/:62:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"计算字段 存储在数据库表中的数据一般不是应用程序所需要的格式，我们需要直接从数据库中检索转换过的数据，然后再在C端重新格式化。 \r\r","date":"2018-01-16","objectID":"/mysql/:62:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"拼接字段 拼接(concatenate)，将值联结到一起构成单个值。在MySQL的SELECT语句中，可使用Concat()函数来拼接两个列。 多数DBMS使用+或||来实现拼接，MySQL使用Concat()函数来实现。当把SQL语句转换为MySQL语句时请一定注意。 SELECTConcat(name,', id')FROMtable1; \r使用别名 拼接字段做的很好，但新列并没有名字，而是使用Concat(name, ', id')作为列名。这样虽不能说不好，但利于使用。 为了解决这个问题，MySQL支持别名(alias)。可使用AS关键字赋予。 SELECTCONCAT(name,', id')ASnameIdFROMtable1; \r\r","date":"2018-01-16","objectID":"/mysql/:62:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"执行算术计算 计算字段的另一常见用途是对检索出的数据进行算术计算。 MySQL算术操作符: 操作符 说明 + 加 - 减 * 乘 / 除 SELECTid,quantity,price,quantity*priceAStotalPriceFROMtable1; \r\r\r","date":"2018-01-16","objectID":"/mysql/:62:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"数据处理函数 本章介绍什么是函数，MySQL支持何种函数，以及如何使用这些函数。 \r\r","date":"2018-01-16","objectID":"/mysql/:63:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"函数 与其它大多数计算机语言一样，SQL支持利用函数来处理数据。函数一般在数据上执行，它给数据的转换和处理提供了方便。 函数没有SQL的可移植性强。几乎每种DBMS的实现都支持其它不支持的函数，而且可能差异还很大。 为了代码的可移植性，许多SQL程序员不赞成使用特殊实现的功能。虽然这样有很多好处，但不总是利于应用程序的性能。 如果你决定使用函数，应该做好代码注释，以便大家知晓。 \r\r","date":"2018-01-16","objectID":"/mysql/:63:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用函数 大多数SQL支持以下类型的函数: 用于处理文本串的文本函数 用于在数值数据上进行算术操作的数值函数 用于处理日期和时间值并从这些值中提取特定成分的日期和时间函数 返回DBMS正使用的特殊信息的系统函数 \r文本处理函数 常见文本处理函数: 函数 说明 Left() 返回串左边的字符 Length() 返回串的长度 Locate() 找出串的子串 Lower() 将串转换为小写 LTrim() 去掉串左边的空格 Right() 返回串右边的字符 RTrim() 去掉串右边的空格 Soundex() 返回串的SOUNDEX值 SubString() 返回子串的字符 Upper() 将串转换为大写 SOUNDEX是将任何文本串转换为描述其语音表示的字母数字模式的算法。 SELECTname,UPPER(name)ASname_upcase,LENGTH(name)ASname_lengthFROMtable1ORDERBYname; \r\r日期和时间处理函数 日期和时间采用相应的数据类型和特殊的格式存储，以便能快速和有效地排序或过滤，并且节省物理存储空间。 一般，应用程序不使用用来存储日期和时间的格式，因此日期和时间函数总是被用来读取、统计和处理这些值。由于这个原因，日期和时间函数在MySQL语言中具有重要的作用。 常用的日期和时间处理函数: 函数 说明 AddDate() 增加一个日期 AddTime() 增加一个时间 CurDate() 返回当前时间 Month() 返回日期的月份部分 Now() 返回当前日志和时间 Second() 返回时间的秒部分 Time() 返回日期时间的时间部分 Year() 返回日期的年份部分 SELECTCURDATE(),CURTIME(),Now();SELECTid,nameFROMtable1WHEREDate(datetime)BETWEEN'2018-12-01'AND'2019-01-31'; 这是用WHERE使用日期和时间对数据进行过滤的一个好时机。请注意日期格式(yyyy-mm-dd)，应该总是使用yyyy而不是YY表示年份，这样更可靠。 \r\r数值处理函数 数值处理函数仅处理数值数据。这些函数一般用于代数、三角或几何运算。 常用数值处理函数: 函数 说明 Abc() 求绝对值 Cos() 求余弦 Exp() 求指数值 Mod() 求余数 Pi() 求圆周率 Rand() 返回一个随机数 Sin() 求正弦 Sqrt() 求平方根 Tan() 求正切 \r\r\r","date":"2018-01-16","objectID":"/mysql/:63:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"汇总数据 本章介绍什么是SQL的聚集函数，以及如何利用它们汇总表的数据。 \r","date":"2018-01-16","objectID":"/mysql/:64:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"聚集函数 我们经常需要汇总熟不而不用把它们实际检索出来，为此MySQL提供了专门的函数。以便分析和报表的生成。 这种类型的检索栗子有以下几种: 确定表中行数 获得表中行组的和 找出表列的最大值、最小值、平均值 返回实际表数据是对时间和处理资源的一种浪费。而实际想要的是汇总信息。 聚集函数(aggregate function)，运行在行组上，计算和返回单个值的函数。 SQL聚集函数: 函数 说明 AVG() 返回某列的平均值 COUNT() 返回某列的行数 MAX() 返回某列的最大值 MIN() 返回 某列的最小值 SUM() 返回某列值之和 \r\rAVG函数 AVG()通过对表中的行数计数并计算特定列值之和，求得该列的平均值。可用来返回所有列的平均值，也可用来返回特定列或行的平均值。 AVG()忽略列值为NULL的行。 SELECTAVG(price)ASavg_priceFROMtable1;#多列SELECTAVG(price),AVG(age)FROMtable1; \r\rCOUNT函数 可利用COUNT()确定表中行的数据或符合特定条件的行的数目。 COUNT()函数有两种使用方式: 使用COUNT(*)对表中的行的数目进行技术，不管是否为空 石宏COUNT(column)对特定列的值进行行计数 SELECTCOUNT(*)FROMtable1;SELECTCOUNT(column1)FROMtable1;SELECTCOUNT(column1)FROMtable1WHEREname='xxx'; \r\rMAX函数 MAX()函数用于返回列中的最大值。 它忽略列值为空的行。 对非数值数据使用MAX()，虽然它一般用来找出最大的数值或日期，但MySQL允许将它用来返回任意列中的最大值，包括返回文本列中的最大值。在用于文本数据时，如果数据按相应的列排序，则它返回最后一行。 SELECTMAX(column1),MAX(column2)FROMtable1; \r\rMIN函数 MIN()函数返回指定列的最小值。 它也会忽略列值为空的行。 对于非数值的使用，它与MAX类似。MySQL允许将它用来返回任意列中的最小值，包括返回文本列中的最小值。在用于文本数据时，如果数据按相应的列排序，则它返回最前面的行。 SELECTMIN(column1)FROMtable1; \r\rSUM函数 SUM()用来返回特定列值的和。它也可以用来合计计算值。 SUM()函数忽略列值为NULL的行。 SELECTSUM(price)AStotalFROMtable1;SELECTSUM(price*quantity)AStotalFROMtable1WHERExxx; \r\r","date":"2018-01-16","objectID":"/mysql/:64:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"聚集不同值 对于以上5个聚集函数，都可以使用如下: 对所有的行执行计算，指定ALL参数或不给参数； 只包含不同的值，使用DISTINCT参数； ALL为默认。 SELECTAVG(DISTINCTprice)ASavg_priceFROMtable1; \r\r","date":"2018-01-16","objectID":"/mysql/:64:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"组合聚集函数 SELECT语句可以根据需要包含多个聚集函数。 SELECTCOUNT(*),MIN(price),MAX(price),AVG(price)ASavg_priceFROMtable1; \r\r\r","date":"2018-01-16","objectID":"/mysql/:64:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"分组数据 本章介绍如何分组数据，以便能汇总表内容的自己。这涉及到GROUP BY子句和HAVING子句。 \r","date":"2018-01-16","objectID":"/mysql/:65:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"数据分组 分组允许把数据分为多个逻辑组，以便能对每个组进行聚集计算。 \r\r","date":"2018-01-16","objectID":"/mysql/:65:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"创建分组 在SELECT语句中使用GROUP BY子句建立分组。使用GROUP BY的一些重要规定: GROUP BY可以包含任意数目的列。这使得能对分组进行嵌套，分数据分组提供更细致的控制； 如果在GROUP BY子句中嵌套了分组，数据将在最后规定的分组上进行汇总； GROUP BY子句中列出的每个列都必须是检索列或有效的表达式； 除聚集计算语句外，SELECT语句中的每个列都必须在GROUP BY子句中给出； 如果分组列中具有NULL值，则NULL将作为一个分组返回。如果列中有多行NULL值，它们将分为一组； GROUP BY子句必须出现在WHERE子句之后，ORDER BY子句之前； 使用WITH ROLLUP关键字，可以得到每个分组以及每个分组汇总界别的值。 SELECTid,SUM(score)FROMtable1GROUPBYid; \r\r","date":"2018-01-16","objectID":"/mysql/:65:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"过滤分组 除了能用GROUP BY分组数据外，MySQL还允许过滤分组。规定包括哪些分组、排除哪些分组。 因为WHERE过滤指定的是行而不是分组，所以MySQL为此提供了另外的子句——HAVING。它非常类似于WHERE，事实上，目前为止所学过的所有类型的WHERE子句都可以用HAVING来替代。唯一差别是WHERE过滤行，而HAVING过滤分组。 HAVING支持所有WHERE操作符； WHERE在数据分组前进行过滤，它排除的行不包括在分组中； HAVING在数据分组后进行过滤。 SELECTid,SUM(score)FROMtable1GROUPBYidHAVINGSUM(score)\u003e=200;SELECTid,SUM(score)FROMtable1WHEREid\u003e10GROUPBYidHAVINGSUM(score)\u003e200; \r\r","date":"2018-01-16","objectID":"/mysql/:65:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"分组和排序 虽然GROUP BY和ORDER BY经常完成相同的工作，但它们非常不同。 一般在使用GROUP BY子句时，应该也给出ORDER BY子句。这是保证数据正确包旭的唯一方法。 SELECTid,SUM(score)FROMtable1WHEREid\u003e10GROUPBYidHAVINGSUM(socre)\u003e200ORDERBYSUM(score)DESC; \r\r","date":"2018-01-16","objectID":"/mysql/:65:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"SELECT子句顺序 子句 说明 是否必须使用 SELECT 要返回的列或表达式 是 FROM 从中检索数据的表 仅在从表选择数据时使用 WHERE 行级过滤 否 GROUP BY 分组说明 仅在按组计算聚集时使用 HAVING 组级过滤 否 ORDER BY 输出排序顺序 否 LIMIT 要检索的行数 否 \r\r\r","date":"2018-01-16","objectID":"/mysql/:65:5","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"子查询 本章介绍什么是子查询以及如何使用它们。 \r","date":"2018-01-16","objectID":"/mysql/:66:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"子查询 SELECT语句是SQL的查询。从单个数据库表中检索数据的单条SELECT语句是简单查询。 SQL还允许创建子查询(subquery)——即嵌套在其它查询中的查询。 \r\r","date":"2018-01-16","objectID":"/mysql/:66:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"利用子查询进行过滤 把一条SELECT语句的返回结果用于另一条SELECT语句的WHERE子句。 #将复杂的子查询分解为多行并进行适当缩进，能极大简化子查询的使用SELECTid,scoreFROMtable1WHEREidIN(SELECTSidFROMtable2);SELECTid,nameFROMtable1WHEREidIN(SELECTSidFROMtable2WHEREScoreIN(SELECTScoreFROMtable3)); 在WHERE子句中使用子查询能够编写出功能很强并且灵活的SQL语句。对于嵌套的子查询数目没有限制，不过在实际使用时由于性能的限制，不建议嵌套太多。 请注意权衡子查询和性能。 \r\r","date":"2018-01-16","objectID":"/mysql/:66:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"作为计算字段使用子查询 使用子查询的另一方法是创建计算字段。 相关子查询(correlated subquery)，涉及外部查询的子查询。 逐渐增加子查询来建立查询，用子查询测试和调试查询很有技巧性，特别是在这些语句的复杂性不断增加的情况下更是如此。 SELECTname,score(SELECTCOUNT(*)FROMtable2WHEREtable2.id=table1.id)FROMtable1ORDERBYname; \r\r\r","date":"2018-01-16","objectID":"/mysql/:66:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"联结表 本章介绍什么是联结，为什么要使用联结，如果编写使用联结的SELECT语句。 \r\r","date":"2018-01-16","objectID":"/mysql/:67:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"联结 SQL最强大的功能之一就是能在数据检索查询的执行中**联结(join)**表。 在能够有效地使用联结之前，必须了解关系表以及关系数据库设计的一些基础知识。 \r\r关系表 外键(foreign key)，为某个表中的一列，它包含另一个表的主键值，定义了两个表之间的关系。 可伸缩(scale)，能够不断适应增加的工作量而不失败。设计良好的数据库或应用程序称之为可伸缩性好(scale well)。 关系数据可以有效地存储和方便处理。因此，关系数据库的可伸缩性比菲关系数据库要好。 \r\r为什么要使用联结 分解数据为多个表能更有效地存储，更方便地处理，并且具有更大的可伸缩性。但这些好处是有代价的。 如果数据存储在多个表中，怎样使用单条SELECT语句检索出数据？ 答案是使用联结。简单地说，联结是一种机制，用来在同一条SELECT语句中关联表，因此称之为联结。使用特殊的语法，可以联结多个表返回一组输出，联结在运行时关联表中正确的行。 联结是由MySQL根据需要建立，它存在于查询的执行当中。 \r\r","date":"2018-01-16","objectID":"/mysql/:67:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"创建联结 SELECTt1_name,t2_name,t2_priceFROMtable1,table2WHEREt1.id=t2.idORDERBYt1_name,t2_name; 应该保证所有联结都有WHERE子句，否则MySQL经返回比想要的数据多得多的数据。 叉联结(cross join)，有时我们会听到返回称为叉联结的笛卡尔积的联结类型。 \r\r内部联结 目前为止所用的联结称为等值联结(equijoin)，它基于两个表之间的相等测试。这种联结也称为内部联结。 其实，对于这种联结可以使用稍微不同的语法来明确指定联结的类型。 ANSI SQL规范首选INNER JOIN语法。 SELECTt1_name,t2_name,t2_priceFROMtable1INNERJOINt2ONt1.id=t2.id; \r\r联结多个表 SQL对一条SELECT语句中可以联结的表的数目没有限制，创建联结的基本规则也相同。 MySQL在运行时关联指定的每个表已处理联结，这种处理可能是非常耗费资源的，因此应该仔细，不要联结不必要的表。联结的表越多，性能下降的越厉害。 SELECTt2_name,t1_name,t2_price,quantityFROMtable1,table2,table3WHEREtable2.id=table1.idANDtable3.id=table2.idANDnum=xxx; \r\r\r","date":"2018-01-16","objectID":"/mysql/:67:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"高级联结 本章介绍如何对被联结的表使用表别名和聚集函数。 \r\r","date":"2018-01-16","objectID":"/mysql/:68:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"表别名 SQL还允许给表名起别名: 缩短SQL语句； 允许在单条SELECT语句中多次使用相同的表； 表别名只在查询中使用，与列别名不同，它不返回到客户机。 SELECTname,contactFROMtable1ASt1,table2ASt2,table3ASt3WHEREt1.id=t2.idANDt3.num=t2.numANDid='xxx'; \r\r","date":"2018-01-16","objectID":"/mysql/:68:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"不同类型的联结 前面使用的称为内部联结或等值联结，除此之外，还有3中其它联结: 自联结 自然联结 外部联结 \r\r自联结 使用自联结而不用子查询。 自联结通常作为外部语句用来替代从相同表中检索数据时使用的子查询语句。虽然最终结果是相同的，但有时候处理联结比处理子查询快的多。应该试一下两种方法，以确定哪一种的性能更好。 #子查询SELECTprod_id,prod_nameFROMproductsWHEREvend_id=(SELECTvend_idFROMproductsWHEREprod_id='xxx')#使用联结#此查询中的两个表实际上是相同的表#虽然这是合法的，但对products的引用具有二义性，因为MySQL不知道你引用的是products表中的哪个实例#为了解决此问题，使用了表别名SELECTp1.prod_id,p2.prod_nameFROMproductsASp1,productsASp2WHEREp1.vend_id=p2.vend_idANDp2.prod_id='xxx'; \r\r自然联结 无论何时对表进行联结，应该至少有一列出现在不止一个表中。标准的联结返回所有数据，甚至相同的列多次出现。自然联结排除多次出现，使每个列只返回一次。 #通配符只对第一个表使用。#所有其它列明确列出，所以没有重复的列被检索出来。SELECTc.*o.order_num,o.order_date,oi.prod_id,oi.quantity,OI.item_priceFROMcustomersASc,ordersASo,orderitemsASoiWHEREc.cust_id=o.cust_idANDoi.order_num=o.order_numANDprod_id='xxx'; 事实上，迄今为止我们建立的每个内部联结都是自然联结，很可能我们永远都不会用到不是自然联结的内部联结。 \r\r外部联结 许多联结将一个表中的行与另一个表中的行相关联。但有时候会需要包含没有关联行的那些行。 联结包含了那些在相关表中没有关联行的行，这种类型的联结称为外部联结。 在使用OUTER JOIN语法时，必须使用RIGHT或LEFT关键字指定包括其所有行的表。(（RIGHT指出的是OUTER JOIN右边的表，而LEFT指出的是OUTER JOIN左边的表) 外部联结的类型，它们的唯一差别是所关联的表的顺序不同。 左外部联结 右外部联结 #内部联结栗子SELECTStudent.Id,Score.scoreFROMStudentINNERJOINScoreONStudent.Id=Score.Sid;+----+-------+ |Id|score|+----+-------+ |1|80.0||1|90.0||1|99.0||2|70.0||2|60.0||2|80.0|+----+-------+ 6rowsinset(0.00sec)#外部联结#LEFTSELECTStudent.Id,Score.scoreFROMStudentLEFTOUTERJOINScoreONStudent.Id=Score.Sid;+----+-------+ |Id|score|+----+-------+ |1|80.0||1|90.0||1|99.0||2|70.0||2|60.0||2|80.0|+----+-------+ 6rowsinset(0.00sec)#RIGHTSELECTStudent.Id,Score.scoreFROMStudentRIGHTOUTERJOINScoreONStudent.Id=Score.Sid;+------+-------+ |Id|score|+------+-------+ |1|80.0||1|90.0||1|99.0||2|70.0||2|60.0||2|80.0||NULL|80.0||NULL|80.0||NULL|80.0|+------+-------+ 9rowsinset(0.01sec) MySQL不支持简化字符*=和=*的使用，这两种操作在其它DBMS中很流行。 \r\r","date":"2018-01-16","objectID":"/mysql/:68:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"带聚合函数的联结 聚合函数用来汇总数据。 SELECTcustomers.cust_name,customers.cust_id,COUNT(orders.order_num)ASnum_ordFROMcustomersINNERJOINordersONcustomers.cust_id=orders.cust_idGROUPBYcustomers.cust_id;SELECTcustomers.cust_name,customers.cust_id,COUNT(orders.order_num)ASnum_ordFROMcustomersLEFTOUTERJOINordersONcustomers.cust_id=orders.cust_idGROUPBYcustomers.cust_id; \r\r","date":"2018-01-16","objectID":"/mysql/:68:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"联结和联结条件 联结及其使用要点: 注意所使用的联结类型； 保证使用正确的联结条件，否则将返回不正确的数据； 应该总是提供联结条件，否则会得出笛卡尔积； 在一个联结中可以包含多个表，甚至每个联结可以采用不同的联结类型。虽然这样做合法也很有用，但应该在一起测试它们之前，分别测试每个联结。 \r\r\r","date":"2018-01-16","objectID":"/mysql/:68:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"组合查询 本章讲述如何利用UNION操作符将多余SELECT语句组合成一个结果集。 \r\r","date":"2018-01-16","objectID":"/mysql/:69:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"组合查询 多数SQL查询都只包含从一个或多个表中返回数据的单条SELECT语句。MySQL也允许执行多个查询(多条SELECT语句)，并将结果作为单个查询结果集返回。这些组合查询通常称为并(union)或符合查询(compound query)。 有两种基本情况，需要使用组合查询: 在单个查询中从不同的表返回类似结构的数据； 对单个表执行多个查询，按单个查询返回数据。 组合查询和多个WHERE条件。 多数情况下，组合相同表的两个查询完成的工作与具有多个WHERE子句条件的单挑插叙完成的工作相同。换句话说，任何具有多个WHERE的SELECT语句都可以作为一个组合查询给出。 为了使表述简单，本章栗子的组合查询使用相同的表。但是UNION组合查询可以使用不同的表。 \r\r","date":"2018-01-16","objectID":"/mysql/:69:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"创建组合查询 可用UNION操作来组合数条SQL查询。 \r使用UNION 在各条SELECT语句之间放上关键字UNION。 SELECTSid,scoreFROMScoreWHEREscore\u003e=80;+-----+-------+ |Sid|score|+-----+-------+ |01|80.0||01|90.0||01|99.0||02|80.0||03|80.0||03|80.0||03|80.0|+-----+-------+ SELECTSid,scoreFROMScoreWHEREscoreIN(60,70);+-----+-------+ |Sid|score|+-----+-------+ |02|70.0||02|60.0|+-----+-------+ #使用UNION组合这两条语句SELECTSid,scoreFROMScoreWHEREscore\u003e=80UNIONSELECTSid,scoreFROMScoreWHEREscoreIN(60,70);+-----+-------+ |Sid|score|+-----+-------+ |01|80.0||01|90.0||01|99.0||02|80.0||03|80.0||02|70.0||02|60.0|+-----+-------+ \r\rUNION规则 在进行UNION操作是有几条规则需要注意: UNION必须由两条或两条以上的SELECT语句组成，语句之间用关键自UNINO分隔； UNION中的每个查询必须包含先沟通的列、表达式或聚集函数； 列数据类型必须兼容，类型不必完全相同，但必须是DBMS可以隐含地转换的类型 \r\r包含或取消重复的行 UNION从查询结果中自动去除了重复的行，这是UNION的默认行为。如果有需要想返回所有匹配行，可使用UNION ALL。 SELECTSid,scoreFROMScoreWHEREscore\u003e=80UNIONALLSELECTSid,scoreFROMScoreWHEREscoreIN(60,70);+-----+-------+ |Sid|score|+-----+-------+ |01|80.0||01|90.0||01|99.0||02|80.0||03|80.0||03|80.0||03|80.0||02|70.0||02|60.0|+-----+-------+ \r\r对组合查询结果排序 在使用UNION组合查询时，只能使用一条ORDER BY子句，并且它必须出现在最后一条SELECT语句之后。 对于结果集，不存在用一种方式排序一部分，而又用另一种方式排序另一部分，因此不允许使用多条ORDER BY子句。 SELECTSid,scoreFROMScoreWHEREscore\u003e=80UNIONSELECTSid,scoreFROMScoreWHEREscoreIN(60,70)ORDERBYSid,score;+-----+-------+ |Sid|score|+-----+-------+ |01|80.0||01|90.0||01|99.0||02|60.0||02|70.0||02|80.0||03|80.0|+-----+-------+ \r\r\r","date":"2018-01-16","objectID":"/mysql/:69:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"全文本搜索 本章将介绍如何使用MySQL的全文本搜索功能进行高级的数据查询和选择。 \r\r","date":"2018-01-16","objectID":"/mysql/:70:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"理解全文本搜索 并非所有引擎都支持全文本搜索(FULLTEXT SEARCH)。 MySQL最常用的两个引擎为MyISAM何InnoDB，前者支持全文本搜索，而后者不支持。 虽然LIKE通配符匹配和REGX正常匹配非常有用，但存在几个重要的限制: 性能，通配符和正则表达式通常要求MySQL尝试匹配表中所有行(而这些搜索极少使用表索引)。因此，由于被搜索的行数不断增加，这些搜索可能非常耗时； 明确控制，使用通配符和正则表达式匹配，很难明确地控制什么和不匹配什么； 智能化的结果，虽然基于通配符和正则表达式的搜索提供了非常灵活的搜索，但它们都不能提供一种智能化的选择结果的办法。 所有这些限制以及更多的限制都可用全文本搜索来解决。在使用全文本搜索时，MySQL不需要分别查看每个行，不需要分别分析和处理每个词。MySQL创建指定列中各词的一个索引，搜索可以针对这些词进行。这样，MySQL可以快速有效地决定哪些词匹配，哪些词不匹配，匹配的频率… \r\r","date":"2018-01-16","objectID":"/mysql/:70:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用全文搜索 为了进行全文搜索，必须索引被搜索的列，而且要随着数据的改变不断地重新索引。在对表列进行适当设计后，MySQL会自动进行所有的索引和重新索引。 索引之后，SELECT可与Match()和Against()一起使用以实际执行搜索。 \r启用全文本搜索 #创建MyISAM引擎表CREATETABLEfulltextSearch(note_idintNOTNULLAUTO_INCREMENT,prod_idchar(10)NOTNULL,note_datedatetimeNOTNULL,note_texttextNULL,PRIMARYKEY(note_id),FULLTEXT(note_text))ENGINE=MyISAMCHARSET=utf8; 不要再导入数据时使用FULLTEXT。 更新索引要花时间，虽然不是很多，但毕竟要花时间。如果正在导入数据到一个新表，此时不应该启用FULLTEXT索引。应该先导入所有数据，再修改表，定义FULLTEXT。 \r\r进行全文本搜索 在索引之后，使用两个函数Match()(指定搜索的列)，Against()(指定要使用的搜索表达式)执行全恩搜索。 SELECTnote_text,Match(note_text)Against('salah')ASrankFROMfulltextSearch; \r\r使用查询扩展 查询扩展用来设法放宽所返回的全文本搜索结果的范围。 在使用查询扩展时，MySQL对数据和索引进行两边扫描来完成搜索: 首先，进行一个基本的全文本搜索，找出与搜索条件匹配的所有行； 其次，MySQL检查这些匹配行并选择所有有用的词； 再其次，MySQL再次进行全文本搜索，这次不仅使用原来的条件，而且还是用所有有用的词。 利用查询扩展，能找出可能相关的结果，即使它们并不精确包含所查找的词。 #简单栗子，没有扩展查询SELECTnote_textFROMtable1WHEREMatch(note_text)Against('xxx');#使用扩展查询SELECTnote_textFROMtable1WHEREMatch(note_text)Against('xxx'WITHQUERYEXPANSION); 表中的行越多，使用查询扩展返货的结果越好。 \r\r布尔文本搜搜 MySQL支持全文本搜索的布尔方式(bollean mode)。 布尔方式即使某有FULLTEXT索引也可以使用。但这是一个非常缓慢的操作。 以布尔方式，可提供关于如下内容的细节: 要匹配的词； 要排斥的此；· 排列提示； 表达式分组； 另外一些内容。 SELECTnote_textFROMtable1WHEREMatch(note_text)Against('xxx'INBOOLEANNODE); 全文本布尔操作符: 布尔操作符 说明 + 包含，词必须存在 - 排除，词必须不出现 \u003e 包含，而且增加等级值 \u003c 包含，且减少等级值 () 把此排成子表达式 ~ 取消一个此的排序值 * 词尾的通配符 \"\" 定义一个短语 -- 栗子 -- 搜索包含rabbit和bait的行 SELECTnote_textFROMtable1WHEREMatch(note_text)Against('+rabbit +bait'INBOOLEANMODE);-- 没有指定操作符，匹配包含rabbit和bait中的至少一个词的行 SELECTnote_textFROMtable1WHEREMatch(note_text)Against('rabbit bait'INBOOLEANMODE);-- 匹配rabbit bait短语而不是两个词 SELECTnote_textFROMtable1WHEREMatch(note_text)Against('\"rabbit bait\"'INBOOLEANMODE); \r\r全文本搜索的使用说明 全文本搜索的某些重要说明: 在索引全文本数据时，短词(3个或3个以下字符的词)被忽略且从索引中排除； MySQL带有一个內建的费用次(stopword)列表，这些词在索引全文本数据时总是被忽略。如果需要，可覆盖这个列表； 许多次出现的频率很高，搜索它们没有用处。因此MySQL规定了一条50%规则，如果一个词出现在50%以上的行中，则将它作为一个非用词忽略。此规则不用于布尔方式； 如果表中的函数少于3行，则全文本搜索不反悔结果(因为每个词或者不出现，或者至少出现在50%的行中)； 忽略词中的单引号； 不具有词分隔符的语言不能恰当地返回全文本搜索结果； 仅在MyISAM引擎中支持全文本搜索 \r\r\r","date":"2018-01-16","objectID":"/mysql/:70:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"插入数据 本章介绍如何利用SQL的INSERT语句将数据插入表中。 \r","date":"2018-01-16","objectID":"/mysql/:71:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"数据插入 INSERT是用来插入(添加)行到数据库表的。插入有几种方式: 插入完整的行； 插入行的一部分； 插入多行； 插入某些查询的结果。 \r\r","date":"2018-01-16","objectID":"/mysql/:71:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"插入完整的行 各个列必须以它们在表定义中出现的次序填充。 虽然这种语法很简单，但并不安全，应该尽量避免使用。下面的SQL语句高度依赖于表中列的定义次序，并且还依赖于其次序容易获得的信息。即使可得到这种次序信息，也不能保证下一次表结构变动后各个列完全保持相同的次序，因此，编写依赖于特定列次序的SQL语句是很不安全的。 INSERTINTOtable1VALUES(NULL,'aaaa A, AA','abCD','ChengDu','12345','xxx',NULL);#INSERT语句一般不会产生输出#由于第一列id是自增，所以可以不给出值 更安全INSERT语句: INSERTINTOtable1(name,address,city,state,contact,email)VALUES('zhang','HighTech','Chengdu','SC','15566668888','xxx@example.com'); 因为提供了列名，VALUES必须以其指定的次序匹配指定的列名，不一定按各个列出现在表中的次序。 其优点是，即使表的结构发生改变，此INSERT语句仍然能够正确工作。你会发现id列的NULL值是不必要的，id列并没有出现在列表中，所以不需要任何值。 当然，你也可以给出列名，并给出其NULL值。 INSERTINTOtable1(name,contact,email,address)VALUES('ZHANG',NULL,NULL,'HighTect'); 总使用列的列表。 一般不要使用没有明确给出列的列表的INSERT语句。使用列表能使SQL代码继续发挥作用，即使表结构发生了变化。 仔细地给出值。 不管使用哪种INSERT语法，都必须给出VALUES的正确数目。如果不提供列名，则必须给每个表列提供一个值。如果提供列名，则必须对每个列出的列给出一个值。否则，将产生行插入不成功的错误消息。 省略列。 如果表的定义允许，则可以在INSERT操作中省略某些列。省略的列必须满足以下某个条件: 该列定义为允许NULL值； 在表定义中给出默认值。如果不给出值，将使用默认值； 提高整体性能。 INSERT操作可能很耗时(特别是有很多索引需要更新时)，而且它可能降低等待处理的SELECT语句的性能。 如果数据检索是最重要的，你可通过在INSERT和INTO之间添加关键字LOW_PRIORITY，指示MySQL降低INSERT语句的优先级。这同样也适用于UPDATE和DELETE语句。 \r\r","date":"2018-01-16","objectID":"/mysql/:71:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"插入多行 INSERT可以插入一行或多行到一个表中。 有两种方式: 使用多条INSERT语句； 一条INSERT的多个值 #多条INSERTINTOtable1(name,address,city,state)VALUES('name1','hightec','cd','sc');INSERTINTOtable1(name,city,state)VALUES('name2','cd','sc')#单条INSERTINTOtable1(name,address,city,state,country)VALUES('NAME1','HIGHTEC','CD','SC','CN'),('NAME2','HIGHTEC','CD','SC','CN'); 提高INSERT的性能。 此技术可提高数据库处理的能力，因为MySQL用单条INSERT语句处理多个插入比使用多条INSERT语句快。 \r\r","date":"2018-01-16","objectID":"/mysql/:71:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"插入检索的数据 INSERT可将一条SELECT语句的结果插入表中，这称为INSERT SELECT，顾名思义，它由一条INSERT语句和一条SELECT语句组成。 INSERTINTOtable1(id,contact,email,name,address,city,state,country)SELECTid,contact,email,name,address,city,state,countryFROMtable2WHEREname='zhang21'; INSERT SELECT中的列名，为了简单起见，此例子中使用了相同的列名。但其实不一定要求列名匹配。 \r\r\r","date":"2018-01-16","objectID":"/mysql/:71:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"更新和删除数据 本章介绍如何利用UPDATE语句和DELETE语句进一步操控表数据。 \r","date":"2018-01-16","objectID":"/mysql/:72:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"更新数据 有两种方式使用UPDATE: 更新表中特定行； 更新表中所有行。 基本的UPDATE语句由3部分组成: 要更新的表； 列名和它们的新值； 确定要更新行的过滤条件。 不要省略WHERE子句。 在使用UPDATE时一定要注意细心。因为稍有不注意，就会更新表中的所有行。 UPDATE与安全。 可以限制和控制UPDATE语句的使用。 -- 更新单列 UPDATEtable1SETemail='beef@meat.com'WHEREid=123ANDname='beef';#更新多列UPDATEtable1SETemail='milk@drink.com',address='hightec'WHEREid=123;#为了删除某个列的值，可将其设置为NULLUPDATEtable1SETemail=NULLWHEREid=123; 在UPDATE语句中使用子查询。 UPDATE语句可以使用子查询，使得能用SELECT语句检索出的数据更新列数据。 UPDATEtable1SETzip=(SELECTzipFROMtable2WHEREid=111)WHEREid=111;UPDATEtable1SETzip='646100'WHEREid=(SELECTidFROMtable2WHEREzip='646100'); IGNORE关键字。 如果用UPDATE语句更新多行，并且在更新这些行中的一行或多行时出现一个错误，则整个UPDATE操作被取消。而使用IGNORE关键字，这可以忽略错误，继续执行。 UPDATEIGNOREtable1... \r\r","date":"2018-01-16","objectID":"/mysql/:72:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"删除数据 有两种方式使用DELETE: 从表中删除特定的行； 从表中删除所有行。 不要省略WHERE子句。 在使用DELETE时一定要注意细心。因为稍不注意，就会错误地删除表中所有行。 DELETE与安全。 可以限制和控制DELETE语句的使用。 删除表的内容而不是表。 DELETE语句从表中删除行，甚至是表中所有行。但是，DELETE不删除表本身。 更快地删除。 如果想从表中删除所有行，不要使用DELETE。可使用TRUNCATE TABLE语句，它完成相同的工作，但速度更快。(它实际是删除原来的表并重新创建一个表，而不是逐行删除表中的数据)。 DELETEFROMtableWHEREid=123ANDname='beef'; DELETE不需要列名或通配符，以为它删除整行而不是删除列。为了删除指定的列，请使用UPDATE语句。 \r\r","date":"2018-01-16","objectID":"/mysql/:72:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"更新和删除的指导原则 UPDATE语句和DELETE语句都使用了WHERE子句，这样做的理由很充分。如果省略了WHERE子句，则UPDATE或DELETE操作将应用到表中所有行。 下面是SQL使用者在使用UPDATE和DELETE语句时应该遵循的习惯: 请一定使用带WHERE子句的UPDATE或DELETE语句； 保证每个表都有主键，尽可能像WHERE子句那样使用它； 在对UPDATE或DELETE语句使用WHERE子句前，应先使用SELECT进行测试，以保证它过滤的是正确的记录； 使用强制实施完整性的数据库，这样MySQL将不允许删除具有与其它表相关联的数据的行； 一定要小心操作，MySQL没有撤销按钮。 \r\r\r","date":"2018-01-16","objectID":"/mysql/:72:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"创建和操作表 本章介绍表的创建、更改和删除的基本知识。 \r","date":"2018-01-16","objectID":"/mysql/:73:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"创建表 一般有两种创建表的方法: 使用交互式创建和管理表的工具； 直接使用MySQL语句操纵。 \r利用CREATE TABLE语句创建表，必须给出下列信息: 新表的名字； 表列的名字和定义。 -- HELP CREATE TABLE; #CREATETABLEtablenameIFNOTEXISTSCREATETABLEtablename(idintNOTNULLAUTO_INCREMENT,namechar(50)NOTNULL,addresschar(50)NULL,countrychar(20)NULLDEFAULTCN,emailchar(255)NULL,textstextNULL,PRIMARYKEY(id),FULLTEXT(texts))ENGINE=InnoDBCHARSET=utf8mb4; 关于上面创建表语句的一些解释: MySQL忽略空格，所以建议进行适当的缩进(格式化)以方便阅读； 在创建新表时，指定的表名必须不存在，否则将出错； 如果你仅想创建一个不存在的表， 应该在表后面给出IF NOT EXISTS; NULL值就是没有值或缺值 允许NULL值的列也允许在插入行时不给出该列的值； 不允许NULL值的列不接受没有值的行，也就是必须要有值。 注意理解NULL值和空串(''，两个单引号，中间没有字符)。空串是一个有效的值，而不是无值； 主键必须唯一 如果主键使用单个列，则它的值必须唯一； 如果主键使用多个列，则这些列的组合值必须唯一； 主键中只能使用不允许NULL值的列。允许NULL值的列不能作为唯一标识。 自增(AUTO_INCREMENT)告诉MySQL，本列每当增加一行 时自动增量。每个表只允许一个自增列，而且它必须被索引。当然，你也可以在插入语句中指定它的值，只要这个值是唯一的即可。后续的增量将开始使用该手工插入的值。让MySQL生成主键的一个缺点就是你不知道这些值是谁； 指定默认值。如果在插入行时没有给出值，MySQL允许指定此时使用的默认值。使用DEFAULT关键字指定。默认值只支持常量； 数据库引擎。如果忽略，则默认为InnoDB InnoDB是一个可靠地事务处理引擎； MEMORY在功能等同于MyISAM，速度很快(特别适合临时表)； MyISAM是一个性能极高的引擎，它支持全文搜索。 \r\r","date":"2018-01-16","objectID":"/mysql/:73:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"更新表 为更新表定义，可使用ALTER TABLE语句。但是，理想状态下，当表中存储数据以后，该表就不应该再被更新。在表的设计过程中需要花费大量时间来考虑，以便后期不贵该表进行大的改动。 小心使用ALTER TABLE。 应该在进行表结构改动之前做一个完整的备份。数据表的更改不能撤销。如果增加了不需要的列，可能不能删除它们。类似地，如果删除了不应该删除的列，可能会丢失该列中的所有数据。 使用ALTER TABLE必须给出以下信息: 必须存在的表名； 所做更改的列表。 -- HELP ALTER TABLE; #给表添加一个列ALTERTABLEtablenameADDadd_line1CHAR(20)NULL,#删除表列ALTERTABLEtablenameDROPCOLUMNadd_line1; ALTER TABLE的一种常见用途是定义外键。 ALTERTABLEorderitemsADDCONSTRAINTfk_orderitems_ordersFOREIGNKEY(order_num)REFERENCEorders(order_num);ALTERTABLEordersADDCONSTRAINTfk_orders_customersFOREIGNKEY(cust_id)REFERENCEcustomers(cust_id); 复杂的表结构一般需要手动删除过程，它涉及: 用新的列布局创建一个新表； 使用INSERT SELECT语句从旧表复制数据到新表； 检验包含所需数据的新表； 重命名旧表； 用旧表原来的名字重命名新表； 根据需要，重新创建触发器、存储过程、索引和外键。 \r\r","date":"2018-01-16","objectID":"/mysql/:73:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"删除表 删除表(删除整个表而不是其内容)，使用DROP TABLE语句。 删除表没有确认，也不能撤销，执行这条语句将会永久删除该表。 -- HELP DROP TABLE; DROPTABLEtablename; \r\r","date":"2018-01-16","objectID":"/mysql/:73:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"重命名表 使用RENAME TABLE语句可以重命名一个表。 -- HELP RENAME TABLE; RENAMETABLEoldnameTOnewname;#重命名多个表RENAMETABLEoldname1TOnewname1,oldname2TOnewname2; \r\r\r","date":"2018-01-16","objectID":"/mysql/:73:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"视图 本章将介绍视图是什么，它们怎样工作，何时使用它们。 \r","date":"2018-01-16","objectID":"/mysql/:74:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"视图 不建议对视图进行更新，因为视图主要用于数据检索，而非更改。 **视图(view)**是虚拟的表。与包含数据的表不一样，视图只包含使用时动态检索数据的查询。 来看个栗子: /* 任何需要这个数据的人都必须理解相关表的结构， 并且知道如何查询和对表进行联结。 */SELECTcust_name,cust_contactFROMcustomers,orders,orderitemsWHEREcustomers.cust_id=orders.cust_idANDorderitems.order_num=orders.order_numANDprod_id='TNT2';/* 假如把整个查询包装成一个名为productcustomers的虚拟表，则可轻松检索出相同的数据。 作为视图，它不包含表中应该有的任何列或数据，它包含的是一个SQL查询。 */SELECTcust_name,cust_contactFROMproductcustomersWHEREprod_id='TNT2'; \r为什么使用视图 视图的常见应用: 重用SQL语句； 简化复杂的SQL操作。在编写查询后，可以方便地重用它而不必知道它的基本查询细节； 使用表的组成部分而不是整个表； 保护数据。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限； 更改数据格式和表示。视图可返回与底层表的标识和格式不同的数据。 在视图创建之后，可以用与表基本相同的方式利用它们。可以对视图执行SELECT操作，过滤和排序，将视图联结到其它视图或表，甚至还能添加和更新数据。 重要的是知道视图仅仅是用来查看存储在别处的数据的一种设施。视图本身不包含数据，因此它们返回的数据是从其它表中检索出来的。在添加或更改这些表中的数据时，视图将返回改变过的数据。 性能问题 因为视图不包含数据，所以每次使用视图时，都必须处理查询执行时所需的任一个检索。如果你用多个联结和过滤创建了复杂的视图或嵌套了视图，可能会发现性能下降得很厉害。因此，在部署使用了大量视图的应用前，应该进行测试。 \r\r视图的规则和限制 视图创建和使用的一些最常见的规则和限制: 视图必须唯一命名(不能与其它视图或表同名)； 对于可以创建的视图数目没有限制； 为了创建视图，必须具有足够的访问权限； 视图可以嵌套，即可从其它视图中检索数据的查询来构造一个视图； ORDER BY可用在视图中，但如果该视图检索数据SELECT中也含有ORDER BY，那么该视图中的ORDER BY将被覆盖； 视图不能索引，也不能有关联的触发器或默认值； 视图可以和表一起使用。 \r\r","date":"2018-01-16","objectID":"/mysql/:74:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用视图 使用CREATE VIEW viewName创建视图； 使用SHOW CREATE VIEW viewName查看创建视图的语句； 使用DROP VIEW viewName删除视图； 更新视图时，可以先用DROP再用CREATE，也可以直接使用CREATE OR REPLACE VIEW。 \r\r","date":"2018-01-16","objectID":"/mysql/:74:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"利用视图简化复杂的联结 视图最常见的应用之一是隐藏复杂的SQL，这通常会涉及联结。 -- 这是不使用AS会报错 CREATEVIEWproductcustomersASSELECTcust_name,cust_contact,prod_idFROMcustomers,orders,orderitemsWHEREcustomers.cust_id=order.cust_idANDorderitems.order_num=orders.order_num;#查看视图SHOWVIEWproductcustomers;#此视图包含上面检索出来的三列内容DESCRIBEproductcustomers;SHOWCOLUMNSFROMproductcustomers;#检索的结果也是这三列SELECT*FROMproductcustomers;#这里注意，如果创建视图中使用的源表数据发生更新或变动，则视图也会相应的发生改变 \r用视图重新格式化检索出的数据 视图的另一常见用途是重新格式化检索出的数据。 -- 例如要经常使用拼接列 SELECTConcat(RTrim(name),'(',RTrim(contry),')')AStitleFROMtable1ORDERBYname;-- 不必在每次需要时执行联结，创建一个视图每次需要时使用它即可 CREATEVIEWviewLocationASSELECTConcat(RTrim(name),'(',RTrim(country),')')AStitleFROMtable1ORDERBYname;-- 检索 SELECT*FROMviewLocation; \r\r使用视图过滤不想要的数据 视图对于应用普通的WHERE子句也很有用。 如果从视图检索数据时使用了WHERE子句，则两组WHERE子句(传递给视图的和视图自身的)将自动组合。 -- 栗子 CREATEVIEWcustomerEmailListASSELECTid,name,emailFROMtable1WHEREemailISNOTNULL;SELECT*FROMcustomerEmailListWHEREid=111; \r\r使用视图与计算字段 视图对于简化计算字段的使用特别有用。 -- 栗子 CREATEVIEWviewTotalASSELECTid,num,quantity,item_price,quantity*item_priceAStotal_priceFROMtable1;SELECT*FROMviewTotalWHEREid=123; \r\r更新视图 通常，视图是可更新的(即对它使用INSERT, UPDATE, DELETE)。更新一个视图将更新其基表。如果你对视图增加或删除行，实际上是对其基表增加或删除行。 但是，并非所有视图都是可更新的。如果MySQL不能正确地确定被更新的基数据，则不允许更新、插入和删除。如果视图定义中有以下操作: 分组(GROUP BY, HAVING)； 联结； 子查询； 并； 聚集函数(MIN(), COUNT()...)； DICTINCT; 导出(计算)列。 不建议对视图进行更新，因为视图主要用于数据检索，而非更改。 \r\r\r","date":"2018-01-16","objectID":"/mysql/:74:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"存储过程 本章介绍什么是存储过程，为什么要使用存储过程以及如何使用存储过程… \r","date":"2018-01-16","objectID":"/mysql/:75:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"存储过程 迄今为止，使用的大多数SQL语句都是以针对一个/多个表的单条语句。并非所有操作都这么简单，经常会有一个完整的操作需要多条语句才能完成。 可以创建存储过程。存储过程简答来说，就是为以后的使用而保存的一条或多条MySQL语句的集合。可将其视为批文件，虽然它们的作用不仅限于批处理。 \r\r","date":"2018-01-16","objectID":"/mysql/:75:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"为什么要使用存储过程 使用它的一些主要理由: 通过把处理封装在容易使用的单元中，简化复杂的操作； 由于不要求反复建立一系列处理步骤，这保证了数据的完整性； 简化对变动的管理； 提高性能； 存在一些职能用在单个请求中的MySQL元素和特性，存储过程可以使用它们来编写功能更强更灵活的代码； 一般来说，存储过程的编写比基本SQL语句更复杂，编写存储过程需要更高的技能，更丰富的经验； 你可能没有创建存储过程的安全访问权限。 MySQL将编写存储过程与执行存储过程的安全和访问分开来。即使你没有权限编写存储过程，也可在适当的时候执行别的存储过程。 \r\r","date":"2018-01-16","objectID":"/mysql/:75:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用存储过程 使用存储过程需要知道如何执行和创建它们。 \r创建存储过程 -- HELP CREATE PROCEDURE; CREATEPROCEDUREprocedureTest()BEGINSELECTAvg(price)ASpriceAvgFROMtable1;END;#BEGIN,END语句用来限定存储过程体 注意 MySQL命令行的分隔符，如果使用MySQL命令行实用程序，请仔细阅读此说明。 默认的MySQL语句分隔符为;，MySQL命令行实用程序也是用;作为语句分隔符。如果命令行实用程序要解释存储过程自身内的;字符，则它们最终不会成为存储过程的成分，这会使存储过程的SQL出现语法错误。 解决办法是临时修改命令行实用程序的语句分隔符。 -- 除了\\(转义字符)，其它都可作为语句分隔符 -- 临时修改MySQL分隔符 DELIMITER//CREATEPROCEDUREprocedureTest()BEGINSELECTAvg(price)ASpriceAvgFROMtable1;END//-- 恢复MySQL默认分隔符 DELIMITER; \r\r执行存储过程 CALL语句接受存储过程以及需要传递给它的参数。 存储过程实际上是一种函数，所以后面需要有括号()。 -- 栗子 CALLprocedureTest(); \r\r删除存储过程 -- 如果过程不存在，则删除会产生一个错误 DROPPROCEDUREprocedureTest; \r\r使用参数 一般，存储过程并不显示结果，而是把结果返回给你指定的变量。 变量是内存中一个特定的位置，用来临时存储数据。MySQL的变量都必须以@开始。 MySQL支持三种类型的参数: IN，传递给存储过程 OUT，从存储过程传出 INOUT，对存储过程传入和传出 -- 此存储过程接受三个参数 CREATEPROCEDUREprocedureTest2(OUTplDECIMAL(8,2),OUTphDECIMAL(8,2),OUTpaDECIMAL(8,2))BEGINSELECTMin(price)INTOplFROMtable1;SELECTMax(price)INTOphFROMtable1;SELECTAvg(price)INTOpaFROMtable1;END;-- 执行 CALLprocedureTest2(@pricelow,@pricehigh,@priceaverage);SELECT@pricelow,@pricehigh,@priceaverage;-- 另一个栗子 CREATEPROCEDUREorderTotal(INonumerINT,OUTototalDECIMA(8,2))BEGINSELECTSum(item_price*quantity)FROMorderitemsWHEREorder_num=onumberINTOototal;END;-- 执行 CALLorderTotal(12345,@total);SELECT@total; \r\r建立智能存储过程 在存储过程内包含业务规则和智能处理时，它们的威力才真正显现出来。 #栗子/* Name: ordertotal Parameter: onumber = order number taxable = 0 if not taxable, 1 if taxable ototal = order total variable */CREATEPROCEDUREordertotal(INonumberINT,INtaxableBOOLEAN,#布尔值1(true),0(false)OUTototalDECIMAL(8,2))COMMENT'Obtain order total, optinally adding tax.'BEGIN-- Declare variable for total DECLAREtotalDECIMAL(8,2);-- Declare tax percentage DECLAREtaxrateINTDEFAULT6;-- Get the order total SELECTSum(item_price*quantity)FROMorderitemsWHEREorder_num=onumberINTOtotal;-- Is this taxable? IFtaxableTHEN-- Yes, so add taxrate to the total SELECTtotal+(total/100*taxrate)INTOtotal;ENDIF;-- And finally, save to out varible SELECTtotalINTOototal;END;-- 执行 CALLordertotal(12345,0,@total);SELECT@total; \r\r检查存储过程 -- 显示创建存储过程 SHOWCREATEPROCEDUTExxx;-- 获得存储过程详细信息 SHOWPROCEDURESTATUS;SHOWPROCEDURESTATUSLIKE'procedureTest1'; \r\r\r","date":"2018-01-16","objectID":"/mysql/:75:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"游标 本章将介绍任何是游标，如何使用游标。 \r","date":"2018-01-16","objectID":"/mysql/:76:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"游标 MySQL检索操作返回一组称为结果集的行。但没有办法得到某些行，也不存在每次一行地处理所有行的简单方法。 有时，需要在检索出来的行中前进或后退一行或多行。这就是使用游标(cursor)的原因。 游标(cursor)，是一个存储在MySQL服务器上的数据库查询，它不是一条SELECT语句，而是被该语句检索出来的结果集。在存储了游标之后，应用程序可以根据需要滚动或浏览其中的数据。 游标主要用于交互式应用，其中用户需要滚动屏幕上的数据，并对其数据进行浏览或做出更改。 不像其它DBMS，MySQL的游标只能用于存储过程(和函数)。 \r\r","date":"2018-01-16","objectID":"/mysql/:76:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用游标 使用游标的几个明确步骤: 在使用游标前，必须声明它(DECLARE)。此过程并没有检索数据，它只是定义要使用的SELECT语句； 一旦声明后，必须打开(OPEN)游标以供使用。此过程用前面定义的SELECT把数据检索出来； 对于填有数据的游标，根据需要取出各行； 在结束游标使用时，必须关闭(CLOSE)游标。 \r创建游标 DECLARE语句创建游标，并定义相应的SELECT语句，根据需要带WHERE和其它子句。 -- 游标栗子 CREATEPROCEDUREprocedureTest()BEGINDECLAREnumberCursorCURSORFORSELECTnumberFROMtable1;END; \r\r打开和关闭游标 -- 打开游标 -- 在处理OPEN语句时执行查询，存储检索出的数据以供浏览和滚动 OPENnumberCursor;-- 关闭游标 -- CLOSE释放游标使用的所有内部内存和资源，因此在每个游标不再需要时都应该关闭 CLOSEnumberCursor;-- 一个游标关闭后，如果没有重新打开，则不能使用它 如果你不明确关闭游标，MySQL将会在到达END语句是自动关闭它。 -- 此存储过程声明、打开和关闭一个游标，但对检索出的数据什么也没做。 CREATEPROCEDUREprocedureTest()BEGINDECLAREnumberCursorCURSORFORSELECTnumberFROMtable1;-- OPEN OPENnumberCursor;-- CLOSE CLOSEnumberCursor;END; \r\r使用游标数据 游标打开后，可使用FETCH语句分别访问它的每一行。它指定检索什么数据，检索出的数据存储在什么地方。它还向前移动游标的内部行指针，是下一条FETCH语句检索下一行。 CREATEPROCEDUREprocedureTest()BEGINDECLAREoINT;DECLAREnumberCursorCURSORFORSELECTnumberFROMtable1;OPENnumberCursor;FETCHnumberCursorINTOo;CLOSEnumberCursor;END; \r\r\r","date":"2018-01-16","objectID":"/mysql/:76:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"触发器 本章介绍什么是触发器，为什么要使用触发器，如何使用触发器。 \r","date":"2018-01-16","objectID":"/mysql/:77:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"介绍 MySQL语句在需要时被执行，存储过程也是如此。但是，如果你想要某条语句(某些语句)在事件发生时自动执行，怎么办？例如: 检查每次新增的电话号码格式是否正确 检查大小写 每卖出一个产品时，都从库存中减去订购的数量 无论何时删除一行，都在某个存档表中保留一个副本 这些例子的共同之处是它们都需要在某个表发生更改时自动处理。这确切地说就是触发器(trigger)。 触发器是MySQL响应一下任意语句而自动执行的一条MySQL语句(或位于BEGIN和END语句之间的一组语句): DELETE INSERT UPDATE 其它MySQL语句不支持触发器。 只有表才支持触发器。 \r\r","date":"2018-01-16","objectID":"/mysql/:77:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"创建触发器 创建触发器时，需要给出4条信息: 唯一的触发器名； 触发器关联的表； 触发器应该响应的活动(DELETE, INSERT, UPDATE)； 触发器何时执行(BEFORE或AFTER)。 -- HELP CREATE TRIGGER; CREATETRIGGERtriggerTest-- 创建新触发器 AFTERINSERTONtable1-- 触发器将在INSERT 表table1成功执行后执行 FOREACHROW-- 对每个插入行执行 SELECT'table1 added'INTO@triggerInfo;-- 对每个插入显示一次，MySQL v5+ 需要使用变量来实现 #查看SHOWTRIGGERS; \r\r","date":"2018-01-16","objectID":"/mysql/:77:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"删除触发器 触发器不能更新或覆盖。为了修改一个触发器，必须先删除然后重新创建。 DROPTRIGGERtriggerTest; \r\r","date":"2018-01-16","objectID":"/mysql/:77:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用触发器 三种触发器: INSERT UPDATE DELETE \rINSERT触发器 INSERT触发器在INSERT语句执行之前(BEFORE)或之后(AFTER)执行。 在INSERT触发器代码内，可引用一个名为NEW的虚拟表，访问被插入的行； 在BEFORE INSERT触发器中，NEW中的值也可被更新(允许更改被插入的值)； 对于AUTO_INCREMENT列，NEW在INSERT执行之前包含0，在INSERT执行之后包含新的自动生成值。 \r\rUPDATE触发器 UPDATE触发器在UPDATE语句执行之前或之后执行。 在UPDATE触发器代码中，你可引用一个名为OLD的虚拟表访问以前(UPDATE语句前)的值，引用一个名为NEW的虚拟表访问新更新的值； 在BEFORE UPDATE触发器中，NEW中的值也可被更新(允许更改将要用于UPDATE语句的值)； OLD中的值全都是只读的，不能更新。 -- 以下保证name总为大写 CREATETRIGGERupdateTable1BEFOREUPDATEONtable1FOREACHROWSETNEW.name=UPPER(NEW.name)-- 测试 UPDATEtable1SETname='NAme1'WHERid=1;SELECTnameFROMtable1WHEREid=1;+-------+ |name|+-------+ |NAME1|+-------+ \r\rDELETE触发器 DELETE触发器在DELETE语句执行之前或之后执行。 在DELETE触发器代码内，你可引用一个名为OLD的虚拟表，访问被删除的行； OLD中的值全都是只读的，不能更新。 -- 使用OLD保存将要被删除的行到一个备份表 -- 你需要创建一个与table1相同列的table1BAK表 DELIMITER//CREATETRIGGERdeletetable1BEFOREDELETEONtable1FOREACHROWBEGININSERTINTOtable1BAK(id,name,date)VALUES(OLD.id,OLD.name,OLD.date);END//DELIMITER; \r\r小技巧 创建触发器可能需要特殊的安全访问权限，但是，触发器的执行是自动的。如果INSERT, UPDATE, DELETE能够执行，则触发器也能执行； 应该使用触发器来保证数据的一致性(大小写、格式…)； 触发器的一种非常有意义的使用是创建审计跟踪； MySQL触发器中不支持CALL语句，这表示触发器不能调用存储过程。 \r\r\r","date":"2018-01-16","objectID":"/mysql/:77:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"事务处理 本章介绍什么是事务处理，如何利用COMMIT和ROLLBACK语句来管理事务处理。 \r","date":"2018-01-16","objectID":"/mysql/:78:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"介绍 并非所有存储引擎都支持事务处理。 MyISAM不支持明确的事务处理管理 ，而InnoDB支持。 事务处理(transaction processing)，可以用来维护数据库的完整性，它保证成批的MySQL操作要么完全执行，要么完全不执行。 事务处理的几个术语: 事务(transaction)，指一组SQL语句； 回退(rollback)，指撤销指定SQL语句； 提交(commit)，指将未存储的SQL语句结果写入数据库表； 保留点(savepoint)，指事务处理中设置的临时占位符(placeholder)，你可以对它发布回退(与回退整个事务处理不同)。 \r\r","date":"2018-01-16","objectID":"/mysql/:78:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"控制事务处理 管理事务处理的关键在于将SQL语句组分解为逻辑块，并明确规定数据很是应该回退，何时不应该回退。 -- 标识事务的开始 STARTTRANSACTION; \r\r使用ROLLBACK MySQL的ROLLBACK命令用来回退(撤销)MySQL语句。它只能在一个事务处理内使用。 事务处理可用来管理INSERT, UPDATE和DELETE语句。你不能回退CREATE或DROP操作。 SELECT*FROMtalbe1;-- 显示该表不为空 STARTTRANSACTION;-- 开始事务处理 DELETEFROMtable1;-- 删除整个表内容 SELECT*FROMtable1;-- 检索空表 ROLLBACK;-- 回退开始事务之后的所有语句 SELECT*FROMtable1;-- 检索表，所有信息又回来了 隐含地事务关闭。 当COMMIT或ROLLBACK语句执行后，事务会自动关闭。 \r\r使用COMMIT 一般的MySQL语句都是直接针对数据库表执行和编写的。这就是所谓的隐含提交(implicit commit)，即提交操作是自动进行的。 但在事务处理块中，提交不会隐含地进行。为进行明确的提交，使用COMMIT语句。 STARTTRANSACTION;DELETEFROMtable1WHEREid=2010;DELETEFROMtable2WHEREid=2010;COMMIT;-- 仅在不出错时写入更改，如果其中一条语句出错，则DELETE不会提交，即它自动撤销。 \r\r使用SAVEPOINT 简单的ROLLBACK和COMMIT语句就可以写入或撤销整个事务处理。更复杂的事务处理可能需要部分提交或回退。 为了支持回退部分事务处理，必须能在事务处理块中何时的位置放置占位符。这样，如果需要回退，则可回退到某个占位符。 这些占位符称为保留点。 -- 创建占位符 -- 使用唯一名字，以便知道回退到何处 SAVEPOINTdetele1; 保留点越多越好，这样便能进行灵活地回退。 保留点在事务处理完成(COMMIT或ROLLBACK)后自动释放。也可使用RELEASE SAVEPOINT明确地释放保留点。 \r\r更改默认提交行为 默认的MySQL行为是自动提交所有更改。 -- 你可以设置MySQL不自动提交 -- autocommit标志决定是否自动提交更改，不管有没有COMMIT语句 SETautocommit=0; \r\r\r","date":"2018-01-16","objectID":"/mysql/:78:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"字符集和校对 本章介绍MySQL处理不同字符集和语言的基础知识。 \r","date":"2018-01-16","objectID":"/mysql/:79:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"字符集和校对顺序 数据库被用来存储和检索数据。不同的语言和字符集需要以不同的方式存储和检索。因此，MySQL需要适应不同的字符集，适应不同的排序和检索数据的方法。 重要术语: 字符集，为字母和符号的集合； 编码，为某个字符集成员的内部表示； 校对，为规定字符如何比较的指令。 \r\r","date":"2018-01-16","objectID":"/mysql/:79:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"使用字符集和校对顺序 MySQL支持众多的字符集。不同的表、不同的列口可以指定不同的字符集。 -- 查看完整的字符集 SHOWCHARACTERSET;SHOWCHARACTERSETLIK'utf8%';+---------+---------------+--------------------+--------+ |Charset|Description|Defaultcollation|Maxlen|+---------+---------------+--------------------+--------+ |utf8|UTF-8Unicode|utf8_general_ci|3||utf8mb4|UTF-8Unicode|utf8mb4_general_ci|4|+---------+---------------+--------------------+--------+ -- 默认字符集 SHOWVARIABLESLIKE'character%';+--------------------------+----------------------------+ |Variable_name|Value|+--------------------------+----------------------------+ |character_set_client|utf8||character_set_connection|utf8||character_set_database|latin1||character_set_filesystem|binary||character_set_results|utf8||character_set_server|latin1||character_set_system|utf8||character_sets_dir|/usr/share/mysql/charsets/|+--------------------------+----------------------------+ -- 默认校对 SHOWVARIABLESLIKE'collation%';+----------------------+-------------------+ |Variable_name|Value|+----------------------+-------------------+ |collation_connection|utf8_general_ci||collation_database|latin1_swedish_ci||collation_server|latin1_swedish_ci|+----------------------+-------------------+ 为表和列指定字符集: -- 栗子 CREATETABLEtableTest(c1INT,c2VARCHAR(10),C3VARCHAR(20)CHARACTERSETlatin1COLLATElatin1_general_ci)DEFAULTCHARACTERSETutf8mb4COLLATEhebrew_general_ci; \r\r\r","date":"2018-01-16","objectID":"/mysql/:79:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"安全管理 本章将介绍mysql的访问控制和用户管理。 \r","date":"2018-01-16","objectID":"/mysql/:80:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"访问控制 尽量权限最小化。 除非必要，尽量不要使用root进行登录。不该在日常的MySQL操作中使用root用户。 \r\r","date":"2018-01-16","objectID":"/mysql/:80:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"管理用户 注意理解MySQL中用户和账户的概念，账户为用户加权限。 -- mysql.user表包含所用账户信息 SELECTuserFROMmysql.user; \r创建用户 -- 新建用户 CREATEUSERuser1IDENTIFIEDBY'user1-passwd';-- 重命名用户 RENAMEUSERuser1TOUser1; \r\r删除用户 -- 删除用户账号及权限 DROPUSERUser1; \r\r设置权限 新创建的用户没有分配权限，它们能登录MySQL，但不能看到数据。 GRANT至少需要以下信息: 要授予的权限； 被授予访问权限的库或表； 用户名。 GRANT和REVOKE可在几个层次上控制访问权限: 整个Server，使用GRANT ALL和REVOKE ALL; 整个Database，使用ON db.*; 特定的表，使用ON db.tableName; 特定的列; 特定的存储过程。 详细权限: 权限 描述 ALL 除GRANT OPTION外的所有权限 ALTER 修改表 ALTER ROUNTINE 修改和删除存储过程 CREATE 创建表 CREATE ROUTINE 创建存储过程 CREATE TEMPORARY TABLE 创建临时表 CREATE USER 创建、删除、重名用户和解除所有权限 CREATE VIEW 创建视图 DELETE 删除 DROP 删除表 EXECUTE 使用CALL和存储过程 FILE 使用SELECT INTO OUTFILE和LOAD DATA INFILE GRANT OPTION 使用GRANT和REVOKE INDEX 创建和删除索引 INSERT 插入 LOCK TABLES 锁表 PROCESS 使用SHOW FULL PROCESSLIST RELOAD 使用FLUSH REPLICATION CLIENT 服务器位置的访问 REPLICATION SLAVE 由复制从属使用 SELECT 检索权限 SHOW DATABASES 查看数据库 SHOW VIEW 查看视图 SHUTDOWN 关闭MySQL SUPER 使用CHANGE MASTER, KILL, LOGS, PURGE, MASTER, SET GLOBAL的超级权限 UPDATE 更新 USAGE 无访问权限 -- 查看用户权限 SHOWGRANTSFORUser1;+-----------------------------------+ |GrantsforUser1@%|+-----------------------------------+ |GRANTUSAGEON*.*TO'User1'@'%'|+-----------------------------------+ -- 添加权限 -- HELP GRANT; -- 如果未指定主机，默认为% GRANTSELECTONtestDB.*TO'User1'@'localhost';-- 多个权限 GRANTSELECT,INSERTONtestDB.user1TTO'User1'@'localhost';-- 解除权限 -- HELP REVOKE REVOKESELECTONtestDB.*FROM'User1'@'localhost'; \r\r修改密码 -- 修改指定用户密码 SETPASSWORDFORUser1=Password('User-passwd');-- 不指定用户名，则修改自己密码 SETPASSWORD=Password('My-passwd'); \r\r\r","date":"2018-01-16","objectID":"/mysql/:80:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"数据库维护 本章介绍常见的数据库维护。 \r","date":"2018-01-16","objectID":"/mysql/:81:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"备份数据 可能的解决方案: mysqldump实用程序来备份； 可使用MySQL的BACKUP TABLE或SELECT INTO OUTFILE转储所有数据到某个外部文件，此外部文件必须不存在。使用RESTORE TABLE来还原。 为保证所有数据都被写到磁盘，可能需要在备份前刷新(FLUSH TABLES)。 \r\r","date":"2018-01-16","objectID":"/mysql/:81:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"进行数据库维护 应该知道的一些语句: ANALYZE TABLE，用来检查表键是否正确； CHECK TABLE，用来针对许多问题对表进行检查: 如果MyISAM表访问产生不正确和不一致的结果，可能需要用REPAIR TABLE来修复相应的表。这条语句不应该经常使用； 如果bong一个表中删除大量数据，应该使用OPTIMIZE TABLE来回收所用的空间，从而优化表的性能。 ANALYZETABLEmysql.user;+------------+---------+----------+----------+ |Table|Op|Msg_type|Msg_text|+------------+---------+----------+----------+ |mysql.user|analyze|status|OK|+------------+---------+----------+----------+ CHECKTABLEmysql.user;+------------+-------+----------+----------------------------------------------------------+ |Table|Op|Msg_type|Msg_text|+------------+-------+----------+----------------------------------------------------------+ |mysql.user|check|warning|2clientsareusingorhaven't closed the table properly | | mysql.user | check | status | OK | +------------+-------+----------+----------------------------------------------------------+ \r\r","date":"2018-01-16","objectID":"/mysql/:81:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"诊断启动问题 在排除系统启动问题时，首先应该用手动启动Server。使用以下几个重要的mysqld命令行选项: --help --safe-mode，装载减去某些最佳配置的Server； --verbose，显示全文本消息； --version，显示版本信息 \r\r","date":"2018-01-16","objectID":"/mysql/:81:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"查看日志 主要日志有: 错误日志，可用--log-error命令行选项更改； 查询日志，可用--log命令行选项更改； 二进制日志， 可用--log-bin命令行选项更改； 慢查询日志，可用--log-slow-queries命令行选项更改。 在使用日志时，可使用FLUSH LOGS语句来刷新和重新开始所有日志文件。 \r\r\r","date":"2018-01-16","objectID":"/mysql/:81:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"改善性能 本章将学习与MySQL性能有关的某些要点。 \r与性能相关的一些要点: 硬件； MySQL配置 SHOW VARIABLES; SHOW STATUS; 查看所有MySQL活动进程, SHOW PROCESSLIST; 可终止某个特定的进程，KILL $mysql-pid; 使用联结、并、子查询等查询方式，找出最佳的查询方法； 使用EXPLAIN语句让MySQL解释他将如何执行一条SELECT语句； 一般来说，存储过程比一条条地执行MySQL语句快； 应该总使用正确的数据类型； 绝不要检索比需求还有多的数据； 有的操作支持一个可选的DELAYED关键字； 在导入数据时，应该关闭自动提交。你可能还想删除索引，然后在导入完成后再重建索引； 必须索引数据库表以改善数据检索的性能； 索引改善数据检索的性能，但损害数据插入、删除和更新的性能； LIKE很慢，一般来说，最好使用FULLTEXT而不是LIKE； 数据库是不断变化的实体。之前优化好了，之后可能也会面目全非了； 记得查看MySQL官方文档。 \r\r\r","date":"2018-01-16","objectID":"/mysql/:82:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"数据类型 本章介绍MySQL中不同的数据类型。 \r","date":"2018-01-16","objectID":"/mysql/:83:0","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"串 最常用的数据类型是串，有两种基本串类型: 定长串：接受长度固定的字符串，其长度是在创建表时指定的。CHAR属于定长串类型； 变长串：存储可变长度的文本。有些具有最大定长，有些则是完全变长的。不管哪种，只有指定的数据得到保存(额外的数据不保存)，TEXT数据变长串类型。 既然变长数据类型这样灵活，为什么还要使用定长数据类型？ 因为性能。MySQL处理定长列远比处理变长列快的多。此外，MySQL不允许对变长列(或列的可变部分)进行索引。这会极大影响性能。 不管使用何种形式的串数据类型，请使用引号。 数据类型 描述 CHAR 1-255个字符的定长串。它的长度必须在创建时指定，否则MySQL假定为CHAR(1) ENUM 接受最多6K个串组成的一个预定义集合的某个串 LONGTEXT 与TEXT相同，但最大长度为4GB MEDIUMTEXT 与TEXT相同，但最大长度为16K SET 接受最多64个串组成的一个预定义集合的零个或多个串 TEXT 最大长度为64K的变长文本 TINYTEXT 与TEXT相同，但最大长度为255字节 VARCHAR 长度可变，最大不超过255字节。如果指定VARCHAR(n)，则可存储0-n个字符的变长串 你可能会认为电话号码和邮政编码等应该存储在数值字段中，但是，这样做确是不可取的。如果邮政编码为01234，则保存的数值为1234，实际上丢失了一位数字。 需遵守的基本规则是，如果是数值计算，则应该存储在数值类型中；如果作为字符串使用，则应该保存在串数据类型中。 \r\r","date":"2018-01-16","objectID":"/mysql/:83:1","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"数值数据类型 数据数据类型存储数值。 注意有符号和**无符号(UNSIGNED)**也会影响存储范围。 数据类型 描述 BIT 位字段，1-64位 BIGINT 整数值，64位。有符号和无符号范围不同 BOOLEAN 布尔值，0或1 DECIMAL 精度可变的浮点数 DOUBLE 双精度浮点数 FLOAT 单精度浮点数 INT(INTEGER) 整数值，32位。有符号和无符号范围不同 MEDIUMINT 整数值，24位。有符合和无符号范围不同 REAL 4字节的浮点值 SMALLINT 整数值，16位。有符号和无符号范围不同 TINYINT 整数值，8位。有符号和无符号范围不同 数值不使用引号。 MySQL中没有专门存储货币的数据类型，一般情况下使用DECIMA(8, 2)。 \r\r","date":"2018-01-16","objectID":"/mysql/:83:2","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"日期和时间类型 MySQL使用专门的数据类型来存存储日期和时间。 数据类型 描述 DATE 日期格式为YYYY-MM-DD DATETIME DATE和TIME的组合 TIMESTAMP 功能呢DATETIME相同，但范围较小 TIME 时间格式为HH:MM:SS YEAR 2位数字，表示70(1970)-69(2069)，不推荐 4位数字，表示1901-2155年，推荐 \r\r","date":"2018-01-16","objectID":"/mysql/:83:3","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["database"],"content":"二进制数据类型 二进制数据类型可以存储任何数据，如图像、多媒体、字处理文档… 数据类型 描述 BLOB 最大长度位64KB MEDIUMBLOB 最大长度为16MB LONGBLOB 最大长度位4GB TINYBLOB 最大长度位255字节 ","date":"2018-01-16","objectID":"/mysql/:83:4","tags":["MySQL","RDS","Database","DBMS"],"title":"MySQL","uri":"/mysql/"},{"categories":["linux"],"content":"参考： sysctl命令 ulimit命令 ulimit、limits.conf、sysctl和proc文件系统 sysctl.conf学习和调优 sysctl sysctl 命令被用于在内核运行时动态地修改内核的运行参数，可用的内核参数在目录 /proc/sys 中。它包含一些Tcp/Ip堆栈和虚拟内存系统的高级选项，可以通过修改某些值来提高系统性能。 sysctl可以读取和设置超过五百个系统变量。 sysctl变量的设置通常是字符串、数字或布尔型（布尔型用1表示yes，0表示no）。 sysctl - configure kernel parameters at runtime. 语法： #sysctl [options] [variable[=value]] [...] sysctl -w net.ipv4.tcp_syncookies=1 可以通过sysctl命令修改系统变量，也可以通过编辑sysctl.conf配置文件来修改系统变量。 sysctl.conf - sysctl preload/configuration file. 举个栗子： vim /etc/sysct.conf # Controls source route verification # Default should work for all interfaces net.ipv4.conf.default.rp_filter = 1 # net.ipv4.conf.all.rp_filter = 1 # net.ipv4.conf.lo.rp_filter = 1 # net.ipv4.conf.eth0.rp_filter = 1 # Disables IP source routing # Default should work for all interfaces net.ipv4.conf.default.accept_source_route = 0 # net.ipv4.conf.all.accept_source_route = 0 # net.ipv4.conf.lo.accept_source_route = 0 # net.ipv4.conf.eth0.accept_source_route = 0 # Controls the System Request debugging functionality of the kernel kernel.sysrq = 0 # Controls whether core dumps will append the PID to the core filename # Useful for debugging multi-threaded applications kernel.core_uses_pid = 1 # Increase maximum amount of memory allocated to shm # Only uncomment if needed # kernel.shmmax = 67108864 # Disable ICMP Redirect Acceptance # Default should work for all interfaces net.ipv4.conf.default.accept_redirects = 0 # net.ipv4.conf.all.accept_redirects = 0 # net.ipv4.conf.lo.accept_redirects = 0 # net.ipv4.conf.eth0.accept_redirects = 0 # enable Log Spoofed Packets, Source Routed Packets, Redirect Packets # Default should work for all interfaces net.ipv4.conf.default.log_martians = 1 #net.ipv4.conf.all.log_martians = 1 # net.ipv4.conf.lo.log_martians = 1 # net.ipv4.conf.eth0.log_martians = 1 # Decrease the time default value for tcp_fin_timeout connection net.ipv4.tcp_fin_timeout = 25 # Decrease the time default value for tcp_keepalive_time connection net.ipv4.tcp_keepalive_time = 1200 # Turn on the tcp_window_scaling net.ipv4.tcp_window_scaling = 1 # Turn on the tcp_sack net.ipv4.tcp_sack = 1 # tcp_fack should be on because of sack net.ipv4.tcp_fack = 1 # Turn on the tcp_timestamps net.ipv4.tcp_timestamps = 1 # Enable TCP SYN Cookie Protection net.ipv4.tcp_syncookies = 1 # Enable ignoring broadcasts request net.ipv4.icmp_echo_ignore_broadcasts = 1 # Disable ping requests net.ipv4.icmp_echo_ignore_all = 1 # Enable bad error message Protection net.ipv4.icmp_ignore_bogus_error_responses = 1 # make more local ports available # net.ipv4.ip_local_port_range = 1024 65000 # set TCP Re-Ordering value in kernel to 5 net.ipv4.tcp_reordering = 5 # Lower syn retry rates net.ipv4.tcp_synack_retries = 2 net.ipv4.tcp_syn_retries = 3 # Set Max SYN Backlog to 2048 net.ipv4.tcp_max_syn_backlog = 2048 # Various Settings net.core.netdev_max_backlog = 1024 # Increase the maximum number of skb-heads to be cached net.core.hot_list_length = 256 # Increase the tcp-time-wait buckets pool size net.ipv4.tcp_max_tw_buckets = 360000 # This will increase the amount of memory available for socket input/output queues net.core.rmem_default = 65535 net.core.rmem_max = 8388608 net.ipv4.tcp_rmem = 4096 87380 8388608 net.core.wmem_default = 65535 net.core.wmem_max = 8388608 net.ipv4.tcp_wmem = 4096 65535 8388608 net.ipv4.tcp_mem = 8388608 8388608 8388608 net.core.optmem_max = 40960 重新加载内核参数： #-p, read values from file sysctl -p #-a, display all variables sysctl -a \rulimit 大多Unix-Like系统，都提供了限制每个进程和每个基本用户使用线程，文件和网络连接等系统资源的一些方法。 假设有这样一种情况，当一台Linux主机上同时登陆了10人，在资源无限制的情况下，这10个用户同时打开了500个文件。假设每个文件的大小有10M，这是系统的内存资源就会收到巨大挑战。 但是任何一台主机的资源都不可能是无限的。所以，资源的合理配置和分配，不仅仅是保证系统可用性的必要条件，也与系统上软件运行的性能有着密不可分的联系。 ulimit是指每个user使用各种资源的限制值。ulimit 命令用来限制系统用户对shell资源的访问，它是一种简单并且有效的实现资源限制的方式。 ulimit的设置值是 per-process的，也就是说，每个进程都有自己的limits值； 使用ulimit进行修改，是立即生效的； ulimit只影响shell进程及其子进程，用户登出后失效； 修改ulimit设置之后，要重启程序修改值才会有效。可通过/proc文件系统查看运行进程当前的限制值; 使用ulimit对系统限制的改变在系统重启后都会恢复到默认值; 可以在profile中加入ulimit的设置，便能做到永久生效。 u","date":"2018-01-09","objectID":"/sysctl-ulimit-proc/:0:0","tags":["linux","kernel","ulimit","proc"],"title":"sysctl和ulimit和proc","uri":"/sysctl-ulimit-proc/"},{"categories":["linux"],"content":"设置ulimit 可以在以下位置进行ulimit的设置： /etc/profile，所有用户有效，永久生效； ~/.bash_profile,当前用户有效，永久生效； 直接在控制台修改，当前用户有效，临时生效； \r永久生效： vim /etc/profile vim ~/.bash_profile 临时生效： ulimit -a core file size (blocks, -c) 0 data seg size (kbytes, -d) unlimited scheduling priority (-e) 0 file size (blocks, -f) unlimited pending signals (-i) 7170 max locked memory (kbytes, -l) 64 max memory size (kbytes, -m) unlimited open files (-n) 1024 pipe size (512 bytes, -p) 8 POSIX message queues (bytes, -q) 819200 real-time priority (-r) 0 stack size (kbytes, -s) 8192 cpu time (seconds, -t) unlimited max user processes (-u) 7170 virtual memory (kbytes, -v) unlimited file locks (-x) unlimited #修改限定值 ulimit -n 201400 ulimit -t ulimited \rlimits.conf limits.conf - configuration file for the pam_limits module limits.conf是pam_limits.so的配置文件，Linux PAM(Pluggable Authentication Modules，插入式认证模块)。突破系统默认限制，对系统资源有一定保护作用。 pam_limits模块对用户的会话进行资源限制，然后/etc/pam.d/下的应用程序调用pam_***.so模块。 limits.conf是针对用户，而sysctl.conf是针对整个系统参数配置。 一个shell的初始limits就是由pam_limits设定的，用户登录后，pam_limits会给用户的shell设定在limits.conf定义的值； pam_limits的设定值也是per-process； pam_limits的设置是 永久生效的。 配置limits.conf： vim /etc/security/limits.conf 举个栗子： #\u003cdomain\u003e \u003ctype\u003e \u003citem\u003e \u003cvalue\u003e #* soft core 0 #* hard rss 10000 #@student hard nproc 20 #@faculty soft nproc 20 #@faculty hard nproc 50 #ftp hard nproc 0 #@student - maxlogins 4 domain： username @groupname type： soft hard - item： core，限制内核文件的大小 date，最大数据大小 fsize，最大文件大小 memlock，最大锁定内存地址空间 nofile，打开文件的最大数目 rss，最大持久设置大小 stack，最大栈大小 cpu，以分钟为单位的最多CPU时间 nproc，进程的最大数目 as，地址空间限制 maxlogins，此用户允许登录的最大数目 value： item值的大小 \r# /proc\r","date":"2018-01-09","objectID":"/sysctl-ulimit-proc/:1:0","tags":["linux","kernel","ulimit","proc"],"title":"sysctl和ulimit和proc","uri":"/sysctl-ulimit-proc/"},{"categories":["linux"],"content":"什么是/proc文件系统 Linux内核提供了一种通过/proc文件系统，在运行时访问内核内部数据结构，改变内核设置的机制。 proc文件系统是一个伪文件系统，它只存在内存当中，不占用外部空间。它以文件系统的方式为访问系统内核数据的操作提供接口。 对/proc中内核文件的修改，针对的是整个系统的内核参数，修改后立即生效，但修改是 临时的，重启后失效。 ","date":"2018-01-09","objectID":"/sysctl-ulimit-proc/:2:0","tags":["linux","kernel","ulimit","proc"],"title":"sysctl和ulimit和proc","uri":"/sysctl-ulimit-proc/"},{"categories":["linux"],"content":"/proc与sysctl.conf的对应关系 修改/proc文件系统中的参数是临时的，但修改sysctl.conf的参数确是永久有效的。 配置文件sysctl.conf变量在/proc/sys下，其对应关系如下： #将文件名的 . 变为 / #/proc/sys/net/ipv4/icmp_echo_ignore_all #net.ipv4.icmp_echo_ignore_all echo 0 \u003e /proc/sys/net/ipv4/icmp_echo_ignore_all vim /etc/sysctl.conf net.ipv4.icmp_echo_ignore_all = 0 ","date":"2018-01-09","objectID":"/sysctl-ulimit-proc/:3:0","tags":["linux","kernel","ulimit","proc"],"title":"sysctl和ulimit和proc","uri":"/sysctl-ulimit-proc/"},{"categories":["linux"],"content":"/proc文件系统几个常用的内核文件 /proc/meminfo #内存信息 /proc/cpuinfo #CPU信息 /proc/sys/fs/file-max #文件打开数 /proc/sys/fs/file-nr #整个系统目前使用的文件句柄数量 ","date":"2018-01-09","objectID":"/sysctl-ulimit-proc/:4:0","tags":["linux","kernel","ulimit","proc"],"title":"sysctl和ulimit和proc","uri":"/sysctl-ulimit-proc/"},{"categories":["linux"],"content":"/proc文件系统中文件的权限 proc中的每个文件都有一组分配给它的非常特殊的文件许可权，并且每个文件属于特定的用户标识。 只读：任何用户都不能更改该文件，它用于表示系统信息 root写 root读 ","date":"2018-01-09","objectID":"/sysctl-ulimit-proc/:5:0","tags":["linux","kernel","ulimit","proc"],"title":"sysctl和ulimit和proc","uri":"/sysctl-ulimit-proc/"},{"categories":["linux"],"content":"对/proc进行读写 cat /proc/sys/net/ipv4/icmp_echo_ignore_all #0 echo 1 \u003e /proc/sys/net/ipv4/icmp_echo_ignore_all #当然,也可是用sysctl来配置 ","date":"2018-01-09","objectID":"/sysctl-ulimit-proc/:6:0","tags":["linux","kernel","ulimit","proc"],"title":"sysctl和ulimit和proc","uri":"/sysctl-ulimit-proc/"},{"categories":["linux"],"content":"/proc内核文件详解 /proc/buddyinfo 每个内存区中的每个order有多少块可用，和内存碎片问题有关 /proc/cmdline 启动时传递给kernel的参数信息 /proc/cpuinfo cpu的信息 /proc/crypto 内核使用的所有已安装的加密密码及细节 /proc/devices 已经加载的设备并分类 /proc/dma 已注册使用的ISA DMA频道列表 /proc/execdomains Linux内核当前支持的execution domains /proc/fb 帧缓冲设备列表，包括数量和控制它的驱动 /proc/filesystems 内核当前支持的文件系统类型 /proc/interrupts x86架构中的每个IRQ中断数 /proc/iomem 每个物理设备当前在系统内存中的映射 /proc/ioports 一个设备的输入输出所使用的注册端口范围 /proc/kcore 代表系统的物理内存，存储为核心文件格式，里边显示的是字节数，等于RAM大小加上4kb /proc/kmsg 记录内核生成的信息，可以通过/sbin/klogd或/bin/dmesg来处理 /proc/loadavg 根据过去一段时间内CPU和IO的状态得出的负载状态，与uptime命令有关 /proc/locks 内核锁住的文件列表 /proc/mdstat 多硬盘，RAID配置信息(md=multiple disks) /proc/meminfo RAM使用的相关信息 /proc/misc 其他的主要设备(设备号为10)上注册的驱动 /proc/modules 所有加载到内核的模块列表 /proc/mounts 系统中使用的所有挂载 /proc/mtrr 系统使用的Memory Type Range Registers (MTRRs) /proc/partitions 分区中的块分配信息 /proc/pci 系统中的PCI设备列表 /proc/slabinfo 系统中所有活动的 slab 缓存信息 /proc/stat 所有的CPU活动信息 /proc/sysrq-trigger 使用echo命令来写这个文件的时候，远程root用户可以执行大多数的系统请求关键命令，就好- 像在本地终端执行一样。要写入这个文件，需要把/proc/sys/kernel/sysrq不能设置为0。这个文件对root也是不可- 读的 /proc/uptime 系统已经运行了多久 /proc/swaps 交换空间的使用情况 /proc/version Linux内核版本和gcc版本 /proc/bus 系统总线(Bus)信息，例如pci/usb等 /proc/driver 驱动信息 /proc/fs 文件系统信息 /proc/ide ide设备信息 /proc/irq 中断请求设备信息 /proc/net 网卡设备信息 /proc/scsi scsi设备信息 /proc/tty tty设备信息 /proc/net/dev 显示网络适配器及统计信息 /proc/vmstat 虚拟内存统计信息 /proc/vmcore 内核panic时的内存映像 /proc/diskstats 取得磁盘信息 /proc/schedstat kernel调度器的统计信息 /proc/zoneinfo 显示内存空间的统计信息，对分析虚拟内存行为很有用 以下是/proc目录中进程N的信息： /proc/N pid为N的进程信息 /proc/N/cmdline 进程启动命令 /proc/N/cwd 链接到进程当前工作目录 /proc/N/environ 进程环境变量列表 /proc/N/exe 链接到进程的执行命令文件 /proc/N/fd 包含进程相关的所有的文件描述符 /proc/N/maps 与进程相关的内存映射信息 /proc/N/mem 指代进程持有的内存，不可读 /proc/N/root 链接到进程的根目录 /proc/N/stat 进程的状态 /proc/N/statm 进程使用的内存的状态 /proc/N/status 进程状态信息，比stat/statm更具可读性 /proc/self 链接到当前正在运行的进程 ","date":"2018-01-09","objectID":"/sysctl-ulimit-proc/:7:0","tags":["linux","kernel","ulimit","proc"],"title":"sysctl和ulimit和proc","uri":"/sysctl-ulimit-proc/"},{"categories":["linux"],"content":"当你为你的产品签发许可，你就是在出让自己的权利。不过，你仍拥有版权和专利（如果申请了专利）。许可的目的，是向使用你产品的人提供一定的权利。 不管产品是免费分发，还是出售，指定一份许可协议都非常有用。否则，对于免费，你相当于放弃了自己的所有权利，任何人都没有义务表明你的原始作者身份。对于出售，你将不得不花费比开发更多的精力用来处理授权问题。 而开源许可协议是这些事情变得简单，开发者很容易向一个项目贡献自己的代码，它还可以保护你原始作者的身份，使你至少获得认可。开源许可协议还可以阻止其它人将某个产品据为己有。 \r几大开源许可协议 \r","date":"2018-01-09","objectID":"/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/:0:0","tags":["license"],"title":"开源许可协议","uri":"/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/"},{"categories":["linux"],"content":"GNU Project GNU是“GNU’s Not Unix”的递归缩写，发音为 /‘gnu:'/； GNU Project，是一个由自由软件集体协作项目，它的目标是创建一套完全自由的操作系统，称为GNU； GNU是一个自由操作系统，其内容软件完全以 GPL 方式发布，它的设计类似于Unix，但它不包含具有著作权的Unix代码。 ","date":"2018-01-09","objectID":"/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/:1:0","tags":["license"],"title":"开源许可协议","uri":"/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/"},{"categories":["linux"],"content":"GPL GNU(General Public Licence)，GNU通用许可协议(简称GPL)是广泛使用的免费软件许可证，也称为 copyleft，与copyright相对应。 GPL保证了所有开发者的权利，同时为使用者提供了足够的复制、分发、修改的权利。 需要注意的是，分发的时候，需要明确提供源代码和二进制文件。 可自由复制： 你可以将软件复制到你的电脑或任何地方，复制份数没有限制； 可自由分发： 可下载后拷贝分发； 可以用来盈利： 你可以在分发软件的时候收费，但必须在收费前向你的客户提供该软件的 GNU GPL许可协议，以便让他们知道，他们可以从别的渠道免费得到这份软件以及你收费的理由； 可自由修改： 你过你想添加或删除某个功能，没问题。如果你想在别的项目中使用部分代码，也没问题，唯一要求是使用了这段代码的项目也必须使用 GPL协议。 ","date":"2018-01-09","objectID":"/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/:1:1","tags":["license"],"title":"开源许可协议","uri":"/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/"},{"categories":["linux"],"content":"LGPL GNU还有另外一种协议，叫做LGPL（Lesser General Public License），它对产品所保留的权利比GPL少。 总的来说，LGPL适合那些用于非GPL或非开源产品的开源类库或框架。因为GPL要求，使用了GPL代码的产品也必须使用GPL协议，开发者不允许将GPL代码用于商业产品。LGPL绕过了这一限制。 GPL和LGPL都属于GNU计划里面的许可证。 \r ","date":"2018-01-09","objectID":"/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/:1:2","tags":["license"],"title":"开源许可协议","uri":"/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/"},{"categories":["linux"],"content":"BSD 伯克利软件套件（Berkeley Software Distribution，缩写BSD），也被称为伯克利Unix，是一个操作系统的名称，衍生自Unix，也被用来代表一整套软件发行版。 BSD许可证（Berkeley Software Distribution License），是自由软件中使用广泛的许可证。BSD软件就是遵照这个许可证来发布，该许可证也因此而得名。 BSD在软件分发方面的限制比别的开源协议要少，且和GPL兼容，并为开源组织所认可。 \r ","date":"2018-01-09","objectID":"/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/:2:0","tags":["license"],"title":"开源许可协议","uri":"/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/"},{"categories":["linux"],"content":"MIT MIT（Massachusetts Institute of Technology），麻省理工学院。 MIT许可协议（The MIT License）是许多软件授权条款中，被广泛使用的其中一种。与其他常见的软件许可协议相比，MIT是相对宽松的软件许可协议，除了必须包含许可声明外，再无任何限制。 MIT许可协议核心条款： 该软件及其相关文档对所有人免费，可以任意处置，包括使用、复制、修改、合并、发表、分发、再授权或销售； 唯一的限制，软件中必须包含上述版权和许可证。 \r ","date":"2018-01-09","objectID":"/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/:3:0","tags":["license"],"title":"开源许可协议","uri":"/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/"},{"categories":["linux"],"content":"Apache Apache许可证（Apache License），是一个由Apache软件基金会发布的自由软件许可证。Apache许可证要求被授权者保留版权和放弃权利的声明，但它不是一个反版权的许可证。兼容与GPL。 除了为用户提供版权许可之外，还有专利许可，对于那些涉及专利内容的开发者而言，该协议最适合。 永久权利：一旦被授权，永久拥有； 全球范围的权利：在一个国家获得授权，适用于所有国家； 授权免费，且无版税：前后期均无任何费用； 授权不可撤销：一旦获得授权，没有任何人可以取消。 分发代码方面，要在声明中对参与开发的人给予认可并包含一份许可协议原文。 \r ","date":"2018-01-09","objectID":"/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/:4:0","tags":["license"],"title":"开源许可协议","uri":"/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/"},{"categories":["linux"],"content":"MPL MPL是The Mozilla[mɔzilə] Public License的简写，是1998年初Netscape的 Mozilla小组为其开源软件项目设计的软件许可证。 MPL许可证出现的最重要原因就是，Netscape公司认为GPL许可证没有很好地平衡开发者对源代码的需求和他们利用源代码获得的利益。 同著名的GPL许可证和BSD许可证相比，MPL在许多权利与义务的约定方面与它们相同（因为都是符合OSIA 认定的开源软件许可证）。 MPL几个特点： MPL虽然要求对于经MPL许可证发布的源代码的修改也要以MPL许可证的方式再许可出来，以保证其他人可以在MPL的条款下共享源代码。但是，在MPL 许可证中对“发布”的定义是“以源代码方式发布的文件”，这就意味着MPL允许一个企业在自己已有的源代码库上加一个接口，除了接口程序的源代码以MPL 许可证的形式对外许可外，源代码库中的源代码就可以不用MPL许可证的方式强制对外许可。这些，就为借鉴别人的源代码用做自己商业软件开发的行为留了一个豁口； MPL许可证第三条第7款中允许被许可人将经过MPL许可证获得的源代码同自己其他类型的代码混合得到自己的软件程序； 对软件专利的态度，MPL许可证不像GPL许可证那样明确表示反对软件专利，但是却明确要求源代码的提供者不能提供已经受专利保护的源代码（除非他本人是专利权人，并书面向公众免费许可这些源代码），也不能在将这些源代码以开放源代码许可证形式许可后再去申请与这些源代码有关的专利； 对源代码的定义，MPL许可证第3条有专门的一款是关于对源代码修改进行描述的规定，就是要求所有再发布者都得有一个专门的文件就对源代码程序修改的时间和修改的方式有描述。 \r ","date":"2018-01-09","objectID":"/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/:5:0","tags":["license"],"title":"开源许可协议","uri":"/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/"},{"categories":["linux"],"content":"CC 知识共享许可协议(Creative Commons License，简称CC)，并非严格意义上的开源许可，是一种公共版权许可协议。它主要用于设计，其允许分发受版权保护的作品。 CC协议主要包含4种基本形式： 署名权：必须为原始作业署名，然后才可以修改、分发、复制； 保持一致：作品同样可以在CC协议的基础上修改、分发、复制； 非商业：不能用于商业用途； 不能衍生新作品：你可以复制、分发、但不能修改，也不能以此为基础创作自己的作品。 ","date":"2018-01-09","objectID":"/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/:6:0","tags":["license"],"title":"开源许可协议","uri":"/%E5%BC%80%E6%BA%90%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE/"},{"categories":["linux"],"content":"参考： CentOS 7下配置本地yum源及yum客户端 Centos7 配置本地源+阿里yum源/epel-yum+修改优先级 调整CentOS 7中yum仓库的优先级 国内开源站点 \r国内开源镜像站点 网易开源镜像站：http://mirrors.163.com/ 阿里云开源镜像站：http://mirrors.aliyun.com 清华大学开源镜像站：https://mirrors.tuna.tsinghua.edu.cn/ 浙江大学开源镜像站： http://mirrors.zju.edu.cn/ 中国科技大学开源镜像站：http://mirrors.ustc.edu.cn/ \r CentOS自带源 rpm包管理方式，对于安装、升级、卸载却难以处理包之间的依赖关系。而yum作为一个rpm包前端管理工具，可以自动处理依赖性，并支持在线现在、安装、升级、卸载rpm软件包。 CentOS默认自带CentOS-Base.repo源，但官方源在国外，连接速度令人心痛。并且有很多软件在默认源里面是找不到的。 ","date":"2018-01-09","objectID":"/yum/:0:0","tags":["yum"],"title":"Yum源","uri":"/yum/"},{"categories":["linux"],"content":"配置网络yun源 配置aliyun.repo： #先备份默认源 mv CentOS-Base.repo{,.bak} #下载阿里云源替换默认源 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo yum clean all yum makecache #重构yum缓存 yum repolist #查看yum仓库 \r","date":"2018-01-09","objectID":"/yum/:1:0","tags":["yum"],"title":"Yum源","uri":"/yum/"},{"categories":["linux"],"content":"配置本地yum源 配置本地yum源，考虑到优先使用本地安装包，所以会涉及到一个优先级的概念。 安装完毕后，就可以在yum源中添加一个优先级priority。 安装yum优先级插件： yum install -y yum-plugin-priorities #检查安装完成后配置 vim /etc/yum/pluginconf.d/priorities.conf enable=1 #enable=0 创建本地yum源： mv /etc/yum.repos.d/CentOS-Base.repo{,.bak} vim /etc/yum.repos.d/CentOS-Local.repo [base-Local] name=Centos- Local baseurl=file:///mnt/xxx gpgcheck=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 priority=1 #优先级为1 [updates-Local] name=CentOS- Local gpgcheck=0 baseurl=file:///dir/path/ gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 priority=1 ······ #具体可参考CentOS-Base.repo #可将aliyun源优先级写成2 yum clean all yum makecache ","date":"2018-01-09","objectID":"/yum/:2:0","tags":["yum"],"title":"Yum源","uri":"/yum/"},{"categories":["linux"],"content":"配置ftp方式源 vim /etc/yum.repos.d/ftp.repo [ftp-media] name=name=CentOS-$releasever - media baseurl=ftp://ip gpgcheck=0 enable=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 yum clean all yum makecache \r其他常见YUM源 官方的默认yum源提供的软件包往往是很滞后的，(可能为了服务器版本的稳定性和安全性)。并且官方默认源提供的RPM包也不够丰富。 ","date":"2018-01-09","objectID":"/yum/:3:0","tags":["yum"],"title":"Yum源","uri":"/yum/"},{"categories":["linux"],"content":"EPEL源 EPEL的全称叫 Extra Packages for Enterprise Linux 。EPEL是由 Fedora 社区打造，为 RHEL 及衍生发行版如 CentOS、Scientific Linux 等提供高质量软件包的项目。装上了 EPEL之后，就相当于添加了一个第三方源。 EPEL源为服务器提供了大量的rpm包(这些包可能有很多在默认源中没有)，并且绝大多数rpm包比官方默认源版本要新。 添加epel源： epel下载地址：http://download.fedora.redhat.com/pub/epel/ rpm -vih http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-9.noarch.rpm #yum install -y epel-release ","date":"2018-01-09","objectID":"/yum/:4:0","tags":["yum"],"title":"Yum源","uri":"/yum/"},{"categories":["linux"],"content":"remi源 Remi源大家或许很少听说，不过Remi源GoFace强烈推荐，尤其对于不想编译最新版的linux使用者，因为Remi源中的软件几乎都是最新稳定版。 或许您会怀疑稳定不？ 放心，这些都是Linux骨灰级的玩家编译好放进源里的，他们对于系统环境和软件编译参数的熟悉程度毋庸置疑。 添加remi源： Remi下载地址：http://rpms.famillecollet.com rpm -ivh http://rpms.famillecollet.com/enterprise/remi-release-7.rpm #yum install -y http://rpms.famillecollet.com/enterprise/remi-release-7.rpm ","date":"2018-01-09","objectID":"/yum/:5:0","tags":["yum"],"title":"Yum源","uri":"/yum/"},{"categories":["linux"],"content":"RPMForge源 RPMForge是CentOS系统下的软件仓库，拥有4000多种的软件包, 被CentOS社区认为是最安全也是最稳定的一个软件仓库。 添加RPMForge源： RPMForge下载地址：http://repository.it4i.cz/mirrors/repoforge/redhat/el7/en/x86_64/rpmforge/RPMS/ GitHub:https://github.com/repoforge rpm -ivh http://repository.it4i.cz/mirrors/repoforge/redhat/el7/en/x86_64/rpmforge/RPMS/rpmforge-release-0.5.3-1.el7.rf.x86_64.rpm #yum localinstall --nogpgcheckhttp://repository.it4i.cz/mirrors/repoforge/redhat/el7/en/x86_64/rpmforge/RPMS/rpmforge-release-0.5.3-1.el7.rf.x86_64.rpm ","date":"2018-01-09","objectID":"/yum/:6:0","tags":["yum"],"title":"Yum源","uri":"/yum/"},{"categories":["db"],"content":"数据结构 在计算机科学中，**数据结构(data structure)**是计算机中存储、组织数据的方式。 大多数数据结构都有数列、记录、可辨识联合、引用等基本类型构成。 数据结构意味着结构和封装，一个数据结构可被视为两个函数之间的接口，或是由数据类型联合组成的存储内容的访问方法和封装。 数据结构可通过程序语言所提供的数据类型、引用及其它操作加以实现。不同种类的数据结构适合不同种类的应用，部分数据结构甚至是为了解决特定问题而设计。 一个涉及良好的数据结构，应该尽可能使用较少的时间与空间资源的前提下，支持各种程序运行。 正确选择数据结构可以提高算法的效率，在计算机程序设计里，选择适当的数据结构是一项重要工作。 \r ","date":"2017-12-11","objectID":"/datastructrue/:0:0","tags":["db","data"],"title":"数据结构","uri":"/datastructrue/"},{"categories":["db"],"content":"常见数据结构 数组(Array); 栈(Stack): 后进先出，线性表； 队列(Queue): 先进先出，线性表； 链表(Linked List): 每个节点包括两部分，一个存储数据元素的数据域，另一个存储下一个节点地址的指针域； 树(Tree)； 图(Graph)； 堆(Heap): 一种动态树形结构； 散列表(Hash)； ","date":"2017-12-11","objectID":"/datastructrue/:1:0","tags":["db","data"],"title":"数据结构","uri":"/datastructrue/"},{"categories":["db"],"content":"数组(Array) 数组数据结构，是由相同类型的元素的集合所组成，分配一块连续的内存来存储。利用数组元素的索引(index)可计算出元素对应存储地址。 数组有 一维数组、二维数组、多维数组、可变长数组…。 \r ","date":"2017-12-11","objectID":"/datastructrue/:1:1","tags":["db","data"],"title":"数据结构","uri":"/datastructrue/"},{"categories":["db"],"content":"栈(Stack) 堆栈又称为栈，是计算机科学中一种特殊的串列形式的抽象资料类别。 其特殊之处在于只能允许在链接串列或阵列的一端(栈顶指标:top)，进行加入数据(push)和取出数据(pop)。 由于栈数据结构只允许在一端进行操作，因为按照后进先出(LIFO, last-in-first-out)的原理运行。 ","date":"2017-12-11","objectID":"/datastructrue/:1:2","tags":["db","data"],"title":"数据结构","uri":"/datastructrue/"},{"categories":["db"],"content":"队列(Queue) 队列，是先进先出(FIFO, first-in-first-out)的线性表。在具体应用中通常用链表或数组来实现。 队列只允许在后端(Rear)进行插入操作，在前端(Front)进行删除操作。 \r ","date":"2017-12-11","objectID":"/datastructrue/:1:3","tags":["db","data"],"title":"数据结构","uri":"/datastructrue/"},{"categories":["db"],"content":"链表(Linked List) 链表是一种线性表，但并不按线性的顺序存储数据，而是在每一个节点里存到下一个节点的指针(Pointer)。 由于不必须按顺序存储，链表再插入的时候可以达到 O(1)的时间复杂度，比另一种线性表顺序表快得多。但查找一个节点或访问特定节点则需要 O(n)的时间，而顺序表相应的时间复杂度分别是 O(logn)和O(1)。 是用链表结构可以克服数组链表需要预先知道数据大小的缺点，链表可以充分利用计算机内存空间，实现灵活的内存动态管理。但是链表失去了数组随机读取的优点，同时链表由于增加了节点的指针域，空间开销比较大。 链表有单向链表、双向链表、循环链表…。 链表用来构建许多其它数据结构，如栈，队列和他们的派生。 ","date":"2017-12-11","objectID":"/datastructrue/:1:4","tags":["db","data"],"title":"数据结构","uri":"/datastructrue/"},{"categories":["db"],"content":"树(Tree) 树是一种抽象数据类型，用来模拟具有树状结构性质的数据集合。 树有有序树、无序树（二叉树，B树，霍夫曼树）。 \r ","date":"2017-12-11","objectID":"/datastructrue/:1:5","tags":["db","data"],"title":"数据结构","uri":"/datastructrue/"},{"categories":["db"],"content":"图(Graph) 在数学上，一个图是表示物体与物体之间的关系的方法，是图论的基本研究对象。 图有：有向图、无向图、简单图、多重图。 ","date":"2017-12-11","objectID":"/datastructrue/:1:6","tags":["db","data"],"title":"数据结构","uri":"/datastructrue/"},{"categories":["db"],"content":"堆(Heap) 堆是计算机科学中一类特殊的数据结构的统称。 堆通常是一个可以被看做一棵树的数组对象。在队列中，调度程序反复提取队列中的第一个作业并运行，因为实际情况中某些时间较短的任务将等待很长时间才能结束，或者某些不短小，但具有重要性的作业，同样应当具有优先权。堆即为解决此类问题设计的一种数据结构。 堆常用于排序，这种算法称作堆排序。 \r ","date":"2017-12-11","objectID":"/datastructrue/:1:7","tags":["db","data"],"title":"数据结构","uri":"/datastructrue/"},{"categories":["db"],"content":"散列表(Hash) 散列表也叫哈希表，是根据**键(key)**而直接访问在内存存储位置的数据结构。 它通过计算一个关于键值的函数，将所需查询的数据映射到表中的一个位置来访问记录，这加快了查找速度。这种映射函数称为散列函数，存放记录的数组称为散列表。 ","date":"2017-12-11","objectID":"/datastructrue/:1:8","tags":["db","data"],"title":"数据结构","uri":"/datastructrue/"},{"categories":["database"],"content":"参考： MongoDB官方文档 MongoDB中文文档 https://zh.wikipedia.org/wiki/MongoDB http://www.ywnds.com/?p=5635 https://www.centos.bz/2017/08/mongodb-secure-intro-user-auth/ http://www.03sec.com/3176.shtml http://www.ywnds.com/?p=6502 http://wiki.jikexueyuan.com/project/the-little-mongodb-book/ 环境： CentOS7_x64； MongoDB3.4； \r \rNoSQL NoSQL(Not Only SQL)是对不同于传统的关系型数据库的**数据库管理系统(DBMS)**的统称。 NoSQL不使用SQL作为查询语言，其数据结构可以不需要固定的表格模式，有横向可扩展性的特征。 NoSQL用于超大规模数据的存储，这些类型的数据存储不需要固定的模式，无序多余操作就可以横向扩展。 关系型数据库的典型实现主要被调整用于执行规模小而读写频繁，或大批量极少写访问的事务。 当代典型的关系型数据库在一些数据敏感的应用中表现了糟糕的性能。例如： 为巨量文档创建索引 高流量网站的网页服务 发送流媒体 NoSQL数据库分类： 类型 | 栗子 | 特点 | - | - 文档存储 | MongoDB | 用类似json的格式存储，存储的内容是文档型的。这样就有机会对某些字段建立索引，实现关系数据库的某些功能 图形关系存储 | Neo4j | 图形关系的最佳存储 键-值(key-value)存储 | 最终一致性的键-值存储 架构性键-值存储 | xxx 主机式服务 | key-value硬盘存储 key-value RAM存储 | MemcacheDB Redis 多数据库 | OpenQM | xxx 时序型数据库 | Graphite | xxx 对象数据库 | ObjecStore | 通过类似面向对象语言的语法操作数据库，通过对象的方式存取数据 列存储 | HBase | 顾名思义，按列存储数据。方便存储结构化和半结构化数据，方便做数据压缩，针对某一列或某几列的查询有很大的IO优势。 \r \rMongoDB简介 \rMongoDB(https://www.mongodb.com/)，是一种文档导向的数据库管理系统，由C++撰写而成，以此来解决应用程序开发社区中的大量现实问题。它是一种NoSQL。 MongoDB支持的数据结构非常松散，是类似于json的bson格式，因此可以存储比较复杂的数据类型。 MongoDB是一个开源文档数据库，提供高性能，高可用性和自动扩展。 预备知识： MongoDB中的database有和数据库一样的概念。一个MongoDB实例中，可以有零个或多个数据库，每个都作为一个高等容器，用于存储数据； MongoDB数据库中有零个或多个collections(集合)。集合类似于传统意义上的table(表)； MongoDB的集合是由零个或多个documents(文档)组成。文档类似于row(行)； MongoDB的文档由零个或多个fields(字段)组成。字段类似于columns(列)； MongoDB中Indexes(索引)扮演的角色与RDMS中一样； MongoDB中的Cursors(游标)很重要，当你向MongoDB取数据的时候，它会给你返回一个结果集的指针而不是真正的数据，这个指针我们叫它游标。我们可以用游标做任何事情，比如计数或跨行之类。 ## MongoDB特点\r不如这样认为，MongoDB是关系型数据库的一个代替案。比如用Lucene作为关系型数据库的全文检索索引的加强，或者是Redis作为持久性key-value存储。 无模式(Flexible Schema)： 它不需要一个固定的模式，这使得他们比传统的数据库表要灵活更多。 **写操作(Writes)**：\rMongoDB可以胜任的一个特殊角色是在日志领域。有两点使得MongoDB的写操作非常快：\r1. 可以选择发送了写操作之后立刻返回，而无需等到操作完成；\r2. 可以控制数据持久性的写行为。\r\r**高性能(High Performance)**：\rMongoDB提供了高性能的数据持久性。尤其是：\r- 对嵌入式数据模型的支持减少了数据库系统上的I/O活动；\r- 索引支持更快的查询，并且可以包含来自嵌入式文档和数组的键。\r**高可用(High Availability)**：\rMongoDB的复制工具，称为副本集。提供：自动故障转移和数据冗余。\r\r**持久性(Durability)**：\r在MongoDB中，日志(Journaling)是默认启动的，该功能允许快速恢复服务器，比如遭遇到了服务器奔溃或停电的问题。\r**丰富的查询语言(Rich Query Language)**：\rMongoDB支持丰富的查询语言来支持读写操作(CRUD)，数据聚合(Data Aggregation)，全文搜索(Text Search)。\r\r**水平可伸缩性(Horizontal Scalability)**：\rMongoDB提供了横向可伸缩性。\r**支持多个存储引擎(Support for Multiple Storage Engines)**：\r在MongoDB3.2以后默认引擎为: WiredTiger Storage Engine，允许第三方为MongoDB开发存储引擎。\r## database和collection\rMongoDB stores BSON documents. ### databases\rIn MongoDB,databases hold collections of documents. 如果一个数据库不存在，当你第一次存储数据时，MongoDB会自动创建数据库。这意味着可以切换到不存在的数据库。 默认情况下，集合不要求其文档具有相同的模式；文档不要求具有相同的字段集；字段的数据类型在集合的文档间可以有所不同。 #select a db use \u003cdb\u003e #create a db use newdb db.newcoll.insert({name:'zhang'}) db.newcoll.insert({filed01:'filed01', filed02:'filed02', filed03:'filed03', filed04:'filed04'}) db.newcoll.insert({groups: ['A', 'B', 'C']}) db.newcoll.find().pretty() \r### collection\rMongoDB stores documents in collections. collection类似于关系型数据库中的table。 db.coll02.insert({x:1}) db.coll03.createIndex({y:1}) ### 显式创建(explicit creation)\rMongoDB提供了db.createCollection()方法来显式创建一个附带各种选项的集合。如设置document最大大小，文件验证规则等选项。 如果不需要指定这些选项，就不需要使用显式创建集合，而直接向集合中插入数据即可。 修改collection选项，使用collMod方法。 \r### 视图(View)\r视图的定义是公开的，视图的解释操作将包括定义视图的管道。因此，避免直接引用视图定义中的敏感字段和值。 创建/删除视图： db.runCommand( { crete: \u003cview\u003e, viewOn: \u003csource\u003e, pipeline: \u003cpipeline\u003e }) db.createView(\u003cview\u003e, \u003csource\u003e, \u003cpipeline\u003e, \u003ccollation\u003e) db.collection.drop() **视图行为：**\r视图存在以下行为： 视图只读，视图上的写操作将会出错； 视图使用底层集合的索引； 如果视图的基础集合被分割，视图也被认为可分割； 不能重命名视图； 视图上的字符串使用视图的默认排序规则。 ### 限制集\r限制集是固定大小的集合支持基于文档插入顺序的高吞吐率的插入、检索、删除操作。 限制集工作在某种程度上类似于循环缓冲区：一旦一个文档填满分配给它的空间，它将通过在限制集中重写老文档来给新文档让出空间。 #### 行为\r插入顺序 限制集合能够保留插入顺序。因此，查询并不需要索引来保证以插入顺序来返回文档。减少了索引的消耗，限制集可以支持更高的插入吞吐量。 最旧文档的自动删除 为了给新文档腾出空间，再不需要脚本或显示删除操作的前提下，限制集自动删除集合中最旧的文档。 例如replication set中的oplog.rs集合。考虑潜在用于集合封顶的用例： 存储高容量系统生成的日志信息。没有索引的情况下向限制集中插入文档的速度接近于直接在文件系统中写日志的速度； 在限制集中缓存少量的数据。 _id索引 限制集合有一个_id字段并且默认在_id字段上创建索引。 \r#### 限制和建议\r更新 更新限制集中的文档，创建一个索引保证这些更新操作不需要进行集合扫描。 文档大小 一个更新或替换操作改变了文档大小，操作将会失败。 文档删除 不能从一个限制集中删除文档！ 为了从一个集合中删除所有文档，使用drop()方法来删除集合然后重新创建限制集。 分片 不能对限制集分片。 查询效率","date":"2017-12-11","objectID":"/mongodb/:0:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"mongodb异常关闭后 #首先查看日志文件 tail /var/log/mongodb/mongod.log #删除 rm /var/run/mongodb/mongod.pid /var/db/mongodb/mongod.lock \r MongoDB配置文件 MongoDB的配置文件格式使用了YAML格式。 YAML维基百科，Yet Another Markup Language。强调以数据为中心，而不是标记语言为重点，用方向缩略语重命名。 默认配置文件`/etc/mongod.conf` 的几个大块：\r systemLog: #日志 storage: #存储 processManagement: #进程管理 net: #网络 security: #安全 operationProfiling: #性能分析器 replication: #主从复制 sharding: #架构 setParameter: #自定义变量 auditLog: #检测日志 snmp: #简单网络管理协议 ## systemLog\r日志相关参数： systemLog: verbosity: \u003cint\u003e #日志级别，默认0,1-5均会包含debug信息 quiet: \u003cboolean\u003e #安静，true时mongod将会减少日志的输出量 traceAllExceptions: \u003cboolean\u003e #打印异常详细信息 syslogFacility: \u003cstring\u003e #指定用于登录时信息到syslog Facility水平，前提是启用syslog path: \u003cstring\u003e #日志路径，默认情况下，MongoDB将覆盖现有的日志文件 logAppend: \u003cboolean\u003e #mongod重启后，在现有日志后继续添加日志，否则备份当前日志，然后创建新日志 logRotate: rename|reopen #日志轮询，防止一个日志文件特别大。rename重命名日志文件，默认值；reopen使用Linuxrotate特性，关闭并重新打开日志文件，前提为logAppend: true destination: \u003cstring\u003e #日志输出目的地，可为file或syslog，若不指定，则会输出到 std out timeStampFormat: \u003cstring\u003e #指定日志格式的时间戳，有 ctime, Iso869-utc, iso8691-local component: #为不同的组件指定各自的日志信息级别 accessControl: verbosity: \u003cint\u003e command: verbosity: \u003cint\u003e ## storage\r存储引擎相关参数: storage: dbPath: \u003cstring\u003e #mongodb进程存储数据目录，此配置进队此mongod进程有效，你使用配置文件开启的mongod就可以指定额外的数据目录 indexBuildRetry: \u003cboolean\u003e #当构件索引时mongod意外关闭，那么在此启动是否重建索引，默认true repairPath: \u003cstring\u003e #在repair期间使用此目录存储临时数据，repair结束后此目录下数据将被删除 journal: enabled: \u003cboolean\u003e #journal日志持久存储，journal日志用来数据恢复，通常用于故障恢复，建议开启 commitIntervalMs: \u003cnum\u003e #mongod日志刷新值，范围1-500毫秒，默认100，不建议修改 directoryPerDB: \u003cboolean\u003e #是否将不同的数据存储在不同的目录中，dbPath子目录 syncPeriodSecs: \u003cint\u003e #fsync操作将数据flush到磁盘的时间间隔，默认为60秒，不建议修改 engine: \u003cstring\u003e #存储引擎 mmapv1: #mmapv1存储引擎，3.2前默认 preallocDataFiles: \u003cboolean\u003e nsSize: \u003cint\u003e quota: enforced: \u003cboolean\u003e maxFilesPerDB: \u003cint\u003e smallFiles: \u003cboolean\u003e journal: debugFlags: \u003cint\u003e commitIntervalMs: \u003cnum\u003e wiredTiger: #WiredTiger存储引擎，3.2后默认 engineConfig: cacheSizeGB: \u003cnumber\u003e #最大缓存大小 journalCompressor: \u003cstring\u003e #日志压缩算法，可选值有 none，snappy(默认)，zlib directoryForIndexes: \u003cboolean\u003e #是否将索引和collections数据分别存储在dbPath单独的目录中 collectionConfig: blockCompressor: \u003cstring\u003e #collection数据压缩算法，可选none, snappy，zlib indexConfig: prefixCompression: \u003cboolean\u003e #是否对索引数据使用前缀压缩。对那些经过排序的值存储有很大帮助，可有效减少索引数据的内存使用量。 inMemory: #inMemory内存存储引擎，bate版 engineConfig: inMemorySizeGB: \u003cnumber\u003e ## processManagement\r进程相关参数: processManagement: fork: \u003cboolean\u003e #是否以fork模式运行mongod进程，默认情况下，mongod不作为守护进程运行 pidFilePath: \u003cstring\u003e #将mongod进程ID写入指定文件，如未指定，将不会创建PID文件 ## net\r网络相关参数: net: prot: \u003cint\u003e #监听端口，默认27017 bindIp: \u003cstring\u003e #绑定IP，如果此值是“0.0.0.0”则绑定所有接口 maxIncomingConnections: \u003cint\u003e #mongod进程允许的最大连接数，如果此值超过系统配置的连接数阈值，将不会生效(ulimit) wireObjectCheck: \u003cboolean\u003e #当客户端写入数据时，检查数据的有效性（BSON）。如果数据格式不良，update,insert等操作将会被拒绝 ipv6: \u003cboolean\u003e #是否支持多实例之间使用ipv6 unixDomainSocker: #适用于Unix系统 enabled: \u003cboolean\u003e pathPrefix: \u003cstring\u003e filePermissions: \u003cint\u003e http: # enabled: \u003cboolean\u003e JSONEnabled: \u003cboolean\u003e RESTInterfaceEnabled: \u003cboolean\u003e ssl: sslOnNormalPorts: \u003cboolean\u003e mode: \u003cstring\u003e PEMKeyFile: \u003cstring\u003e PEMKeyPassword: \u003cstring\u003e clusterFile: \u003cstring\u003e clusterPassword: \u003cstring\u003e CAFile: \u003cstring\u003e CRLFile: \u003cstring\u003e allowConnectionsWithoutCertificates: \u003cboolean\u003e allowInvalidCertificates: \u003cboolean\u003e allowInvalidHostnames: \u003cboolean\u003e disabledProtocols: \u003cstring\u003e FIPSMode: \u003cboolean\u003e compression: compressors: \u003cstring\u003e ## security\r安全相关参数: security: authorization: enabled #MondoDB认证功能 keyFile: /path/mongo.key #MongoDB副本集节点身份验证密钥文件 clusterAuthMode: \u003cstring\u003e #集群members间的认证模式 transitionToAuth: \u003cboolean\u003e javascriptEnabled: \u003cboolean\u003e #是否允许执行JavaScript脚本 redactClientLogData: \u003cboolean\u003e sasl: hostName: \u003cstring\u003e serviceName: \u003cstring\u003e saslauthdSocketPath: \u003cstring\u003e enableEncryption: \u003cboolean\u003e encryptionCipherMode: \u003cstring\u003e encryptionKeyFile: \u003cstring\u003e kmip: keyIdentifier: \u003cstring\u003e rotateMasterKey: \u003cboolean\u003e serverName: \u003cstring\u003e port: \u003cstring\u003e clientCertificateFile: \u003cstring\u003e clientCertificatePassword: \u003cstring\u003e serverCAFile: \u003cstring\u003e ldap: servers: \u003cstring\u003e bind: method: \u003cstring\u003e saslMechanism: \u003cstring\u003e queryUser: \u003cstring\u003e queryPassword: \u003cstring\u003e us","date":"2017-12-11","objectID":"/mongodb/:1:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"mongo shell基础知识 ","date":"2017-12-11","objectID":"/mongodb/:2:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"启动monso shell 启动mongo shell前确保MongoDB实例正在运行。 mongo [option] [db address] [.js] #以默认配置启动 mongo #以特定配置启动 mongo --port 27018 #连接远程mongo shell mongo --host $host --port $port -u $user -p $passwd mongo \u003cdb\u003e mongo \u003chost\u003e/\u003cdb\u003e mongo \u003chsot:port\u003e/\u003cdb\u003e **.mongorc.js文件**\rmongo shell开始运行时，mongo将在用户主目录下检查`.mongorc.js`的js文件。如果找到，mongo将在首次命令行之前解释执行.mongorc.js的内容。\r如果你使用mongo shell执行一个js或表达式，无论是通过`mongo --eval`，或指定一个.js文件，mongo都将在js处理完成之后读取.mongorc.js文件。可使用 `--norc`选项禁止加载.mongorc.js。\r ll /root/.mongorc.js # -rw------- 1 root root 0 Dec 27 2016 /root/.mongorc.js ### 使用mongo shell\r可能在启动mongo shell的时候会警告: WARNING: /sys/kernel/mm/transparent_hugepage/defrag is ‘always’. We suggest setting it to ‘never’. WARNING: /sys/kernel/mm/transparent_hugepage/defrag is ‘always’. We suggest setting it to ‘never’ WARNING: Access control is not enabled for the database. hugepage(大内存页面)，是Linux操作系统一种管理内存的方式。和通常方式相比，hugepage模式下内存分配管理会有所差异。 MongoDB显然不希望这个特定被启用。 新版MongoDB增加了安全性设计，推荐用户创建使用数据库时进行验证。所以我们需要创建用户认证。 关闭hugepage: vim /etc/rc.d/rc.local echo never \u003e /sys/kernel/mm/transparent_hugepage/enabled echo never \u003e /sys/kernel/mm/transparent_hugepage/defrag chmox a+x /etc/rc.d/rc.local 创建用户认证: \u003euse admin \u003edb.createUser( { user: \"zhang\", pwd: \"zhang\", roles: [{ role: \"root\", db: \"admin\"}] } ) mongo -u zhang -p zhang --authenticationDatabase admin #或 mongo use admin db.auth(\"zhang\", \"1314520\") mongo #显示当前使用数据库 \u003edb #切换数据库 \u003euse \u003cdatabase\u003e #查看所有数据库 \u003eshow dbs 你可以切换到一个并不存在的数据库。当你第一次向数据库存储数据，如创建一个集合，MongoDB将自动创建数据库。\r use nodb db.nocollestion.insert({x:1}); ### 格式化打印结果\rdb.collection.find()方法返回一个cursor(游标)。如果返回的游标未使用var关键字指定变量，则游标将自动迭代最多20次，以打印出与查询匹配的前20个documents #在操作中添加`.pretty()`，以格式化打印结果 #使用.pretty显示结果很舒服 db.collection.find().pretty() print() #无格式打印 printjson() #用JSON打印 ### mongo shell中的多行操作\rmongo shell中如果你以( , { , [开始，那么知道你输入了对应的) , } , ]才算结束命令。 \r### Tab命令补全和键盘快捷键\rmongo shell支持键盘快捷键，例如： 使用 上/下箭头 进行历史命令切换； 使用 Tab键 自动补全命令。 ### mongo shell批量操作\r mongo -u xxx -p xxx --authenticationDatabase=xxx \u003c\u003c EOF show dbs use zhang db.coll01.drop() db.coll02.update( { _id: \"xxx\" }, { name: \"zhang\" }) EOF ### 退出mongo shell\r quit() exit Ctrl+c ## 配置mongo shell\r可在mongo shell中设置变量prompt的值来修改提示符内容。 prompt变量可以存储字符串以及JavaScript代码。 也可以在.mongorc.js文件中增加提示符的逻辑操作来设置每次启动mongo shell的提示符。 ### 自定义提示符\r自定义提示符展示操作符： 在mongo shell中定义一下变量。 cmdCount = 1; prompt = function() { return (cmdCount++) + '\u003e '; } #效果 1\u003e 2\u003e ... **自定义提示符显示数据库和主机名：**\r形式为：@$ host = db.serverStatus().host; prompt = function() { return db+'@'+host+'$' } #效果 test@localhost$ **自定义提示符展示服务器启动时间和文档数：**\r prompt = function() { return 'Uptime:' + db.serverStatus().uptime + 'Documents:' + db.stats().objects + '\u003e '; } #效果 Uptime:1234 Documents:5 \u003e **注意：**\r在mongo shell里面定义的`prompt`变量知识临时生效的，退出shell后便没有。\r如果想要当前用户永久生效，可写入`~/.mongorc.js`文件。则此用户每次启动mongo shell前都会执行这个文件。\r vim ~/.mongorc.js host = db.serverStatus().host; prompt = function() { return db+\"@\"+host+\"\u003e \"; } ### 在mongo shell中使用外部编辑器\r可在启动mongo shell之前设置EDITOR环境变量来在mongo shell中使用自己的编辑器。 export EDITOR=vim mongo #edit \u003cvariable\u003e|\u003cfunction\u003e function myfunc(){} edit myfunc #此时是edit使用vim编辑myfunc function myfunc(){ print(\"It was edited by vim!\") } myfunc() ### 修改mongo shell批处理大小\rdb.collection.find()是一种JavaScript方法，返回一个cursor(游标)。如果返回的游标未使用var关键字指定变量，则游标将自动迭代最多20次，以打印出与查询匹配的前20个documents。 可以设置DBQuery.shellBatchSize属性来修改默认20篇文档。 DBQuery.shellBatchSize = 10; ## 获取mongo shell帮助\r合理运用Tab键补全命令！ ###命令行帮助 mongo --help ###mongo shell里查看帮助列表 help ###数据库帮助 #db.\u003cmethod\u003e show dbs db.help() ###集合帮助 #db.\u003ccollection\u003e.\u003cmethod\u003e show collections db.collections.help() ###游标帮助 db.collection.find().help() ###封装对象帮助 help misc \r## 给mongo shell写脚本\r可使用JavaScript为mongo shell编写脚本，用于处理MongoDB中的数据或执行管理操作。 ### 打开新连接\r在mongo shell或JavaScript文件中，可使用Mongo()构造函数来实例化数据库连接： new Mongo() new Mongo(\u003chost\u003e) new Mongo(\u003chost:port\u003e) #栗子 conn = new Mongo(); db = conn.getDB('mydb'); #将全局db变量设置为mydb #连接 db = connect('localhost:27017/mydb'); #认证 db.auth(\u003cuser\u003e, \u003cpasswd\u003e) db.auth({ user: \u003cuser\u003e, pwd: \u003cpassed\u003e }) ### 交互式和脚本化mongo的区别\rmongo shell中的帮助与JavaScri","date":"2017-12-11","objectID":"/mongodb/:2:1","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"mongo shell 历史命令 mongo shell历史命令保存在~/.dbshell文件中，cat ~/.dbshell。也可以使用上/下键切换历史命令。 ### 命令行选项\roption | description | - --help | 显示命令行选项 --nodb | 启动mongo shell而不连接到数据库 --shell | 执行文件后运行mongo shell \r### mongo shell命令助手\rhelp methods and commands | description | - help | 显示帮助 db.help | 显示数据库方法的帮助 db.collection.help() | 显示集合方法的帮助 show dbs | 打印服务器上的所有数据库列表 show databases | 打印所有可获取的数据库列表 use \u003cdb\u003e | 切换数据库 show collections | 打印当前数据库上的所有集合列表 show users | 打印当前数据库的用户列表 show roles | 打印当前数据库的所有角色(user-define and built-in)列表 show profile | 打印花费1ms或更多时间的五个最近的操作 load() | 在shell中执行一个JavaScript文件，建议使用绝对路径 \r### mongo shell的基本JavaScript操作\rmongo shell为数据库操作提供了一个JavaScript API。 db引用当的是前数据库的变量。 JavaScript db-operation | description | - db.auth() | 在安全模式下认证用户 coll = db.\u003ccollection\u003e | 将当前db中的特定collection设置为coll，可在此变量上执行操作，如coll.find(); db.collection.find() | 查找集合中的所有文档，并返回一个游标 db.collection.insert() | 插入一个新文档到集合中 db.collection.update() | 更新集合中一个存在的文档 db.collection.save() | 插入或更新 集合中的文档 db.collection.remove() | 从集合中删除文档 db.collection.drop() | 删除整个集合 db.collection.createIndex() | 在集合中创建索引 db.getSiblingDB() | 跨数据库查询 ### 键盘快捷键\rkeysrtoke | function | - Up/Down arrow | 前/后 历史命令 Left/Right arrow | 左右移动 Home/End | 行首/行尾 Tab | 自动补全 ctrl+c | 退出 ctrl+L | 清屏 ### mongo shell查询方法\r在mongo shell中，使用find()和findOne()方法执行读操作。 read-operations | description | - db.collection.find(\u003cquery\u003e) | 查找集合中与匹配的文档，如果未指定或为空，则读取操作会选择集合中的所有文档 db.collection.find(\u003cquery\u003e, \u003cprojection\u003e) | 查找与匹配的文档，返回特定字段 db.collection.find().sort(\u003csort order\u003e) | 返回排序结果 db.collection.find(\u003cquery\u003e).sort(\u003csort order\u003e) | 返回匹配和排序结果 db.collection.find(...).limit(\u003cn\u003e) | 限制输出结果为行 db.collection.find().pretty().limit() | 匹配，格式化，限制输出 db.collection.find().limit().pretty() | 同上 db.collection.find(...).skip(\u003cn\u003e) | 跳过前行 db.collection.count() | 返回集合中文档总数 db.collection.find().count() | 返回匹配文档总数 db.collection.findOne(\u003cquery\u003e) | 查找并返回单一的文档，null表示未找到 ### 管理命令助手\rjs db-administrative-methods | description | - db.cloneDatabase(\u003chost\u003e) | 从指定主机克隆当前数据库，noauth mode db.copyDatabase(\u003cfrom\u003e, \u003cto\u003e, \u003chost\u003e) | copy db to db db.fromColl.renameCollection(\u003ctoColl\u003e) | rename collection db.repairDatabase() | 修复当前db db.dropDatabases() | 删除当前数据库 \r### 打开附加连接\r可以在mongo shell中创建一个新连接。 \u003edb = connect(\"\u003chost\u003e:\u003cport\u003e/\u003cdb\u003e\") #db = connect(\"192.168.1.11/admin\") \u003econn = new Mongo() \u003edb = conn.getDB(\"dbname\") \r MongoDB CRUD操作 CRUD操作就是*创建(create)，读取(read)，更新(update)，删除(delete)*文档(document)! **创建(create)操作**\r创建或插入， 即是向 collection 添加新的 document。如果插入时集合不存在，插入操作会创建该集合。\r db.collection.insert() db.collection.insertOne() db.collection.insertMany() **读取(read)操作**\r读操作，获取 collection 中的 document。\r db.collection.find() **更新(update)操作**\r更新操作，修改 collection 中已经存在的 document。\r db.collection.update() db.collection.updateOne() db.collection.updateMany() db.collection.replaceOne() **删除(delete)操作**\r删除操作，是从一个 collection 中删除 document 的操作。\r db.collection.remove() db.collection.deleteOne() db.collection.deleteMany() \r## 插入文档(Insert)\r### 插入方法\rMongoDB提供了如下插入方法向collection中插入document： db.collection.insert(), 向集合中插入一个或多个文档; db.collection.insertOne(), 向集合中插入一个文档; db.collection.insertMany(), 向集合中插入多个文档. db.collection.insert() db.collection.insert(),向collection中插入一个或多个document。 要想插入一个document，传递一个文档给该方法；要想插入多个documents，传递文档数组给该方法。 #插入一个文档 db.user.insert( { _id: \"ZhangTest\", name: \"zhang\", age: 2017, sex: \"man\" } ) #插入多个文档 db.user.insert( [ { name: \"AAA\", age: 20, status: \"A\" }, { name: \"BBB\", age: 21, status: \"B\" }, { name: \"CCC\", age: 22, status: \"C\" } ] ) #### db.collection.insertOne()\rdb.collection.insertOne(),向collection中插入单个document。 db.user.insertOne( { name: \"zhang\", age: \"2017\", sex: \"man\", education: \"bachelor\" } ) #此处并未自定义_id字段，因此它会自动添加_id字段 db.collection.insertMany() db.collection.insertMany(),向collection插入多个documents。 db.user.insertMany( [ { name: \"AAA\", age: \"20\", status: \"A\" }, { name: \"BBB\", age: \"21\", status: \"B\" }, { name: \"CCC\", age: \"22\", status: \"C\" } ] ) #自动生成3个document的_id字段 ","date":"2017-12-11","objectID":"/mongodb/:2:2","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"插入操作的行为表现 创建集合 插入的时候如果collection不存在，那么插入操作会创建collection。 _id字段 在MongoDB中，存储于collection中的每一个document都需要一个唯一的_id字段作为primary_key。如果一个插入的document操作遗漏了_id字段，则MongoDB driver会自动生成一个ObjectId。 原子性 MongoDB中所有的写操作在单一文档层级上是原子的。 ","date":"2017-12-11","objectID":"/mongodb/:2:3","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"查询文档(Read) MongoDB提供了db.collection.find()方法从collection中读取document。 db.collection.find( \u003cquery filter\u003e, \u003cprojection\u003e ) #\u003cquery filter\u003e指明返回哪些document #\u003cprojection\u003e指明返回匹配document的那些filed ","date":"2017-12-11","objectID":"/mongodb/:3:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"示例 db.user.insertMany( [ { _id: 1, name: \"A\", favorites: { artist: \"Picasso\", food: \"pizza\" }, finished: [ 11, \"AA\" ], points: [ { points: 85, bonus: 30 }, { points: 85, bonus: 10 } ] }, { _id: 2, name: \"B\", favorites: { artist: \"Miro\", food: \"merigue\" }, finished: [ 22, \"BB\" ], points: [ { points: 85, bonus: 20 }, { points: 64, bonus: 12 } ] }, { _id: 3, name: \"C\", favorites: { artist: \"Gaogeng\", food: \"cake\" }, finished: [ 33, \"CC\" ], points: [ { points: 67, bonus: 8 }, { points: 55, bonus: 21 } ] } ] ) ","date":"2017-12-11","objectID":"/mongodb/:3:1","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"查询和规划操作符 Comparison: $eq $gt $gte $lt $ne $in $nin Logical： $or $and $not $nor Element: $exists $type Evaluation: $mod $regex $text $where Geospatial: $geoWithin $geoIntersects $near $nearSphere Array: $all $eleMatch $size Bitwise: $bitsAllSet $bitsAnySet $bitsAllClear $bitsAnyClear Comments: $comment Projection Operators: $ $eleMatch $meta $slice 选择collectino中所有document 一个空的query filter会选择集合汇总所有文档。 db.users.find({}) db.user.find() 指定查询过滤条件 1. 指定等于条件 { \u003cfield1\u003e: \u003cvalue1\u003e, ...} #栗子 db.user.find( { name: \"C\" } ) 2. 使用查询操作符指定条件 { \u003cfield1\u003e: { \u003coperator1\u003e: \u003cvalue1\u003e }, ... } #栗子 db.user.find( { name: { $in: [ \"A\", \"B\" ] } } ) 3. 指定逻辑查询条件条件 逻辑查询(AND, OR, NOT)。符合查询可以在集合文档的多个字段上指定条件。 #AND db.user.find( { name: \"A\", age: { $lt: 30} } ) #OR db.user.find( { $or: [ { name: \"A\" }, { age: { $lt: 30 } } ] } ) #AND和OR db.user.find( { name: \"A\", $or: [ {age: { $lt: 30 } }, { type: 1 } ] } ) 嵌入式文档的查询 当字段中包含嵌入文档时，查询可以指定嵌入文档中的精确匹配或使用圆点(.)表示法对嵌入文档的单个字段指定匹配。 #精确匹配 db.user.find({ favorites: { artist: \"Picasso\", food: \"pizza\" } }) #圆点.表示法，记得加引号 db.user.find( { \"favorites.artist\": \"Picasso\" } ) 数组上的查询 当字段包含数组，可查询精确的匹配数组或数组中特定的值。如果数组包含嵌入文档，可使用圆点表示法查询内嵌文档中特定的字段。 #精确匹配 db.user.find({ finished: [ 11, \"AA\" ] }) #匹配一个数组元素，会显示整个文档 db.user.find({ finished: \"BB\" }) #匹配数组中指定元素，会返回整个文档 db.user.find({ \"finished.1\": \"CC\" }) #指定数组中的多个查询条件 db.user.find({ finished: { $elemMatch: {$gte: 11, $lt: 33} } }) db.user.find({ finished: { $gt: 11, $lt: 33 } }) #嵌入文档数组 db.user.find({ 'points.points': {$lte: 80 } }) db.user.find({ \"points.0.points\": {$lte: 80} }) #元素组合满足查询条件 db.user.find({ \"points.points\": {$lte: 80}, \"points.bouns\": 20 }) \r","date":"2017-12-11","objectID":"/mongodb/:3:2","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"返回查询的映射字段 默认地，MongoDB中的查询返回匹配文档中的所有字段。为了限制MongoDB发送给应用的数据量，我们可以在查询操作中包括一个projection文档。 \r映射文档 映射文档限制了返回所有匹配文档的字段。映射文档可以致命包括哪些字段或排除哪些字段。 这个就很不错了，可以过滤掉我们不需要的信息。 db.users.find( {name: \"AAA\"} ,{_id: 0, name: 1, age: ture} ) db.user.find( { name: \"BBB\"}, {_id: false} ) 1或true，表示在返回的文档中包含字段； 0或false，排除该字段； \r","date":"2017-12-11","objectID":"/mongodb/:3:3","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"更新文档(Update) 更新方法： db.collection.updateOne(), 更新一个文档 db.collection.updateMany(), 更新多个文档 db.replaceOne(), 替换一个文档 db.collection.update(), 更新或替换一个文档 \r","date":"2017-12-11","objectID":"/mongodb/:4:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"更新的行为表现 原子性： MongoDB中所有的写操作在单一文档层级上是原子的。 _id字段： 不能更新_id字段的值，也不能用不同_id字段值的替换文档来替换已存在的文档。 文档大小： 当执行更新操作增加的文档大小超过了为该文档分配的空间时，更新操作会在磁盘上重定位该文档。 字段顺序： MongoDB按照文档写入的顺序整理文档字段。但_id字段始终是文档中第一个字段；renaming操作可能会导致文档中的字段重新排序。 \r","date":"2017-12-11","objectID":"/mongodb/:4:1","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Update Operator Fields name | description | - $currentDate | 将字段值设置为当前日期(date or timestamp) $inc | 按指定的数字递增字段的值 $min | 指定的值小于字段的值时才更新 $max | 指定的值大于字段的值时才更新 $mul | 将字段的值乘以指定的数字 $rename | 重命名一个字段 $set | 设置文档中字段的值 $setOnInsert | 如果更新导致文档插入，则设置字段的值 $unset | 从文档中删除指定的字段， \rArray name | description | - $ | 用作更新与查询条件匹配的第一个元素的占位符 $[] | 用作更新与查询条件匹配的文档的数组的所有元素的占位符 $[] | xxx $addToSet | 在集合中不存在元素时添加元素到数组 $pop | 移除数组中的第一项或最后一项 $pull | 删除所有匹配指定查询的数组元素 $push | 向数组中添加项 $pullAll | 从数组中删除所有匹配的值 \rModifiers name | description | - $each | 修饰$push and $addToSet， 向数组中添加多个项 $position | 修饰$push，在数组中指定位置添加元素 $slice | 修饰$push，限制更新数组的大小 $sort | 修饰$push，重新排列存储在数组中的文档 BitWise $bit 执行按位AND,OR,XOR更新 ","date":"2017-12-11","objectID":"/mongodb/:4:2","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"更新文档字段中指定字段 为了修改文档中的字段，MongoDB提供了update operators，如用来修改值的$set。 { \u003cupdate operator\u003e: { \u003cfield\u003e: \u003cvalue\u003e, ...} } #更改指定字段的值 db.user.update( { _id: 1 }, { $set: {name: \"SET\"} } ) #删除指定字段，文档中其他字段还在 db.user.update( { _id: 1 }, { $unset: {name: \"SET\"} } ) # db.user.updateMany( { _id: 2}, { $set: {name: \"AAA\", age: 222} } ) ","date":"2017-12-11","objectID":"/mongodb/:4:3","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"文档替换(Replace) 当替换文档时，替换的文档必须仅仅有 \u003cfield\u003e: \u003cvalue\u003e组成。 替换文档可以有不同于源文档的字段，但_id字段是不变的。 **建议使用_id作为过滤条件，因为它是唯一的。 db.collection.replaceOne() db.user.replaceOne( { name: \"AAA\" }, { name: \"A\", age: 2, sex: \"man\", favorites: { artist: \"Dali\", food: \"banana\" } } ) db.user.update( { _id: 1}, { name: \"A\", age: 2, sex: \"man\", favorites: { artist: \"Dali\", food: \"banana\" } } ) \r","date":"2017-12-11","objectID":"/mongodb/:4:4","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"删除文档(Delete) 方法： db.collection.remove(), 删除一个文档，或所有满足匹配的文档; db.collection.deleteOne(), 删除匹配最多条件的单个文档，即使可能有多个文档可能与指定过滤条件匹配; db.collection.deleteMany(), 删除所有匹配指定过滤条件的文档。 ","date":"2017-12-11","objectID":"/mongodb/:5:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"删除的行为表现 Indexes 删除操作不会删除索引，即使从集合中删除了所有的文档。 原子性 MongoDB中所有的写操作在单一文档层级上是原子的。 ","date":"2017-12-11","objectID":"/mongodb/:5:1","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"删除 #删除所有文档 db.collectin.deleteMany({}) db.collection.remove({}) #删除所有满足条件的文档 db.user.remove( { name: \"A\" } ) db.user.deleteMany( { name: \"A: } ) #仅删除一个满足条件最多的文档 db.user.deleteOne( { name: \"A\" } ) db.users.remove( { name: \"A\"}, 1) \r聚合(Agrregation) 聚合操作处理数据记录并返回计算的结果。聚合操作将多个文档中的值(value)分组，并对分组的数据进行各类操作以返回单个结果。 MongoDB提供了三种方式进行聚合： aggregation pipeline(聚合管道); map-reduce function(映射化简); single aggregation methods(聚合指南) \rAggregation Pipeline(聚合管道) MongoDB的聚合框架(aggregation framework)是仿照数据处理管道的概念(concept)。Document输入多级管道，它将Document转换为聚合结果。 最基本的pipeline stage提供了：类似查询(query)操作的过滤器(filter)和类似修改(modify)输出文档格式的文档转换。 其他pipeline operation提供了按特定字段对文档进行分组和排序的工具，以及聚合数组内容(包括文档数组)的字段或工具。此外，pipeline stage可以使用运算符(operators)来处理任务。(如计算平均值和连接等…) pipeline通过在MongoDB中使用本地操作，从而提供了高效的数据聚合。所以也是MongoDB中数据聚合的首选方法。 aggregation pipeline能够在一个共享的集合上操作。 aggregation pipeline可以使用索引来提高某些阶段的性能(performance)。另外，管道聚合还有一个内部优化阶段(optimization phase)。 \rMap-Reduce(映射化简) 一般来说，map-reduce操作有两个阶段： map stage: 处理每个文档并未每个输入文档发出一个或多个对象(object)； reduce stage: 结合映射操作的输出。 可选地，map-reduce有一个对结果做最后修改的最后阶段。与aggregation-operation类似，map-reduce可以指定查询条件来选择一个输入文档，以及对结果进行排序和限制。 map-reduce使用自定义的JavaScript函数执行映射和化简操作，以及可选的最终操作。与聚合管线相比，自定义的JavaScript提供了很大的灵活性。一般来说，map-reduce比aggregation pipeline效率更低，更复杂。 map-reduce能够在一个共享的集合上操作，同样也可以输出到共享集合。 \rSingle Purpose Aggregation Operations(聚合指南) MongoDB同样提供了db.collection.count()和db.collection.distinct()。 所有这些操作都从单个集合中聚合文档，虽然这些操作提供了对常见聚合过程的简单访问，但它们缺少aggregation pipeline和map-reduce的灵活性和功能。 ","date":"2017-12-11","objectID":"/mongodb/:5:2","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Aggregation Pipeline(聚合管道) MongoDB的聚合框架是仿照数据处理管道的概念。文档输入多级管道，它将文档转换为聚合结果。 当map-reduce的复杂性可能是没有保证的，aggregation pipeline为map-reduce提供了一个可选也可能是聚合任务的首选解决方案。 aggregation pipeline对key value和result size有一些限制。 \r\r","date":"2017-12-11","objectID":"/mongodb/:6:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"映射化简 \r","date":"2017-12-11","objectID":"/mongodb/:7:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"聚合指南 MongoDB文本索引 MongoDB支持在字符串内容上执行文本检索(text search)的查询操作。视图不支持文本检索。 为了执行文本检索，MongoDB使用text index和$text操作符。text索引可以包括任何值为字符串或字符串元素数组的字段。 栗子： db.sample.insert( [ { _id: 1, name: \"A\", description: \"AAA\" }, { _id: 2, name: \"B\", description: \"BBB\" }, { _id: 3, name: \"C\", description: \"CCC\" } ] ) 为了执行文本检索查询，你必须在集合有一个text索引，一个集合只能有一个文本检索索引，但是这个索引可以覆盖多个字段。 启动在name和description字段上的文本检索： db.sample.createIndex( { name: \"text\", description: \"text\" } ) 使用$text查询操作符在一个有text index的集合上执行文本检索 db.sample.find({ $text: { $search: \"A B\" } }) #精确检索 db.sample.find({ $text: { $search: \"A \\\"B\\\"\" } }) #词语排除 db.sample.find({ $text: { $search: \"A B -AAA\" } }) MongoDB默认返回没排序的结果。然而文本检索将会对每个文档计算一个相关性分数，表明该文档与查询的匹配程度。 为了使用相关性分数进行排序，你必须使用 $meta textScore字段进行映射然后基于该字段进行排序。 db.sample.find( { $text: { $search: \"A AAA B\" } }, { score: { $meta: \"textScore\" } } ).sort( { score: { $meta: \"textScore\" } }) 文本检索可以在聚合管道中使用。 \r\r","date":"2017-12-11","objectID":"/mongodb/:8:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"文本索引 \r","date":"2017-12-11","objectID":"/mongodb/:9:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"文本检索操作符 \r","date":"2017-12-11","objectID":"/mongodb/:10:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"在管道聚合中使用文本索引 \r","date":"2017-12-11","objectID":"/mongodb/:11:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"使用基本技术Rosette语义平台的文本索引 \r","date":"2017-12-11","objectID":"/mongodb/:12:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"文本检索语言 \rMongoDB数据模型 MongoDB的数据具有灵活的模式，集合本身没有对文档结构的规则性校验。 ","date":"2017-12-11","objectID":"/mongodb/:13:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"数据模型设计介绍 关系型数据库要求你再插入数据之前必须先定义好一个表的模式结构，而MongoDB的集合并不限制文档结构。 这种灵活性让对象和数据库文档之间的映射变得很容易。即使数据记录之间有很大的变化，每个文档也可以很好的映射到各条不同的记录。 当然，在实际使用中，同一个集合中的文档往往都有一个比较类似的结构。 数据模型设计中最具挑战性的是在应用程序需求，数据库引擎性能要求和数据读写模式之间的权衡考量。 \r","date":"2017-12-11","objectID":"/mongodb/:14:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"文档结构 引用(reference) 引用方式通过存储链接或引用信息来实现两个不同文档之间的关联。 应用程序可以通过解析这些数据库引用来访问相关数据。简单来讲，这就是规范化的数据模型。 内嵌(embedded data) 内嵌方式指把相关联的数据保存在同一个文档之内。 MongoDB的文档结构允许一个字段或一个数组内的值为一个嵌套的文档。这种冗余的数据模型可以让应用程序在一个数据库内完成对相关数据的读取或修改。 \r","date":"2017-12-11","objectID":"/mongodb/:14:1","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"写操作的原子性 在MongoDB中，写操作在文档级别是原子的(atomic)，没有一个单独的写操作可以原子地影响多个文档或多个集合。但，对原子性写操作利好的内嵌数据模型会限制应用程序对数据的使用场景。 嵌入(embdded)数据的非规格化(denormalized)数据模型将单个文档所表示的实体(entity)的所有相关数据组合在一起。这有利于原子写操作，因为单个写操作可以插入或更新实体的数据； 规格化(normalizing)数据通过多个集合拆分数据，并需要多个不是原子集合的写操作。 \r","date":"2017-12-11","objectID":"/mongodb/:14:2","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"文档的增长 如果文档的大小超出分配给文档的原空间大小，那么MongoDB就需要把文档从磁盘上的现有位置移动到一个新的位置以存放更多的数据。这种数据增长的情况也会影响到是否要使用规范化或非规范化。 \r","date":"2017-12-11","objectID":"/mongodb/:14:3","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"数据的使用和性能 设计文档模型时，一定要考虑应用程序会如何使用你的数据。 例如： 假如应用程序通常只会使用最近插入的文档，那么可以考虑使用限制集； 假如应用会做大量的读操作，那么可以加多一些索引的方法来提升常见查询的性能。 \r","date":"2017-12-11","objectID":"/mongodb/:14:4","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"文档验证 MongoDB提供了在更新和插入期间验证(validate)文档的功能(capability)。验证规则是在每个集合中指定使用验证符(validator)选项，利用一个文档指定验证堆栈或表达式。 通过collMod命令附带验证符选项向一个已经存在的集合添加文档验证； 利用db.createCollection()命令附带验证符选项来创建文档验证规则。 db.createCollection( \"contacts\", { validator: { $or: [ { phone: { $type: \"string\" } }, { email: { $regex: /@mongodb\\.com$/ } }, { status: { $in: [ \"Unknown\", \"Incomplete\" ] } } ] } } ) MongoDb同样提供了validationLevel选项，它确定了MongoDb在更新期间如何将验证规则应用到已有文档，以及验证操作选项。它确定MongoDB是否错误并拒绝违反验证规则的文档，或者警告日志中的违规，但允许无效的文档。 \r","date":"2017-12-11","objectID":"/mongodb/:15:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"行为 验证发生在更新和插入期间。当向一个文档添加验证，在修改之前，现有文档不会进行验证检查。 \r现有文档 可使用validationLevel选项来控制MongoDB怎样处理现有文档。 默认情况下，MongoDB是严格的，并且将验证规则应用于所有插入和更新操作。 #moderate level #在中等级别下，对不符合验证标准的现有文档更新将不会检查有效性 db.runCommand({ collMod: \"contacts\", validator: { $or: [ { phone: { $exists: true } }, { email: { $exists: true}} ] }, validationLevel: \"moderate\" }) 设置validationLevel为off以禁用验证功能。 \r接受或拒绝无效文档 validationAction选项决定了MongoDB如何处理违反(violate)验证规则的文档。 默认情况下，validationAction是错误的，并且拒绝任何违反验证条件的插入和更新操作。 #当validationAction为warn时，MongoDB记录所有违反行为，但允许插入或更新操作。 db.createCollection( \"contacts\", { validator: { $or: [ { phone: { $type: \"string\" } }, { email: { $regex: /@mongodb\\.com$/ } }, { status: { $in: [ \"Unknown\", \"Incomplete\" ] } } ] }, validationAction: \"warn\" } ) #如下违规操作将会报警，并由于是warn，所以写入成功 db.contacts.insert( { name: \"Amanda\", status: \"Updated\" } ) \r约束(restriction) 无法在admin,local,config数据库的集合 和 system.*集合 里面指定验证符(validator)。 \r绕过文档验证 通过bypassDocumentValidation选项来绕过文档验证。 \r","date":"2017-12-11","objectID":"/mongodb/:15:1","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"数据建模理论 ","date":"2017-12-11","objectID":"/mongodb/:16:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"数据模型设计 一个高效的数据模型能够很好的满足应用程序的需求。设计一个文档数据结构最关键的考量就是决定是使用嵌套(embdded)还是引用(reference)。 内嵌式数据模型(非规范化) 在MongoDB里面，可以把相关的数据包括在一个单个的结构或者文档下面。这样的数据模型也叫作非规范化模式。 内嵌数据可以让应用程序把相关的数据保存在同一条数据记录里面，这样，应用程序就可以发送较少的请求给MongoDB来完成常用的查询和更新请求。 一般来说，下述情况建议使用内嵌数据模型： 数据对象之间有包含(contain)关系； 数据对象间有一对多的关系。 通常情况下，内嵌数据会对读操作有比较好的性能提高，可以使应用程序在一个单个操作就可以完成对数据的读取。同时，内嵌数据也对更新相关数据提供了一个原子性写操作。 \r规范化数据模型 一般来说，下述情况可以使用规范化模型： 内嵌数据会导致很多数据的重复，并且读性能的优势又不足与盖过数据重复的弊端时； 需要表达比较复杂的多对多关系时； 大型多层次结构数据集。 ","date":"2017-12-11","objectID":"/mongodb/:16:1","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"MongoDB特性和数据模型的关系 MongoDB的数据建模不仅仅取决于应用程序的数据需求，也要考虑MongoDB本身的一些特性。 \r文档增长性(increase) 如果更新操作导致文档大小增加，那么可能需要重新设计数据模型，在不同文档之间使用引用的方式而非内嵌、冗余的数据结构。 MongoDB会自动调整空白填充的大小以尽可能的减小文档迁移。你也可以使用一个预分配策略来防止文档的增长。 \r原子性(atomic) 在MongoDB中，所有在文档级别的操作都具有原子性。一个单个写操作最多只可以修改一个文档。即使是一个会改变同一个集合中多个文档的命令，在同一时间也只会操作一个文档。即便是涉及多个子文档的多个操作，只要是在同一文档之内，这些操作仍旧是有原子性的。 尽可能保证那些需要在一个原子操作内进行修改的字段定义在同一个文档里面。如果你的应用程序允许对两个数据的非原子性更新操作，那么可把这些数据定义在不同的文档内。 把相关数据定义到同一个文档里的内嵌方式有利于这种原子性操作。对于那些使用引用来关联相关数据的数据模型，应用程序必须再用额外的读和写操作去取回和修改相关的数据。 \r分片(sharding) MongoDB使用分片来实现水平扩展。使用分片的集群可以支持海量的数据和高并发读写。使用分片技术把一个数据库内的某一个集合的数据进行分区，从而达到把数据分到多个mongod实例(或分片上)的目的。 MongoDB依据分片键分发数据和应用程序的事务请求。选择一个合适的分片键对性能有很大的影响，也会促进或阻碍MongoDB的定向分片查询和增强的写性能。所以在选择分片键的时候要仔细考量分片键所用的字段。 \r索引(index) 对常用操作可以使用索引来提高性能。对查询条件中常见的字段，以及需要排序的字段创建索引。 MongoDB会对_id自动创建唯一索引。 创建索引时，需要考虑索引的下述特征： 每个索引要求至少8KB的数据空间； 每增加一个索引，就会对写操作性能有一些影响。对于一个写多读少的集合，索引会变得很费时。因为每个插入必须要更新所有索引； 每个索引都会占一定的硬盘空间和内存(对于活跃的索引)。索引可能会用到很多这样的资源，因此对这些资源要进行管理和规划，特别是在计算热点数据大小的时候。 \r集合的数量 某些情况下，可能需要把相关的数据保存到多个集合里面。比如： { log: \"dev\", ts:..., info: ... } { log: \"debug\", ts:..., info: ... } 一般来说，很大的集合数量对性能没有什么影响，反而在某些场景下有不错的性能。使用不同的集合在高并发批处理场景下会有很好的帮助。 当使用有大量集合的数据模型时，请注意： 每个集合有几KB的额外开销； 每个索引(包含_id)，需要至少8KB的数据空间； 每个MongoDB的数据库有且仅有一个命名文件(namespace file)(.ns)。这个命名文件保存了数据库的所有元数据，每个索引和集合在这个文件里都有一条记录； MongoDB的命名文件有大小的限制(默认16MB)。利用db.system.namespaces.count()查看。 \r包含大量小文档的集合 如果你有一个包含大量小文档的集合，则应该考虑为了性能而嵌入。如果你可以通过一些逻辑关系将这些小文档分组，并且你经常通过这个分组来检索文档，那么你应该考虑将小文档\"卷起来\"成为包含一系列嵌入式文档的大文档。 将这些小文档“卷起来”成为逻辑分组，意味着检索一组文档的查询设计顺序读取和较少的随机磁盘访问。此外，将文档“卷起”并将公共字段移动到较大的文档会使字段上的索引受益。公共字段的副本将会减少，并且相应索引中的关联键条目也会减少。 然而，如果你通常只需要检索分组中的一个文档的子集，那么“滚动”文档可能无法提供更好的性能。此外，如果晓得，独立的文档代表数据的自然模型，那你应该维护改模型。 \r小文档的存储优化(storage optimization) 每个MongoDB文档都包含一定的开销(overhead)，这些开销通常是无关紧要的。但如果文档只有几个字节，那就相当重要了。 考虑以下有关优化这些集合的存储利用率的建议： 显示地使用_id字段； 使用较短的字段名称； 嵌套文档。 数据生命周期管理 数据模型决策应考虑数据生命周期管理。 集合的**TTL功能*在一段时间后标识文档到期。如果应用程序需要一些数据才能在数据库中持久化一段有限的时间，请考虑使用TTL特性。 此外，你的应用程序仅使用最近插入的文档，请考虑限制集。 ","date":"2017-12-11","objectID":"/mongodb/:16:2","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"数据模型例子与范式 ","date":"2017-12-11","objectID":"/mongodb/:17:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"文档关系建模 一对一关系建模：内嵌文档模型 用内嵌文档方式实现一对一关系。 一对多关系建模：内嵌文档模型 用内嵌文档方式实现一对多关系。 一对多关系建模：文档引用模式 用文档引用实现一对多关系。 \r","date":"2017-12-11","objectID":"/mongodb/:17:1","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"树结构建模 父文档引用 父文档引用模式用一个文档来表示树的一个节点。每一个文档除了存储节点的信息，同时也保存该节点父节点文档的id值。 db.test.insert({ _id: \"MongoDB\", parent: \"Databases\" }) db.test.insert({ _id: \"Databases\", parent: \"Programming\" }) db.test.insert({ _id: \"Programming\", parent: \"Books\" }) db.test.insert({ _id: \"Books\", parent: null }) #查询父节点 db.test.findOne({ _id: \"MongoDB\" }).parent #对parent字段创建索引，这样可以快速的按照父节点查找 db.test.createIndex({ parent: 1 }) #查询一个父节点的所有子节点 db.test.find({ parent: \"Databases\" }) \r子文档引用 子文档引用模式用一个文档来表示树的一个节点。每一个文档除了存储节点信息外，同时也用一个数组来保存该节点的所有子节点的id值。 db.test.insert({ _id: \"MongoDB\", children: [] }) db.test.insert({ _id: \"Databases\", children: [ \"MongoDB\", \"dbm\" ]}) db.test.insert({ _id: \"Programming\", children: [ \"Languages\", \"Databases\" ]}) db.test.insert({ _id: \"Books\", children: [ \"Programming\" ]}) #查询子节点 db.test.findOne({ _id: \"Databases\"}).children #对children字段创建索引，这样就可以快速按照子节点查找 db.test.createIndex({ children: 1 }) #查找一个子节点的父节点和同级节点 db.test.find({ children: \"MongoDB\" }) \r祖先数组(ancestors array) 祖先数组模式用一个文档来表示树的一个节点。每一个文档除了存储节点的信息，同时也存储了对父文档及祖先文档的id值。 db.test.insert({ _id: \"MongoDB\", ancestors: [ \"Books\", \"Programming\", \"Databases\" ], parent: \"Databases\" }) db.test.insert({ _id: \"Databases\", ancestors: [ \"Books\", Programming\" ], parent: [ \"MongoDB\", \"dbm\" ]}) db.test.insert({ _id: \"Programming\", ancestors: [ \"Books\" ], parent: \"Books\" }) db.test.insert({ _id: \"Books\", ancestors: [ ], parent: null }) #查询一个节点的祖先节点 db.test.findOne({ _id: \"MongoDB\" }).ancestors #对ancestors创建索引 db.test.createIndex({ ancestors: 1 }) #利用ancestors字段来查找某个节点的所有子代节点 db.test.find({ ancetors: \"Programmming\" }) \r物化路径(materialized path) 物化路径模式将每个树节点存储在文档中。除了存储节点信息外，同时也存储了祖先文档或路径的id值。 db.test.insert({ _id: \"Books\", path: null }) db.test.insert({ _id: \"Programming\", path: \",Books,\" }) db.test.insert({ _id: \"Databases\", path: \",Books,Programming,\" }) db.test.insert({ _id: \"MongoDB\", path: \",Books,Programming,Databases,\" }) #查询整个树的所有节点并按path排序 db.test.find().sort({ path: 1 }) #可以在path字段上使用re来查询 db.test.find({ path: /,Programming,/ }) db.test.find({ path: /^,Books,/ }) #在path字段上创建索引 db.test.createIndex({ path: 1 }) \r嵌套集合(nested set) 嵌套集合模式对整个树结构进行一次深度优先的遍历。遍历时候对每个节点的压栈和出栈作为两个不同的步骤记录下来。每一个节点就是一个文档，除了节点信息外，文档还保存父节点的id以及遍历的两个步骤编号。压栈是的步骤保存到left字段里，而出栈时的步骤编号则保存到right字段里。 db.test.insert({ _id: \"Books\", parent: 0, left: 1, right: 12 }) db.test.insert({ _id: \"Programming\", parent: \"Books\", left: 2, right: 11 }) db.test.insert({ _id: \"Databases\", parent: \"Programming\", left: 5, right: 10 }) db.test.insert({ _id: \"MongoDB\", parent: \"Databases\", left: 6, right: 7 }) #查询摸个节点的子代节点 db.test.find({ left: { $gt: db.test.findOne({ _id: \"Databases\" }), right: { $lt: db.test.findOne({\"_id: \"Databases\"}) } }) ","date":"2017-12-11","objectID":"/mongodb/:17:2","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"具体应用模型举例 原子性事务建模 如何使用内嵌技术来保证同一文档内相关字段更新操作的原子性。 举例来说，假设你在设计一个图书馆的借书系统，你需要管理书的库存量以及出借记录。一本书的可借数量加上借出数量的和必须等于总的保有量，那么对这两个字段的更新必须是原子性的。 \r关键词搜索建模 描述了一种把关键词保存在数组里并使用多键索引来实现关键词搜索功能的方法。 为实现关键词搜索，在文档内增加一个数组字段并把每一个关键词加到数组里。然后你可以对该字段建一个 多键索引。这样你就可以对数组里面的关键词进行查询了。 \r货币数据建模 处理货币数据的应用程序通常需要捕获小数(franctional)货币单位，并在执行算术时需要精确地模拟十进制四舍五入。许多现代系统(float,double)使用的基于二级制的浮点运算不能精确地表示小数，而且需要某种程度的近似，因而不适合于货币运算。因此，在货币数据建模时，这一约束是一个重要的考虑因素。 数字模型 如果需要查询数据库中精确、数学书有效匹配或需要执行Server端算术，则数字模型可能是适合的。 非数字模型 如果需要在Server端做一些对货币数值的数学计算，那么严格精度可能会更合适一些。 \r时间数据模型 MongoDB默认存储UTC时间，并将任何本地时间转换成这种形式。 \rMongoDB管理 administration The administration 文档说明了MongoDB实例和部署正在进行的操作和维护。本文档包括这些问题的高级概述，以及涵盖操作MongoDB的特定过程的教程。 \r","date":"2017-12-11","objectID":"/mongodb/:17:3","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"操作清单(operation checklist) 如下清单，提供了帮助你避免在MongoDB部署中出现问题的建议。 \r","date":"2017-12-11","objectID":"/mongodb/:18:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"文件系统(file system) 将磁盘分区与RAID配置对齐； 避免对dbpath使用NFS。使用NFS会导致性能下降和不稳定； 针对Linux/Unix的文件格式，建议使用XFS或EXT4。如果可能的话，对MongoDB使用XFS性能会更好； 对于WiredTiger存储引擎，强烈建议使用XFS来避免使用EXT4时发现的性能问题； 针对Windows，不要使用FAT(FAT16/32/exFAT)文件系统，请使用NTFS文件系统。 \r","date":"2017-12-11","objectID":"/mongodb/:18:1","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"复制(replication) 验证所有非隐藏副本集成员的RAM, CPU, 磁盘, 网络设置, 配置等方面是否相同； 配置oplog的大小来适合你的用例； 确保副本集包好至少3个以journaling方式运行的数据承载节点； 在配置副本集成员时使用主机名(hostname)，而不是IP地址； 确保所有的mongod实例之间使用全双工网络； 确保每台主机都能解析它自己； 确保副本集包含奇数个投票的成员(voting members)，确保票数不会相等则一定会有主被选举出来； 确保mongod实例有0或1票； 为了高可用(high availability)，副本集集群最少部署3台数据中心。 \r","date":"2017-12-11","objectID":"/mongodb/:18:2","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"分片(sharding) 将配置服务器放置于专用硬件，以便在大型集群中实现最佳性能。确保硬件有足够的RAM来讲数据文件完全存储到内存中，并且有专门的存储； 使用NTP同步分片集群上所有组件的时钟； 确保Mongod, mongos和配置服务器之间的全双工网络连接； 使用CNAME将配置服务器标识到集群中，以便可以在不停机的情况下重命名和重新编号配置服务器。 \r","date":"2017-12-11","objectID":"/mongodb/:18:3","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Journaling 确保所有实例都使用journaling； 将journal放置于低延迟(low-latency)磁盘上，用于编写密集的工作负载。注意，这将影响快照式备份(snapshot)，因为构成数据库状态的文件将驻留在单独的volume上。 \r","date":"2017-12-11","objectID":"/mongodb/:18:4","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"硬件(hardware) 使用RAID10和SSD能够获得最佳性能； 确保每个mongod为它的dbpath提供了IOPS； 在虚拟环境中运行时，避免动态内存功能； 避免将所有副本集成员放置于相同的SAN(存储区网络)中。 \r","date":"2017-12-11","objectID":"/mongodb/:18:5","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"部署到云上 AWS; Azure; Aliyun; Tencent. ","date":"2017-12-11","objectID":"/mongodb/:18:6","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"操作系统配置 Linux 关闭hugepages和defrag； 调整存储数据库文件设备上的readahead设置，以适应用例； 在虚拟环境中的RHEL7/CENTOS7上禁用优化工具； 为SSD驱动使用noop或deadline磁盘调度； 禁用NUMA或将vm.zone_reclaim_mode设置为0，并运行node interleaving的mongod实例； 调整硬件的ulimit值以适应实例； 对dbpath挂载点使用noatime； 对你的部署配置足够的文件句柄(fs.file-max value of 98000)，内核pid限制(kernel.pid_max value of 64000)，每个进程的最大线程数(kernel.threads-max value 0f 64000)； 确保你的系统配置有swap交换分区； 确保系统默认TCP keepalived设置正确。 Windows 考虑禁用NTFS的最后访问时间更新。这类似与在Unix-like系统上禁用atime。 ","date":"2017-12-11","objectID":"/mongodb/:18:7","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"备份(backup) 安排备份和恢复过程的定期测试，以便手头有时间估计，并恢复其功能。 ","date":"2017-12-11","objectID":"/mongodb/:18:8","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"监控(monitor) 监视Server的硬件统计信息(磁盘使用，CPU，可用磁盘空间…) 监视mongodb的状态。 ","date":"2017-12-11","objectID":"/mongodb/:18:9","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"负载均衡(load balance) 配置负载均衡启用\"sticky session\"或“client affinity”，对现有连接有足够的超时时间； 避免放置负载均衡器在MongoDb集群或副本集组件。 \r","date":"2017-12-11","objectID":"/mongodb/:18:10","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"开发清单(development checklist) 如下清单，提供了帮助你避免在MongoDB部署期间出现的问题的建议。 ","date":"2017-12-11","objectID":"/mongodb/:19:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"数据持久性(data durability) 确保副本集至少包含3个(带有w:majority)数据承载节点，这3个数据承载节点需要为副本集的高数据持久性； 确保所有实例都是用了journaling。 ","date":"2017-12-11","objectID":"/mongodb/:19:1","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"架构设计(schema design) MongoDB中的数据具有动态结构。collection并不要求document结构。这有助于迭代开发和多态性。然而，集合中的文档通常具有高度的同类结构。 确保你需要的集合集中的索引(indexes)支持你的查询(query)。除了_id索引，你必须显式的创建所有索引； 确保你的架构设计支持你的开发类型； 确保你的架构设计不依赖于长度不受绑定的索引数组； 再架构设计时考虑文档大小限制。 \r","date":"2017-12-11","objectID":"/mongodb/:19:2","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"复制(replication) 使用奇数个副本集成员以确保选举顺利进行。如果有偶数个成员，请使用仲裁者(arbiter)以确保级数的选票； 确保使用监控工具和适当的写关注来保持从库数据最新； 不要使用从库读取来扩展整体读取吞吐量。 \r","date":"2017-12-11","objectID":"/mongodb/:19:3","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"分片(sharding) 确保你的sharded key将负载均匀地分配到分片上； 对需要按分片数进行缩放的工作负载(workload)使用有针对性的操作； 对非目标(non-targeted)查询，总是从主节点读取可能对陈旧或孤立的数据很敏感； 当向新的非散列(hash)分片集合中插入大数据集时，Pre-split and manually balance chunks。 ","date":"2017-12-11","objectID":"/mongodb/:19:4","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"驱动(drivers) 使用连接池(connection pooling)； 确保你的应用程序在复制集选举期间还能够处理瞬时写入(transient write)和错误读取； 确保你的应用程序处理失败的请求并适时地重试它们； 使用指数退避逻辑重试数据库请求； 如果需要计算数据库操作的编译执行时间，对读操作使用cursor.maxTimeMS()，对写操作使用wtimeout。 \r","date":"2017-12-11","objectID":"/mongodb/:19:5","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"性能(MongoDB Perfomance) 当遇到性能下降时，通常与数据库的访问策略、硬件可用性和开放的数据库连接数相关； 一些用户可能由于不适当的索引策略或结果不足而经历性能限制，或由于架构设计模式差； 性能问题可能表明数据库正以最大限度运行，是时候给数据库添加额外的容量(capacity)了。尤其是，应用程序的工作集应该有足够的物理内存。 \r","date":"2017-12-11","objectID":"/mongodb/:20:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"锁紧性能(lock performance) MongoDB使用锁系统来确保数据集的一致性。如果某些操作需要长时间运行(long-running)，或队列窗体，随着请求和操作等待lock，性能将会下降； 锁相关的减速是可以间歇的，可查看lock部分是否影响了性能； locak.deadlockCount提供了遭遇死锁(deadlocks)的次数； 如果globalLock.currentQueue.total很高，则可能有大量的请求在等待lock。这表明并发问题(concurrency issue)可能影响性能； 如果globalLock.totalTime时间比uptime高，那么数据库在锁定状态中存在了大量时间； 长查询(long query)可能会导致索引无效使用、非最佳(non-optimal)建构设计、差的查询结构、系统体系结构问题、RAM不足导致页面错误(page fault)和磁盘读取。 \r","date":"2017-12-11","objectID":"/mongodb/:20:1","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"连接数(number of connections) 在某些情况下，应用程序和数据库之间的连接数量可能超出服务器处理请求的能力。serverStatus文档中的以下字段可以提供观察： globalLock.activeClients包含正在进行或排队的活动操作的客户端总数； connnections由以下两个字段组成： 1，connections.current连接到数据库实例的当前客户端总数； 2，connections.available可用的连接总数。 如果有大量的并发程序请求，则数据库可能无法满足需求。那么就需要增加部署的容量。 对于读操作巨大(read-heavy)的应用程序，增加你的副本集大小并将读操作分发给SECONDARY。 对于写操作巨大(write-heavy)的应用程序，部署分片并将一个或多个分片添加到分片集群中，以便在mongod实例之间分配负载。 连接数到达峰值也可能是应用程序或驱动错误所导致的结果。 除非收到系统范围的限制，否则MongoDB对传入连接没有限制。在基于Unix系统上，可使用ulimit命令或修改/etc/sysctl系统文件来修改系统限制。 ","date":"2017-12-11","objectID":"/mongodb/:20:2","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"数据库性能分析(database profiling) MongoDB的profiler是一种数据库分析系统，可以帮助识别低效的查询和操作。 有如下分析级别(profiling-level)可用： Level | Settiing | - 0 | Off.No profiling 1 | On.Only includes “slow” operations 2 | On.Includes all operations 在mongo shell中运行如下命令来配置性能分析器： #dbsetProfilingLever() db.setProfilingLevel(1) slowOpThresholdMs的设置定义了什么是一个slow操作，要设置一个慢操作的阈值(threshold)，可以在运行时作为db.setProfilingLevel()操作的一个参数来配置slowOpThresholdMs。 默认情况下，mongod将会把所有的慢查询(slow query)记录到日志，这是由slowOpThresholdMs定义的。 通过在mongo shell中使用show profile，你可以在数据库中的system.profile集合中查看性能分析器的输出。 或者执行如下操作： #返回超过100ms的所有操作，这个值请高于阈值`slowOpThresholdMs` db.system.profile.find( { millis: { $gt: 100 } } ) 你必须使用查询操作符去访问system.profile文档中的查询字段。 ","date":"2017-12-11","objectID":"/mongodb/:20:3","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"数据库性能分析器(databases profiler) 数据库性能分析器(db profiler)收集有关MongoDB的写操作、游标和运行在mongod实例上的命令的细微数据，你可以在每个数据库或每个实例基础上启用性能分析(profiling)。默认情况系，分析器是关闭的。启用profiling的时候需要配置profiling leverl。 The database profiler将所有的数据收集到system.profile集合中，它是一个限制集(capped collection)。 \r分析等级(Profiling levels) 0， 关闭分析器，不收集任何数据。mongod总是将操作时间长于slowOpThresholdMs的值写入日志。这是默认分析器级别； 1， 只收集慢操作的分析数据。默认是以100ms； 2， 收集所有数据库操作的分析数据。 \r启用分析器(profiling)和设置分析级别(profiling level) 当启用profiling，也要设置profiling level，分析器将数据记录到system.profile集合。当你在数据库中启用profiling后，MongoDB会在数据库中创建system.profile集合。 使用db.setProfilingLevel()来设置profiling level和启用profiling。 db.setProfilingLevel(1) 指定慢操作的阈值(the Threshold for slow operations) 慢操作的阈值(threshold)应用于整个mongod实例。当你修改了阈值，那你就对所有的数据库实例进行了修改。修改了数据库慢操作的阈值同样也会影响整个mongod实例性能分析子系统的慢操作阈值。 默认情况下，慢操作的阈值为100ms。性能分析level-1将会记录长于阈值的慢操作到日志。 要更改阈值，请将两个参数(parameter)在mongo shell传递给db.setProfilingLevel()。第一个参数是为当前的数据库设置profiling level，第二个参数是为整个mongod实例设置默认的慢操作阈值。 栗子： mongo \u003euse zhang \u003edb.serProfilingLevel(1,100) #会在zhang数据库下生产system.profile集合 \r检查分析等级(check profiling level) db.getProfilingStatus() #default #{ \"was\" : 0, \"slowms\" : 100 } db.getProfilingLevel() #0 \r为一个完整的mongod实例启用profiling 在测试环境中，处于开发目的，你可以为一个完整的mongod实例启用profiling功能。性能分析等级应用于mongod实例中的所有数据库。 #设置level：1，slowOpThresholdMs: 50 mongod --profile 1 --slowms 50 \r数据库分析和分片 无法对mongos实例启用profiling。要对分片集群启用profiling功能，你必须对分片集群中的每个mongod实例启用profiling功能才行。 查看性能分析器的数据(profiler data) 数据库性能分析器关于数据库操作的日志信息放置于system.profile集合中。如需查看性能信息，请查询该集合。 栗子： db.system.profile.find() db.system.profile.find().limit(10).sort({ ts: -1 }).pretty() #指定时间 db.system.profile.find( { millis: { $gt: 5 } } ).pretty() #除了某个命令外 db.system.profile.find({ op: { $ne: 'cmd' } }).pretty #某个特定集合 db.system.profile.find( { ns: 'db.collection' } ).pretty() #显示最近的事件 show profile \r分析器开销(profiler overhead) 分析器对性能影响很小。system.profile集合是一个默认大小为1MB的限制集。这样大小的集合通常可以存储上千份分析文档，但一些应用程序可能在每次操作中只使用或多或少的分析数据。 \r在Primary上面修改system.profile集合的大小 停止profiling； 删除(drop)system.profile集合； 新建一个system.profile集合； 重启profiling。 use db db.serProfilingLevel(0) db.system.profile.drop() db.createCollection( \"system.profile\", { capped: true, size: 4000000 } ) db.setProfilingLevel(1) 在Secondary上修改system.profile集合的大小 在Secondary上修改system.profile集合的大小，你必须停止Secondary，然后以standalone模式运行它，之后执行修改步骤。当做完上述步骤之后，以一个副本集成员的方式使用standalone模式重启它。 \r","date":"2017-12-11","objectID":"/mongodb/:20:4","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"禁用显见的大页面(Disable Transparent Huge Pages) Transpatent Huge Pages(THP)是一个Linux的内存管理系统，通过使用更大的内存页，减少了在具有大量内存的机器上进行Translation Lookaside Buffer(TLB)查找的开销。 然而，数据库工作负载(workload)在THP中的性能往往很差，因为它们往往具有稀疏的(sparse)而不是连续的(contiguous)内存访问模式。你应该在Linux机器上禁用THP来确保MongoDB获得最佳的性能。 1. 创建init.d脚本 #!/bin/bash ### BEGIN INIT INFO # Provides: disable-transparent-hugepages # Required-Start: $local_fs # Required-Stop: # X-Start-Before: mongod mongodb-mms-automation-agent # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: Disable Linux transparent huge pages # Description: Disable Linux transparent huge pages, to improve # database performance. ### END INIT INFO case $1 in start) if [ -d /sys/kernel/mm/transparent_hugepage ]; then thp_path=/sys/kernel/mm/transparent_hugepage elif [ -d /sys/kernel/mm/redhat_transparent_hugepage ]; then thp_path=/sys/kernel/mm/redhat_transparent_hugepage else return 0 fi echo 'never' \u003e ${thp_path}/enabled echo 'never' \u003e ${thp_path}/defrag re='^[0-1]+$' if [[ $(cat ${thp_path}/khugepaged/defrag) =~ $re ]] then # RHEL 7 echo 0 \u003e ${thp_path}/khugepaged/defrag else # RHEL 6 echo 'no' \u003e ${thp_path}/khugepaged/defrag fi unset re unset thp_path ;; esac 2. 使之可执行 chmod 755 /etc/init.d/disable-transparent-hugepages 3. 配置操作系统以在开机的时候运行它 #Debian系列 update-rc.d disable-transparent-hugepages defaults #RedHat系列 chkconfig --add disable-transparent-hugepages #SUSE insserv /etc/init.d/disable-transparent-hugepages 4. 如果适用，覆盖(override)tuned和ktune #RedHat/CentOS7 mkdir /etc/tuned/no-thp vim /etc/tuned/no-thp/tuned.conf [main] include=virtual-guest [vm] transparent_hugepages=never tuned-adm profile no-thp 5. 测试你做的改变 cat /sys/kernel/mm/redhat_transparent_hugepage/enabled cat /sys/kernel/mm/redhat_transparent_hugepage/defrag #always madvise [never] 另一种简便的方式来禁用THP vim /etc/rc.d/rc.local echo 'never' \u003e /sys/kernel/mm/transparent_hugepage/enabled echo 'never' \u003e /sys/kernel/mm/transparent_hugepage/defrag chmod u+x /etc/rc.d/rc.local \r","date":"2017-12-11","objectID":"/mongodb/:20:5","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Unix系统下的ulimit的设置 大多Unix-Like系统，都提供了限制每个进程和每个基本用户使用线程，文件和网络连接等系统资源的一些方法。 ulimits防止单个用户使用太多的系统资源。有时，这些限制的默认值太小，这会导致MongoDB操作过程中出现一系列问题。 #限制文件 #/etc/security/limits.conf #/etc/security/limits.d/ \r资源利用 mongod和mongos每次使用线程和文件描述符来跟踪连接和管理内部操作。 通常情况下，所有的mongod和mongos实例： 利用每一个文件描述符和线程来跟踪每个即将到来的连接； 将每个内部线程或pthread作为一个系统进程来跟踪。 mongod mongod实例使用的每个数据文件都有一个文件描述符； 当storage.journal.enabled为true是，mongod进程实例使用的每个日志文件都有一个文件描述符； 在复制集中，每个mongod保持一个连接复制集中所有其他集合成员的连接。 mongos mongos实例与每个分片都保持一个连接池，所有mongos可以重用连接，这样因为不用建立新连接，从而能快速的满足请求； 通过限制连接数，可以防止mongos因在mongod实例上创建太多连接而产生级联效应。 资源限制的设置 ulimit是指每个user使用各种资源的限制值。因此，无论你的mongod实例是以单个用户多进程执行还是以多mongod进程执行，都可以看到对这些资源的连接。 ulimits有hard和soft两个方式。 hard：是指用户在任何时候都可以活动的进程的最大数量，这是上限。没有任何non-root进程能够增加hard ulimit； soft：是对会话或进程实际执行的限制，但任何进程都可以将其增加到hard ulimit的最大值。 较低的soft limit可能无法创建新线程(thread)，如果连接数太高，则关闭错误连接。因此，将soft和hard的值都设置为推荐值是非常重要的。 修改ulimit设置之后，要重启程序修改值才会有效。可通过/proc文件系统查看运行进程当前的限制值。 使用ulimit对系统限制的改变在系统重启后都会恢复到默认值。需要修改其它文件来确保修改一直生效。 ulimit ulimit -a core file size (blocks, -c) 0 data seg size (kbytes, -d) unlimited scheduling priority (-e) 0 file size (blocks, -f) unlimited pending signals (-i) 7170 max locked memory (kbytes, -l) 64 max memory size (kbytes, -m) unlimited open files (-n) 1024 pipe size (512 bytes, -p) 8 POSIX message queues (bytes, -q) 819200 real-time priority (-r) 0 stack size (kbytes, -s) 8192 cpu time (seconds, -t) unlimited max user processes (-u) 7170 virtual memory (kbytes, -v) unlimited file locks (-x) unlimited 修改ulimit #-f (文件大小) #-t (cpu 时间) #-v (虚拟内存) #-n (单个进程文件打开数) #-m (memory size) #-u (可打开的进程/线程) ulimit -t unlimited ulimit -u 64000 ","date":"2017-12-11","objectID":"/mongodb/:20:6","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"配置和维护(maintenance) ","date":"2017-12-11","objectID":"/mongodb/:21:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Run-time databases configuration command line和configuration file interfaces为MongoDB管理员提供了控制数据库系统操作的大量选项和设置。 使用配置文件启动MongoDB实例： mongod --config /etc/mongod.conf mongod -f /etc/mongod.conf 配置数据库 mongodb的配置文件从MongoDB3.0以后使用YAML格式。 vim /etc/mongod.conf processManagement: fork: true net: bindIp: 127.0.0.1 port: 27017 storage: dbPath: /var/lib/mongodb systemLog: destination: file path: \"/var/log/mongodb/mongod.log\" logAppend: true storage: journal: enabled: true 对于大多数以standalone模式运行的servers，以上是一个足够的基本配置。 Unix-Like操作系统需要以超级用户(root)权限才能运行端口小于1024的程序。 安全考虑(security consideration) 下面的配置选项集合对于限制对于mongod实例的访问非常有用。 net: port: 27017 bindIp: 127.0.0.1,192.168.1.11 security: authorization: enabled 复制集和分片配置(replication and sharding configuration) 复制集的配置非常简单，只需要replSetName在集合中的所有成员具有一致的副本集名字。 replication: replSetName: zhang 开启副本集认证： #利用openssl生成keyFile openssl rand -base64 256 \u003e /dir/path/mongodb/keyFile security: replSetName: zhang keyFile: /dir/path/mongodb/keyfile chown -R mongod:mongod /dir/path/mongodb 设置keyFile启用身份认证，并为复制集成员在相互身份认证时使用的认证文件指定一个密钥文件。密钥文件的内容是任意的，但在复制集中的所有成员和连接到该集合的mongos实例之间必须相同。不然怎么能认证通过呢。 秘钥文件的大小必须小于1KB，并且只能包含base64集中的字符，并且此密钥文件在Unix系统上必须not have group或not have world permissions。 分片配置(sharding configuration) 分片要求配置服务器和分片服务器的Mongod实例具有不同的mongod配置文件。配置服务器存储集群的元数据(metadata)，而分片服务器存储数据(data)。 在配置文件中给mongod实例配置配置服务器(config-server)，给sharding.clusterRole指定配置服务器。 #配置config-server net: bindIp: 192.168.1.11 port:27001 replication: replSetName: zhang sharding: clusterRole: configserver #configserver必须要是一个部署的副本集 在同一个系统上运行多个数据库实例(multiple database instances) 在许多情况下，在单个系统(single system)上运行多个数据库实例是不推荐的。 但可能由于一些部署或者测试的目的，你需要在单个系统上运行多个mongod实例。在这些情况下，请为每一个mongod实例使用一个基本的配置文件，但要额外配置如下值： dbpath(必须); pidFilePath(必须); systemLog(非必须，但建议开启); 栗子： #mongod_27017实例 vim /etc/mongod_27017.conf systemLog: path: /var/log/mongod_27017.log storage: dbPath: /var/lib/mongodb27017 processManagement: pidFilePath: /var/lib/mongodb27017/mongod_27017.pid #mongod_27018实例 vim /etc/mongod_27018.conf systemLog: path: /var/log/mongod_27018.log storage: dbPath: /var/lib/mongodb27018 processManagement: pidFilePath: /var/lib/mongodb27018/mongod_27018.pid ##启动实例 mongod -f /etc/mongod_27017.conf mongod -f /etc/mongod_27018.conf \r诊断配置(diagnostic configuration) 以下配置选项可控制各种mongod行为，用以诊断的目的： operationProfiling.mode设置database profiler level。profiler在默认情况下不处于活动状态，因为它本身可能会影响性能。除非启用它，否则不会对查询进行分析； operationProfiling.slowOpThresholdMs配置慢操作的阈值以确定查询是否慢，用以作为分析器记录日志的目的。默认阈值是100ms； systemLog.verbosity控制mongod写入日志的日志输出量。只有在遇到未在正常日志记录级别中反映的问题是才启用此选项。 ","date":"2017-12-11","objectID":"/mongodb/:21:1","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"升级(upgrade)到最新的MongoDB 修订(revisions)提供了security patches、bug fixes以及不包含任何反向破坏更改的新的或更改的功能。但是，最新版本也可能存在一些兼容性问题，请注意。 \r升级之前(before upgrading) 确保备份了最新的数据集； 有关特定MongoDb版本的特殊事项和兼容性问题，请注意查看； 如果你的安装包包括了复制集，在升级期间预定维护窗口(maintanence window)。 \r升级程序(upgrade procedure) 在升级之前请一定要备份所有数据！ 按照如下步骤升级： 对于使用认证的部署，首先升级所有的MongoDB drivers； 升级分片集群； 升级任一standalone实例； 升级不属于分片集群的任一副本集。 \r升级一个MongoDB实例 要升级mongod或mongos实例，使用如下方法之一： 使用操作系统的包管理工具和官方MongoDB包进行升级(推荐的方法)； 使用新二进制文件替换现有二进制文件来升级实例。 \r替换现有二级制文件(replace the existing binaries) 在升级MongoDB前请一定备份你的所有数据！ 首选的升级方式是使用包管理工具和官方的MongoDB包。 通过替换现有二进制文件来升级mongod或mongos实例，执行如下操作： 下载最新MongoDB二进制文件到本地，并解压缩到MongoDB安装目录； 关闭实例； 替换二进制文件； 重启实例。 \r升级分片集群 禁用分片集群的平衡器(blancer)； 升级配置服务器(config-server)； 升级每个分片； 升级每个mongos实例； 重新启用平衡器。 \r升级复制集 若要升级复制集，请单独升级每个副本集成员。从Secondary开始，最后以Primary结束。 升级SECONDARY 升级SECONDARY的mongod实例； 升级一个Secondary之后，在升级下一个实例之前，请等待Secondary恢复(recover)到SECONDARY state。使用rs.status()命令来检查复制集成员的状态。 升级PRIMARY 使用rs.stepDown命令来退出primary，以启动正常的故障转移过程； 查看是否有另外的SECONDARY节点成为了PRIMARY节点； 关闭并升级实例。 \r","date":"2017-12-11","objectID":"/mongodb/:21:2","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"管理mongod进程 开启mongod进程 mongod #指定数据目录 mongod --dbpath /dir/mongodb/ #指定TCP端口 mondod --port 12345 #将mongod以守护进程的方式启动 mongod --fork --logpath /var/log/mongod.log #其他选项 mongod --help \r停止mongod进程 #使用shutdownServer() use admin db.shutdownServer() #使用--shutdown mongod --shutdown #使用ctrl+c ctrl+c #使用kill #千万不要使用kill -9(SIGKILL)来终止mongod kill mongod_pid kill -2 mongod_pid \r停止一个复制集 步骤： 检查SECONDARY的oplog的时间戳； 如果从节点的时间戳落后于主节点10s内，mongod将会返回不会被关闭的消息。你可以传递一个timeoutSecs参数给shutdown命令来等待从节点追上主节点； 一旦从节点追上进度或60s后，主节点将会关闭。 强制关闭复制集：db.adminCommand( { shutdown: 1, force: true } ) 如果没有节点能立刻更新到最新的数据，发送shutdown加上timeoutSecs参数来在指定的时间内保持对从节点的检查。如果在分配的时间内有任意的一个从节点追上，主节点将会关闭。反之，主节点不会关闭。 db.adminCommand({ shutdown: 1, timeoutSecs: 5 }) #或 db.shutdownServer({ timeoutSecs: 5}) \r","date":"2017-12-11","objectID":"/mongodb/:21:3","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"终止(Terminate)运行的操作 MongoDB提供了两种方法来终止正在运行的操作。 maxTimeMS() db.killOp() maxTimeMS() maxTimeMS()方法给一个操作(operation)设置了时间限制(time limit)。这个时间单位默认是毫秒(ms)。当这个操作达到了指定的时间限制时，MongoDB将在下一个中断点(interrupt point)中断这个操作。 栗子： db.location.find( { \"town\": { \"$regex\": \"(Pine Lumber)\", \"$options\": 'i' } } ).maxTimeMS(30) db.runCommand( { distinct: \"collection\", key: \"city\", maxTimeMS: 45 } ) \rkillOp killOp()方法将在下一个中断节点中断正在运行的操作。killOp()方法通过操作ID(operation ID)来标识目标操作。 栗子： db.killOp(\u003copID\u003e) #查看正在运行的操作 db.currentOp() 注意： 终止正在运行的操作时一定要谨慎！只使用db.killOp()方法来终止由客户端发起的操作，而不要终止内部数据库(internal database)的操作。 \r","date":"2017-12-11","objectID":"/mongodb/:21:4","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"轮询(rotate)日志文件 当使用--logpath选项或systemLog.path设置时，mongod或mongos实例会将所有活动和操作的实时账户报告给日志文件。默认情况下，只有当使用了logRotate命令，或者mongod或mongos进程从操作系统接收到一个SIGUSR1信号时，才会进行日志轮询响应。 MongoDB的标准日志轮询方法会存档当前日志文件并启动一个新的日志文件。为此，mongod或mongos实例将通过ISODate日期格式的UTC时间戳来重命名当前日志文件。然后它会打开一个新的日志文件，关闭旧的日志文件，并将所有新的日志发送到新的日志文件。 你也可以通过配置MongoDB的systemLog.logRatate或--logRotate选项，来支持Unix/Linux的日志轮询功能。 最后，你可以使用--syslog选项来配置mongod发送日志数据到系统日志。在这种情况下，你可以选用其他的日志轮询工具。 默认日志轮询行为 在mongo shell中轮询日志： #开启一个实例 mongod -v --logpath /var/log/mongodb/test01.log #列出日志文件 ls /var/log/mongodb/test01.log* #轮询日志文件 mongo \u003euse admin \u003edb.runCommand({ logRotate: 1 }) #查看新的日志文件 ls /var/log/mongodb/test01.log* #new: test01.log #old: test01.log-2018-01-11T08-22-50 使用--logRotate reopen选项轮询日志： mongod -v --logpath /var/log/mongodb/test01.log --logRotate reopen --logapend ls /var/log/mongodb/test01.log* mongo \u003euse admin \u003edb.runCommand({ logRotate: 1 }) \r系统日志轮询(Syslog log rotate) mongod --syslog \r使用SIGUSR1强制日志轮询 对于基于Unix/Linux的系统，可以使用SIGUSR1信号来轮询单个进程的日志。 kill -SIGUSR1 \u003cmongod-pid\u003e \r","date":"2017-12-11","objectID":"/mongodb/:21:5","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"数据中心意识(data center awareness) ","date":"2017-12-11","objectID":"/mongodb/:22:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"MongoDB部署中的分离(segregation)操作 MongoDB拥有许多特性，包括允许数据库管理员和开发者在部署数据库的过程中通过一些功能或地理组群对数据库应用进行分割操作。 MongoDB支持跨越不同维度的操作的分段，这可能包括了在单个数据中心(single data center)的部署中的多数据中心(multi-date center)部署、机架、网络或电源电路的多个数据中心和地理区域。 MongoDB还支持基于功能或操作参数的数据库分离操作，以确保某些mongod实例仅用于报告工作负载，或只在特定的分片上分离集合的某些高频部分。 特别是在MongoDB中你可以： 确保写操作传播到复制集的特定成员； 确保复制集中的特定成员响应了查询操作； 确保分片键在具体范围上的平衡，并且驻留在特定的分片上。 ","date":"2017-12-11","objectID":"/mongodb/:22:1","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"区域(zone) 管理分片区域(manage shard zones) 按位置分割数据(segementing data by location) \r为SLA或SLO改变分层硬件 按应用程序或客户分割数据 \rDistributed Local Writes for Insert Only Workloads \r管理分片区域 \r","date":"2017-12-11","objectID":"/mongodb/:22:2","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"MongoDB备份方案(backup methods) 在生存中部署MongoDB时，如果发生数据丢失的事件，你应该指定一个捕获和恢复备份的策略(strategy)。 \rback up with MongoDB cloud manager or Ops manager MongoDB Cloud Manager Ops Manager 复制底层数据文件进行备份(back up by copying underlying data files) 使用文件系统快照备份(back up with filesystem snapshots) 你可以通过复制MongoDB的底层数据文件来创建MongoDB部署的备份。 如果MongoDB储存其数据文件的卷(volume)支持时间点快照(point-in-time snapshots)，则可以使用这些快照在某个时刻创建MongoDB系统的备份。 文件系统的快照是一个操作系统的卷管理器的功能，并没有具体到MongoDB。通过文件系统快照，操作系统将卷的快照用作数据备份的基准。快照的机制取决于底层的存储系统。 例如，在Linux上，逻辑卷管理器(LVM)可以创建快照。 要获得运行中的MongoDB进程的正确快照，必须启用日志记录(jorunaling)，并且日志必须与其它MongoDB数据文件存储在相同的逻辑卷上。如果没有启用日志记录，则无法保证快照将是一致有效地。 为了获得分片集群一致的快照，你必须禁用平衡器(balancer)和捕捉每一个分片的快照以及大约在同一时刻的配置服务器。 使用cp或scp备份 如果你的系统不支持快照功能，则可以使用cp，rsync或类似的工具直接复制文件。 由于复制多个文件不是原子操作，因此你必须在复制文件之前停止对mongod的所有写入。否则，你将复制处于无效状态的文件。 复制底层数据而产生的备份不支持复制集的时间恢复节点，并且难以管理更大的共享集群。此外，这些备份很大。因为它们包括索引和复制底层存储填充和分片。 相反，mongodump会创建较小的备份。 使用mongodump备份 如果在mongodump创建备份的同时，应用程序对数据进行修改，那么mongodump将会与这些应用竞争资源。 mongodump从一个MongoDB数据库中读取数据，并创建高保真度(high fidelity)的BSON文件。mongorestore工具可使用这个文件来进行MongoDB数据库恢复。 mongodump和mongorestore是用于备份和恢复小型MongoDB部署的简单和高效的工具，但对于捕获较大的系统并不理想。 mongodump和mongorestore针对正在运行的mongod进程进行操作，可以直接操纵底层的数据文件。默认情况下，mongodump不会捕获local database数据库的内容。 mongodump只捕获数据库中的文档(documents)，用以给备份节省空间，但mongorestore或mongod必须在恢复数据之后重建索引。 当连接到MongoDB实例时，mongodump可能会对MongoDB的性能产生不利影响。如果你的数据大小大于系统内存，查询可能会将工作单元从内存中推开，从而导致页面错误。 当mongodump在捕获输出时，应用程序可以继续修改数据。对于复制集来说，mongodump提供了--oplog选项来用以在mongodump操作期间包含数据的oplog条目。这允许相应的mongorestore操作去还原所捕获的oplog。 然而，对于复制集来说，请考虑使用MongoDB Cloud Manager 或 Ops Manager来备份。 \r","date":"2017-12-11","objectID":"/mongodb/:23:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"使用文件系统快照进行备份和恢复(back up and restore with filesystem snapshots) 使用系统工具创建MongoDB系统的备份，诸如LVM，或block-level备份方法。使用系统工具来创建MongoDB数据文件的设备的副本。这些方法完成迅速、工作可靠，但是需要在MongoDB之外进行额外的系统配置。 \r快照综述(snapshots overview) 快照的工作方式是在实时数据(live data)和一个特定快照卷之间创建指针(pointer)。这个指针在理论上等同于硬链接(hard link)。作为工作数据偏离的快照，快照过程使用写时复制(copy-on-write)策略。结果，快照又只存储修改的数据。 创建快照后，在文件系统上挂载(mount)快照镜像，并从中复制数据。生成的备份包含所有数据的完整副本。 \rValid database at the time of snapshot 当快照生成时数据库必须有效。这就意味着数据库所接收的所有写入(write)都需要完整的写入磁盘————无论是journal还是数据文件。 如果备份发生时磁盘上没有写入(write)，备份将不反映这些更改。 对于WiredTiger storage engine，数据文件反映了最后一个检查点(last checkpoint)的一致状态。每2GB的数据或每分钟就会出现检查点。 \rEntire disk image 快照创建一个整个磁盘镜像的镜像。除非你需要备份你的整个系统，否则考虑隔离(isolate)你的MongoDB数据文件、journal，并配置一个不包含任何其他数据的逻辑磁盘。 或者，将所有的MongoDB数据文件保存在一个专用的设备上，这样你就可以在没有重复(duplicating)和无关(extraneous)数据的情况下进行备份。 \rSite failure precaution 确保将数据从快照复制到其他系统。这确保了在站点故障(site failure)的时候数据是安全的。 No incremental backups 本教程不包含增量备份(incremental backups)的过程。虽然不同的快照方法提供了不同的功能，但下面列出的LVM方法不提供捕获增量备份的任何容量。 Snapshots with journaling 如果你的mongod实例启用了journaling，则可以使用任何类型的文件系统和volume/block level快照工具来创建备份。 如果你在基于Linux的系统上管理你自己的基础架构，请使用LVM配置你的系统以提供磁盘包并提供快照功能。 在Linux上使用LVM进行备份和还原 生产备份系统必须考虑一些特定环境的应用程序特定需求和因素。 \rCrete a snapshot 确保你创建的快照具有足够的空间来考虑数据的增长； 如果快照超出了空间，快照镜像将无法使用。请放弃这个逻辑卷并创建另外一个； 命令执行完毕时快照将存在。你可以随时直接从快照进行还原，也可以创建新的逻辑卷并从此快照还原到备用镜像； 虽然快照对于快速创建高质量的备份非常好，但它们并不是理想的作为存储备份数据的格式； 快照通常取决于并位于与原始磁盘镜像相同的存储基础架构上。因此，将这些快照存档并将其存储在别处至关重要。 #下面的这个vg-name指卷组名，这个卷组首先需要建立 #系统卷组和设备的位置和路径可能因LVM的配置二略有不同 #此大小不反映数据大小 lvcreate --size 1G --snapshot --name mongodb-snap20180111 /dev/vg-name/mongodb Archive a snapshot 创建好snapshot之后，挂载mount快照并将数据复制到单独的存储中。 压缩快照： umount /dev/vg-name/mongodb-snap01 dd if=/dev/vg-name/mongodb-snap01 | gzip \u003e mongodb-snap01.gz \rRestore a snapshot 同样适用LVM进行还原。 #lv-mongodb, vg0-vgname lvcreate --size 1G --name mongodb vg0 gzip -d -c mongodb-snap01.gz | dd of=/dev/vg0/mongodb mount /dev/bg0/mongodb /dir/path 还原的快照中有一个陈旧的mongo.lock文件，如果你没有从快照中删除此文件，那么MongoDB可能会认为锁文件指示的是不正常的关闭。如果你开启了storage.journal.enabled，但没有使用db.fsyncLock()的话，那不需要删除mongo.lock文件，反之，删除它。 \rRestore directly form a snapshot 不使用gz压缩文件下还原备份。 umount /dev/vg-name/mongodb-snap01 lvcreate --size 1G --name mongodb vg0 dd if=/dev/vg0/mongodb-snap01 of=/dev/vg0/mongodb mount /dev/vg0/mongodb /dir/path \rRemote backup storage 可以使用组合的进程和SSH实施离线备份。 umount /dev/vg-name/mongodb-snap01 dd if=/dev/vg0/mongodb-snap01 | ssh user@host gzip \u003e /dir/path/mongodb-snap01.gz lvcreate --size 1G --name mongodb vg0 ssh user@host gzip -d -c /dir/path/mongodb-snap-01.gz | dd of =/dev/vg0/mongodb mount /dev/vg0/mongodb /dir/path \r使用单独卷上的Journal日志文件或没有Journal日志文件进行备份实例 从MongoDB3.2开始，为了使用WiredTiger对MongoDB实例进行volume-level备份，数据文件和Journal日志文件不再要求驻留在一个卷上。 如果你的mongod实例没有使用Journal，或者启用了将Journal志文件放置于一个单独的卷上，则必须刷新(flush)对磁盘的所有写入，并在备份期间锁住数据库用以阻止写操作。 如果有复制集(replica set)配置，那么你可以在SECONDARY上不接收读取用以备份数据。 1. 刷新写入磁盘并锁定数据库以防止进一步的写入： #锁住数据库 db.fsyncLock(); 2. 使用快照备份数据库： 3. 解锁数据库： #解锁数据库 db.fsyncUnlock(); \r","date":"2017-12-11","objectID":"/mongodb/:23:1","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"使用MongoDB工具进行备份和恢复(back up and restore with MongoDB tools) 使用MongoDB提供的备份还原工具——mongodump和mongorestore来处理BSON data，对于创建小型部署的备份是很有用的。 对于弹性(resilient)备份和非破坏性(non-disruptive)备份，使用文件系统或块级磁盘快照。 因为mongodump和mongorestore操作通过与正在运行中的mongod实例进行交互(interacting)，它们会影响正在运行的数据库的性能(performance)。这些工具不仅会为正在运行的数据库实例创建流量，还会强制数据库通过内存读取所有的数据。当MongoDB读取不经常(infrequently)使用的数据时，它会驱逐(evict)频繁(frequently)访问的数据，导致数据库正常工作负载的性能下降。 当使用MongoDB’s tools 来备份你的数据时，考虑如下建议： 标签文件(label file)，以便你可以识别备份的内容以及备份所反映的时间点 如果对你来说，mongodump和mongorestore对性能的影响是不可接受的，请使用替代备份策略——filesystem snapshot或MongoDB CloudManager 使用--oplog去捕获在mongodump期间的传入写(write)操作，以确保备份一致性的数据状态 通过将备份文件还原到测试环境中，以确认备份是可用的 MongoDB tools MongoDB工具介绍及区别： mongoexport mongoexport is a utility that produces a JSON or CSV export of data stored in a MongoDB instance. mongoimport The mongoimport tool imports content from an Extended JSON, CSV, or TSV export created by mongoexport, or potentially, another third-party export tool. mongodump mongodump is a utility for creating a binary export of the contents of a database. mongodump can export data from either mongod or mongos instances. mongodump excludes the content of the local database in its output. The mongodump utility backs up data by connecting to a running mongod or mongos instance. mongorestore The mongorestore program writes data from a binary database dump created by mongodump to a MongoDB instance. 步骤(Procedures) 使用mongodump备份 `mongodump·备份数据库，如果数据库启用了访问控制，则必须拥有每个备份的数据库查询的权限。内置的备份角色提供了执行任何和数据库备份有关所需的权限。 这就意味着你使用mongodump的user必须要对所备份的数据库有读取权限。 mongodump能够为整个服务器、数据库或集合创建备份，或者使用查询仅备份集合的一部分。 mongodump默认排除local数据库。 mongodump必须要能够连接到正在运行的mongod或mongos实例。默认连接为127.0.0.1:27017。 mongodump默认创建在当前目录下创建./dump备份文件。 如果mongodump备份目录中已经存在备份数据目录，那么mongodump将会覆盖它们。 指定认证库来认证你的用户名和密码。 \r使用oplog进行时间点操作 在mongodump中使用--oplog选项来收集oplog条目，用以在副本集中构建数据库的实时快照。 使用--oplog，mongodump会从源数据库复制所有的数据，包括备份开始到结束这段时间所有的oplog记录。 在mongorestore还原时使用--oplogReplay选项，允许你还原特定时间节点的备份。这就对应在mongodump期间oplog的记录。 #127.0.0.1:27017 ./dump mongodump #--host,-h --port mongodump -h mongodb.example.net --port 27107 mongudump -h 127.0.0.1 --port 27018 #-o, --out mongoodump -o /var/mongodb_backup/ mongodump --host 127.0.0.1 --port 27017 --out /var/mongodb_backup/ #--collection, --db mongodump --db zhang --out /var/mongodb_backup/zhang mongodump --db zhang --collection test #--authenticationDatabase mongodump --port 27018 -u zhang -p \"passwd\" --authenticationDatabase admin -d zhang -o /var/mongodb_backup/zhang 使用mongorestore还原 若要将数据还原到启用了访问控制的MongoDB部署，如果备份数据不包括system.profile集合数据，则restore角色提供了对数据库的访问权限。 如果备份数据包含了system.profile集合并且目标数据库不包含system.profile集合，那么mongorestore会去创建这个集合即使mongorestore并没有还原system.profile文档。因此，用户就需要额外的权限才能在system.profile集合中上执行createCollection和convertToCapped。 如果使用--oplogReplay，这个restore角色还不足以重放oplog。所以如果需要重放oplog，请使用一个能够重放oplog的角色。 mongorestore /var/mnogodb_backup mongorestore /var/mnogodb_backup --oplogReplay mongorestore --port 27018 -u zhang -p \"passwd\" --authecticationDatabase admin -d zhang /var/mongodb_back/zhang \r批量化操作mongo shell(EOF) for coll in {collection1,collection2,...} do mongo host:port/db -u x -p xx \u003c\u003c EOF use db db.$coll.drop() EOF done \r","date":"2017-12-11","objectID":"/mongodb/:23:2","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"从MongoDB备份中还原副本集 你不能将单个数据集(data set)还原为三个新的mongod实例，然后为此创建一个副本集(replication set)。 如果你将数据集复制到每个mongod实例，然后创建副本集，则MongoDB将强制SECONDARY执行initial sync。 向一个单一副本集节点中还原数据(Restore Database into a Single Node Replica Set) 获取备份数据库文件 使用备份数据库文件作为数据库路径启动一个mongod实例 #方法1，直接启动 mongod --dbpath /dir/path/mongodump --replSet \u003creplName\u003e #方法2，使用配置文件启动，推荐 vim /etc/mongod.conf storage: dbPath: /dir/path/mongodump replication: replSetName: zhang 连接到mongo shell 初始化这个新的副本集 #对于有且仅有一个成员的副本集使用rs.initiate() rs.initiate() \r向副本集中添加成员(Add Members to the Replica Set) MongoDB对于还原副本集SECONDARY节点提供了两种选择： 手动复制数据库文件到数据目录 允许initial sync 建议： 如果备份的数据库文件很大，那么initial sync可能需要很长的时间才能完成。对于大型数据库，最好将数据库文件复制到每台主机上。 Copy Database File and Restart mongod Instance Shut down the mongod instance that you restored 使用 --shutdown 或 db.shutdownServer()来确保一个正常干净的关闭 复制Primary的数据目录到每个从节点 Start the mongod instance that you restorerd Add the secondaries to the replica set PRIMARY\u003ers.add() \rUpdate Secondaries using Initial Sync 确保副本集成员的数据目录为空 将每个潜在成员添加到副本集 \r","date":"2017-12-11","objectID":"/mongodb/:23:3","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"备份和还原分片集群(sharded cluster) 通过文件系统快照(fs snapshots)备份一个分片集群 通过Database Dumps备份一个分片集群 Schedule Backup Window for Sharded Clusters \r还原一个分片集群 \r","date":"2017-12-11","objectID":"/mongodb/:23:4","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"从意外关闭中恢复(Recover a standalone after an unexpected shutdow) 当一个standalone模式的mongod实例关闭了journaling功能后，一个unclean的shutdown可能会导致数据处于不一致的状态。 当unclean shutdown之后，如果在dbPath下存在一个非空的mongod.lock文件，则mongod实例会记录如下信息： Dectected unclean shutdown - mongod.lock is not empty 这样的话你必须要修复你的数据库，才能正常的启动mongod。 警告： 不要用如下方法处理副本集 unclean shutdown。相反，你应该从备份或者从另一个副本集的成员恢复。 默认情况下，MongoDB在启用journaling的情况下运行，以防止发生unclean shutdown时数据不一致的问题。 使用运行mongod实例的那个用户来进行修复，避免由权限不一致而导致的新问题。 Create a backup of the data files Start mongod with –repair \r","date":"2017-12-11","objectID":"/mongodb/:23:5","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"监控(Monitoring)MongoDB 监控是数据库管理的重要组成部分，充分了解MongoDB的运行状态，并在没有危机的情况下维护和部署。此外，了解MongoDB的正常操作参数将允许你在问题升级成为故障前诊断他们。 ","date":"2017-12-11","objectID":"/mongodb/:24:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Monitoring for MongoDB \rMonitoring Strategies(策略) 有三种方法可以从运行中的MongoDB实例中收集状态信息： MongoDB提供的一组实时上报程序，提供数据库活动的实时报告； 数据库命令以更大的保真度返回有关当前数据库状态的统计信息； MongoDB Atlas，MongoDB Cloud Manager； 每个策略在不同的情况下都是很有用的，所以它们能够很好地进行互补。 MongoDB Reporting Tools Utilities MongoDB提供了许多可以返回活动统计信息的实用工具，这对于诊断问题和评估操作非常有用。 mongostat mongostat按类型捕获并返回数据库操作的计数(insert,query,update,delete…) mongotop mongotop通过类型捕获和返回数据库操作(insert,query,update,delete) \rCommands MongoDB包含了许多上报数据库状态的命令。这些命令可以提供比上面的实用程序更精细的粒度级别。考虑在脚本和程序中使用它们的输出来开发自定义警报。 db.currentOp方法是一个识别当前数据库实例正在进行的操作。 db.serverStatus() db.serverStatus()，返回数据库状态的一般概述，详细的磁盘使用，内存使用，连接，journaling日志和索引访问。它返回快速并不影响MongoDB性能。 db.stats() db.stats()，提供了database上的统计信息。返回使用的存储量，数据库包含的数据量及对象，collection和索引计数器。 db.collection.stats() db.collection.stats()，提供了collection上的统计信息。包含集合中的对象数量，结合大小，集合磁盘空间用量，索引信息。 rs.status() rs.status()，返回一个复制集状态的概述。 第三方工具 许多第三方(third party)工具支持对MongoDB的监控。 Nagios Zabbix Ganglia Motop … \r","date":"2017-12-11","objectID":"/mongodb/:24:1","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Monitor MongoDB with SNMP on Linux SNMP is only available in MongoDB Enterprise ","date":"2017-12-11","objectID":"/mongodb/:24:2","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Monitor MongoDB Windows with SNMP MongoDB索引 Indexes \r索引支持在MongoDB中高效地(effecient)执行查询。没有索引，MongoDB就必须采取collection scan。扫描每个集合中的每个文档，用以匹配查询。如果查询存在适当的索引，则MongoDB可以使用该索引来限制它必须检查的文档数量。 索引是特殊的数据结构，将集合数据集中的一小部分以易于遍历(traverse)的形式存储。索引存储特定字段或字段集的值，按字段值排序。索引条目的排序支持高效的相等匹配和基于范围的查询操作。除此之外，MongoDB可以使用索引中的排序返回排序后的结果。 从根本上来说(fundamentally)，MongoDB中的索引类似于其他数据库的索引。MongoDB在collection级别定义索引，并支持集合的文档的任何字段或子字段上的索引。 默认_id索引 在创建一个collection期间，MongoDB在_id字段上创建一个唯一的索引。你也可以自定义_id的值。你不能在_id字段上删除此索引。 创建一个索引 db.collection.createIndex方法只有在同一规范不存在时才创建索引。 db.collection.createIndex(\u003ckey and index type\u003e, option) 索引类型 MongoDB提供了许多不同的索引类型来支持特定类型的数据和查询。 Single Field 除了MongoDB定义的_id索引，MongoDB还支持在文档的单个字段上创建用户自定义的升序(ascending)/降序(descending)索引。 对于单字段索引和排序操作，MongoDB可以在任何方向遍历索引。 Compound(复合) Index MongoDB也支持多个字段的用户自定义索引。 Multikey Index MongoDB使用多键索引来索引存储在数组中的内容。 Geospatial(地理空间) Index 为了支持对地理空间坐标数据的有效查询，MongoDB提供了两个特殊的索引：2d index返回平面几何的2D索引；2dsphere index返回球形几何结果。 Text Index MongoDB提供了一个文本(text)类型索引，用以支持搜索集合中的字符串内容(string content)。 Hashed(散列) Index 为了支持基于散列的分片，MongoDB提供了散列索引类型，它索引字段值的散列值。但只支持相等的匹配，而不能支持基于范围的查询。 Index Properties(特性) Unique Index 索引的唯一性是MongoDB拒绝索引字段的重复值。 Partial Index 部分索引仅索引复合指定过滤器表达式的集合中的文档。 Sparse(稀疏) Index 索引的稀疏属性确保索引仅包含具有索引字段的文档的条目，跳过没有索引字段的文档。 TTL Index TTL索引是MongoDB可以用来在一定时间后自动从集合中删除文档的特殊索引。对于某些类型的消息，如机器生成的事件数据，日志和会话信息等，只需在数据库库中保存有限的时间，这是非常理想的。 Index Use 索引能够提高读操作的效率。 \rIndex and Collation 要使用索引进行字符串比较，操作还必须指定相同的排序规则。 **Coverd Query**\r当查询条件和查询投影仅包含索引字段时，MongoDB将直接从索引返回结果，而不扫描任何文档或将文档带入内存。\r","date":"2017-12-11","objectID":"/mongodb/:24:3","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Single Filed Index \r","date":"2017-12-11","objectID":"/mongodb/:25:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Compound Index \r","date":"2017-12-11","objectID":"/mongodb/:26:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Multikey Index \r","date":"2017-12-11","objectID":"/mongodb/:27:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Text Index ","date":"2017-12-11","objectID":"/mongodb/:28:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"2dsphere Index \r","date":"2017-12-11","objectID":"/mongodb/:29:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"2d Index \r","date":"2017-12-11","objectID":"/mongodb/:30:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"geoHaystack Index \r","date":"2017-12-11","objectID":"/mongodb/:31:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Hashed Index \r","date":"2017-12-11","objectID":"/mongodb/:32:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Index Property \r","date":"2017-12-11","objectID":"/mongodb/:33:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Index Build Operation on a Populated Collection \r","date":"2017-12-11","objectID":"/mongodb/:34:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Index Intersection \r","date":"2017-12-11","objectID":"/mongodb/:35:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Manage Index \r","date":"2017-12-11","objectID":"/mongodb/:36:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Measure Index Use \r","date":"2017-12-11","objectID":"/mongodb/:37:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Indexing Strategy \r","date":"2017-12-11","objectID":"/mongodb/:38:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Index Reference \rMongoDB存储 Storage \rFAQ: MongoDB Storage: https://docs.mongodb.com/v3.4/faq/storage/ 存储引擎(storage engine)是MongoDB管理数据库主要的组件。 journal日志，用于数据库不正常关闭时修复数据库。有几种可选的配置项，用以平衡数据库的性能和可用性。 GridFS是一个适合处理大文件的多功能的存储系统，例如那些超过16MB文档大小限制的文件。 \r","date":"2017-12-11","objectID":"/mongodb/:39:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Storage Engine 存储引擎是数据库的组件，负责管理数据库在内存(in-memory)和磁盘中(on-disk)两种存储方式。 由于不同的存储引擎在特定的工作负载下有更好的性能，所以，为你的应用程序选择一个适当的存储引擎会提高性能。 **WiredTiger**是从MongoDB3.2开始的默认存储引擎。它非常适合大多数工作负载，并推荐使用它来进行部署。WiredTiger提供了文档级并发模型，检查点和要说等特性。 **MMAPv1**是一个原始的MongoDB存储引擎，它是MongoDB3.2以前的默认存储引擎。它在大量读取和写入以及更新方面的工作负载表现良好。 **In-Memory**要在MongoDB Enterprise中才能获取。它不是将文档保存在磁盘上，而是将它们保留在内存中，以获得可预测的数据延迟。 \r","date":"2017-12-11","objectID":"/mongodb/:40:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"WiredTiger存储引擎 MongoDB3.2以后使用WiredTiger存储引擎作为默认存储引擎。 mongod --storageEngine wiredTiger #或 vim /etc/mongod.conf storage: engine: wriedTiger 文档级别并发(currency) WiredTiger使用文档级并发来控制写操作。因此，多个客户端可以同时修改一个集合中的不同文档。 对于大多数读写操作，WiredTiger使用乐观的并发控制。WiredTiger仅在global、database和collection-levels使用intent lock。 当存储引擎检测到两个操作之间的冲突时，其中一个操作将引发写冲突，从而导致MongoDB透明地重试该操作。 快照和检查点 WiredTiger users multiVersion Concurrency Control(MVCC).在操作开始时，WiredTiger向事务提供数据的实时快照。快照显示内存中数据的一致性视图。 当写入磁盘时，WiredTiger将快照中的所有数据以一致性的方式跨越所有数据文件写入磁盘。持久(durable)的数据充当数据文件中的检查点。检查点确保数据文件与最后一个检查点保持一致性，并包括最后一个检查点。 MongoDB配置WiredTiger来创建检查点(即将快照数据写入磁盘)，间隔时间为60s，或2G日志数据。 在写入新检查点期间，前一个检查点仍然有效。 当WiredTiger的元数据表被原子地更新以引用新的检查点，新的检查点将变得可访问和永久。一旦新检查点可以访问，WiredTiger就会从旧的检查点这种释放页面(free page)。 Journal WiredTiger采用预写事务日志联合检查点，用以确保数据的持久性(durability)。 你也可以关闭journal功能来减少维护日志的开销。 WiredTiger日志坚持在检查点之间修改所有数据。如果MongoDB在检查点之间退出，它将使用日志重放自上一个检查点以来修改的所有数据。 WiredTiger journal使用snappy compression Library来进行压缩。 WiredTiger最小日志记录的大小是128Byte，如果日志记录小于等于128Byte，则WiredTiger不会压缩日志文件。 对于以standalone模式运行的mongo实例，关闭journal日志功能意味着当MongoDB意外地在检查点之前退出时，你将丢失一些数据修改。对于复制集成员，复制过程和恒提供足够的持久性保证。 Compression 使用WiredTiger，MongoDB支持压缩所有的collections和indexes。通过使用CPU进行压缩，减少了储存空间的使用。 默认地，WiredTiger使用snappy compression library对所有的collections进行block压缩，对所有索引进行前缀(prefix)压缩。 对于collection，也可以使用zlib进行block压缩。可通过storage.wiredTiger.collectionConfig.blockCompressor设置压缩方法。 对于index，使用storage.wiredTiger.indexConfig.prefixCompression关闭prefix压缩。 对于大多数工作负载，默认压缩设置平衡了存储效率和处理要求。 Memory Use 对于WiredTiger，MongodB使用WiredTiger内部缓存和文件缓存。 从MongoDB3.4开始，WiredTiger内部缓存将使用一下两种类型中更大的一种： 50% of RAM minus 1GB 256MB WiredTiger内部缓存中的数据与磁盘上格式的数据使用不同的表现形式： 文件系统缓存的数据与磁盘上的格式相同，包括了对数据文件进行压缩的好处。操作系统使用文件系统缓存来减少磁盘I/O 指标加载在WiredTiger内部缓存有一个不同的磁盘上的数据表示格式，但仍然可利用 prefix index compression来减少内存使用。索引前缀压缩重复数据删除常用前缀的索引字段。 WiredTiger内存缓存的collection数据是未压缩的，并使用与磁盘格式不同的表现形式。block compression能够节省大量磁盘空间，但必须解压缩数据后服务器才能操作。 通过文件系统缓存，MongoDB自动使用 (WiredTiger缓存或其他进程不使用)空闲内存。 调整WiredTiger内部缓存的大小，避免将WiredTiger的内初缓存值增加到默认值之上。 #命令行 --wiredTigerCacheSizeGB #配置文件 storage.wiredTiger.engineConfig.cacheSizeGB Change Standalone to wiredTiger MongoDB version 3.0 or later in order to use wiredTiger storage engine! 过程： mongod is running export data using mongodump create a data directory for the new mongod running with wiredTiger start mongod with wiredTiger upload the dumpdata using mongorestore Change Replica Set to wiredTiger Replica sets can have members with different storage engines. 因此，你可以把所有成员的存储引擎更换为WiredTiger。 MongoDB version 3.0 or later in order to use wiredTiger storage engine! 过程： shutdown the secondary member.–db.shutdownServer prepare a data directory for the new mongod running with wiredTiger start mongod with wiredTiger repeat the procedure for other replica set secodaries you wish to upgrade Change Sharded Cluster to wiredTiger if the shard is a standalone, see [Change Standalone to wiredTiger](#Change Standalone to wiredTiger); if the shard is a replica set, see [Change Replica Set to wiredTiger](#Change Replica Set to wiredTiger). \rChange config server to wriedTiger 如果你打算更新config server使用WiredTiger，那么必须全部更新！ 过程： disable the balancer–sh.disableBalancer() shutdown the third config server to ensure read-only metadata.–db.shutdownServer() export the data of the second config server with mongodump For the second config server, create a new data directory for use with WiredTiger. Stop the second config server.–db.shutdownServer() Start the second config server mongod with the WiredTiger storage engine option. Upload the exported data using mongorestore to the second config server. Shut down the second config server to ensure read-only metadata.–db.shutdownServer() Restart the third config server to prepare for its upgrade. Export the data of the third config server with mongodump For the third config server, create a new data directory for use with WiredTiger. Stop the third config server. Start the third config server with the WiredTiger storage engine option. Upload the exported data using mo","date":"2017-12-11","objectID":"/mongodb/:40:1","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"MMAPv1存储引擎 \r","date":"2017-12-11","objectID":"/mongodb/:40:2","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"In-Memory存储引擎 \r","date":"2017-12-11","objectID":"/mongodb/:40:3","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Journaling 为了在发生故障时提供持久性，MongoDB使用了县写日志记录到磁盘的日志文件。 To provide durability in the event of a failure, MongoDB uses write ahead logging to on-disk journal files. ","date":"2017-12-11","objectID":"/mongodb/:41:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"journaling and the wiredTiger storage engine 本节所指的log指的是WiredTiger的 write-ahead log(journal)，而不是MongoDB日志文件。 WiredTiger使用checkpoints在磁盘上提供一致的数据视图，并允许MongoDB从上一个checkpoint修复。然而，如果MongoDB在检查点之间以外退出，则需要使用journaling来修复上次检查点之后发生的信息。 使用journaling的修复过程： 在数据文件中查找上一个检查点的标识符(identifier) 在journaling文件中搜索与上一个检查点标识符匹配的记录 应用自上一个检查节点依赖journal文件中的操作 \rjournal process 通过journaling，WiredTiger为每个客户端启动的写操作创建一个journal记录。journal record包括有初始写入引起的任何内部写入操作。 例如，集合中文档的更新可能导致对index的修改，WiredTiger创建一个包含update操作及其相关index修改的单独的journal record。 MongoDB将WiredTiger配置为in-memory的buffering来存储日志记录。线程坐标来分配和复制到他们的缓冲区的一部分。所有日志记录高达128KB是缓存的。 WiredTiger根据如下条件将journal record同步到磁盘。 每50ms MongoDB在WiredTiger中设置60s为间隔的用户数据检查点或2GBjournal数据已被写入，以先发生为准。 如果写操作包含有j:true的写关注点，则WiredTiger强制对journal文件进行同步。 MongoDB限制了journal文件大小为100MB，因此WiredTiger每100MB就会创建一个新的journal文件。当创建了一个新的journal文件时，WiredTiger会同步上一个journal文件。 在写操作之间，虽然日志记录保留在WiredTiger缓冲区中，但在mongod实例hard shutdown之后可能会丢失更新。 Journal File MongoDB在数据库目录下创建一个journal子目录存放journal文件。名字为WiredTigerLog.\u003csequence\u003e，从0000000001开始。如上图所示。 Journal文件包含对每一个写操作的记录。每个记录都有唯一的标识符。 MongoDB将WiredTiger配置为对journal数据使用快速压缩。最小日志大小为128KB，如果小于此，WiredTiger不会压缩此记录。最大大小为100MB，超过此，WiredTiger会创建一个新的journal文件。 MongoDB自动删除旧日志文件，以维护从上一个检查点恢复所需的文件。 \r","date":"2017-12-11","objectID":"/mongodb/:41:1","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Journaling and the MMAPv1 Storage Engine \r","date":"2017-12-11","objectID":"/mongodb/:41:2","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Journaling and the In-Memory Storage Engine \r\r","date":"2017-12-11","objectID":"/mongodb/:41:3","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Manage Journaling MongoDB uses write ahead logging to an on-disk journal to guarantee write operation durability. 启用journal后，如果MongodB意外退出，则程序可以恢复写入了journal日志文件的所有内容。MongoDB将在重启时重新应用写操作，并保持一致性。 ","date":"2017-12-11","objectID":"/mongodb/:42:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"过程 Enable journaling mongod --jouranl ##或 vim /etc/mongod.conf storage: journal: enabled: true Disable journaling mongod --noJournal ###或 修改配置文件 警告 不要在生产系统上禁用日记功能。 如果在一个副本集上使用--noJournal关闭了journal日志，则还应该修改副本集配置文件。 Monitor journal status serverStatus Recover data after unexpected shutdown 在奔溃后重启时，MongoDB会在服务器可用之前replay journal日志记录中的所有日志文件。 \r","date":"2017-12-11","objectID":"/mongodb/:42:1","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"GridFS GridFS是一种用于存储和检索超过BSON文档大小限制值16MB的文件规范。 GridFS没有将单个文件存储到单个的文档中，而是将文件分割成部分(parts)或块(chunks)，并将每个块存储到单独的文档中。默认情况下，GridFS的块大小为255KB。也就是说，GridFS将文件分成255KB的块，最后一块大小就不确定了。 GridFS使用两个集合来存储文件。一个存储文件块(chunks)，另一个存储文件元数据(metadata)。 当你查询(query)GridFS文件时，驱动程序会根据需要重新组装这些块。你可对通过GridFS存储的文件执行范围查询。还可以从任意文件部分访问信息。 GridFS不仅可用于存储超过16MB的文件，还可用于存储需要访问的任何文件，而不必将整个文件加载到内存中。 ","date":"2017-12-11","objectID":"/mongodb/:43:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"何时使用GridFS 在MongoDB中，使用GridFS存储大于16MB的文件。 某些情况下，在MongoDB数据库中存储大文件可能比在系统级文件系统上更有效。 如果文件系统限制了一个目录中的文件数量，则可使用GridFS存储所需的文件 当你想要访问大文件的部分信息时而不想将整个文件加载到内存中时，可使用GridFS收回文件的各个部分，而不必将整个文件读入内存 当你希望文件和元数据自动同步并部署在多个系统和设施中时，可使用GridFS 如果需要原子地(atomically)更新整个文件的内容，请不要使用GridFS。作为一种选择，你可以为每个文件存储多个版本，并在元数据中指定该文件的当前版本。 此外，如果文件都是小于16MB的BSON文件大小限制，则考虑手动存储在一个单文档中，而不必使用GridFS。 \r","date":"2017-12-11","objectID":"/mongodb/:43:1","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"使用GridFS 使用GridFS存储和检索文件，请使用如下任何一项： A MongoDB Driver The mongofile cmd-line tool \r","date":"2017-12-11","objectID":"/mongodb/:43:2","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"GridFS集合 GridFS把文件存储在两个集合里： chunks collection stores the binary chunks files collection stores the file’s metadata GridFS将这些集合放在一个普通的存储区(bucket)中，每个存储区前面加上名称。默认地，GridFS使用两个名为fs的存储区集合： fs.files fs.chunks 币可以选择一个不同的存储区名字，也可以在一个数据库中创建多个存储区。 The chunks collection 块集合中的每个文档都表示一个独立的文件块。格式如下： { \"_id\": \u003cObjectId\u003e, \"files_id\": \u003cObjectId\u003e, \"n\": \u003cnum\u003e, \"data\": \u003cbinary\u003e } 块集合中的文档包含如下字段： chunks._id The unique ObjectId of the chunk chunks.files_id The _id of the “parent” document chunks.n The sequence number of the chunk，GridFS从0开始标号所有块 chunks.data BSON Binary type \rfile集合 GridFS的file集合，格式如下： { \"_id\": \u003cObjectId\u003e, \"length\": \u003cnum\u003e, \"chunkSize\": \u003cnum\u003e, \"uploadData\": \u003ctimestamp\u003e, \"md5\": \u003chash\u003e, \"filename\": \u003cstring\u003e, \"contentType\": \u003cstring\u003e, \"aliases\": \u003cstring array\u003e, \"metadata\": \u003cany\u003e } files._id The unique identifier for this document files.length The size of the document in bytes files.chunSize The size of each chunk in bytes files.uploadDate The date the document was first stored by GridFS files.md5 An MD5 hash of the complete file file.filename Optional. A human-readable name for the GridFS file file.contentType Optional. A valid MIME type for the GridFS file files.aliases Optional. An array of alias strings files.metadata Optional. The metadata field may be of any data type and can hold any additional information you want to store ","date":"2017-12-11","objectID":"/mongodb/:43:3","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"GridFS索引 为了提高效率，GridFS在每个chunks and files collections上使用索引。 \rchunks索引 GridFS使用一个唯一的、混合的索引。在chunks集合上使用files_id和n字段。 db.fs.chunks.find( { files_id: myFileID } ).sort( { n:1 }) #创建索引 db.fs.chunks.createIndex({ files_id: 1, n:1 }, { unique: true }); files索引 GridFS使用索引，在files集合上使用filename和uploadDate字段。 db.fs.files.find({ filename: myFileName }).sort({ uploadDate: 1 }) #创建索引 db.fs.files.createIndex({ filename:1, uploadDate: 1 }); \r","date":"2017-12-11","objectID":"/mongodb/:43:4","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"分片GridFS 如果需要分片GridFS数据存储，使用chunks集合设置: { files_id: 1, n:1} or { files_id: 1 }作为分片key索引。 不能对chunks集合使用hash分片。 files_id是一个ObjectId。 \r MongoDB安全 Security \rMongoDB提供了各种特性(features)，如身份认证(authentication)、访问控制(access control)、加密(encryption)，以保护MongoDB部署。 \r","date":"2017-12-11","objectID":"/mongodb/:43:5","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Security Checklist 启用访问控制和强制认证 Enable Access Control and Enforce Authentication 可使用默认的MongoDB认证机制或现有的外部框架 配置基于角色的访问控制 Configure Role-Based Access Control 首先创建administrator，接着在创建其他用户 创建角色，定义一组用户所需的确切访问权限 加密通信 Encrypt Communication 配置MongoDB使用TLS/SSL加密连接 加密和保护数据 Encrypt and Protect Data 限制网络曝光 Limit Network Exposure 确保MongoDB运行在一个受信任的网络环境上，并限制MongoDB的监听接口 审计系统活动 Audit System Activity 跟踪对数据库配置和数据的访问和更改 使用专用用户运行MongoDB Run MongoDB with a Dedicated User 使用专用的操作系统用户账户运行MongoDB进程 使用安全配置选项运行MongoDB Run MongoDB with Secure Configuration Options MongoDB为了支持某些服务端操作执行：mapReduce,group,$where 如果你不使用这些操作，请关闭服务器端脚本执行--noscripting 请求一个安全技术执行指南 Request a Security Technical Implementation Guide 考虑安全标准合格性 Consider Security Standards Compliance ","date":"2017-12-11","objectID":"/mongodb/:44:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"认证 Authentication 要作为用户进行身份认证，必须提供用户名(username)，密码(password)和与用户关联的身份验证数据库(authentication database)。 mongo --host --username --password --authenticationDatabase #Or mongo \u003euse \u003cauthenticationDatabase\u003e \u003edb.auth('username','password') \r 认证机制 Authentication Mechanisms MongoDB支持多种认证机制 SCRAM-SHA-1 MongoDB Challenge and Response (MONGODB-CR) x.509 Certificate Authentication LDAP proxy authentication(MongoDB Enterprise) Kerberos authentication(MongoDB Enterprise) 内部认证 Internal Authentication 除了验证客户端的身份外。MongoDB还可以要求副本集和分片集的成员对其各自的成员进行认证 \r","date":"2017-12-11","objectID":"/mongodb/:45:0","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"用户 Users \r要在MongoDB中验证客户端，必须向MongoDB添加相应的用户。 用户管理接口 User Management Interface 使用db.createUser()方法创建用户 添加用户时，可为用户分配角色以授予权限 在数据库管理中创建的第一个用户应该是具有管理其他用户权限的administrator 也可以更新/删除一个已经存在的用户的权限 认证数据库 Authentication Database 在特定的数据库中创建用户，这个数据库是用户的认证库 用户名和认证库充当该用户的唯一标识符。如果两个用户具有相同的用户名，但是在不同的数据库中创建，则它们是两个单独的用户 用户可拥有不同数据库的权限，而不限于认证库 通过数据库角色给用户分配相应的权限 认证一个用户 Authentication Database 使用用户名、密码、认证库验证一个用户 集中的用户数据 Centralized User Data MongoDB将所有的用户名、密码和认证库信息，保存到admin库的syste.users集合中 使用用户管理命令而不要直接访问这个集合 分片集群用户 Sharded Cluster Users \r添加用户 Add Users MongoDB使用基于角色的访问控制(RBAC)来确定用户的访问权限。用户被授予一个或多个角色，这些角色确定用户对MongoDB资源的访问或权限，以及用户可以执行的操作。 用户应该只具有确保系统最小权限所需要的最小权限。 \r前提(Prerequisites) 对于用户创建，你必须拥有以下权限 在数据库中创建一个新用户，必须在数据库资源上有createUser操作 对一个用户授权角色，必须在角色数据库中有grantRole操作 \r栗子 use admin db.createUser( { user: 'zhang', pwd: 'passwd123', roles: [ { role: 'root' }, { db: 'admin' } ] } ) #在配置文件中开启用户认证 vim /etc/mongod.conf security: authorization: enabled ","date":"2017-12-11","objectID":"/mongodb/:45:1","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"认证机制 Authentication Mechanisms \rSCRAM-SHA-1 MONGODB-CR x.509 MongoDB对于客户端身份认证和副本集、分片集成员的内部认证支持x.509证书认证。 x.509证书认证需要安全的TLS/SSL连接。 \r证书授权(Certificate Authority) 在生产使用中，MongoDB的部署应该使用由认证机构签名和生成的有效证书。 \rClient x.509 Certificates 要想服务器验证身份，客户端可以使用x.509证书而不是用户名和密码。 Client Certificate Requirements： 单个证书颁发机构(CA)必须同时为客户端和服务器颁发证书 客户端证书必须包含如下字段： keyUsage = digitalSignature extendedKeyUsage = clientAuth 每个唯一的MongoDB用户必须有一个唯一的证书 一个客户端x.509证书的主题，包含了可辨识名称(DN)。必须不同于成员x.509证书 \rMongoDB user and $external database 若要使用客户端证书进行认证，必须先将客户端证书中的subject值添加为MongoDB用户。每个唯一的x.509客户端证书对因孤独一个MongoDB用户。 在$external database中添加用户，认证库便是外部数据库。 \rAuthenticate 使用x.509客户端进行身份验证，请通过TLS/SSL连接到MongoDB。--ssl and --sslPEMKeyFile \rMember x.509 Certificates 对于内部认证，分片集和副本集的成员可以使用x.509证书来代替使用SCRAM-SHA-1认证机制的keyfile。 Member Certificate Requirements CA必须为所有分片集，副本集成员颁发x.509证书 成员证书的主题中找到Distinguished Name(DN)必须为以下至少一个属性指定非空值：Organization(O)，Organization Unit(OU)，Domain Component(DC) 组织属性，组织单元属性和域组件必须与其他集群成员的证书相匹配。 CN=host1,OU=Dept1,O=MongoDB,ST=NY,C=US C=US, ST=CA, O=MongoDB, OU=Dept1, CN=host2 \rMongoDB Configuration 配置文件：security.clusterAuthMode and net.ssl.clusterFile cmd-line options: –clusterAuthMode and –sslClusterFile \rMember Certificate and PEMKeyFile 配置文件： net.ssl.PEMKeyFile cmd-line option: –sslPEMKeyFile ","date":"2017-12-11","objectID":"/mongodb/:45:2","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"Enterprise Authentication Mechanisms \r\r","date":"2017-12-11","objectID":"/mongodb/:45:3","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"MongoDB认证和角色 要想了解MongoDB的权限必须先了解如下一些关键字： user 用户，用于提供客户端连接MongoDB的认证账户 role 角色，数据权限的集合，创建用户的时候必须要指定对应的角色，否则用户无法操作数据库 resource 资源，包括database或collection 也可以是database和collection的组合 actions 权限操作，定义了 user 能够对 resource document 执行的操作。如 增、删、改、查 privilege 权限，privilege 是一组 resource 和 action的组合，对资源拥有什么操作称为权限 authenticationDatabase 认证库，即创建角色或用户时所在的库 \r角色管理 MondoDB支持基于角色的访问控制（RBAC）来管理对MongoDB系统的访问。一个用户可以被授权一个或多个角色以决定该用户对数据库资源和操作的访问权限。在权限以外，用户是无法访问系统的。 数据库角色在创建用户的role参数中设置。角色分为內建角色和自定义角色。 \r内建角色 数据库用户角色 read：允许用户读取指定数据库 readWrite：允许用户读写指定数据库 数据库管理员角色 dbAdmin：允许用户进行索引创建、删除，查看统计或访问system.profile，但没有角色和用户管理的权限 userAdmin：提供了在当前数据库中创建和修改角色和用户的能力 dbOwner：提供对数据库执行任何操作的能力。这个角色组合了readWrite、dbAdmin和userAdmin角色授权的特权 集群管理角色 hostManager：提供监视和管理服务器的能力 clusterManager：在集群上提供管理和监视操作。可以访问配置和本地数据库，这些数据库分别用于分片和复制 clusterMonitor：提供对监控工具的只读访问 clusterAdmin：提供最强大的集群管理访问(副本集、分片、主从等)。组合了clusterManager、clusterMonitor和hostManager角色的能力，还提供了dropDatabase操作 备份恢复角色 backup：提供备份数据所需的能力 restore： 提供使用mongorestore恢复数据的能力 所有数据库角色 readAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读权限 readWriteAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读写权限 userAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的userAdmin权限 dbAdminAnyDataBase：只在admin数据库中可用，赋予用户所有数据库的adAdmin权限 超级用户角色 root：超级权限，只能针对admin库 内部角色 __system：提供对数据库中任何对象的任何操作的特权 \r自定义角色 MongoDB内置角色一般来说都是够用的，但当内置角色不满足需求时就可以自定义角色了。使用 db.createRole() 方法来自定义角色。 只能在admin库中创建角色： use admin db.createRole( { role:\u003crole_name\u003e, #定义角色名称 privilege:[ #权限集 { resource:{cluster:true, actions:[\u003caction_name\u003e] }, { resource: {db:\u003cdb_name\u003e, collection:\u003ccoll_name\u003e }, { actions:[\u003caction_name\u003e] } #定义对这个库或集合可进行的权限操作，这是一个数组 ], roles:[ { role:\u003crole_name\u003e, db:\u003cdb_name\u003e } ] #是否继承其他的角色 } ) 角色创建完毕后MongoDB会在系统库admin下创建一个collection名叫 system.roles，里面存储的即是角色相关的信息。 db.system.roles.find() \r操作角色 #查看角色 db.getRole() #角色继承 #角色授权 db.grantRolesToRole() #角色移权 db.revokeRolesfromRole() \r用户管理 创建用户： db.createUser({ user:\"xxx\", pwd:\"xxxx\", customDate:\"xxx\", roles:[{ #指定角色名称以及认证库 role:\"xxx\", db:\"xxxx\" }] }) \r开启认证： vim /etc/mongo.conf security: authorization：enabled db.auth(\"user\",\"passwd\") #在use db后 或 mongo -u user -p passwd --authenticationDatabase xxx #在哪个库创建的用户就需要使用哪个库进行认证 \r查看用户： db.getUser(\"user\") db.system.users.find() \r删除用户： db.dropUser(\"user\") db.dropAllUsers() 添加用权限： db.grantRolesToUser() \r修改用户密码： db.changeUserPassword(\"user\",\"new_passwd\") \r在MongoDB中删除库和集合并不会级联删除对应的角色和用户。因此如果想彻底删除对应的业务应该先删除库与其对应的角色和用户。 如果既想实现精细化权限控制又想简化用户管理，原则上建议只给开发创建一个账户，并且使用admin做认证库，这样可以避免清理过期业务库而导致无法登陆的问题。 ","date":"2017-12-11","objectID":"/mongodb/:45:4","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["database"],"content":"内部认证 Internal Authentication 可以对副本集和分片集成员进行验证。 对于成员的内部认证，MongoDB可以使用keyfile或x.509证书。 KeyFile keyfiles的内容作为成员的共享密码，其长度必须在6-1024个字符之间，只能包含base64 set中的字符。 openssl rand -base64 512 \u003e /etc/mongodb.keyfile chmod 600 /etc/mongodb.keyfile chown mongod:mongod /etc/mongodb.keyfile #配置文件：security.keyFile #cmd-line option: --keyFile vim /etc/mongod.conf security: authorization: enabled keyFile: \"/etc/mongodb.keyfile\" clusterAuthMode: \"keyFile\" \rx.509 内部认证使用x.509进行验证。 CA必须为所有分片集，副本集成员颁发x.509证书 成员证书的主题中找到Distinguished Name(DN)必须为以下至少一个属性指定非空值：Organization(O)，Organization Unit(OU)，Domain Component(DC) 组织属性，组织单元属性和域组件必须与其他集群成员的证书相匹配。 CN=host1,OU=Dept1,O=MongoDB,ST=NY,C=US C=US, ST=CA, O=MongoDB, OU=Dept1, CN=host2 \rMongoDB Configuration 配置文件：security.clusterAuthMode and net.ssl.clusterFile cmd-line options: –clusterAuthMode and –sslClusterFile 在副本集中强制秘钥文件访问控制 Enforce Keyfile Access Control in a Replica Set \r对副本集执行访问控制需要配置： 使用内部身份验证副本集成员之间的安全性 使用用户访问控制连接客户端和副本集间的安全性 步骤： 创建一个密钥文件 Create a keyfile 通过密钥文件进行身份验证，副本集中的每个mongod实例都使用密钥文件的内容作为共享密码，用于验证部署中的其它成员。 #yum install -y openssl openssl rand -base64 756 \u003e \u003cpath-to-keyfile\u003e chmod 400 \u003cpath-to-keyfile\u003e chown \u003cowner\u003e:\u003cowner\u003e 复制密钥文件到每个副本集成员 Copy the keyfile to each replica set member 将密钥文件复制到每一台主机的副本集成员中。 确保运行mongod实例的用户就是keyfile的所有者，并可以访问密钥文件。 \r关闭所有的副本集成员 Shut down all members of the replica set 关闭每个副本集中的mongod，从Secondary开始。知道所有的成员都脱机为止，包括任何仲裁者(Arbiter)。Primary是最后一个关闭的成员。 use admin db.shutdownServer() \r启动访问控制并重启副本集成员 vim /etc/mongod.conf security: keyFile: \u003cpath-to-keyfile\u003e clusterAuthMode: keyfile replication: replSetName: \u003creplcaSetName\u003e #cmd-line mongod --keyFile \u003cpath-to-keyfile\u003e --clusterAuthMode keyfile --replSet \u003creplicaSetName\u003e \r连接到mongo shell 在Primary上使用rs.status()来标识副本集成员。 \r创建一个administrator Create the user administrator 必须在Primary上创建用户。 admin = db.getSiblingDB(\"admin\") admin.createUser( { user: 'zhang', pwd: 'password', roles: [{ role: 'userAdminAnyDatabase', db: 'admin' }] } ) \r开启用户认证 vim /etc/mongod.conf security: authorization: enabled keyFile: \u003cpath-to-keyfile\u003e clusterAuthMode: keyfile replication: replSetName: \u003creplcaSetName\u003e \r以管理员身份进行认证 Authenticate as the User Administrator mogno \u003edb.getSiblingDB(\"admin\").auth('zhang','password') #or mongo -u 'zhang' -p 'password' --authenticationDatabase 'admin' \r创建集群管理员(可选) Create the cluster administrator (Optional) db.getSiblingDB(\"admin\").createUser( { \"user\" : \"ravi\", \"pwd\" : \"changeme2\", roles: [ { \"role\" : \"clusterAdmin\", \"db\" : \"admin\" } ] } ) 在不停机的副本集中强制实施keyfile访问控制","date":"2017-12-11","objectID":"/mongodb/:45:5","tags":["mongodb","nosql"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["http"],"content":"常见HTTP请求方法 HTTP协议的请求方法有：GET, POST, HEAD PUT DELETE, OPTIONS, TRACE, CONNECT Method | Description | - GET | 向Server请求文件 POST | 向Server发送数据并让Server进行处理 PUT | 向Server发送数据并存储在Server端 HEAD | 检查一个对象是否存在 DELETE | 从Server上删除一个文件 CONNECT | 对通道提供支持 TRACE | 跟踪到Server的路径 OPTION | 查询Server的性能 HTTP Status Code 当我们从Client向Server发送请求时，Server会向我们返回StatusCode。 StatusCode会告诉我们Server的响应的状态，通过它，我们就可以知道当前请求是成功还是出现了问题。 HTTP StatusCode放置在HTTP Response报文中。 StatusCode由三位数字组成，第一个数字定义了响应类型，有五种可能值： 状态码 | 响应类别 | 描述 | - | - 1xx | 指示信息 | 服务器正在处理请求 2xx | 成功 | 请求以正常处理完毕 3xx | 重定向 | 需要进行额外操作以完成请求 4xx | 客户端错误 | 客户端原因导致服务器无法处理请求 5xx | 服务器错误 | 服务器原因导致处理请求出错 \r","date":"2017-12-01","objectID":"/http-method-status/:0:0","tags":["http","状态码"],"title":"HTTP请求方法和状态码","uri":"/http-method-status/"},{"categories":["http"],"content":"常见HTTP状态码 状态码 | 描述 | - 200-OK | 服务器成功返回网页，这是成功的HTTP请求返回的标准状态码 301 - Moved Permanently | 永久跳转，所有请求的网页将永久跳转到被设定的新位置 400 - Bad Request | 客户端请求有语法错误，不能被服务器理解 403 - Forbidden | 禁止访问，这个请求时合法的，但是服务器端因为匹配了预先设置的规则而拒绝响应客户端的请求，此类问题一般为服务器权限配置不当所致 404 - Not Found | 服务器找不到客户端请求的指定页面，可能是客户端请求了服务器不存在的资源所导致 500 - Internal Server Error | 内部服务器错误，服务器遇到了意料不到的情况，不能完成客户的请求。这是一个较为笼统的报错，一般为服务器的设置或内部程序问题所致 502 - Bad Gateway | 坏的网关，一般是代理服务器请求后端服务器时，后端服务不可用或没有完成响应网关服务器。一般为代理服务器下面的节点出了问题 503 - Service Unavailable | 服务当前不可用，可能为服务器超载或停机维护所致，或者是代理服务器后面没有可以提供服务的节点 504 - Gateway Timeout | 网关超时，一般是网关代理服务器请求后端服务时，后端服务没有在特定的时间内完成处理请求，一般为服务器过载所致，没有在指定的时间内返回数据给代理服务器 \r","date":"2017-12-01","objectID":"/http-method-status/:1:0","tags":["http","状态码"],"title":"HTTP请求方法和状态码","uri":"/http-method-status/"},{"categories":["http"],"content":"1xx 1xx（临时响应），表示临时响应并需要请求者继续执行操作。 状态码 | 描述 | - 100 - Continue | 请求者应当继续提出请求 101 - Switching Protocols | 请求者要求服务器更换协议，服务器已确认并准备更换 \r## 2xx\r2xx（成功），表示成功处理了请求。 状态码 | 描述 | - 200 - OK | Server已成功处理了请求 201 - Created | 请求成功并且Server创建了新的资源 202 - Accepted | Server以接受请求，但尚未处理 203 - Non-Authoritative Information | Server已成功处理了请求，但返回的信息可能来自另一个来源 204 - No Content | Server成功处理了请求，但没有返回任何内容 205 - Reset Content | 没有新的内容，但浏览器应该重置它所显示的内容 206 - Partial Content | 服务器成功处理了部分GET请求 \r","date":"2017-12-01","objectID":"/http-method-status/:2:0","tags":["http","状态码"],"title":"HTTP请求方法和状态码","uri":"/http-method-status/"},{"categories":["http"],"content":"3xx 3xx（重定向），表示要完成请求需要进一步操作。 状态码 | 描述 | - 300 - Multiple Choices | 针对请求，Server可执行多种操作 301 - Moved Permanently | 请求的网页已移动到新位置 302 - Found | Server目前从不同位置的网页响应请求 303 - See Other | 请求者对不同位置使用单独的GET请求来检索时 304 - Not Modified | 自从上次请求后，请求的网页内容未修改过 305 - Use Proxy | 请求者只能使用代理访问请求的网页 307 - Temporary Redirect | Server从不同位置的网页响应请求，但请求者继续使用原有位置进行请求 \r","date":"2017-12-01","objectID":"/http-method-status/:3:0","tags":["http","状态码"],"title":"HTTP请求方法和状态码","uri":"/http-method-status/"},{"categories":["http"],"content":"4xx 4xx（请求错误），表示请求可能出错，妨碍了Server的处理。 状态码 | 描述 | - 400 - Bad Request | Server不理解请求的语法 401 - Unauthorized | 请求要求身份认证 403 - Forbidden | Server拒绝请求 404 - Not Found | Server找不到请求的网页 405 - Method Not Allowed | 请求方法不被允许 406 - Not Acceptable | 无法使用请求的恩日工特性响应请求的网页 407 - Proxy Authentication Required | 请求需要代理授权 408 - Request Timeout | Server等候请求时超时 409 - Conflict | Server在完成请求时发生冲突 410 - Gone | 请求的资源以永久删除 411 - Length Required | Server不接受不含有效内容长度Header的请求 412 - Precondition Failed | Server为满足请求者在请求中设置的一个前提条件 413 – Request Entity Too Large | 请求实体太大，Server无法处理 414 - Request URI Too Long | 请求的URI过长，Server无法处理 415 – 不支持的媒体类型 | 请求的格式不受支持 416 – Requested Range Not Satisfiable | 页面无法提供请求的范围 417 – 执行失败 | Server未满足期望请求Header的要求 451 | 基于法律上的的原因，不能像请求者展示网页内容 \r","date":"2017-12-01","objectID":"/http-method-status/:4:0","tags":["http","状态码"],"title":"HTTP请求方法和状态码","uri":"/http-method-status/"},{"categories":["http"],"content":"5xx 5xx（服务器错误），表示服务器在尝试处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是请求出错。 状态码 | 描述 | - 500 - Internal Server Error | Server遇到错误，无法完成请求 501 - Not Implemented | Server不具备完成请求的功能 502 - Bad Gateway | Server作为网关或代理时，从upstream收到无效响应 503 - Service Unavailable | Server暂时无法使用 504 - Gateway Timeout | Server作为网关或代理时，没有及时从upstream收到请求 505 - HTTP Version Not Supported | Server不支持请求中所用的HTTP版本 ","date":"2017-12-01","objectID":"/http-method-status/:5:0","tags":["http","状态码"],"title":"HTTP请求方法和状态码","uri":"/http-method-status/"},{"categories":["linux"],"content":"FHS介绍 FHS(Filesystem Hierarchy Standard)，文件系统层次化标准：http://www.pathname.com/fhs FHS主要目的是希望让用户了解安装文件通常放置的目录。所以希望软件开发商、系统制定者以及维护系统的用户，都能够遵循FHS的标准。 FHS-compliant system： | 可分享的(shareable) | 不可分享的(unshareable)\r | - | -\r 不变的(static) | /usr /opt | /etc /boot 可变的(variable) | /var/mail /var/spool/news | /var/run /var/lock shareable： 可分享给其他系统(主机)挂载使用； unshareable： 不适合分享给其他主机； static： 有些数据基本是不会变化的； variable： 进程变更的数据。 FHS针对目录树架构仅定义出三层目录下应该放置什么数据，这三个目录下所应该放置的目录也都有特定规定。\r /： The root filesystem, 与开机系统有关； /usr: The /usr hierarchy, Unix software resource； /var: The /var hierarchy, 与系统运行过程有关。 \r# The Root Filesystem\r根目录(/)是系统最重要的一个目录。不但所有目录都是由根目录衍生出来，同时根目录还与系统的启动、还原、修复等操作相关。 若系统出现问题，根目录必须要包含能够修复文件系统的程序才行。 破坏根文件系统上的数据的错误比破坏其他任何分区都要严重！ 为了平衡这些考虑，建议尽可能保持根分区小。 应用程序不应在根目录中创建特殊文件或子目录！ The following dirs or symbolic-links, are required in /\r目录 | 描述 | -\r /bin | 必要的二进制命令 /boot | boot-loader的静态文件 /dev | 设备文件 /etc | 主机特定的系统配置文件 /lib | 基本的共享库(shared libraries)和内核模块(kernel modules) /media | 可移除媒体的挂载点 /mnt | 临时挂载文件系统的挂载点 /opt | 第三方软件包放置目录 /sbin | 必要的系统二进制命令 /srv | 系统提供的服务数据 /tmp | 临时文件 /usr | /usr层次结构 /var | /var层次结构 除了上面列出必须存在的目录，下面这些目录很也很重要。\r目录 | 描述 | -\r /lost+found | 在ext文件系统里，当文件系统发生错误时，将一些遗失的片段放置到此目录下 /home | 用户家目录 /root | root用户家目录 /proc | 虚拟文件系统，放置的数据都在内存当中，不占磁盘空间 /sys | 虚拟文件系统，记录内核相关信息，不占磁盘空间 另外需要注意的是，因为根目录与开机有关，开机过程中仅有根目录被挂载。其他分区则是在开机完成后才会持续进行挂载。\r因此，根目录下与开机过程有关的目录就不能放到不同的分区中去。\r如： /etc /bin /sbin /dev /lib ## /bin\r/bin, 基本用户二进制命令文件，供所有用户（系统管理员和用户）使用。 /bin下不能有子目录(subdirectory)。 The following commands or symbolic-links to commands, are required in /bin\r命令 | 描述 | -\r cat | 将文件连接到stdout的实用程序(Utility) chgrp | 更改文件所有权 chmod | 更改文件访问权限 chown | 更改文件所有者和和组 cp | 复制文件和目录 date | 打印或设置系统数据和时间 dd | 转换和复制文件 df | 磁盘使用情况 dmesg | 打印或控制kernel消息缓冲区 echo | 显示一行文本 false | do nothing, 不成功 true | do nothing, 成功 hostname| 系统主机名 kill | 发送信号到进程 ln | 在文件之间创建链接 login | 在系统上开始会话 ls | 列出目录内容 mkdir | 创建目录 mknod | 创建block或character特殊文件 more | 文本翻页 mount | 挂载文件系统 umount | 解挂文件系统 mv | move/rename文件 ps | 报告进程状态 pwd | 打印当前工作目录 rm | remove文件或目录 sed | sed流编辑器 sh | Bourne command shell stty | 更改或打印终端设置 su | change uid sync | 刷新文件系统缓冲区 uname | 打印系统信息 The following programs or symbolic-links to programs, must be in /bin if the corresponding-system is installed:\r命令 | 描述 | -\r csh | The C shell(可选) ed | 编辑器(可选) tar | tar归档(可选) cpio | cpio归档(可选) gzip | GNU压缩工具(可选) gunzip | GNU解压缩工具(可选) netstat | 网络统计(可选) ping | ICMP网络测试(可选) ## /boot\r/boot :static file of the boot-loader 该目录包含引导过程所需所有内容，处理引导是不需要的配置文件和映射安装文件外。 因此，/boot储存kernel开始执行用户模式之前使用的数据。 ** 操作系统kernel必须位于 / or /boot** ## /dev\r/dev :device files /dev 目录是特殊或设备文件的位置。 ## /etc\r/etc :host-specific system configuration 配置文件是用来控制程序操作的本地静态文件，不能是可执行的二进制文件。 The following files or symbolic-links to files, must be in /etc if the corresponding-subsystem is installed.\r文件 | 描述 | 备注 | - csh.login | C shell登录的系统范围初始化文件 | Optional exports | NFS文件系统访问控制列表 | Optional fstab | 文件系统静态信息 | Optional ftpusers | FTP守护进程用户访问控制列表 | Optional gateways | 路由网关文件 | Optional gettydefs | getty终端设置 | Optional group | 用户组文件 | Optional passwd | 密码文件 | Optional host.conf | 解析器配置文件 | Optional hosts | 主机域名的静态信息 | Optional hosts.allow | Tcp-wrapper的主机访问文件 | Optional hosts.deny | Tcp-wrapper的主机禁止文件 | Optional hosts.equiv | rlogin, rsh, rcp的可信主机列表 | Optional hosts.lpd | lpd的可信主机列表 | Optional inetd.conf | inetd配置文件 | Optional inittab | init配置文件 | inittab is no longer used when using systemd id.so.conf | 搜索共享库的额外目录 | Optional issue | 预登录消息和 | CentOS Linux 7(core) kernel \\r on an \\m motd | 登录后信息 | Welcome to $host mtab | 文件系统动态信息 | Optional mtools.conf | mtools配置文件 | Optional networks | 网络名称的静态信息 | Optional printcap | lpd打印机功能数据库 | Optional profile | sh shell login的系统范围初始化文件 | Optional protocols | IP协议列表 | Optional resolv.conf | 域名服务器解析文件 | Optional rpc | RPC协议列表 | Optional securetty | root登录的TTY访问控制 | Optional shells | 有效登录shell的路径名 | Optional syslog.conf | syslogd配置文件 | Optional ## /etc/opt\r/etc/opt :/opt的配置文件 第三方应用程序软件的特定主机配置文件，必须安装在/etc/opt/ 中。 ## /etc/xml\r/etc/xml :XML的配置文件 这里安装和定义XML系统的高","date":"2017-11-27","objectID":"/fhs/:0:0","tags":["linux","fhs","文件系统"],"title":"Filesystem Hierarchy Standard","uri":"/fhs/"},{"categories":["linux"],"content":"Linux Linux操作系统的附件 ","date":"2017-11-27","objectID":"/fhs/:1:0","tags":["linux","fhs","文件系统"],"title":"Filesystem Hierarchy Standard","uri":"/fhs/"},{"categories":["linux"],"content":"/ :根目录 在Linux系统上，如果内核位于/，建议使用Linux内核源代码包中使用的名称vmlinux或vmlinuz。 我的CentOS7中，内核文件默认是/boot/vmlinuz-$kernel-version.$arch ### /bin :基本用户命令二进制文件(供多有用户使用)\r\r### /dev :设备和特殊文件\r /dev/null : 写入该设备的所有数据都被丢弃。从这个设备读取将返回一个EOF条件。 /dev/zero : 该设备是归零数据的来源，写入该设备的所有数据被丢弃。从这个设备读取将返回包含zero的请求的字节数。 /dev/tty : 该设备类似于进程控制终端。一旦这个设备被打开，所有读写操作就好像实际的控制终端以及被打开一样。 ### /etc :主机的特定系统配置\rLinux系统要将附件文件放置到/etc中。 \r### /lib64 和 /lib32 :64/32位库(依赖于体系结构)\r64位体系结构PPC64,AMD64,x86_64必须将64位库放置于/lib64中，将32位库放置于/lib中； 64位体系结构IA64必须将64位库放置于/lib中。 ### /proc :内核和进程信息虚拟文件系统\rPROC文件系统是用于处理进程和系统信息的标准Linux方法，而不是/dev/kmem和其它类似方法。 强烈建议使用PROC文件系统获取 存储，进程，内存，内核等信息。 \r### /sbin :基本系统二进制文件\rLinux系统将这些附加文件放置于/sbin中： 第二扩展文件系统命令（可选）： badblocks dumpe2fs e2fsck mke2fs mklost+found tune2fs boot-loader 映射安装程序（可选）： lilo 静态二进制文件： ldconfig sln(static ln) ssync(static sync) 出现问题时，sln（静态ln）和ssync（静态同步）非常有用； idconfig程序可以作为升级知道的手段； sln的主要用途，修复不良协调升级后/lib中不正确的符号链接动态库。 对于/sbin, idconfig二进制文件是可选的。因为站点可能会在启动时选择运行idconfig而不是仅在升级共享库时。 以下是一些常见问题： 我刚刚删除了/lib/； 我无法找到库的名称，因为ls是动态链接。我使用的shell没有内置ls，我也不知道使用echo *作为替换； 我有一个静态ln，但我不知道怎么称呼这个链接。 杂项： #ctrl+alt+del ctrlaltdel #keyboard rate kbdrate 为了应对某些键盘出现如此高的重复速率一致无法使用,kbdrate可以安装在某些系统上的/sbin中； 由于ctrl+alt+del组合键在内核中的默认操作是硬重启，因此通常建议在将根文件系统挂在到读写模式之前禁用该行为。这就可能需要ctrlaltdel程序，它可以安装在系统的/sbin中。 ## /usr/include :C程序包含的头文件\r如果安装了C或C++编译器，则只有非 基于glibc的系统才需要这些链接符号。 /usr/include/asm -\u003e /usr/src/linux/include/asm-\u003carch\u003e /usr/include/linux -\u003e /usr/src/linux/include/linux ## /usr/src :源代码\r对于基于glibc的系统，此目录没有具体指导。 对于glibc之前基于linux libc修订版的系统： /usr/src/linux是唯一放置Linux内核源代码的位置。 ## /usr/spool/cron :cron和jobs\r此目录包含了cron和程序的可变数据。 ","date":"2017-11-27","objectID":"/fhs/:1:1","tags":["linux","fhs","文件系统"],"title":"Filesystem Hierarchy Standard","uri":"/fhs/"},{"categories":["monitor"],"content":"参考： Zabbix官方网站 Zabbix中文文档 Zabbix-repo仓库: http://repo.zabbix.com 阿里云镜像: https://mirrors.aliyun.com/zabbix/zabbix/ . 环境： CentOS7x86_64 Zabbix 3.4 \r\r \rZabbix简介 Zabbix （音同 zæbix），是由 Alexei Vladishev 开发的一种网络监视、管理系统，基于 Server-Client 架构。Zabbix 的授权是属于 GPLv2。 Zabbix可用于监视各种网络服务、服务器和网络机器等状态。是一个基于WEB界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案。 Zabbix也可经由SNMP、TCP、ICMP、SSH等对目标进行监视。 ","date":"2017-11-14","objectID":"/zabbix/:0:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"Zabbix的系统构成 Zabbix系统由以下各独立模块组成： Zabbix Server，服务端(以C开发)。Server端通过收集SNMP和Agent发送的数据，写入数据库，再通过PHP+Apache在Web端展示； Zabbix Agent，客户端(基本支持所有操作系统)，并将监控主机数据发送给Server； Zabbix Frontend，Web管理端(以PHP和JavaScript构成)； Zabbix Proxy(可选组件)。用于分布式监控。 \r","date":"2017-11-14","objectID":"/zabbix/:1:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"Zabbix的特点 Zabbix是一个高度集成的网络监控解决方案，一个简单的安装包中提供多样性功能。 数据收集； 灵活的阀值(触发器)定义； 高度可配置化的告警； 实现图表绘制； Web监控功能； 丰富的可视化选项； 历史数据存储； 配置简单； 使用模板； 网络发现； Zabbix API； 权限管理系统； 功能强大并易于扩展的监控代理。 \r 定义 Zabbix的常用术语含义。 主机(host)： 一台你想监控的网络设备，用IP或域名表示。主机名不能使用中文创建，会报错。 主机组(host group): 主机的逻辑组，它包含主机和模板。组名可以使用中文。 监控项(item): 你想要接收的主机的特定数据，一个度量数据。 触发器(trigger): 一个被用于定义问题阀值和评估监控项接收到的数据的逻辑表达式。 事件(event): 单次发生的需要注意的事情。 异常(problem): 一个处在异常状态的触发器。 动作(action): 一个对事件作出反应的预定义的操作。 升级(escalation): 一个在动作内执行操作的自定义场景。 媒介(media): 发送报警通知的手段。 通知(notification): 利用已选择的媒体途径把事情相关信息发送给用户。 远程命令(remote command): 预先定义好的，满足一定条件后，可在被监控主机上自动执行的命令。 模板(template): 一组可以被应用到一个或多个主机上的实体的集合。 应用(application): 一组监控项组成的逻辑分组。 Web场景(Web scenario): 利用一个或多个HTTP请求来检查网站的可用性。 前端(frontend): Zabbix提供的Web界面。 Zabbix API: Zabbix API允许你使用JSON RPC协议来创建、更新和获取Zabbix对象信息或执行任何其他的自定义的任务。 Zabbix server: Zabbix软件监控的核心程序，主要功能是与Zabbix proxies和agent进行交互、触发器计算、发送告警通知，并将数据集中保存等。 Zabbix agent: 部署在监控对象上，能够主动监控本地资源和应用。 Zabbix proxy: 帮助Zabbix server收集数据，分担Zabbix server的负载。 \r Zabbix进程 ","date":"2017-11-14","objectID":"/zabbix/:2:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"Agent zabbix agent部署在监控的目标上，主动监测本地的资源和应用（硬件驱动，内存，处理器统计等）。 zabbix agent手机本地的操作信息并将数据报告给zabbix server用于进一步处理。 zabbix agent有被动(passive)和主动(active)两种检查方式。 ## Server\rzabbix server是zabbix软件的核心程序。它通过轮询和捕获数据，计算是否满足触发器条件，向用户发送通知。\r它是zabbix监控代理和Proxy代理报告系统可用性和完整性数据的核心组件。zabbix server自身可以通过简单远程检查网络服务(如Web服务器和邮件服务器)。\rserver是一个包含了被存储了所有配置，统计方面的和可操作数据的中央仓库，它是监控系统问题升级以致于激活警告管理器的zabbix中的实体。 基本的zabbix server分三个不同的组件：zabbix server，web前端，数据库存储。 zabbix的所有配置信息都存储在服务器和web前端进行交互的数据库中。 zabbix server进程是以守护进程（Daemon）运行的。 ## Proxy\rzabbix proxy是一个可以从一个或多个受监控的设备设备收集监控数据，并将信息发送到zabbix server的进程，基本上是代表server工作。\r所有收集的数据都在本地进行缓存，然后传送到proxy所属的zabbix server。\rzabbix proxy是完成远程区域、分支机构、没有本地管理员的网络的集中监控的理想解决方案。 zabbix proxy需要使用独立的数据库，以守护进程的方式运行。 ## Java gateway\rzabbix守护进程原生支持监控JMX程序，它被称为zabbix java gateway。zabbix gateway是用Java语言写成。\r要查得一台主机特定的JMX计数器值，zabbix server向zabbix java gateway发送请求，后者使用JMX管理API去请求远程的有关应用。应用不许额外安装软件，只需要启动时在命令行指定 -Dcom.sun.management.jmxremote即可（是在java程序）。 每个zabbix server或zabbix agent只能配置一个java gateway。 \r## Sender\rzabbix sender是一种命令行应用，它可以将性能数据发送到zabbix server进行处理。该应用通常用在长时间运行的用户脚本，用于定期发送可用性和性能数据。\r zabbix_sender -z zabbix -s \"xxx\" -k db.connections -0 43 -z :server主机 -s :受监控主机的技术名称 -k :监控项的键 -o :要发送的值 ## Get\rzabbix get也是一种命令行应用，用于与zabbix agent进行通信，并从agent那里获取所需的信息。\r该应用通常被用于zabbix agent故障排除\r zabbix_get -s $host -p xxx -k system.cpu.load[all,avg15] -s --host -p --port -I --source-address -k --key -h --help -V --version \r 安装Zabbix ","date":"2017-11-14","objectID":"/zabbix/:3:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"Zabbix安装要求 硬件： 内存，最小128MB； 磁盘，最小256MB； CPU，可能需要大量CPU资源； SMS(短信)通知服务，串行通讯口(serial communication port)和串口GSM调制解调器(serial GSM modem)。可选项。 支持平台： Linux; IBM AIX; FreeBSD; NetBSD; OpenBSD; Mac OS X; Solaris; Windows(Only Agent). 软件： Zabbix基于Apache Web服务器、领先的数据库引擎和PHP脚本语言进行构建。 数据库管理系统： MySQL 5.0.3 及以上； Oracle 10g 及以上； PostgreSQL 8.1 及以上； SQLite 3.5及以上； IBM DB2 9.7 及以上。 前端： Apache 1.3.12 及以上； PHP 5.4.0及以上； PHP-Extension: 软件 | 版本 | 备注 | - | - gd | 2.0及以上 | PHP GD扩展包必须支持PNG图片 bcmatch | | php-bcmatch ctype | | php-ctype libXML | 2.6.15及以上 | php-xml xmlreader | | php-xmlreader xmlwrite | | php-xmlwriter session | | php-session sockets | | php-net-socket mbstring | | php-mbstring gettext | | php-gettext ldap | | php-ldap mysqli | | 使用MySQL作为Zabbix后端数据库所需的组件 pgsql | | 使用PostgreSQL作为Zabbix后端数据库所需的组件 sqlite3 | | 使用SQLite作为Zabbix后端数据库所需的组件 客户端浏览器： 必须启用Cookie和JavaScript功能。 服务器： 要求 | 描述 | | - | OpenlPMI | 支持IPMI功能所需组件 | libssh2 | 支持SSH功能 | fping | 支持ICMP ping功能 | libcurl | 支持Web监控，VMware监控及SMTP认证 | libiksemel | 支持Jabber功能 | libxml2 | 支持VMware监控 | net-snmp | 支持SNMP监控 | Java网关： Java gateway编译和运行在Java 1.6 及以上版本。 数据库容量： Zabbix配置数据需要使用固定的磁盘空间，而这个空间不会过多增长。 Zabbix数据库容量主要依赖于以下参数： 每秒处理值的数量(Number of processed values per second); 历史(History)数据的回收清理设置(Housekeeper); 趋势(Trends)数据的回收清理设置(Housekeeper); 事件(Events)数据的回收清理设置(Housekeeper)。 时钟同步： 对于Zabbix稳定运行而言，服务获取精确的系统时间是非常重要的。对于所有运行Zabbix组件的系统，强烈建议这些系统的时间保持同步。 ntpd是一个临幸的用于同步主机和其他服务器之间的时间的后台程序。 ## 安装、启动、配置Zabbix\rZabbix-repo仓库：[repo.zabbix.com](repo.zabbix.com)\r该仓库服务器同时提供`yum`和`apt`源码库。\r","date":"2017-11-14","objectID":"/zabbix/:4:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"配置源码库 1. 从官方下载源码库 #rpm -ivh http://repo.zabbix.com/zabbix/$version/rhel/7/$arch/$zabbix-release.rpm rpm -ivh http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-1.el7.centos.noarch.rpm #阿里云镜像 #rpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-1.el7.noarch.rpm #镜像失效的话自己去官网找 2. 手动配置zabbix.repo vim /etc/yum.repos.d/zabbix.repo [zabbix] name=Zabbix-Repo baseurl=http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/ gpgcheck=0 enable=1 ### 安装Zabbix部署包\r使用MySQL数据库安装Zabbix Server、Web前端： yum install -y zabbix-server-mysql zabbix-get 注意：此处Zabbix数据库使用MySQL，请自行安装MySQL。 安装Zabbix Agent： yum install -y zabbix-agent ### 安装初始化数据库\r查看刚刚安装的 zabbix-server-mysql： 解压得到的sql脚本create.sql只会在对应的数据库中初始化zabbix所需要的数据库表，但是不会创建zabbix数据库。所以后面我们还需要手动创建zabbix数据库。 rpm -ql zabbix-server-mysql cd /usr/share/doc/zabbix-server-mysql-3.x.xx/ #有一个create.sql.gz的压缩文件 gunzip create.sql.gz #得到create.sql 在MySQL中创建zabbix数据库： msyql -uxxx -p mysql\u003eCREATE DATABASE 'zabbix' DEFAULT CHARACTER SET 'utf8'; mysql\u003eSHOW DATABASES; mysql\u003eGRANT ALL ON zabbix.* TO 'zabbix'@'localhost' identified by 'zabbix'; mysql\u003eFLUSH PRIVILEGES; #导入sql脚本 mysql -uroot -p -Dzabbix \u003c ./create.sql USE zabbix; SHOW TABLES; #mysql限制IP vim /etc/my.cnf [mysqld] bind-address=127.0.0.1 ![zabbix-database alt=\"zabbix-database\"](/images/zabbix_database.png)\r\r### 配置zabbix server并启动\r编辑zabbix server配置文件： vim /etc/zabbix/zabbix_server.conf #常会修改的参数 #数据库配置 DBHost=localhost DBName=zabbix DBUser=zabbix DBPassword=zabbix DBPort=3306 DBSocket=/var/lib/mysql/mysql.sock #服务监听端口 ListenPort=10051 #服务端源IP SourceIP= #日志记录方式，file使用指定文件作为日志文件，system将日志发往syslog，console将日志发送控制台 LogType=file LogFile=/var/log/zabbix/zabbix_server.log 启动zabbix服务端： systemctl start zabbix-server #此处可能由于没有关闭SELinux而报错 tail /var/log/zabbix/zabbix_server.log cannot set resource limit: [13] Permission denied #关闭SELinux setenforce=0 vim /etc/selinux/config SELINUX=disabled #查看zabbix-server默认监听的10051端口 netstat -nltp ### 安装zabbix web\rzabbix web可以安装在单独的主机上，只要能连接到zabbix database所在数据库就行。但为了方便，都安装在了server上。\rzabbix web需要LAMP环境： #可能需要自己配置PHP remi源，注意PHP及扩展版本问题 yum install -y httpd php php-mysql php-mbstring php-gd php-bcmatch php-ldap php-xml #指定php版本 #yum --enablerepo=remi-php56 install php-mysql php-mbstring php-gd php-bcmatch php-ldap php-xml 安装zabbix web所需的两个包： yum install -y zabbix-web zabbix-web-mysql #此处默认使用php5.4 #因为我的环境是php5.6,会报错 #此时就需要指定php版本来安装 yum --enablerepo=remi-php56 install zabbix-web zabbix-web-mysql rpm -ql zabbix-web #zabbix-web位于/usr/share/zabbix/ ","date":"2017-11-14","objectID":"/zabbix/:4:1","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"编辑zabbix的前端Apach-PHP配置文件 zabbix前端的Apache配置文件位于 /etc/httpd/conf.d/zabbix.conf: vim /etc/httpd/conf.d/zabbix.conf #需修改时区 php_value max_execution_time 300 php_value memory_limit 128M php_value post_max_size 16M php_value upload_max_filesize 2M php_value max_input_time 300 php_value always_populate_raw_post_data -1 php_value date.timezone Asia/Shanghai #建议顺便修改/etc/php.ini的时区 vim /etc/php.ini date.timezone = Asia/Shanghai #添加httpd的虚拟主机访问zabbix web \u003cVirtualHost IP:80\u003e servername zabbix.me documentroot /usr/share/zabbix 默认数据 \u003c/VirtualHost\u003e #开启httpd服务 systemctl start httpd ![/etc/httpd/conf.d/zabbix.conf](/images/Zabbix/zabbix_conf.png)\r\r添加hosts后就可以利用域名访问zabbix-web端了。\r echo -e \"192.168.1.9 \\t zabbix.me\" \u003e\u003e /etc/hosts ### 在web端配置zabbix\r在浏览器访问 http://zabbix.me 初始化zabbix配置。 配置好后就需要用账号密码进行登录zabbix-web端dashboard。 默认用户名是：admin，密码是配置文件里面设置的。 登录进Dashboard后，可修改语言为中文。 如果你的Zabbix无法看到中文选项，那么可能需要如下操作： vim /usr/share/zabbix/include/locales.inc.php #修改 'zh_CN' =\u003e ['name' =\u003e _('Chinese (zh_CN)'), 'display' =\u003e true], 如果又遇到中文乱码的问题，则可以从windows中挑选一些好看的中文字体，将对应字体文件放置到zabbix web的字体目录中。 windows中字体后缀.TTF，Linux中为.ttf。注意修改大小写。 cd /usr/share/zabbix/fonts #只有一个默认字体 graphfont.ttf #将新字体放置到此目录下 #修改配置文件中对应字体名称 vim /usr/share/zabbix/include/define.inc.php #将默认字体名字修改为字体目录下 你需要的字体名 define('ZBX_FONT_NAME', 'graphfont'); define('ZBX_GRAPH_FONT_NAME', 'graphfont'); // font file name #栗子，如perpetua字图PER.ttf define('ZBX_FONT_NAME', 'PER'); define('ZBX_GRAPH_FONT_NAME', 'PER'); // font file name 图形显示乱码，同样是用以上方法。在windowss上找一个中文字体上传到zabbix字体目录，并修改配置文件就可以了。 Zabbix Web界面菜单： 管理菜单，用于管理zabbix自身及zabbix相关设置； 配置菜单，用于配置监控相关设置； 报表菜单，为管理员生成一段时间内的监控统计信息； 检测中菜单，用于查看被监控的相关数据； 资产记录菜单，查看被监控的主机有哪些，以及相关的资产信息。 ","date":"2017-11-14","objectID":"/zabbix/:4:2","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"安装zabbix agent Agent端安装也非常方便，直接在Client上安装两个包即可。 #配置zabbix源 rpm -ivh http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-1.el7.centos.noarch.rpm #aliyun镜像 #rpm -ivh http://mirrors.aliyun.com/zabbix/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-1.el7.noarch.rpm #安装 yum install -y zabbix-agent zabbix-sender rpm -ql zabbix-agent #/etc/zabbix/zabbix_agentd.conf zabbix的“主动模式”与“被动模式”都在/etc/zabbix/zabbix_agentd.conf中定义。 配置最常用的agent端： vim /etc/zabbix/zabbix_agentd.conf ####GENERAL PARAMETERS 通用配置 PidFile= LogFile= ####Passive checks related 被动模式配置 #指定允许哪台服务器拉取本机数据 Server= #指定agent端工作于被动模式时监听的端口号 ListenPort=10050(默认) #指定agent端工作与被动模式时所监听的IP地址 ListenIP=0.0.0.0(默认) #指定预生成的agent进程数量 StartAgents= ####Active checks related #agent工作于主动模式时，将消息推送到哪台Server上 ServerActive=IP1,IP2... #指定当前主机主机名，Server端通过对应的主机名识别主机 Hostname= #指明agent端每隔多少秒将采集的数据发往Server端 RefreshActiveChecks= #栗子 Server=192.168.1.9 ServerActive=192.168.1.9 Hostname=zabbix.me **启动zabbix-agent**\r```sh\rsystemctl zabbix-agent start\r#查看状态,默认端口10050 netstat -nltp ![zabbix-agent状态](/images/Zabbix/zabbix-agent.png) \u003cbr\u003e \u003cbr/\u003e --- # 快速开始zabbix-web菜单 zabbix-web界面中包含有**监测中、资产记录、报表、配置、管理**五项菜单。 \u003cbr\u003e ## 登录和配置用户 在浏览器输入 [zabbix.me](zabbix.me) (修改hosts)，登录zabbix-web后台。 默认用户名：**Admin**，密码：**zabbix**。它是超级管理员。 为了防止暴力破解和词典攻击，连续尝试五次登录失败，zabbix界面将暂停30秒。 \u003cbr\u003e 可以通过**管理(Management)**菜单下的**用户(User)**，新建、查看、管理用户信息。 zabbix在安装后自定义了两个用户： - Admin用户是zabbix的超级管理员，拥有所有权限； - Guest用户是一个特殊的默认用户。如果你没有登录，你访问zabbix的时候其实就是“guest”权限。guest默认没有任何权限。 你可以创建一个用户(user)并将其加入特定的用户组(Group)以提升用户权限。 ![新建用户](/images/Zabbix/user.png) 可以仅用用户信息里面-报警媒介里面，自定义严重性的报警。只有勾选部分的报警信息才会发送过来。这也很棒！ 如果存在严重性则使用： - [ ] Not classified - [ ] Information - [ ] Warning - [ ] Average - [ ] High - [ ] Disaster ![Use if severity](/images/Zabbix/Useifseverity.png) \u003cbr/\u003e \u003cbr\u003e ## 新建主机 zabbix中的主机(host)是一个你想要监控的网络实体(物理的、虚拟的)。对于主机的定义非常灵活。它可以是一台物理服务器，一个网络交换机，一个虚拟机或一些应用。 \u003cbr\u003e 可以通过**配置(Configuration)**菜单下的**主机(Host)**，查看已配置主机相关信息。 默认有一个“Zabbix Server”的定义好的主机。 点击**创建主机(Create host)**后，填写对应的主机名称、添加对应的主机群组，zabbix-agent的IP地址和端口，以及其它信息。 ![创建主机](/images/Zabbix/host.png) \u003cbr\u003e \u003cbr\u003e ## 新建监控项 监控项是zabbix中获得数据的基础。没有监控项，就没有数据。因为一个主机中只有监控项定义了”单一的指标“或者”需要获得的数据“。 \u003cbr\u003e 可以通过**配置(Configuration)**菜单下的**主机(Item)**，找到需要配置**监控项(Item)**的主机，然后创建监控项。 主机默认是没有定义任何监控项的。 填写对应的监控名称、类型、键值、主机接口、信息类型等等信息。 ![添加监控项](/images/Zabbix/create-item.png) \u003cbr\u003e 可在**监控(Monitoring)**菜单中**最新数据(Latest data)**查看之前定义的监控项和获得的值。 还可选择以**图形(Graph)**或**值**来查看监控项的相关信息。 ![upload监控信息](/images/Zabbix/upload.png) 同样也还以在Zabbix-Server端获得数据信息： ```sh #zabbix_get -s $ip -k $value zabbix_get -s 192.168.1.9 -k system.cpu.load ","date":"2017-11-14","objectID":"/zabbix/:5:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"新建触发器 监控项只用于收集数据。如果要自动评估收到的数据，我们则需要定义触发器(trigger)。 触发器包含了一个表达式，这个表达式定义了数据的可接受的阈值级别。 如果收到的数据超过了定义好的级别，触发器将被触发，或者进入异常状态(problem)。 从而引起我们的注意，让我们知道有问题发生。如果数据再次恢复到合理范围，触发器将会转到正常状态(OK)。 可以通过**配置(Configuration)菜单下的主机(Hosts)选项，找到某主机的触发器(Triggers)**创建触发器。 填写对应的触发器名称、表达式、描述等信息。 ","date":"2017-11-14","objectID":"/zabbix/:6:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"获取问题通知 当监控项收集了数据后，触发器会根据异常状态触发报警。根据一些报警机制，它也会通知我们一些重要的事情，而不是直接在zabbix-web端进行查看。 这就是通知(Notification)的功能。 E-mail是最常用的异常通知发送方式。当然还有SMS（短信），脚本等媒体类型。 可以通过管理(Administration)菜单中的报警媒体类型(Media types)，点击预定义媒体类型列表中的Email，来配置Email。 为了建立一个通知，我们需要在配置菜单下动作中，创建动作(Create action)。 一旦满足了触发器的条件，变回触发执行动作。如收到E-mail等… \r","date":"2017-11-14","objectID":"/zabbix/:7:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"新建模板 如果我们配置上前台主机，一些自动化操作会带来更多便利性。没错，**模板(templates)**功能就可以实现。 模板允许对有用的监控项、触发器和其他对象进行分组，只需要一步就可以对监控主机应用模板，已达到反复重用的目的。 当一个模板链接到一个主机后，主机会继承这个模板中的所有对象。简单而言，一组预先定义好的检查会被快速应用到主机上。 Zabbix为各种操作系统、设备以及应用准备好了一些预定义的模板。你可以快速部署使用他们。 但是请注意，一些模板需要根据你的实际情况和使用环境进行适当俄调整。 比如，一些检查项是不需要的，一些轮询周期过于频繁等。 \r在**配置**菜单下的**模板(Templates)**下，点击**创建模板(Create template)**。填写对应的模板名称，群组等信息。\r![创建模板](/images/Zabbix/create-template.png)\r创建模板完毕后，可将模板链接到主机。之后，模板及其所有对象被添加到了主机。 配置(Configuration) ","date":"2017-11-14","objectID":"/zabbix/:8:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"主机和主机组(Hosts and groups) 一般来讲，zabbix主机是指你希望监控的那些设备。如服务器、工作站、交换机等。 创建主机是使用zabbix过程的首要任务。 我们可以把主机组想象成项目组。根据不同的功能将主机划分到主机组是非常重要的，这样可以对以后创建的用户和用户组在定义权限的时候，不用给他们zabbix admin权限，而只需要根据主机组(项目组)给予用户和用户组对应项目(主机组)的权限即可。 这样很大程度上方便了Zabbix监控多个项目，也利于管理。同样，报警的时候也只会收到权限内的相关报警信息。 ","date":"2017-11-14","objectID":"/zabbix/:9:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"配置一台主机 配置–主机–创建主机–填写相关参数信息。 可以在已经存在的主机上使用 Clone或Full Clone创建一个新主机。 Clone将保留所有的主机参数和模板链接； Full Clone将额外保留指数实体(应用集、监控项、触发器、视图、规则、Web场景)。 新建主机下： 主机(Host)：包含了通用的主机属性； 模板(Template)：允许将模板链接诶到主机，所有实体将从模板继承； IPMI：包含IPMI管理属性； 宏(Macros)：允许定义主机级别的用户宏； 主机资产记录(Host inventory)：允许为主机收工输入库存信息； 允许你请求与主机的加密的连接。 ","date":"2017-11-14","objectID":"/zabbix/:9:1","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"资产管理(Inventory) 你可以将联网设备的资产信息保存在zabbix里。 资产信息实在配置主机时人工录入建立的资产信息数据，或者通过使用某些自动填充选项完成的录入。 构建资产库： 手动模式： 在配置一台主机的时候，手动输入资产信息； 自动模式： 在配置主机的时候，选择自动。 之后便可以在资产记录菜单中的概述，主机项中查看相关信息。 \r","date":"2017-11-14","objectID":"/zabbix/:9:2","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"批量更新(Mass update) 有时候可能需要一次更改多个主机的某些属性，使用**批量更新(mass update)**功能来代替打开每个主机进行编辑。 可批量处理主机、模板、IPMI、资产、加密相关信息。 \r","date":"2017-11-14","objectID":"/zabbix/:9:3","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"监控项(Items) 监控项是从主机收集的数据信息。 配置主机后，需要添加一些监控项以开始获取数据。快速添加多个监控项的一种方法是将预定义的模板附加到主机。 在单个监控项中，可指定从主机收集哪些数据信息。 为此，可使用监控项key。 如system.cpu.load将收集处理器负载的数据。 要给 key 指定更过参数，请在后面添加方括号[]。 如system.cpu.load[avg5]， 返回最近5分钟的CPU负载平均值。 ","date":"2017-11-14","objectID":"/zabbix/:10:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"创建一个监控项 可在主机中新建一个监控项。 不支持的监控项：如果由于某种原因无法检索该值，则该监控项可能不被支持。这些监控项仍然以固定的间隔重新检查。 监控项的key: key名称允许使用字符： 0-9a-zA-Z_-. key参数，用 逗,号 分隔： xxx[par1,par2…] key参数也可以为空，此时使用默认值： key key参数带引号，则允许任何Unicode字符，如果包含双引号则需要 \\反斜杠 转义 key参数是一个数组，它需要包含在方括号中 自定义间隔(Custom intervals) 创建关于监控项的自定义时间规则。 灵活间隔被设计为重新定义默认监控项的的更新间隔，但调度间隔用于指定独立执行的检查计划。 **灵活的间隔(Flexible intervals)：**允许重定义特定时间段的默认间隔。 间隔(Interval)： 指定时间段的更新间隔； 期间(Period)： 灵活间隔有效的时间段； 举个栗子： 60(interval), 1-7,00-24(period)。监控项每隔60s检查一次。 \r**调度间隔(Scheduling intervals)：**用于在特定时间检查监控项。 调度间隔定义为， md\u003cfilter\u003ewd\u003cfilter\u003eh\u003cfilter\u003em\u003cfilter\u003es\u003cfilter\u003e。 md: month days(1-31) wd: week days(1-7) h: hours(0-23) m: minutes(0-59) s: seconds(0-58) : 指定其前缀的值—-[from-to/step]。 其实类似于Linux中定时任务的写法，只不过这里把单位(md,wd,h,m,s)写在了数值的前面。 举个栗子： md1-15 #1-15号 wd3 #星期三 h0-12 #上半天 m1,3,5,7,9 #每个1,3,5,7,9分钟 s/10 #每个10s #组合体 wd1-5h9-18m/10 #每个工作日的上班时间每个10分钟 ","date":"2017-11-14","objectID":"/zabbix/:10:1","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"监控项类型(Items type) 监控项类型包含从系统获取数据的多种方式。每个监控项类型都有一组自己支持的监控项key和所需的参数。 zabbix提供的监控项类型： zabbix代理检查(agent checks) SNMP代理检查 SNMP traps IPMI检查 简单检查(simple checks) VMware监控(monitoring) 日志文件监控 计算监控项(Calculated items) zabbix内部检查(internal checks) SSH检查 Telnet检查 外部检查(External checks) 汇总检查(Aggregate checks) 捕捉器监控项(Trapper items) JMX监控 ODBC监控 zabbix代理(zabbix agent)： 这些检查与zabbix代理进行通信实现数据的采集。 zabbix agent-passive： 被动模式，Server向Agent索要数据； zabbix agent-active： 主动模式，Agent主动上报数据给Server。 可支持的监控项，可在新建监控项是在键值里面查看。 SNMP代理(SNMP agent)： 在启用SNMP的设备(如打印机，交换机，路由器…)上使用SNMP监控，为了能够监控SNMP代理在这些设备上提供的数据，zabbix服务器初始化配置时必须具有SNMP支持。 仅通过UDP协议执行SNMP检查。 配置SNMP监控： 使用SNMP接口为设备创建一个主机； 找出要监控项目的SNMP字符串； 创建一个监控项。 IPMI检查： 你可以在zabbix中监控 智能平台管理接口(IPMI) 设备的运行状况和可用性。 要执行IPMI检查，zabbix服务器必须首先配置IPMI支持。 简单检查： 简单检查通常用于远程无代理监控服务。 日志文件监控： zabbix可用于集中监控和分析 具有/不具有 日志转动能力的日志文件。 当日志文件包含某些字符串或字符串模式时，通知信息可用于警告用户。 \r计算监控项： 计算监控项是创建虚拟数据源的一种方式。这些值将根据算术表达式定期计算。所有计算都由Server完成。 **内部检查：**\r内部检查可以监控zabbix的内部检查。即Server或Agent Server的运行情况。\r**SSH检查：**\r运行SSH检查是作为无代理监控的，SSH检查不需要zabbix代理。 执行SSH检查zabbix服务器必须初始化配置为SSH2支持。 SSH检查提供两种身份验证方法，一种是用户/密码，另一种是基于密钥文件。 zabbix SSH 密钥配置: vim /etc/zabbix/zabbix_server.conf #SSHKeyLocation= SSHKeyLocation=/home/zabbix/.ssh usermod -m -d /home/zabbix zabbix chown zabbix:zabbix /home/zabbix chmod 700 /home/zabbix cd /home/zabbix \u0026\u0026 su zabbix ssh-keygen -t rsa 外部检查： 外部检查是由zabbix Server通过运行shell脚本或二进制的检查。 外部检查不需要再被监控的主机上运行任何代理。 \r汇总检查： 在汇总检查中，zabbix通过直接从数据库中查询监控信息，然后进行信息聚合。 聚合检查不需要再被监控的主机上运行任何代理。 捕捉器监控项： 捕捉器监控项接收传入的数据，而不是查询它。对于想要推送到zabbix的任何数据都是适用的。 要使用捕捉器监控项，需要在zabbix中建立一个捕捉器监控项，将数据送给zabbix。 JMX监控项： JMX监控可用于监视Java应用程序的JMX计数器。 JMX监视器以zabbix守护进程方式运行，名为zabbix java gateway。 \rODBC监控： ODBC监控对应于zabbix web管理端中的数据库监控器监控项类型。 ODBC是用于访问 数据库管理系统(DBMS) 的C语言中间件API。 zabbix可以查询ODBC支持的任何数据库。为了实现监控，zabbix不直接连接到数据库，而是使用ODBC中设置的ODBC接口和驱动。 该功能允许为多个目的更加有效地监控不同的数据库。 \r","date":"2017-11-14","objectID":"/zabbix/:10:2","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"历史与趋势(history and trends) 历史与趋势是zabbix中存储数据的两种方式。 历史保持每个收集的值，而趋势是每小时的平均信息。 建议保持的历史数据尽可能少，但可以保留更多的趋势数据。 ","date":"2017-11-14","objectID":"/zabbix/:10:3","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"用户自定义参数(user parameter) 有时你想运行一个代理检查，但它不是zabbix预定义的。这时就能用到用户参数。 用户参数是由zabbix代理之星的命令，最多可以返回512KB的数据。 key 是唯一的。 用户参数用法： UserParameter=\u003ckey\u003e,\u003ccommand\u003e #栗子 UserParameter=ping,echo 1 #使用ping键为一个监控项返回 1 #复杂栗子 UserParameter=mysql.ping,mysqladmin -uroot -ppwd ping | grep -c 'alive' #mysqld状态为alive返回1，否则0 #灵活的用户参数 UserParameter=key[*],command #[*]定义该key接受括号内的参数 #栗子 UserParameter=ping[*],echo $1 UserParameter=mysql.ping[*],mysqladmin -u$1 -p$2 ping | grep -c 'alive' #mysql.ping[zabbix,passwd] UserParameter=wc[*],grep -c \"$2\" $1 #wc[/etc/passwd,root] **用户自定义参数扩展zabbix代理：**\r是将key添加到被监控的主机哦！\r```sh\r#编写命令--SQL查询总数\rmysqladmin -uxxx -pxxx status | cut -f4 -d\":\" | cut -f1 -d\"S\"\r#将命令添加到zabbix_agentd.conf vim /etc/zabbix/zabbix_agentd.conf #找到如下字段 ","date":"2017-11-14","objectID":"/zabbix/:10:4","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"Option: UserParameter UserParameter=mysql.totalquery,mysqladmin -uroot -pxxx status | cut -f4 -d\":\" | cut -f1 -d\"S\" #mysql.totalquery这个key是唯一的标识符 #测试此参数 ##测试参数可用与否很重要哈 zabbix_agentd -t mysql.totalquery #重启zabbix-agent，将重新加载配置 zabbix_get -s $host -k mysql.totalquery \u003cbr\u003e ### 可加载模块(loadable modules) 可加载模块提供了一种关于zabbix性能扩展的选项。 可加载模块基本上只zabbix守护程序使用的共享库，并在启动时加载。 可加载模块具有很多优点，卓越的性能和可实现任何逻辑的能力，更重要的是使用和共享了zabbix模块的开发能力。 \u003cbr/\u003e ### windows性能计数器(windows perfomance counter) 使用perf_counter[]key有效的监控windows性能计数器 \u003cbr\u003e ### 批量更新(mass update) 使用批量更新功能，可一次更改多个监控属性。 \u003cbr\u003e ### 值映射(value mapping) 对于接收值更人性化的表示，可以使用包含数值和字符串之间的映射的**值映射**。 如： - 0 ---\u003e error - 1 ---\u003e true - F ---\u003e Full - D ---\u003e Differential - I ---\u003e Incremental - ... \u003cbr/\u003e ### 应用集(Application) **应用集**对逻辑组中的监控项进行分组。 如，对MongoDB的可用性，空间，负载，慢查询，执行命令...，可归于 MongoDB应用于中。 \u003cbr\u003e ### 队列(queue) **队列**显示正在等待刷新的监控项。 队列只是一个逻辑表达的数据。 队列显示的统计信息是zabbix服务器性能是否健康的指标。 在 管理--队列 下对去队列。 \u003cbr/\u003e ### 值缓存(value cache) 为了计算触发表达式，以及让计算/聚合监控项和一些宏更快，zabbix服务器支持值的缓存选项。 在内存中的缓存可用于访问历史数据，而不用之间调用数据库。如果缓存中不存在历史值，则从数据库请求缺少的值，并相应地跟新缓存。 要启用值缓存功能，修改zabbix_server.conf中可选的ValueCacheSize参数。 \u003cbr\u003e \u003cbr/\u003e ## 触发器(Trigger) 触发器是评估有项目采集的数据并表示当前系统状况的逻辑表达式。 触发器表达式允许定义一个什么状况的数据是“可接受”的阈值。如果超过了可接受状态，则触发器会被触发。 \u003cbr\u003e ### 配置一个触发器(configuring a trigger) 在主机里面配置触发器。 \u003cbr/\u003e ### 触发器表达式(trigger expression) 一个简单有效的表达式看起来像： ```sh {\u003cserver\u003e:\u003ckey\u003e.\u003cfunction\u003e(\u003cparameter\u003e)}\u003coperator\u003e\u003cconstant\u003e #如 {192.168.1.7:agent.ping.time()}=0 函数参数(function parameters)： 大多数数字型的函数接受秒数来作为参数。 #600s内所有值的总和 sum(600) #随后5个值总和 sum(#5) avg() count() last() min() max() #5m 可被 300s 代替 #1k 代表 1024bytes 运算符(operators)： 优先级 | 运算符 | 定义 | - | - 1 | - | 负号(minus) 2 | not | 逻辑非(NOT) 3 | *, / | 乘，除 4 | +, - | 加，减 5 | \u003c, \u003c=, \u003e, \u003e= | - 6 | =, \u003c\u003e | 相等，不等于 7 | and | 逻辑与 8 | or | 逻辑或 触发器示例： {www.zabbix.com:system.cpu.load[all,avg1].last()}\u003e5 {www.zabbix.com:system.cpu.load[all,avg1].last()}\u003e5 or {www.zabbix.com:system.cpu.load[all,avg1].min(10m)}\u003e2 {www.zabbix.com:net.if.in[eth0,bytes].min(5m)}\u003e100k {$url1:net.tcp.service[smtp].last()}=0 and {$url2:net.tcp.service[smtp].last()}=0 {$host:icmpping.count(30m,0)}\u003e5 {$host:system.cpu.load[all,avg1].min(5m)}\u003e2 and {$hsot:system.cpu.load[all,avg1].time()}\u003e000000 and {$host:system.cpu.load[all,avg1].time)()}\u003c060000 ... 滞后(Hysteresis): 有时候需要一个触发器状态OK和PROBLEM之间的间隔，而不是简单的阈值。 要做到这一点，我们首先定义一个PROBLEM事件的触发器表达式，然后为OK选择 ‘Recovery expression’，并未OK事件书如不同的表达式 如： #Problem expression {server:temp.last()}\u003e20 #Recovery expression {server:temp.last()}\u003c=15 #两者之间便有了几个滞后值 ","date":"2017-11-14","objectID":"/zabbix/:10:5","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"触发器依赖(trigger dependency) 有时候，一台主机的可用性取决于另一台主机。如一台路由器后的上网设备。 这就是主机之间某些依赖关系可能有用的地方，依赖关系设置的通知可能会被抑制，而只发送根本问题的通知。 zabbix中触发器的依赖，一个触发器可能有多个依赖于它的触发器。 路由器和路由器后的Server同时宕机，如果有依赖关系，则zabbix不会执行服务器的触发动作。 值得注意的是，如果触发器所依赖的触发器被禁用，则次触发器的事件和动作将不会被抑制。 ","date":"2017-11-14","objectID":"/zabbix/:10:6","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"批量更新 使用批量更新，可一次更改一些触发器的某些属性。 \r","date":"2017-11-14","objectID":"/zabbix/:10:7","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"触发器严重性(trigger severity) 触发器严重性定义了触发器的重要程度: 未分类(not classified), 灰色 信息(information), 淡蓝 警告(warning), 黄色 一般严重(average), 橙色 严重(High), 淡红 灾难(disaster), 红色 ","date":"2017-11-14","objectID":"/zabbix/:10:8","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"自定义触发器严重性(customising trigger) 在 管理 – 一般 – 触发器严重性，里面自定义触发器严重性。 \r","date":"2017-11-14","objectID":"/zabbix/:10:9","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"预测触发功能(predictive trigger function) 有时候有即将到来的问题的迹象。可以发现这些迹象，以便提前采取行动，以减小影响。 zabbix具有基于历史数据预测受监视系统的未来行为的工具，这些工具通过预测触发功能实现。 ","date":"2017-11-14","objectID":"/zabbix/:10:10","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"事件标签(event tag) 在zabbix中可以自定义事件标签，在触发器级别上定义事件标签。在事件标签定以后，相应的新事件被标记为时间标签数据。 在拥有自定义时间标签的情况下，可以变得更加灵活。 例如： 识别日志文件中的问题并单独关闭他们； 用它来过滤通知； 查看前端的事件标签信息； 从项目值中提取的信息作为标签值； 在通知中更好地识别问题； 通过使用模板级别的标签来建华配置任务； 使用低级别发现的标签创建触发器。 ","date":"2017-11-14","objectID":"/zabbix/:10:11","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"事件(Events) zabbix可以生成一下几种类型的事件： trigger events-触发器事件； discovery events-发现事件； auto registration events-自动注册事件； internal events-内部事件； 事件以时间戳，并可以发送Email等基础动作。 在 监控-问题 里面查看信息信息。 ","date":"2017-11-14","objectID":"/zabbix/:11:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"触发器事件生成(trigger events generation) 触发器状态的变化是事件最常见和最重要的来源。每次触发器的状态改变时，都会生成一个事件。 改时间包含了触发器状态变更的详细信息、发生时间以及信息的状态。 触发器会创建两种类型的事件：问题(problem)和正常(OK) ","date":"2017-11-14","objectID":"/zabbix/:11:1","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"手动关闭问题事件(manual closing of problems) 当触发器状态从“问题(problem)”变成“正常(OK)”时，很难判断是通过触发器表达式的方式解决。这时就需要手动解决。 只有在触发器中启用 “允许手动关闭” 选项，问题事件才可以被手动关闭。 ","date":"2017-11-14","objectID":"/zabbix/:11:2","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"其他事件来源(other event source) zabbix定期扫描网络发现规则中定义的IP范围，可以为每个规则单独配置检查频率。一旦发现主机或服务，就会生成一个发现事件。 zabbix可以生成以下事件： Service Up/Down Host Up/Down Service Discovered/Lost Host Discovered/Lost \r","date":"2017-11-14","objectID":"/zabbix/:11:3","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"事件关联(event correlation) 通常，在zabbix中正常事件会关闭所有的问题事件，但在某些情况下需要更细致的方法。可以根据事件标签关联问题事件。 如，当监控日志文件时，在日志文件中想要发现某些问题，并将它们单独关闭，而不是一起关闭。 \r","date":"2017-11-14","objectID":"/zabbix/:12:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"可视化(visualisation) ","date":"2017-11-14","objectID":"/zabbix/:13:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"图形(graphs) 大量的监控数据被采集到zabbix中，如果能用可视化的表现形式来查看，那就直观和容易多了。 zabbix为用户提供了如下图形： 监控项数据的内置简单图形 “simple graphs”； 创建更复杂的自定义图形 “customised graphs”； 特定图形 “ad-hosc graphs\"快速访问几个监控项的数据比较。 简单图形(simple graphs)： zabbix提供的简单图形，用来可视化显示监控项采集到的数据。并不需要配置就可以查看。 通过 监控-最新数据-图形 来展示图形。 自定义图形(customised graphs)： 自定义图形，提供定制功能。这就有点厉害了。这个是手动配置的。 可以为单个主机、多个主机、单个模板、多个模板创建自定义图形。 在 配置-主机-图形-创建图形 里编辑图形属性； 图形编辑后可点击预览。 特设图形(ad-hoc graphs)： 简单图形和自定义图形都不允许快速创建多个监控项目数据的比较图形，工作量小且没有维护。 在 检测-最新数据-旋转监控项前复选框-显示数据图(显示堆叠数据图) 下， 里面也包含了 正常和层积 的图形风格。 ### 拓扑图(networking maps)\r运维人员如果想要了解网络环境的基础设施状况，可以在zabbix中创建网络拓扑图。 配置拓扑图(configurating network maps): 在 监控-拓扑图 下，可以创建拓扑图。点击拓扑图中的 构造函数 选项，来打开编辑区域。 然后在编辑区域中添加元素和链接元素。 链接指示器(link indicators): 可以为网络拓扑图中的元素之间的链接分配一些触发器，当这些触发器状况为“Problem”时，可以在链接上体现出来。 如果多个触发器进入\"Problem\"状态，则严重程度最高的将决定链接的颜色和样式。 ### 聚合图形(screen)\r在zabbix的聚合图形页面上，你可把各种来源的信息聚集到一起，一边在单个屏幕上快速查看。 在 监测-图形聚合 下，对其进行创建、配置、管理和查看。 基本上，聚合图形是一个表格，你选择把每个表格有多少单元格以及其中要显示的元素。 元素如下： 简单图形； 简单图形原型； 用户自定义图形； 自定义图形原型； 拓扑图； 其他聚合图形； 纯文本信息； 服务器信息； 触发器信息； 主机/主机组信息； 系统状态； 数据概述； 时钟； 事件历史； 动作历史； URL。 ### 幻灯片演示(slide shows)\r在幻灯片演示中，可以配置多个聚合图形以设定的间隔逐个显示。 在 监测-聚合图形-幻灯片演示 下。 \r## 模板(template)\r模板是可以方便地应用于多个主机的一组实体。 配置模板(configuring a template)： 配置模板需要首先通过定义一些参数来创建模板，然后添加实例。 在 配置-模板-创建模板 链接模板(linking)： 链接是将模板应用于主机的过程，之后主机将拥有模板的所有实体。 嵌套(nesting)： 嵌套是一种包含一个或多个其它模板的模板方式。 可以在一个嵌套模板中奖一些模板链接在一起。 嵌套的好处在于，您只需要讲一个模板链接到主机，并且主机会自动继承链接的模板的所有实体。 ","date":"2017-11-14","objectID":"/zabbix/:13:1","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"事件通知(notifications upon events) 当配置了一些项目和触发器，并且由于触发器改变状态，现在正在发生一些事件，之后就要考虑 action。 发送通知是zabbix提供的主要操作之一。 为了能够发送和接收通知，必须： 定义一些media； 配置action，向指定的media发送消息。 action由condition和operation组成。当条件满足是，执行操作。 操作主要是 发送消息和执行远程命令。 ","date":"2017-11-14","objectID":"/zabbix/:14:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"media类型 媒体是zabbix中发送通知和警报的传送通道。 E-mail: 在 管理-媒体类型 下，配置Email。 SMS： zabbix支持使用连接到zabbix-server的串行端口的串行GSM调制解调器发送SMS消息。 确保： 串行设备的速度(在Linux下通常为/dev/ttyS0) 与 GSM调制解调器的速度相匹配。zabbix没有设置串行链路的速度，它使用默认设置。 zabbix用户对串行设备有读写访问权限。 GSM调制解调器输入PIN码，并在电源复位后保留PIN码。或者在SIM卡上禁用PIN。 管理-媒体类型下 要为用户分配电话号码：管理-用户-报警媒介，添加报警媒介(如电话号码等) Jabber： zabbix支持发送jabber消息。 Ez Texting： 可以使用 zabbix技术合作伙伴 Ez Texting发送信息。 脚本： 警报脚本在zabbix服务器上执行，这些脚本位于服务器配置文件中定义的目录中(AlertScriptsPath)。 cat /etc/zabbix/zabbix_server.conf AlertScriptsPath=/usr/lib/zabbix/alertscripts #创建报警脚本 vim /usr/lib/zabbix/alertscripts/zabbix_test.sh #!/bin/bash to=$1 subject=$2 body=$3 #可以同时给多个用户发送，用空格隔开 cat \u003c\u003cEOF | mail -s \"$subject\" \"to\" $body EOF 然后我们在创建脚本媒体的时候，写入相关参数。 ### actions\r可以根据所有支持的类型的时间定义操作： 触发事件：当trigger的状态从OK转到Problem或回转时； 发现事件； 自动注册事件； 内部事件； 配置-动作-创建动作 条件(condition) 只有在事件与定义的条件匹配的情况下才执行操作。 注意运算类型：似与非似 操作(operation) 操作：发送信息，执行远程命令。 发送消息 远程命令 (不支持在zabbix-agent上执行远程命令，需要在zabbix-server到代理的命令才能直接连接。远程命令限制255字符，可以将过个命令放置于新行上来执行过个命令。及时目标主机处于维护状态，也会执行远程命令). 配置-动作-操作，在操作细节中修改操作类型为远程命令。 在Zabbix代理（自定义脚本）上执行的那些远程命令必须首先在相应的命令中启用 zabbix_agentd.conf.确保 EnableRemoteCommands 参数设置为 1 并取消注释。 如果更改此参数，请重新启动代理守护程序。 vim /etc/zabbix/zabbix_agentd.conf EnableRemoteCommands=1 cd /usr/lib/zabbix/alertscripts #或修改zabbix-server.conf中的文件位置 vi sendmail.sh chown zabbix.zabbix ./sendmail.sh \u0026\u0026 chmod a+x ./sendmail.sh 接下来在动作中选择为执行远程命令，并在相应位置输入命令。 支持自定义脚本、SSH、Telnet等方式。 在信息中使用宏(using macros in messages)： 在消息主题和消息文本中，可使用宏来更有效的问题报告。 恢复操作(recovery operation): 恢复操作允许在问题解决时通知我们。 恢复操作支持消息和远程命令。 ","date":"2017-11-14","objectID":"/zabbix/:14:1","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"宏(macros) 官方支持的宏的完整列表：https://www.zabbix.com/documentation/3.4/manual/appendix/macros/supported_by_location zabbix支持许多在多种情况下使用的宏。宏是一个变量，由如下特殊语法标识。 宏类似于全局变量，宏是特别有用的，特别是在报警动作中。对于不同的细节加上特定的宏，能够使报警信息更加详细。 {MACRO} 根据在上下文汇总，宏解析为一个特殊的值。有效地使用宏可以节省时间，并使zabbix更加高效。 宏可以在监控项键值参数中使用。宏只能用在监控项键值参数的一部分中。 如item.key[server_{HOST.HOST}_local] 。 ","date":"2017-11-14","objectID":"/zabbix/:15:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"宏函数(macro function) 宏函数能提供自定义宏值的功能。 宏函数语法： {\u003cmacro\u003e.\u003cfunc\u003e(\u003cparams\u003e)} #\u003cmacro\u003e, 要定义的宏 #\u003cfunc\u003e, 要应用的函数 #\u003cparams\u003e, 以逗号分隔的函数参数列表 #栗子 {{ITEM.VALUE}.regsub{pattern, output}} ","date":"2017-11-14","objectID":"/zabbix/:15:1","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"用户宏(user macro) 除了支持开箱即用的宏之外，zabbix还支持更灵活的用户宏。 用户宏可在全局、模板和主机级别进行定义。有一个特殊语法： {$MACRO} 用户宏可用于： 监控项名称； 监控项键值参数； 触发器名称和描述； 触发器表达式参数和常量； 许多其他位置。 ","date":"2017-11-14","objectID":"/zabbix/:15:2","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"自动发现宏(LLD) 有一种自动发现(LLD)函数中使用的宏类型，可用于创建监控项、触发器和图形原型。然后，当发现真实的文件系统、网络接口等，这些宏将替换为真实的值，并且以这些值来创建真实的监控项、触发器和图形。 {#MACRO} ","date":"2017-11-14","objectID":"/zabbix/:15:3","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"用户和用户组(user and group) zabbix中所有用户都通过web前端去访问zabbix应用程序。并为每一个用户分配唯一的登录名和密码，被加密储存于zabbix数据库中。 配置用户(configuring user) 管理-用户，创建和管理用户。 权限(permission) 可定义相应的用户类型，如用户，管理员和超级管理员。 用户组(groups) 管理-用户组，创建和配置用户组。 \r 服务监控(service monitoring) 服务监控，旨在帮助那些想要高级业务监控的人。 在很多情况下，我们关注的不是底层细节，而是提供的可用性服务。 服务是分层表示监控数据。 IT Workstations workstation1 workstation2 Services 配置-服务，最高节点的服务是’root'。 你可以通过添加低级服务节点和各个节点服务创建下层层次结构。 \rWeb监控(web monitoring) 配置-主机-web监测，创建或修改web监测信息。 可使用zabbix检查几个网站可用性方面。(zabbix中包含libcurl库才行) 要使用web监控，需要定义web场景。包括一个或多个HTTP请求或步骤。Zabbix-Server根据预定义的命令周期性的执行这些步骤。 Web监测中的**要求的字段(required string)**支持正则表达式，所以这对于检索页面信息很有用。这个真的很有用！ 所有web场景会收集下列数据： 整个场景中所有步骤的平均下载速度； 失败的步骤数量； 最后一次错误信息 web场景的所有步骤，都会收集下列数据： 平均下载速度； 响应时间 HTTP状态吗 ","date":"2017-11-14","objectID":"/zabbix/:16:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"Web监控项(web monitoring items) 在创建web场景时，会自动添加一些新监控项进行监控。 创建场景后，zabbix会自动添加以下监控项进行监控，将它们链接到所选的应用程序。 场景的下载速度； 场景的失败步骤； 场景的最后一个错误消息； 举个栗子： ##创建Web监测 #配置-主机-Web监测-创建web监测 URL：web.zabbix.me/monitor.php 要求的状态码：200 超时：20s ##创建web监测触发器 #配置-主机-触发器-创建触发器 严重性：一般严重 #触发条件：状态码!=200 表达式：N\u003c\u003e200 ##创建触发报警对应的动作 #配置-动作-创建动作 #触发条件 触发器示警度=一般严重 or 触发器=web.zabbix.me #操作：发送Email 发送给zabbix administrator用户群组 仅送到Email 默认信息/自定义信息 ##在媒体类型中定义Email相关信息 #管理-报警媒体类型-Email SMTP服务器：smtp.xxx.com smtp端口：465 SMTP电邮：发件人Email 安全链接：SSL/TLS 认证：Usernameand passwd 用户名：xxx 密码： xxx ##接下来就可以测试接收报警Email了 \r 虚拟机监控(VM monitoring) zabbix支持对VMware的监控，使用low-levle-discovery(LLD)自动发现VMware hypervisors和虚拟机，并根据事先定义的主机原型，为这些虚拟机建立主机，添加监控。 zabbix中提供了几个模板，可以直接用来解控VMware vCenter 或 ESX hypervisor。 虚拟机监控分为两个步骤：\r- 首先，zabbix是通过VMware collector进程来监控虚拟机。这些进程通过SOAP协议从VMware服务获取必要的信息，对其进行预处理并储存到zabbix-server共享内存中；\r- 然后，zabbix-pollers通过zabbix简单检查VMware keys来检索这些数据。\r要使虚拟机监控正常工作，需要libxml2库和libcurl库的支持。 配置-自动发现-创建自动发现 配置-主机-自动发现 \r 维护(maintenance) 可在zabbix中为主机和主机组定义维护周期。 有两种维护类型：“继续对目标进行监控数据的收集” 和 “停止对目标进行监控数据的收集” 要在维护期间正常接收问题通知，必须在动作配置中的选项中取消选择暂停操作。 为了确保定期维护按照预期的时间进行，需要对zabbix的所有部分使用通用时区。 配置-维护-创建维护期 维护期的主机显示的是橙色背景！ 事件确认(event acknowledgment) zabbix中的问题事件可以由用户确认。 如果用户获得了有关问题时间的通知，可以访问zabbix前端，从时间导航到确认屏幕并确认问题。 当他们确认时，可输入评论或其他一些相关描述。 这样其他系统用户同样的问题，他们便会立即看到是否已被解决和目前的评论。 以这种方式，可以更协调的进行解决多个系统用户的问题的工作流程。 要确认事件，用户必须至少要有对相应触发器的读取权限。 在Dashboard下，在出现的问题里，点击确认，进入确认事件。\r也可在监控-问题下查看问题详细信息。\r 配置导出/导入(Configuration export/import) zabbix导入/导出功能，使得可以在一个zabbix系统与另一个zabbix系统之间交换各种配置实体。 类似于数据库的导入导出。即也可以对zabbix做备份。 可导出/导入的对象有：主机组； 模板； 主机； 拓扑； 图片； 聚合图形； 值映射。 数据也可导出： XML - 在前端 XML or JSON - 在zabbix API 导出的详细信息： 所有支持的元素都导出到一个文件中； 不导出从连链接模板继承的主机和模板实体； 由低级别发现创建的实体依赖于他们的任何实体不会导出。 导入详细信息： 第一次遇到错误停止导入； 导入支持XML和JSON文件； 使用“删除缺失”选项导入主机/模板时，导入的XML文件中不存在主机/模板宏也将被删除。 将Zabbix展现在Nginx上 毕竟现在Nginx用的多，那就把Apache换成Nginx吧！ Nginx仓库:http://nginx.org/packages/ 自己安装Nginx: 下载nginx-release-xx.rmp仓库源来安装； 手动创建/etc/yum.repo.d/nginx.repo； 直接下载ngix.rpm来安装； 直接下载源码来安装。 相较于Apache，Nginx也只是配置个server就行了。优化什么的自己弄。 vim /etc/nginx/conf.d/zabbix.conf server { listen 80; server_name zabbix.me; root /usr/share/zabbix; access_log /var/log/nginx/zabbix.access.log main; allow 127.0.0.1; allow Your-IP; deny all; location / { if (!-f $request_filename) { rewrite ^([^\\?]+)$ /index.php?1=$1 last; } } location ~ \\.php$ { root /usr/share/zabbix; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; } } nginx -t systemctl start nginx 下载就可以正常访问zabbix-web端了! \r Zabbix监控 Zabbix自带的templates基本涵盖了大部分监控信息。 大部分操作系统： OS Linux; OS AIx; OS FreeBSD; OS Solaris; OS Windows; … 大部分服务： CPU; Filesystems; HTTP/HTTPS service; Memory; Network interfaces; Processes; Secutity; Zabbix server/agent/Proxy; SMTP,POP,SSH,NTP, service; ICMP Ping; SNMP; … 虚拟机： VM VMware; VM WMware Hypervisor; … 网络设备： Cisco; Huawei; TPLink; HP; … 除了Zabbix自带的templates，你还可以下载templates并导入zabbix-server。\r例如PHP-FPM, MongoDB, Apache, Nginx, Redis等额外软件的监控就需要下载额外templates。 \r","date":"2017-11-14","objectID":"/zabbix/:17:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"监控MySQL ","date":"2017-11-14","objectID":"/zabbix/:18:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"使用Zabbix自带模板监控MySQL Zabbix默认带有MySQL的监控和模板，所以无需再去下载。不过需要配置用户，密码，主机，端口等信息。 vim /etc/zabbix/zabbix-agentd.d/userparameter_mysql.conf #For all the following commands HOME should be set to the directory that has .my.cnf file with password information. #这句话叫我们新建一个带有mysql密码信息的.my.cnf文件 #并把此配置文件里面的HOME改为.my.cnf所的在目录 #.my.cnf文件里面的用户要对MySQL数据库有权限才行，没有权限请记得加 [mysql] host=localhost user=zabbix password=zabiix socket=/var/lib/mysql/mysql.sock [mysqladmin] host=localhost user=root password=password socket=/var/lib/mysql/mysql.sock #测试 zabbix_get -s 127.0.0.1 -k mysql.ping #1 \r","date":"2017-11-14","objectID":"/zabbix/:18:1","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"使用Percona插件监控MySQL Zabbix默认带有MySQL的监控和模板，所以无需再去下载。不过需要配置用户，密码，主机，端口等信息。 但是Zabbix自带的MySQL监控太简陋了。 所以使用Percona提供的模板及监控。 Percona Monitoring Plugins-URL: https://www.percona.com/downloads/percona-monitoring-plugins/LATEST/ Percona Monitoring Plugins for Zabbix- Instructions: https://www.percona.com/doc/percona-monitoring-plugins/LATEST/zabbix/index.html 此插件地址需要我们选择Percona-Version和Software平台。 选择平台后，我们只需安装zabbix的rpm包就好： #安装rpm包 yum install -y https://www.percona.com/downloads/percona-monitoring-plugins/percona-monitoring-plugins-1.1.7/binary/redhat/7/x86_64/percona-zabbix-templates-1.1.7-2.noarch.rpm #安装软件 #注意php版本问题 yum install -y percona-zabbix-templates ls /var/lib/zabbix/percona #scripts目录有.sh脚本文件 #templates目录有配置文件和模板文件 #复制配置文件 cp /var/lib/zabbix/percona/templates/userparameter_percona_mysql.conf /etc/zabbix/zabbix_agentd.d/ #我看了一下，这个配置文件和zabbix自带的MySQL配置文件一样 #添加MySQL的相关信息 vim /var/lib/zabbix/percona/scripts/ss_get_mysql_stats.php $mysql_user = 'root'; $mysql_pass = 'password'; $mysql_port = 3306; $mysql_socket = '/var/lib/mysql/mysql.sock'; $mysql_flags = 0; #测试脚本 /var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh gg #10 #创建.my.cnf文件 vim /etc/zabbix/zabbix_agentd.d/.my.cnf [mysql] host=localhost user=root password=password socket=/var/lib/mysql/mysql.sock [mysqladmin] host=localhost user=root password=password socket=/var/lib/mysql/mysql.sock [client] host=localhost user=root password=password socker=/var/lib/mysql/mysql.sock #重启服务 systemctl restart zabbix-agent #测试 sudo -u zabbix -H /var/lib/zabbix/percona/scripts/get_mysql_stats_wrapper.sh running-slave #0/1 导入模板，模板文件位于：/var/lib/zabbix/percona/templates/zabbix_agent_template_percona_mysql_server_ht_2.0.9-sver1.1.7.xml 但我直接导入模板时报错——标签无效 “/zabbix_export/date”: “YYYY-MM-DDThh:mm:ssZ” 预计。 此模板需要先导入Zabbix2.4后再导出，然后再导入到Zabbix3.4。太麻烦。 所以需要下载修改过的模板： http://jaminzhang.github.io/soft-conf/Zabbix/zbx_percona_mysql_template.xml wget http://jaminzhang.github.io/soft-conf/Zabbix/zbx_percona_mysql_template.xml 下载之后导入模板，然后链接主机。 链接之后可以部分监控可能显示不支持的。 如：Received value [rm: 无法删除”/tmp/localhost-mysql_cacti_stats.txt\": 不允许的操作0] is not suitable for value type [Numeric (float)] 没有权限。 解决办法： cd /tmp chown -R zabbix:zabbix localhost-mysql_cacti_stats.txt systemcet restart zabbix-agent ","date":"2017-11-14","objectID":"/zabbix/:18:2","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"监控MongoDB 感谢大神： MongoDB-templates: https://share.zabbix.com/databases/mongodb/mongodb-for-zabbix-3-2 ; GitHub: https://github.com/oscm/zabbix/tree/master/mongodb 此github-repo中还包含了Oracle, php-fpm, postfix, redis, Nginx。可参看README.md来配置zabbix对它们的监控。 \r### 安装步骤\r1. 在zabbix-agent安装jq jq - Command-line JSON processor; yum install -y jq **2. 在zabbix-agent的MongoDB中创建用于监控的账号**\r创建用于读取MongoDB相关信息的账户及其权限。\r mongo \u003euse admin \u003edb.createUser( { user:'zabbix', pwd:'zabbix', roles:[{ role:'clusterMonitor', db:'admin'}] } ) **3. 在agent下载github仓库的MongoDB模板等文件**\r wget https://codeload.github.com/oscm/zabbix/zip/master -O master.zip #这里面不仅仅有mongodb，还有redis,php等。 #我们只需要进入mongodb目录就好 unzip master.zip cd ./zabbix-master/mongodb ls #mongodb.sh , 执行脚本 #userparameter_mongodb.conf ，配置脚本 #zbx_export_templates.xml，zabbix模板文件 **4. 移动并配置mongodb.sh**\r cp ./mongodb.sh /etc/zabbix chmod a+x /etc/zabbix/mongodb.sh vi mongodb.sh #如果HOST,PORT不是默认，请修改 DB_HOST=127.0.0.1 DB_PORT=27017 DB_USERNAME=zabbix DB_PASSWORD=zabbix **5. 移动并修改userparameter_mongodb.conf**\r cp ./zabbix-master/userparameter_mongodb.conf /etc/zabbix/zabbix_agentd.d vi ./userparameter_mongodb.conf UserParameter=mongodb.status[*],/etc/zabbix/mongodb.sh $1 $2 $3 $4 $5 #修改为mongdb.sh真实位置 #这个是用户自定义的参数，可以之间写入到zabbix_agent.conf里面 **6. 重启zabbix-agent**\r systemctl restart zabbix-agent **7. 在zabbix-web导入mongodb模板**\r 配置-模板-导入模板； 选择./master/mongodb/zbx_export_templates.xml模板文件，并导入； 接下来便可以在 templates中看到\"Template App MongoDB\"这个模板； 可将此模板链接到某个主机上监控，并到最新数据里查看相关MongoDB信息； 如果相对此模板就行修改，可编辑zbx_export_templates.xml文件。 \r","date":"2017-11-14","objectID":"/zabbix/:19:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"监控一台主机上的额外mongod实例 由于可能一台主机上运行的mongod实例不止一个，所以我们需要修改一下前面下载的配置文件，用以监控其它端口的mongod实例。 此处假设默认的mongod实例运行在27017端口上 另外还有一个mongod实例运行在27018端口上 此处假设我们已经完成了前面对27017mongodb的监控了 操作： cd /etc/zabbix cp mongodb.sh mongodb_27018.sh vim ./mongodb_27018.sh #配置监控的mongodb账号和端口 DB_HOST=127.0.0.1 DB_PORT=27018 DB_USERNAME=zabbix DB_PASSWORD=zabbix #现在就有了提取27017/27018两个mongodb实例的脚本 #mongodb.sh #mongodb_27018.sh cd ./zabbxi-agentd.d vim userparameter_mongodb.conf #在默认的27017下面添加一行提取mongodb_27018信息的脚本 UserParameter=mongodb.status[*],/etc/zabbix/mongodb.sh $1 $2 $3 $4 $5 UserParameter=mongodb_27018.status[*],/etc/zabbix/mongodb_27018.sh $1 $2 $3 $4 $5 #现在zabbix-server端就可以同时获取27017/27018两个mongodb实例的信息 #但是Web界面还不能直接显示出来，因为27018的键值和默认不相同 #没错，就是上面我们修改的 mongodb_27018.status[*] 接下来要在Zabbix-Web端配置监控项用以提取信息 我们先找到一个默认的MongoDB自带的配置模板，如MongoDB Connections current，点进去查看它的键值对为mongodb.status[connections,current] 因此我们只需要修改为我们配置文件里面的mongodb_27018.status[*]就可以了。 其余个监控项以此类推，我觉得其他服务也应该可以如此。 你也可以对此建立一个单独的模板，如MongoDB_27108 templates。在此监控模板下创建上面的监控项。这样就可以对所有主机生效了。也可以批量化操作，更方便一些。 下面是我的参考Template App MongoDB模板建立的Template App MongoDB_27018 \r","date":"2017-11-14","objectID":"/zabbix/:19:1","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"监控PHP-FPM 同样使用上面大神的模板。 步骤和监控MongoDB类似： #进入下载的文件目录 cd ./zabbix-master/php-fpm cp ./php-fpm.xml.sh /etc/zabbix chmod a+x /etc/zabbix/php-fpm.xml.sh vim /etc/zabbix/php-fpm.xml.sh #如果这三个参数修改了，请修改 #因为是使用culr，所以请允许此IP能够访问此页面 #另外还要Nginx允许Server-IP访问哦，不然无法读取数据 #我测试的时候用IP无法获取数据，所以用的域名 #如果没做域名解析，请加本地hosts #php-fpm_status使用我修改的 HOST=\"localhost\" PORT=\"80\" #status=\"status\" status=\"php-fpm_status\" cp ./userparameter_php-fpm.conf /etc/zabbix/zabbix_agent.d/ #当然也可以把这个用户自定义参数写入zabbix_agent.conf #修改自定义参数里面的文件位置 vim /etc/zabbix/zabbix_agent.d/userparameter_php-fpm.conf UserParameter=php-fpm.status[*],/etc/zabbix/php-fpm.xml.sh $1 #php-fpm，nginx的状态必须用Nginx展现，Zabbix-Server是使用curl提取状态页面的信息 vim /etc/nginx/conf.d/zabbix.conf server { listen 80; server_name zabbix.me localhost; #如果localhost与其他配置文件冲突，那就用IP #server_name zabbix.me 127.0.0.1 Private-IP Public-IP; root /usr/share/zabbix; access_log /var/log/nginx/zabbix.access.log main; #allow无法使用localhost，所有内外网要分开写 allow 127.0.0.1; allow Private-IP; allow Public-IP; allow Zabbix-Server-IP; allow Remote-View-IP; deny all; location / { if (!-f $request_filename) { rewrite ^([^\\?]+)$ /index.php?1=$1 last; } } #Nignx_Status location /nginx_status { stub_status on; #开启nginx自带的状态检查功能 access_log off; } #php-fpm_Status #php-fpm的默认状态页面是/status,/ping。我修改了一下。 location ~ ^/php-fpm_(status|ping)$ { access_log off; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; } location ~ \\.php$ { root /usr/share/zabbix; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; } } \rphp-fpm状态页面的配置文件 vim /etc/php-fpm.d/www.conf #说明和用法如下，我做简单修改 #修改默认值 ;pm.status_path = /status pm.status_path = /php-fpm_status ;ping.path = /ping ping.path = /php-fpm_ping ;ping.response = pong ping.response = 200 #用法 zabbix.me/php-fpm_status zabbix.me/php-fpm_ping #配置文件提供了格式化输出 zabbix.me/php-fpm_status?html zabbix.me/php-fpm_status?html\u0026full ; output syntax. Example: ; http://www.foo.bar/status ; http://www.foo.bar/status?json ; http://www.foo.bar/status?html ; http://www.foo.bar/status?xml ; http://www.foo.bar/status?full ; http://www.foo.bar/status?json\u0026full ; http://www.foo.bar/status?html\u0026full ; http://www.foo.bar/status?xml\u0026full #修改完毕后重启服务 systemctl restart php-fpm nginx #具体看下面描述 ##这下面是说明 ; The URI to view the FPM status page. If this value is not set, no URI will be ; recognized as a status page. It shows the following informations: ; pool - the name of the pool; ; process manager - static, dynamic or ondemand; ; start time - the date and time FPM has started; ; start since - number of seconds since FPM has started; ; accepted conn - the number of request accepted by the pool; ; listen queue - the number of request in the queue of pending ; connections (see backlog in listen(2)); ; max listen queue - the maximum number of requests in the queue ; of pending connections since FPM has started; ; listen queue len - the size of the socket queue of pending connections; ; idle processes - the number of idle processes; ; active processes - the number of active processes; ; total processes - the number of idle + active processes; ; max active processes - the maximum number of active processes since FPM ; has started; ; max children reached - number of times, the process limit has been reached, ; when pm tries to start more children (works only for ; pm 'dynamic' and 'ondemand'); ; Value are updated in real time. ; Example output: ; pool: www ; process manager: static ; start time: 01/Jul/2011:17:53:49 +0200 ; start since: 62636 ; accepted conn: 190460 ; listen queue: 0 ; max listen queue: 1 ; listen queue len: 42 ; idle processes: 4 ; active processes: 11 ; total processes: 15 ; max active processes: 12 ; max children reached: 0 ; ; By default the status page output is formatted as text/plain. Passing either ; 'html', 'xml' or 'json' in the query string will return the corre","date":"2017-11-14","objectID":"/zabbix/:20:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"监控Nginx Zabbix是通过stub_status模块实现对Nginx的监控。 Nginx的ngx_http_stub_status_module模块提供了基本的Nginx状态信息，源码安装的话需要加上–with-http_stub_status_module编译参数，如果是epel源yum安装的话，已经默认启用该模块。 在Nginx配置文件中加入如下配置： location /nginx_status { allow IP; deny all; stub_status on; access_log off; } #栗子 Active connections: 14 server accepts handled requests 22889 22889 72510 Reading: 0 Writing: 2 Waiting: 12 \r一些状态信息 Active connections 当前active client的连接数，包括Wating accepts 接受的客户端连接总数 handled 已处理的连接总数。通常，handled与accepts相同，除非已达到了资源限制(如worker_connections限制) requests 客户端请求总数 Reading 当前nginx正在读取request header的连接数 Writing 当前Nginx将reponse写回客户端的连接数 Waiting 当前等待请求的空闲客户端的连接数 上面的结果还可通过命令来查看 netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a,S[a]}' 以上数据是通过Web端查看。 但，我们需要把数据收集到Zabbix-Server。还需要使用之前下载同MongoDB，php-fpm一起的那个包。 操作，基本还是类似MongoDB，php-fpm。只是个别参数需要修改一下。 cd ./zabbix-master/nginx/ cp ./nginx.sh /etc/zabbix/ chmod a+x /etc/zabbix/nginx.sh cp ./userparameter_nginx.conf /etc/zabbix/zabbix_agentd.d vim /etc/zabbix/nginx.sh #HOST=\"localhost\" PORT=\"80\" #stub_status=stub_status stub_status=nginx_status vim /etc/zabbix/zabbix_agentd.d/userparameter_nginx.conf #修改成脚本对应的位置 UserParameter=nginx.status[*],/etc/zabbix/nginx.sh $1 现在想以前一样导入模板。 然后在链接模板就可以了。 \r","date":"2017-11-14","objectID":"/zabbix/:21:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"监控Redis 监控Redis，也是把包里面对应的文件复制过去就行。 cd ./zabbix-master/redis cp ./userparameter_redis.conf /etc/zabbix/zabbix_agentd.d/ #如果redis设置有密码，请加上密码 #如果是不同的端口，请修改 UserParameter=redis.local[*],redis-cli -h 127.0.0.1 -p 6379 info|grep $1|grep -v _human|cut -d : -f2 #UserParameter=redis.local[*],redis-cli -h 127.0.0.1 -p 6379 -a Password info|grep $1|grep -v _human|cut -d : -f2 UserParameter=redis.status[*],redis-cli -h $1 -p $2 -a Password info|grep $3|grep -v _human|cut -d : -f2 UserParameter=redis.proc,pidof redis-server | wc -l #重启服务 systemctl restart redis 导入模板，链接主机，OK。 \r \r系统监控 ","date":"2017-11-14","objectID":"/zabbix/:22:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"CPU CPU的性能状态信息： 简写 | 描述 | 说明 | - | - us | user cpu tim | 用户使用CPU时间 sy | system cpu time | 系统使用CPU时间 id | idle cpu time | CPU的空闲时间 wa | io wait cpu time | CPU等待IO时间 ni | user nice cpu time | 用nice调整进程优先级的CPU时间 st | steal time | 虚拟机偷取的CPU时间比，被强制等待虚拟CPU的时间 si | softirq time | 系统处理软件中断所花费的CPU时间 hi | hard time | 系统硬中断所花费的CPU时间 interrupt | 中断 | 被处理过的中断数 cs | Context switches | 上下文切换 ql | processor queue length | 队列长度 processor load | processor load | 处理器负载，几核乘以几 \r","date":"2017-11-14","objectID":"/zabbix/:23:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"Tips 当我们要监控并报警CPU使用率时，我们可以反过来用CPU空闲时间来定义 cpu idle tiem% + cpu usage time% = 1 (CPU usage time% gt 80%) == (CPU idel time% lt 20%) (CPU usage time% gt 90%) == (CPU idel time% \u003c 10%) 所以监控CPU使用率就可以监控CPU空闲时间，并依据这个报警 \r","date":"2017-11-14","objectID":"/zabbix/:23:1","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"内存 Zabbix中自带的Linux OS模板提供了Total memory和Available memory选项，这两者直接用模板就可以了。 但没有提供内存使用率的选项，因此需要我们自定义。 内存使用率 = 可用内存 / 总内存 ast(vm.memory.size[available])/last(vm.memory.size[total]) ","date":"2017-11-14","objectID":"/zabbix/:24:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"自定义内存使用率 我们只需要在Linux OS模板下配置内存使用率，就可以一劳永逸。 配置(Configuration) 模板(Templates) OS Linux模板的监控项(Items) 创建监控项 监控项名称: Available memory percent 类型： 可计算的 键值： vm.memory.size[percent] 公式： 100*last(vm.memory.size[available])/last(vm.memory.size[total]) 记得将其加入Memory应用集，这样便于查找和管理 可加入单位： % \r","date":"2017-11-14","objectID":"/zabbix/:24:1","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"添加触发器 配置 模板 OS Linux模板 触发器 创建触发器，当可用内存率在三分钟内的平均值小于20%时报警 名字：Available memory percent lt 20% on {HOST.NAME} 严重性：一般严重 表达式： {Template OS Linux:vm.memory.size[percent].avg(3)}\u003c20 \r\r\r","date":"2017-11-14","objectID":"/zabbix/:24:2","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"磁盘 由于Zabbix-Server自带的Linux OS模板中的filesystem的监控是一个自动发现规则，而在应用集中的filesystem是没有监控项的。所有对于磁盘的监控和触发要在自动发现规则中去定义。 \r\r","date":"2017-11-14","objectID":"/zabbix/:25:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"进程和端口 Zabbix-Server自带有检测进程和端口的键值对。 ","date":"2017-11-14","objectID":"/zabbix/:26:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"检测进程数 proc.num[\u003cname\u003e,\u003cuser\u003e,\u003cstate\u003e,\u003ccmdline\u003e] name: 进程名； user: 运行该进程的用户； state: run sleep zomb cmdline: ps -ef的最后那项，如/usr/bin/mongod -f /etc/mongod.conf 现在Zabbix-Server端测试： #zabbix-get --host hostname --key proc.num[\u003cname\u003e,\u003cuser\u003e,\u003cstate\u003e,\u003ccmdline\u003e] #检测mongd进程数量 zabbix-get --host 192.168.1.11 --key proc.num[mongod,,,] #2，因为我开了两个mongd实例 zabbix-get --host 192.168.1.11 --key proc.num[mongod,root,,] #1，只有一个是以root运行的，有一个是以mongod运行的 由于我们上面使用的MongoDB监控模板没有判断mongod进程存活与否的判断，此处我们在MongoDB模板中增加一个检查mongod进程的监控项，并创建对应的触发器。 ","date":"2017-11-14","objectID":"/zabbix/:26:1","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"端口 net.tcp.listen[port] 检查 TCP 端口 是否处于侦听状态。返回 0 - 未侦听；1 - 正在侦听 此处我也用Mongod举例。我的两个mongod实例分别监听在27017,27018/tcp。 在Zabbix-Server端先测试： #net.tcp.listen[port] zabbix-get --host 192.168.1.11 --key net.tcp.listen[27017] #1 zabbix-get --host 192.168.1.11 --key net.tcp.listen[27018] #1 在Web端创建监控项和触发器与上面类似。 \r用户自定义参数(user parameter) 我也是参考了上述大神的脚本，进行参考而来。 由于公司需要监控大量的Web页面和API接口的状态，并通过页面判断相关key-value的正确性，用以判断状态。此处可能由模拟登录等操作，Zabbix自带的Web监控不太够用，所以此处自定义用户参数来实现。 此处，我叫公司开发人员帮忙将全部接口以及Web页面内容都生成到一个json文件里，如 http://zhang21.cn/test.json。然后用jq命令解析json文件，里面key一一对应value，这样取值就很方便了。 ","date":"2017-11-14","objectID":"/zabbix/:26:2","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"jq jq 是一款命令行下处理 JSON 数据的工具。真的很好用！ jq官网：https://stedolan.github.io/jq/ GitHub: https://github.com/stedolan/jq \r安装jq yum install -y jq 使用jq jq --help #查看所有键键值 curl --silent http://zhang21.cn/test.json | jq . ###栗子 { \"collapsectimes\": 130, \"collapsectimes\": 0, \"bootfailtimes\": 23, \"failrate\": 0.3623, \"bootrate\": 0.3324, \"time\": \"2018-01-25 15:03:30\", \"db_error\": false } #查看某个键值 curl --silent http://zhang21.cn/test.json | jq '.time' curl --silent http://zhang21.cn/test.json | jq '.bootrate' ### 2018-01-25 15:03:30 0.3324 #查看某个不存在的值，会返回null curl --silent http://zhang21.cn/test.json | jq '.zhang' ### null json嵌套解析 cat test.json | jq '.location.city' ### \"Chengdu\" json解析数组 cat test.json | jq '.array[1].name' ### \"Zhang\" \r内建函数 jq还有一些内建函数，如key,hss。 key用来获取json中的key元素： curl --silent http://zhang21.cn/test.json | jq 'keys' ### [ collapsectimes, collapsectimes, bootfailtimes, failrate, bootrate, time, db_error ] has用来判断是否存在某个key: curl --silent http://zhang21.cn/test.json | jq 'has(\"time\")' ### true ","date":"2017-11-14","objectID":"/zabbix/:27:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"jq的select语句 使用select函数来完成jq的过滤操作。 jq的select语句太好了! select 接受一个条件表达式作为参数。其输入可以是迭代器，或者和 map 函数配合使用来处理数组。当输入中的某个元素使 select 参数中的条件表达式结果为真时，则在结果中保留该元素，否则不保留该元素。 对json文件的值是数组的，根据数据里面的key在取值，厉害厉害。 cat zhang.json \"array\": [ { \"ip\": \"192.168.1.11\", \"loads\": 1234 }, { \"ip\": \"192.168.1.22\", \"loads\": 567 } ] ####栗子 cat /etc/zabbix/zhang.json | jq \".array[] | select(.ip == \\\"192.168.1.11\\\")\" { \"ip\": \"192.168.1.11\", \"loads\": 1234 } cat /etc/zabbix/zhang.json | jq \".array[] | select(.ip == \\\"192.168.1.11\\\").loads\" 1234 我们在自定义用户参数的时候便可以将ip作为参数传入 cat /etc/zabbix/zhang.json | jq \".array[] | select(.ip == \\\"$1\\\").loads\" \r","date":"2017-11-14","objectID":"/zabbix/:27:1","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"编写自定义参数和脚本 将脚本放置于/etc/zabbix，可将自定义参数写入zabbix-agentd.conf文件，也可单独写入/etc/zabbix/zabbix_agentd.d/(推荐)，这样修改更方便。 ","date":"2017-11-14","objectID":"/zabbix/:28:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"编写脚本文件 cd /etc/zabbix vim xbreport.sh ########## # Zabbix3.4 # Zhang21 # Thu Jan 25 15:20:44 CST 2018 ########### url=\"http://zhang21.cn/test.json\" JQ=`which jq` CURL=`which curl` function XBREPORT() { $CURL --silent $url | $JQ \".$1\" } if [ $# == 0 ]; then echo $\"Usage $0{browsercollapsectimes|servercollapsectimes|xiaobaibootfailtimes|terminaldesktopfailrate|competebootrate|db_error}\" exit else XBREPORT \"$1\" fi \r","date":"2017-11-14","objectID":"/zabbix/:28:1","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"编写自定义参数文件 cd /etc/zabbix/zabbix_agentd.d vim userparameter_XBreport.conf ########## # Zabbix3.4 # Zhang21 # Thu Jan 25 15:45:19 CST 2018 ########## UserParameter=XBreport[*],/etc/zabbix/xbreport.sh $1 \r","date":"2017-11-14","objectID":"/zabbix/:28:2","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"测试自定义参数 zabbix_get --host host --key XBreport[time] ### \"2018-01-25 17:03:18\" ","date":"2017-11-14","objectID":"/zabbix/:28:3","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"自定义用户参数额外 由于我的json文件key对应的value中内嵌有数组，所以我需要再提取数组内的值。 curl http://zhang21.cn/test.json | jq '.array' ### [ { \"ip\": \"1.1.1.1\", \"loads\": 1051 }, { \"ip\": \"2.2.2.2\", \"loads\": 356 } ] #array[],array[1],array[2],array[n] #array[].ip, array[1].ip #array[].loads, array[2].loads 上面的数据中包含有zabbix无法解析的特殊符号，所以需要改变策略。 由于zabbix对UserParameter中包含**'\"`*?[]{}~$?\u0026;()\u003c\u003e|#@**这些特殊字符无法进行处理，此处有两种方法来解决。 在zabbix_agentd.conf中开启参数UnsafeUserParameters，将其值设置为1 或者，使用多个变量$1 $2 $3...来解决我这个数组值的问题 我是使用多个变量来解决我这个情况的。 看下脚本。 cd /etc/zabbix vim ./zhang.sh url='http://www.zhang21.cn/test.json' JQ=`which jq` CURL=`which curl` function ZHANG() { $CURL --silent $url | $JQ \".$1\" } if [ $# == 0 ]; then echo $\"Usage $0 {aaa|bbb|ccc|...}\" exit elif [ $# ==1 ]; then ZHANG \"$1\" elif [ $# == 2 ]; then ZHANG \"$1[$2]\" else ZHANG \"$1[$2].$3\" fi cd /etc/zabbix/zabbix_agentd.d/userparameter_Zhang.conf UserParameter=Zhangxx[*],/etc/zabbix/zhang.sh $1 $2 $3 测试： systemctl restart zabbix-agentd zabbix_get --host host --key Zhangxx[array] zabbix_get --host host --key Zhangxx[array,0] zabbix_get --host host --key Zhangxx[array,0,loads] zabbix_get --host host --key Zhangxx[array,1,ip] 测试正确能取到值的话，在Web端设置相对应的监控项。注意自己定义的key不要写错了。 数组的key栗子： Zhangxx[array] Zhangxx[array,0]或Zhangxx[array,1] Zhangxx[array,0,ip], Zhangxx[array,0,loads] \r","date":"2017-11-14","objectID":"/zabbix/:28:4","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"在Web端添加监控项 由于这个参数是我们自定义的，所以在填写监控项key的时候需要我们手动填写自己定义的参数。 注意监控项的参数和信息类型。 这里我遇到一个问题，我自定义key的执行脚本在Web端报超时问题，无法取值。这是由于zabbix默认的脚本执行超时时间为3s，所以我们需要修改超时时间30s(最大值)。 vim /etc/zabbix/zabbix_server.conf vim /etc/zabbix/zabbix_agentd.conf \r","date":"2017-11-14","objectID":"/zabbix/:28:5","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"设置触发器和报警 这个就根据你个人项目实际情况设置对于的触发器和报警。 \r短信报警 ","date":"2017-11-14","objectID":"/zabbix/:28:6","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"腾讯短信服务 由于公司使用的是腾讯企业邮箱，可以将邮箱直接与微信绑定，从而在微信中实时显示邮件消息，所以不用微信报警！ 此处使用的腾讯短信SMS服务： https://cloud.tencent.com/product/sms 短信文档： https://cloud.tencent.com/document/product/382/13445 API文档： https://cloud.tencent.com/document/product/382/13297 SDK文档： https://cloud.tencent.com/document/product/382/5804 Python SDK: https://cloud.tencent.com/document/product/382/11672 由于腾讯提供了程序SDK，所以我选择了linux自带的Python SDK。 这里面有详细的Python使用方法，做一些小修改就可以使用了。 \r","date":"2017-11-14","objectID":"/zabbix/:29:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"配置 ","date":"2017-11-14","objectID":"/zabbix/:30:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"获取Python SDK 获取Python SDK ","date":"2017-11-14","objectID":"/zabbix/:30:1","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"申请SDK AppID和App Key 申请SDK AppID以及APP Key。 申请完毕后，效果如下： ","date":"2017-11-14","objectID":"/zabbix/:30:2","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"申请短信签名 下发短信必须携带短信签名。 短信签名需要上传公司证件进行认证，大概十分钟左右！ 效果如下： ","date":"2017-11-14","objectID":"/zabbix/:30:3","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"申请短信模板 下发短信内容必须经过审核。 在此短信模板中，我们必须要定义相关变量{n}，其他都是不会变化的常量。此处我定义了五个变量，分别为了带入Zabbix中的宏： 问题名，{TRIGGER.NAME} 主机名，{HOST.NAME} 事件事件，{EVENT.TIME} 事件日期，{EVENT.DATE} URL，{TRIGGER.URL} ","date":"2017-11-14","objectID":"/zabbix/:30:4","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"SDK配置 yum install -y eple-realse yum install -y python-pip pip install qcloudsms \r","date":"2017-11-14","objectID":"/zabbix/:30:5","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"Python代码配置 腾讯文档：https://cloud.tencent.com/document/product/382/11672 由于我是向多人发送短信，所以做了小修改： #zabbix-server cd /usr/lib/zabbis/alartscripts vim sendSms.py #!/bin/python #coding: utf-8 from qcloudsms_py import SmsSingleSender from qcloudsms_py.httpclient import HTTPError import sys appid = App ID appkey = App Key phone_numbers = [\"12345\", \"1234567\"] #params = [\"Problem\", \"Hostname\", \"Time\", \"Date\",\"Url\"] params = [sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4], sys.argv[5]] msender = SmsSingleSender(appid, appkey) for i in phone_numbers: try: result = msender.send_with_param(86, i, 短信内容模板ID, params) except HTTPError as e: print(e) except Exception as e: print(e) print(result) 要给sendSms.py加上可执行权限哈！chmod a+x ./sendSms.py。 sys.argv变量是一个字符串的列表。特别地，sys.argv包含了命令行参数 的列表，即使用命令行传递给你的程序的参数。 使用Python的sys.argv[n]可以像shell一样将放在文件后的变量传入文件执行。此处对于在Zabbix-Web端将宏放在脚本后，作为变量传入，非常重要。 sys.argv[0]代表sendSms.py文件 sys.argv[1]才代表第一个参数。 \r","date":"2017-11-14","objectID":"/zabbix/:30:6","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["monitor"],"content":"Zabbix Web端配置 配置-动作-创建动作-操作 注意事项： 建议针对触发器示警度最高就行短信报警，其它交给Email 操作类型，选择远程命令 目标列表，选择当前主机 类型，自定义脚本 执行在，这个一定是放在Zabbix-Server上来执行哈 命令，文件名SendSms.py后面接的宏一定要加上双引号(\"\") 最后根据不同的内容，设置不同的报警机制。后台的脚本也修改为对应的名称，修改里面对应的手机号码。 首先根据不同报警设置不同的触发条件 运维组，SendSms_dev.py，修改运维对应的号码 开发组，SendSms_develop.py，修改对于的号码 其实这个发送短信，就是在执行远程命令。 你命令里是发送短信就发送短信，你命令里是发送邮件就发送邮件。这个还是挺不错的。 \r针对不同业务向不同人员报警 有时候我们只需要关心我们自己那部分就可以了，没必要所有报警都发送给所有人，这样很不方便。 所以，我们可以根据业务相关，组别权限等，分别向不同的人报警不同的信息。 如下我的一个栗子图： ","date":"2017-11-14","objectID":"/zabbix/:31:0","tags":["zabbix"],"title":"Zabbix","uri":"/zabbix/"},{"categories":["linux"],"content":"参考： git-scm文档 廖雪峰Git教程 Git内部原理 Git内部原理-伯乐在线 \r \r\r介绍 git(/ɡɪt/)是一个分布式版本控制软件,最初由林纳斯·托瓦兹（Linus Torvalds）创作，于2005年以GPL发布。Git是免费的。 林纳斯·托瓦兹自嘲地取了这个名字“git”，该词源自英国俚语，意思大约是“混账”。 \r","date":"2017-11-07","objectID":"/git/:0:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"集中式与分布式 集中式版本控制系统，版本库是集中存放在中央服务器的，而干活的时候，用的都是自己的电脑，所以要先从中央服务器取得最新的版本，然后开始干活，干完活了，再把自己的活推送给中央服务器。 集中式版本控制系统最大的毛病就是必须联网才能工作。 常用集中式版本控制系统有：CVS、SVN。 分布式版本控制系统根本没有“中央服务器”，每个人的电脑上都是一个完整的版本库，这样，你工作的时候，就不需要联网了，因为版本库就在你自己的电脑上。既然每个人电脑上都有一个完整的版本库，那多个人如何协作呢？比方说你在自己电脑上改了文件A，你的同事也在他的电脑上改了文件A，这时，你们俩之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。 常用分布式版本控制系统有：Git。 和集中式版本控制系统相比，分布式版本控制系统的安全性要高很多，因为每个人电脑里都有完整的版本库，某一个人的电脑坏掉了不要紧，随便从其他人那里复制一个就可以了。而集中式版本控制系统的中央服务器要是出了问题，所有人都没法干活了。 \r\r常用命令 几个专用名词: Workspace：工作区 Index/Stage：暂存区 Repository：仓库区（或本地仓库） Remote：远程仓库 常用命令： #配置 #Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下 #--global全局配置 git config --global user.name \"Username\" git config --globla user.email \"Email\" #创建版本库 #虽然在任意目录下都可创建git-repo，但还是建议在一个空目录下创建git-repo mkdir gitest\u0026\u0026cd gitest #init, Create an empty Git repository or reinitialize an existing one git init #生成了一个.git目录，这个目录是git用来追踪管理版本库的，不要随意修改此目录的内容 echo \"First Git test\" \u003e README #增加/删除文件 #所有的版本控制系统，只能跟踪文本文件的改动 #把文件添加到暂存区 #git add file #git add dir #当前目录 #git add . git add　README #删除 #git rm file #改名 #git move file #提交 #把暂存区提交到仓库区 #-m, 为本次提交的说明信息 git commit -m \"Update Readme\" #为什么Git添加文件需要add, commit一共两步呢？ #因为commit可以一次提交很多文件，所以你可以多次add不同的文件。 git add file1 file2 file3 git commit -m \"add 3files\" #分支 #查看分支 git branch git branch -a # 新建一个分支，但依然停留在当前分支 git branch [branch-name] # 新建一个分支，并切换到该分支 git checkout -b [branch] # 新建一个分支，与指定的远程分支建立追踪关系 git branch --track [branch] [remote-branch] # 切换到指定分支，并更新工作区 git checkout [branch-name] # 建立追踪关系，在现有分支与指定的远程分支之间 git branch --set-upstream [branch] [remote-branch] # 合并指定分支到当前分支 git merge [branch] # 删除分支 git branch -d [branch-name] # 删除远程分支 git push origin --delete [branch-name] git branch -dr [remote/branch] #标签 git tag #远程同步 # 下载远程仓库的所有变动 git fetch [remote] # 显示所有远程仓库 git remote -v # 显示某个远程仓库的信息 git remote show [remote] # 增加一个新的远程仓库，并命名 git remote add [shortname] [url] # 取回远程仓库的变化，并与本地分支合并 git pull [remote] [branch] # 上传本地指定分支到远程仓库 git push [remote] [branch] # 强行推送当前分支到远程仓库，即使有冲突 git push [remote] --force # 推送所有分支到远程仓库 git push [remote] --all #撤销 # 恢复暂存区的指定文件到工作区 git checkout [file] # 恢复某个commit的指定文件到暂存区和工作区 git checkout [commit] [file] # 恢复暂存区的所有文件到工作区 git checkout . # 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变 git reset [file] # 重置暂存区与工作区，与上一次commit保持一致 git reset --hard # 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变 git reset [commit] # 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致 git reset --hard [commit] # 重置当前HEAD为指定commit，但保持暂存区和工作区不变 git reset --keep [commit] # 新建一个commit，用来撤销指定commit # 后者的所有变化都将被前者抵消，并且应用到当前分支 git revert [commit] # 暂时将未提交的变化移除，稍后再移入 git stash git stash pop #其它 # 生成一个可供发布的压缩包 $ git archive \r\r \r\r内部原理 Git 的内部工作原理和实现方式，学习这些内容对于理解 Git 的用处和强大功能是非常重要的。 首先要弄明白一点，从根本上来讲 Git 是一套内容寻址(content-addressable) 文件系统——它是一个相当酷的东西，在此之上提供了一个 版本控制系统(VCS)用户界面。 \r","date":"2017-11-07","objectID":"/git/:1:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"底层命令和高层命令 由于 Git 最初是一套面向版本控制系统的工具集，而不是一个完整的、用户友好的版本控制系统，所以它还包含了一部分用于完成底层工作的命令。 这些命令被设计成能以 UNIX 命令行的风格连接在一起，抑或藉由脚本调用，来完成工作。 这部分命令一般被称作底层命令（plumbing），而那些更友好的命令则被称作高层命令（porcelain）。 Git Repo下有一个.git目录，几乎所有 Git 存储和操作的内容都位于该目录下。如果你要备份或复制一个库，基本上将这一目录拷贝至其他地方就可以了。 .git内容: branches/ config: 包含项目特有的配置选项 description: 仅供 GitWeb 程序使用 HEAD： Git核心部分，指向当前分支 hooks/： 客户端或服务端钩子脚本 index： Git核心部分，保存了暂存区域信息 info/: 保存了一份不希望在.gitignore文件中管理的忽略模式的全局性排除文件 objects/： Git核心部分，存储所有数据内容 refs/： Git核心部分，存储指向数据 (分支) 的提交对象的指针 #可能还有其它文件 COMMIT_EDITMSG FETCH_HEAD logs/ ORIG_HEAD \r\r\r","date":"2017-11-07","objectID":"/git/:2:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"Git对象 Git 是一套内容寻址文件系统。从内部来看，Git 是简单的 key-value 数据存储。它允许插入任意类型的内容，并会返回一个键值，通过该键值可以在任何时候再取出该内容。可以通过底层命令 hash-object 来示范这点，传一些数据给该命令，它会将数据保存在 .git 目录并返回表示这些数据的键值。 Git 初始化了 objects 目录，同时在该目录下创建了 pack 和 info 子目录。 新建文件后，此目录中会出现新目录(目录内容为哈希值)。 echo \u0026#039;test content\u0026#039; | git hash-object -w --stdin d670460b4b4aece5915caf5c68d12f560a9fe3e4 #也可以直接添加文件 #git hash-object -w test.txt find .git/objects -type f .git/objects/d6/70460b4b4aece5915caf5c68d12f560a9fe3e4 #使用git cat-file取回对象内容 git cat-file -p d670460b4b4aece5915caf5c68d12f560a9fe3e4 test content \r\r","date":"2017-11-07","objectID":"/git/:3:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"树对象 tree object tree 对象可以存储文件名，同时也允许存储一组文件。Git 以一种类似 UNIX 文件系统但更简单的方式来存储内容。所有内容以 tree 或 blob 对象存储，其中 tree 对象对应于 UNIX 中的目录，blob 对象则大致对应于 inodes 或文件内容。 git cat-file -p master^{tree} 100644 blob a38f463bb1bdb05ce38cf7d9cfd4ed11286a708c README.md 040000 tree f7cda840304ce5729444dd60904a0bbdf95fa0b5 test #master^{tree} 表示 branch 分支上最新提交指向的 tree 对象 #请注意 test 子目录并非一个 blob 对象，而是一个指向别一个 tree 对象的指针 git cat-file -p f7cda840304ce5729444dd60904a0bbdf95fa0b5 040000 tree 02e9e8af4ae37db0fcd1943fdc832b27ad03ea03 2018 #这才是两个blob对象 git cat-file -p 02e9e8af4ae37db0fcd1943fdc832b27ad03ea03 100644 blob 7066d2a8d6f8e3c6c44bdbf3a775c96cc9d0a3b9 2018-12-14.md 100644 blob c0a915bf91f77db873a425058391e500c1504bae 2018-12-21.md 你可以自己创建 tree 。通常 Git 根据你的暂存区域或 index 来创建并写入一个 tree 。因此要创建一个 tree 对象的话首先要通过将一些文件暂存从而创建一个 index 。 #指定了文件模式为 100644，表明这是一个普通文件 git update-index --add --cacheinfo 100644 \\ 83baae61804e65cc73a7201a7252750c76066a30 test.txt \r\r","date":"2017-11-07","objectID":"/git/:3:1","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"提交对象 commit object #创建commit 对象 echo \u0026#039;first commit\u0026#039; | git commit-tree d8329f fdf4fc3344e67ab068f836878b6c4951e3b15f3d #查看 git cat-file -p fdf4fc3 \r\r\r","date":"2017-11-07","objectID":"/git/:3:2","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"Git References 引用(references, refs)，可在.git/refs下查看相关内容。 #有三个目录 ls .git/refs heads remotes tags \r\r","date":"2017-11-07","objectID":"/git/:4:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"HEAD 当你执行 git branch \u003cbranch-name\u003e 这条命令的时候，Git 怎么知道最后一次提交的散列值呢？答案就是 HEAD 文件。HEAD 文件是一个指向你当前所在分支的引用标识符。 #这就是上面.git/refs目录下 cat .git/HEAD ref: refs/heads/test git checkout master cat .git/HEAD ref: refs/heads/master #你也可以设置它的值 #但不能设置为refs以外的值，会报错 git symbolic-ref HEAD refs/heads/test cat .git/HEAD ref: refs/heads/test \r\r","date":"2017-11-07","objectID":"/git/:4:1","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"Tags Tag 对象指向一个 commit 而不是一个 tree。它就像是一个分支引用，但是不会变化——永远指向同一个 commit，仅仅是提供一个更加友好的名字。 Tag 有两种类型：annotated 和 lightweight 。 \r\r","date":"2017-11-07","objectID":"/git/:4:2","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"Remotes 如果你添加了一个 remote 然后推送代码过去，Git 会把你最后一次推送到这个 remote 的每个分支的值都记录在refs/remotes 目录下。 git log commit 1deea62fa622d00db113abe136e9b22e1f3eac4c xxxxxxxxx cat .git/refs/heads/origin/master 1deea62fa622d00db113abe136e9b22e1f3eac4c #切换分支 git checkout test git log commit 3e1fcc1f8c035320d985b0202e18a6a00fe068c0 cat .gt/refs/heads/origin/test 3e1fcc1f8c035320d985b0202e18a6a00fe068c0 \r\r\r","date":"2017-11-07","objectID":"/git/:4:3","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"Packfiles Git 往磁盘保存对象时默认使用的格式叫松散对象 (loose object) 格式。Git 时不时地将这些对象打包至一个叫 packfile 的二进制文件以节省空间并提高效率。当仓库中有太多的松散对象，或是手工调用git gc 命令，或推送至远程服务器时，Git 都会这样做。 Git 打包对象时，会查找命名及尺寸相近的文件，并只保存文件不同版本之间的差异内容。 Git 自动定期对仓库进行重新打包以节省空间。当然也可以手工运行 git gc 命令来这么做。 #举个栗子 find .git/objects -type f .git/objects/01/55eb4229851634a0f03eb265b69f5a2d56f341 # tree 2 .git/objects/1a/410efbd13591db07496601ebc7a059dd55cfe9 # commit 3 .git/objects/1f/7a7a472abf3dd9643fd615f6da379c4acb3e3a # test.txt v2 .git/objects/3c/4e9cd789d88d8d89c1073707c3585e41b0e614 # tree 3 .git/objects/83/baae61804e65cc73a7201a7252750c76066a30 # test.txt v1 .git/objects/95/85191f37f7b0fb9444f35a9bf50de191beadc2 # tag .git/objects/ca/c0cab538b970a37ea1e769cbbde608743bc96d # commit 2 .git/objects/d6/70460b4b4aece5915caf5c68d12f560a9fe3e4 # \u0026#039;test content\u0026#039; .git/objects/d8/329fc1cc938780ffdd9f94e0d364e0ea74f579 # tree 1 .git/objects/fa/49b077972391ad58037050f2a75f74e3671e92 # new.txt .git/objects/fd/f4fc3344e67ab068f836878b6c4951e3b15f3d # commit 1 \r\r\r","date":"2017-11-07","objectID":"/git/:5:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"Refspec #假设添加了一个远程Repo git remote add origin git@ github.com:schacon/simplegit-progit.git #之后可在.git/config中查看 缺省情况下 refspec 会被 git remote add 命令所自动生成， Git 会获取远端上 refs/heads/ 下面的所有引用，并将它写入到本地的 refs/remotes/origin/: git log origin/master git log remotes/origin/master git log refs/remotes/origin/master #它们全是等价的，因为 Git 把它们都扩展成 refs/remotes/origin/master 如果你想让 Git 每次只拉取远程的 master 分支，而不是远程的所有分支，你可以把 fetch 这一行修改成这样： #默认 #fetch = +refs/heads/*:refs/remotes/origin/* fetch = +refs/heads/master:refs/remotes/origin/master 你可以使用命名空间来达到这个目的。如你有一个QA组，他们推送一系列分支，你想每次获取 master 分支和QA组的所有分支，你可以使用这样的配置段落： [remote \u0026quot;origin\u0026quot;] url = git@ github.com:schacon/simplegit-progit.git fetch = +refs/heads/master:refs/remotes/origin/master fetch = +refs/heads/qa/*:refs/remotes/origin/qa/* push Refspec 如果QA组成员想把他们的 master 分支推送到远程的 qa/master 分支上，可以这样运行： git push origin master:refs/heads/qa/master 删除 Refspec 以使用 refspec 来删除远程的引用，是通过运行这样的命令： #因为 refspec 的格式是 : #通过把 部分留空的方式，这个意思是是把远程的topic 分支变成空，也就是删除它 git push origin :topic \r\r\r","date":"2017-11-07","objectID":"/git/:6:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"传输协议 Git 可以通过两种主要的方式在版本库之间传输数据：dumb Protocol 和 smart protocol \r","date":"2017-11-07","objectID":"/git/:7:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"Dumb protocol Git 基于HTTP之上传输通常被称为 dump protocol，这是因为它在服务端不需要有针对 Git 特有的代码。这个获取过程仅仅是一系列 GET 请求，客户端可以假定服务端的Git仓库中的布局。 #栗子 git clone http://github.com/schacon/simplegit-progit.git \r\r","date":"2017-11-07","objectID":"/git/:7:1","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"Smart protocol dump procotol 虽然很简单但效率略低，且它不能从客户端向服务端发送数据。 智能协议是更常用的传送数据的方法，但它需要在服务端运行一个进程，而这也是 Git 的智能之处——它可以读取本地数据，理解客户端有什么和需要什么，并为它生成合适的包文件。 总共有两组进程用于传输数据，它们分别负责上传和下载数据。 为了上传数据至远端， Git 使用 send-pack 和 receive-pack 进程。这个 send-pack 进程运行在客户端上，它连接至远端运行的 receive-pack 进程。 当你在下载数据时， fetch-pack 和 upload-pack 进程就起作用了。客户端启动 fetch-pack 进程，连接至远端的 upload-pack 进程，以协商后续数据传输过程。 举例来说，在项目中使用命令 git push origin master 时, origin 是由基于 SSH 协议的 URL 所定义的。 Git 会运行 send-pack 进程，它会通过 SSH 连接你的服务器。 它会尝试通过 SSH 在服务端执行命令 \r\r\r","date":"2017-11-07","objectID":"/git/:7:2","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"维护和恢复 有的时候，你需要对仓库进行清理 - 使它的结构变得更紧凑，或是对导入的仓库进行清理，或是恢复丢失的内容。 \r","date":"2017-11-07","objectID":"/git/:8:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"维护 Git 会不定时地自动运行一个叫做 auto gc 的命令。 大多数时候，这个命令并不会产生效果。 然而，如果有太多松散对象（不在包文件中的对象）或者太多包文件，Git 会运行一个完整的 git gc 命令。 这个命令通常并不会产生效果。 大约需要 7000 个以上的松散对象或超过 50 个的包文件才能让 Git 启动一次真正的 gc 命令。 你可以通过修改 gc.auto 与 gc.autopacklimit 的设置来改动这些数值。 #栗子 git gc --auto \r\r","date":"2017-11-07","objectID":"/git/:8:1","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"数据恢复 在你使用 Git 的时候，你可能会意外丢失一次提交。 通常这是因为你强制删除了正在工作的分支，但是最后却发现你还需要这个分支；亦或者硬重置了一个分支，放弃了你想要的提交。 如果这些事情已经发生，该如何找回你的提交呢？ 首先需要判断当前处于什么位置，然后恢复到之前某个位置。 #查看commit git log --pretty=oneline 3e1fcc1f8c035320d985b0202e18a6a00fe068c0 update 1.txt a3f3bdd9cf22ce499d1b3cdff5bb26c94032a15d add 2.txt f4c90e173ef18e738f0287af71ae0878beec9316 add 1.txt 748d8d3152b3a9a81068e29ae00fa797c2223520 add README #重置 git reset --hard ${commit-id} #也可以使用 git reflog 1a410ef HEAD@{0}: reset: moving to 1a410ef ab1afef HEAD@{1}: commit: modified repo.rb a bit 484a592 HEAD@{2}: commit: added repo.rb #查看log git log -g commit 1a410efbd13591db07496601ebc7a059dd55cfe9 Reflog: HEAD@{0} (Scott Chacon \u003cschacon@gmail.com\u003e) Reflog message: updating HEAD Author: Scott Chacon \u003cschacon@gmail.com\u003e Date: Fri May 22 18:22:37 2009 -0700 third commit 你可以通过创建一个新的分支指向这个提交来恢复它： #748d8d3152b3a9a81068e29ae00fa797c2223520 add README git branch test 748d8d3152b3a9a81068e29ae00fa797c2223520 git checkout test ls README.md #删除分支 git checkout master git branch -D test \r\r","date":"2017-11-07","objectID":"/git/:8:2","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"移除对象 Git 有许多过人之处，不过有一个功能有时却会带来问题：git clone 会将包含每一个文件的所有历史版本的整个项目下载下来。如果项目包含的仅仅是源代码的话这并没有什么坏处，毕竟 Git 可以非常高效地压缩此类数据。 不过如果有人在某个时刻往项目中添加了一个非常大的文件，那们即便他在后来的提交中将此文件删掉了，所有的签出都会下载这个 大文件。因为历史记录中引用了这个文件，它会一直存在着。 警告：这个操作对提交历史的修改是破坏性的。 它会从你必须修改或移除一个大文件引用最早的树对象开始重写每一次提交。 如果你在导入仓库后，在任何人开始基于这些提交工作前执行这个操作，那么将不会有任何问题 - 否则，你必须通知所有的贡献者他们需要将他们的成果变基到你的新提交上。 git rm bigfiles.tar.gz git commit -m \"remove big files\" #查看清理了多少空间 git gc #git count-objects -v \r\r\r","date":"2017-11-07","objectID":"/git/:8:3","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"环境变量 Git 总是在一个 bash shell 中运行，并借助一些 shell 环境变量来决定它的运行方式。 \r","date":"2017-11-07","objectID":"/git/:9:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"全局行为 GIT_EXEC_PATH: 决定 Git 到哪找它的子程序 PREFIX: 也类似，除了用于系统级别的配置 GIT_PAGER: 控制在命令行上显示多页输出的程序 GIT_EDITOR: 当用户需要编辑一些文本（比如提交信息）时， Git 会启动这个编辑器 \r\r","date":"2017-11-07","objectID":"/git/:9:1","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"版本库位置 GIT_DIR: 是 .git 目录的位置 GIT_CEILING_DIRECTORIES: 控制查找 .git 目录的行为 GIT_WORK_TREE: 是非空版本库的工作目录的根路径 如果没指定，就使用 $GIT_DIR 的父目录 GIT_INDEX_FILE: 是索引文件的路径 GIT_OBJECT_DIRECTORY: 用来指定 .git/objects 目录的位置 GIT_ALTERNATE_OBJECT_DIRECTORIES: 一个冒号分割的列表 (格式类似/dir/one:/dir/two:…) 用来告诉 Git 到哪里去找不在 GIT_OBJECT_DIRECTORY 目录中的对象. 如果你有很多项目有相同内容的大文件，这个可以用来避免存储过多备份。 \r\r","date":"2017-11-07","objectID":"/git/:9:2","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"路径规则 GIT_GLOB_PATHSPECS, GIT_NOGLOB_PATHSPECS: 控制通配符在路径规则中的默认行为 GIT_LITERAL_PATHSPECS: 禁用上面的两种行为；通配符将不能用，前缀覆盖也不能用 GIT_ICASE_PATHSPECS: 让所有的路径规格忽略大小写 \r\r","date":"2017-11-07","objectID":"/git/:9:3","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"提交 `GIT_AUTHOR_NAME: 是 “author” 字段的可读的名字 GIT_AUTHOR_EMAIL: 是 “author” 字段的邮件 GIT_AUTHOR_DATE: 是 “author” 字段的时间戳 GIT_COMMITTER_NAME: 是 “committer” 字段的可读的名字 GIT_COMMITTER_EMAIL: 是 “committer” 字段的邮件 GIT_COMMITTER_DATE: 是 “committer” 字段的时间戳 \r\r","date":"2017-11-07","objectID":"/git/:9:4","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"网络 GIT_SSL_NO_VERIFY: 告诉 Git 不用验证 SSL 证书。 这在有些时候是需要的， 例如你用一个自己签名的证书通过 HTTPS 来提供 Git 服务， 或者你正在搭建 Git 服务器，还没有安装完全的证书 GIT_HTTP_USER_AGENT: 设置 Git 在通过 HTTP 通讯时用到的 user-agent \r\r","date":"2017-11-07","objectID":"/git/:9:5","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"比较与合并 GIT_DIFF_OPTS: 这个有点起错名字了 有效值仅支持 -u 或 –unified=，用来控制在 git diff 命令中显示的内容行数 GIT_EXTERNAL_DIFF: 用来覆盖 diff.external 配置的值。 如果设置了这个值， 当执行Gitgit diff 时，Git 会调用该程序 GIT_DIFF_PATH_COUNTER 和 GIT_DIFF_PATH_TOTAL: 对于 GIT_EXTERNAL_DIFF 或diff.external 指定的程序有用。 前者表示在一系列文件中哪个是被比较的（从 1 开始），后者表示每批文件的总数。 GIT_MERGE_VERBOSITY: 控制递归合并策略的输出。 允许的值有下面这些： 0: 什么都不输出，除了可能会有一个错误信息 1: 只显示冲突 2: 还显示文件改变(默认值) 3: 显示因为没有改变被跳过的文件 4: 显示处理的所有路径 5: 显示详细的调试信息 \r\r","date":"2017-11-07","objectID":"/git/:9:6","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"调试 GIT_TRACE: 控制常规跟踪，它并不适用于特殊情况。 它跟踪的范围包括别名的展开和其他子程序的委托 GIT_TRACE_PACK_ACCESS: 控制访问打包文件的跟踪信息 GIT_TRACE_PACKET: 打开网络操作包级别的跟踪信息 GIT_TRACE_PERFORMANCE: 控制性能数据的日志打印 GIT_TRACE_SETUP: 显示 Git 发现的关于版本库和交互环境的信息 \r\r","date":"2017-11-07","objectID":"/git/:9:7","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"其它 GIT_SSH GIT_ASKPASS GIT_NAMESPACE GIT_FLUSH GIT_REFLOG_ACTION \r\r \r\rfetch与pull Git中从远程的分支获取最新的版本到本地有两个命令: fetch: 当于是从远程获取最新版本到本地，不会自动merge pull: 相当于是从远程获取最新版本并merge到本地 几个概念： FETCH_HEAD: 是一个版本链接，记录在本地的一个文件中，指向着目前已经从远程仓库取下来的分支的末端版本 commit-id git fetch: 这将更新git remote中所有的远程仓库所包含分支的最新commit-id, 将其记录到.git/FETCH_HEAD文件中 git pull: 基于本地的FETCH_HEAD记录，比对本地的FETCH_HEAD记录与远程仓库的版本号，然后git fetch获得当前指向的远程分支的后续版本的数据，然后再利用git merge将其与本地的当前分支合并。 首先，你的每一个操作都是要指明来源和目标，对于pull来说，目标就是当前分支。 其次，你得清楚git是有tracking 的概念的，所谓tracking就是把来源和目标绑定在一起，节省一些操作是需要输入的参数。 默认是在当前分支，平时养成好习惯，没谱的时候把来源和目标都带上。 #直接使用git fetch #创建并更新本 地远程分支 git fetch #只是手动指定了要fetch的remote。在不指定分支时通常默认为master #git fetch origin [branch] git fetch origin #指定远程remote和FETCH_HEAD，并且只拉取该分支的提交 git fetch origin dev #git pull \u003c远程主机名\u003e \u003c远程分支名\u003e:\u003c本地分支名\u003e #取回远程主机某个分支的更新，再与本地的指定分支合并。 #当你在 master 下 git pull #等于 fetch origin，然后 merge origin/master #当你在 develop 下 git pull #等于 fetch origin，然后 merge origin/develop #多个分支 #切换到dev git checkout dev #这会在当前分支合并test git pull origin test #查看 .git/config [remote \"origin\"] url = git@xxx:xxx/xxx.git fetch = +refs/heads/*:refs/remotes/origin/* #它指明了 fetch 动作的来源 #也就是说， git fetch 的操作就是取下上述目标的更新 #但是——取下的东西到底在哪儿？ #查看 .git/FETCH_HEAD 可以简单的这样理解： #fetch 从另外一个版本库下载对象和引用 #pull 获取并合并另外的版本库或一个本地分支 git pull = git fetch + merge to local #git fetch origin master #git merge FETCH_HEAD #如果搞不清楚，指明源和目标是最稳当的 git pull [remote] [branch] \r 时光穿梭机 #查看repo当前状态 git status #查看改变 git diff ","date":"2017-11-07","objectID":"/git/:9:8","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"版本回退 每当文件修改到一定程度的时候，就可以提交一次。这样即使误操作后，还可以从最近的commit中恢复，而不是把工作成果全部丢失。 #查看提交记录 #git的commit id是一个SHA1的16进制散列 git log Update README.md commit e89d28373c19321466f99e15cd3cdcc5fffe868f Author: zhang21 \u003celite_zhang21@163.com\u003e Date: Thu Apr 5 23:40:13 2018 +0800 #版本回退，如果文件误删，可以从commit中恢复 #查看提交记录，能看到Commit ID(sha1sum散列值) #在Git中，用HEAD表示当前版本，也就是最新的Commit ID #上一版本HEAD^, 上上版本HEAD^^, 倒数第十个版本HEAD~100 #HEAD指的是当前版本 #重置当前HEAD到指定状态 git reset --hard HEAD^ #也可以利用commit id回退 git reset --hard $commit_id #查看历史命令 git reflog #在本地回退之后，是无法push到远程的 #必须强制push git push origin master --force \r","date":"2017-11-07","objectID":"/git/:10:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"工作区和暂存区 git add实质是吧文件修改添加到暂存区 git commit实质是把暂存区的所有内容提交到当前分支 \r","date":"2017-11-07","objectID":"/git/:11:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"管理修改 为什么git比其它版本控制系统设计的更优秀，因为它跟踪并管理的是修改，而非文件。 如果修改后的文件没有使用git add放入暂存区的话，那么git commit也不会生效的。 \r","date":"2017-11-07","objectID":"/git/:12:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"撤销修改 如果要纠正文件，可以手动修改文件并恢复到上一版本状态。 但也可以使用git命令。 #丢弃工作区的修改 #--很重要，没有--就变成了切换分支的命令 git checkout -- filename #当你不但改乱了工作区某个文件的内容，还添加到了暂存区时。想丢弃修改，分两步。 #第一步用命令git reset HEAD file，就回到了场景1，第二步git checkout --file。 git reset HEAD file \u0026\u0026 git checkout -- file \r","date":"2017-11-07","objectID":"/git/:13:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"删除文件 在git中，删除也是一个修改操作。 有两种情况： 误删除 真删除 #rm，从工作区和索引中删除文件 #如果一个文件已经被提交到版本库，那么你永远不用担心误删 git rm README #误删某文件，需要恢复 git checkout -- README \r 远程仓库 用于验证推送，GitHub与本地仓库使用SSH加密传输，所以这需要创建一对密钥。 #生成SSH Key ssh-keygen -t rsa -C \"email-address\" #会生成.ssh目录，里面包含公私钥 #将公钥id_ras.pub填入GitHub \r","date":"2017-11-07","objectID":"/git/:14:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"添加远程仓库 #origin是默认的远程仓库名，你可以修改 git remote add origin git@xxx.com:username/xxx.git #推动本地仓库到远程 #实际上是推动本地的master分支到远程 #-u关联了本地master和远程master git push -u origin master #之后 git push origin master # 推送本地特定分支到远程特定分支 git push origin local-1:remote-2 \r","date":"2017-11-07","objectID":"/git/:15:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"从远程库克隆 #将远程仓库克隆到本地 #如果是多人协作开发，那么每个人各自从远程克隆一份就可以了 #可以使用ssh协议或https协议(每次都要输入口令) git clone git@xxx.com:username/xxx.git #克隆指定分支 git clone -b test URL \r 分支管理 你可以创建一个自己的分支，别人看不到，还继续在原来的分支上正常工作。而你在自己的分支上干活，想提交就提交，而不会影响到其他人。 \r","date":"2017-11-07","objectID":"/git/:16:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"创建于合并分支 HEAD严格来说不是指向提交，而是指向分支(如master)，分支才是指向提交。 当工作完成后，便可合并分支，然后删除额外的分支。 #查看分支 #*代表当前工作分支 git branch #创建分支 git branch \u003cbranch-name\u003e #切换分支 git checkout \u003cbranch-name\u003e #创建并切换分支，等于上面的创建和切换分支 git checkout -b \u003cbranch-name\u003e #在test分支下新建test.txt git checkout test echo 'Just a test' \u003e ./test.txt git add test.txt git commit -m 'Just a test branch' #回到master git checkout master #此分支下并没有test.txt #也就是说并没有其它分支提交的内容 #合并分支到当前分支 git merge \u003cbranch-name\u003e #合并test分支到当前的master分支 git merge test #删除分支 git branch -d \u003cbranch-name\u003e #合并完成后删除test分支 git brancd -d test \r","date":"2017-11-07","objectID":"/git/:17:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"解决冲突 合并分支玩玩也不是一帆风顺的！ 可能在你创建了新分支后，master分支又进行了提交，而你的新分支也做了提交，这是合并分支便会带了问题。 当git分支无法合并时，就必须首先要解决冲突。解决冲突后，再提交和合并。 #查看分支合并图 git log --graph \r","date":"2017-11-07","objectID":"/git/:18:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"分支管理策略 在实际开发中，master分支应该是非常稳定的。也就是只用来发布新版本，不能在上面干活 干活应在其它分支上(如dev)，干完后合并到master 工作人员都在dev上干活，每个人都有自己的分支，然后将自己的分支合并到dev就可以了 合并分支时，加上--no-ff参数就可以用普通模式合并，合并后的历史有分支，能看出来曾经做过合并，而fast forward合并就看不出来曾经做过合并。 \r","date":"2017-11-07","objectID":"/git/:19:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"Bug分支 Git提供了一个stash功能，可以把工作现场储藏起来，等以后恢复现场后继续工作。 git stash #创建debug分支 git checkout -b 'issue-25' git checkout master git merge --no-ff -m \"debug 25\" 'issue-25' #切回工作区 git stash list git stash apply stash@xxx #手动删除stash git stash drop #恢复同时也删除stash git stash pop \r","date":"2017-11-07","objectID":"/git/:20:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"Feature分支 添加一个新功能时，你肯定不希望因为一些实验性质的代码，把主分支搞乱了，所以，每添加一个新功能，最好新建一个feature分支，在上面开发，完成后，合并，最后，删除该feature分支。 丢弃一个没有被合并过得分支，可通过git branch -D \u003cbranch-name\u003e强行删除。 \r","date":"2017-11-07","objectID":"/git/:21:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"多人协作 #查看远程仓库 git remote #显示远程仓库详细信息 git remote -v #推送指定分支 git push origin test #抓取分支 git clone #更新分支 git pull #合并分支 git merge #推送分支 git push ","date":"2017-11-07","objectID":"/git/:22:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"版本库（Repository） 隐藏目录.git是Git的版本库。 Git版本库里面存放了很多东西，其中最重要的就是 stage(或index)的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。 用git add把文件添加进去，实际是把文件添加到暂存区； 用git commit提交更改，实际是把暂存区的所有内容提交到当前分支。默认git commit就是往master上提交更改。 \r \rrebase 使用rebase(变基)命令重新整理提交记录。尽量不要对任何已经提交到公共仓库中的commit进行修改，除非你自己明白。 \r\r \r\rSSHKey 创建SSHKey并在本地关联多个SSH #把你的github邮箱地址 ssh-keygen -t rsa -C \"email@example.com\" #会生成 ~/.ssh，包含 私钥：id_rsa，公钥：id_rsa.pub 将公钥写入Github 在Github–Account settings–SSH Keys–Add SSH Key里面，添加你的id_rsa.pub公钥文件。 当然，你可以添加多个Key哦，毕竟可能你有多台登陆设备。 这个就相当于SSH无密钥认证。 在主机上关联多个git vim ~/.ssh/config #One Host git.xxx.com IdentityFile ~/.ssh/id_rsa Hostname IP User git Port 10022 #two Host github IdentityFile ~/.ssh/id_rsa Hostname github.com User git Port 22 #three #这样可用于ssh登录 Host zhang21 Hostname ip User username Port 22 IdentityFile ~/.ssh/id_rsa #一定要记着修改权限 chmoe 600 ~/.ssh/* #测试连接 ssh -T git@github.com \r 标签管理 发布一个新版本时，通常先在版本库中打一个标签(tag)，这样，就唯一确定了打标签时刻的版本。 将来无论什么时候，取某个标签的版本，就是把那个打标签的时刻的历史版本取出来。所以，标签也是版本库的一个快照。 tag其实是指向 commit id的。 git有commit，为什么还要引入tag? commit id 是一串散列值，并不简单明了。但是tag,我可以写为\"v1.0\",“v1.2”… 让tag，“v1.0\"指向对应的commit id，很方便明了。 \r","date":"2017-11-07","objectID":"/git/:23:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"创建标签 #切换到需要打tag的分支上 git brach test #创建tag 默认tag是打在最新提交的commit上 #git tag \u003ctag-name\u003e git tag v1.0 #查看所有tag git tag #指定tag对应的commit #git tag \u003ctag-name\u003e \u003ccommit_id\u003e git tag v1.0 65432ba #标签不是按时间顺序列出的，而是按照字母排序 git show $tag-name git show v1.0 #创建带有说明的标签 #git tag -a \u003ctag-name\u003e -m \"v1.1 released\" \u003ccommit-id\u003e git tag -a v1.1 -m \"V1.1\" 6543bb #查看标签说明 git show \u003ctag-name\u003e #用私钥签名一个标签 #依赖GPG #git tag -s \u003ctag-name\u003e -m \"pri-key\" \u003ccommit-id\u003e git tag -s v1.2 -m \"pri-key v1.2\" 6543bc \r","date":"2017-11-07","objectID":"/git/:24:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["linux"],"content":"操作标签 #删除标签 #git tag -d \u003ctag-name\u003e git tag -d v1.2 #推送某个标签到远程 #git pust origin \u003ctag-name\u003e git push origin v1.0 #推送全部标签 git push origin --tags #删除远程标签 git push origin :refs/tags/\u003ctag-name\u003e \r \r\r忽略特殊文件 创建一个.gitignore特殊文件，然后把要忽略的文件名填进去，Git就会自动忽略这些文件。 各种模板： https://github.com/github/gitignore 检查.gitignore文件: git check-ignore .gitignore \r\r \r搭建Git服务器 常见的Git服务器有： GitLab: https://gitlab.com/ Gogs（go git service）: https://gogs.io/ ","date":"2017-11-07","objectID":"/git/:25:0","tags":["linux","tool","git"],"title":"Git","uri":"/git/"},{"categories":["诗歌"],"content":"——波兰诗人维斯拉瓦·辛波丝卡(Wislawa Szymborska) They’re both convinced that a sudden passion joined them. Such certainty is beautiful, but uncertainty is more beautiful still. Since they’d never met before, they’re sure that there’d been nothing between them. But what’s the word from the streets, staircases, hallways – perhaps they’ve passed each other a million times? I want to ask them if they don’t remember a moment face to face in some revolving door? perhaps a “sorry” muttered in a crowd? a curt “wrong number” caught in the receiver? but I know the answer. No, they don’t remember They’d be amazed to hear that Chance has been toying with them now for years. Not quite ready yet to become their Destiny, it pushed them close, drove them apart, it barred their path, stifling a laugh, and then leaped aside. There were signs and signals, even if they couldn’t read them yet. Perhaps three years ago or just last Tuesday a certain leaf fluttered from one shoulder to another? Something was dropped and then picked up. Who knows, maybe the ball that vanished into childhood’s thicket? There were doorknobs and doorbells where one touch had covered another beforehand. Suitcases checked and standing side by side. One night, perhaps, the same dream, grown hazy by morning. Every beginning is only a sequel, after all, and the book of events is always open halfway through. ","date":"2017-11-06","objectID":"/love-at-first-sight/:0:0","tags":["诗歌"],"title":"Love at First Sight","uri":"/love-at-first-sight/"},{"categories":["network"],"content":" \r过滤语法 wireshark过滤分为两种: 抓包过滤 显示过滤 尽量避免使用抓包过滤。即便多看几个报文，也比漏掉一个报文要好。 \r\r","date":"2017-10-25","objectID":"/wireshark/:0:0","tags":["wireshark","network"],"title":"Wireshark","uri":"/wireshark/"},{"categories":["network"],"content":"抓包过滤 类型 host net port 方向 src dst 协议 ether ip/arp tcp/udp http/dns/ftp/icmp … 逻辑运算符 \u0026\u0026 || ! 栗子： #主机 host www.xx.com src host 192.168.1.1 \u0026\u0026 dst port 80 host 193.168.1.1 || host 192.168.1.2 #广播包 !broadcast #MAC ether host 00:88:ab:56:12:0d src ether host 00:88:ab:56:12:0d #IP host 192.168.1.1 dst host 192.168.1.1 #net net 192.168.1.0/24 src net 192.168.1.0/24 #vlan vlan 11 #Port port 80 ! port 443 dst port 80 udp dst port 5678 portrange 1-80 \r\r","date":"2017-10-25","objectID":"/wireshark/:1:0","tags":["wireshark","network"],"title":"Wireshark","uri":"/wireshark/"},{"categories":["network"],"content":"显示过滤 比较操作符 == != \u003e \u003c \u003e= \u003c= 逻辑操作符 and or xor not IP ip.addr ip.src ip.dst Port tcp.port tcp.srcport tcp.dstport tcp.flag.syn tcp.flag.ack Protocol arp ip icmp udp tcp dns … 栗子： #ip ip.addr == 1.1.1.1 ip.src == 1.1.1.1 and ip.dst == 2.2.2.2 #port tcp.port == 80 tcp.dstport == 80 tcp.flag.syn == 1 #pro arp not icmp \r\r \r\rHTTPS Wireshark也可以分析HTTPS加密的包，但你需要用证书将包先解密。 在Edit-\u003ePreferences-\u003eProtocol-\u003eSSL选项填写相关信息进行解密。 ","date":"2017-10-25","objectID":"/wireshark/:2:0","tags":["wireshark","network"],"title":"Wireshark","uri":"/wireshark/"},{"categories":["linux"],"content":"参考： Linux Shell脚本攻略 鸟哥的Linux私房菜 k-vim: https://github.com/wklken/k-vim \r \r\rinode 参考: wiki: https://zh.wikipedia.org/wiki/Inode 关于 inode 理解inode \r\r","date":"2017-10-24","objectID":"/linuxshell/:0:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"简介 inode是UNIX操作系统中的一种数据结构，它包含了与文件系统中各个文件系统对象(文件、目录、设备文件、socket、管道…)的元数据信息。在UNIX中创建文件系统时，同时将会创建大量的inode。通常，文件系统磁盘空间中大约百分之一空间分配给了inode表。 Unix先驱丹尼斯·里奇说，inode这个命名的来源可能是文件系统的存储组织为一个扁平数组，分层目录信息使用一个数作为文件系统这个扁平数组的索引值（index）。 理解inode，要从文件储存说起。 文件储存在硬盘上，硬盘的最小存储单位叫做扇区（Sector）。每个扇区储存512字节（相当于0.5KB）。 操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个块（block）。这种由多个扇区组成的\"块\"，是文件存取的最小单位。“块\"的大小，最常见的是4KB，即连续八个sector组成一个block。 文件数据都储存在块中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为索引节点。 \r\r\r","date":"2017-10-24","objectID":"/linuxshell/:1:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"细节 文件系统创建（格式化）时，就把存储区域分为两大连续的存储区域。一个用来保存文件系统对象的元信息数据，这是由inode组成的表，每个inode默认是256字节或者128字节。另一个用来保存文件系统对象的内容数据，划分为512字节的扇区，以及由8个扇区组成的4K字节的块。块是读写时的基本单位。一个文件系统的inode的总数是固定的。这限制了该文件系统所能存储的文件系统对象的总数目。典型的实现下，所有inode占用了文件系统1%左右的存储容量。 文件系统中每个文件系统对象对应一个inode数据，并用一个整数值来辨识。这个整数常被称为inode号码（i-number或inode number）。由于文件系统的inode表的存储位置、总条目数量都是固定的，因此可以用inode号码去索引查找inode表。 Inode存储了文件系统对象的一些元信息，如所有者、访问权限（读、写、执行）、类型（是文件还是目录）、内容修改时间、inode修改时间、上次访问时间、对应的文件系统存储块的地址，等等。知道了1个文件的inode号码，就可以在inode元数据中查出文件内容数据的存储地址。 文件名与目录名是文件系统对象便于使用的别名。一个文件系统对象可以有多个别名，但只能有一个inode，并用这个inode来索引文件系统对象的存储位置。 inode不包含文件名或目录名的字符串，只包含文件或目录的元信息 Unix的文件系统的目录也是一种文件。打开目录，实际上就是读取目录文件。目录文件的结构是一系列目录项（dirent）的列表。每个目录项，由两部分组成：所包含文件或目录的名字，以及该文件或目录名对应的inode号码 文件系统中的一个文件是指存放在其所属目录的目录文件中的一个目录项，其所对应的inode的类别为文件；文件系统中的一个目录是指存放在其父目录文件中的一个目录项，其所对应的inode的类别为目录。可见，多个文件可以对应同一个inode;多个目录可以对应同一个inode 文件系统中如果两个文件或者两个目录具有相同的inode号码，那么就称它们是硬链接关系。实际上都是这个inode的别名。换句话说，一个inode对应的所有文件（或目录）中的每一个，都对应着文件系统某个目录文件中唯一的一个目录项 创建一个目录时，实际做了3件事：在其父目录文件中增加一个条目；分配一个inode；再分配一个存储块，用来保存当前被创建目录包含的文件与子目录。被创建的目录文件中自动生成两个子目录的条目，名称分别是：.和..。前者与该目录具有相同的inode号码，因此是该目录的一个硬链接。后者的inode号码就是该目录的父目录的inode号码。所以，任何一个目录的硬链接总数，总是等于它的子目录总数（含隐藏目录）加2。即每个子目录文件中的..条目，加上它自身的目录文件中的.条目。再加上父目录文件中的对应该目录的条目。 通过文件名打开文件，实际上是分成三步实现：首先，操作系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。 \r\r\r","date":"2017-10-24","objectID":"/linuxshell/:2:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"讨论 一个文件系统对象可以有多个名字，这些具有硬链接关系的文件系统对象名字具有相同的inode号码，彼此是平等的。即首个被创建的文件并没有特殊的地位。这与符号链接不同。一个符号链接文件有自己的inode，符号链接文件的内容是它所指向的文件的名字。因此删除符号链接所指向的文件，将导致这个符号链接文件在访问时报错 删除一个文件或目录，实际上是把它的inode的链接数减1。这并不影响指向此inode的别的硬链接 一个inode如果没有硬链接，此时inode的链接数为0，文件系统将回收该inode所指向的存储块，并回收该inode自身 从一个inode，通常是无法确定是用哪个文件名查到此inode号码的。打开一个文件后，操作系统实际上就抛掉了文件名，只保留了inode号码来访问文件的内容。库函数getcwd()用来查询当前工作目录的绝对路径名。其实现是从当前工作目录的inode逐级查找其上级目录的inode，最后拼出整个绝对路径的名字 历史上，对目录的硬链接是可能的。这可以使目录结构成为一个有向图，而不是通常的目录树的有向无环图。一个目录甚至可以是自身的父目录。现代文件系统一般禁止这些混淆状态，只有根目录保持了特例：根目录是自身的父目录。ls /..就是根目录的内容 一个文件或目录在文件系统内部移动时，其inode号码不变。文件系统碎片整理可能会改变一个文件的物理存储位置，但其inode号码不变。非UNIX的FAT及其派生的文件系统是无法实现inode不变这一特点。 inode文件系统中安装新库十分容易。当一些进程正在使用一个库时，其它进程可以替换该库文件名字的inode号码指向新创建的inode，随后对该库的访问都被自动引导到新inode所指向的新的库文件的内容。这减少了替换库时重启系统的需要。而旧的inode的链接数已经为0，在使用旧库的进程结束后，旧的inode与旧库文件会被系统自动回收。 \r\r\r","date":"2017-10-24","objectID":"/linuxshell/:3:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"结构 POSIX标准强制规范了文件系统的行为。每个文件系统对象必须具有： 设备ID，标识容纳该文件的设备 以字节为单位的文件大小 磁盘块 用户(uid) 组(gid) r/w/x权限 时间戳 ctime: inode自身被修改的时间； mtime：内容修改的时间； atime：最后一次被访问的时间 链接数，有多少硬链接指向此inode 使用stat系统调用可以查询一个文件的inode号码及一些元信息。 # 使用stat查看某个文件inode stat _config.yml File: '_config.yml' Size: 2522 Blocks: 8 IO Block: 4096 regular file Device: fd02h/64770d Inode: 52354 Links: 1 Access: (0664/-rw-rw-r--) Uid: ( 1000/ zhang) Gid: ( 1000/ zhang) Access: 2019-04-22 09:39:28.735991059 +0800 Modify: 2018-07-07 15:37:50.000000000 +0800 Change: 2018-12-11 07:38:26.287109004 +0800 Birth: - \r\r\r","date":"2017-10-24","objectID":"/linuxshell/:4:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"大小 inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode表（inode table），存放inode所包含的信息。 由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是磁盘还未存满的情况。这时，就无法在磁盘上创建新文件。 # 查看inode df -i Filesystem Inodes IUsed IFree IUse% Mounted on overlay 26214400 597690 25616710 3% / tmpfs 485005 17 484988 1% /dev tmpfs 485005 16 484989 1% /sys/fs/cgroup /dev/mapper/centos-home 215418880 297955 215120925 1% /home/test /dev/mapper/centos-root 26214400 597690 25616710 3% /etc/hosts shm 485005 1 485004 1% /dev/shm tmpfs 485005 1 485004 1% /proc/acpi tmpfs 485005 1 485004 1% /proc/scsi tmpfs 485005 1 485004 1% /sys/firmware \r\r\r","date":"2017-10-24","objectID":"/linuxshell/:5:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"硬软链接 \r","date":"2017-10-24","objectID":"/linuxshell/:6:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"硬链接 一般情况下，文件名和inode号码是\"一一对应\"关系，每个inode号码对应一个文件名。但是，Unix/Linux系统允许，多个文件名指向同一个inode号码。 这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为\"硬链接”（hard link）。 运行上面这条命令以后，源文件与目标文件的inode号码相同，都指向同一个inode。inode信息中有一项叫做\"链接数\"，记录指向该inode的文件名总数，这时就会增加1。 反过来，删除一个文件名，就会使得inode节点中的\"链接数\"减1。当这个值减到0，表明没有文件名指向这个inode，系统就会回收这个inode号码，以及其所对应block区域。 这里顺便说一下目录文件的\"链接数\"。创建目录时，默认会生成两个目录项：\".“和”..\"。前者的inode号码就是当前目录的inode号码，等同于当前目录的\"硬链接\"；后者的inode号码就是当前目录的父目录的inode号码，等同于父目录的\"硬链接\"。所以，任何一个目录的\"硬链接\"总数，总是等于2加上它的子目录总数（含隐藏目录）。 \r\r","date":"2017-10-24","objectID":"/linuxshell/:6:1","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"软链接 文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的\"软链接\"（soft link）或者\"符号链接（symbolic link）。 这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错：“No such file or directory”。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode\"链接数\"不会因此发生变化。 \r\r \r\rvim 在Linux中使用文本编辑器来编辑你的Linux参数配置文件是一件很重要的事情，因此系统管理员至少应该熟悉一种文本编辑器。 在Linux中，绝大部分的配置文件都是以ASCII(键盘上可找到)的纯文本形式。因此利用简单的文本编辑器就能修改。 ASCII（发音：/ˈæski/ ass-kee[1]，American Standard Code for Information Interchange，美国信息交换标准代码）是基于拉丁字母的一套电脑编码系统。从[0000 0000 - 0111 1111]共128个字符。 \rvi文本编辑器 所有的Unix Like系统都会内置vi文本编辑器，其他的文本编辑器则不一定存在 很多软件的编辑接口都会主动调用vi(如 crontab等命令) vim是vi的高级版本 vim具有程序编辑的能力，可以主动以字体颜色辨别语法的正确性，方便程序设计 程序简单，编辑速度相当快速 vi中的tab键所得结果与空格符不一样 vi中，数字是很有意义的 数字通常代表重复做几次，或去到第几个的意思 ","date":"2017-10-24","objectID":"/linuxshell/:6:2","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"警告信息 当我们使用vim时，vim会在当前目录下再创建一个名为filename.swp的暂存文件。 由于vim的工作被不正常中断，导致暂存盘无法通过正常流程来结束，所以暂存文件就不会消失。此时编辑文件就会出现某些异常情况。 可能有其他人或程序同时在编辑这个文件 在前一个vim的环境中，可能因为某些不明原因导致vim中断(crashed) \r","date":"2017-10-24","objectID":"/linuxshell/:7:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"三种模式 vim包括三种模式： 一般模式 编辑模式 命令行模式 \r","date":"2017-10-24","objectID":"/linuxshell/:8:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"一般模式 命令 | 说明 | - x | 向后删除一个字符 X | 向前删除一个字符 nx,nX | 向前/后 删除n个字符 dd | 删除当前行 D | 删除当前行所有字符，使之成为空行 ndd | 删除光标所在行的向下n行 d1G | 删除光标所在行到第一行 dG | 删除光标所在行到最后一行 yy | 复制光标所在行 y1G | 复制光标所在行到第一行 yG | 复制光标所在行到最后一行 ynj | 复制光标所在行和向下n行 dnj | 删除光标所在行和向下n行 p | 将复制的数据粘贴到光标下一行 P | 将复制的数据粘贴到光标上一行 J | 将光标所在行与下一行结合成一行 u | undo,恢复前一个操作 ctrl+r | 重做上一个操作 . | 重复前一个操作 \r","date":"2017-10-24","objectID":"/linuxshell/:8:1","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"编辑模式 命令 | 说明 | - i | 在当前光标所在处插入文字 I | 在光标所在行第一个非空字符插入文字 a | 在当前光标后插入文字 A | 在当前光标所在行最后插入文字 o | 在光标所在行的下一行行首插入字符 O | 在光标所在行的上一行行首插入字符 r | 替换光标所在那一个字符 R | 一直替换光标所指的文字，直到退出 Esc | 退出，回到一般模式 \r","date":"2017-10-24","objectID":"/linuxshell/:8:2","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"命令模式 命令 | 说明 | - h | 方向左 j | 方向下 k | 方向上 l | 方向右 | 光标移到下一行的第一个非空字符 | 光标移到当前行的第一个非空字符 0 | 光标移到当前行的第一个字符 $ | 光标移到当前行的最后一个字符 n空格 | 光标在当前行向右移动n个字符 G | 光标移到最后一行的第一个非空字符 gg | 光标移到第一行的第一个非空字符，相当于1G nG | 光标移到第n行的第一个非空字符 /word | 在光标之后查找word字符串 ?word | 在光标之前查找word字符串 n/N | 重复前一个查找 :s/word1/word2 | 在光标当前行将word1替换成word2 :n1,n2s/word1/word2/g | 在n1行-n2行间将word1替换成word2 %s/word1/word2/gc | 全局将word1替换成word2，在替换前让用户确认(confirm) :w | 保存到文件 :w file2 | 保存到file2文件 :r file3 | 从file3文件读取数据并写入 :wq/:x | 保存并退出 :q | 退出 :q! | 强制退出 :!cmd | 执行命令 :r!cmd | 将执行命令写入 :set nu | 显示行号 :set nonu | 取消行号 :n1,n2w file4 | 将n1行-n2行的内容保存到file4文件 \r","date":"2017-10-24","objectID":"/linuxshell/:8:3","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"Visual模式 参考: https://vimjc.com/vim-visual-mode.html Visual Mode下可以选择一块编辑区域，然后对选中的文件内容执行复制、粘贴、插入、删除、替换、改变大小写等操作，是vim使用过程中常用的一种模式。 在vim命令模式下，使用v或V或ctrl+v都可进入可视化模式。这三种模式的主要区别在于: v字符选择模式: 选中光标经过的所有字符 V行选择模式: 选中光标经过的所有行 ctrl+v块选择模式: 选中一整个矩形框表示的所有文本 具体细致的操作就不写了，但却是非常使用。 ","date":"2017-10-24","objectID":"/linuxshell/:9:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"环境设置与记录 因为vim会主动将你曾经的行为记录下来，好方便下次操作。这个文件是自动生成的。 ~/.vim.info ~/.vim.rc 整体vim设置 /etc/vimrc 此外，每个Distribution对vim的默认环境都不太相同。所以你可能需要设置成你自己的工作方式。 参数 | 说明 | - :set nu :set nonu | 行号设定 :set hlsearch :set nohlsearch | 高亮设定 :set autoindent :set noautoindent | 自动缩排设定 :set backup | 自动备份设定 :set ruler | 状态栏设定 :set showmode | 模式显示设定，如INSERT :set backspace=(012) | 设定退格(backspace)值 :set all | 显示所有环境参数 :set | 显示与系统默认值不同的参数 :syntax on/off | 程序语法显示 :set bg=dark/light | 设定背景颜色 栗子： vim /root/.vimrc \"这是注释\" set nu set ruler set bg=dark syntax on set hlsearch \r\r","date":"2017-10-24","objectID":"/linuxshell/:10:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"注意事项 ","date":"2017-10-24","objectID":"/linuxshell/:11:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"中文编码问题 修改语系编码： LANG=zh_CN.utf-8 ","date":"2017-10-24","objectID":"/linuxshell/:11:1","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"Linux与Dos的换行字符 Linux的换行(Enter)为LF符号($) Dos的换行(Enter)为CRLF符号(^M$) 不同系统之间复制纯文本文件可能会有问题，此时可以转换： unix2dos file newfile dos2unix file newfile ","date":"2017-10-24","objectID":"/linuxshell/:11:2","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"语系编码转换 iconv - convert text from one character encoding to another #iconv -f 源编码 -t 新编码 filename [-o newfile] #-o，转换到新文件 iconf -f big4 -t utf8 old.big5 -o new.utf8 \r\r\r","date":"2017-10-24","objectID":"/linuxshell/:11:3","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"使用正则 VIM里的正则用着太爽了，不用不知道，用了非常好！请注意转义哈！ 在vim里的查找(/, ?)和替换(:s, :1,ns, :%s)功能中，使用正则可极大提高效率。 vim毕竟是个编辑器，如果直接饮用正则表达式的元字符会造成一些麻烦。所以需要对正则元字符进行转义。 vim有一个magic，可以设置哪些正则元字符需要转义，哪些不需要。 vim :set magic :set nomagic magic (\\m)：除了 $ . * ^ 之外的元字符都需要转义，也就是反斜杠(\\) /\\m.* #查找任意字符串 nomagic (\\M)：除了`$ ^`之外的元字符都需要转义 /\\M.* #查找特定字符串.* 我不建议使用，这样使得vim使用很错乱。还是老老实实使用转义好些。 \r正则表达式的元字符参考本文档的正则表达式章节。 栗子: vim 1.txt # \\s，空格 # 删除每行开通的空格 :%s/^\\s*//g # 去掉开头的行号 11, 20s/^[0-9]\\{2\\}//g # 查找 /[0-9]\\{3,5\\} # 查找多个 /aaa\\|bbb\\|ccc #替换多个 :%s/aaa\\|bbb/HAHAHAHA/g \r\r\r","date":"2017-10-24","objectID":"/linuxshell/:12:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"插件 插件是一种扩展VIM功能的方法。VIM将插件分为： 全局插件(global)：无条件加载和操作 文件类型插件(filetype)：仅为特定文件类型加载和操作，参阅vim --\u003e :help filetype VIM默认会在特定位置查找插件： Linux/OS X： ~/.vim/plugin Windows： $HOME/vimfiles/plugin 文件类型插件为ftplugin 插件只是VIM脚本，因此你可以使用它们来定义函数、映射和命令，就像在.vimrc中一样。 插件通常不仅仅是位于相应目录中的单个.vim文件。它们通常还包括自动加载脚本(:help autoload)，语法脚本(:help syntax)和缩进处理脚本。将这些脚本中的所有代码打包在一起，提供强大的钩子来增强VIM。 VIM內建的帮助(:help plugin)包含各种详细信息。有一些优秀资源: Learn Vimscript the Hard Way Writing Vim Plugins 可使用放在适当的目录的插件并启动VIM。当然，有些插件可能有比较复杂的安装过程(比如YouCompleteMe插件)。 目前，像Pathogen和Vundle这样的插件管理器是手动安装插件文件的流行替代品，特别是因为插件通常带有多个文件。 \r","date":"2017-10-24","objectID":"/linuxshell/:13:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"vim插件管理器 当没有插件管理器时，Vim 用户必须手动下载 tarball 包形式的插件，并将它们解压到 ~/.vim 目录中。在少量插件的时候可以。但当他们安装更多的插件时，就会变得一团糟。所有插件文件分散在单个目录中，用户无法找到哪个文件属于哪个插件。此外，他们无法找到他们应该删除哪个文件来卸载插件。这时 Vim 插件管理器就可以派上用场。插件管理器将安装插件的文件保存在单独的目录中，因此管理所有插件变得非常容易。 介绍几个常见的VIM插件管理器: Pathogen: https://github.com/tpope/vim-pathogen Vundle: https://github.com/VundleVim/Vundle.vim Plug: https://github.com/junegunn/vim-plug Vundle 安装Vundle前请先安装vim和git。 sudo yum install -y vim git # 下载Vundle git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim # 配置vundle vim ~/.vimrc #加入以下内容 set nocompatible \" required filetype off \" required set rtp+=~/.vim/bundle/Vundle.vim call vundle#begin() Plugin 'gmarik/Vundle.vim' call vundle#end() \" required filetype plugin indent on \" required \" 设置包括vundle和初始化相关的runtime path set rtp+=~/.vim/bundle/Vundle.vim call vundle#begin() \" 另一种选择, 指定一个vundle安装插件的路径 \"call vundle#begin('~/some/path/here') \" 让vundle管理插件版本,必须 Plugin 'VundleVim/Vundle.vim' \" 以下范例用来支持不同格式的插件安装. \" 请将安装插件的命令放在vundle#begin和vundle#end之间. \" Github上的插件 \" 格式为 Plugin '用户名/插件仓库名' Plugin 'tpope/vim-fugitive' \" 来自 http://vim-scripts.org/vim/scripts.html 的插件 \" Plugin '插件名称' 实际上是 Plugin 'vim-scripts/插件仓库名' 只是此处的用户名可以省略 Plugin 'L9' \" 由Git支持但不再github上的插件仓库 Plugin 'git clone 后面的地址' Plugin 'git://git.wincent.com/command-t.git' \" 本地的Git仓库(例如自己的插件) Plugin 'file:///+本地插件仓库绝对路径' Plugin 'file:///home/gmarik/path/to/plugin' \" 插件在仓库的子目录中. \" 正确指定路径用以设置runtimepath. 以下范例插件在sparkup/vim目录下 Plugin 'rstacruz/sparkup', {'rtp': 'vim/'} \" 安装L9，如果已经安装过这个插件，可利用以下格式避免命名冲突 Plugin 'ascenator/L9', {'name': 'newL9'} \" 你的所有插件需要在下面这行之前 call vundle#end() \" 必须 filetype plugin indent on \" 必须 加载vim自带和插件相应的语法和文件类型相关脚本 \" 忽视插件改变缩进,可以使用以下替代: \"filetype plugin on \" \" 简要帮助文档 \" :PluginList - 列出所有已配置的插件 \" :PluginInstall - 安装插件,追加 `!` 用以更新或使用 :PluginUpdate \" :PluginSearch foo - 搜索 foo ; 追加 `!` 清除本地缓存 \" :PluginClean - 清除未使用插件,需要确认; 追加 `!` 自动批准移除未使用插件 \" \" 查阅 :h vundle 获取更多细节和wiki以及FAQ \" 将你自己对非插件片段放在这行之后 # 安装插件 # vim中 :PluginInstall # bash vim _PluginInstall +qall # 查找插件 # vim :PluginSearch # 要从vimscripts网站刷新本地的列表 :PluginSearch! # 查看已安装插件 # vim :PluginList # 更新插件 # vim :PluginUpdate \r\rPlug 它是一个速度非常快的、极简的 vim 插件管理器。它可以并行地安装或更新插件。你还可以回滚更新。 # 下载安装 curl -fLo ~/.vim/autoload/plug.vim --create-dirs \\ https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim # 配置 vim ~/.vimrc # 以 call plug#begin(PLUGIN_DIRECTORY) 开始，并以 call plug#end() 结束 # 栗子 \" Specify a directory for plugins \" - For Neovim: ~/.local/share/nvim/plugged \" - Avoid using standard Vim directory names like 'plugin' call plug#begin('~/.vim/plugged') \" Make sure you use single quotes \" Shorthand notation; fetches https://github.com/junegunn/vim-easy-align Plug 'junegunn/vim-easy-align' \" Any valid git URL is allowed Plug 'https://github.com/junegunn/vim-github-dashboard.git' \" Multiple Plug commands can be written in a single line using | separators Plug 'SirVer/ultisnips' | Plug 'honza/vim-snippets' \" On-demand loading Plug 'scrooloose/nerdtree', { 'on': 'NERDTreeToggle' } Plug 'tpope/vim-fireplace', { 'for': 'clojure' } \" Using a non-master branch Plug 'rdnetto/YCM-Generator', { 'branch': 'stable' } \" Using a tagged release; wildcard allowed (requires git 1.9.2 or above) Plug 'fatih/vim-go', { 'tag': '*' } \" Plugin options Plug 'nsf/gocode', { 'tag': 'v.20150303', 'rtp': 'vim' } \" Plugin outside ~/.vim/plugged with post-update hook Plug 'junegunn/fzf', { 'dir': '~/.fzf', 'do': './install --all' } \" Unmanaged plugin (manually installed and updated) Plug '~/my-prototype-plugin' \" Initialize plugin system call plug#end() # 重载.vimrc以使用vim source ~/.vimrc # vim :PlugInstall :PlugUpdate :PlugClean # 升级plug # vim :PlugUpgrade \r\r\r","date":"2017-10-24","objectID":"/linuxshell/:13:1","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"vim常见插件 NERDTree： 文档树 YouCompleteMe： 代码补全 Rainbow： 彩虹括号 UndoTree： 关闭vim后也可代码撤回 vim-gitgutter：显示git信息 ctrlp： tagbar：浏览当前文件的标签并获得其结构的概述 \r\r\r","date":"2017-10-24","objectID":"/linuxshell/:13:2","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"k-vim k-vim: https://github.com/wklken/k-vim k-vim是一份很好的vim配置，我个人使用的是这个配置。 \r\r","date":"2017-10-24","objectID":"/linuxshell/:14:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"代码折叠 vim支持多种代码折叠: manual: 手工定义折叠 indent: 用缩进表示折叠 expr: 用表达式来定义折叠 syntax: 用语法高亮来定义折叠 diff: 对没有更改的文本进行折叠 marker: 用标志折叠 k-vim里配置的折叠方法是indent。此缩进方法的操作如下： za: 折叠缩进处的代码 ,zz: k-vim配置的za zM: 关闭所有的折叠 zR: 打开所有的折叠 \r\r\r","date":"2017-10-24","objectID":"/linuxshell/:14:1","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"调试器 介绍vim下常用的代码调试器(debugger)。 ","date":"2017-10-24","objectID":"/linuxshell/:15:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"GDB 官网: https://www.gnu.org/software/gdb/ 教程: https://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/gdb.html GDB(GNU debugger)，是GNU软件系统中的标准调试器。支持C、C++等。 \r\r","date":"2017-10-24","objectID":"/linuxshell/:15:1","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"pdb和ipdb Pythone调试器: pdb: Python内建的调试器，用法与gdb一样。 ipdb: 一个开源的Python调试器，它和pdb有相同的接口，但是，它相对于pdb，具有语法高亮、tab补全、更友好的堆栈信息等高级功能。 pdb是python的标准库，无需安装就可以使用。而ipdb是一个第三方库，需要使用pip安装。 这两个调试器有两种使用方法： 一是集成在源代码中加入断点，但需要修改源码，麻烦。 import ipdb xxx ipdb.set_strace() 二是交互式命令调试 python3 -m ipdb xxx.py ipdb\u003e ipdb\u003e help Documented commands (type help \u003ctopic\u003e): ======================================== EOF cl disable interact next psource rv unt a clear display j p q s until alias commands down jump pdef quit source up args condition enable l pdoc r step w b cont exit list pfile restart tbreak whatis break continue h ll pinfo return u where bt d help longlist pinfo2 retval unalias c debug ignore n pp run undisplay Miscellaneous help topics: ========================== exec pdb ipdb常用命令 命令 描述 b/break 设置断点 tbreak 设置临时断点 cl/clear 清除断点 c/continue 继续执行程序 l/list 查看指定的代码行 ll/longlist 查看整个代码 s/step 执行会进入函数 n/next 执行不会进入函数 a 可列出当前函数的参数 r/return 执行代码直到从当前函数返回 j 忽略某段代码 pp 打印表达式的值 run/restart 重启，重启后断点、设置等会保留 q/quie/exit 中止并退出 h/help 帮助 栗子： python3 -m ipdb xxx.py # 在第3行设置断点 ipdb\u003e b 3 # 执行到断点处 ipdb\u003e c # 查看2-7行代码 ipdb\u003e l 2,7 \r\r \r\r编码 参考： ASCII: https://zh.wikipedia.org/wiki/ASCII Unicode: https://zh.wikipedia.org/wiki/Unicode ","date":"2017-10-24","objectID":"/linuxshell/:15:2","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"Unicode 计算机处理的是数字(二进制文件)。他们在存储字符时要给每个字符分配一个数值。 早期的编码系统称为 ASCII（美国信息交换标准码）， 一共有128（0-127）个值，每个值用7bit 保存。ASCII可以满足小写、大写、数字标点符号和一些控制字符的处理。 人们曾尝试将ASCII字符扩展到8bit，这种新的被称为“扩充ASCII”的编码一直没有成为国际性标准。 为了克服ASCII和扩充ASCII先天上的不足，Unicode Consortiun（多语言软件生产商群体）创建了一种能够提供广泛字符集的通用编码系统，称为Unicode。 Unicode最初设置为2Byte的字符集。但版本3的Unicode用的是4Byte编码，并且与ASCII与扩充的ASCII完全兼容。 现在被称为Basic Latin（基本拉丁文）的ASCII字符集就是前25位全部置零的Unicode码。 现在被称为 Latin-1（拉丁文1）的扩充ASCII字符集就是前24位全部置零的Unicode码。 Unicode中的每个字符或符号由一个32bit数来定义，因此这种编码可以定义高达2的32次方(4 294 067 296)个字符或符号。 它的记法使用了十六进制数字，格式如下： U-XXXXXXXX #每个 X 都是一个十六进制的数字 #因此，它的数值从U-00000000到U-FFFFFFFF ","date":"2017-10-24","objectID":"/linuxshell/:16:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"ASCII 美国信息交换码（American Standard Code of Information Internet，ASCII）是一种7bit码，设计来为128个大多数是美国英语里使用的符号提供编码。 今天的ASCII码已成为Unicode的一部分，它占据了Unicode中的前128个码（00000000-0000007F）。 ASCII的一些特点： space(20-sp)字符，是一个可打印的字符，打印出一个空格 大写字母从(41-A)开始，小写字母从(61-a)开始。按ASCII比较时，大写字母的数值会小于小写字母 大写字母与小写字母在他们的7bit编码中只有1bit不同，A(1000001)，a(1100001)，两者相差(20)十六进制 小写字母并没有紧跟在大写字母后面，这两者之间还有几个标点符号(5B-60) 数字从(30-0)开始 从00到1F这最开始的32个字符加上最后一个字符(7F)全都是非打印字符。字符(00)被用作定界符，已定义字符串的结束。字符(7F)是删除字符，它被某些编程语言用来删除前一个字符。剩下的非打印字符称为控制字符，用于数据通信 ASCII控制字符： 二进制 | 十进制 | 十六进制 | 缩写 | Unicode 表示法 | 脱出字符 表示法 | 名称/意义 | - | - | - | - | - | - 0000 0000 | 0 | 00 | NUL | ␀ | ^@ | 空字符（Null） 0000 0001 | 1 | 01 | SOH | ␁ | ^A | 标题开始 0000 0010 | 2 | 02 | STX |␂ | ^B | 本文开始 0000 0011 | 3 | 03 | ETX | ␃ | ^C | 本文结束 0000 0100 | 4 | 04 | EOT | ␄ | ^D | 传输结束 0000 0101 | 5 | 05 | ENQ | ␅ | ^E | 请求 0000 0110 | 6 | 06 | ACK | ␆ | ^F | 确认回应 0000 0111 | 7 | 07 | BEL | ␇ | ^G | 响铃 0000 1000 | 8 | 08 | BS | ␈ | ^H | 退格 0000 1001 | 9 | 09 | HT | ␉ | ^I | 水平定位符号 0000 1010 | 10 | 0A | LF | ␊ | ^J | 换行键 0000 1011 | 11 | 0B | VT | ␋ | ^K | 垂直定位符号 0000 1100 | 12 | 0C | FF | ␌ | ^L | 换页键 0000 1101 | 13 | 0D | CR | ␍ | ^M | Enter键 0000 1110 | 14 | 0E | SO | ␎ | ^N | 取消变换（Shift out） 0000 1111 | 15 | 0F | SI | ␏ | ^O | 启用变换（Shift in） 0001 0000 | 16 | 10 | DLE | ␐ | ^P | 跳出数据通讯 0001 0001 | 17 | 11 | DC1 | ␑ | ^Q | 设备控制一（XON 激活软件速度控制） 0001 0010 | 18 | 12 | DC2 | ␒ | ^R | 设备控制二 0001 0011 | 19 | 13 | DC3 | ␓ | ^S | 设备控制三（XOFF 停用软件速度控制） 0001 0100 | 20 | 14 | DC4 | ␔ | ^T | 设备控制四 0001 0101 | 21 | 15 | NAK | ␕ | ^U | 确认失败回应 0001 0110 | 22 | 16 | SYN | ␖ | ^V | 同步用暂停 0001 0111 | 23 | 17 | ETB | ␗ | ^W | 区块传输结束 0001 1000 | 24 | 18 | CAN | ␘ | ^X | 取消 0001 1001 | 25 | 19 | EM | ␙ | ^Y | 连接介质中断 0001 1010 | 26 | 1A | SUB | ␚ | ^Z | 替换 0001 1011 | 27 | 1B | ESC | ␛ | ^[ | 退出键 0001 1100 | 28 | 1C | FS | ␜ | ^\\ | 文件分区符 0001 1101 | 29 | 1D | GS | ␝ | ^] | 组群分隔符 0001 1110 | 30 | 1E | RS | ␞ | ^^ | 记录分隔符 0001 1111 | 31 | 1F | US | ␟ | ^_ | 单元分隔符 0111 1111 | 127 | 7F | DEL| ␡ | ^? | 删除 ASCII可显示字符: 进制 | 十进制 | 十六进制 | 图形 | - | - | - 0010 0000 | 32 | 20 | (space) 0010 0001 | 33 | 21 | ! 0010 0010 | 34 | 22 | \" 0010 0011 | 35 | 23 | # 0010 0100 | 36 | 24 | $ 0010 0101 | 37 | 25 | % 0010 0110 | 38 | 26 | \u0026 0010 0111 | 39 | 27 | ' 0010 1000 | 40 | 28 | ( 0010 1001 | 41 | 29 | ) 0010 1010 | 42 | 2A | * 0010 1011 | 43 | 2B | + 0010 1100 | 44 | 2C | , 0010 1101 | 45 | 2D | - 0010 1110 | 46 | 2E | . 0010 1111 | 47 | 2F | / 0011 0000 | 48 | 30 | 0 0011 0001 | 49 | 31 | 1 0011 0010 | 50 | 32 | 2 0011 0011 | 51 | 33 | 3 0011 0100 | 52 | 34 | 4 0011 0101 | 53 | 35 | 5 0011 0110 | 54 | 36 | 6 0011 0111 | 55 | 37 | 7 0011 1000 | 56 | 38 | 8 0011 1001 | 57 | 39 | 9 0011 1010 | 58 | 3A | : 0011 1011 | 59 | 3B | ; 0011 1100 | 60 | 3C | \u003c 0011 1101 | 61 | 3D | = 0011 1110 | 62 | 3E | \u003e 0011 1111 | 63 | 3F | ? 0100 0000 | 64 | 40 | @ 0100 0001 | 65 | 41 | A 0100 0010 | 66 | 42 | B 0100 0011 | 67 | 43 | C 0100 0100 | 68 | 44 | D 0100 0101 | 69 | 45 | E 0100 0110 | 70 | 46 | F 0100 0111 | 71 | 47 | G 0100 1000 | 72 | 48 | H 0100 1001 | 73 | 49 | I 0100 1010 | 74 | 4A | J 0100 1011 | 75 | 4B | K 0100 1100 | 76 | 4C | L 0100 1101 | 77 | 4D | M 0100 1110 | 78 | 4E | N 0100 1111 | 79 | 4F | O 0101 0000 | 80 | 50 | P 0101 0001 | 81 | 51 | Q 0101 0010 | 82 | 52 | R 0101 0011 | 83 | 53 | S 0101 0100 | 84 | 54 | T 0101 0101 | 85 | 55 | U 0101 0110 | 86 | 56 | V 0101 0111 | 87 | 57 | W 0101 1000 | 88 | 58 | X 0101 1001 | 89 | 59 | Y 0101 1010 | 90 | 5A | Z 0101 1011 | 91 | 5B | [ 0101 1100 | 92 | 5C | 0101 1101 | 93 | 5D | ] 0101 1110 | 94 | 5E | ^ 0101 1111 | 95 | 5F | _ 0110 0000 | 96 | 60 | ` 0110 0001 | 97 | 61 | a 0110 0010 | 98 | 62 | b 0110 0011 | 99 | 63 | c 0110 0100 | 100 | 64 | d 0110 0101 | 101 | 65 | e 0110 0110 | 102 | 66 | f 0110 0111 | 103 | 67 | g 0110 1000 | 104 | 68 | h 0110 1001 | 105 | 69 | i 0110 1010 | 106 | 6A | j 0110 1011 | 107 | 6B | k 0110 1100 | 108 | 6C | l 0110 1101 | 109 | 6D | m 0110 1110 | 110 | 6E | n 0110 1111 | 111 | 6F | o 0111 0000 | ","date":"2017-10-24","objectID":"/linuxshell/:17:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"UTF-8 UTF-8（8-bit Unicode Transformation Format）是一种针对Unicode的可变长度字符编码，也是一种前缀码。它可以用来表示Unicode标准中的任何字符，且其编码中的第一个字节仍与ASCII兼容，这使得原来处理ASCII字符的软件无须或只须做少部分修改，即可继续使用。 UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。 UTF-8的编码规则很简单，只有二条: 对于单字节的符号，字节的第一位设为0，后面7位为这个符号的unicode码。因此对于英语字母，UTF-8编码和ASCII码是相同的 对于n字节的符号（n\u003e1），第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的unicode码 \r \rBash ","date":"2017-10-24","objectID":"/linuxshell/:18:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"bash与shell 管理整个计算机硬件的其实是操作系统的内核(kernel)。这个内核是需要被保护的，所以一般用户就只能通过shell来跟内核通信，让内核达到我们想要达到的工作。 ","date":"2017-10-24","objectID":"/linuxshell/:19:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"硬件、内核与shell 我们必须通过shell，将我们输入的命令与内核通信，让内核可以控制硬件正确无误的工作。 操作系统其实是一组软件。由于这组软件在控制整个硬件与管理系统的活动监测，如果这组软件能被用户随意操作，若用户应用不当，将会使得整个系统奔溃。因为操纵系统管理的就是整个硬件功能，所以当然不能够被随便一些没有管理能力的终端用户随意使用。 但我们总是需要让用户操作系统的，所以就有了在操作系统上面发展的应用程序。用户可以通过应用程序来指挥内核，让内核达到我们所需要的硬件任务。 也就是说，只要能够操作应用程序的接口都能够称为shell。 狭义的shell指的是命令行方面的软件，包括bash等。广义的shell则包括图形界面的软件。 \r","date":"2017-10-24","objectID":"/linuxshell/:19:1","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"命令行shell 各Distribution的命令行界面都一样 远程管理非常快速 Linux的任督二脉 \r","date":"2017-10-24","objectID":"/linuxshell/:19:2","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"系统合法shell与/etc/shells 由于shell依据发布者的不同就有许多版本，例如Bourne SHell（sh）、C SHell、K SHell、TCSH等。 Linux默认使用的这一版本就是Bourne Again SHell(bash)，这个shell是Bourne SHell的增强版，也是基于GNU框架下发展出来的。 检查系统可用shell: cat /etc/shells 合法shell要写入/etc/shells，系统某些服务在运行过程中，会去检查用户能够使用的shell。 查看用户shell权限： cat /etc/passwd，最后一行便是默认shell。 ","date":"2017-10-24","objectID":"/linuxshell/:19:3","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"bash shell bash是GNU计划中重要的工具软件之一，目前也是Linux distributions 的标准shell。 bash主要兼容于sh，并且依据一些用户的需求而加强shell 版本。 bash的优点： 命令记忆能力history 命令与文件补全功能tab 命令别名设置功能alias 作业控制、前台、后台控制(job control, foreground, background) 使用前台、后台的控制可以让作业进行得更为顺利。至于作业控制(jobs)的用途更广，可以让我们随时将工作丢到后台中执行，而不怕不小心使用ctrl+c来中断该进程 程序脚本shell script 通配符(Wildcard) ","date":"2017-10-24","objectID":"/linuxshell/:19:4","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"type命令 type命令用于判断一个命令是內建命令还是外部命令(非bash提供)。 type ls type -t ls #file，外部命令 #alias，别名 #builtin，內建命令 ","date":"2017-10-24","objectID":"/linuxshell/:19:5","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"shell变量 变量就是以一组文字或符号等，来替代一些设置或者是一串保留的数据。 ","date":"2017-10-24","objectID":"/linuxshell/:20:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"变量显示与设置 echo: 显示变量 echo $PATH unset: 取消变量 unset $ZHANG ","date":"2017-10-24","objectID":"/linuxshell/:20:1","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"变量设置规则 变量与变量内容以一个等号=连接，如myname=zhang 等号两边不能有空格符，否则错误 变量名称只能是英文字母和数字，开头字符不能是数字 变量内容若有空格，可使用双引号或单引号 双引号内的特殊符号，保有原本的特性 单引号内的特殊字符则仅为一般字符 转义字符\\\\，将特殊符号变成一般字符 在一串命令中，还需要使用其他命令，使用反单引号 反引号``内的命令将被优先执行，而其执行结果将作为外部的输入信息 若该变量为了增加变量内容时，可用**$变量名称 **或**${变量}**累加内容 myname=${myname}xxx 若该变量需要在其他子进程执行，请以export来使变量变成环境变量 通常大写字符为系统默认变量，自行设置变量可以使用小写字符，方便判断 什么是子进程？在我目前这个shell下，去打开另一个新的shell。新的那个shell就是子进程。 在一般状态下，父进程定义的变量是无法在子进程内使用的，要通过export将变量变成环境变量后才可以。 注意单引号、双引号和反引号。 ","date":"2017-10-24","objectID":"/linuxshell/:20:2","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"环境变量 环境变量可以帮我们达到很多功能，包括主文件夹的变换、提示符的显示、执行文件查找的路径等。 env: 显示环境变量 set: 查看所有变量 包括环境变量和自定义变量 #HOME，用户主目录 #SHELL，当前环境使用的shell #HISTSIZE，历史命令 #PATH，执行文件查找路径 #LANG，语系 #$PS1，命令提示符 #PS2，第二行提示符 设置$PS1，$PS2: \\d #可显示出『星期 月 日』的日期格式，如：\"Mon Feb 2\" \\H #完整的主机名 \\h #仅取主机名在第一个小数点之前的名字 \\t #显示时间，24小时格式的『HH:MM:SS』 \\T #显示时间，为12小时格式的『HH:MM:SS』 \\A #显示时间，为24小时格式的『HH:MM』 \\@ #显示时间，为12小时格式的『am/pm』 \\u #目前使用者的账号名称，如『root』 \\v #BASH的版本信息 \\w #完整工作路径名，由根目录写起的目录名称。但家目录会以 ~ 取代 \\W #利用basename函数取得工作目录名称，所以仅会列出最后一个目录名。 \\# #下达的第几个命令 \\$ #提示字符，root时，提示字符为#；否则就是$ $钱字号本身也是变量，代表当前shell的PID –\u003e echo $$ ?问号也是一个特殊变量，代表上一个运行命令的回传值 –\u003e echo $? 0 命令运行成功 errorcode 命令运行错误 ","date":"2017-10-24","objectID":"/linuxshell/:20:3","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"语系变量 locale - get locale-specific information. 设置LANG的时候，其他的语系变量就会被这个变量所替代。 ","date":"2017-10-24","objectID":"/linuxshell/:20:4","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"变量键盘读取、数组与声明 read： 读取来自键盘输入的变量 declare,typeset: 声明变量类型 变量的默认类型为字符串 若不指定变量类型，则1+2就是一个字符串而不是计算式 数组变量类型 var[1]=‘varray1’ var[2]=‘varray2’ echo “${${var[1]}, ${var[2]}}” \r","date":"2017-10-24","objectID":"/linuxshell/:20:5","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"bash shell操作环境 自定义我们登录主机的时候屏幕上面会有一些说明文字，并且登录的时候还可以给用户提供一些信息或者欢迎文字，或环境变量和命令别名等。 ","date":"2017-10-24","objectID":"/linuxshell/:21:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"路径与命令查找顺序 命令的运行顺序： 以绝对/相对路径执行命令 由alias找到该命令来执行 由bash内置的（builtin）命令来执行 通过$PATH这个变量的顺序找到的第一个命令来执行 ","date":"2017-10-24","objectID":"/linuxshell/:21:1","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"bash登录与欢迎消息 /etc/issue –\u003e 终端登录消息 CentOS Linux 7 (core)….. /etc/motd –\u003e 用户登录后取得一些消息 Welcome to aliyun ECS \r","date":"2017-10-24","objectID":"/linuxshell/:21:2","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"bash环境配置文件 操作系统有一些环境配置文件的存在，让bash在启动时直接读取这些配置文件，以规划好bash的操作环境。 这些配置文件又可以分为全体系统的配置文件以及用户个人偏好配置文件。 命令别名、自定义的变量在你注销bash后就会失效。所以你想要保留你的设置，就得要将这些设置写入配置文件才行。 login shell 取得bash需要完整的登录流程 non-login shell 取得bash接口的方法不需要登录 ","date":"2017-10-24","objectID":"/linuxshell/:21:3","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"bash shell快捷键 Ctrl+C –\u003e 终止当前命令 Ctri+D –\u003e 输入结束(EOF) Ctri+M –\u003e Enter Ctrl+S –\u003e 暂停屏幕输出 Ctrl+Q –\u003e 恢复屏幕输出 Ctrl+U –\u003e 在提示字符下，将整列命令删除 Ctrl+Z –\u003e 暂停目前命令 ","date":"2017-10-24","objectID":"/linuxshell/:21:4","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"通配符与特殊符号 通配符： 符号 | 说明 | - | 代表0-∞个 任意字符 ? | 代表一定有一个 任意字符 [-] | 中括号内任一字符 [^] | 非中括号内字符 bash常见特殊符号，理论上文件名不要用到上述字符。 符号 | 说明 | - | 注释 \\ | 转义字符 1 | 管道线 ; | 连续命令分隔符 ~ | 用户主目录 $ | 取变量前导符 \u0026 | 将命令放入后台 ! | 逻辑非 / | 目录符号 , » | 输出定向 \u003c, « | 输入定向 '' | 单引号 \"\" |　双引号 () | 子shell {} | 命令区块混合 \r","date":"2017-10-24","objectID":"/linuxshell/:21:5","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"重定向 数据流重定向就是将某个命令执行后应该要出现在屏幕上的数据传输到其他的地方，如文件或设备。 标准输入(stdin)，代码为0，使用\u003c或者\u003c\u003c 标准输出(stdout)，代码为1，使用\u003e或者\u003e\u003e 标准错误(stderr)，代码为2，使用2\u003e或者2\u003e\u003e \u003e表示以覆盖方式写入，\u003e\u003e表示以追加方式写入 \r","date":"2017-10-24","objectID":"/linuxshell/:22:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"管道 管道命令使用 \" | \" 这个界定符号。 管道命令\" | \" 仅能处理经由前面一个命令传来的正确信息。所以对stderror没有直接处理能力。 在每个管道后面接的第一个数据必定是命令，而且这个命令必须要能够接收standard input的数据才行，这样的命令才可以是管道命令。 \rBash特殊符号 在编写shellscripts的时候，特殊符号也有其重要的功能。 符号 | 描述 | 栗子 | - | - #! | shellban，申明脚本所使用的shell | #!/bin/bash \\ | 转义字符 | \\n l | 管道 | stdout l grep ,» | 输出定向 | \u003e 1.txt \u003c,« | 输入定向 | \u003c 1.txt 2\u003e | 错误定向 | 2\u003e error.txt ; | 连续命令分隔符 | cmd1;cmd2 \u0026\u0026 | 与，只有当前命令完成后才执行后一个命令 | cmd1 \u0026\u0026 cmd2 ll | 或，或此或彼 | cmd1 ll cmd2 ~ | 用户家目录 | cd ~ | 注释符 | #comments $ | 取用变量前导符 | $PATH或${PATH} \u0026 | 工作控制，将命令放入后台(bg) | command\u0026 ? [] [-] [^] | 通配符 | .sh ?.sh [a-z].txt [^zhang].txt ! | 逻辑非 | != = 两边无空格 | 赋值符号 | name=zhang = 两边有空格 | 比较符号 | if [ $name = zhang ] $0 | 执行文件脚本名 | /root/zhang.sh $1, $2 | 第1,2个…变量 | ./zhang.sh start $# | 参数个数 | if [ $# -ne 2 ]；then echo 'Usage: $0 arg1 arg2' $@ | 代表$1,$2,$3…之意 | 每个变量是独立的 $* | 代表$1c$2c$3…之意 | c为分割字符，默认为空格键 $? | 命令状态码，成功为0 | $? $$ | 当前shell的PID | echo $$ ‘单引号’ | 单引号内特殊字符仅为一般字符 | echo '$host'--$host “双引号” | 双引号内特殊符号，可保有原本特性 | echo \"$host\" --localhost `反引号` | 运行命令 | 反引号内命令先执行 () | 以子shell方式执行 | $(date) {} | 命令区块的组合 | PS1 | 命令提示符 | $PS1 PS2 | 第二行以后的提示字符 | $PS2 shift | 移动参数 | shift后面可以接数字，代表拿掉最前面的几个参数 set | 查看所有变量 | set unset | 取消变量 | unset name，没有$符号 export | 使某变量成为环境变量 | export name，没有$符号 source | source命令通常用于重新执行刚修改的初始化文件，使之立即生效，而不必注销并重新登录 | source file \r \rshell脚本 shell脚本有点像早期的批处理程序，即将一些命令汇整起来一次执行.但shell脚本拥有更强大的功能，可以进行类似程序(program)的编写，并且不需要经过编译(compile)就能执行。 \r","date":"2017-10-24","objectID":"/linuxshell/:23:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"介绍 shell脚本是利用shell的功能写的一个程序(program)。这个程序是使用纯文本文件，将一些shell的语法与命令(含外部命令)写在里面，搭配正则表达式、命令管道与数据流重定向等功能，还提供了数组、循环、条件与逻辑判断等重要功能， 以达到我们所想要的处理目的。 shell脚本用在系统管理上面是很好的一项工具，但用在处理大量数值运算上就不够好。因为shell脚本的速度较慢，且使用的cpu资源较多，造成主机资源的分配不良。 使用shell脚本的优势： 自动化管理的重要依据 追踪与管理系统的重要工具 简单入侵检测功能 连续命令单一化 简单的数据处理 跨平台支持与学习历程较短 shell脚本注意事项： 命令的执行是从上到下从左到右，分析与执行 命令的执行中：命令、参数间的多个空白都会被忽略掉 空白行也将被忽略，tab按键所得的空白同样视为空格键 读取到一个Enter符号(CR)，就尝试开始执行该行命令 一行内容太多，则可以使用\\[Enter]来扩展到下一行 任何加在#后面的内容都将被视为注释而被忽略 shell脚本文件的执行方式： 直接命令执行 .sh文件必须具有可读和可执行权限，使用绝对路径或相对路径来执行 以bash进程来执行 bash xx.sh sh xx.sh shell脚本执行方式的区别： 直接执行，脚本是在子进程的bash中执行的。当子进程完成后，子进程内的各项变量或操作将会结束而不会传回到父进程中。 source来执行，在父进程中执行 \r","date":"2017-10-24","objectID":"/linuxshell/:24:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"编写一个shell脚本 编写一个良好的shell脚本的技巧： 脚本的功能 脚本的版本信息 脚本的作者 脚本的版权声明方式 脚本的历史记录 脚本内较特殊的命令，使用绝对路径的方式来执行 脚本执行时需要的环境变量预先声明与设置 在较为特殊的程序代码部分，建议务必要加上批注说明 脚本的退出状态码 对于一些字符串变量，使用括号引起来 set -e会让脚本出错就停止运行 set -eu会让脚本中有变量没有定义而退出 可以给变量定义默认值，如${FOO:-'default'} 为脚本设置-h或--help来显示帮助信息，千万别把这两个参数作为功能 使用$()而非反引号来获得命令行的输出，主要是易读 一定要小心使用rm -rf这样的命令。比如rm -rf $MYDIDR/*，如果$MYDIR为空，结果是灾难性的 考虑使用find/while而不是for/find 防御式编程，在正式执行命令前，把相关的东西都检查好 学会使用grep/awk/sed这些命令 检查命令是否存在，不建议用which，因为它没有设置状态码。建议使用hash/type。 \r","date":"2017-10-24","objectID":"/linuxshell/:25:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"shell脚本判断式 当我要检测系统上某些文件或相关属性时，使用test命令。 test -e /root/test.txt \u0026\u0026 echo 'Exist' || 'Not exist' \r文件类型判断： 选项 说明 -e 是否存在 -f 是否存在文件 -d 是否存在目录 -b 是否存在block device -c 是否存在character device -S 是否存在Socket文件 -p 是否存在pipe文件 -L 是否存在链接文件 \r文件权限判断： 选项 说明 -r 是否可读 -w 是否可写 -x 是否可执行 -u 是否具有SUID -g 是够具有SGID -k 是否具有Sticky bit -s 是否为非空白文件 \r文件之间的比较： 选项 说明 -nt newer than -ot old than -ef 是否为同一个文件 整数之间的比较： 选项 说明 -eq equal -ne not equal -gt greater than -lt less than -ge greater or equal -le less or equal \r字符串之间的比较： 选项 说明 -z 是否为空 -n 非空 str1 = str2 是否相等 != 不等于 多重条件判断： 选项 说明 -a and -o or ! 非 \r判断符号[]: 如果需要在bash中使用中括号来作为shell的判断式时，必须要注意中括号的两端需要有空格符来分隔。 中括号内的变量，每个最好都用双引号括起来 中括号内的常量，最好都以单或双引号括起来 \r","date":"2017-10-24","objectID":"/linuxshell/:26:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"shell脚本的默认变量 # 示例 /root/test.sh opt1 opt2 opt3 $0 $1 $2 $3 执行文件的脚本名就是$0 文件后接的第一个参数就是$1，以此类推 $#，表示参数个数 $@，表示\"$1\", “$2”… shift，参数变量号码偏移 shift n，代表拿掉前面几个参数的意思 \r","date":"2017-10-24","objectID":"/linuxshell/:27:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"条件判断语句 ","date":"2017-10-24","objectID":"/linuxshell/:28:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"if…then语句 if…then 是最常见的条件判断式。 单层条件判断： if [ confition ]; then xxx fi 多层条件判断： if [ condition ]; then xxx; else xxx; fi if [ confition1 ]; then xxx; elif [ condition2 ]; then xxx; else xxx; fi ","date":"2017-10-24","objectID":"/linuxshell/:28:1","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"case…esac语句 有多个既定变量内容，那么只需要针对这几个变量来设置状况就好。 case $变量名 in \"$var1\") xxx ;; \"$var2\") xxx ;; *) xxx ;; esac ####栗子 #/etc/init.d/network case \"$1\" in start) xxx ;; stop) xxx ;; restart) xxx ;; status) xxx ;; esac ","date":"2017-10-24","objectID":"/linuxshell/:28:2","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"function功能 什么是函数？函数可以在shell脚本当中做出一个类似自定义执行命令的东西。最大的动能是，可以简化很多的程序代码。 因为shell脚本的执行方式是由上而下、由左而右。因此在shell脚本当中，function的定义一定要在程序的最前面，这样才能够在执行时被找到可用的程序段。 vim func.sh function fname () { } ####栗子 function Zhang() { echo $1 $2 } Zhang \"$1\" \"$2\" #执行 sh func.sh aaa bbb ","date":"2017-10-24","objectID":"/linuxshell/:28:3","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"循环语句 ","date":"2017-10-24","objectID":"/linuxshell/:29:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"while do done(不定循环) while是当condition条件成立时，就进行循环，condition条件不成立就停止。 while [ condition1 ] do xxx done \r","date":"2017-10-24","objectID":"/linuxshell/:29:1","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"until do done(不定循环) until是当condition条件成立时，终止循环；否则就持续进行循环的循环。 until [ condition ] do xxx done \r","date":"2017-10-24","objectID":"/linuxshell/:29:2","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"for do done(固定循环) for i in con1 con2 con3 ... do xxx done ####栗子 for i in 192.168.1.{1,2,3} do ping -c 1 $i done \rfor do done的数值处理： for ((初始值;限制值；步长)) do xxx done ####栗子 for ((i=0;i\u003c10;i++)) do echo $i done \r","date":"2017-10-24","objectID":"/linuxshell/:29:3","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"shell脚本的追踪与调试 最好在shell脚本执行之前先行调试。 sh [-nvx] xxx.sh #-v 运行脚本前，先将脚本内容输入到屏幕 #-n 仅查询语法问题 #-x 边显示边执行 当然也可以把这几个调试参数写到shellbang中 #!/bin/bash -x \r\r 小试牛刀 ","date":"2017-10-24","objectID":"/linuxshell/:30:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"简介 #bash(Bourne Again Shell)，shell环境使得用户能与操作系统的内核进行交互操作 #!/bin/bash #date #description cmd1; cmd2 cmd3 #sh /path/xx.sh #Bash还有一个历史记录文件 ~/.bash_history \r","date":"2017-10-24","objectID":"/linuxshell/:31:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"终端打印(echo) #终端作为交互式工具，用户可以通过它与shell环境进行交互 echo '$var' echo $var echo -e \"1\\t2\\t3\" echo -e '\\e[1;31m Red color \\e[0m' #彩色 echo {1..10} #输出1到10 echo {A..H} #for i in {a..z} cat \u003c\u003c EOF 11 22 33 EOF # \\转义字符 printf \"%-5s %-10s $-4.2f\\n\" 001 Zhang 56.789 #格式替代符%s %d %c %f, -左对齐 ","date":"2017-10-24","objectID":"/linuxshell/:32:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"玩转变量和环境变量 #Bash中，每一个变量默认值值都是字符串形式 #环境变量和自定义变量 echo $SHELL echo $UID var=value #这是赋值 #var = value这是相等操作 echo $var echo ${var} echo ${#var} #字符数 #export用来设置环境变量，此后，任何shell中的程序都会继承环境变量 ZHANG=Gentleman export ZHANG PATH=\"$PATH:/home/zhang/bin\" export $PATH \r","date":"2017-10-24","objectID":"/linuxshell/:33:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"通过shell进行数学运算 #let, expr, bc, [], (()) #要注意默认是字符串类型哦 n1=1;n2=2 let sum=n1+n2 let n1++;let n2-=1 sum=$[ n1 + n2 ] sum2=$(( sum + 3 )) sum=`expr 3 + 4` #浮点计算 bc echo \"8 * 1.1\" | bc #设置小数点精度 echo \"scale=2; 3/8\" | bc #进制转换 num=100 echo \"obase=2; $num\" | bc num=1100100 echo \"obase=10; ibase=2; $num\" | bc #平方和平方根 echo \"sqrt(100)\" | bc echo \"10^2\" | bc ","date":"2017-10-24","objectID":"/linuxshell/:34:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"文件描述符重定向 #最常用的文件描述符是 stdin(0), stdout(1), stderr(2); 通过内容过滤将输出重定向到文件 echo \"This is a sample text 1\" \u003e temp.txt #覆盖 echo \"This is sample text 2\" \u003e\u003e temp.txt #追加 ls + \u003estdout.txt 2\u003estderr.txt cmd 2\u003e\u00261 /dev/null == com \u0026\u003e /dev/null #null设备也被称为黑洞 #当一个command发生错误并退回时，它会返回一个非0的状态码 echo $? #tee命令，一方面可将数据重定向到文件，另一方面还可提供一份重定向数据的副本作为后续命令的stdin #tee默认覆盖文件，-a选项追加 cat temp.txt | tee tee.txt | cat -n \r","date":"2017-10-24","objectID":"/linuxshell/:35:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"数组和关联数组 #数组借助索引将多个独立的数据存储为一个集合 #普通数组只能使用整数作为数组索引，而关联数组可以使用字符串作为数组索引 #还可将数组定义成一组索引-值(index-value) arr=(1 two 3 four 5) echo ${arr[0]} arr[0]=One index=3 echo ${arr[$index] #arr[3] echo ${arr[*]}echo ${#arr[*]}#arr-length #关联数组可用任意文本作为数组索引 declare -A ass_arr ass_arr=([index1]=val1 [index2]=val2 ...) #内嵌索引-值 ass_arr[index3]=val3 #独立索引-值 echo ${!ass_arr[*]}#列出数组索引 ","date":"2017-10-24","objectID":"/linuxshell/:36:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"别名(alias) #alias作用是暂时的，关闭终端后别名就失效； #为使别名一直保持，可将其写入 ~/.bashrc，因为每一个新的shell都会执行~/.bashrc中的命令 #新设置的别名将取代已有别名 alias vi=vim; unalias vi echo \"alias ll='ls -l --color=auto'\" \u003e\u003e ~/.bashrc #\\对别名命令进行转义，执行原本的命令。避免攻击者利用别名将某些特权命令替换成别有用心的命令 \\vi test.sh \r","date":"2017-10-24","objectID":"/linuxshell/:37:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"获取、设置日期和延时(date) #很多应用程序需要以不同的格式打印日期，设置日期和时间，以及根据日期和时间执行操作; #延时通常用于在程序执行过程中提供一段等待时间; #在Unix-like系统中，日期被存储为一个整数，其大小为世界标准时间1970年1月1日0时0分0秒起所流逝的秒数； #这种计时方式被称之为 纪元时或Unix时间； #通过纪元时间，可知道两个日期之间相隔了多少秒 #编写以循环方式运行的监视脚本时，设置时间间隔是必不可少的 date +%s #!/bin/bash start=$(date +%s) commands sleep 1 end=$(date +%s) diff=$((end - start)) echo \"$diffseconds\" #显示指定时间 date +%F -d -1days date +%H -d -3hours #将标准时间转换为原子时间 date -d '2018-02-07 14:05:53' +%s 1517983553 #将原子时间转换为标准时间 date --date='@1517983553' Wed Feb 7 14:05:53 CST 2018 ","date":"2017-10-24","objectID":"/linuxshell/:38:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"调试脚本(sh) #调试功能能在出现一些异常情况时生成运行信息 #!/bin/bash -xv sh -x sh -n \r","date":"2017-10-24","objectID":"/linuxshell/:39:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"函数和参数(function) function fname() { statements } fname() { echo $1, $2 #访问第参数1和参数2,$n第n个参数 echo \"$@\" #以列表的形式一次性打印所有参数 echo \"$*\" #类似于$@，但参数被作为单个实体 return 0 #f返回值 } fname 1 22 333 #返回上面定义的变量 #递归函数，能够调用自身，不断地生成新的进程，最终会造成xx #导出函数，使用export导出，这样函数作用域就可以扩展到子进程 export -f fname #读取命令返回值 echo $? ","date":"2017-10-24","objectID":"/linuxshell/:40:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"读取命令序列输出(` `, $() ) #输入通常是stdin，输出stderr或stdout,这些命令称为 过滤器(filter)。我们使用 管道(pipe) 来连接每一个过滤器 cmd1 | cmd2 | cmd3 #子shell，子shell生成独立的进程，不会对当前shell有任何影响，所做改变仅限于子shell内 zhang=$(ls | cat -n) #反引用 zhang=`ls | cat -n` \r","date":"2017-10-24","objectID":"/linuxshell/:41:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"读取字符(read) #read是一个重要的从标准输入中读取文本的命令 #可以使用read以交互的形式来读取用户的输入 read -n 5 zhang #读取字符数 echo $zhang read -s passwd #不回显 echo $passwd read -t 5 zhang #超时时间 echo $zhang read -p zhang #显示提示信息 echo $zhang read -d \":\" zhang #定界符结束输入 123： echo $zhang ","date":"2017-10-24","objectID":"/linuxshell/:42:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"字段分隔符和迭代器 #内部字段分隔符(Internal Field Separator, IFS)是shell中的一个重要概念 #IFS的默认值为空白字符(换行符、制表符、空格) awk -F: '{print $1,$3}' /etc/passwd #IFS=\":\" #对一些列值进行迭代，循环非常有用 for i in {1..10} do cmd done while condition do cmd done until condition do cmd done \r","date":"2017-10-24","objectID":"/linuxshell/:43:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"比较与测试 #程序中的流程控制是由比较和测试语句来处理的 if condition1 || condition2 then cmd1 elif condition3 \u0026\u0026 condition4 then cmd2 else cmd3 fi #算术比较 if [ $num -ge 10 -a $num -lt 20 ] -eq -gt -ge -lt -le -a -o #文件系统相关 if [ -f $file1 -o -x $file2] -x -w -r -f -d -e -b #block -l #字符串比较 [[ $str1 = $str2]] = #=号旁有空格--是比较关系；=号旁没空格，是赋值语句 != \u003e \u003c -z #空字符 -n #非空字符 #使用test命令来执行条件检测 if [ $num -eq 0 ] -- if test $num -eq 0 \r命令之乐 ","date":"2017-10-24","objectID":"/linuxshell/:44:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"简介 各种命令可谓Unix-Like系统中优美的部分，它能帮我们搞定各种繁杂的任务。 一旦你尝试过Linux提供的这些利器，你一定会感到惊讶：以前没有这些命令的时候，自己是什么熬过来的。 最钟爱的莫过于 grep, awk, sed, find 命令了！ 本章将会为你介绍一些最有趣同时也是最实用的命令。 ","date":"2017-10-24","objectID":"/linuxshell/:45:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"用cat进行拼接 #cat命令通常用于读取、显示或拼接文件内容，不过它所具备的能力远不止此 #cat(concatenate, 拼接) cat file1 file2 ··· echo \"Ahaha\" | cat - file1 file2 #-指stdin文本文件名 cat -s file3 -- cat file3 | tr -s '\\n' #压缩空白行 cat -T test.py #将制表符显示为 ^I, 避免制表符和连续空格误用, 产生错误缩进 cat -n file4 #显示行号 \r","date":"2017-10-24","objectID":"/linuxshell/:46:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"录制与回放终端会话(script) 当你需要准备一个命令行教程时，如果将我们输入命令后的一切按照先后次序记录下来，再进行回放，是不是很nice！ 通过 script, scriptreplay 命令, 把终端会话记录到文件，并回放。 #-t,将时间数据输出到标准错误； -a,追加输出 script -t 2\u003e timing.log -a output.session #两个文件随意取名, 如不将错误重定向会显示在屏幕上导致很乱 输入命令 cmd2 ··· exit #退出录制 scriptreplay -t timing.log output.session #播放 ","date":"2017-10-24","objectID":"/linuxshell/:47:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"文件查找与文件列表(find) find 是Unix/Linux命令行工具箱中最棒的工具之一。 find 命令沿着文件层次结构向下遍历，匹配符合条件的文件，并执行相应的操作。 find - search for files in a directory hierarchy #基于文件名及正则表达式搜索 find /home/zhang #列出/home/zhang目录及其子目录线所有文件和文件夹 find /home/zhang -name \"*.txt\" find . -name \"*.sh\" -o -iname \"zhang*\" #匹配多个 find /home/zhang -path \"201710*\" #-path将文件路径作为一个整体进行匹配 find . -regex \".*\\(\\.txt|\\.[0-9]+\\)$\" #匹配以.txt或数字结尾的文件 #使用-maxdepth, -mindepth参数，来限制find的遍历深度 #-type, 根据文件类型搜索。 f(普通文件)，d(目录)，b(块设备)，l(符号链接)，s(套接字)等 find /home -maxdepth 1 -type f(d) #参数顺序也会影响find的查找效率 #根据文件类型搜索 find /dev -type b #查看/dev及其子目录下设备文件 find / -maxdepth 1 -type l #查找/下链接文件 #根据文件时间进行搜索 #Unix/Linux文件系统中的每一个文件都有三种时间戳(timestamp),-表示小于，+表示大于 #Unix中并没有所谓的 \"创建时间\" 的概念 #访问时间(-atime,以天为单位； -amin,以分钟为单位):用户最近一次访问文件时间； #修改时间(-mtime,以天为单位； -mmin,以分钟为单位):文件最后一次修改时间； #变化时间(-ctime,以天为单位； -cmin,以分钟为单位):文件元数据(如权限，所有权)最后一次变化时间； find /home/zhang -type f -mtime 7 #7天前被修改的普通文件 find /home/zhang -type f -amin -10 #搜索10分钟内被修改的普通文件 find . -type f -newer file1.txt #找出比file1.txt新的文件 #基于文件大小的搜索 #b(块，512字节), c(字节), w(字，2字节), k(千字节), M(兆字节), G(吉字节) find . -type -f -size +100k #删除匹配的文件 find . -type f -name \"*.swp\" -delete #基于文件权限和所有权的匹配 find . -type f -perm 644 find /var/apache -type f -name \"*.php\" -perm 644 #搜索基于权限的文件 find /var -maxdepth 2 -type f -user zhang #搜索基于用户的文件 #执行命令或动作 #find命令可以借助-exec与其他命令进行结合 #{}是一个特殊字符串，将替换为相应文件名 find . -type f -perm 764 -user zhang -exec chmod 644 {} \\; #将所属用户zhang，权限764的文件权限修改为644 find . -type f -mmin +30 -name \"*.txt\" -exec cp {} {}.old \\; #复制最近30内修改的名字为.txt的文件 #-exec结合多个命令 #我们无法在-exec参数中直接使用多个命令，不过我们可以把多个命令写到一个shellscript中，然后执行 -exec ./test.sh {} \\; find . -type f -name \"*.sh\" -mmin -10 -exec sh {} \\; #让find跳过特定目录 -prune #利用find搭配tar打包 #查找7天内的文件并打包 #建议使用绝对路径，管道无效，所有要定向到文件 find /dir/path/zhang -type -f -mmtime -7 \u003e /dir/path/zhang/zhang.list \u0026\u0026 tar -T /dir/path/zhang/zhang.list -czvf /dir/path/zhang123.tar.gz #检查是否正确 tar -tf /dir/path/zhang123.tar.gz #不能使用find -exec tar，这样打包以后只有最后一个文件 ","date":"2017-10-24","objectID":"/linuxshell/:48:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"利用stat命令查看atime, mtime, ctime stat - display file or file system status stat 1.txt #Access: #Modify: #Change: ","date":"2017-10-24","objectID":"/linuxshell/:48:1","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"利用touch命令修改atime, mtime, ctime touch - change file timestamps #-a change only the access time #-m change only the modification time #-d instead of current time #-t instead of current time ","date":"2017-10-24","objectID":"/linuxshell/:48:2","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"玩转xargs xargs - build and execute command lines from standard input #xargs能够处理stdin并将其转换为特定命令的命令行参数 #也可以将单行或多行输入文本转换成其他格式(如多行变单行) cmd | xargs #将多行输入转换为单行输出 echo -e \"1\\n2\\n3\" | xargs #将换行符替换为空格 #将单行输入转换成多行输出 echo \"1 2 3\" | xargs -n 1 #每行一个参数 echo \"hahaZhahaZhahaZhaha\" | xargs -n 2 -d Z #-d指定分隔符 #读取stdin，将格式化参数传递给命令 cat test.txt | xargs -n 1 ./zhang.sh #zhang.sh arg1; zhang.sh arg2... 每次提供一个参数 cat test.txt | xargs -n X ./zhang.sh #X为参数个数，一次提供全部参数 #指定替换字符串 cat test.txt | xargs -I {} ./zhang.sh {} #结合find使用xargs find . -type f -name \"*.txt\" -print0 | xargs -0 ls #-print0无换行输出, -0将\\0作为输入界定符 #统计某文件行数 find /path -type f -name \"*.c\" -print0 | xargs -0 wc -l #结合stdin，运用while和子shell cat file.txt | while read arg; do cat $arg; done == cat file.txt | xargs - {} cat {} cmd0 | (cmd1; cmd2; cmd3) | cmd4 #子shell \r","date":"2017-10-24","objectID":"/linuxshell/:49:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"用tr进行转换 tr - translate or delete characters #tr命令经常用来编写优美的单行命令 #tr可对来自stdin的字符 进行替换、删除以及压缩 echo \"AH WONDERFUL\" | tr 'A-Z' 'a-z' #转换大小写 echo \"AH WONDERFUL\" | tr 'A-Z' 'a-b' --\u003e ab bbbbbbbbb #tr [option] set1 set2 #如果两个字符集长度不相等，那么set2会不断重复其最后一个字符，直到长度与set1相同 echo 12345 | tr '0-9' '9876543210' #数字加密 echo 87654 | tr '9876543210' '0-9' #数字解密 echo 'He is a cool boy, and she is a beautiful girl' | tr 'A-Za-z' 'NOPQRSRUVWXYZABCDEFGHIJKLMnopqrstuvwxyzabcdefghijklm' #加密 echo 'Ur vf n pbby obl, naq fur' | tr 'NOPQRSRUVWXYZABCDEFGHIJKLMnopqrstuvwxyzabcdefghijklm' 'A-Za-z' #解密 cat 1.txt | tr '\\t' ' ' #将制表符转换为空格 #删除字符 echo \"Hello 530 World\" | tr -d '0-9' #-d删除，删除数字 Hello World echo \"Hello 520 World\" | tr -d -c '0-9' #-c补集 520 #压缩字符，将连续的重复字符压缩为单个字符 echo \"GNU's not Unix\" | tr -s ' ' #-s压缩，压缩空格 GNU's not Unix echo -e \"1\\n2\\n3\\n4\\n5\" \u003e sum.txt cat sum.txt | echo $[ $(tr '\\n' '+') 0 ] -- echo $[1+2+3+4+5+0] #tr字符类 \\a 终端鸣响 \\b 退格 \\f 换页 \\n 换行 \\r 回车 \\t 水平制表符 \\v 垂直制表符 string1-stringN #从字符1到字符N升序过程中的所有字符 [字符*次数] [:alnum:] #所有字母和数字 [:alpha:] #所有字母 [:digit:] #所有数字 [:lower:] #所有小写字母 [:upper:] #所有大写字母 [:graph:] #所有可打印字符，不含空格 [:print:] #所有可打印字符，包含空格 [:blank:] #所有水平排列的空白字符 [:cntrl:] #所有控制字符 [:punct:] #所有标点字符 [:space:] #所有空白字符 [:xdigit:] #所有十六进制数 [=字符] #指定字符 \r","date":"2017-10-24","objectID":"/linuxshell/:50:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"校验和 与 核实文件完整性(md5sum) #校验和(checksum)程序从文件中生成校验和密钥，然后利用校验和密钥核实文件的完整性 #校验和对于编写备份脚本或系统维护脚本非常重要，因为它们都会涉及通过网络传输文件 #通过使用校验和核实，我们就可以识别那些在网络传输过程中出现损坏的文件，并重传，从而确保数据完整性 #校验和对于核实数据完整性非常有用 #广泛使用的校验和技术有：md5sum, sha1sum #对单个文件进行校验 md5sum sum.txt \u003e sum.md5 #302c28003d487124d97c242de94da856 sum.txt md5sum -c sum.md5 #-c检查 #sum.txt: 确定 #对目录进行校验 #对目录计算校验和意味着我们需要对目录中的所有文件以递归的方式进行计算 yum install -y md5deep md5deep -r ./dir \u003e dir.md5 #recursive递归 md5sum -c dir.md5 #可以将测试dir下某个文件更改一下，校验的时候会报错 ## 排序、单一、重复(`sort`,`uniq`)\r #sort - 对文本文件进行行排序 #uniq - 删除排序文件中的重复行 echo -e \"333\\n1\" \u003e 1.txt; echo -e \"22\\n22\" \u003e 2.txt sort 1.txt 2.txt -o ./sorted.txt #1 #22 #22 #333 cat sortec.txt | uniq #1 #22 #333 sort -n #按数字进行排序 sort -r #逆向排序 sort -M #按月份排序 sort -C #检查是否排序 sort -b #忽略空白 #依据键或列进行排序 sort -k 2 data.txt #依据第二列来排序 #uniq要么使用管道，要么使用排过序的文件作文输入 uniq -u sorted.txt #只显示唯一的行(即没有重复出现的行) uniq -d sorted.txt #只显示重复的行 uniq -s 2 -w 2 sorted.txt #-s忽略前2个字符，-w指定用于比较的最大字符数 \r","date":"2017-10-24","objectID":"/linuxshell/:51:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"临时文件命名、随机数 #在编写shell脚本时，我们经常需要存储临时文件。最适合存储临时数据的位置是 /tmp #/tmp目录中的内容会在系统重启后被清空 filename=$RANDOM #RANDOM返回一个随机数 filename2=$$ #当前shell的PID filename3=$((date +%F)) #通过日期命令 ","date":"2017-10-24","objectID":"/linuxshell/:52:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"split命令分割文件 使用split命令来分割一个大文件。 #某些情况下，需要把文件分割成多个更小的片段 dd if=/dev/zero bs=100k count=1 of=./data.file #生成一个大小100k内容全是0的文件 split -b 20k data.file #-d指定分割大小 #data.file xaa xab xac xad xae,这五个文件都为20k #我测试了一下，几个文件加起来数据没变，几个文件总行数没变 #单位有 k, m, G, c(byte), w(word) #-d以数字为后缀， -a指定后缀长度 split data.file -b 20k -d -a 2 spt #增加前缀名'spt' #data.file spt00 spt01 spt02 spt03 spt04 split -l 10 data.file #-l按行数来分割文件 #split只能根据大小或行数分割文件 #csplit可以根据文件本身特点进行分割 -f #指定分割后文件前缀 -n #指定分割后文件后缀数字个数 -b #指定后缀格式 ","date":"2017-10-24","objectID":"/linuxshell/:53:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"根据扩展名切分文件名 #借助%操作符将名称从 “名称.扩展名” 格式中提取出来 file=\"zhang.txt\" name1=${file%.*} #删除位于%右侧的通配符(.*)所匹配的字符串，通配符从右向左进行匹配 #zhang #*号通配符，.号 #%属于非贪婪匹配(non-greedy),它会匹配通配符最短结果 #%%属于贪婪匹配(greedy)，它会匹配符号条件的最长字符串 name2=${file#*.} #删除位于#右侧的通配符(*.)所匹配的字符串，通配符从左向右进行匹配 #txt # #属于非贪婪匹配 # ##属于贪婪匹配 #栗子 URL=“www.google.com” echo ${URL%.*} #非贪婪匹配，移除最右边.及其后面内容 www.google echo ${URL%%.*} #贪婪匹配 www echo ${URL#*.} #非贪婪匹配，移除最左边.及其前面内容 google.com echo ${URL##*.} #贪婪匹配 com \r","date":"2017-10-24","objectID":"/linuxshell/:54:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"批量重命名和移动 综合运用find、rename、mv命令。 ","date":"2017-10-24","objectID":"/linuxshell/:55:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"拼写检查与词典操作 #Linux大多数发行版都含有一份词典文件，另外还有一个被称为aspell的拼写检查命令 #words --\u003e /usr/share/dict/linux.words grep \"^good\" /usr/share/dict/linux.words aspell \r","date":"2017-10-24","objectID":"/linuxshell/:56:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"交互输入自动化 #写一个读取交互式输入脚本 vi jiaohu.sh #!/bin/bash read -p \"Input a number:\" num read -p \"Input name:\" name echo \"You have enterd number:$num, name:$name\" echo -e \"1\\nzhang\" | ./jiaohu.sh You have entered number:1, name:hello #or echo -e \"1\\nzhang\" \u003e input.txt ./jiaohu.sh \u003c input.txt #交互式输入自动化 #用expect实现自动化 yum install -y expect vim auto_expect.sh #!/bin/expect spawn ./jiaohu.sh #spawn指定需要自动化哪一个命令 expect \"Input a number:\" #expect提供需要等待的消息 send \"1\\n\" #send是要发送的消息 expect \"Input name:\" send \"zhang\" expect eof #expect eof指明命令交互结束 ./auto_expect.sh \r以文件之名 ","date":"2017-10-24","objectID":"/linuxshell/:57:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"简介 Unix将操作系统中的一切都视为文件。 ","date":"2017-10-24","objectID":"/linuxshell/:58:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"生成任意大小的文件(dd) 由于各种原因，可能需要生成一个包含随机数据的文件。 #dd命令会克隆给定的输入内容，然后将一模一样的副本写到输出 #如果不指定if，dd会从stdin中读取输入；如果不指定of，dd会输出到stdout #/dev/zero是一个字符设备，它会不断返回0值字节(\\0) dd if=/dev/zero of=junk.data bs=1M count=1 ","date":"2017-10-24","objectID":"/linuxshell/:59:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"文本文件的交集与差集 #comm命令用于两个文件之间的比较 #交集(intersection),差集(set difference), 求差 #comm必须使用排过序的文件作为输入 echo -e \"1\\n2\\n3\" \u003e A.txt \u0026\u0026 echo -e \"3\\n2\\n3\" \u003e B.txt sort -n A.txt -o A.txt \u0026\u0026 sort -n B.txt -o B.txt comm A.txt B.txt #输出第一列为A独有，第二列为B独有，第三列为交集 comm A.txt B.txt -1 -2 #-1从输出中删除第一列，-2删除第二列，-3删除第三列 \r","date":"2017-10-24","objectID":"/linuxshell/:60:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"查找并删除重复文件 #重复文件指的是那些虽然名字不同但内容却一模一样的文件 ls -lS #以文件大小排序，识别大小相等的文件 md5sum #接下来计算这些文件的校验和 \r","date":"2017-10-24","objectID":"/linuxshell/:61:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"创建长路径目录 mkdir -p /home/zhang/1/22/333 2\u003e/dev/null ","date":"2017-10-24","objectID":"/linuxshell/:62:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"文件权限、所有权和粘滞位 #用户(user)，用户组(group)，其他用户(other) ll ./* #d目录，c字符设备，b块设备，l符号链接，s套接字，p管道，-普通文件 #用户还有一个称为setuid(S)的特殊权限，它出现在用户的x位置 #setuid权限允许用户以其拥有者的权限来执行可执行文件，即便这个文件是由其他用户运行的 -rwSrw-r-- #组也拥有一个setgid(S)权限，它出现在组的x位置 #它允许以同该目录拥有者所在组相同的有效组权限来运行可执行文件 -rwxrwSr-- #目录有一个特殊权限，叫做粘滞位(sticky bit)(T或t)，出现在其他用户的x位置 #当一个目录设置了粘滞位，只有创建该目录的用户才能删除目录中的文件,即便group和other有w权限 -rwxr--rwT chmod u=rwx g=rw o=r file1 chmod u+x g-w file2 chmod 744 file3 chmod a+x . -R #以递归方式设置权限 chown user.group . -R #以递归方式设置所有权 chmod a+t dir1 #设置粘滞位 chmod +s fiel4 chown root.root file4 chmod +s file4 ./file4 #每次file4都是以root运行 #setuid的使用不是无限制的，它只能应用在Linux ELF格式二进制，而不能用于脚本文件。 \r","date":"2017-10-24","objectID":"/linuxshell/:63:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"创建不可修改文件 #不可修改(immutable),是保护文件不被修改的安全手段之一。 #一旦文件被设置为不可修改，任何用户(包括root)都不能修改，除非将其不可修改属性移除 chattr #修改文件在Linux第二扩展文件系统(E2fs)上的特有属性 chattr +i file1 #这样就无法删除file1 chattr -i file1 ","date":"2017-10-24","objectID":"/linuxshell/:64:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"批量生成空白文件 #touch命令可用来生成空白文件，如果文件存在，则可以用它修改文件的时间戳 for name in {1..100}.txt;do touch $name done touch -a/-m #更改文件访问/修改时间 touch -d \"Thu Oct 31 14:20:13 CST 2017\" file1 #指定特定时间戳 \r","date":"2017-10-24","objectID":"/linuxshell/:65:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"查找符号链接及其指向目标 #符号链接(软链接)只不过是指向其他文件的指针 ln -s /usr/bin /bin ls -l / | grep \"^l\" find / -maxdepth 1 -type l readlink /bin #找出链接目标 ","date":"2017-10-24","objectID":"/linuxshell/:66:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"列举文件类型统计信息 #在Unix/Linux系统中，文件类型并不是由文件扩展名决定的 file /etc/passwd file -b /etc/passwd \r","date":"2017-10-24","objectID":"/linuxshell/:67:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"环回文件与挂载(mount) #环回文件系统是指那些在文件中而非物理设备中创建的文件系统 dd if=/dev/zero of=loopback.file bs=1G count=1 mkfs.ext4 loopback.file mount -o loop loopback.file /mnt/loopback #-o loop来挂载环回文件 df -h umount /mnt/loopback #将ISO文件作为环回文件挂载 mount -o loop linux.iso /mnt/iso \r","date":"2017-10-24","objectID":"/linuxshell/:68:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"生成ISO文件以及混合ISO #可引导光盘自身具备引导能力，也可以运行操作系统或其他软件。不可引导光盘则做不到这些。 cat /dev/cdrom \u003e /dev/sdc #sdc指U盘 dd if=/dev/cdrom of=/dev/sdc #将ISO写入usb存储设备 mkisofs -V \"Label\" -o /dev/sdc /dev/cdrom cdrecord -v dev=/dev/cdrom image.iso ","date":"2017-10-24","objectID":"/linuxshell/:69:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"查找文件差异并进行修补 diff - compare files line by line #补丁文件(patch file) #diff命令可以生成差异文件 diff -u file1 file2 #一体化形式输出 diff -u file1 file2 \u003e diff.patch patch -p1 file1 \u003c diff.patch #得到file2 patch -p1 file2 \u003c diff.patch #得到file1 patch -R file1 \u003c diff.patch; patch -R file2 \u003c diff.patch #还原 #diff也能够以递归的形式作用于目录，它对目录中所有内容生成差异输出 diff -Naur dir1 dir2 #-N将所有确实文件视为空文件， -a将所有文件视为文本文件 #-u生成一体化输出， -r遍历目录下所有文件 栗子： echo -e '1\\n1\\n1\\n1' \u003e /tmp/1.txt echo -e '1\\n1\\n0\\n1' \u003e /tmp/2.txt #比较 diff -u 1.txt 2.txt --- 1.txt 2018-12-14 16:08:36.457495835 +0800 +++ 2.txt 2018-12-14 16:08:37.574495820 +0800 @@ -1,4 +1,4 @@ 1 1 -1 +0 1 #解释 --- 1.txt 2018-12-14 16:08:36.457495835 +0800 +++ 2.txt 2018-12-14 16:08:37.574495820 +0800 #第一部分，是文件的基本信息 #---表示变动前的文件 #+++表示变动后的文件 @@ -1,4 +1,4 @@ #第二部分，变动的位置用两个@作为起首和结束。 #-号表示第一个文件(1.txt), 1表示第一行，4表示连续四行。也就是第一个文件从第一行开始连续四行 #+号表示第二个文件(2.txt), 1表示第一行，4表示连续四行。 1 1 -1 +0 1 #第三部分表示变动的具体内容 #除了有变动的那些行以外，也是上下文各显示3行。它将两个文件的上下文合并显示在一起，所以称为合并显示 #每一行最前面的标志位，空表示无变动，减号表示第一个文件删除的行，加号表示第二个文件新增的行 ","date":"2017-10-24","objectID":"/linuxshell/:70:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"head与tail head file1; tail file1 #head与tail默认打印10行 head -n 5 file1; tail -n 6 file1 #指定行数 head -n -5 file1 #打印除了最后5行外所有行 tail -n +(5+1) file1 #打印除了开始5行外所有行 tail -f /var/log/nginx/access.log #--follow，动态关注文件 \r","date":"2017-10-24","objectID":"/linuxshell/:71:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"只列出目录的其他方法 ls -d . ls -l . | grep \"^d\" ls -F . | grep \"/$\" find . -maxdepth 1 -type d \r## pushd和popd\r #在命令行中使用pushd和popd快速定位，pushd和popd以栈的方式运作 #当没有鼠标时，复制粘贴就不怎么实用了 #pushd和popd可以用于在多个目录之间进行切换而无需复制并粘贴目录路径 pushd /home/user1; pushd /home/user2; pushd /home/user3 #将路径添加到栈 pushd +2 #切换到/home/user3 popd #移除最近添加入栈的目录 cd /root; cd /home/user cd - #回到上次的目录 cd .. #切换到上一级目录 cd ~ #切换到用户主目录 ","date":"2017-10-24","objectID":"/linuxshell/:72:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"统计文件的行数、单词数、字符数 #wc(word count)，是一个统计工具 wc -l file1 #统计行数 wc -w file1 #统计单词数 wc -c file #统计字符数 wc -L file #打印最长行长度 wc file1 #行、单词、字符数 \r","date":"2017-10-24","objectID":"/linuxshell/:73:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"目录树 #tree命令是以图形化的树状结构打印文件和目录,在Linux发行版中默认未安装 yum install -y tree tree /home/zhang tree /home/zhang -P \"*.sh\" #只标记出.sh文件 tree /home/zhang -I \"*.sh\" #标记出除.sh文件外所有文件 tree /home/zhang -h #显示大小 tree /home/zhang -H http://localhost -o tree.html #以html形式输出目录树 \r让文本飞 ","date":"2017-10-24","objectID":"/linuxshell/:74:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"简介 shell脚本可以将sed, awk, grep, cut等这类优美的工具组合在一起，用于解决文本处理相关问题。 ","date":"2017-10-24","objectID":"/linuxshell/:75:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"正则表达式 Regular Expression 正则表达式是一种用于文本匹配的形式小巧、具有高度针对性的编程语言。只依靠通配符技术，能够匹配的文本范围相当有限。 正则表达式基本组成 正则表达式 描述 ^ 行起始标记 $ 行尾标记 . 匹配任意一个字符 [] 匹配包含在[]中的任意一个字符 [^] 匹配出[^]之外任意一个字符 [-] 匹配[]中范围内的任意一个字符 ？ 重复0或1次 + 重复\u003e=1次 * 重复\u003e=0次 () 创建一个用于匹配的子串 {n} 重复n次 {n, } 重复\u003e=n次 {n,m} 重复n到m次 \\ 转义字符 竖线l 匹配竖线l两边任意一项 POSIX字符类 POSIX字符类(POSIX character class),是一个形如[:…:]的特殊元序列，它用于匹配特定的字符范围。 正则表达式 描述 [:alnum:] 字母与数字字符 [:alpha:] 字母字符 [:blank:] 空格与制表符 [:digit:] 数字字符 [:lower:] 小写字母 [:upper:] 大写字母 [:punct:] 标点符号 [:space:] 所有空白字符 元字符 元字符(meta character)，是一种Perl风格的正则表达式，只有一部分文本处理工具支持它。 正则表达式 描述 \\A 字符串的开头 \\b 单词边界 \\B 非单词边界 \\d 单个数字字符 \\D 单个非数字字符 \\f 换页字符 \\n 换行符 \\r 回车 \\s 单个空白字符 \\S 单个非空白字符 \\t 跳进字符 \\v 垂直跳进字符 \\w 单个单词字符(数字，字母和_) \\W 单个非单词字符 \\z 字符串的结尾 \\Z 匹配字符串的结尾，或结尾的换行符之前 #匹配一个ipv4地址 [0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3} #匹配一个邮箱地址 [\\w]+@[\\w]\\.com ","date":"2017-10-24","objectID":"/linuxshell/:76:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"用grep在文件中搜索文本 grep命令是Unix中用于文本搜索的工具，它能够接受正则表达式和通配符。 grep \"匹配文本/通配符\" file1 file2... --color=auto #重点标记匹配 grep -E \"正则表达式\" file egrep \"正则\" file grep -v #反向匹配 grep -c #统计匹配行数 grep -n #打印出匹配的行号 grep -o #唯一匹配 grep -l \"匹配\" file1 file2 #返回匹配的文件名 grep -R #递归匹配 grep -i #忽略大小写 grep -e \"匹配1\" -e \"匹配2\" #匹配多个样式 grep -f match.txt file1 #从match.txt文件读取匹配 grep \"匹配\" --include=*.{sh,txt} --exclude=*.log --exclude-dir=/home/user -r /home #包括或排除文件 -A/-B n #输出匹配 之后/之前 n行 -c n #输出匹配 前后 n行 #正则匹配多个 egerep \"(a|b)\" ","date":"2017-10-24","objectID":"/linuxshell/:77:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"用cut按列切分文件 cut是一个将文本按列进行切分的小工具，它也可以指定每列定界符。在cut的术语中，每列都是一个字段。 #制表符'\\t' 是cut默认的定界符 cut -d' ' -f1 1.txt #-d指定分隔符，-f打印第几个字段 cut -f1,2,3 #打印1,2，3列 -c字符； -b字节； cut -c 1-5 1.txt #打印1-5字符 cut -c -2 1.txt #打印前2个字符 cut -c 3- #打印第3个字符到行尾 \r","date":"2017-10-24","objectID":"/linuxshell/:78:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"统计特定文件词频 #单词解析可以用 关联数组,正则表达式配合sed,awk,grep等工具来完成 #关联数组中，将单词作为数组索引，单词次数作为数组值 egrep -o \"\\b[:alpha:]+\\b\" #匹配单词 \r","date":"2017-10-24","objectID":"/linuxshell/:79:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"sed入门 sed是stream editor(流编辑器)的缩写，它是文本处理中非常重要的工具。能够完美地配合正则表达式使用。 #sed - stream editor for filtering and transforming text #字符/在sed中最为定界符使用 #替换 #sed 's/匹配样式/替代字符串/' sed 's/pattern/repalce/' file #替换 sed -i 's/pattern/repalce/' file #将替换应用于file echo \"1.txt\" \u003e 1.txt \u0026\u0026 sed 's/txt/haha' 1.txt #在输出中用haha替换txt sed -i 's/txt/haha/' 1.txt #将1.txt文件中的txt用haha替换掉 #-i选项替换原文件 echo \"hahaha\" | sed 's/ha/HA/g' #全部替换 echo \"hahaha\" | sed 's/ha/HA/2g' #指定位置替换，从第2处开替换全局 #移除匹配样式的行 sed '/pattern/d sed '/^$/d' ##移除空白行 #在sed中用\u0026标记已匹配字符串 echo \"A wonderful goal\" | sed 's/\\w\\+/[\u0026]/g' #\\w\\+匹配每一个单词 #子串匹配标记\\1,\\2... echo \"1st 2nd 3rd\" | sed 's/\\(\\w\\+\\) \\(\\w\\+\\) \\(\\w\\+\\)/\\2 \\1 \\3/' 2nd 1st 3rd #将\\2和\\1交换次序，(),+等在sed中要转义，否则要报错 #组合多个表达式 sed 'expression1; expression2; ... echo \"aabbcc\" | sed 's/a/A/; s/b/B/; s/c/C/g' AaBbCC #双引号 \" \" 内的特殊符号（如$等），可以保有原本的特性 #单引号 ' ' 内的特殊字符则仅为一般字符（纯文本） #引用 text=hello echo 'hello world' | sed \"s/$text/HELLO/\" HELLO world \r","date":"2017-10-24","objectID":"/linuxshell/:80:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"awk入门 awk被设计用于数据流，它可以对列和行进行操作。 #awk ‘begin{print \"start\"} pattern {command} end{print \"end\"}’ file awk '{sum += $1}; {print sum}' #awk脚本由:begin块、end块和能使用模式(pattern)匹配的通用语句块 组成 #3个部分都是可选的 #awk也可以从stdin中读取内容 cat /etc/passwd | awk -F: '{print $1}' #-F指定界定符 #awk中的特殊变量 #NR：记录数量(number of records)，对应于当前行号 #NF：字段数量(number of fields)，对应于当前行的字段数 #$0：执行过程中当前行的文本内容 #$1,$2...$NF：第1个/2个.../最后一个 字段的内容 echo -e \"L1 1\\nL2 22\\nL3 333\" | awk '{print NR NF $0 $1 $2}' # NR NF $0 $1 $2 $NF=最后一个=$2 1 2 L1 1 L1 1 1 2 2 L2 2 L2 2 2 3 2 L3 3 L3 3 3 #将外部变量传递给awk #-v选项可将外部值传递给awk # -v var=val --assign=var=val var='12345' echo | awk -v v1=$var '{print v1}' #多个变量 var1=111; var2=222 echo | awk '{print v1,v2}' v1=$var1 v2=$var2 #变量来自文件而非标准输入 awk '{print v1,v2}' v1=$var1 v2=$var2 file #用样式对awk进行过滤处理 awk 'NR \u003c 3,NR==4' 1.txt #行号\u003c5的行 awk '/linux/' 1.txt #匹配带有linux的行（可用re） awk '!/linux/' 1.txt #!匹配不带linux的行 #设置定界符 awk -F: '{print $1}' /etc/passwd awk '{FS=\":\"} {print $1}' /etc/passwd awk '{FS=\":\"; print $1}' /etc/passwd #从awk中读取命令输出，用getline读取行 echo | awk '{\"grep root /etc/passwd\" | getlin out; print out}' root❌0:0:root:/root:/bin/bash #在awk中使用循环 awk '{for(i=1;i\u003c4;i++) {print $i}}' 2.txt #输出第1,2,3列 #使用awk删除某列 awk -F' ' '{$1=null;$2=null;print}' ./file ","date":"2017-10-24","objectID":"/linuxshell/:81:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"对文件中的行、单词、字符进行迭代 #迭代文件中的每一行 echo -e \"1\\n22\\n333\" | while read line;do echo $line;done grep \"bash\" /etc/passwd | while read line;do echo $line;done #1 #22 #333 #迭代一行中的每一个单词 echo \"1 22 333\" | while read line;do for word in $line;do echo $word;done;done #1 #22 #333 #迭代一个单词中的每一个字符 echo \"abc\" | while read line; do for word in $line; do for((i=0;i\u003c${#word};i++)); do echo ${word:i:1}; done; done; done #写成一行 echo \"abc\" | while read line; do for word in $line; do for((i=0;i\u003c${#word};i++)); do echo ${word:i:1}; done; done; done #a #b #c #${#word}返回变量word的长度 \r","date":"2017-10-24","objectID":"/linuxshell/:82:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"按列合并文件(paste) 可以使用paste命令实现列拼接 #paste - merge(整合) lines of files echo -e \"1\\n2\\n3\" \u003e 1.txt \u0026\u0026 echo -e \"Line1\\nLine2\\nLine3\" \u003e 2.txt paste 1.txt 2.txt 1 Line1 2 Line2 3 Line3 #默认定界符是制表符，用-d指定 paste 1.txt 2.txt -d',' ## 打印文件或行中的第n个单词或n列\r awk -F':' '{print $1,$3}' file1 cut -d':' -f 1,3 file1 \r## 打印不同行或样式之间的文本\r awk 'NR==1,NR==10' /etc/passwd awk 'NR==1,NR==10' /etc/passwd | awk -F\":\" '{print $1,$NF}' #打印特定行内的特定列 awk '/start_pattern/, /end_pattern/' file #打印start到end之间的内容,可使用re awk '/root/, /zhang/' /etc/passwd #打印root到zhang之间内容 awk '/^ro.?t'/, /bash$/' /etc/pass ","date":"2017-10-24","objectID":"/linuxshell/:83:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"以逆序形式打印行 可以使用awk, tac完成。tac就是反过来的cat。 #tac - 反转显示文件中的行，行内的内容无法用tac反向排列 tac 1.txt awk '{lifo[NR]=$0; lno=NR} END{ for(;lno\u003e-1;lno--) {print lifo[lno]};}' 1.txt \r## 解析文本中的电子邮件和URL\r从给定的文件中解析出所需要的文本是我们从事文本处理时的一项任务。 grep, egrep, fgrep - print lines matching a pattern #egrep #匹配一个邮箱地址 egrep -o '[a-zA-Z0-9.]+@[0-9a-zA-Z.]+\\.[a-zA-Z]{2,4}' emails.txt #匹配一个URL地址 egrep -o \"http://[a-zA-Z0-9.]+\\.[a-zA-Z]{2,3}\" urls.txt ","date":"2017-10-24","objectID":"/linuxshell/:84:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"打印某个样式之前/之后n行(grep) grep \"zhang\" /etc/passwd -A 5 #Ater grep \"zhang\" /etc/passwd -B 5 #Before grep \"zhang\" /etc/passwd -C 5 #前后五行都打印 \r## 在文件中移除包含某个单词的句子\r只要能写出正确的正则表达式(Regular Expression)，那就手到擒来 sed 's/[^.]*handsome boy[^.]*\\.//g' file.txt #句子以.结束 ## 文本切片与参数操作\r #替换变量内容中的部分文字 var=\"One two three\" echo ${var/t/T} #只替换了一个 #One Two three #指定字符串起始位置和长度 #${变量:开始部分:长度} ${vari:start:length} echo {var:0:2} #On echo {var:1:6} #ne two #起始字符的索引是0,将最后一个字符索引记为-1 echo ${var:(-1)} #e echo ${var3} #ree \r一团乱麻？没这回事 ","date":"2017-10-24","objectID":"/linuxshell/:85:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"入门 本章会研究一些用于解析网站内容、下载数据、发送数据表单以及网站颇为任务自动化之类的实例。我们可以仅用几行脚本就将很多原本需要通过浏览器交互进行的活动管理自动化。通过命令行工具利用HTTP协议所提供的功能，我们可以用脚本解决大部分Web自动化的问题。 ","date":"2017-10-24","objectID":"/linuxshell/:86:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"网站下载(wget,curl) 使用一些命令行下载工具，从给定的URL中下载文件或网页。 wget是一个用于文件下载的命令行工具，选项多且用法灵活。 #Wget - The non-interactive(非交互式) network downloader wget URL1 URL2... wget http://xxx.com/nginx-1.12.0.tag.gz wget https://xxx/a.rpm http://xxxx/bb.rpm #指定文件名，指定信息输出(wget默认是stdout) wget http://mirrors.aliyun.com/repo/Centos-7.repo -O aliyun.repo -o ./wget.log wget URL -t 5 #-t，重试次数 #下载限速 wget --limit-rate=10m URL #下载限速 wget -Q 100m URL #指定下载配额 #端点续传 #wget进行的下载在完成前被中断，从断点开始下载 wget -c URL #用cURL下载 #cURL是一个比wget更强大的高级命令工具 #和wget不同，curl并不将下载数据写入文件，而是写入stdout，因此必须重定向到文件 #复制或镜像整个网站 #wget有一个选项可以使其像爬虫一样以递归方式手机网页上所有URL链接，并逐个下载 #这样一来就可以下载一个网站的所有页面 wget --mirror URL #-m(--mirror) -N -r -l inf --no-remove-listing 的缩写形式。 或 wget -r -N -l DEPTH URL #-r递归下载，-l指定递归深度，-N(timestamp)只获取比本地时间新的文件 #访问需要认证的HTTP或FTP页面 wget --user \"username\" --password \"pass\" URL #如未在命令行内输入密码，则会由网页提示手动输入 \r","date":"2017-10-24","objectID":"/linuxshell/:87:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"以格式化纯文本下载网页(links) 网页其实就是包含HTML标记和其他诸如Javascript，CSS等元素的HTML页面。HTML标记是网页的基础，也许需要解析网页来查找特定的内容。 links,是一个基于命令行的Web浏览器 #links - lynx-like alternative character mode WWW browser #在命令行中浏览一个网页 links www.baidu.com #以ASCII形式下载网页 links --dump URL \u003e URL.txt #打开本地html文件 links 1.html ## cURL入门\rcURL支持包括HTTP、HTTPS、FTP在内的众多协议。它还支持POST、cookie、认证、从指定偏移处下载部分文件、参照页(referer)、用户代理字符串、扩展头部(extra header)、限速、文件大小限制、进度条等特性。 #curl - transfer a URL #cURL通常将下载文件输出到stdout，将进度信息输出到stderr #要想避免显示进度信息，可使用--silent #curl可用来下载、发送各种HTTP请求、指定HTTP头部等操作 curl URL --silent #输出到stdout #-O写入文件，文件名从URL中解析 curl http://www.baidu.com/index.html -O --silent #创建index.html #-o将数据写入指定文件 curl URL -o baidu.html --progress #--progress显示进度条 links baidu.html #端点续传 #和wget不同，cURL包含更高级的下载恢复特性，能够从特定的文件偏移处继续下载 #curl可以通过指定一个偏移量来下载部分文件 手动：curl URL/file -C offset #偏移量以Byte为单位的整数 自动：curl -C -URL #自动续传 #用cURL设置参照页字符串, --referer #参照页(referer)是位于HTTP头部中的一个字符串，用来标识用户从哪个页面到达当前页面的 #如果用户点击网页A中某个链接，转到了网页B。那么网页B头部的referer会包含网页A的URL curl --referer Referer_URL target_URL curl --referer http://www.baidu.com http://jianshu.com #用cURL设置cookie, --cookie #可以用curl来存储HTTP操作过程中使用到的cookie #cookie用key=value形式，指定多个用 分号 分隔 curl URL --cookie \"user=AAA;name=bbb\" curl URL --cookie-jar cookie.txt #将cookie另存为 #用cURL设置用户代理字符串, --user-agent #如果不指定代理，一些需要用户代理的网页就无法显示 curl URL --user-agent(-A) \"Mozilla\" #用-H \"头部信息\"传递多个头部信息 curl - H \"Host:www.haha.com\" -H \"Accept-language: en\" URL #限定cURL可占用的带宽 curl URL --limit-rate 10m #指定最大下载量 curl URL --max-filesize 大小(Bytes) #用cURL进行认证，-u username:password指定用户名和密码 curl -u user:pass URL curl -u user URL #手动输入密码 #只打印响应头部信息(无数据部分), -I curl -I URL \r","date":"2017-10-24","objectID":"/linuxshell/:88:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"从命令行访问163邮箱 curl -u user http://mail.163.com #手动输入密码 \r","date":"2017-10-24","objectID":"/linuxshell/:89:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"制作图片抓取器及下载工具 可以用脚本解析图像文件并将图片自动下载下来。 curl -s URL | grep -o \"\u003cimg src=[^\u003e]*\u003e\" | sed 's/\u003cimg src=//g; s/\u003e//g' \u003e img.list #匹配图片的URL，可能还需要细化修改 #不同的URL可能有不同的规则，根据实际情况取出img的URL #下载图片 wget $URL 或 curl -s -O $URL \r","date":"2017-10-24","objectID":"/linuxshell/:90:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"查找网站中的无效链接(lynx) 将查找无效链接的工作自动化，那就比纯手动厉害多了！ lynx -traversal URL #会将URL中所有链接生成到reject.dat文件中 sort -u reject.dat | while read link do output=`curl -I $link -s | grep \"HTTP/.*OK\"` if [[ -z $output ]] then echo $link fi done \u003c links.txt ## 跟踪网站变更(`curl+diff`)\r可以编写一个定期运行的变更跟踪器(change tracker)，一旦发生变更，跟踪器便会发出声音或发送提示信息。 在不同时间检索网站，然后利用 diff 命令进行比对。 curl URL --silent -o `date +%F`.html #第一次 curl URL --silent -o `date +%F`.html #第二次 diff -u 第一次 第二次 \r","date":"2017-10-24","objectID":"/linuxshell/:91:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"以POST方式发送网页并读取响应 POST 和 GET 是HTTP协议中用于发送或检索信息的两种请求类型。 在GET请求方式中，利用网页的URL来发送参数(“键-值”)；而POST方式用于提交表单，如提交用户名、密码以及检索登录页面等。 curl URL -d “postarg=AABBCC” #-d,http post data curl URL -d \"post1=key1\u0026post2=key2\u0026post3...\" #指定多个数据 wget URL -post-data \"post1=key1\" \rPlan B ","date":"2017-10-24","objectID":"/linuxshell/:92:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"简介 提取快照和备份数据都是重要的工作，我们可以通过shell脚本来实现备份自动化。 归档和压缩对于SA来说同样很重要，有多种压缩格式。 加密是一种保护数据的方法，为了减少加密数据的大小，文件在加密前通常需要先归档和压缩。 \r","date":"2017-10-24","objectID":"/linuxshell/:93:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"用tar归档 tar命令可以用来归档文件(tar archives tar)。可以将多个文件和文件夹打包为单个文件，同时还能保留所有的文件属性。 由tar命令创建的文件通常称为tarball。 #归档文件，-c(create file) tar -cf 1.tar [sources] #-f(specify filename)指定文件名 #文件名必须紧跟在-f之后 tar -cvf txt.tar *.txt #-v(verbose)详细信息 #向已归档文件中添加文件，-r tar -rvf txt.tar *.html #列出归档文件中的内容，-t tar -tf txt.tar #列出归档内容 tar -tvf txt.tar #列出内容详细信息 #从归档文件中提取文件或文件夹，-x(exact) tar -xf txt.tar #默认提取到当前目录 #-C指定提取目录 tar -xvf txt.tar -C /dir/path #只提取归档中特定文件 tar -xf txt.tar 1.txt 1.html -C /tmp #只会提取1.txt和1.html文件 #在tar中使用stdin和stdout tar -cvf - *.text | tar -xvf - -C /tmp #拼接两个归档文件，-A tar -Af txt.tar html.tar tar -tvf txt.tat #验证是否成功 #添加选项，可以将指定的任意文件加入到归档文件中。如果同名文件已存在，不会覆盖源文件，那么结果就是归档中包含了多个同名文件 #通过检查时间戳来更新对党文件中的内容，-u #只有比归档文件中同名文件 更新(newer) 才添加 tar -uvf html.tar 1.html #比较归档文件与文件系统中的内容，-d tar -df txt.tar 1.txt 2.txt #从归档文件中删除文件，--delete tar -f txt.tar --delete 1.txt 2.txt #从归档文件中排除部分文件,--exclude tar -cf all.tar ./* --exclude=\"*.html\" #排除.html文件 tar -cvf txt.tar *.txt --exclude=\"1.txt\" #打印总字节数,--totals tar -cf all.txt ./* --totals #压缩tar归档文件，指定不同压缩格式 #-z, .tar.gz #-j, .tar.bz2 #--lzma, .tar.lzma, #.tar.lzo tar -czvf txt.tar.gzip *.txt tar -xzvf txt.tar -C /dir/path #tar后删除原文件 tar -czvf txt.tar.gz ./txt --remove-files \r","date":"2017-10-24","objectID":"/linuxshell/:94:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"用cpio归档 cpio是类似于tar的另一种归档格式。它多用于RPM软件包、Linux内核和initramfs文件等。 cpio通过stdin获取输入，并将归档写入stdout。 touch file{1..4} echo file1 file2 file3 file4 | cpio -ov file.cpio #-o指定输出，-v打印归档文件列表 #-i指定输入，-t列出归档中文件 cpio -it \u003c file.cpio ","date":"2017-10-24","objectID":"/linuxshell/:95:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"用gunzip或gzip压缩 gzip是GNU/Linux下常用压缩格式。gzip,gunzip都可处理gzip压缩文件类型。 gzip只能够压缩单个文件，而无法对目录和多个文件进行归档。因此需要先交给tar，然后再用gzip压缩 gzip file #file.gz，会覆盖原文件 gunzip file.gz #file，也会删除原文件 #列出压缩文件的属性信息，-l gzip -l file.gz #指定gzip的压缩级别，--fast或--best --fast 最低压缩比，最快速度完成 --best 最高压缩比，最慢速度完成 #将gzip与归档文件结合，-z tar -czvf txt.tar.gzip ./*.txt #-a指定从文件扩展名自动判断压缩格式 tar -cavf txt.tar.gzip ./*.txt #tar只能从命令行中接收有限个文件，要解决这个问题，可以写一个循环并添加-r选项 #解压缩，-x tar -xzvf txt.tar.gzip tar -xavf txt.tar.gzip -C /dir/path \r","date":"2017-10-24","objectID":"/linuxshell/:96:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"用bunzip或bzip压缩 bzip2通常能够生成比gzip更小(压缩比更高)的文件。 bzip2 file #file.bz2,同理会覆盖原文件 bzip2 file -k #保留原文件 bunzip2 file.bz2 #解压缩 bunzip file.bz2 -k #从stdin读入并写到stdout cat file | bzip2 -c \u003e file.bz2 #将bzip2与归档文件结合，-j tar -cvjf 1.tar.bz2 ./1.* tar -cavf 1.tar.bz2 ./1.* #-a根据文件扩展名自动判断压缩格式 tar -xjvf 1.tar.bz2 tar -xavf 1.tar.bz2 -C /tmp #压缩比 #从1级(速度最快，压缩率最低)到9级 bzip -9 -k file #对成千上万的文件进行归档，需要借助 循环和-r选项 \r","date":"2017-10-24","objectID":"/linuxshell/:97:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"lzma压缩 lzma是一个较新的压缩工具，它提供了比gzip或bzip2更好的压缩率。 xz, unxz, xzcat, lzma, unlzma, lzcat - Compress or decompress .xz and .lzma files lzma file #file.lzma,同样也会删除原文件 lzma file -k #保留原文件 unlzma file.lzma #从stdin读入并写入stdout cat file | lzma -C \u003e file.lzma #与tar相结合,--lzma tar -cvf 1.tar.lzma ./1.* --lzma tar -cavf 1.tat.lzma ./1.* #自动判断 tar -xvf 1.tar.lzma --lzma tar -xavf 1.tar.lzma -C /tmp #压缩率 #从1级到9级(压缩级别最高，速度最慢) #对成千上万的文件，需要使用循环和-r选项 ## zip归档和压缩\rzip在Linux下不如gzip,bzip2那么广泛，但在Internet上的文件通常都采用这种格式。 zip - package and compress (archive) files zip file.zip file unzip file.zip #与lzma,gzip,bzip2相比，zip完成后不会删除原文件 #对目录和文件进行递归操作,-r zip -r dir.zip /root/test ./file #向归档文件中增加内容，-u zip dir.zip -u newfile #从压缩文件中删除内容，-d zip -d dir.zip file #列出归档文件中内容 unzip -l dir.zip ","date":"2017-10-24","objectID":"/linuxshell/:98:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"超高压缩率的squashfs文件系统 squashfs是一种只读型的超高压缩率文件系统。这种文件系统能够将 2GB-3GB的数据压缩成一个700MB的文件。 你有没有想过Linux Live CD是怎样运行的？当Live CD启动后，它会加载一个完整的Linux环境。这就是利用了一种被称为squashfs的只读型压缩文件系统。它将根文件系统保存在一个压缩过的文件系统文件中。这个文件可以使用环回的形式来挂载并对其中的文件进行访问。一次当进程需要某些文件，可以将它们解压，然后载入内存中使用。 如果需要构建一个定制的Live OS，或是需要超高压缩率的文件并且无需解压就可以访问文件，那么squashfs的相关知识就能派上用场。要解压个头较大的压缩文件，需要花费不少时间。但如果将文件以环回形式挂载，速度就飞快，因为只有出现访问请求的时候，对应的那部分压缩文件才会被解压缩。而普通的解压缩方式是首先解压缩所有的数据。 环回文件系统就是指那些在文件中而非物理设备中创建的文件系统。比如我们可以创建一个文件，然后把这个文件格式化为我们常见ntfs、exfat或者ext4等文件系统格式，然后把它挂载在一个目录上使用。 如果你有一张Ubuntu CD，可以在CDRom Root/casper/filesystem.squashfs中找到文件.squashfs。 squashfs在内部采用了gzip和lzma这类压缩算法。 mksquashfs - tool to create and append to squashfs filesystems yum install squashfs-tools -y #创建squashfs文件 mksquashfs source compressfile.squashfs mksquashfs /etc etc.squashfs #/etc(67M) --\u003e etc.suqashfs(18M) #要挂载squashfs文件，利用环回形式进行挂载 mkdir /mnt/squash mount -o loop etc.squashfs /mnt/squash #此处挂载使用etc.squashfs文件系统 #如果直接查看etc.squashfs，就是一个普通文件，但是挂载以后所有文件都出现了 umount /mnt/squash #在创建squashfs文件时排除指定文件，-e mksquashfs /etc etc.squashfs -e /etc/passwd /etc/shadow /etc/*.txt #在挂载之后就没有相关文件了 \r","date":"2017-10-24","objectID":"/linuxshell/:99:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"加密工具与散列 加密技术主要用于防止数据遭受未经授权的访问。 Linux下某些工具用于执行加密和解密，使用加密算法散列值来验证数据完整性。 crypt, gpg, base64, md5sum, sha1sum, openssl的用法 ","date":"2017-10-24","objectID":"/linuxshell/:100:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"ccypt ccrypt是为了取代UNIX crypt而设计的，这个实用工具可用于文件和数据流加密及解密。 ccrypt - encrypt and decrypt files and streams ccrypt 1.txt #会要求输入口令(encryption key) #之后会生成1.txt.cpt覆盖原文件 #更改key,-x ccrypt -x 1.txt.cpt #输入old key和new key #解密，-d(--decrypt) ccrypt -d 1.txt.cpt #输入key解密 ","date":"2017-10-24","objectID":"/linuxshell/:100:1","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"gpg gpg(GNU privacy guard,GNU隐私保护)，是一种应用广泛的加密方案。 它采用签名密钥技术保护文件内容，只有经过认证的用户才能访问数据。我们对gpg签名早已耳熟能详。 gpg - OpenPGP encryption and signing tool #加密，-c(--symmetric)对称加密 gpg -c file #会要求输入口令(Passphrase)，生成file.gpg #解密 gpg file.gpg ","date":"2017-10-24","objectID":"/linuxshell/:100:2","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"base64 base64是一组类似的编码方案(encoding scheme)，它通过将ASCII字符转换成以64为基数的形式(radix-64 representation)来用ASCII字符串描述二进制数据。base64可用来对 编码和解码 base64字符串。 base64 - base64 encode/decode data and print to standard output #将文件编码为base64格式 base64 file \u003e outputfile cat file | base64 \u003e outputfile #解码,-d base64 -d outputfile \u003e file ","date":"2017-10-24","objectID":"/linuxshell/:100:3","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"md5sum与sha1sum md5sum 和 sha1sum 都是单向散列算法(unidirecrional hash algorithm)，均无法逆推出原始数据。 它们通常用于验证数据完整性或为特定数据生成唯一的密钥，因为通过分析文件内容，它们可以为每个文件生成一个唯一的密钥。 这种类型的散列算法是存储密码的理想方案。密码使用其对应的散列值来存储。如果某个用户需要认证，读取该用户提供的密码并转换成散列值，然后将其与之前存储的散列值进行比对。 将密码以明文的形式存储是非常危险的事情，它面临密码泄露的危险。而因为 md5sum和sha1sum 是单向散列算法，所以密码使用散列值存储是很安全的。 echo \"1.txt\" \u003e 1.txt md5sum 1.txt #生成密钥到stdout #39061daa34ca3de20df03a88c52530ea 1.txt sha1sum file #生成密钥到stdout #659fcbc505db207c03b5c4c0b6981d63286abe21 1.txt #查看/etc/shadow中密码的散列值 awk 'NR==1' /etc/shadow | awk -F: '{print $2}' #root密码散列 #$6$BxpV48gPsjuq6.pF$wE7pUDwtOI.v64kd5folG68yUt2UAQDTUGgKa5Iz69GaupEoRAdCeerP8nRKXo48c4azutUCGhnDgzd1qe8YX0 ","date":"2017-10-24","objectID":"/linuxshell/:100:4","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"shadowlike散列(salted散列) shadow密码通常都是salted密码，所谓SALT就是额外的一个字符串，用来起一个混淆的作用，使加密更加不同里被破解。salt由一些随机位组成，被用作密钥生成函数的输入之一，以生成密码的salted散列值。 #/etc/passwd里面的密码散列类型就是salted散列 #查看root密码对应的散列值 head -1 /etc/shadow root:$6$ZlHRCZG2iRwQUXAu$RAEDH97nPdZB2RK20npua6Qf6jB7osatoC99ow3LtPQ6aORdLISYC7/4iTYU162emkQLt4ZafdgjyAeoSB7IU0::0:99999:7::: #openssl - OpenSSL command line tool #shadow密码是使用openssl生成 #将SALT_STRING替换为随机字符串，同时将pass替换成你想测试的密码 openssl -1 -salt SALT_STRING passwd ","date":"2017-10-24","objectID":"/linuxshell/:100:5","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"用rsync备份系统 rsync借助差异计算以及压缩技术来最小化数据传输量。相较于cp命令，它的优势在于使用了高效的差异算法(difference algorithm)。 它还支持网络数据传输。在进行复制的同时，rsync会比较源端和目的端的文件，只有当文件有更新是才进行复制。默认情况下，rsync并不会在目的端删除源端已不存在的文件。 rsync - a fast, versatile, remote (and local) file-copying tool inotifywait - wait for changes to files using inotify #-a进行归档，-v详细信息 rsync -av source destination rsync -av /etc /tmp #异地cp rsync -av source username@host:PATH rsync -av username@host:PATH destination #rsync借助于ssh，可以使用ssh无秘钥认证 rsync -av /etc zhang@192.168.1.11:~ #-z, --compress compress file data during the transfer rsync -avz zhang@192.168.1.11:/etc /tmp #注意，路径格式 rsync /etc /tmp #整个/etc目录 rsync /etc/ /tmp #/etc目录下所有内容 #显示进度，--progress rsync -avz --progress /etc /tmp #排除部分文件，--exclude rsync -avz /etc /tmp --exclude=/etc/nginx --exclude \"*.txt\" #更新rsync时，删除不存在的文件，--delete #默认情况下，rsync并不会在目的端删除源端已不存在的文件 rsync -avz /etc zhang@192.168.1.1:~ --delete #定期调度 crontab -e 0 */10 * * * rsync -avz /etc user@host:PATH #实时同步，inotifywait+rsync yum install inotify-tools -y #-m(monitor),-r(recursive),-q(--quiet)静默模式，-e(event) vi inotify_rsync.sh inotifywait -mrq -e creat,delete,modify,move --exclude \"^.*\\.filepart$\" /etc | while read file do rsync -az --exclude=\".*\" --exclude=\"*.swp\" --exclude=\".filepart\" --delete /etc /tmp \u003e /dev/null 2\u003e$1 done \r## 用Git备份版本控制\r维护和恢复变更最好的方法是使用版本控制系统。由于代码变更频繁，版本控制系统多用于软件开发和代码维护。 Git(GNU it)是有名气也是最高效的版本控制系统。我们可在非编程环境下用Git备份普通文件。 git - the stupid content tracker mkdir /home/zhang/gittest cd /home/zhang/gittest #在源主机中添加用户信息 git config --global user.name \"username\" #设置用户名 git config --global user.email \"someone@example.com\" #设置邮箱 #创建一个空的Git版本库或初始化一个老版本 git init #记录变更到版本库 git commit #添加远程git目录并同步备份 git remote add origin user@host:/home/zhang/gittest #为git跟踪(git tracking)添加或删除文件 #add,添加内容至索引 git add * #git add *.txt; git add *.ph #添加部分文件 #删除不需要跟踪的文件和文件夹 #rm,从工作去和索引删除文件 git rm file #git rm *.txt #检查点或创建备份点(check point) git commit -m \"Commit Message\" #push,更新远程 git push #用Git恢复数据 #log,显示提交日志 git log #返回之前某个版本或状态 git checkout xxxxxxxx(Commit ID) #clone,克隆一个版本库到本地 git clone URL git clone user@host:PATH ## 用`dd`克隆磁盘\rdd命令能用于克隆任何类型的磁盘，如硬盘、闪存、CD、DVD及软盘。 可能需要创建所有分区的副本而不仅仅是复制内容，包括硬盘分区、引导记录、分区表等信息。 使用dd的时候，要留意参数的顺序。错误的参数会损毁全部数据。dd基本上算是一个比特流复制器(bitstream duplicator),它可以将来自磁盘的比特流写入文件，也可以将来自文件的比特流写入硬盘。 dd - convert and copy a file dd if=source of=target bs=block_size count=count #bs块大小，count块数 dd if=/tmp/centos7.iso of=/dev/sdc #/dev/zero是一个字符设备，它总是返回字符'\\0' dd if=/dev/zero of=./file bs=10m count=100 #用环回(loop back)方法可将任何由dd生产的文件镜像进行挂载 mount -o loop file /mnt \r无网不利 ","date":"2017-10-24","objectID":"/linuxshell/:101:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"简介 网络是计算机系统中重要的部分。我们以Tcp/Ip为协议栈，所有操作都是基于它进行的。 一些使用网络的应用通过打开并连接到防火墙端口进行运作，而有的管理任务可以通过网络进行。 ","date":"2017-10-24","objectID":"/linuxshell/:102:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"网络小知识 网络接口(Interface)用来连接网络。在每个系统中，默认都有一个称之为环回接口的lo，这个接口指向当前主机本身。 操作系统维护者一个被称为路由表(routing table)的表格，它包含了分组如何转发以及通过网络中的哪些节点转发的消息。 metric是路由算法用以确定到达目的地的最佳路径的计量标准，如路径长度。 #显示网络接口、子网掩码等详细信息 ifconfig #/sbin/ifconfig #显示某个特定接口 ifconfig eth0 #提取IP地址 ifconfig eth0 | egrep -o \"inet [^ ]*\" | grep -o \"[0-9.]*\" #设置网络接口的IP地址和子网掩码 ifconfig eht0 192.168.1.11 ifconfig eth0 192.168.1.11 netmask 255.255.255.0 #远程的时候，千万别乱改IP，不然连不上你就要去机房了 #MAC地址欺骗 ifoconfig eth0 hw ether 11:22:33:44:55:66 #域名服务器与DNS cat /etc/resolv.conf #添加域名服务器 echo \"name 114.114.114.114\" \u003e\u003e /etc/resolv.conf #nameserver 114.114.114.114 #一个域名可以分配多个地址，DNS只会返回其中一个 #要想获得域名所有IP地址，需要使用DNS查找工具 #DNS查找工具 host www.baidu.com nslookup www.baidu.com #自定义解析 cat /etc/hosts echo \"192.168.1.11 www.zhang.me\" \u003e\u003e /etc/hosts #设置默认网关，显示路由表信息 #路由表 route route -n #以数字形式显示地址 #设置默认网关 route add default gw $ip $interface route add default gw 192.168.1.1 eht0 #显示分组途经的所有网关地址 traceroute www.baidu.com \r","date":"2017-10-24","objectID":"/linuxshell/:103:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"ping ping使用 **网际控制报文协议(Internet Control Message Protocol,ICMP)**的echo分组。如果分组能够送达且该主机为活动主机，那它就会发送一条回应。一旦主机不可到达，ping返回错误信息\"Destination Host Unreachable\"。 ping 192.168.1.1 #往返时间(Round Trip Time,RTT) #发送分组数量 ping $URL -c 6 \r","date":"2017-10-24","objectID":"/linuxshell/:104:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"列出网络上所有活动主机 当涉及大型局域网时，可能需要检查网络上的其他主机的活动状态。 一台非活动主机可能是：没有开机；网络连接有问题；主机禁ping；防火墙问题。 当我们要检测ip时，在一个脚本中，每一次ping都是依次执行。即使所有的ip地址都是彼此独立，由于编写的是顺式程序(sequential program)，ping命令也只能按顺序执行。每次执行一个ping命令。都要经历一段延迟——“发送echo分组，并接收或等待回应超时”。 要是处理几百个ip地址的话，这个延时就真不短了。我们可以使用并行方式来加速所有ping命令的执行。 可以将ping命令中的循环体放入**( )\u0026** 中，**( )** 使其中的命令可作为子shell来执行，**\u0026** 使之在后台继续运行。 #编写G一个并行方式的ping脚本 fo ip in 192.168.1.{1..255} do ( ping $ip -c2 \u0026\u003e /dev/null; if[ $? -eq 0 ] then echo \"$ipis alive\" fi )\u0026 wait done #wait命令是脚本只有在所有子进程或后台进程全部终止或完成后才能结束 #使用fping,-a显示活动主机，-g生成目标列表,-u显示无法到达主机 fping -a 192.168.0.0/24 -g 2\u003e /dev/null fping -a 192.168.0.1 192.168.3.255 -g 2\u003e ./unreach.txt #将unreach主机找出 cat unreach.txt | egrep -o \"to [0-9.]+$\" | grep -o \"[0-9.]*\" ","date":"2017-10-24","objectID":"/linuxshell/:105:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"传输文件 有很多不同的方法可以在网络节点上传输文件，常见的协议有FTP, SFTP, RSYNC, SCP。 通过FTP传输文件可使用lftp命令； 通过SSH传输文件可使用sftp； RSYNC使用SSH与rsync命令； scp通过SSH进行传输。 文件传输协议(File Transfer Protocol, FTP)，使用21端口。FTP是明文传输，So… 需要远程主机上启用了FTP服务器才能使用FTP。 lftp user@ftp-host #输入密码后便可以操作如下命令 cd -- lcd(本地) mkdir get filename #下载文件 put filename #上传文件 quit #退出 \rSFTP(Secure FTP,安全FTP)，运行在SSH连接之上。利用SSH连接模拟FTP接口。 它不需要源端运行FTP服务器，不要运行OpenSSH。SFTP是一个交互式命令，提供了命令提示符。 rsync广泛用于网络文件与系统快照的备份。 SCP(Secure Copy,安全复制)，远程文件复制工具。通过SSH加密通过进行传输。 scp SOURCE DESTINATION scp /path/file user@host:PATH scp usr@host:/dir/file /home/zhang #需要输入密码，可以用SSH无秘钥认证 #-r递归复制,-p保持文件权限和模式 scp -r /etc user@host:/tmp scp -rp user@host:/var/www /var \r","date":"2017-10-24","objectID":"/linuxshell/:106:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"SSH无秘钥认证 特别是在定时任务传输备份文件时，无秘钥认证就很方便了。SSH服务默认在22端口，你可以在配置文件中修改。 具体步骤： 创建SSH密钥(公钥和私钥)； 将客户端公钥上传给需要连接的主机，并写入~/.ssh/authorized_keys文件； 修改相关目录(700)和文件权限(600)； ssh-keygen -t rsa #后续操作默认即可 #生成~/.ssh/id_rsa.pub和id_rsa #写入远程主机 ssh user@host \"cat \u003e\u003e ~/.ssh/authorized_keys\" \u003c ~/.ssh/id_rsa.pub ","date":"2017-10-24","objectID":"/linuxshell/:107:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"用SSH在远程主机上运行命令 #连接远程主机 ssh user@host #非默认端口 ssh user@host -p 2211 #在远程主机中运行命令 ssh user@host 'command' ssh user@host 'cmd1'; 'com2'... ssh user@host 'whoami' #-C压缩功能，当带宽有限时 ssh -C user@host 'cmd' \r","date":"2017-10-24","objectID":"/linuxshell/:108:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"在本地挂载远程驱动器(sshfs) 在执行读写数据操作时，通过本地挂载远程主机文件系统。利用SSH和sshfs来实现这一功能。 sshfs是FUSE文件系统的一个扩展，FUSE允许其支持的操作系统像使用本地文件系统一样挂载各类数据。 sshfs允许将远程文件系统挂载到本地挂载点上。 相当于便捷的NFS，但并不需要搭建NFS服务。 SSHFS - filesystem client based on ssh #挂载远程文件到本地 ssh user@host:PATH /mnt/sshfs umout /mnt/sshfs ","date":"2017-10-24","objectID":"/linuxshell/:109:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"网络流量和端口分析 应用程序在主机上打开端口，然后与远程主机中打开的端口实现通信。 出于安全方面的考虑，必须留意系统中打开及关闭的端口。 恶意软件和rootkit可能会利用特定的端口及服务运行在系统之中，从而进行攻击。 通过分析开放端口列表以及运行在端口上的服务，我们便可以分析并检查恶意软件，保证主机安全。 了解及使用各种端口分析工具。 lsof - list open files lsof列出系统中开放端口以及运行在端口上的服务的详细信息，文件被哪个程序使用。 -a：列出打开文件存在的进程 -c\u003c进程名\u003e：列出指定进程所打开的文件 -g：列出GID号进程详情 -d\u003c文件号\u003e：列出占用该文件号的进程 +d\u003c目录\u003e：列出目录下被打开的文件 +D\u003c目录\u003e：递归列出目录下被打开的文件 -n\u003c目录\u003e：列出使用NFS的文件 -i\u003c条件\u003e：列出符合条件的进程（4、6、协议、:端口、 @ip ） -p\u003c进程号\u003e：列出指定进程号所打开的文件 -u：列出UID号进程详情 -h：显示帮助信息 -v：显示版本信息 lsof /var/log/messages COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME rsyslogd 12231 root 5w REG 253,0 539973467 68539162 /var/log/messages netstat查看开放端口与服务 netstat - 显示网络连接，路由表，接口状态，伪装连接，网络链路信息和组播成员组; iftop - display bandwidth usage on an interface by host iftop - 展示带宽使用情况； ifstat - handy utility to read network interface statistics ifstat - 展示某时刻网络状态； nload - displays the current network usage nload - 可查看系统总带宽； nethogs - Net top tool grouping bandwidth per process nethogs- 可查看每个进程流量情况； ethtool - query or control network driver and hardware settings ethtool - 检查网卡支持的带宽 #lsof的每一项都对应着一个打开了特定端口的服务 lsof -i:port #查看开放端口和服务 netstat -nltp #查看网络实时状态 iftop #查看当前网络状态 ifstat #查看系统带宽 nload #查看进程流量 nethogs \r","date":"2017-10-24","objectID":"/linuxshell/:110:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"tcpdump tcpdump是一款嗅探工具，也就是命令行格式的wireshark。 tcpdump - dump traffic on a network tcpdump [options] -a：尝试将网络和广播地址转换成名称； -c\u003c数据包数目\u003e：收到指定的数据包数目后，就停止进行倾倒操作； -d：把编译过的数据包编码转换成可阅读的格式，并倾倒到标准输出； -dd：把编译过的数据包编码转换成C语言的格式，并倾倒到标准输出； -ddd：把编译过的数据包编码转换成十进制数字的格式，并倾倒到标准输出； -e：在每列倾倒资料上显示连接层级的文件头； -f：用数字显示网际网络地址； -F\u003c表达文件\u003e：指定内含表达方式的文件； -i\u003c网络界面\u003e：使用指定的网络截面送出数据包； -l：使用标准输出列的缓冲区； -n：不把主机的网络地址转换成名字； -N：不列出域名； -O：不将数据包编码最佳化； -p：不让网络界面进入混杂模式； -q ：快速输出，仅列出少数的传输协议信息； -r\u003c数据包文件\u003e：从指定的文件读取数据包数据； -s\u003c数据包大小\u003e：设置每个数据包的大小； -S：用绝对而非相对数值列出TCP关联数； -t：在每列倾倒资料上不显示时间戳记； -tt： 在每列倾倒资料上显示未经格式化的时间戳记； -T\u003c数据包类型\u003e：强制将表达方式所指定的数据包转译成设置的数据包类型； -v：详细显示指令执行过程； -vv：更详细显示指令执行过程； -x：用十六进制字码列出数据包资料； -w\u003c数据包文件\u003e：把数据包数据写入指定的文件。 栗子： #tcpdump默认将监视第一个网络接口上流过的数据包 tcpdump #指定网络接口 tcpdump -i eth1 -w /tmp/1.cap #指定主机 tcpdump host $hostname tcpdump host $hostname1 and $hostname2 #指定源和目标主机 tcpdump -i eth0 src host $hostname tcpdump -i eth0 dst host $hostname #指定主机和端口 tcpdump tcp port 22 host 192.168.1.11 tcpdump udp port 53 \r \r当个好管家 ","date":"2017-10-24","objectID":"/linuxshell/:111:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"简介 操作系统(Operation System,OS)，是由一系列用于不同目的、服务于不同任务的系统软件组成。 日志记录(logging)和监视是很重要的，能帮助我们从大量数据中收集信息。 监视系统活动的各种命令，日志技术及其使用方法。 ","date":"2017-10-24","objectID":"/linuxshell/:112:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"统计磁盘使用情况(df+du+fdisk) 磁盘空间是一种有限资源，我们需要了解磁盘的可用空间。 df, du, fdisk是Linux中的磁盘管理三板斧 df(disk free): 报告文件系统磁盘空间的使用情况; du(disk usage): 报告磁盘空间使用情况; 使用du时，要确保对其遍历的目录和文件拥有适合的读权限。 fdisk: Linux分区表操作工具软件。 du file1 #默认以字节为单位 #-a,显示目录下所有文件大小 du -a /home/zhang du /home/zhang #只显示目录大小 #-h,以可读形式打印 du -h /home/zhang #-c,显示使用总量 du -c file1 /dir2 du -c *.txt *.sh #-s，打印摘要 du -s /dir du -sh /home/zhang #-b,-k,-m,-B，用特定单位打印 du -k file1 du -m file2 #--exclude,从磁盘统计中排除部分文件 du --exclude=\"*.swap\" -sh /home/zhang #--max-depth,指定最大遍历深度 du -h --max-depth n /dir du -h --max-depth=2 /home/zhang #-x,将/mnt中所有挂载点排除在磁盘统计之外 du -xh /dir #找出目录中最大的文件 du -ak /dir | sort -nrk 1 | head -n 5 #此输出包含了目录大小，需要细化 #利用find替du过滤文件 find /dir -type f --exec du -ak {} \\; | sort -nrk 1 | head #df,磁盘可用空间信息 df -h ","date":"2017-10-24","objectID":"/linuxshell/:113:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"计算命令执行时间 当测试一个应用程序或比较不同的算法时，程序的执行时间非常重要。所以需要计算命令执行时间。 所有的Unix-Like操作系统都包含time命令，可将time放在需要计算执行时间的命令前。 time命令有个可执行二进制文件位于/usr/bin/time，还有一个shell built-in命令也叫作time； 当运行time时，默认调用的是shell built-in命令。內建time命令选项有限； 因此，如果我们需要使用另外的功能，就应该使用/usr/bin/time命令。 #计算命令执行时间 time command time ls #real,挂钟时间(wall clock time),命令从开始执行到结束的时间； #user,指进程花费在用户模式(user-mode)中的CPU时间。这是唯一用于执行进程所花费的时间； #sys，指进程花费在内核模式(in the kernel)中的CPU时间。它代表在内核中执行系统调用所使用的时间。 #-o,将命令执行时间写入文件 /usr/bin/time -o exetime.txt ls / #-a,不影响原文件 /usr/bin/time -a -o exetime.txt ls /home #-f,格式化时间输出 #时间格式字符串 #real %e #user %U #sys %S /usr/bin/time -f \"FORMAT STRING\" command /usr/bin/time -f \"Rtme: %e\" -a -o timing.log uname /usr/bin/time -f \"Rtime: %e\\nUtime: %U\\nStime: %S\" -ao timing.log uname \r","date":"2017-10-24","objectID":"/linuxshell/:114:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"当前登录用户、启动日志、启动故障的相关信息(w+who+lastb+last) 收集与操作系统、当前登录用户、主机运行时间、启动故障等相关信息很有用处。 #获取当前登录用户 who #显示已经登录的用户 w #显示已经登录的用户以及他们在做什么 #会显示用户使用的伪终端(pseudo TTY)，对应设备文件出现在/dev/pts/n #列出登录主机的用户列表 users #查看系统运行时间 uptime #显示用户登录列表 last #获取某个用户登录信息 last zhang #获取重启会话信息 last reboot #获取失败的用户登录信息 lastb ","date":"2017-10-24","objectID":"/linuxshell/:115:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"打印10条最常使用的命令(history) 终端是用来访问shell的工具，在shell中我们可以输入并执行命令。我们可以找出在shell中运行最多的命令。 ~/.bash_history，默认保留1000个最近执行命令。或者history命令。 cat .bash_history | sort -n | uniq -c | sorn -nr | head ","date":"2017-10-24","objectID":"/linuxshell/:116:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"列出占用CPU最多的进程 CPU时间是一项重要资源，有时需要跟踪占用CPU周期最多的进程。 对于需要处理大量请求的服务器来说，CPU是极其重要的资源。通过监视某个时期内CPU的使用情况，可以找出长期占用CPU的进程并对其进行优化，或是调试其他问题。 用ps命令收集系统中进程的详细信息。 ps - report a snapshot of the current processes #-e,以标准语法显示每个进程 ps -e ps -ef #ax,以BSD语法显示每个进程 ps ax pa axu #获取安全信息 #ps -eo euser,ruser,suser,fuser,f,comm,pcpu,label #comm显示命令，pcpu显示CPU使用率 ps -eo comm,pcpu #监视并计算一小时内CPU使用情况的shell脚本 secs=3600 unit_time=60 steps=$(($secs / $unit_time)) echo \"Whatching CPU usage...\" for((i=0; i\u003csteps; i++)) do ps -eo comm,pcpu | tail -n +2 \u003e\u003e /tmp/cpu_usage.$$ sleep $unit_time done echo \"CPU eaters: \" cat /tmp/cpu_usage.$$ | \\ awk '{process[$1]+=$2} END{ for (i in process) { printf(\"%-20s %s\",i,process[i]); } }' | sort -nrk 2 | head #tail -n +K，从第K行开始输出。上面输出第一行是 COMAND 和 %CPU #$1,command; $2,%CPU #process[$1]是一个关联函数，相当于arr[command] #arr[command]=arr[command]+ $2，计算同一命令的累积时间 #i指命令，process[i]指命令运行时间 \r","date":"2017-10-24","objectID":"/linuxshell/:117:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"用watch监视命令输出 可能需要在在某段时期内以固定的间隔时间不短监视某个命令的输出。可利用watch命令。 watch - execute a program periodically, showing output fullscreen #watch命令可以用来在终端以固定的间隔监视命令输出，默认2秒间隔 watch command watch 'command' watch ls watch 'ls -l' #-n,指定时间间隔 watch -n 5 'yum update -y' #-d，突出(highlighting)watch输出中的差异 watch -d -n 1'dd if=/dev/zero of=/tmp/zero.test' ","date":"2017-10-24","objectID":"/linuxshell/:118:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"对文件及目录访问进行记录(inotifywait) 记录重要文件及目录访问，对于追踪文件和目录的变化很有帮助。 inotifywait命令可以用来收集有关文件访问的信息。 inotifywait和rsync用户实时同步哦！ inotifywait - wait for changes to files using inotify yum install -y inotify-tools #-q,减少冗余信息 inotifywait -m -r -q -e create,move,delete /dir inotifywait -m -r -q -e create,move,modify,delete /home/zhang \u003e\u003e inotifywait.log #利用inotifywait检测，rsync同步 inotifywait -mrq -e create,move,modify,delete /dir --exclude=\"*.swap\" | while read file do rsync -av --exclude=\"*.swqp\" --delete /dir user@host:PATH \u003e /dev/null 2\u003e\u00261 done \r","date":"2017-10-24","objectID":"/linuxshell/:119:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"用logrotate管理日志文件 日志文件是Linux系统维护中必不可少的组成部分。日志文件可以帮助跟踪系统中多种服务所发生的事件，这有助于排除系统问题。 但随着时间推移，日志文件会变得越来越大。因而必须对日志文件进行管理。 我们可以利用一种称为“轮询(rotation)”的技术来限制日志文件的体积。一旦日志文件超过了限定大小，就要对它的内容进行抽取(strip)，同时将日志文件的旧条目归档到文件中。 logratate是每一位Linux系统管理员都应该了解的命令。它能够将日志文件大大小限制在给定的SIZE内。 logrotate配置文件位于/etc/logrotate.d logrotate ‐ rotates, compresses, and mails system logs vim /etc/logrotated.d/custom /var/log/custom.log { missingok #日志文件丢失，则忽略 notifempty #仅当源日志文件非空时才进行轮替 size 30k #限制实施轮替的日志文件大小 compress #压缩旧日志 weekly #轮询时间，daily,weekly,yearly rotate 7 #保留旧日志数量 create 0600 root root #创建的日志文件模式，用户和用户组 #还有一些其他选项 } ","date":"2017-10-24","objectID":"/linuxshell/:120:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"用sys记录日志 在Linux系统中，在/var/log中创建并写入日志信息的是由被称为syslog的协议处理的。它由守护进程syslogd负责执行。 每一个标准应用进程都可以用syslog记录日志信息。 syslog处理/var/log下的多个日志文件。但是当logger发送消息时，它用标记字符串来确定应该纪录到哪一个日志文件中。 syslogd使用与日志相关联的TAG来决定应该将其记录到哪一个文件中。 可以从/etc/rsyslog.d/目录的配置文件中看到与日志文件相关联的标记字符串。 Linux中一些重要日志文件： /var/log/boot.log， 系统启动信息； /var/log/message， 内核启动信息； /var/log/auth.log， 用户认证日志； /var/log/dmesg， 系统启动信息； /var/log/mail.log， 邮件服务器日志。 logger - a shell command interface to the syslog #logger命令，默认记录日志信息到/var/log/messages logger \"test log message to messages\" tail -n 1 /var/log/message #-t，指定特定TAG logger -t TAG \"test log message to messages\" \r管理重任 ","date":"2017-10-24","objectID":"/linuxshell/:121:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"简介 GNU/Linux的生态系统是由运行的程序、服务、连接的设备、文件系统、用户等组成。按照我们需要的方式对整个系统有一个微观并对操作系统进行整体上的管理，这就是系统管理的主要目的。 ","date":"2017-10-24","objectID":"/linuxshell/:122:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"收集进程信息(top+ps+pgrep) 进程是程序运行实例(runing instance)。 同一程序的多个实例可以同时运行，但他们的进程ID却互不相同。 进程管理相关的重要命令是： top, display Linux processes; ps, report a snapshot of the current processes; pgrep, look up or signal processes based on name and other attributes. #ps命令 #-f, 显示更多进程信息 ps -f #-e,every; -a,all ps -ef ps -ax #-o, 指定想要的列 ps -e -o parameter1,parameter2... ps -eo comm,pcpu,pmem #pccpu CPU占用率 #pid 进程ID #ppid 父进程ID #pmem 内存使用率 #comm 命令名 #cmd 简单命令 #user 启动进程的用户 #nice 优先级 #time 累积的CPU时间 #etime 进程启动后度过的时间 #tty 所关联的TTY设备 #euid 有效用户ID #stat 进程状态 #--sort,根据参数对ps输出进行排序 #+升序，-降序 ps -eo comm,pcpu,pmem --sort -pcpu ps -eo comm,pcpu,pmem --sort -pcpu,+pmem #-C, 给定命令全名找出PID ps -C cmd -o comm,pid #-u, 指定有效用户列表 #-U, 指定真实用户列表 ps -u root -U zhang -o user,pcpu #-t, 用TTY过滤输出 ps -t TTY1,TTY2... ps -t pts/0,pts/1 -ef #-L, 显示进程相关信息 #LWP线程ID， NLWP线程数量 ps -efL #pgrep命令, 获得一个特定命令的PID列表 #它只需要命令的一部分即可 pgrep cmd pgre inotif pgrep bas #-d, 指定定界符 pgrep rsync -d \":\" #-u, 指定进程的用户 pgrep -u root,zhang rsync #-c, 返回匹配的进程数量 pgrep -c rsync #top命令 top \r\r","date":"2017-10-24","objectID":"/linuxshell/:123:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"杀死进程以及发送响应信息(kill+killall+trap) 在Unix-Like环境中与进程有关的一个重要概念就是信号。 信号是一种进程间通信机制，它用来中断运行的进程以执行某些操作。终止程序也是通过使用信号技术来实现的。 像ctrl+C,ctrl+Z这种作业都属于信号。 kill 命令可用来向进程发送信号; trap 命令用来处理所接收的信号; killall 以名字方式来杀死进程. #列出所有可用信号 kill -l #-s, 发送信号 #信号名称和信号数都可以 kill -信号数 PID kill -s SIGNAL PID #常用信号 #SIGHUP 1 终端断线(对控制进程或终端进行挂起检测(hangup detection)) #SIGINT 2 中断(当按下Ctrl+C时发送该信号) #SIGQUIT 3 退出(同Ctrl+\\) #SIGKILL 9 强制终止(强行杀死进程) #SIGTERM 15 终止进程 #SIGCONT 18 继续(与STOP相反，fg/bg命令) #SIGTST0P 19 暂停(当按下crtl+z时发送该信号) #killall, 通过命令名终止进程 killall -s SIGNAL PName killall -信号数 PName #trap, 捕捉并响应信号 trap 'signal-handler-func' SIGNAL LIST kill信号详解 参考: https://www.imooc.com/article/48534 $ kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR1 11) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM 16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP 21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ 26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR 31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+3 38) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+8 43) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13 48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12 53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-7 58) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-2 63) SIGRTMAX-1 64) SIGRTMAX Linux信号列表： SIGHUP 1: A 终端挂起或者控制进程终止 SIGINT 2: A 键盘中断（如break键被按下） SIGQUIT 3: C 键盘的退出键被按下 SIGILL 4: C 非法指令 SIGABRT 6: C 由abort(3)发出的退出指令 SIGFPE 8: C 浮点异常 SIGKILL 9: AEF Kill信号 SIGSEGV 11: C 无效的内存引用 SIGPIPE 13: A 管道破裂: 写一个没有读端口的管道 SIGALRM 14: A 由alarm(2)发出的信号 SIGTERM 15: A 终止信号 SIGUSR1 30,10,16: A 用户自定义信号1 SIGUSR2 31,12,17: A 用户自定义信号2 SIGCHLD 20,17,18: B 子进程结束信号 SIGCONT 19,18,25: 进程继续（曾被停止的进程） SIGSTOP 17,19,23: DEF 终止进程 SIGTSTP 18,20,24: D 控制终端（tty）上按下停止键 SIGTTIN 21,21,26: D 后台进程企图从控制终端读 SIGTTOU 22,22,27: D 后台进程企图从控制终端写 处理动作中的字母含义： A: 缺省的动作是终止进程 B: 缺省的动作是忽略此信号，将该信号丢弃，不做处理 C: 缺省的动作是终止进程并进行内核映像转储（dump core），内核映像转储是指将进程数据在内存的映像和进程在内核结构中的部分内容以一定格式转储到文件系统，并且进程退出执行，这样做的好处是为程序员 提供了方便，使得他们可以得到进程当时执行时的数据值，允许他们确定转储的原因，并且可以调试他们的程序。 D: 缺省的动作是停止进程，进入停止状况以后还能重新进行下去，一般是在调试的过程中（例如ptrace系统调用） E: 信号不能被捕获 F: 信号不能被忽略 \r\r","date":"2017-10-24","objectID":"/linuxshell/:124:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"which, whereis, file, whatis与平均负载 which hows the full path of (shell) commands。找出某个命令的位置; whereis locate the binary, source, and manual page files for a command。不仅返回命令路径，还能打印命令手册的位置以及命令源代码路径; file determine file type。用来确定文件类型; whatis display manual page descriptions。输出简短描述信息; 平均负载(load average),是系统运行总负载量的一个重要参数。它指明了系统中可运行进程总量的平均值。平均负载由三个值来指定，第一个指明1分钟内的平均值，第二个指明5分钟内的平均值，第三个指明15分钟内的平均值。 单核CPU，类似于单车道，负载在 0.00-1.00 之间正常； 多核CPU，类似于多车道，负载在 核数*(0.00-1.00) 之间正常； 安全的系统负载，单核应该在 0.7 以下； #查看平均负载 uptime cat /proc/loadavg #0.00 0.01 0.05 1/355 44955 #分母355表示系统进程总数, 分子表示正在运行的进程数, 最后一个数字表示最近运行进程ID \r","date":"2017-10-24","objectID":"/linuxshell/:125:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"向用户终端发送消息 系统管理员可能需要向网络中所有主机上的所有用户或特定用户的终端发送消息。 `wallrsync -av –exclude=\"*.s命令用来向所有当前登录用户的终端写入消息。 在Linux系统中，终端是作为设备存在的。因此那些打开的终端在dev/pts/中都会与对应的设备节点文件。向特定设备写入数据将会在对应的终端显示出消息。 echo \"It's just a test\" | wall #查看用户对应的/dev/pts/, 并向某一个用户终端发送信息 ll /dev/pts | awk '{print $3,$6}' echo\"Haha\" \u003e /dev/pts/[1,2,3...] \r","date":"2017-10-24","objectID":"/linuxshell/:126:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"收集系统信息 包括主机名、内核版本、Linux发行版本、CPU信息、内存信息、磁盘分区信息等。 #主机名 hostname uname -n #内核版本，架构 uname -r uname -m uname -a #Linux发行版本 cat /etc/redhat-release #CPU相关信息 lscpu cat /proc/cpuinfo cat /proc/cpuinfo | grep 'model name' #内存详细信息 free -h cat /proc/meminfo #分区信息 cat /proc/partitions fdisk -l #系统详细信息 lshw ","date":"2017-10-24","objectID":"/linuxshell/:127:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"用/proc收集信息 在GNU/Linux操作系统中，/proc是一个位于内存中的伪文件系统(in-memory pseudo filesystem)。 它的引用是为了提供一个可以从用户空间(user space)读取系统参数的接口。 可以对/proc中的文件和子目录进行cat来获取信息，所有内容都是易读的格式化文本。 /proc/下的数字目录，包含了对应进程的相关信息； /proc/environ，包含于进程相关联的环境变量； /proc/cwd，是一个到进程工作目录的符号链接； /proc/fbcat，包含了由进程所使用的文件描述符。 \r","date":"2017-10-24","objectID":"/linuxshell/:128:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"用cron进行调度 GNU/Linux系统包含了各种用于调度任务的工具。cron就是其中之一，它通过守护进程crond使得任务能够以固定的时间间隔在系统后台自动运行。 cron利用的是一个被称为“cron表(cron table)”的文件，这个文件中存储了需要执行的脚本或命令的调度列表以及执行时间。 #分 时 日 月 周 #* * * * * cmd #分钟(0-59) #小时(0-23) #天(1-31) #月(1-12) #工作日(0-7)，0和7都代表周天 #命令 #*号,所有值 #,号,范围。1,3,5,7,9 #-号,连续范文。1-10 #/号,*/10;0-8/20 #栗子 crontab -e * 0-6 * * * /home/zhang/test.sh 1,3,5,7,9 * * * * /home/zhang/test.sh */5 * * * * /home/zhang/test.sh #-l,查看cron表 crontab -l #-r,移除cron表 crontab -r ","date":"2017-10-24","objectID":"/linuxshell/:129:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"cron的高级写法 栗子： @reboot #在启动的时候运行一次 #其实@reboot类似于rc.local，开机启动 @yearly == @annually == 0 0 1 1 * #一年一次 @monthly == 0 0 1 * * #每月一次 @weekly == 0 0 * * 0 #每周一次 @daily == @midnight == 0 0 * * * #每天一次 @hourly == 0 * * * * #每小时一次 crontab -e @reboot /bin/mongod -f /etc/mongod_27018.conf vim /etc/rc.d/rc.local /bin/mongod -f /etc/mongod_27018.conf chmod a+x /etc/rc.d/rc.local ","date":"2017-10-24","objectID":"/linuxshell/:129:1","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"用户管理常用命令 #添加用户 useradd #删除用户 userdel --remove-all-file删除与用户相关的所有文件 #修改shell chsh #修改用户属性 usermod #修改密码过期时间 chage #修改密码 passwd #登录到一个新组 newgrp #添加、删除组 groupadd groupdel #指纹 finger \r \riptables和firewalld **firewalld与iptables比较: ** iptables与firewalld都不是真正的防火墙，它们都只是用来定义防火墙策略的防火墙管理工具而已。或者说，它们只是一种服务 firewalld可以动态修改单条规则，动态管理规则集，允许更新规则而不破坏现有会话和连接；iptables在修改了规则后必须得全部刷新才可以生效 firewalld使用区域和服务而不是链式规则 firewalld默认是拒绝的，需要设置以后才能放行；iptables默认是允许，需要拒绝的才去限制 firewalld自身并不具备防火墙的功能，而是和iptables一样需要通过内核的netfilter来实现。真正使用规则干活的是内核的netfilter firewalld是iptables的一个封装，可以让你更容易地管理iptables规则。它并不是iptables的替代品 firewalld拥有CLI和GUI的两种管理方式 \r\r","date":"2017-10-24","objectID":"/linuxshell/:130:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"firewalld ","date":"2017-10-24","objectID":"/linuxshell/:131:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"区域管理 通过将网络划分成不同的区域，制定出不同区域之间的访问控制策略来控制不同程序区域间传送数据流。 firewalld的默认区域是public区域。 九大区域： 阻塞区域（block） 任何传入的网络数据包都将被阻止 工作区域（work） 相信网络上的其他计算机，不会损害你的计算机 家庭区域（home） 相信网络上的其他计算机，不会损害你的计算机 公共区域（public） 不相信网络上的任何计算机，只有选择接受传入的网络连接 隔离区域（DMZ） 隔离区域也称为非军事区域，内外网络之间增加的一层网络，起到缓冲作用。对于隔离区域，只有选择接受传入的网络连接 信任区域（trusted） 所有的网络连接都可以接受 丢弃区域（drop） 任何传入的网络连接都被拒绝 内部区域（internal） 信任网络上的其他计算机，不会损害你的计算机。只有选择接受传入的网络连接 外部区域（external） 不相信网络上的其他计算机，不会损害你的计算机。只有选择接受传入的网络连接 firewalld有三种配置方法： firewll-config(GUI) firewall-cmd(CLI) 编辑XML配置文件 firewalld默认提供了九个区域的配置文件，它们位于/usr/lib/firewalld/zones: ls /usr/lib/firewalld/zones block.xml dmz.xml drop.xml external.xml home.xml internal.xml public.xml trusted.xml work.xml 常用命令: yum install firewalld firewall-config systemctl start firewalld firewall-cmd --version firewall-cmd --help #永久生效需加上 --permannent firewall-cmd xxx --permannent firewall-cmd --state #查看网络接口使用的区域 firewall-cmd --get-active-zones #查看指定区域的所有配置 firewall-cmd --zone=public --list-all #查看所有区域配置 firewall-cmd --list-all-zones #查看默认区域 firewall-cmd --get-default-zone #设置默认区域 firewall-cmd --set-default-zone=internal #查看指定接口所属区域 firewall-cmd --get-zone-of-interface=eth0 #将接口添加到区域，默认接口都在public firewall-cmd --zone=public --add-interface=eth0 #拒绝|开启 所有包 firewall-cmd --panic-on|off #查看是否拒绝 firewall-cmd --query-panic #无需断开连接更新防火墙规则 firewall-cmd --reload #类似于重启更新规则 firewall-cmd --complete-reload #查看所有打开的端口 firewall-cmd --zone=dmz --list-ports #加入一个端口的区域 firewall-cmd --zone=dmz --add-port=8080/tcp \r\r","date":"2017-10-24","objectID":"/linuxshell/:131:1","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"与服务一起使用 firewalld可以根据特定网络服务的预定义规则来允许相关流量。你可以自定义系统规则，并将它们添加到任何区域。 默认支持的服务的配置文件位置: /usr/lib/firewalld/services 创建的服务文件位置: /etc/firewalld/services cat /usr/lib/firewalld/service/elasticsearch.xml \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003cservice\u003e \u003cshort\u003eElasticsearch\u003c/short\u003e \u003cdescription\u003eElasticsearch is a distributed, open source search and analytics engine, designed for horizontal scalability, reliability, and easy management.\u003c/description\u003e \u003cport protocol=\"tcp\" port=\"9300\"/\u003e \u003cport protocol=\"tcp\" port=\"9200\"/\u003e \u003c/service\u003e 常用命令: #查看默认可用服务 firewall-cmd --get-services #永久启用或禁用HTTP服务 firewall-cmd --zone=区域 --(add|remove)-service=http --permanent #添加123456端口的tcp流量 firewall-cmd --zone=public --add-port=123456/tcp --permanent #将80端口的流量转发到123456端口 firewall-cmd --zone=public --add-forward-port=port=80:proto=tcp:toport=123456 \r","date":"2017-10-24","objectID":"/linuxshell/:131:2","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"iptables iptables/ip6tables — administration tool for IPv4/IPv6 packet filtering and NAT 切记谨慎使用iptables命令，特别是在远程连接的时候。 规则是有顺序的，规则的顺序很重要。当规则顺序排列错误时，会产生很严重的错误。 iptables --help -t\u003c表\u003e： 指定要操纵的表，默认为filter -P： 设置默认策略 -A \u003c链\u003e： 在规则链的末尾中添加条目 -I \u003c链\u003e： 在规则链的头部中插入条目 #请注意-A与-I，这两者的插入顺序是不一致的，-I顺序更高 -D \u003c链\u003e： 从规则链中删除条目 -R： 替换规则链中的条目 -L： 显示规则链中已有的条目 -F： 清楚规则链中已有的条目 -Z： 清空规则链中的数据包计算器和字节计数器 -X： 删除用户定义的链 -N： 创建新的用户自定义规则链 -p： 指定要匹配的数据包协议类型(tcp, udp, icmp...) -s： 指定要匹配的数据包源ip地址(ip/mask, !ip) -d： 匹配 目标地址 --sport： 匹配源端口号 --dport： 匹配目的端口号 -i\u003c网络接口\u003e： 指定数据包进入本机的网络接口 -o\u003c网络接口\u003e： 指定数据包要离开本机所使用的网络接口 -j target： 指定要跳转的目标 -m match： 扩展匹配 -g chain： jump to chain with no return \r\r","date":"2017-10-24","objectID":"/linuxshell/:132:0","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"表格/链/动作 为什么称为iptables? 因为此软件里面有多个表格(table)，每个表格定义了自己的默认策略和规则，且每个表格的用途都不相同。 表(Table) raw: 高级功能 mangle: 数据包修改 nat: 网络地址转换 PREROUTING POSTROUTING OUTPUT filter: 包过滤，是默认表 INPUT OUTPUT FORWARD 链(Chain) INPUT：处理输入数据包 OUTPUT：处理输出数据包 FORWARD：处理转发数据包 PREROUTING：用于目标地址转换(DNAT) POSTOUTING：用于源地址转换(SNAT) 动作(Action) ACCEPT： 接收数据包 DROP： 丢弃数据包 REJECT: 拒绝 REDIRECT： 重定向、映射、透明代理 SNAT： 源地址转换 DNAT： 目标地址转换 MASQUERADE： IP伪装（NAT），用于ADSL LOG： 日志记录 \r","date":"2017-10-24","objectID":"/linuxshell/:132:1","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"常用命令 #格式 iptables -t 表名 \u003c-A/I/D/R\u003e 规则链名 [规则号] \u003c-i/o 网卡名\u003e -p 协议名 \u003c-s 源IP/源子网\u003e --sport 源端口 \u003c-d 目标IP/目标子网\u003e --dport 目标端口 -j 动作 -A: 新增一条规则，在最后面 -I: 插入一条规则，如果没有指定顺序，默认变成第一条规则 --line-numbers： 显示规则行号 -i: 包所进入的那个网络接口 -o: 包所传出的那个网络接口 -p: 指定网络协议 -p tcp --syn(ack, rst) -p udp -p icmp -p all -s: 源IP或网段 -d: 目标IP或网段 -s 192.168.1.11 -d 192.168.1.0/24(192.168.1.0/255.255.255.0) -s !192.168.2.0/24 -j: 后接动作 #记录，此日志默认追加到messages -j LOG --log-prefix=‘IPTABLES-’ #端口号可以是连续的 --sport 1026:65535 --dport 80 -m: 一些iptables外部模块 -m state: 状态模块 -m mac: 网卡地址 --state: 数据包状态 --state INVALID： 无效的数据包 --state ESTABLISHED: 已建立连接 --state NEW: 想要新建连接的数据包 --state RELATED: 表示这个数据包是我们主机发送出去的 --mac-source: 源主机的硬件地址 清除防火墙规则: iptables [ -t tables ] [ -FXZ ] #清除所有已制定的规则 iptables -F #清除用户 \"自定义\" iptables -X #将所有链表的计数与流量统计都归零 iptables -Z #这三个命令会将本机防火墙的所有规则都清除，但却不会改变 默认策略 定义默认策略 --policy, -P iptables -P INPUT DROP iptables -P OUTPUT ACCESS iptables -P FORWARD ACCEPT 开放某个端口 #允许本地回环接口(即运行本机访问本机) iptables -A INPUT -s 127.0.0.1 -d 127.0.0.1 -j ACCEPT #允许已建立的或相关连的通行 iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT #针对网卡执行的放行和防御 iptables -A INPUT -m mac --mac--source aa:bb:cc:11:22:33 -j DROP #允许所有本机向外的访问 iptables -A OUTPUT -j ACCEPT #允许访问22端口 iptables -A INPUT -p tcp --dport 22 -j ACCEPT #允许访问80端口 iptables -A INPUT -p tcp --dport 80 -j ACCEPT # #禁止其他未允许的规则访问 iptables -A INPUT -j reject #禁止其他未允许的规则访问 iptables -A FORWARD -j REJECT 屏蔽IP #屏蔽单个IP的命令 iptables -I INPUT -s 123.45.6.7 -j DROP #封整个段即从123.0.0.1到123.255.255.254的命令 iptables -I INPUT -s 123.0.0.0/8 -j DROP 查看规则 #推荐使用iptables-save iptables-save #备份和恢复 iptables-save \u003e/etc/sysconfig/iptables iptables-restore \u003c/etc/sysconfig/iptables iptables -L -n iptables -L -n --line-numbers 删除已添加规则 iptables -L -n --line-numbers iptables -D INPUT 5 iptables -D OUTPUT 3 \r","date":"2017-10-24","objectID":"/linuxshell/:132:2","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["linux"],"content":"解决重启失效 iptables-save \u003e/etc/sysconfig/iptables #把此加入开机启动 iptables-restore \u003c/etc/sysconfig/iptables \r\r \r分屏显示 分屏有screen和tmux两个工具，我用的tmux，所以下面介绍tmux。 \rtmux(terminal multiplexer)，有以下几个特点: 可以开启多个会话(session) 一个会话可以开多个窗口(window) 一个窗口可以分为多个子窗口(subwindow) 多人复用一个会话，两人显示的内容一样，操作也会同步到会话界面上，也就是我能看到你的操作，你也能看到我的操作。 \r一些常用命令: # 会话相关 # 新建会话 tmux tmux new -s session_name # 显示所有会话 tmux ls # 接入会话 tmux attach -t session_name # 关闭会话 tmux kill-session -t session_name # 切换会话 tmux switch -t session_name # 重命名会话 tmux rename-session -t old_name new_name # tmux下ctrl + b 执行命令 # 帮助 ctrl + b 之后 ? # 命令模式 ctrl + b 之后 : # 新会话 ctrl + b 之后 :new # 列出所有会话，并跳转到会话 ctrl + b 之后 s # 断开当前会话 ctrl + b 之后 d # 重命名当前会话 ctrl + b 之后 $ # 在当前会话加一个窗口 ctrl + b 之后 c # 在一个会话的多个窗口中选择 ctrl + b 之后 w # 窗口操作 # 当前会话下窗口切分 # 垂直分割 ctrl +b 之后 % # 水平分割 ctrl + b 之后 \" # 窗口切换 # ctrl + b 之后 方向键(上下左右) ctrl + b 之后 o # 窗口关闭 # 或者exit也可以 ctrl + b 之后 x # 关闭此会话中的所有窗口 ctrl + b 之后 ! # 修改窗口大小 # 进入命令行模式 ctrl + b 之后 : # 上U, 下D, 左L, 右R # 可以直接使用方向键控制不同窗口大小 ctrl + b + 方向键(上下左右) # 当前窗口向左扩展10 resize-pane -L 10 # 当前窗口向右扩展10 resize-pane -R 10 # 当前窗口向上扩展10 resize-pane -U 10 # 当前窗口向下扩展10 resize-pane -D 10 \r多人复用一个会话是tmux的一个很强的功能。 # Alice在A地远程登录 # 新建一个会话 tmux new -s alice_bob # Bob在B地远程登录 # 查看tmux会话 tmux ls # 追加此会话 tmux attach -t alice_bob 此时两人共用一个会话，内容是共享的，都可以操作，彼此都能看见，这个很强了。 \r\r \r\r运维常见命令 以下命令来自：知乎-运维工程师技能-知道创宇的回答 \r I/O, Device: blktrace: 收集磁盘IO信息中当IO进行到块设备层时的详细信息 perf: 全称Performance Event，是用来进行软件性能分析的工具。它不但可以分析指定应用程序的性能问题，也可以用来分析内核的性能问题，当然也可以同时分析应用代码和内核，从而全面理解应用程序中的性能瓶颈。 iotop: 用来监视磁盘I/O使用状况的top类工具 iostat: 用于监视系统输入输出设备和CPU的使用情况。它的特点是汇报磁盘活动统计情况，同时也会汇报出CPU使用情况。同vmstat一样，iostat也有一个弱点，就是它不能对某个进程进行深入分析，仅对系统的整体情况进行分析。 Network: ping: 测试主机之间网络的连通性。执行ping指令会使用ICMP传输协议，发出要求回应的信息，若远端主机的网络功能没有问题，就会回应该信息，因而得知该主机运作正常。 ip: 来显示或操纵Linux主机的路由、网络设备、策略路由和隧道，是Linux下较新的功能强大的网络配置工具。 ifconfig: 配置和显示Linux内核中网络接口的网络参数。用ifconfig命令配置的网卡信息，在网卡重启后机器重启后，配置就不存在。要想将上述的配置信息永远的存的电脑里，那就要修改网卡的配置文件了。 dig: 域名查询工具，可以用来测试域名系统工作是否正常。 iftop: 实时流量监控工具,监控TCP/IP连接等,缺点就是无报表功能。 ifstat: 网络接口监测工具,比较简单看网络流量。 nload: 查看系统带宽 neghogs: 查看进程流量 ethtool: 检查网卡支持的带宽 tcpdump: 是一款sniffer工具，它可以打印所有经过网络接口的数据包的头信息 netstat: 打印Linux中网络系统的状态信息，可让你得知整个Linux系统的网络情况。 nicstat: 是一款分析网卡流量信息的工具 sar: 是Linux下系统运行状态统计工具，它将指定的操作系统状态计数器显示到标准输出设备。sar工具将对系统当前的状态进行取样，然后通过计算数据和比例来表达系统的当前运行状态。它的特点是可以连续对系统取样，获得大量的取样数据。取样数据和分析的结果都可以存入文件，使用它时消耗的系统资源很小。 /proc: 一个虚拟文件系统 FS: fdisk: 用于观察硬盘实体使用情况，也可对硬盘分区 du: 对文件和目录磁盘使用的空间的查看 df: 显示磁盘分区上的可使用的磁盘空间 Scheduler, VM: strace: strace命令是一个集诊断、调试、统计与一体的工具，我们可以使用strace对应用的系统调用和信号传递的跟踪结果来对应用进行分析，以达到解决问题或者是了解应用工作过程的目的。 vmstat: 显示虚拟内存状态，但是它可以报告关于进程、内存、I/O等系统整体运行状态。 slabtop: 以实时的方式显示内核slab缓冲区的细节信息 dstat: 是一个全能系统信息统计工具 free: 显示当前系统未使用的和已使用的内存数目，还可以显示被内核使用的内存缓冲区 perf: top: 实时动态地查看系统的整体运行情况，是一个综合了多方信息监测系统性能和运行信息的实用工具 pidstat: 用于监控全部或指定进程的cpu、内存、线程、设备IO等系统资源的占用情况 mpstat: 主要用于多CPU环境下，它显示各个可用CPU的状态 ","date":"2017-10-24","objectID":"/linuxshell/:132:3","tags":["Shell","Bash","Linux","Vim"],"title":"Shell","uri":"/linuxshell/"},{"categories":["programming"],"content":"参考: 维基百科: https://zh.wikipedia.org/wiki/YAML YAML: https://yaml.org/ YAML语法检测: http://www.yamllint.com \r\r \r\r概述 YAML: YAML Ain’t Markup Language. YAML is a human friendly data serialization standard for all programming languages. YAML（/ˈjæməl/，尾音类似camel骆驼）是一个可读性高，用来表达数据序列的格式。YAML是\"YAML Ain’t a Markup Language\"(YAML不是一种标记语言)的递归缩写。在开发的这种语言时，YAML的意思其实是：“Yet Another Markup Language”（仍是一种标记语言，但为了强调这种语言以数据做为中心，而不是以标记语言为重点，而用反向缩略语重命名。 YAML是专门用来写配置文件的语言，非常简洁和强大，远比JSON格式方便。 YAML的特点: YAML数据可在编程语言之间移植 包括数据一致的数据模型 人类易于阅读 支持单向处理 易于实现和使用 \r\r \r\r语法规则 基本语法规则如下： 大小写敏感 使用缩进表示层级关系 缩进时不允许使用Tab键，只允许使用空格 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可(一般2个或4个) #表示单行注释，不支持多行注释。多行注释请使用多个# 具有单个流的多个文档用3个连字符(---)分隔 阻止列表项包括与周围块级相同的缩进，因为-符号被视为缩进的一部分 \r\r \r\r格式 YAML支持三种格式： 对象：键值对的集合，又称为映射(mapping)/哈希(hashes)/字典(dictionary) 数组：一组按次序排列的值，又称为序列(sequence)/列表(list) 纯量值（scalars）：单个的、不可再分的值 #栗子- key1:value1- key2:value2#一个列表，两个对象，四个纯量 \r\r","date":"2017-09-02","objectID":"/yaml/:0:0","tags":["Yaml"],"title":"Yaml","uri":"/yaml/"},{"categories":["programming"],"content":"对象 对象是一组键值对，使用冒号结构表示。 key:vaule#Yaml也允许另一种写法，将所有键值对写成一个行内对象。hash:{name: Steve, foo:bar } \r\r","date":"2017-09-02","objectID":"/yaml/:1:0","tags":["Yaml"],"title":"Yaml","uri":"/yaml/"},{"categories":["programming"],"content":"数组 又称为列表或序列。 - list- sequence- array#数组也可以采用行内表示法。animal:[list, sequence, array] 数据结构的子成员是一个数组，则可以在该项下面缩进一个空格。 -- Cat- Dog- Goldfish \r\r","date":"2017-09-02","objectID":"/yaml/:2:0","tags":["Yaml"],"title":"Yaml","uri":"/yaml/"},{"categories":["programming"],"content":"纯量值 纯量是最基本的、不可再分的值。 －　字符串 －　布尔值 －　整数 －　浮点数 －　Null －　时间 －　日期 \r\r","date":"2017-09-02","objectID":"/yaml/:3:0","tags":["Yaml"],"title":"Yaml","uri":"/yaml/"},{"categories":["programming"],"content":"复合结构 对象和数组可以结合使用，形成复合结构。 languages:- Ruby- Perl- Pythonwebsites:YAML:yaml.orgRuby:ruby-lang.orgPython:python.orgPerl:use.perl.org \r\r \r\r特殊符号 ---: 表示文档开始；分割不同内容 ...和---的配合使用: 在一个配置文件中代表一个文件的结束 !!: 类型强行转换 \u003e: 在字符串中折叠换行 |: 保留换行符 引用 \u0026: 完成锚点定义 *: 完成锚点引用 合并内容: 主要和锚点配合使用，可以将一个锚点内容直接合并到一个对象中 #栗子---Time:2018-07-17T15:02:31+08:00User:edWarning:This is an error message for the log file---Time:2018-07-17T15:05:21+08:00User:edWarning:A slightly different error message. #栗子---time:20:03:20player:Sammy Sosaaction:strike (miss)...---time:20:03:47player:Sammy Sosaaction:grand slam... string:- !!str54321- !!strtrue ","date":"2017-09-02","objectID":"/yaml/:4:0","tags":["Yaml"],"title":"Yaml","uri":"/yaml/"},{"categories":["programming"],"content":"参考: Markdown-wiki Markdown官网 Markdown中文文档 Markdown语法 果冻虾仁 \r\r 关于 Markdown 是一种轻量级标记语言。 它允许人们使用易读易写的纯文本格式编写文档，然后转换成有效的XHTML(或者HTML)文档。 \r 语法 ","date":"2017-09-01","objectID":"/markdown/:0:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"首行缩进 #一个空格 \u0026ensp; #两个空格 \u0026emsp; #不断行空白格 \u0026nbsp; 栗子：  一个空格；  两个空格；  不断行空白格； ","date":"2017-09-01","objectID":"/markdown/:1:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"段落与换行 段落的前后必须是空行 空行是指行内什么都没有，或者只有空白符（空格或制表符） 相邻两行文本，如果中间没有空行，会显示在一行中（换行符被转换为空格） 如果需要在段内加入换行 可以在前一行的末尾加入至少两个空格，然后换行写其它的文字 Markdown中的多数区块都需要在两个空行之间 ","date":"2017-09-01","objectID":"/markdown/:2:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"粗体和斜体 语法： *斜体*, _斜体_ **粗体** ***粗斜体*** ~~删除线~~ 显示效果： 斜体, 斜体 粗体 粗斜体 删除线 \r","date":"2017-09-01","objectID":"/markdown/:3:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"分级标题 ","date":"2017-09-01","objectID":"/markdown/:4:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"Setext形式 大标题： 一级大标题 ======== 二级大标题 -------- ","date":"2017-09-01","objectID":"/markdown/:4:1","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"atx形式 普通标题： # 一级标题 ## 二级标题 ### 三级标题 #### 四级标题 ##### 五级标题 \r","date":"2017-09-01","objectID":"/markdown/:4:2","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"超链接 MarkDown支持两种形式的链接语法：行内式和参考式。 ","date":"2017-09-01","objectID":"/markdown/:5:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"行内式 语法说明： [ ] 里面写链接文字，( ) 里面写链接地址，()中的\" “可以指定title属性。 代码： 欢迎来到 [简书](www.jianshu.com \"Jianshu\") 效果： 欢迎来到 简书 ","date":"2017-09-01","objectID":"/markdown/:5:1","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"参考式 参考式超链接一般用在学术论文上面，或某一个链接在文章中多处使用，那么引用的方式创建链接将非常好，它可以让你对链接进行统一的管理。 语法说明： 参考式链接分为两部分，文中的写法[链接文字][链接标记]，在文本任意位置添加[链接标记]:链接地址 “链接标题”，链接地址与链接标题前有一个空格 如果链接文字本身可以作为链接标记，也可以写成[链接文字][] [链接文字]：链接地址的形式 代码： 简书里面有 [简书早报][1]、[简书晚报][2]以及 [简黛玉][3] [简黛玉 美人][3] 是一个[才女][] [1]:http://www.jianshu.com \"Jianshu\" [2]:http://www.jianshu.com \"EveningPaper\" [3]:http://www.jianshu.com [才女]:http://www.jianshu.com 效果： 简书里面有 [简书早报][1]、[简书晚报][2]以及[简黛玉][3] [简黛玉 美人][3] 是一个[才女][] [1]:http://www.jianshu.com “Jianshu” [2]:http://www.jianshu.com “EveningPaper” [3]:http://www.jianshu.com [才女]:http://www.jianshu.com ","date":"2017-09-01","objectID":"/markdown/:5:2","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"自动链接 MarkDown支持以比较简短的自动链接形式来处理网址和电子邮件，只要用\u003c\u003e包起来，MarkDown就会自动把它转成链接。 代码： \u003chttp://example.com\u003e \u003caddress@example.com\u003e ","date":"2017-09-01","objectID":"/markdown/:5:3","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"锚点 MarkDown Extra只支持在标题后插入锚点，其他地方无效。 锚点中的标题如果有空格，则锚点无效。 现在的锚点支持中文标题。 代码： 锚点连接页内标题 [标题一](#Title1) [标题二](#Title2) [标题三](#标题3) # Title1 ## Title2 ### 标题3 \r","date":"2017-09-01","objectID":"/markdown/:6:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"列表 ","date":"2017-09-01","objectID":"/markdown/:7:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"无序列表 使用 * ，+ ，- 表示无序列表 代码： - 无序列表1 - 无序列表2 - 无序列表3 效果： 无序列表1 无序列表2 无序列表3 \r","date":"2017-09-01","objectID":"/markdown/:7:1","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"有序列表 有序列表使用数字接着英文点 代码： 1. 有序列表1 2. 有序列表2 3. 有序列表3 效果： 有序列表1 有序列表2 有序列表3 ","date":"2017-09-01","objectID":"/markdown/:7:2","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"定义型列表 定义型列表由名词和解释组成。一行写上定义，紧跟一行写上解释。解释的写法：紧跟一个缩进（Tab） ","date":"2017-09-01","objectID":"/markdown/:7:3","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"列表缩进 列表项目标记通常是放在最左边，但是其实也可以缩进，最多3个空格，项目标记后则一定要接着至少一个空格或制表符。 代码： * 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。 那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 * 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 效果： 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。 那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 那榆荫下的一潭， 不是清泉， 是天上虹； 揉碎在浮藻间， 沉淀着彩虹似的梦。 ","date":"2017-09-01","objectID":"/markdown/:7:4","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"引用 引用需要在被引用的文本前加上\u003e符号 代码： \u003e 引用1 \u003e 引用2 效果： 引用1 引用2 ","date":"2017-09-01","objectID":"/markdown/:8:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"引用的多层嵌套 区块引用可以嵌套（如引用的引用），只要根据层次加上不同数量的 \u003e符号 代码： \u003e\u003e\u003e 请问MarkDown怎么用？ \u003e\u003e 自己看教程！ \u003e 教程在哪里？ 效果： 请问MarkDown怎么用？ 自己看教程！ 教程在哪里？ ","date":"2017-09-01","objectID":"/markdown/:8:1","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"插入图像 图片的创建方式与超链接类似。 代码： ![](http://zhangxx5678.lofter.com/post/39b969_df4f526#) ","date":"2017-09-01","objectID":"/markdown/:9:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"内容目录 在段落中填写 [TOC] 以显示全文内容结构目录 \r","date":"2017-09-01","objectID":"/markdown/:10:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"注脚 在需要添加注脚的文字后加上注脚名字 [^注脚名字]，称为加注。然后在文中的任意位置（一般最后）添加脚注，脚注前必须有对应的脚注名字。 注脚与注脚间必须空一行！ 注脚自动被搬运到最后面，请到文章末尾查看，并且脚注后的链接可以直接跳转会到加注的地方 代码： 使用 MarkDown[^1]可以提高书写效率，直接转换成 HTML[^2] [^1]:MarkDown是一种纯文本标记语言 [^2]:HTML超文本标记语言 效果： 使用 MarkDown1可以提高书写效率，直接转换成 HTML2 \r","date":"2017-09-01","objectID":"/markdown/:11:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"分割线 可以在一行中用 三个以上的 *,-,_ 建立一个分割线，行内不能有其他东西。 代码： 1. * * * 2. 3. *** 4. 5. - - - 6. 7. --- 效果： ","date":"2017-09-01","objectID":"/markdown/:12:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"GitHub中的表情 Github的Markdown语法支持添加emoji表情，输入不同的符号码（两个冒号包围的字符）可以显示出不同的表情。 比如😊,显示效果为 😊 每个表情对应的符号码：https://www.webpagefx.com/tools/emoji-cheat-sheet/ 或者，果冻虾仁的整理：https://github.com/guodongxiaren/README/blob/master/emoji.md ","date":"2017-09-01","objectID":"/markdown/:13:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"Diff语法 版本控制系统中都少不了diff功能——展示一个文件内容的增加与删除。 绿色(+)表示新增 红色(-)表示删除 语法效果与代码高亮类似，在三个反引号后面写上diff。在内容中+表示新增，-表示删除。 + 111 + 11 + 1 - 222 - 22 - 2 扩展语法 Markdown标准 本身所包含的功能有限，所以产生了许多第三方扩展语法，如 GFW, GitHub Flavored Markdown ","date":"2017-09-01","objectID":"/markdown/:14:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"Tasklist 代码： - [ ] Monday - [ ] Tuesday - [ ] Wednesday - [ ] Tuesday - [ ] Friday 效果： Monday Tuesday Wednesday Tuesday Friday \r","date":"2017-09-01","objectID":"/markdown/:15:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"表格 不管是哪种方式，第一行为表头，第二行为分割表头和主体部分，第三行开始每一行为一个表格行 列与列之间用管道符号 | 隔开 还可设置对齐方式 左对齐 :| 右对齐 |: 中对齐 :|: 代码： 学号 | 姓名 | 分数 - | - | - 001 | 张三 | 78 002 | 李四 | 67 003 | 王五 | 99 学号 | 姓名 | 分数 | - | - 001 | 张三 | 78 002 | 李四 | 67 003 | 王五 | 99 \r","date":"2017-09-01","objectID":"/markdown/:16:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"GitHub上的表格 GitHub上的表格与上有一点不同。 | 学号 | 姓名 | 分数 | - | - | - | 001 | 张三 | 78 | 002 | 李四 | 67 | 003 | 王五 | 99 学号 姓名 分数 001 张三 78 002 李四 67 003 王五 99 ","date":"2017-09-01","objectID":"/markdown/:17:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"代码块和高亮 ","date":"2017-09-01","objectID":"/markdown/:18:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"代码块 插入代码的方式有两种，一种是利用缩进(Tab)，另一种是利用反引号 `` 和 ``` ``` 代码： Python语言的输出函数 `Print()` 怎么使用？ 效果： Python语言的输出函数 Print() 怎么使用？ import os from flask import Flask app = Flask(app) ","date":"2017-09-01","objectID":"/markdown/:18:1","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"高亮 在 ``` 之后添加代码的语言 代码： ```python import os from flask import Flask app = Flask(app) ``` 效果： import os from flask import Flask app = Flask(app) \r","date":"2017-09-01","objectID":"/markdown/:18:2","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"流程图 flow chart/flow diagram，需要安装额外的插件才能支持流程图。 流程图语法参考: https://mermaidjs.github.io/ Hexo Plugins: https://hexo.io/plugins/ hexo默认好像不支持流程图，需要在hexo Plugins去查找此类插件，安装此类插件，然后修改hexo配置文件。 具体的使用方法请参考插件说明。 ","date":"2017-09-01","objectID":"/markdown/:19:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"数学公式 参考: https://blog.csdn.net/lanxuezaipiao/article/details/44341645 https://juejin.im/post/5a6721bd518825733201c4a2 LaTex数学符号表 LaTEX: https://zh.wikipedia.org/wiki/LaTeX 是一种跨平台的基于TEX的排版系统，对于生成复杂表格和数学公式，这一点表现得尤为突出。 因此它非常适用于生成高印刷质量的科技和数学、化学类文档。 MathJax: https://en.wikipedia.org/wiki/MathJax MathJax是一种跨浏览器JavaScript库，它使用MathML，LaTeX和ASCIIMathML 标记在Web浏览器中显示数学符号。 MathJax作为Apache License下的开源软件。 MathJax语法: https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference 由于许多支持markdown的都不会显示LaTeX公式，所以有一个加载链接来显示的效果。 参考知乎: https://www.zhihu.com/question/26887527 #如 ![](http://latex.codecogs.com/gif.latex?\\\\frac{1}{1+sin(x)}) #后接具体的公司，注意转移 \r","date":"2017-09-01","objectID":"/markdown/:20:0","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"公式 许多扩展的Markdown编辑器支持基于Mathjax编写的数学公式。 LaTeX有两种数学公式： 行内式 与其它文字混杂。 这是一个$行内式$栗子 块级公式 单独成行。 $$块级公式$$ 栗子： 这是一个$E=mc^2$公式 $$\\sum_{i=1}^n a_i=0$$ $$f(x_1,x_x,\\ldots,x_n) = x_1^2 + x_2^2 + \\cdots + x_n^2 $$ $$\\sum^{j-1}_{k=0}{\\widehat{\\gamma}_{kj} z_k}$$ \r\r","date":"2017-09-01","objectID":"/markdown/:20:1","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"基本类型 上/下标 分式 根式 求和 积分 矩阵 数组 空格 省略号 矢量 括号 希腊字母 \r上下标 上标(superscript): ^ 下标(subscript): _ 如果上小标内容大于一个字符，要用{} 虽然空格和顺序对公式没有影响，但建议使用统一的风格，不用混用： 先下标后上标 先上标后下标 #上标 $$E=mc^2$$ #下标 $$x_2$$ #上下标 $$x_{subscript} ^{superscript}$$ #左右上下标 $${}_{a} ^{b} x ^{c} _{d}$$ $${}_{左下} ^{左上} x ^{右上} _{右下}$$ #空格和顺序其实没影响 \r分式 分式(fraction) 为了区分frac是函数不是公式，使用\\frac进行转义 #用法 $$\\frac{分子}{分母}$$ $$\\frac{x+y} {2}$$ $$\\frac{1} {1+\\frac{1} {2}} \r根式 开方(sqrt) 使用\\sqrt转义 #默认为开平方 $$\\sqrt[开方次数]{开方因子}$$ $$\\sqrt {x}$$ $$\\sqrt[3] {\\frac{x} {y}}$$ $$\\sqrt[x] {1+\\sqrt[y] {1+a^2}}$$ \r求和 求和(summation) 使用\\sum转义 #用法 $$\\sum_{起点}^{终点}表达式$$ $$\\sum_{i=0} ^{n} \\frac{1} {k}$$ $$\\sum_{i=0}^{n} i^2=\\frac{(n^2+n)(2n+1)} {6}$$ \r积分 积分(integral) 使用\\int转义 #用法 $$\\int_{下限}^{上限} 被积函数d被积量$$ $$\\int_{a}^{b} f(x)dx$$ \r矩阵 矩阵(matrix) #\u0026区分行间元素 #\\\\\\\\代表换行 #无括号矩阵 $$\\begin{matrix}1 \u0026 2 \\\\\\\\ 3 \u0026 4 \\end{matrix}$$ #花括号矩阵 $$\\begin{pmatrix} 1\u00262 \\\\\\ 3\u00264 \\end{pmatrix}$$ #中括号矩阵 $$\\begin{bmatrix} 1\u00262 \\\\\\\\ 3\u00264 \\end{bmatrix}$$ #大括号矩阵 $$\\begin{Bmatrix} 1\u00262 \\\\\\\\ 3\u00264 \\end{Bmatrix}$$ #竖线矩阵 $$\\begin{vmatrix} 1\u00262 \\\\\\\\ 3\u00264 \\end{vmatrix}$$ #双竖线矩阵 $$\\begin{Vmatrix} 1\u00262 \\\\\\\\ 3\u00264 \\end{Vmatrix}$$ \r\r数组 数组(array) \r\r空格 空格(space/blank) #紧贴 $$a\\!b$$ #正常 $$ab$$ #小空格 $$a\\,b$$ #中空格 $$a\\;b$$ #大空格 $$a\\ b$$ #quad空格 $$a\\quad b$$ #两个quad空格 $$a\\qquad b$$ \r\r省略号 省略号(ellipsis) \\ldots 与文本底线对齐的省略号 cdots 与文本中线对齐的省略号 #\\ldot, \\cdot可表示单个点，对齐方式不变 $$f(x_1,x_2,\\ldots,x_n) = x_1^2 + x_2^2 + \\cdots + x_n^2$$ \r\r矢量 矢量(vector) #用法 $$\\vec{矢量值}$$ $$\\vec{a}$$ $$\\vec{a} \\cdot \\vec{b}=0$$ \r\r括号 括号(bracket) (), [], |可以直接表示，而{}本来是用于分组，因此需要转义\\{\\}来表示，也可使用\\lbrace, \\rbrace来表示。 原始括号并不会随着公式大小缩放，需要使用\\left和\\right标记实现自适应调整，它两必须成对出现。 #小括号() $$(\\frac{1}{2})$$ $$\\left( \\frac{1}{2} \\right)$$ #中括号[] $$[\\frac{1}{2}]$$ $$\\left[ \\frac{1}{2} \\right]$$ #绝对值| $$|\\frac{1}{2}|$$ $$\\left| \\frac{1}{2} \\right|$$ #大括号{} $$\\{ \\frac{1}{2} \\}$$ $$\\left\\{ \\frac{1}{2} \\right\\}$$ #尖括号\u003c\u003e #\\langle \\rangle $$\\langle \\frac{1}{2} \\rangle$$ $$\\left\\langle \\frac{1}{2} \\right\\rangle$$ #向正无穷大取整(ceil) $$\\lceil \\frac{1}{2} \\rceil$$ $$\\left\\lceil \\frac{1}{2} \\right\\rceil$$ #向下取整 $$\\lfloor \\frac{1}{2} \\rfloor$$ $$\\left\\lfloor \\frac{1}{2} \\right\\rfloor$$ \r\r","date":"2017-09-01","objectID":"/markdown/:20:2","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"希腊字母 | 大写 | LaTex代码 | 小写 | LaTex代码 | 中文名称 | | - | - | - | - | | A | A | α | \\alpha | 阿尔法 | | B | B | β | \\beta | 贝塔 | | Γ | Γ | γ | \\gamma | 伽马 | | D | D | δ | \\delta | 德尔塔 | | E | E | ϵ | \\epsilon | 伊普西隆 | | Z | Z | ζ | \\zeta | 泽塔 | | H | H | η | \\eta | 伊塔 | | Θ | Θ | θ | \\theta | 西塔 | | I | I | ι | \\iota | 约塔 | | K | K | κ | \\kappa | 卡帕 | | Λ | Λ | λ | \\lambda | 兰姆达 | | M | M | μ | \\mu | 缪 | | N | N | ν | \\nu | 纽 | | X | X | ξ | \\xi | 克西 | | O | O | ο | \\omicron | 欧米克隆 | | P | P | π | \\pi | 派 | | R | R | ρ | \\rho | 柔 | | Σ | Σ | σ | \\sigma | 西格玛 | | T | T | τ | \\tau | 陶 | | Υ | Υ | υ | \\upsilon | 宇普西隆 | | Φ | Φ | ϕ | \\phi | 弗爱 | | X | X | χ | \\chi | 卡 | | Ψ | Ψ | ψ | \\psi | 普赛 | | Ω | Ω | ω | \\omega | 欧米伽 | $$\\alpha$$ $$\\beta$$ $$\\gamma$$ $$\\delta$$ \r\r","date":"2017-09-01","objectID":"/markdown/:20:3","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["programming"],"content":"特殊符号 关系运算符 集合运算符 对数运算符 三角运算符 微积分运算符 逻辑运算符 带帽符号 连线符号 箭头符号 \r关系运算符 ±：\\pm ×：\\times ÷：\\div ∣：\\mid ∤：\\nmid ⋅⋅：\\cdot ∘：\\circ ∗：\\ast ⨀：\\bigodot ⨂：\\bigotimes ⨁：\\bigoplus ≤：\\leq ≥：\\geq ≠：\\neq ≈：\\approx ≡：\\equiv ∑：\\sum ∏：\\prod ∐：\\coprod \r集合运算符 ∅ ：\\emptyset ∈：\\in ∉：\\notin ⊂：\\subset ⊃：\\supset ⊆：\\subseteq ⊇：\\supseteq ⊇：\\bigcap ⋃：\\bigcup ⋁：\\bigvee ⋀：\\bigwedge ⨄：\\biguplus ⨆：\\bigsqcup \r对数运算符 log：\\log lg：\\lg ln：\\ln \r三角运算符 ⊥ ：\\bot ∠：\\angle 30∘：30^\\circ sin：\\sin cos：\\cos tan：\\tan cot：\\cot sec：\\sec csc：\\csc \r微积分运算符 ′：\\prime ∫：\\int ∬：\\iint ∭：\\iiint ∬∬：\\iiiint ∮：\\oint lim：\\lim ∞：\\infty ∇：\\nabla \r逻辑运算符 ∵ ：\\because ∴：\\therefore ∀：\\forall ∃：\\exists ≠：\\not= ≯：\\not\u003e ⊄：\\not\\subset \r戴帽符号 y^ ：\\hat{y} yˇ：\\check{y} y˘：\\breve{y} \r箭头符号 ↑ ：\\uparrow ↓：\\downarrow ⇑：\\Uparrow ⇓：\\Downarrow →：\\rightarrow ←：\\leftarrow ⇒：\\Rightarrow ⇐：\\Leftarrow ⟶：\\longrightarrow ⟵：\\longleftarrow ⟹：\\Longrightarrow ⟸：\\Longleftarrow \r\r 生成GitHub上的徽章 生成徽章: https://shields.io/ 生成进度： https://github.com/fehmicansaglam/progressed.io 进入徽章(Badge)网站，找到如下部分生成徽章。之后会得到一个徽章地址，在GitHub中插入此徽章地址就好。 进入进度(Progress)网站，找到某个格式的链接，在GitHub中插入此链接。 \r\r \r编辑器 介绍一些常用的书写、编辑Markdown的工具。 MarkdownPad Windows (windows); Texts (Windows, osX); MarkPad (Windows); Haroopad (Windows, osX, Linux); ReText (Linux); 等等 \r 格式转换 Markdown文档可以方便地转换为 HTML, Word, PDF 等文件格式。 可以利用 软件 或者 命令 转换文件。 转换为 HTML 转换为 PDF 转换为 Word MarkDown是一种纯文本标记语言 ↩︎ HTML超文本标记语言 ↩︎ ","date":"2017-09-01","objectID":"/markdown/:20:4","tags":["markdown"],"title":"Markdown","uri":"/markdown/"},{"categories":["linux"],"content":"参考： Nginx官方文档 Nginx-Wikipedia Nginx-repo 环境： CentOS7x86_64; Nginx1.12.1 \r\r \rNginx介绍 Nginx（发音同engine x）是一个 Web服务器，也可以用作反向代理，负载平衡器和 HTTP缓存。它能反向代理 HTTP, HTTPS, SMTP, POP3, IMAP 的协议连接。 基于BSD-like协议发行，支持多种操作系统。 作为HTTP服务软件的后起之秀，Nginx有很多优点： 在性能上，Nginx占用的系统资源更少，支持更多的并发连接（特别是小静态文件场景下），达到更高的访问效率； 在功能上，Nginx不仅是一个优秀的Web服务软件，还可以作为反向代理 负载均衡及缓存使用。它类似于LVS负载均衡及HAProxy等专业代理软件，又类似于Squid等专业缓存服务软件； 在安装配置上，Nginx方便、简单、灵活。 Nginx功能丰富，可作为HTTP服务器、反向代理服务器、邮件服务器。支持FastCGI, SSL, Virtual Host, URL Rewrite, Gzip等功能，并支持很多第三方模块扩展。 \r","date":"2017-09-01","objectID":"/nginx/:0:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"与PHP的集成 自PHP-5.3.3起，PHP-FPM加入到了PHP核心，编译时加上–enable-fpm即可提供支持。 PHP-FPM以守护进程在后台运行，Nginx响应请求后，自行处理静态请求，PHP请求则经过fastcgi_pass交由PHP-FPM处理，处理完毕后返回。 Nginx和PHP-FPM的组合，是一种稳定、高效的PHP运行方式，效率要比传统的Apache和mod_php高出不少。 Nginx的重要特性： 可针对静态资源高速高并发访问及缓存； 可使用反向代理加速，并且可进行数据缓存； 具有简单负载均衡、节点健康检查和容错功能； 支持远程FastCGI、Uwsgi、SCGI、Memcached Servers的加速和缓存； 支持SSL、TLS、SNI； 具有模块化的架构：过滤器包括gzip压缩、ranges支持、chunked响应、XSLT、SSI及图像缩放等功能。在SSI过滤器中，一个包含多个SSI的页面，如果FastCGI或反向代理处理，可被并行处理； 它具备的其他WWW服务特性： 支持基于名字、端口及IP的多虚拟主机站点； 支持Keep-alived和pipelined连接； 可进行修改Nginx配置，并且在代码上线时，可平滑重启，不中断业务访问； 可自定义访问日志格式，临时缓冲些日志操作，快速日志轮询及通过rsyslog处理日志； 可利用信号控制Nginx进程； 支持 3xx-5xx HTTP状态码重定向； 支持rewrite模块，支持URI重写及正则表达式匹配； 支持基于客户端IP地址和HTTP基本认证的访问控制； 支持PUT、DELETE、MKCOL、COPY及MOVE等较特殊的HTTP请求方法； 支持FLV流和MP4流技术产品应用； 支持HTTP响应速率限制； 支持同一IP地址的并发连接或请求数连接； 支持邮件服务器代理； ","date":"2017-09-01","objectID":"/nginx/:1:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"Nginx常用功能 ","date":"2017-09-01","objectID":"/nginx/:2:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"http代理于反向代理 Nginx在做反向代理时，提供性能稳定，并且能够提供配置灵活的转发功能。Nginx可以根据不同的正则匹配，采取不同的转发策略，比如图片文件结尾的走文件服务器，动态页面走web服务器，只要你正则写的没问题，又有相对应的服务器解决方案，你就可以随心所欲的玩。并且Nginx对返回结果进行错误页跳转，异常判断等。如果被分发的服务器存在异常，他可以将请求重新转发给另外一台服务器，然后自动去除异常服务器。 \r","date":"2017-09-01","objectID":"/nginx/:2:1","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"负载均衡 Nginx提供的负载均衡策略有2种：内置策略和扩展策略。内置策略为轮询，加权轮询，Ip hash。扩展策略，就天马行空，只有你想不到的没有他做不到的啦，你可以参照所有的负载均衡算法，给他一一找出来做下实现。 ","date":"2017-09-01","objectID":"/nginx/:2:2","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"web缓存 Nginx可以对不同的文件做不同的缓存处理，配置灵活，并且支持FastCGI_Cache，主要用于对FastCGI的动态程序进行缓存。配合着第三方的ngx_cache_purge，对制定的URL缓存内容可以的进行增删管理。 ","date":"2017-09-01","objectID":"/nginx/:2:3","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"web服务 Nginx作为Web服务器的主要应用场景包括： 使用Nginx运行HTML、JS、CSS、小图片等静态数据； 结合FastCGI运行PHP等动态程序（如fastcgi_pass）； 结合Tomcat/Resin等支持Java动态程序（如proxy_pass）。 \r Nginx安装 ","date":"2017-09-01","objectID":"/nginx/:2:4","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"RPM源安装: yum install -y gcc gcc-c++ make libtool zlib zlib-devel openssl openssl-devel pcre pcre-devel 安装依赖 rpm -ivm http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm 安装RPM源 #安装Nginx yum install -y nginx #查询安装 rpm -q nginx ","date":"2017-09-01","objectID":"/nginx/:3:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"添加Nginx yum repository安装 vim /etc/yum.repos.d/nginx.repo #必须唯一 [nginx] name=nginx-repo baseurl=http://nginx.org/packages/$OS/$OSRELEASE/$basearch/ gpgcheck=0 enabled=1 ","date":"2017-09-01","objectID":"/nginx/:4:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"源码安装 #建议解压于此目录 cd /usr/local/src wget http://xxx.xx.com/nginx.tar.gz tar -zxvf nginx.tar.gz cd ./nginx ./configure --prefix=/usr/local make\u0026\u0026make install \rNginx配置 ","date":"2017-09-01","objectID":"/nginx/:5:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"*.conf Nginx配置文件主要分为四部分： main(全局设置)； server(主机设置)； upstream(上游服务器设置)，用于反向代理和负载均衡； location(URL匹配特定位置)。 栗子： 运行nginx -t检查配置文件有误错误，这很重要! #main块 user nginx; worker_processes 4; client_max_body_size 10M error_log /var/log/nginx/error.log warn; pid /var/run/nginx.pid; events { worker_connections 102400; } #http块 http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - ...'; access_log /var/log/nginx/access.log main; sendfile on; gzip on; keepalive_timeout 60; include /etc/nginx/conf.d/*.conf; #upstream块 upstream up_name{ server ip1; server ip2:port; server domain; } server { server_name www.zhang21.cn; listen 80; listen 443; ssl on; ssl_certificate /dir/path/xxx.crt; ssl_certificate_key /dir/path/xxx.key; location / { root /var/www/zhang; index index.php index.html index.htm; allow 192.168.1.0/22; deny all; } location ~ \\.php$ { root /var/www/zhang; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; } } } 全局块： 配置影响Nginx全局的指令。一般由运行Nginx服务器的用户组，Nginx进程pid存放路径，日志存放路径，允许生成的worker_processes等。 events块： 配置影响Nginx服务器或与用户的网络连接。有每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网络连接，开启多个网络连接序列化等。 http块： 可以嵌套多个server，配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置。如文件引入，mime-type定义，日志自定义，是否使用sendfile传输文件，链接超时时间，单连接请求数等。 server块： 配置虚拟主机的相关参数，一个http中可以有多个server。 location块： 配置请求的路由，以及各种页面的处理情况。 \rNginx http功能模块 | 模块说明 | - ngx_http_core_module | 一些核心的http参数配置，对应Nginx的配置中的http块 ngx_http_access_module | 访问控制模块，用来控制网站用户对Nginx的访问 ngx_http_gzip_module | 压缩模块，对Nginx返回的数据压缩，属于性能优化模块 ngx_http_fastcgi_module | FastCGI模块，和动态应用相关的模块，如PHP ngx_http_proxy_module | proxy代理模块 ngx_http_upstream_module | 负载均衡模块，可实现网站的负载均衡及节点的监控检查 ngx_http_rewrite_module | URL重写模块 ngx_http_limit_conn_module | 限制用户并发连接数及请求数模块 ngx_http_limit_req_module | 根据定义的key限制Nginx请求过程的速率 ngx_http_log_module | 访问日志模块，以指定的格式记录Nginx访问信息 ngx_http_auth_basic_module | web认证模块，设置通过账号，密码访问Nginx ngx_http_ssl_module | ssl模块 ngx_http_stub_status_module | 记录Nginx基本访问状态信息扥的模块 \rNginx的日志时自动切割，并且一行可以记录多个日志格式。 Nginx日志格式 | 说明 | - $remote_addr | 客户端ip地址 $http_x_forward_for | 当前端有代理服务器时，设置web节点记录web节点记录客户端地址的配置 $remote_user | 客户端用户名称 $time_local | 访问时间和时区 $request | 请求的http协议和URL $status | 请求状态，如200 $body_bytes_sent | 发送给客户端文件主体内容大小 $http_referer | 从哪个页面链接访问过来 $http_user_agent | 客户端浏览器信息 \r","date":"2017-09-01","objectID":"/nginx/:6:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"server http服务上支持若干虚拟主机。每个虚拟主机对应一个server配置项，配置项里面包含该虚拟主机的相关配置。每个server里面可同时有多个server_name。 在提供mail代理服务时，也可建立若干server，每个server通过监听地址或端口来区分。 #监听端口，默认80 listen 80; listern 443; #listen 88 server_name www.zhang21.cn \r","date":"2017-09-01","objectID":"/nginx/:7:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"location location是http服务中，某些特定的URL对应的一系列配置项。 root 定义此location的根目录位置，一般放置在server里 index 定义路径下的默认访问的文件名 location / { root /dir/path; index index.html index.htm; } ","date":"2017-09-01","objectID":"/nginx/:8:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"location的正则写法 location的使用方法： 符号 | 含义 | 优先级 | 用法 | - | - | - = | 精确匹配 | 最高 | location = ~ | 区分大小写的正则匹配 | 次次之 | location ~ ~* | 不区分大小写的正则匹配 | 次次之 | location ~* ^~ | 常规字符串匹配 | 次之 | location ^~ / | 通用匹配 | 最低 | location / 优先级： = \u003e 完整路径 \u003e ^~ \u003e ~, ~* \u003e 部分路径 \u003e / ","date":"2017-09-01","objectID":"/nginx/:8:1","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"location使用建议 location的使用根据实际情况来定。 但个人觉得至少应该有三个匹配规则： 直接匹配网站跟，通过域名访问网站首页比较频繁 处理静态文件请求，这是Nginx作为http服务器的强项 通用规则，用来转发动态请求到后端的应用服务器(符php-fpm) 根据实际情况的自定义需求 server { listen 80; listen 443; server_name zhang21.cn www.zhang21.cn; root /dir/path/zhang; ssl on; ssl_certificate /etc/nginx/ssl/zhang.crt; ssl_certificate_key /etc/nginx/ssl/zhang.key; #rewtire ^(.*)$ https://zhang21.cn/$1 permanent; return 301 https://zhang21.cn/$requets_uri location = / { rewrite .*? /index.html last; } location ^~ /static/ { root /dir/path/zhang/static; } location ~* \\.(gif|jpg|png|css|js)$ { root /dir/path/zhang/static; } location / { if (!-f $request_filename) { rewrite ^([^\\?]+)$ /index.php?q=$1 last; } location ~ \\.php$ { root /dir/path; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; include fastcgi_params; } } \r","date":"2017-09-01","objectID":"/nginx/:8:2","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"Rewrite Nginx的主要功能是实现URL地址重写。Nginx的rewrite规则需要PCRE软件的支持，即通过Perl兼容正则表达式语法进行规则匹配。 Nginx rewrite语法： server, location, if rewrite regex replacement [flag] rewrite的功能就是，使用Nginx提供的全局变量或自定义变量，结合正则表达式(re)和标志位实现URL重写以及重定向 rewrite只能放在server，location，if中，并且只能对域名后边的除去传递的参数外的字符串起作用 如果相对域名或参数字符串起作用，可以使用全局变量匹配，也可使用proxy_pass反向代理 表面看rewrite和location功能有点像，都能实现跳转。主要区别在于： rewrite实在同一域名内更改获取资源的路径 location是对一类路径做访问控制或反向代理，可proxy_pass到其它机器 循环超多10次，返回500 Internal Server Error! ","date":"2017-09-01","objectID":"/nginx/:9:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"flag last 表示完成rewrite，继续向下匹配新的规则 break 停止执行当前虚拟主机的后续rewrite指令集 redirect 返回302临时重定向，地址栏会显示跳转后的地址 permanent 返回301永久重定向，地址栏会显示跳转后的地址 last和break用来实现URL重写，浏览器地址栏的URL地址不变，但在服务器端访问的程序及路径发生了变化 redirect和permanent用来实现URL跳转，浏览器地址栏会显示跳转后的URL地址 Nginx的rewrite功能应用非常广泛： 可调整用户浏览的URL，使其看起来更规范 将动态URL地址伪装成静态地址提供服务 让旧域名跳转到新域名上 根据特殊变量、目录、客户端的信息进行URL跳转 ","date":"2017-09-01","objectID":"/nginx/:9:1","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"if指令 if语法： if (condition) { xxx; } if的条件可以是如下内容： 当表达式只是一个变量时，如果值为空或任何以0开头的字符串都会被当作false 直接比较变量和内容时，使用**=**或**!=** **~正则表达式匹配，~*不区分大小写的正则匹配，!~**不匹配 -f和**!-f**，用来判断是否存在文件 -d和**!-d**，用来判断是否存在目录 -e和**!-e**，用来判断时都存在文件或目录 -x和**!-x**，用来判断文件是否可执行 栗子： if ($http_user_agent ~ MSIE) { rewrite ^(.*)$ /msie/$1 break; } if ($http_cookie ~* \"id=([^;])(?:;|$)\") { set $id $1; } if ($http_method = POST) { return 405; } if (!-f $request_filename) { break; proxy_pass http://zhang; } if ($invalid_referer) { return 403; } ","date":"2017-09-01","objectID":"/nginx/:9:2","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"Nginx全局变量 常用作if判断的全局变量： 变量 | 描述 | 备注 | - | - $args | 等于请求行中的参数 | 同$query_string $body_bytes_sent | 响应是发送的body字节数 | xxx $content_length | Request Header中的Content-Length字段 | 内容长度 $content_type | Request Header中的Content-Type字段 | 内容类型 $document_root | 当前根路径 | xxx $host | 请求主机头字段，否则为服务器名称 | xxx $hostname | 主机名 | xxx $http_user_agent | 客户端agent信息 | xxx $http_cookie | 客户端cookie信息 | xxx $is_args | 如果有$args参数，这个变量等于\"?\"，否则等于空 | xxx $limit_rate | 限制连接数度 | xxx $remote_addr | 客户端IP地址 | xxx $remote_port | 客户端端口 | xxx $remote_user | 经过Auth Basic Module验证的用户名 | 要先开启Nginx认证 $request | 用户请求信息 | xxx $request_method | 客户端请求方法 | 通常为POST或GET $request_body | 记录POST过来的数据信息 | xxx $request_filename | 当前请求的文件路径 | 由root或alias指令与URI请求生成 $request_completion | 如果请求结束，设置为OK。否则为空 | xxx $scheme | HTTP方法 | 如http, https $server_protocol | 请求使用的协议 | 通常为HTTP/1.0或HTTP/1.1 $server_addr | 服务器地址 | 在完成一次系统调用后可以确定这个值 $server_name | 服务器名称 | xxx $server_port | 请求到达服务器的端口号 | xxx $status | 请求的响应状态码 | 如200 $request_uri | 包含请求参数的原始URI，不包含主机名 | 如\"/foo/bar.php?arg=abc\" $uri | 不带请求参数的当前URI，不包含主机名 | 如\"/foo/bar.html\" 栗子： http://localhost:88/test1/test2/test.php $hsot: localhost $server_port: 88 $request_uri: http://localhost:88/test1/test2/test.php $document_uri: /test1/test2/test.php $document_root: /var/www/test $request_filename: /var/www/test/test1/test2/test.php ","date":"2017-09-01","objectID":"/nginx/:9:3","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"rewrite实例 http { log_format main xxxx; rewrite_log on; server { root /var/www/zhang; location / { error_log logs/rewrite.log notice; rewrite '^/images/([a-z]{2})/([a-z0-9]{5})/(.*)\\.(png|jpg|gif)'/data?file=$3.$4; set $image_file $3; set $image_type $4; } location /data { access_log logs/images.log main; root /data/images; type_file /$arg_file /images404.html; } location = /image404.html { return 404 \"Image Not Found\\n\"; } } } ","date":"2017-09-01","objectID":"/nginx/:9:4","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"访问控制 ","date":"2017-09-01","objectID":"/nginx/:10:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"添加用户密码验证 参考: https://docs.nginx.com/nginx/admin-guide/security-controls/configuring-http-basic-authentication/ 有时需要为我们的网站设置访问账号和密码权限。 注意，此密码需要使用加密软件生成，直接写入密码的明文无效。 具体为这两个参数： auth_basic 默认值： auth_basic off; 使用位置：http, server, location, limit_except auth_basic_user_file 使用位置： http, server, location, limit_except 栗子： cd /etc/nginx/conf.d vim test.conf location / { auth_basic \"nginx auth test\"; auth_basic_user_file /etc/nginx/.auth; } 配置用户密码 #Verify that apache2-utils (Debian, Ubuntu) or httpd-tools (RHEL/CentOS/Oracle Linux) is installed. yum install -y httpd-tools #htpasswd file username htpasswd .auth user1 New password: Re-type new password: Adding password for user user1 #查看加密密码 cat .auth user1:$apr1$NIOeayen$hTAvJ5ZTwUHE6Hm1MiF920 \r\r","date":"2017-09-01","objectID":"/nginx/:10:1","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"限制IP访问 allow deny server { ... allow IP1 allow IP2; deny all; location / { allow IP 1; deny all; } } 注意： deny一定要加一个IP，否则会直接跳转403，不在往下执行。如果403默认页是在同一域名下，会造成死循环访问 对于allow的IP短，从允许访问的IP段位从小到大排列，如127.0.0.0/24， 10.10.0.0/16 以deny all结尾，表示除了上面允许的，其它都禁止 \r","date":"2017-09-01","objectID":"/nginx/:10:2","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"语法检查 在启动或重启Nginx服务前检查语法非常重要，可以防止因配置错误导致网站重启或重载配置对用户的影响。 每次更改Nginx配置文件后都需要重新加载，将配置信息加载到内存中。这样设计的目的是大幅度提升Nginx的访问性。 nginx -t nginx -s reload Nginx优化 ","date":"2017-09-01","objectID":"/nginx/:11:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"常用优化 \r","date":"2017-09-01","objectID":"/nginx/:12:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"隐藏Nginx版本号 一般来说，软件漏洞都和版本有关。因此要尽量隐藏对访问用户显示各类敏感信息。 vim /etc/nginc/nginx.conf #nginx版本号默认是开启的 #位置：http, server, location http { server_tokens off|on; } ","date":"2017-09-01","objectID":"/nginx/:12:1","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"更改Nginx服务默认用户 修改配置文件 vim /etc/nginx/nginx.conf user nginx; 如果是编译安装，直接在编译的时候指定用户和组 ./configure --user=nginx --group=nginx ","date":"2017-09-01","objectID":"/nginx/:12:2","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"优化Nginx进程对应的配置 vim /etc/nginx/nginx.conf worker_process n; #建议n为CPU核数 #高并发场合可考虑为核数*2 #查看CPU核数 cat /proc/cpuinfo | grep processor | wc -l lscpu top命令，按1显示所有CPU核数 ","date":"2017-09-01","objectID":"/nginx/:12:3","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"优化绑定不同的Nginx进程到不同的CPU上 默认情况下，Nginx的多个进程有可能跑在某一个CPU或CPU的某一核上，导致Nginx进程使用硬件资源不均。 所以，要尽可能地分配不同的Nginx进程给不同的CPU处理，达到充分有效利用硬件的多CPU多核资源的目的。 4核CPU配置举例： vim /etc/nginx/nginx.conf worker_processes 4; #CPU亲和力参数 worker_cpu_affinity 0001 0010 0100 1000; ","date":"2017-09-01","objectID":"/nginx/:12:4","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"Nginx事件处理模型优化 Nginx的连接处理机制在不同的操作系统会采用不同的I/O模型，在Linux下，Nginx使用epoll的I/O多路复用模型，在FreeBSD中使用kqueue的I/O多路复用模型，在solaris中使用/dev/poll方式的I/O多路复用模型，在Windows中使用的是icop。 配置： #对于linux内核，推荐使用epoll工作模式 #Linux下默认epoll vim /etc/nginx/nginx.conf events { use epoll; } ","date":"2017-09-01","objectID":"/nginx/:12:5","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"Nginx单个进程允许的客户端最大连接数 请根据服务器性能和程序的内存使用量来合理制定最大连接数。 这个连接数包括了所有连接，如代理服务器连接、客户端的连接、实际的并发连接。 Nginx总并发连接数=worker*worker_connections vim /etc/nginx/nginx.conf events { worker_connections 10240; } 仅仅修改了nginx最大连接数可能还不行，由于Linux系统有ulimit限制，所以可能还要做额外操作。 如：nginx: [warn] 10240 worker_connections exceed open file resource limit: 1024。 配置： ulimit -a ulimit -n 10240 注意，使用ulimit命令修改的值并不是永久生效的。 ","date":"2017-09-01","objectID":"/nginx/:12:6","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"Nginx worker进程最大打开文件数 可能也要注意ulimit系统限制！ vim /etc/nginx/nginx.conf events { worker_rlimit_nofile 65535; } \r","date":"2017-09-01","objectID":"/nginx/:12:7","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"开启高效文件传输 sendfile sendfile()是作用于两个文件描述符之间的数据拷贝，这个拷贝是在内核之中的，被称为零拷贝。sendfile（）比read和write函数要高效很多，因为write和read函数要把数据拷贝到应用层再进行操作。 #位置：http, server, location, if in location sendfile on; tcp_nopush 激活或禁用Linux上的TCP_CORK socket选项，仅当开启sendfile生效。允许把 http response和文件的开始部分放在一个文件里发布，其积极作用是减少网络报文段的数量。 位置： http, server, location tcp_nopush on; ","date":"2017-09-01","objectID":"/nginx/:12:8","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"Nginx连接参数，连接超时时间 keep-alive可以使客户端到服务器端已经建立的连接一致工作不退出，当服务器有持续请求时，keep-alive会使用已经建立的连接提供服务，从而避免服务器重新建立新连接请求处理。 连接超时的作用： 将无用的连接设置为尽快超时，可保护系统资源（CPU、内存、磁盘） 连接很多时，及时断掉那些已经建立好但又长时间不做事的连接，以减少其占用的服务器资源。因为服务器维护连接也是消耗资源的 黑客和恶意用户攻击网站，也会不断地和服务器建立多个连接，消耗连接数但啥也不干，大量消耗服务器的资源，此时就应该及时断掉这些恶意占用资源的连接 LNMP环境中，如果用户请求了动态服务，则Nginx就会建立连接，请求FastCGI服务以及后端的MySQL服务，此时这个Nginx连接就要设置一个超时时间，在用户容忍的时间内返回数据，或者再多等一会后端服务返回数据，具体策略根据具体业务进行具体分析 后端的FastCGI服务及MySQL服务也有对连接的超时控制 位置： http, server, location keepalive_timeout 60; 默认情况下当数据发送时，内核并不会马上发送，可能会等待更多的字节组成一个数据包，这样可以提高I/O性能。 但是，在每次只发送很少字节的业务场景中，不使用tcp_nodelay功能，等待时间会比较长。 位置： http, server, location tcp_nodelay on; 读取客户端请求头数据的超时时间，如果超过这个时间，客户端还没有发送完整的header数据，服务器端将返回“Request time out（408）”错误。 位置： http, server client_header_timeout 20; 读取客户端请求主体的超时时间，如果在这个超时时间内，客户端没有发送任何数据，Nginx将返回“Request time out（408）”错误。 位置： http, server, location client_body_timeout 60; 指定响应客户端的超时时间，为握手后的一个超时。如果超过这个时间，客户端没有任何活动，Nginx将会关闭连接。 位置： http, server, location send_timeout 60; ","date":"2017-09-01","objectID":"/nginx/:12:9","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"上传文件大小限制(动态应用) 设置为0，表示禁止检查客户端请求主体的大小。 位置： http, server, location client_max_body_size 20m; ","date":"2017-09-01","objectID":"/nginx/:12:10","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"gzip压缩 Nginx gzip压缩模块提供了压缩文件内容的功能，用户请求的内容在发送到用户客户端之前，Nginx服务器会根据一些具体的策略实施压缩，以节约网络出口带宽，同时加快数据传输效率，提升用户体验。 压缩对象： 纯文本内容压缩比很高，如 html, js, css, xml等 被压缩的纯文本文件必须要大于1KB，由于压缩算法的特殊原因，极小的文件压缩后可能反而变大 图片、媒体等文件尽量不要压缩，因为这些文件大都经过压缩，再压缩很可能不会减小很多，或有可能增大，同时还要消耗系统资源 配置： #压缩功能 gzip on; #允许压缩的页面最小字节数 gzip_min_length 1K; #申请4个单位为16K的内存作为压缩结果流缓存 gzip_buffers 4 16K; #http协议版本 gzip_http_version 1.1; #指定压缩比，1压缩比最小，处理速度最快；9压缩比最大，传输速度最快，处理最慢 gzip_comp_level 5; #指定压缩类型，对应文件类型参考mime.types gzip_types text/html text/css; #vary header支持 gzip_vary on; 在response header中查看效果： Content-Encofing: gzip ","date":"2017-09-01","objectID":"/nginx/:12:11","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"expires缓存 Nginx expires的功能就是为用户访问的网站内容设定一个过期时间。 当用户第一次访问这些内容时，会把这些内容储存在用户浏览器本地，这样用户第二次及以后继续访问该网站时，浏览器会检查加载已经缓存在用户浏览器本地的内容，而不用去服务器下载，直到缓存的内容过期或被清除为止。 缓存也要根据业务！当网站数据更新时，用户端看到的可能还是旧的已经缓存的内容。 配置： 根据文件扩展名进行判断 location ~ .*\\.(gif|png|jpg|swf)$ { expires 10d; } location ~ .*\\.(css|js)$ { expires 20d; } 根据目录进行判断 location ~ ^/(images|static|media)/ { expires 50d; } 在response header中查看： Expires: 缓存过期时间 Cache-Control： 缓存总时间 \r","date":"2017-09-01","objectID":"/nginx/:12:12","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"FastCGI相关参数 FastCGI参数是配合Nginx向后请求PHP动态引擎服务的相关参数，这里指的是Nginx中的配置参数。 Module ngx_http_fastcgi_module： https://nginx.org/en/docs/http/ngx_http_fastcgi_module.html #给FastCGI服务器设置地址 fastcgi_pass #设置一个将在 $fastcgi_scripts_name 变量结尾的URI之后添加的文件名 fastcgi_index #设置一个应该传递给FastCGI服务器的参数，当且仅当fastcgi_param在当前级别上没有定义指令时，这些指令将从上一级继承 fastcgi_param #指定在哪种情况下将请求传递给下一个服务器； fastcgi_next_upsteam #表示Nginx服务器和后端FastCGI服务器连接的超时时间，默认值为60秒，这个参数通常不要超过75秒 fastcgi_connect_timeout #设置Nginx允许FastCGI服务器端返回数据的超时时间，即在规定时间之内后端服务器必须传完所有的数据。否则，Nginx将断开这个连接 fastcgi_send_timeout #设置Nginx从FastCGI服务器端读取响应信息的超时时间，表示连接建立成功后，Nginx等待后端服务器的响应时间，是Nginx已经进入后端的排队之中等候处理的时间 fastcgi_read_timeout #这是Nginx FastCGI的缓冲区大小参数，设定用来读取从FastCGI服务器端收到的第一部分响应信息的缓冲区大小，这里的第一部分通常会包含一个小的响应头部 fastcgi_buffer_size #设定用来读取从FastCGI服务器端收到的响应信息的缓冲区大小和缓冲区数量 fastcgi_buffers #用于设置系统很忙时可以使用的proxy_buffers大小，官方推荐大小为proxy_buffers * 2 proxy_busy_buffers_size #用于设置系统很忙时可以使用的fastcgi_buffers大小，官方推荐为 fastcgi_buffers * 2 fastcgi_busy_buffers_size #FastCGI临时文件大小 fastcgi_temp_file_write_size #表示开启FastCGI缓存并为其指定一个名称 fastcgi_cache cachename_nginx #fastcgi_cache缓存目录 fastcgi_cache_path #用来指定应答代码的缓存时间 fastcgi_cache_valid #设置请求几次之后响应将被缓存 fastcgi_cache_min_uses #定义在哪些情况下使用过期缓存 fastcgi_cache_use_stale #定义fastcgi_cache的key fastcgi_cache_key ","date":"2017-09-01","objectID":"/nginx/:13:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"日志与安全 现在Nginx 日志已经自动轮询了，所以感觉没有必要自己切割日志！ ","date":"2017-09-01","objectID":"/nginx/:14:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"不记录不需要的日志 日志写入太频繁会消耗大量的磁盘I/O，降低服务性能。 location ~ .*\\.(js|png|css|gif|jpg) { access_log off; } ","date":"2017-09-01","objectID":"/nginx/:14:1","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"日志权限 因为nginx master process的UID是root，所以可以修改日志权限。 不需要在日志目录上给Nginx用户读或写许可，很多人没注意这个问题，把权限直接给了Nginx用户，这就存在安全隐患。 chown -R root:root /path/log/nginx chmod -R 700 /path/log/nginx ","date":"2017-09-01","objectID":"/nginx/:14:2","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"站点目录及URL访问控制 ","date":"2017-09-01","objectID":"/nginx/:15:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"根据扩展名限制程序或文件访问 利用Nginx配置禁止访问上传资源目录下的PHP、Shell、Perl、Python程序文件，这样用户即使上传了木马文件也没法执行，从而加强了网站的安全。 对这些的限制必须放在Nginx处理.php, .py, .sh等文件的前面！ #禁止解析指定目录下的程序 location ~ ^/images/.*\\.(php|py|sh|pl)$ { deny all; } location ~ ^/static/.*\\.(py|php|pl|sh) { deny all; } #禁止访问某些文件 location ~* \\.(txt|doc)$ { root /var/www/file; deny all; } ","date":"2017-09-01","objectID":"/nginx/:15:1","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"禁止访问指定目录 location ~ ^/test/ { deny all; } #禁止访问多个目录 location ~ ^/(test|zhang) { deny all; } #返回状态码 location ~ ^/haha/ { return 403 \"Hahaha\"; } \r","date":"2017-09-01","objectID":"/nginx/:15:2","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"禁止非法域名解析访问网站 防止用户恶意域名解析。 cd /etc/nginx/conf.d vim default.conf #返回HTTP状态码 server { listen 80 default_server; server_name _; return 403; } #重定向 server { listen 80 default_server; server_name _; rewrite ^(.*) https://www.baidu.com permanent; } 利用default_server，将网站所有请求定向到维护页面。 server { listen 80 default_server; server_name _; root /var/www; location / { rewrite ^(.*) /maintance.html break; } } cd /var/www vim maintance.html \u003chtml\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003cstyle type=\"text/css\"\u003e h1{text-align: center; color: red;} \u003c/style\u003e \u003c/head\u003e \u003cbr\u003e \u003cbr\u003e \u003cbody\u003e \u003ch1\u003e网站维护中！\u003c/h1\u003e \u003c/body\u003e \u003c/html\u003e ","date":"2017-09-01","objectID":"/nginx/:16:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"图片及目录防盗链 ","date":"2017-09-01","objectID":"/nginx/:17:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"什么是资源盗链 简单地说，就是某些不法网站未经许可，通过在其自身网站程序里非法调用其他网站的资源，然后在自己的网站上显示这些调用的资源，达到填充自身网站的效果。 这一举动不仅浪费了调用资源网站的网络流量，还造成其他网站的带宽及服务压力吃紧。 问题： 某公司CDN源站流量没有变化，但CDN加速那边流量超了很多。这么大异常流量，全都是钱呀！ ","date":"2017-09-01","objectID":"/nginx/:17:1","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"常见防盗链解决方案 根据HTTP referer 实现防盗链 在HTTP 协议中，有一个表头字段叫 referer，使用URL格式来表示是哪里的链接用了当前网页的资源。 通过referer可以检测访问的来源网页，如果是资源文件，可以跟踪到显示它的网页地址，一旦检测出来不是本站，马上进行阻止。 HTTP referer 是header的一部分，当浏览器向web服务器发送请求时，一般会带上referer，告诉服务器我是从哪个页面过来的，服务器借此获得一些信息用于处理。 根据cookie防盗链 通过加密技术变换访问路径实现防盗链 ","date":"2017-09-01","objectID":"/nginx/:17:2","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"Nginx实现防盗链 利用referer，针对指定扩展名进行rewrite或其他操作。 请根据实际情况进行域名防盗链！ location ~* \\.(jpg|png|gif|wav|mp3|zip|rar)$ { valid_referers none blocked *.zhang.com; if ($invalid_regerer) { rewrite https://www.baidu.com; } } 或者在产品设计上解决防盗链，如为资源加上水印等措施。 \r","date":"2017-09-01","objectID":"/nginx/:17:3","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"错误页面优雅展示 我们可以将404、403等错误信息重定向到其他指定的页面，提升网站的用户访问体验！ location / { xxxx; error_page 403 /403.html; error_page 404 /404.jpg; error_page 500 503 504 /50x.html; location = /50x.html { root /var/www/50x.html; } } ","date":"2017-09-01","objectID":"/nginx/:18:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"目录及文件权限优化 为了保证网站安全，所有站点的目录和用户组都为root，所有目录权限是755，所有文件权限是644。 虽然这样的全线可以防止黑客上传修改站点的文件，但这样合法的用户便也没有了上传权限。 比较好的方法是将用户上传文件的服务器与读取服务器进行分离，这样就可以进行安全授权。不同的服务所在的目录的权限依据业务功能而不同。 严格控制Nginx目录的访问才能降低网站被入侵的风险！ \r","date":"2017-09-01","objectID":"/nginx/:19:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"反爬虫优化 ","date":"2017-09-01","objectID":"/nginx/:20:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"robots.txt机器人协议 robots协议(维基百科)，也称为机器人协议，全称是网络爬虫排除标准（Robots Exclusion Protocol）。网站通过Robots协议告诉搜索引擎那些页面可以抓取，那些页面不能抓取。 robots.txt协议并不是一个规范，而只是约定俗成的，所以并不能保证网站的隐私。 User-Agent: * Allow: /zhang Disallow: / ","date":"2017-09-01","objectID":"/nginx/:20:1","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"Nginx反爬虫配置 if ($http_user_agent ~* LWP::Simple|BBBike|wget) { return 403; } if （$http_user_agent ~* (Firefox|MSIE) { rewrite ^（.*） http://www.baidu.com: } ","date":"2017-09-01","objectID":"/nginx/:20:2","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"限制HTTP请求方法 if ( $request_method !~ ^(GET|POST|HEAD)$ ) { return 501; } \r","date":"2017-09-01","objectID":"/nginx/:21:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"CDN CDN的全称是 Content Delivery Network，中文意思是内容分发网络。 我们可以利用CDN做网站内容加速。 简单地讲，通过现有的Internet中增加一层新的网络架构，将网站的内容发布到最接近用户的Cache服务器内，通过智能DNS负载均衡技术，判断用户的来源，让用户就近使用与服务器相同线路的带宽访问Cache服务器，取得所需的内容。 例如，北京电信用户访问北京电信Cache服务器上的内容，四川网通用户访问成都网通Cache服务器上的内容。这样可以有效减少数据在网络上传输的时间，提高访问速度。 CDN是一套全国或全球的风不是缓存集群，其实质是通过职能DNS判断用户的来源地域及上网线路，为用户选择一个最接近用户地域，以及和用户上网线路相同的服务器节点。因为低于近，线路相同，所以可以大幅度提升用户浏览网站的体验。 CDN的价值： 提升用户体验 阻挡大部分流量攻击 CDN的特点： 通过服务器内存缓存网站数据，提高了企业站点（尤其是含有大量图片、视频等的站点）的访问速度，并大大提高企业站点的稳定性； 用户根据智能DNS技术自动选择最适合的Cache服务器，降低不同运营商之间互联瓶颈造成的影响，实现了跨运营商的网络加速，保证不同网络中的用户都能得到良好的访问速度； 加快了访问速度，减少了原站点的带宽； 用户访问时从服务器的内存中读取数据，分担了网络流量，同时减轻了原站点负载压力； 使用CDN可以分担源站的网络流量，同时减轻源站的负载压力，并降低黑客入侵及各种DDOS攻击对网站的影响，保证网站有较好的服务质量； ","date":"2017-09-01","objectID":"/nginx/:22:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"使用CDN的要求 首先要说的是，不是所有的网站都可以一上来就能用CDN的。要加速的业务数据应该存在独立的域名。如 pub.zhang21.com，业务内容图片、附件、JS、CSS等静态元素，这样的静态网站域名才能使用CDN。 将域名做CNAME(别名) 将如上的pub.zhang21.com配置成CDN的域名。 \r","date":"2017-09-01","objectID":"/nginx/:22:1","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"程序架构优化 解耦 是开发人员中流行的一个名词，简单地说就是把一堆程序代码按照业务用途分开，然后提供服务。 例如，注册登录、上传、下载、浏览、商品页信息等都应该是独立的程序服务，只不过在客户端看来是一个整体而已。 分离的最佳方式是分别使用独立的服务器，可以选择改动程序或者在负载均衡器上配置（如Nginx），过滤请求，然后抛给后面对应的服务器。 根据扩展名分发，请求图片就抛给图片服务器； 根据URL路径转发，请求下载就交给下载服务器； 请求动态PHP处理的就交给动态处理器； 不符合以上要求的就交给默认服务器； \r","date":"2017-09-01","objectID":"/nginx/:23:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"使用no-root用户启动Nginx 默认情况下，Nginx的Master进程使用的是root用户，worker进程使用的是Nginx指定的普通用户。 使用root用户跑Nginx的Master进程有两个最大问题： 管理权限必须是root，这就使得最小化分配权限原则遇到困难 使用root跑Nginx服务，一旦网站出现漏洞，用户就可以很容易地获取服务器的root权限 \r","date":"2017-09-01","objectID":"/nginx/:24:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"控制Nginx并发连接数 ngx_http_limit_conn_module这个模块用于限制每个定义的Key值的连接数，特别是单IP的连接数。 不是所有的连接数都会被计数，一个符合要求的连接是整个请求头已经被读取的连接。 用法： #位置： http limit_conn_zone key zone=name:size; #位置： http, server, location limit_conn zone number; 栗子： http { limit_conn_zone $binary_remote_addr zone=addr:10m; xxx; } server { xxx; location /download/ { limit_conn addr 3; #限制单IP并发连接为3 } } \r","date":"2017-09-01","objectID":"/nginx/:25:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"控制客户端请求Nginx的速率 ngx_http_limit_req_module被用来限制每个IP访问没法key的请求速率。 用法： #位置： http limit_req_zone key zone=name:size rate=rate; #位置： http, server, location limit_req zone=name; 栗子： http { limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; server { location /search/ { limit_req zone=one burst=5; } } } upstream模块 ","date":"2017-09-01","objectID":"/nginx/:26:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"反向代理与负载均衡 严格地说，Nginx仅仅是作为Nginx Proxy反向代理使用的，因为这个反向代理功能表现的效果是负载均衡集群的效果，所以本文称之为Nginx负载均衡。 普通的负载均衡软件，如LVS，其实现的功能只是对请求数据包的转发、传递，从负载均衡下的节点服务器来看，接收到的请求还是来自访问负载均衡器的客户端的真实用户 反向代理服务器在接收访问用户请求后，会代理用户 重新发起请求代理下的节点服务器，最后把数据返回给客户端用户。在节点服务器看来，访问的节点服务器的客户端用户就是反向代理服务器，而非真实的网站访问用户 即，LVS等负载均衡是转发用户请求的数据包，而Nginx反向代理是接收用户请求后重新发起请求后端节点 这里我去看了一下Nginx的access.log，客户端的访问日志全在代理节点上（Nginx-upstream），而后端节点的access.log的来源是前端代理节点的IP ","date":"2017-09-01","objectID":"/nginx/:27:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"Nginx负载均衡的组件 实现Nginx负载均衡的组件主要有两个: proyx upstream Nginx_http模块 | 模块说明 | - ngx_http_proxy_module | proxy代理模块，用于把请求后抛给服务器节点或upstream服务器池 ngx_http_upstream_module | 负载均衡模块，可以实现网站的负载均衡功能即节点的健康检查 ","date":"2017-09-01","objectID":"/nginx/:28:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"nginx upstream模块 upstream模块介绍 Module ngx_http_upstream_module: https://nginx.org/en/docs/http/ngx_http_upstream_module.html upstream主要是用于七层上的负载均衡和转发。 Syntax： upstream name { ... } Default: — Context: http Nginx的负载均衡功能依赖于ngx_http_upstream_module模。所支持的代理方式包括： proxy_pass fastcgi_pass memcached_pass uwsgi_pass scgi_pass upstream模块允许Nginx定义一组或多组节点服务器组，使用时可通过proxy_pass代理方式把网站的请求发送到事先定义好的对应upstream组的名字上。 \rupstream模块内容放置于http{}内: upstream upstream_name { server address [ parameters ] } ####栗子 http { upstream zhang { server 192.168.1.22:8080 weight=5; server www.zhang.cn weigh=5 max_conns=102400; server 192.168.33 max_fails=2 fail_timeout=20s; server backup.zhang.cn backup; } } server { location / { proxy_pass http://zhang; } } ####reslove http { resolver 10.0.0.1; upstream u { zone ...; ... server example.com resolve; } } address可以是主机名、域名、ip或Unix Socket，也可以指定端口号 域名时需要解析的哦 parameters代表可选参数, 有如下： backup，表示当前server是备用服务器，只有其它非backup后端服务器都挂掉了或很忙才会分配请求给它 max_conns，限制同时连接到代理服务器的最大数量。默认值为0，表示没有限制。 weight，表示当前server负载权重，权重越大几率愈高 max_fails和fail_timeout一般会关联使用，如果某台server在fail_timeout时间内出现了max_fails次连接失败，那么Nginx会认为其已经挂掉，从而在 fail_timeout 时间内不再去请求它，fail_timeout默认是 10s，max_fails默认是1，即默认情况只要是发生错误就认为服务器挂了，如果将max_fails设置为0，则表示取消这项检查 down，标志服务器永远不可用，可配合ip_hash使用 resolve，监视与服务器域名相对应的ip地址的变化，并自动地修改上游配置，而不用重启Nginx route，设置服务器路由名称 service slow_start，设置服务器将其weight从零恢复到正常值的时间 drain，使服务器进入drain模式，在此模式下，只有绑定到服务器的请求才会被代理 upstream模块参数 | 说明 | - weight | 服务器权重 max_fails | Nginx尝试连接后端主机失败的次数，这个值是配合proxy_next_upstream、fastcgi_next_upstream和memcached_next_upstream这三个参数来使用的。当Nginx接收后端服务器返回这三个参数定义的状态码时，会将这个请求转发给正常工作的的后端服务器。如404、503、503、max_files=1 fail_timeout | max_fails和fail_timeout一般会关联使用，如果某台server在fail_timeout时间内出现了max_fails次连接失败，那么Nginx会认为其已经挂掉，从而在fail_timeout时间内不再去请求它，fail_timeout默认是10s，max_fails默认是1，即默认情况只要是发生错误就认为服务器挂了，如果将max_fails设置为0，则表示取消这项检查 backup | 表示当前server是备用服务器，只有其它非backup后端服务器都挂掉了或很忙才会分配请求给它 down | 标志服务器永远不可用，可配合ip_hash使用 \r如果是两台Web服务器做高可用，可能就需要Keepalived配合。那使用backup参数通过负载均衡功能就可以实现Web服务器集群了。 \rupstream模块调度算法 调度算法一般分为： 静态调度算法: 即负载均衡器根据自身设置的规则进行分配，不需要考虑后端节点服务器的情况 轮询 权重 ip_hash 动态调度算法: 即负载均衡器会根据后端节点的当前状态来决定是否分发请求，如连接数少或响应时间短的优先获得请求 fair least_conn url_hash 一致性hash 轮询(rr) 默认调度算法。 按照客户端请求顺序把请求逐一分配到不同的后端节点服务器，相当于LVS中的rr算法。如果后端服务器宕机，宕机的服务器会被自动从节点服务器池中剔除，以使客户端的用户访问不受影响，新的请求分配给正常的服务器。 权重轮询(wrr) 权重越大，被转发的请求也就越多。可以根据服务器的配置和性能指定权重大小，有效解决新旧服务器性能不均带来的请求分配问题。 upstream weight { server 191.168.1.11 weight=1; server 192.168.1.22 weight=2; } ip_hash 每个请求按客户端IP的hash结果分配，当新的请求到达时，先将其客户端ip通过哈希算法得出一个值，在随后的客户端请求中，客户IP的哈希值只要相同，就会被分配到同一台服务器。 该调度算法可以解决动态网页的session共享问题，但有时会导致请求分配不均，因为国内大多数都是NAT上网模式，多个客户端对应一个外部IP，所以这些客户端都会被分配到同一个节点服务器，从而导致请求分配不均。 ip_hash中，后端服务器在负载均衡调度中的状态不能有 weight和backup，有也不会生效 upstream iphash { ip_hash; server 192.168.1.11; server 192.168.1.22:8080; } fair 根据后端节点服务器的响应时间来分配请求，响应时间短的优先分配。这是更加智能的调度算法。 Nginx本身不支持这种算法，需要upstream_fair模块: https://github.com/gnosek/nginx-upstream-fair upstream fair { server 192.168.1.11; server 192.168.1.22; fair; } least_conn 根据后端节点的连接数来决定分配情况，哪个机器少就分发给它。 url_hash 根据访问URL的hash结果来分配请求的，让每个URL定向到同一个后端服务器，后端服务器为缓存服务器时效果显著。 Nginx本身不支持url_hash，需要hash。 upstream urlhash { server hahaha1:5678; server hahaha2:5678; hash $request_uri; hash_method md5; #同样不能使用 weight、backup } 一致性hash 一致性hash算法一般用于代理后端业务为缓存服务器（如Memcached）的场景，通过将用户请求的URI或者指定字符串进行计算，然后调度到后端的服务器上，此后任何用户查找同一个URI货值指定字符串都会被调度到这一台服务器上，因此后端的每个节点缓存的内容都是不同的。 upstream { consistent_hash $request_uri; server xxx; server xxx; } ","date":"2017-09-01","objectID":"/nginx/:28:1","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"nginx proxy模块 \rproxy_pass介绍 Syntax: proxy_pass URL; Default: — Context: location, if in location, limit_except \rproxy_pass指令属于ngx_http_proxy_module模块，此模块可以将请求转发到另一台服务器，在实际的反向代理工作中，会通过location功能匹配指定的URI，然后把接收到服务匹配URI的请求通过proyx_pass抛给定义好的upstream节点池。 location /download/ { proxy_pass http://download/vedio/; } #这是前端代理节点的设置 #交给后端upstream为download的节点 location /name/ { rewrite /name/([^/]+) /users?name=$1 break; proyx_pass http://127.0.0.1; } ","date":"2017-09-01","objectID":"/nginx/:28:2","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"http_proyx模块参数 ngx_http_proxy_module: https://nginx.org/en/docs/http/ngx_http_proxy_module.html Nginx的代理功能是通过http_proxy模块来实现的。 proxy模块 | 说明 | - proxy_next_upstream | 什么情况下将请求传递到下一个upstream proxy_limite_rate | 限制从后端服务器读取响应的速率 proyx_set_header | 设置http请求header传给后端服务器节点，如：可实现让代理后端的服务器节点获取访问客户端的这是ip client_body_buffer_size | 客户端请求主体缓冲区大小 proxy_connect_timeout | 代理与后端节点服务器连接的超时时间 proxy_send_timeout | 后端节点数据回传的超时时间 proxy_read_timeout | 设置Nginx从代理的后端服务器获取信息的时间，表示连接成功建立后，Nginx等待后端服务器的响应时间 proxy_buffer_size | 设置缓冲区大小 proxy_buffers | 设置缓冲区的数量和大小 proyx_busy_buffers_size | 用于设置系统很忙时可以使用的proxy_buffers大小，推荐为proxy_buffers*2 proxy_temp_file_write_size | 指定proxy缓存临时文件的大小 ","date":"2017-09-01","objectID":"/nginx/:28:3","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"Nginx负载均衡配置 ","date":"2017-09-01","objectID":"/nginx/:29:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"配置后端节点 vi /etc/nginx/nginx.conf server { listen 80; root /path/xxx; location / { xxxx; } } ","date":"2017-09-01","objectID":"/nginx/:29:1","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"配置反向代理节点 upstream test { server test1 weight=5; server test2 weight=5; server 192.168.1.33; } vi /etc/nginx/nginx.conf server { listen 8888; server_name www.test.com www.xx.com; location / { proxy_read_timeout 10s; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_404; proyx_pass http://test;#把用户的请求反向代理定义的upstream服务器池 #proyx_set_header Host $host;在代理后端服务器发送的http请求头中加入host字段信息 #proxy_set_header X-Real-IP $remote_addr;后端节点服务器日志获取客户端真实ip，否则全都是代理节点的ip #proyx_connect_timeout 30s; #proxy_buffers 4m; #xxx } xxxxx } ","date":"2017-09-01","objectID":"/nginx/:29:2","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"与反向代理配置相关的参数 除了具有多虚拟主机代理以及节点服务器记录真实用户ip的功能外，Nginx还提供了相当多的作为反向代理和后端节点服务器对话的相关控制参数。 由于参数众多，建议把这些参数都写到另外一个配置文件里，然后用 include 方式包含到虚拟主机配置文件里。其他Nginx参数也同样可以使用此方法。 vim /etc/nginx/proxy.conf proxy_set_header Host $host; proxy_set_header $remote_addr; proxy_connect_timeout 60s; proxy_read_timeout 20s; proxy_send_timeout 20s; proxy_buffer_size 64k; proxy_buffers 4 64k; proxy_busy_buffers_size 128k; proxy_temp_file_write_size 2m; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_404 vim /etc/nginx/conf.d/test.conf server { listen 80; server_name www.test.com www.xxx.com; location / { include /etc/nginx/proxy.conf; } } proxy_next_upstream参数补充 当Nginx接收后端服务器发返回的proxy_next_upstream参数定义的状态码时，会将这个请求转发给正常工作的后端服务器，如500、502、503，此参数可以提升用户访问体验。 proyx_next_upstream error timeout invalid_header http_500 http_503 http_502 http_504; \r","date":"2017-09-01","objectID":"/nginx/:29:3","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"根据URL中的目录地址实现代理转发 通过Nginx实现动静分离，即通过Nginx反向代理配置规则实现让动态资源和静态资源及其他业务分别由不同的服务器解析，已解决网站性能、安全、用户体验等重要问题。 ","date":"2017-09-01","objectID":"/nginx/:30:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"动静态分离 配置upstream.conf upstream static { server 192.168.1.11; #或server static.com----hosts:static.com 192.168.1.11 } upstream upload { server 192.168.1.22; } upstream default { server 192.168.1.33; } #在http中加入,注意位置 http { include upstream.conf; } \r配置virtual.conf #方案1：利用location实现 location /static/ { proyx_pass http://static; include proyx.conf; } location /upload/ { proxy_pass http://upload; include proxy.conf; } location / { proxy_pass http://default; include proxy.conf; } ======================================== #方案2：利用if语句实现 if ($request_uri ~* \"^/static/(.*)$\") { proxy_pass http://static/$1; } if ($request_uri ~* \"^/upload/(.*)$\") { proxy_pass http://upload/$1; } location / { proxy_pass http://default; include proyx.conf; } ","date":"2017-09-01","objectID":"/nginx/:30:1","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"URL目录地址转发的应用场景 根据HTTP的URL进行转发的应用情况，被称为 第7层（应用层）的负载均衡；而LVS的负载均衡一般用于TCP等的转发，因此被称为第四层（传输层）的负载均衡 。 有时因为需求，需要在代理服务器上通过配置规则，使得匹配不同规则的请求会交给不同的服务器池处理。 ","date":"2017-09-01","objectID":"/nginx/:30:2","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"根据客户端的设备(user_agent)转发 为了让不同客户端设备用户有更好的访问体验，需要在后端架设不同服务器来满足不同的客户端访问。如PC端和移动端，移动端又有安卓、苹果、Pad等。 常规4层负载均衡解决方案架构 在常规4层负载均衡架构下，可以使用不同的域名来实现这个需求。 如，分配移动端访问 wap.xxx.com，PC端访问www.xxx.com。 通过不同域名来引导用户到指定后端服务器，但是这样就分别得记住不同的域名。 第7层负载均衡解决方案 在7层负载均衡架构下，对外只需要用一个域名，如www.xxx.com，然后通过获取用户请求中的设备信息$http_user_agent，根据此信息转给后端合适的服务器处理。 \r根据$user_agent转发 location / { if ($http_user_agent ~* \"android\") { proxy_pass http://android; } if ($http_user_agent ~* \"iphone\") { proxy_pass http://iphone; } proxy_pass http://default; include proyx.conf; 根据文件扩展名实现代理转发 location ~* .*\\.(gif|jpg|png|css|js)$ { proyx_pass http://static; include proxy.conf; } #if if ($request_uri ~* \".*\\.php$\") { proxy_pass http://php; } if ($request_uri ~* \".*\\.(jpg|png|css|js)$\") { proxy_pass http://static; } \r在开发无法通过程序实现动静分离的时候，运维可以根据资源实体进行动静分离，根据不同实现策略制定后端服务器不同的组。在前端代理服务器上通过路径、扩展名等进行规则匹配，从而实现请求的动态分离。 \r","date":"2017-09-01","objectID":"/nginx/:30:3","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["linux"],"content":"Nginx负载均衡检测节点状态 淘宝技术团队开发了一个Tengine（Nginx分支）模块nginx_upstream_check_module: https://github.com/yaoweibin/nginx_upstream_check_module，用于提供主动式后端服务器健康检查。 通过它检测后端realserver的健康状态，如果后端节点不可用，则所有的请求就不会转发到该节点上。 Nginx需要通过打补丁的方式将该模块添加进去。 wget https://codeload.github.com/yaoweibin/nginx_upstream_check_module/zip/master unzip master cd nginx_upstream_check_module-master #解压后的文件夹 cd nginx源码安装包（我是 /usr/local/nginx-1.12.1） patch -p1 \u003c ../nginx_upstream_check_module-master/check_1.12.1+.patch #选择对应的Nginx版本号，我的是1.12.1 #打补丁 #编译，注意以前的编译参数 ./configure --prefix=/usr/local/nginx \\ --user=nginx --group=nginx \\ --with-http_ssl_module \\ --with-http_realip_module \\ --with-http_addition_module \\ --with-http_gzip_static_module \\ --with-http_stub_status_module \\ --with-http_sub_module \\ --with-pcre \\ --add-module=../nginx_upstream_check_module-master make #给已经安装的Nginx系统打补丁不用执行make install #make是重新生成Nginx二进制启动命令 #备份 mv /usr/local/nginx/sbin/nginx{,.bak} #经打过补丁的Nginx二进制程序复制到/usr/local/nginx/sbin/ 下 cp /usr/local/nginx-1.12.1/objs/nginx /usr/local/nginx/sbin/ nginx -t 配置nginx_upstream_check 配置upstream.conf upstream zhang { server 192.168.1.7:5678 weight=1; server 192.168.0.99:5678 weight=1; check interval=3000 rise=2 fall=5 timeout=1000 type=http; #每个3秒对负载均衡中所有节点检测一次，请求2次正常标记realserver状态为up； #如果检测5次都失败，则标记realserver状态为down，超时时间为1秒； #检查的协议为HTTP； } 配置/status： location /status { check_status; access_log off; allow 192.168.1.0/24; deny all; } \r \rstream模块 Module ngx_stream_core_module: http://nginx.org/en/docs/stream/ngx_stream_core_module.html nginx从1.9.0开始，新增加了一个stream模块，用来实现四层协议(tcp/udp)的转发、代理和负载均衡。 这个模块不是默认构建的，需要使用--with-stream参数。 yum install -y nginx-mod-stream 这个实现四层反向代理和转发的功能真的是很强大，只需一台反向代理服务器，转发给所有后端机器。 栗子： vim /etc/nginx/nginx.conf stream{ include /etc/nginx/stream.d/*.conf } ########################## cd /etc/nginx/stream.d #转发Elasticsearch vim elastic.conf upstream elastic-cluster { server ip1:9200; server ip2:9200; xxx; } server { listen 9200; proxy_pass elastic-cluster; } #dns vim dns.conf upsetrem dns-cluster { server ip:5353; server dns.example.com:53; xxx } #tcp server { listen port; proxy_pass dns-cluster; } #udp server { listen 53 udp; proxy_pass dns-cluster; } #ipv6 server { listen [::1]:53; proxy_pass unix:/xxx/xx.socket } #MySQL vim mysql.conf upstream mysql-cluster { server ip:3306; server ip2:3306; xxx; } server { listen 3306; proxy_pass mysql-cluster; } #SSH转发 upstream ssh { server ip:22; } server { listen port; proxy_pass ssh; } \r\r \r错误信息 Nginx错误日志的详细说明。 错误信息 描述 (13: Permission denied) while reading upstream xxx (98: Address already in use) while connecting to upstream xxx (99: Cannot assign requested address) while connecting to upstream xxx (104: Connection reset by peer) while reading response header from upstream upstream-fastcgi超时时间request_terminate_timeout过小 (104: Connection reset by peer) 1: 服务器的并发连接数超过其承载量，服务器会将其中一些连接Down掉; 2: 客户关掉了浏览器，而服务器还在给客户端发送数据; 3: 浏览器端按了Stop (104: Connection reset by peer) while connecting to upstream upstream发送了RST，将连接重置 send() failed (111: Connection refused) xxx (111: Connection refued) while connecting to upstream 用户在连接时，若遇到后端upstream挂掉或不通，会收到该错误 (111: Connection refused) while reading response header from upstream 用户在连接成功后读取数据时，若遇到后端upstream挂掉或者不通，会收到此错误 (111: Connection refused) while sending request to upstream Nginx和upstream连接成功后发送数据时，若遇到后端upstream挂掉或不通，会收到该错误 (110: Connection timed out) while connecting to upstream Nginx连接upstream时超时 (110: Connection rimed out) while reading upstream Nginx读取来自upstream的响应时超时 (110: Connection timed out) while reading response header from upstream Nginx读取来自upstream的响应头时超时 (110: Connection timed out) while reading upstream Nginx读取来自upstream的响应时超时 upstream prematurely closed connection 请求URI的时候出现异常，是由于upstream还未返回应答给用户时，用户断掉连接造成。对系统没有影响。 upstream sent invalid header while reading response header from upstream upstream发送的响应头无效 upstream sent no valid HTTP/1.0 header while reading response header from upstream upstream发送的响应头无效 client intended to send too large body 用于设置允许接受的客户","date":"2017-09-01","objectID":"/nginx/:31:0","tags":["nginx","web"],"title":"Nginx","uri":"/nginx/"},{"categories":["诗歌"],"content":"《I Like For You To Be Still》 出自聂努达诗集：《二十首情诗和一首绝望的歌》。 \rI like for you to be still It is as though you are absent And you hear me from far away And my voice does not touch you It seems as though your eyes had flown away And it seems that a kiss had sealed your mouth As all things are filled with my soul You emerge from the things Filled with my soul You are like my soul A butterfly of dream And you are like the word: Melancholy I like for you to be still And you seem far away It sounds as though you are lamenting A butterfly cooing like a dove And you hear me from far away And my voice does not reach you Let me come to be still in your silence And let me talk to you with your silence That is bright as a lamp Simple, as a ring You are like the night With its stillness and constellations Your silence is that of a star As remote and candid I like for you to be still It is as though you are absent Distant and full of sorrow So you would’ve died One word then, One smile is enough And I’m happy; Happy that it’s not true ","date":"2017-09-01","objectID":"/i-like-for-you-to-be-still/:0:0","tags":["诗歌","聂努达"],"title":"I Like For You To Be Still","uri":"/i-like-for-you-to-be-still/"},{"categories":null,"content":"title: SonarQube date: 2019-02-22 15:28:44 categories: infrastructure tags: SonarQube Static Analysis Code Quality 参考: GitHub: https://github.com/SonarSource/sonarqube Website: https://www.sonarqube.org/ Docs: https://docs.sonarqube.org 环境: RHEL7x86_64 SonarQube v7.6 \r\r \r\r介绍 SonarQube 是一个开源的代码质量管理系统。支持超过25中编程语言，不过有些是商业插件。 SonarQube 是一种自动代码审查(code review)工具，用于检测代码中的错误(bugs)，漏洞(vulnerabilities)和代码异味(code smell)。它可以与您现有的工作流程集成，以便在项目分支和拉取请求之间进行连续的代码检查。 \r\r \r\r架构与集成 Architecture and Integration \r","date":"0001-01-01","objectID":"/sonarqube/:0:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"概述 SonarQube平台由4个组件组成: SonarQube Server启动三个主进程: Web Server，供开发人员，管理人员浏览质量快照并配置SonarQube实例 Search Server，基于ElasticSearch从UI返回搜索 Compute Engine Server，负责处理代码分析和上报并将其保存到SonarQube数据库中 SonarQube Database用于存储 SonarQube实例的配置(安全，插件…的设置) 项目，视图…的质量快照 Server上安装了多个插件，可能包括Language，SCM，Intergration，Authentication，Governance… 在CI/CD Server上运行一个或多个 SonarScanner 来分析项目 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:1:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"集成 Integration 以下模式显示了SonarQube如何与其它ALM工具进行集成，以及在哪里使用SonarQube的各种组件。 开发者在他们的IDE中集成SonarLint运行本地分析 开发者推送他们的代码到代码库 CI Server触发自动构建，以及执行运行SonarQube分析所需的SonarScanner 分析报告将发送到SonarQube Server进行处理 SonarQube Server处理分析报告并将结果存储在SonarQuebe数据库中，并在UI中显示结果 开发者通过SonarQube UI审核，评论，挑战他们的Issues以管理和减少他们的技术债务 管理者从分析中接收报告，运维使用API自动配置并从SonarQube中提取数据，使用JMX监控SonarQube Server \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:2:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"关于机器和位置 About Machines and Locations SonarQube平台不能够有多个SonarQube Server和SonarQube Database 为获得最佳性能，每个组件(Server, Database, Scanner)应该安装在单独的机器上，并且此机器应该是专用的 SonarScanner通过添加机器进行扩展 所有机器必须时钟同步 SonarQube Server和SonarQube Database必须位于同一网络下 SonarScanner不需要与SonarQube Server位于同一网络下 SonarScanner与SonarQube Database之间没有通信 \r\r \r\r要求 Requirements \r","date":"0001-01-01","objectID":"/sonarqube/:3:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"先决条件 Prerequisites and Overview 运行SonarQube的唯一先决条件是安装Java(Oracle JRE 8/OpenJDK 8)。 \r","date":"0001-01-01","objectID":"/sonarqube/:4:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"硬件要求 2Cores+ 2GB RAM+ 建议使用高性能I/O的磁盘 \r\r","date":"0001-01-01","objectID":"/sonarqube/:4:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"支持的平台 Java Oracle JRE 8 OpenJDK 8 Database PostgreSQL v9.3-v9.6, v10. UTF-8 charset SQL Server v2014, v2016. Oracle v11, v12, vXE. UTF8-family charset, thin mode MySQL v5.6, v5.7. UTF8 charset, InnoDB storage, mysql-connector-java Web Browser IE 11 Edge Latest FireFox Latest Chrome Safari \r\r","date":"0001-01-01","objectID":"/sonarqube/:4:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"平台说明 \rLinux 如果在Linux上运行，请确保: vm.max_map_count 大于或等于 262144 fs.file-max 大于或等于 65535 运行SonarQube的用户可以打开至少65535个文件描述符 运行SonarQube的用户可以打开至少2048个线程 用以下命令查看和配置它们: sysctl vm.max_map_count sysctl fs.file-max ulimit -n ulimit -u # 配置，但只是临时生效 # root sysctl -w vm.max_map_count=262144 sysctl -w fs.file-max=65536 ulimit -n 65536 ulimit -u 2048 # 永久生效 # /etc/sysctl.d/99-sonarqube.conf 或 /etc/sysctl.conf # user: sonarqube sonarqube - nofile 65536 sonarqube - nproc 2048 如果使用systemd来启动SonarQube，你必须在[Service]的单元文件中指定这些限制: [Service] ... LimitNOFILE=65536 LimitNPROC=2048 \r\rseccomp filter 默认情况下，ElasticSearch使用seccomp filter。在大多数发行版中，此功能在内核中激活。但在RHL6等发行版上，此功能已停用。如果你的发行版中没有此功能，请无法升级到激活了seccomp filter功能的版本，则必须通过更新 $SONARQUBEHOME/conf/sonar.properties_中的sonar.search.javaAdditionalOpts配置: sonar.search.javaAdditionalOpts=-Dbootstrap.system_call_filter=false # 检查 grep SECCOMP /boot/config-$(uname -r) # 如果内核有它，你将看到 CONFIG_HAVE_ARCH_SECCOMP_FILTER=y CONFIG_SECCOMP_FILTER=y CONFIG_SECCOMP=y \r\r \r\r配置和升级 Setup and Upgrade \r","date":"0001-01-01","objectID":"/sonarqube/:4:3","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"快速入门 Get Started in Two Minutes Guide 从ZIP文件安装 使用Docker ","date":"0001-01-01","objectID":"/sonarqube/:5:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"zip文件安装 现在 SonarQube CE 解压 运行 访问 # 具体位置取决于你的安装位置 /opt/sonarqube/bin/[OS]/sonar.sh console # localhost:9000（admin/admin） \r\r","date":"0001-01-01","objectID":"/sonarqube/:5:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"Docker安装 在Docker Hub上下载对应CE的镜像，上面有安装和配置的详细信息。 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:5:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"安装Server 支持多个数据库引擎，请务必遵守各个数据库引擎的要求。 创建一个空的schema和一个sonarqube用户。授予此用户create, update, delete此schema对象的权限。 CREATESCHEMA`sonar`DEFAULTCHARACTERSETutf8;CREATEUSER'sonarqube'@'localhost'IDENTIFIEDBY'sonarqube-PW123';GRANTALLONsonar.*TO'sonarqube'@'localhost'; \r","date":"0001-01-01","objectID":"/sonarqube/:6:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"安装数据库 \rSQL Server 跳过，有需要的请看: https://docs.sonarqube.org/latest/setup/install-server/ \r\rOracle 跳过！ \r\rPostgreSQL 如果你想使用custom schema而不是默认的public schema，则必须设置PostgreSQL的search_path属性: ALTERUSERmySonarUserSETsearch_pathtomySonarQubeSchema \r\rMySQL 注意: Data Center Edition(Enterprise)不支持MySQL! Data Center Edition: Designed for High Availability 可在MySQL中使用两种众所周知的数据库引擎: MyISAM和InnoDB。MyISAM是最老的，并且正在逐渐被InnoDB替代。随着质量控制项目数量的增加，InnoDB显然更快，并且使用SonarQube可以更好地扩展。 如果你是SonarQube的早期使用者，你可能有一系列仍在使用MyISAM引擎的表。你应该将所有表的引擎更改为InnoDB。 一旦所有SonarQube表都使用InnoDB引擎，首先要做的是使用innodb_buffer_pool_size参数为MySQL实例分配最大的RAM，并为query_cache_size参数提供至少15Mb。 阅读这篇文档InnoDB Performance Optimization来优化InnoDB。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:6:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"安装Web Server 首先，检查安装要求； 下载和解压压缩的发行版(不要解压到以数字开头的目录)； 下面变量SONARQUBE-HOME指的是解压的路径。 \r设置数据库访问 编辑$SONARQUBE-HOME/conf/sonar.properties来配置数据库设置。模板可用于每个受支持的数据库。 # Example for MySQL sonar.jdbc.username=sonarqube sonar.jdbc.password=sonarqube-PW123 sonar.jdbc.url=jdbc:mysql://localhost:3306/sonar?useUnicode=true\u0026characterEncoding=utf8\u0026rewriteBatchedStatements=true\u0026useConfigs=maxPerformance\u0026useSSL=false \r添加JDBC驱动 已提供受支持数据库(Oracle除外)的驱动程序。不要更换提供的驱动程序，它们是唯一受支持的。 对于Oracle，将JDBC驱动复制到$SONARQUBE-HOME/extensions/jdbc-driver/oracle。 \r\r配置ElasticSearch存储路径 默认情况下，ES数据存储在$SONARQUBE-HOME/data中，但不建议用于生产环境。相反，你应该将数据存储在其它位置，最好是在具有高速I/O的专用卷。除了保持可接受的性能之外，还可简化SonarQube的升级。 编辑$SONARQUBE-HOME/conf/sonar.properties来配置以下设置: # 请记得添加读写权限 sonar.path.data=/var/sonarqube/data sonar.path.temp=/var/sonarqube/temp \r\r启动Web Server 可在$SONARQUBE-HOME/conf/sonar.properties配置监听地址和端口等。 sonar.web.host=192.0.0.1 sonar.web.port=80 sonar.web.context=/sonarqube # 启动 bin/sonar.sh start # 默认admin/admin \r\r调整Web服务器 默认情况下，SonarQube配置为在任何具有简单Java JRE的计算机上运行。 为了更好地性能，生产环境实例要做的第一件事是使用Java JDK并通过在sonar.web.javaOpts=-server中设置以下行来激活服务器模式。 sonar.web.javaOpts=-server 要修改SonarQube使用的Java JVM只需编辑$SONARQUBE-HOME/conf/wrapper.conf并更新以下行: wrapper.java.command=/path/to/my/jdk/bin/java \r\rFAQ docs: https://docs.sonarqube.org/latest/setup/install-server/ \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:6:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"配置和操作Server Configure \u0026 Operate the Server \r","date":"0001-01-01","objectID":"/sonarqube/:7:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"以SystemD运行 Running SonarQube as a Service on Linux with SystemD 假设如下信息: sonarqube用户 sonarqube组 java virtual machine安装在/opt/java/ sonarqube解压在/opt/sonarqube/ 创建sonarqube用户: useradd -M -s /sbin/nologin 创建service文件/etc/systemd/system/sonarqube.service，具体详情请安装自己的实际情况进行修改。 [Unit] Description=SonarQube service After=syslog.target network.target [Service] Type=simple User=sonarqube Group=sonarqube PermissionsStartOnly=true ExecStart=/bin/nohup /opt/java/bin/java -Xms32m -Xmx32m -Djava.net.preferIPv4Stack=true -jar /opt/sonarqube/lib/sonar-application-7.6.jar StandardOutput=syslog LimitNOFILE=65536 LimitNPROC=8192 TimeoutStartSec=5 Restart=always [Install] WantedBy=multi-user.target # 启动 sudo systemctl enable sonarqube.service sudo systemctl start sonarqube.service \r\r","date":"0001-01-01","objectID":"/sonarqube/:7:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"在代理服务器后保护Server Securing the Server Behind a Proxy \rServer配置 要通过HTTPS运行SonarQube Server，必须构建标准的反向代理服务器。 必须配置反向代理，在每个HTTP Request Header中设置X_FORWARDED_PROTO: https值。如果没有此属性，SonarQube Server启动的重定向将回退到HTTP。 \r\r使用Apache代理 跳过！ \r\r使用Nginx代理 # the server directive is nginx's virtual host directive server { # port to listen on. Can also be set to an IP:PORT listen 80; # sets the domain[s] that this vhost server requests for server_name www.somecompany.com; location / { proxy_pass http://sonarhost:sonarport; } } \r\r使用IIS 跳过！ \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:7:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"安装插件 在SonarQube中安装插件有两种选择: Marketplace，从SonarQube UI自动地安装插件 手动安装， 如果SonarQube实例无法访问Internet，请使用此方法 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:8:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"安装C/C++插件 由于SonarQube的C, C++是商业版才有的功能，所以我使用的CE版就不支持对这两个语言的静态检查。 后来看到 SonarOpenCommunity: https://github.com/SonarOpenCommunity，它里面有这个插件，先感谢开发者，然后再使用。 sonar-cxx: https://github.com/SonarOpenCommunity/sonar-cxx，查看相关说明进行安装和配置。 \r","date":"0001-01-01","objectID":"/sonarqube/:9:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"安装 明白哪个插件版本与当前使用的SonarQube版本监控 下载jar插件，将其放置于$ SONARQUBE_HOME/extensions/plugins目录下 sonar-cxx-plugin-x.y.z.jar: c++ plug-in sonar-c-plugin-x.y.z.jar: c plug-in 重启SonarQube Server 在UI上的Marketplace查看更新 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:9:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"安装PS/SQL插件 由于SonarQube的PL, SQL是商业版才有的功能，所以我使用的CE版就不支持对这两个语言的静态检查。 后来看到: sonar-plsql: https://github.com/felipebz/sonar-plsql 社区开源项目，先感谢开发者，再使用。 安装方法与上面的C/C++一样，下载当前版本支持的插件到对应目录，重启SonarQube Server。 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:10:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"将Server安装为集群 docs: https://docs.sonarqube.org/latest/setup/install-cluster/ 先跳过！ \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:11:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"配置和操作集群 Configure \u0026 Operate a Cluster docs: https://docs.sonarqube.org/latest/setup/operate-cluster/ 先跳过！ \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:12:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"升级 Upgrade the Server 自动处理non-LTS版本的升级。但是，如果在迁移路径中有LTS版本，则必须先迁移LTS，然后再迁移到目标版本。 例如，v5.1 -\u003e v7.0，迁移路径为 v5.1 -\u003e 5.6.7 LTS -\u003e v6.7.x LTS -\u003e v7.0。 \r","date":"0001-01-01","objectID":"/sonarqube/:13:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"如何升级 在开始之前，请备份SnarQube Database。升级问题虽然很少见，但备份确实必须的。 \r\r \r\r分析源代码 Analyzing Source Code \r","date":"0001-01-01","objectID":"/sonarqube/:13:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"概述 一旦安装了SonarQube平台，你就可以安装分析器(analyzer)并开始创建项目了。为此，你必须安装和配置适合你需求的扫描器(scanner)。 Do you build with: Gradle - SonarScanner for Gradle MSBuild - SonarScanner for MSBuild Maven - use the SonarScanner for Maven Jenkins - SonarScanner for Jenkins Azure DevOps - SonarQube Extension for Azure DevOps Ant - SonarScanner for Ant anything else (CLI) - SonarScanner 注意，不建议在运行SonarQube Scanner Analysis的机器上运行反病毒扫描程序，这可能会导致不可预测的行为。 \r","date":"0001-01-01","objectID":"/sonarqube/:14:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"分析产生了什么 What does analysis produce? SonarQube可以对20多种不同的语言进行分析。该分析的结果是 quality measures 和 issues。但是，分析的结果也会因语言而异: 在所有语言中，blame数据将自动从支持的SCM提供程序导入(自动支持Git和SVN)。其它提供需要额外的插件 在所有语言中，执行源代码的静态分析 可对某些语言执行编译代码的静态分析 可对某些语言执行代码的动态分析 \r\r","date":"0001-01-01","objectID":"/sonarqube/:14:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"是否会分析所有文件 Will all files be analyzed? 默认情况下，在分析期间，只有语言分析器(language analyzer)可识别的文件才会加载到项目中。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:14:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"分析期间会发生什么 What happens during analysis? 在分析期间，从Server请求数据，分析提供给分析的文件，并以报告的形式将结果返回到Server，然后在Server-Side异步分析。 分析上报排队并按顺序处理，因此很可能在分析日志显示完成后的短暂时间内，更新的值在SonarQube项目中不可见。但是，你能够分辨出正在发生的事情，因为项目名称右侧的项目主页上会有一个图标。 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:14:3","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"分析参数 Analysis Parameters 可以在多个位置设置用于配置项目分析的参数。这是参数的层次结构： 在UI里定义的全局分析参数(Global)，Administration \u003e Configuration \u003e General Settings 在UI里定义的项目分析参数(Project)，Project Level \u003e Administration \u003e General Settings 在项目分析配置文件或分析器配置文件中定义的项目分析参数 分析/命令行参数，再启动分析时定义，覆盖项目分析参数 注意，只有通过UI设置的参数才会存储在数据库中。 \r","date":"0001-01-01","objectID":"/sonarqube/:15:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"强制参数 Mandatory Parameters \r Server Key Description Default sonar.host.url the server URL http://localhost:9000 Project Configuration Key Description Default sonar.projectKey The project’s unique key. Allowed characters are: letters, numbers, - , _ , . and : , with at least one non-digit. For Maven projects, this is automatically set to \u003cgroupId\u003e:\u003cartifactId\u003e sonar.sources Comma-separated paths to directories containing source files. Read from build system for Maven, Gradle, MSBuild projects \r\r","date":"0001-01-01","objectID":"/sonarqube/:15:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"可选参数 Optional Parameters Project Identity Key Description Default sonar.projectName 显示在Web实例上的项目名称 Maven项目的\u003cname\u003e，否则为项目密钥。如果DB中已有名称，则不会覆盖该名称 sonar.projectVersion 项目版本 Maven项目的\u003cversion\u003e，否则未提供 Authentication Key Description Default sonar.login 具有项目执行分析权限的SonarQube用户的登录或身份验证Token xxx sonar.password 与sonar.login用户名一起使用的密码。如果正在使用身份验Token，则应将此项留空 xxx Web Services Key Description Default sonar.ws.timeout 等待Web服务调用响应的最长时间（秒）。只有在等待服务器响应Web服务调用时在分析期间遇到超时时，才能从默认值修改此值。 60 Project Configuration Key Description Default sonar.projectDescription 项目描述。与Maven不兼容 \u003cdescription用于Maven项目 sonar.links.homepage 项目主页，与Maven不兼容 \u003curl\u003e用于Maven项目 sonar.links.ci CI，与Maven不兼容 \u003cciManagement\u003e\u003curl\u003e用于Maven项目 sonar.links.issue Issue tracker，与Maven不兼容 \u003cissueManagement\u003e\u003curl\u003e用于Maven项目 sonar.links.scm 项目原仓库，与Maven不兼容 \u003cscm\u003e\u003curl\u003e用于Maven项目 sonar.links.scm_dev 开发者连接，与Maven不兼容 \u003cscm\u003e\u003cdeveloperConnection\u003e用于Maven项目 sonar.tests 包含测试的目录的逗号分隔路径,与Maven不兼容 Maven项目的默认测试位置 sonar.sourceEncoding 源文件编码 系统编码 sonar.externalIssuesReportPaths 以逗号分隔的通用Issue上报路径列表 sonar.projectDate 为分析指定日期(yyyy-MM-dd) 当前日志 sonar.projectBaseDir 当您需要在除启动它之外的目录中进行分析时，请使用此属性 xxx sonar.working.directory 设置使用SonarScanner或SonarScanner for Ant（版本大于2.0）触发的分析的工作目录 .sonar sonar.scm.provider 此属性可用于明确告知SonarQube应使用哪个SCM插件来获取项目上的SCM数据 xxx sonar.scm.forceReloadAll 默认情况下，仅检索已更改文件的blame信息。将此属性设置为true可加载所有文件的blame信息 xxx sonar.coverage.jacoco.xmlReportPaths 导入以XML文件形式提供的JaCoCo代码覆盖率报告。此属性接受多个逗号分隔的条目。必须在分析之前生成JaCoCo XML报告 target/site/jacoco/jacoco.xml build/reports/jacoco/test/jacocoTestReport.xml Duplications Key Description Default sonar.cpd.exclusions 要从复制检测中排除的以逗号分隔的文件路径模式列表 xxx sonar.cpd.${language}.minimumtokens xxx 100 sonar.cpd.${language}.minimumLines 如上 10 Analysis Logging Key Description Default sonar.log.level 控制分析期间生成的日志级别 INFO sonar.verbose 向客户端和服务器端分析日志添加更多详细信息 false sonar.showProfiling 显示日志以查看分析仪花费时间的位置 false sonar.scanner.dumpToFile 将指向文件的完整属性列表输出到扫描程序API，作为调试分析的方法 xxx sonar.scanner.metadataFilePath 设置扫描程序写入report-task.txt文件的位置，该文件包含ceTaskId等 sonar.working.directory的值 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:15:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"后台任务 Background Tasks 一个后台任务可以是: 导入一个分析报告 the computation of a Portfolio 导入或导出一个项目 \r###　扫描程序完成分析后会发生什么 What happens after the scanner is done analyzing? 在相关后台任务完成之前，分析尚未完成。即使SonarScanner的日志显示执行完成，在完成后台任务之前，分析结果在SonarQube项目中将不可见。在SonarScanner外出分析代码后，分析结果(Sources, Issues, Metrics) - 分析报告 - 将发送到SonarQube Server，一共计算引擎进行最终处理。分析报告按顺序排队和处理。 在项目级别，当有待处理的分析报告等待消耗时，标题中的**Pending（待处理）**通知将在最近完成的分析的日期旁。 全局管理员可在 Administration \u003e Projects \u003e Background Tasks查看当前队列；项目管理员可在Administration \u003e Background Tasks查看相关任务。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:16:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"如何知道分析报告处理失败的时间 How do I know when analysis report processing fails? 后台任务通常会成功，但有时候异常会导致处理失败。例如: 处理大项目是内存不足(OOM) 现有模块或项目的密钥与报告中的密钥冲突 … 当发生这种情况时，失败的状态会反映在项目主页上，但这需要有人注意到它。你还可以选择在后台任务失败时通过电子邮件接收通知(Notifications)——无论是逐个还是全局。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:16:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"如何诊断失败的后台任务 How do I diagnose a failing background task? 对于没法分析报告，都有一个下拉菜单，允许你访问扫描程序上下文(Scanner Context)，显示代码扫描是扫描程序的配置。 如果任务处理失败，则可使用其它选项显示错误详细信息(Show Error Details)，以获取处理后台任务失败的详情。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:16:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"如何取消待处理的分析报告 How do I cancel a pending analysis report? 管理员可通过单击取消处理待处理任务(pending task)，一旦报告开始处理，取消它就为时已晚。 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:16:3","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"通用问题数据 Generic Issue Data SonarQube支持通用导入格式，用于在代码中引发external issues。它旨在允许你从你喜欢的linter导入issues，即使它不存在插件。 外部问题受到两个重要限制: 它们无法在SonarQube内管理 在SonarQube中无法管理引发这些问题的规则的激活 \r","date":"0001-01-01","objectID":"/sonarqube/:17:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"Import 分析参数sonar.externalIssueReportPaths接受以逗号分隔的报告路径列表。 每个报告必须在顶层(top-level)包含一个名为issues对象的问题对象数组。 Issue字段: engineId - string ruleId - string primaryLocation - Location object type - string. One of BUG, VULNERABILITY, CODE_SMELL severity - string. One of BLOCKER, CRITICAL, MAJOR, MINOR, INFO effortMinutes - integer, optional. Defaults to 0 secondaryLocations - array of Location objects, optional Location字段: message - string filePath - string textRange - TextRange object, optional for secondary locations only TextRange字段: startLine - integer. 1-indexed endLine - integer, optional. 1-indexed startColumn - integer, optional. 0-indexed endColumn - integer, optional. 0-indexed \r\r","date":"0001-01-01","objectID":"/sonarqube/:17:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"栗子 以下是预期格式的栗子: { \"issues\": [ { \"engineId\": \"test\", \"ruleId\": \"rule1\", \"severity\":\"BLOCKER\", \"type\":\"CODE_SMELL\", \"primaryLocation\": { \"message\": \"fully-fleshed issue\", \"filePath\": \"sources/A.java\", \"textRange\": { \"startLine\": 30, \"endLine\": 30, \"startColumn\": 9, \"endColumn\": 14 } }, \"effortMinutes\": 90, \"secondaryLocations\": [ { \"message\": \"cross-file 2ndary location\", \"filePath\": \"sources/B.java\", \"textRange\": { \"startLine\": 10, \"endLine\": 10, \"startColumn\": 6, \"endColumn\": 38 } } ] }, { \"engineId\": \"test\", \"ruleId\": \"rule2\", \"severity\": \"INFO\", \"type\": \"BUG\", \"primaryLocation\": { \"message\": \"minimal issue raised at file level\", \"filePath\": \"sources/Measure.java\" } } ]} \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:17:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"通用测试数据 Generic Test Data 开箱即用，SonarQube支持用于测试覆盖和测试执行导入的通用格式。如果你的语言不插件不支持你的Coverage引擎的本机输出格式，只需将它们转换为这些格式即可。 \r","date":"0001-01-01","objectID":"/sonarqube/:18:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"Generic Coverage 报告路径应该以逗号分隔的列表传递给: sonar.coverageReportPaths 支持的格式由sonar-generic-coverage.xsd进行描述: \u003cxs:schema\u003e \u003cxs:element name=\"coverage\"\u003e \u003cxs:complexType\u003e \u003cxs:sequence\u003e \u003cxs:element name=\"file\" minOccurs=\"0\" maxOccurs=\"unbounded\"\u003e \u003cxs:complexType\u003e \u003cxs:sequence\u003e \u003cxs:element name=\"lineToCover\" minOccurs=\"0\" maxOccurs=\"unbounded\"\u003e \u003cxs:complexType\u003e \u003cxs:attribute name=\"lineNumber\" type=\"xs:positiveInteger\" use=\"required\"/\u003e \u003cxs:attribute name=\"covered\" type=\"xs:boolean\" use=\"required\"/\u003e \u003cxs:attribute name=\"branchesToCover\" type=\"xs:nonNegativeInteger\"/\u003e \u003cxs:attribute name=\"coveredBranches\" type=\"xs:nonNegativeInteger\"/\u003e \u003c/xs:complexType\u003e \u003c/xs:element\u003e \u003c/xs:sequence\u003e \u003cxs:attribute name=\"path\" type=\"xs:string\" use=\"required\"/\u003e \u003c/xs:complexType\u003e \u003c/xs:element\u003e \u003c/xs:sequence\u003e \u003cxs:attribute name=\"version\" type=\"xs:positiveInteger\" use=\"required\"/\u003e \u003c/xs:complexType\u003e \u003c/xs:element\u003e \u003c/xs:schema\u003e 看起来像这样: \u003ccoverage version=\"1\"\u003e \u003cfile path=\"xources/hello/NoConditions.xoo\"\u003e \u003clineToCover lineNumber=\"6\" covered=\"true\"/\u003e \u003clineToCover lineNumber=\"7\" covered=\"false\"/\u003e \u003c/file\u003e \u003cfile path=\"xources/hello/WithConditions.xoo\"\u003e \u003clineToCover lineNumber=\"3\" covered=\"true\" branchesToCover=\"2\" coveredBranches=\"1\"/\u003e \u003c/file\u003e \u003c/coverage\u003e 根节点应该命名为coverage，其version属性应设置为1。 为每个文件插入一个可由测试覆盖的文件元素。其path属性可以是绝对的，也可是相对的。它具有以下属性: lineNumber(强制性) covered(强制性) - 布尔值，指示测试是否实际命中改行 branchesToCover(可选) - 可覆盖的分支数量 coveredBranches(可选) - 实际有测试覆盖的分支数量 \r\r","date":"0001-01-01","objectID":"/sonarqube/:18:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"Generic Execution 报告路径应以逗号分隔的列表传递给: sonar.testExecutionReportPaths 支持的格式如下: \u003ctestExecutions version=\"1\"\u003e \u003cfile path=\"testx/ClassOneTest.xoo\"\u003e \u003ctestCase name=\"test1\" duration=\"5\"/\u003e \u003ctestCase name=\"test2\" duration=\"500\"\u003e \u003cskipped message=\"short message\"\u003eother\u003c/skipped\u003e \u003c/testCase\u003e \u003ctestCase name=\"test3\" duration=\"100\"\u003e \u003cfailure message=\"short\"\u003estacktrace\u003c/failure\u003e \u003c/testCase\u003e \u003ctestCase name=\"test4\" duration=\"500\"\u003e \u003cerror message=\"short\"\u003estacktrace\u003c/error\u003e \u003c/testCase\u003e \u003c/file\u003e \u003c/testExecutions\u003e 根节点应该被命名为testExecutions，它的version属性应该被设置成1。 为每个测试文件插入一个文件元素，其path属性可以是绝对的，也可是相对于模块的根。 注意，与覆盖率报告不同，报告中的文件必须是测试文件名，而不是测试所涵盖的源代码文件。 在file元素内，通过单元测试为每个测试运行插入一个testCase。它具有以下属性/子项: testCase（强制性） name（强制性）: 测试事例的名称 duration(强制性): long value，ms为单位 failure|error|skipped(可选): 如果测试不正确，请使用消息和长描述报告原因 message(强制): 描述原因的短消息 stacktrace（可选）: 包含有关失败、错误、跳过状态的详细信息 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:18:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"PR分析 Pull Request Analysis PR分析是作为Developer Edtion的一部分提供。它允许你: 在SonarQube UI中查看你的PR分析结果并查看状态以显示存在未解决的问题 在你的SCM提供商界面中使用SonarQube issue自动装饰你的PR 从项目的branch and pull request的下拉菜单中可以在SonarQube中看到PR。启用PR装饰后，SonarQube会在PR上发布分析状态。 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:19:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"SCM集成 在代码分期期间收集SCM数据可以解锁许多SonarQube功能: 自动Issue分配 代码查看器中查看代码注释 SCM-driver的新代码检测，没有SCM数据，SonarQube使用分析日期确定新代码 SCM集成需要你的SCM提供商，默认情况下支持SVN和Git。其它提供商，请参阅Marketplace。 如果需要，你可以通过管理设置将其在全局/项目级别将其关闭。 \r","date":"0001-01-01","objectID":"/sonarqube/:20:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"Git \r\r","date":"0001-01-01","objectID":"/sonarqube/:20:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"SVN \r\r \r\rBranches 分支分析作为Developer Editon的一部分提供。分支分析允许你: 分析 long-lived branches 分析 short-lived branches 在短期分支的状态受到影响时通知外部系统 \r由于分支功能是开发版(也就是付费版)功能，因此社区版只能对每个分支创建一个项目。 例如: repo: zhang-repo branch: - master - test - zhang projects: - zhang-repo-master - zhang-repo-test - zhang-repo-zhang \r\r \r\r用户指南 User Guide \r","date":"0001-01-01","objectID":"/sonarqube/:20:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"修复漏水 Fixing the Water Leak \r","date":"0001-01-01","objectID":"/sonarqube/:21:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"什么是漏水 What is the Water Leak 想象一下，有一天你回到家发现厨房地板上有一滩水，水慢慢变大。 你想去拿拖把？还是找到漏水源头并修复它？选择很明显，你得修复它。 那么为什么与代码质量(code quality)有什么不同呢？当你使用SonarQube分析应用程序并意识到它有很多技术债务(technical debt)，这种下意识的反应通常是开始修复-这样那样，要么整理一个补救计划。这就像每天拖地一次而却忽略了漏水源头一样。 通常在这种传统方法中，在发布版本之前，定期进行代码质量(code quality)审计结果是开发人员在发布之前应该采取的行动。这种方法可能在短期内有效，特别是在强有力的管理支持下，但在中长期内始终失败，因为: 代码审查(code review)过程太迟，没有利益相关者热衷于解决问题，每个人都希望新版本发布 开发者通常会推迟不了解项目上下文的外部团队提出的建议。顺便提一下，正在审查的代码已经过时了 使用这种方法明显缺乏对代码质量的所有权。谁拥有质量审查权限？没有人 在整个应用程序投入生产之前，需要检查整个应用程序，显然不可能对所有应用程序使用相同的标准。每个项目都会进行谈判，这将耗尽整个过程的可信度 相反，为什么不将你在家中使用的相同的简单逻辑应用于管理代码质量的方式？修复泄露(leak)意味着将重点放在新代码上，即自上次发布以来添加或更改的代码。然后事情就变得很容易了: Quality Gate可以每天运行，并且可通过它。发版时没有任何意外 开发人员很难回避他们前一天介绍的问题。相反，他们通常很乐意在代码仍然新鲜时修复问题 代码质量有明确的所有权 做不做的标准在不同的应用程序中是一致的，并且在团队之间共享 成本微不足道，因为它是开发过程中的一部分 最为奖励，变化最大的代码具有最高的可维护性，并且未变更的代码具有最低的维护性，这很有意义。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:21:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"怎么做 SonarQube提供两种主要工具来帮助你找到泄漏点: 新代码指标(metrics)显示当前代码与你在其历史记录(previous_version)中选择的特定点之间的度量差异 新代码主要基于SCM blame 数据监测，从新代码期(泄漏期)的第一次分析开始，需要时使用回退机制 Quality Gates允许你设置测量代码的布尔阈值。将它们与差异指标一起使用，可确保你的代码质量随着时间的推移在正确的方向上行驶 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:21:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"项目页 Project Page 项目主页(Project Homepage)是任何项目的切入点，它显示: the releasability status of the project the current state of its quality the quality of what has been produced since the beginning of its New Code Period 项目页面回答了两个问题: can I release my project today? if not, what should I improve to make the project pass the Quality Gate? \r","date":"0001-01-01","objectID":"/sonarqube/:22:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"今天能发版吗 Can I release today? 由于 Quality Gate 是你执行质量策略的最强大的工具，因此该页面以项目的当前质量门状态开始。如果项目通过，则会显示一个简单的绿色全清除。 如果没有，可立即获得详细信息和drill-downs，以便快速识别出错的地方，每个错误条件的一个部分显示当前项目值是什么以及它应该是什么。像往常一样，你可以点击当前值来进行深入分析。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:22:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"应该优先解决什么 What should I fix first? 因为提高项目质量的最佳方法是在问题变得根深蒂固之前捕获并修复新问题，项目的第一个视图以新代码周期为中心，在项目主页右侧以黄色突出显示。项目空间页面显示关键指标的高级摘要，包括当前值和新代码周期值。 在Quality Gate信息的下方，可以获得可靠性和安全域中的旧问题和新问题的数量。然后是可维护性域。单击页面上的任何图形将转到“详细信息”页面或“问题”页面中的详细视图。 开发人员必须做的最重要的事情是确保屏幕黄色部分的新问题得到确认，审核和修复，并确保测试涵盖新代码以防止将来出现回归。无论过去引入了多少问题，或者总体上测试覆盖范围有多少，关注新增问题将确保情况不会降低您之前在生产中发布的版本。 那么，您应该先找到哪些问题：错误，漏洞或代码异味？这取决于，因为答案取决于您的问题的性质。假设你有一个重复5次的代码块问题，在这个重复的代码块中，你有3个Bug和5个安全问题。最好的方法可能是首先修复重复，然后解决新集中位置的错误和漏洞，而不是修复它们5次。 这就是为什么您需要在开始解决之前检查新问题。 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:22:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"Application Applications are available as part of the Enterprise Edition. \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:23:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"Portfolios Portfolios are available as part of the Enterprise Edition. \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:24:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"Issues 在运行分析时，每当一段代码破坏编码规则时，SonarQube就会引发一个issue。编码规则(coding rules)是通过每种语言的相关质量配置文件定义的。 每个问题有五种严重程度: BLOCKER - 很有可能影响生产中应用程序行为的错误。必须立即修复 CRITICAL - 要么是在生产环境中影响应用程序行为可能性很小的bug，要么是代表安全漏洞的问题。必须立即检查代码 MAJOR - 可能严重影响开发人员生产力的质量缺陷 MINOR - 会轻微影响开发人员生产力产生的质量缺陷 INFO - 既不是错误，也不是质量缺陷，只是一个提示 \r","date":"0001-01-01","objectID":"/sonarqube/:25:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"理解issue上下文 Understanding issue context 有时，一旦指出问题，问题就不言而喻了。例如，你的团队已约定了变量命名规则，在某个变量名出线问题时，你不需要理解大量上下文来理解该问题。但在其它情况下，上下文可能对理解为什么会出现这个问题至关重要。这就是为什么SonarQube不仅支持显示问题消息的主要问题位置，还支持次要问题位置。 但有时候，贡献位置地点并不足以理解问题。例如，当通过代码在某些路径上取消引用空指针时，您真正需要的是问题流。每个流程都是一组辅助位置，用于显示可能发生问题的代码的确切路径。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:25:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"生命周期 Lifecycle of Code Smell, Bug, and Vulnerability Issues \r状态 Status 创建之后，Issue会在生命周期中流动，可能为以下五种状态之一: 打开(Open) - 由SonarQube在新问题上设定 确认(Confirmed) - 手动确认以指示问题有效 解决(Resolved) - 手动设置以指示下一个分析应该关闭改问题 重开(Reopened) - 当一个已解决的问题实际上没有得到纠正时，SonarQube会自动设置 关闭(Closed) - 有SonarQube自动设置自动创建的问题 \r\r处理方式 Resolutions 已关闭的问题将有一下两种方式之一: 已修复(Fixed) - 当后续分析显示问题已更正或文件不再可用时自动设置 已移除(Removed) - 当相关规则不再可用时自动设置。改规则可能无法使用，因为它已从质量配置文件中删除，或者因为已卸载基础插件 Resolved issues好友两个处理方式: 误判(False Positive) - 手动设置 不会修复(Won’t Fix) - 不会修复 \r\r问题工作流程 Issue Workflow 在以下情况下，问题会自动关闭(Status: Closed): 问题以正确修复（Resolution: Fixed） 问题不再存在，因为相关编码规则已停用或不再可用(Resolution: Removed) 在以下情况下，问题会自动重新打开(Status: Reopened): 手动修改解决方式为已修复(但是不是误判)的问题，有后续分析显示仍然存在 \r\r","date":"0001-01-01","objectID":"/sonarqube/:25:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"安全热点问题的生命周期 Lifecycle of Security Hotspot Issues 安全热点问题具有专用的生命周期。它们不被视为可操作，必须由具有相关权限的用户进行审核。 创建之后，安全热点问题将流经专用的生命周期，可能是以下四种状态之一: Open - 由SonarQube在新问题上自动设置 Resolved(Won’t Fix) - 当安全审核员接受开发人员针对手动漏洞所做的修复或安全审核员清楚打开的热点或手动漏洞时，SonarQube会自动设置 To Revied - 当开发人员请求安全审核员查看他对手动漏洞所做的修复时自动设置 Reopened - 当开发人员解除打开的手动漏洞或安全审计员手动重新打开问题以便对已解决的问题运行新审计时设置 如果删除了包含安全热点的代码，则只会关闭安全热点问题。如果从项目的质量配置文件中删除了标识热点的规则，则安全热点也可能会被删除。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:25:3","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"理解哪些问题是新的 Understanding which Issues are “New” 为了确定问题的创建日期，在每次分析期间执行算法已确定问题是新的还是之前存在的。此算法依赖于报告问题的行的内容的哈希值(不包括空格)。对于多行问题，使用第一行的哈希值。对于每个文件(在检测到文件重命名后)，算法将从先前的分析中获取问题的基本列表，并尝试将这些问题与新分析报告的原始问题列表进行匹配。该算法尝试使用最强的证据进行首次匹配，然后再回到较弱的启发式算法。 如果问题是在同一规则上，具有相同的行号和相同的行哈希 - 匹配 检测到块在文件内移动，然后如果问题出在同一行(移动的)和同一条规则上- 匹配 在相同的规则上，使用相同的消息并使用相同的行哈希 - 匹配 在相同的规则上，使用相同的消息并使用相同的行号 - 匹配 在相同的规则上，使用相同的行哈希 - 匹配 是否有匹配CLOSED的问题 - 匹配和重新打开 \r\r","date":"0001-01-01","objectID":"/sonarqube/:25:4","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"了解问题回溯 Understanding Issue Backdating 一旦问题被确定为新，下一个问题便是提供它的日期。例如，如果它已经在代码中存在了很长时间，但只能在最近的分析中找到，因为新的规则被添加到配置文件中？该问题是否应该在其行的最后一次更改日期或首次提出的分析日期之间给出？那就是它应该回溯吗？ 如果最后一次更改改行的日期可用，那么在某些情况下，该问题将被回溯: 首先分析项目或分支 当配置文件中的规则为新时 当分析程序升级后 当规则是外部的 因此，回溯可能会使新提出的问题原理New Code Period。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:25:5","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"自动问题分配 Automatic Issue Assignment For Bug, Vulnerability and Code Smell For Security Hotspot User Correlation Known Limitation \r\r","date":"0001-01-01","objectID":"/sonarqube/:25:6","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"问题编辑 Issue edits SonarQube的问题工作流程可帮助你管理问题。你可对一个Issue做七件不同事情，这些行为可分为三类: Technical Review Confirm False Positive Won’t Fix Severity change Resolve Security Hotspots Detect Clear Request Review Reject Dispositioning General Comments Tag Bulk Change \r\r","date":"0001-01-01","objectID":"/sonarqube/:25:7","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"清除已解决的问题 Purging Closed Issues 默认情况下，已关闭的问题将保留30天。当然，你也可以修改它。 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:25:8","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"Rules SonarSource Rules: https://rules.sonarsource.com/ \r","date":"0001-01-01","objectID":"/sonarqube/:26:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"概述 在SonarQube中，分析程序提供在源代码上执行的规则来生成问题。有四种类型的规则: Code Smell (Maintainability domain) Bug (Reliability domain) Vulnerability (Security domain) Security Hotspot (Security domain) \r\r","date":"0001-01-01","objectID":"/sonarqube/:26:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"规则 默认情况下，点击带单栏Rules时，你将看到SonarQube实例上安装的分析程序带来的所有可用规则。你可根据以下条件缩小范围: Language Type Tag Repository Default Severity Status Available Since Template: 显示允许创建自定义规则的规则模板 Quality Profile \r\r","date":"0001-01-01","objectID":"/sonarqube/:26:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"规则细节 要查看规则的详细信息，请点击它。除了基本规则数据之外，您还可以查看其中活动的配置文件（如果有）以及已经引发了多少未解决的问题。 只有拥有正确的权限时，才能使用以下两个操作: Add/Remove Tags Extend Description \r\r","date":"0001-01-01","objectID":"/sonarqube/:26:3","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"规则模板和自定义规则 Rule Templates and Custom Rules 规则模板(Rule templates)由创建提供，允许用户在SonarQube中定义自己的规则。它位于Rules -\u003e Template。 要从模板创建自定义规则，你必须填写一下信息: Name Key (auto-suggested) Description (Markdown format is supported) Default Severity Status The parameters specified by the template \r\r","date":"0001-01-01","objectID":"/sonarqube/:26:4","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"扩展编码规则 Extending Coding Rules 可以添加自定义编码规则。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:26:5","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"规则类型和严重性 Rule Types and Severities Type: Bug Vulnerability Code Smell Security Hotspot Severity: Blocker Critical Major Minor Info \r\r","date":"0001-01-01","objectID":"/sonarqube/:26:6","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"安全相关的规则 Security-related Rules SonarQube质量类型有三种不同的规则: Reliability (bug) Vulnerability (security) Maintainability (code smell) 但另外一种方式，只有两种类型: security rule 其它 两者之间的区别并不在它们捕获的内容，而在于她们来自何处以及强加于它们的标准。 \r","date":"0001-01-01","objectID":"/sonarqube/:27:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"从安全相关的规则的期望是什么 What to expect from security-related rules 需要明确的是，SonarQube语言插件中实现的大多数规则的标准是非常严格: 没有误报。对于正常规则，你应该能够确信任何报告给你的问题确实是一个问题。 但对于与安全相关的规则，情况略有不同。例如，许多安全指南讨论了应如何处理敏感数据。但是，由于规则中不可能确定哪些数据是敏感，哪些是不敏感。因此选择变为： 保持无误判标准并且不实施与安全相关的规则，或者实施与安全的规则不同的标准。 这就是为什么与安全相关的规则很广泛。官方的想法是，该规则将标记任何可疑的内容，并将其留给安全审核人员来剔除误报并发送真正的问题进行补救。 安全热点是一种特殊类型的问题，用于识别安全审核人员应审核的敏感区域，以确定它们是否真的是漏洞。有关热点和审计过程的详细信息，请参阅安全审核和报告。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:27:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"与安全相关的规则来自何方 Where security-related rules come from 绝大多数与安全相关的规则源于既定标准: CWE(Common Weakness Enumeration)：是美国MITRE机构提出的一套语言标准，用于描述软件安全弱点的通用化描述语言。每个CWE条目都包含了CWE标识符/弱点类型名称、类型的描述、弱点的行为、弱点的利用方法、利用弱点的可能性、可能导致的后果、应对措施、代码示例、对应的CVE漏洞数量、参考信息等内容。 SANS Top 25 - CWE/SANS TOP 25 Most Dangerous Software Errors OWASP Top 10 - OWASP Top 10 Application Security Risks 要查找与任何这些标准相关的规则，你可以按标签或文本搜索规则。 \rCWE CWE标准代表Common Weakness Enumeration: Common Weakness Enumeration (CWE™) 是一个常见软件弱点的正式列表或字典，可能出现在软件的体系结构、设计代码或实现中。可能导致可利用的安全漏洞。创建CWE是为了描述软件安全漏洞的通用语言，作为针对这些弱点的软件安全工具的衡量标准；并为弱点识别、缓解和预防工作提供共同的基线标准。 CWE是弱化的描述的层次结构。层次结构中的最低级别是弱点基础(Weakness Base)，它描述了细腻度的弱点。 符合特定要求的工具可以认证为CWE兼容。这些要求是: 您必须能够使用CWE标识符搜索与CWE相关的规则。要在SonarQube平台中执行此操作，只需将CWE标识符（例如CWE-595）放在规则页面上的搜索文本输入中并运行搜索 规则必须与其相关的CWE项目准确链接。要查看SonarQube规则的CWE映射，请参阅规则说明底部的规则参见部分 您必须能够从问题中识别相关的CWE。要在SonarQube平台中执行此操作，请参阅相关规则 产品文档必须包含CWE和CWE兼容性的说明 除了通过CWE id搜索规则外，您还可以通过 cwe rule tag 进行搜索 \r\rSANS TOP 25 SANS Top 25列表是由SANS组织编制的CWE中列出的25个最危险错误的集合。当前的SANS列表分为三类： Insecure Interaction Between Components Risky Resource Management Porous Defenses 要查找与SANS Top 25相关的规则，您可以对类别或相关CWE项目执行文本搜索，或执行规则标记搜索。 \r\rOWASP Top 10 OWASP代表Open Web Application Security Project。它是: 501(c)(3) 全球非营利慈善组织，致力于提高软件的安全性。我们的使命是使软件安全可见，以便全世界的个人和组织能够就真正的软件安全风险做出明智的决策。 OWASP Top 10列出了各种各样的弱点，每个弱点都可以映射到许多单独的规则。 OWASP TOP 10在SonarQube中也对应相关的tag。 要查找与OWASP Top 10相关的规则，您可以对类别执行文本搜索，或执行规则标记搜索。 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:27:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"內建规则和标签 Built-in Rule Tags 标签(tag) 是一种对问题(issue)和规则(rule)进行分类的方法。问题会继承引发它们的规则上的标记。有些标签适用于特定语言，但是更多的标签出现在各种语言中。用户可以为规则和问题添加标签。但大多数规则都有一些开箱即用的标签。 以下是一些非全面的、包含一些內建标签: brain-overload - 一次有太多的东西要留在脑海里 bad-practice - 代码可能按设计工作，但它的设计方式被广泛认为是一个坏主意 cert - 设计CERT标准中的规则 clumsy - 用于完成可以更清晰和简洁地完成的事情的额外步骤 confusing - 将使维护者更长时间地理解，而不是代码实际所做的事情 convention - 编码约定，如格式化、命名、空格… cwe - CWE安全规则 design - 代码设计存在一些问题 lock-in - 使用特定于环境的功能 misra - MISRA标准相关的规则 owasp - 与OWASP TOP 10安全标准相关的规则 pitfall - 没有什么不对，但未来可能出现问题;已经为下一个人设置了一个陷阱，他可能会陷入其中并搞砸了代码 sans-top25 - 与SANS Top 25 Coding Errors安全相关 suspicious - 它不能保证这是一个bug，但它看起来很可疑。至少，代码应该重新检查并且可能为了清晰而重构 unpredictable - 代码可以在当前条件下正常工作，但如果条件发生变化可能会失败 unused - 未使用的代码 user-experience - 代码在技术上没有任何问题，但它可能会使您的部分或全部用户讨厌您 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:28:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"Quality Gates \r","date":"0001-01-01","objectID":"/sonarqube/:29:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"概述 质量阈(Quality Gates)是你在组织中实施质量策略的最佳方式。它可以回答一个问题: 我今天可以将项目发上线吗？ 为了回答这个问题，你可以根据测量项目的度量阈值定义一组布尔条件，例如: No new blocker issues Code coverage on new code greater than 80% … 理想状况下，所有项目都将通过同一质量阈进行验证。但这并不总是实用的。例如，你可能会发现: 技术实现因应用程序而异 您希望确保对某些应用程序有更强的要求 … 这就是为什么你可以根据需要自定义质量阈，它就在顶部的菜单栏上。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:29:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"最佳质量阈配置 Use the Best Quality Gate Configuration 质量阈默认激活并视为內建和只读的Sonar war方式，由SonarQube提供。它代表了我们对实施修复泄露。根据SonarQube的功能自动调整 有三个指标允许你强制执行给定的可靠性，安全性和可维护性的评级。不仅仅是整体而且还有新代码。建议使用这些指标，并将其作为默认质量阈的一部分，以便开发人员在项目页面上查看质量阈时更清楚的反馈。 不要忘记质量阈条件必须使用差值，检查绝对值是没有意义的(如: 代码行数大于1000)。 \r推荐的质量阈(Recommended Quality Gate) 內建的Sonar way质量阈都推荐用于大多数项目。如果专注于保持新代码清洁，而不是花费大量时间来修复旧代码。它开箱即用，已被设置为默认配置文件。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:29:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"质量阈状态 Quality Gate Status \r\r","date":"0001-01-01","objectID":"/sonarqube/:29:3","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"当质量阈失败时获得通知 Getting Notified When a Quality Gate Fails 使用通知机制，在质量阈失败时通知用户。为此，请订阅New quality gate status通知。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:29:4","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"安全 Security 任何用户(甚至是匿名用户)都可以访问质量阈。 要就行更改(create, edit, delete)，必须授予用户管理质量阈的权限。 项目管理员可选择与他们项目相关的质量阈。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:29:5","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"定义质量阈 Defining Quality Gates 要管理质量阈，请转到菜单栏的Quality Gates。 每个质量阈条件都是以下组合: 测量(measure) 比较符(comparison operator) 错误值(error value) 栗子，条件可能是: measure: Blocker issue comparison operator: \u003e error value: 0 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:29:6","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"指标 Metric Definitions 项目有如下指标: 复杂度(Complexity) 重复(Duplications) 问题(Issues) 可维护性(Maintainability) 质量阈(Quality Gates) 可靠性(Reliability) 安全性(Security) 大小(Size) 测试(Tests) \r","date":"0001-01-01","objectID":"/sonarqube/:30:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"复杂度 应用的控制流是简单还是复杂。 \r圈复杂度 Cyclomatic Complexity 可以计算出达到全面覆盖需要的最少测试用例。 它是基于通过代码的路径数计算的，每当函数的控制流分裂时，复杂度计数器就会增加1。每个函数的最小复杂度为1.此计算因语言而异，因为关键字和功能有所不同。 特定语言的详细信息: Language Notes ABAP 这些关键字将使复杂度加一: AND , CATCH , CONTINUE , DO , ELSEIF , IF , LOOP , LOOPAT , OR , PROVIDE , SELECT…ENDSELECT , TRY , WHEN , WHILE C/C++/Objective-C 复杂度加一: `function definitions, while , do while , for , throw statements, switch , case , default , \u0026\u0026 operator, COBOL 复杂度加一: ALSO , ALTER , AND , DEPENDING , END_OF_PAGE , ENTRY , EOP , EXCEPTION , EXIT , GOBACK , CONTINUE , IF , INVALID , OR , OVERFLOW , SIZE , STOP , TIMES , UNTIL , USE , VARYING , WHEN , EXEC CICS HANDLE , EXEC CICS LINK , EXEC CICS XCTL , EXEC CICS RETURN Java 复杂度加一: `if , for , while , case , catch , throw , \u0026\u0026 , JS, PHP 复杂度加一: `function, if, \u0026\u0026, PL/I 复杂度加一: `PROC , PROCEDURE , GOTO , GO TO , DO , IF , WHEN , PL/SQL 复杂度加一: create procedure, create trigger, procedure definition, basic loop statement, when clause statement, continue statement,exit statement, for loop statement, forall statement, if statement, elsif clause, raise statement, return statement, while loop statement, and expression, or expression, when clause expression VB.NET 复杂度加一: method or constructor declaration, AndAlso , Case , Continue , End , Error , Exit , If , Loop , On Error , GoTo , OrElse , Resume , Stop , Throw , Try \r\r认知复杂度 Cognitive Complexity 对应这个应用是否很难被理解，理解代码的控制流程有多难。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:30:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"重复 有: 重复的块(Duplicated blocks) 重复的行(Duplicated lines) 重读文件(Duplicated files) 密度/重复行%(Duplicated lines %) \r重复的块 重复的行的块数。 特定语言的详细信息 非Java项目: There should be at least 100 successive and duplicated tokens. Those tokens should be spread at least on: 30 lines of code for COBOL 20 lines of code for ABAP 10 lines of code for other languages Java项目: There should be at least 10 successive and duplicated statements whatever the number of tokens and lines.检测重复时忽略缩进和字符串文字的差异。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:30:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"问题 有: 新问题(New issues) 新的严重问题(New xxx issues) 所有问题(Issues) 严重问题(xxx issues) 误判问题(False positive issues) 开启问题(Open issues) 确认问题(Confirmed issues) 重开问题(Reopened issues) \r\r","date":"0001-01-01","objectID":"/sonarqube/:30:3","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"可维护性 有: 异味(Code Smells) 新异味(New Code Smells) 维护率(Maintainability Rating) 技术债务(Technical Debt) 新代码的技术债务(Technical Debt on New Code) 技术债务率(Technical Debt Ratio) 新代码的技术债务率(Technical Debt Ratio on New Code) \r维护率 使用SQALE评级。与您的技术债务比率值相关的项目评级。 默认的可维护性评级网格是: A=0-0.05 (\u003c5%) B=0.06-0.1 (6%-10%) C=0.11-0.20(11%-20%) D=0.21-0.5(21%-50%) E=0.51-1(50%-100%) \r\r技术债务 努力修复所有异味。以分钟(min)为度量单位存储在数据库中，单位值中的天假设为8小时(h)。 \r\r技术债务率 开发成本与修复成本之间的比率。技术债务公式为: Remediation cost / Development cost 开发一行代码的成本价值为0.06 day == 0.06 * 8 * 60 min \r\r","date":"0001-01-01","objectID":"/sonarqube/:30:4","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"质量阈 有: 质量阈状态(Quality Gate Status) 质量阈详情(Quality Gate Details) \r\r","date":"0001-01-01","objectID":"/sonarqube/:30:5","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"可靠性 有: Bugs New Bugs 可靠率(Reliability Rating) 可靠性的修复工作(Reliability remediation effort) 新代码可靠性的修复工作(Reliability remediation effort on new code) \r可靠率 A = 0 Bugs B = at least 1 Minor Bug C = at least 1 Major Bug D = at least 1 Critical Bug E = at least 1 Blocker Bug \r\r修复工作 努力解决所有Bugs。以分钟为单位度量值存储在数据库中。如果数值天，则假设一天为8小时。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:30:6","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"安全性 有: 漏洞(Vulnerabilities) 新漏洞(New Vulnerabilities) 安全级(Security Rating) 安全修复工作(Security remediation effort ) 新代码的安全修复工作(Security remedation effort on new code) \r安全评级 A = 0 Vulnerabilities B = at least 1 Minor Vulnerability C = at least 1 Major Vulnerability D = at least 1 Critical Vulnerability E = at least 1 Blocker Vulnerability \r\r","date":"0001-01-01","objectID":"/sonarqube/:30:7","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"大小 有: 类(Classes) 注释行(Comment lines) 注释占比(Comments %) - Comment lines / (Lines of code + Comment lines) * 100 目录(Directories) 文件(Files) 行数(Lines) 代码行数(Lines of code) 每种语言的代码行数(Lines of code per language) 函数(Functions) \r\r","date":"0001-01-01","objectID":"/sonarqube/:30:8","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"测试 有: 条件覆盖(Condition coverage) 新代码条件覆盖(Condition coverage on new code) 条件覆盖命中(Condition coverage hits) 逐行条件(Conditions by line) 逐行条件覆盖(Covered conditions by line) 覆盖(Coverage) 新代码覆盖(Coverage on new code) 行覆盖(Line coverage) 新代码行覆盖(Line coverage on new code) 行覆盖命中(Line coverage hits) 要覆盖的行(Lines to cover) 新代码要覆盖的行(Lines to cover on new code) 跳过单元测试(Skipped unit tests) 未覆盖条件(Uncovered conditions) 新代码未覆盖条件(Uncovered conditions on new code) 未覆盖行(Uncovered lines) 新代码未覆盖行(Uncovered lines on new code) 单元测试(Unit tests) 单元测试持续时间(Unit tests duration) 单元测试错误(Unit test errors) 单元测试失败(Unit test failures) 单元测试成功密度(Unit test success density %) - Test success density = (Unit tests - (Unit test errors + Unit test failures)) / Unit tests * 100 \r条件覆盖 在包含一些布尔表达式的每行代码中，条件覆盖只是回答了以下问题: 每个布尔表达式是否都被评估为 true 和 false?。这是在单元测试执行期间遵循的流控制结构中可能的条件密度。 Condition coverage = (CT + CF) / (2*B), where: CT = conditions that have been evaluated to ‘true’ at least once(已经被评估为true至少一次的条件) CF = conditions that have been evaluated to ‘false’ at least once(已经被评估为false至少一次的条件) B = 条件总数(total number of conditions) \r\r覆盖 它是行覆盖和条件覆盖的混合。它的目标是为以下问题提供更准确的答案: 单元测试覆盖了多少源代码? Coverage = (CT + CF + LC)/(2*B + EL), where: CT = 已经被评估为true至少一次的条件 CF = 已经被评估为false至少一次的条件 LC = 覆盖的行(covered lines) B = 条件总数 EL = 可执行行的总数( total number of executable lines) \r\r行覆盖 在给定的代码行上，行覆盖简单地回答了以下问题: 在执行单元测试期间是否执行了这行代码? 它是单元测试的覆盖率密度: Line coverage = LC / EL, where: LC = 覆盖的行(covered lines) EL = 可执行行的总数(total number of executable lines) \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:30:9","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"概念 Concepts \r\r","date":"0001-01-01","objectID":"/sonarqube/:31:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"架构 Architecture 概念 定义 Analyzer 用于分析源代码以计算快照的客户端程序 Database 存储配置和快照 Server 用于浏览快照数据和进行配置修改的Web界面 \r\r","date":"0001-01-01","objectID":"/sonarqube/:31:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"质量 Quality 概念 定义 Bug 表示代码中出错的问题 Code Smell 代码中与可维护性相关的问题 Cost 花费 Debt 解决问题所需的时间 Issue 代码不符合规则时，快照上会记录一个问题。有: Bugs , Code Smells and Vulnerabilities Measure 给定时间内给定文件或项目的度量值 Metric 一种测量方式。随着时间的推移，度量标准可能具有不同的值或度量 New Code Period 需要密切关注代码中引入新问题的时间段 Quality Profile 一组规则 Rule 应该遵循的编码标准或惯例 Remediation Cost 修复漏洞和可靠性问题所需的估计时间 Snapshot 在给定时间内针对给定项目的一组度量和问题 Security Hotspot 与安全相关的问题，突出显示使用安全敏感API的一段代码 Technical Debt 修复问题所需的估计时间 Vulnerability 与安全相关的问题，代表攻击者的后门 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:31:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"活动 Activity and History 项目活动页面提供项目文件分析的完整列表，以及随着时间推移看到项目措施演变的能力。 活动页面上的图标可帮助你了解几种相互选择的度量方法的演变。 \r","date":"0001-01-01","objectID":"/sonarqube/:32:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"事件 Events 有四种类型的事件: Quality Gate Profile Version Other \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:32:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"SonarLint SonarLint Smart Notifications SonarLint Smart Notifications是作为Developer Edtion的一部分来提供。 智能通知允许使用SonarLint中的连接模式的开发人员以一下情况下从SonarQube接收IDE内的通知: the Quality Gate status (failed / success) of a project /solution open in the IDE changes a SonarQube analysis raises new issues introduced by this developer in a project /solution open in the IDE SonarLint智能通知的激活和取消必须由每个开发人员直接在SonarLint(IDE端)进行单独完成。 可以在SonarQube上逐个服务器地在SonarLint端配置接收通知。 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:33:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"Security Reports \r","date":"0001-01-01","objectID":"/sonarqube/:34:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"安全报告显示了什么 What do the Security Reports show? 安全报告旨在快速为您提供有关应用程序安全性的全景图，并详细说明OWASP, SANS, CWE标准的详细信息。安全报告由分析器提供，分析器依赖于质量配置文件中激活的规则来引发安全问题。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:34:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"热点和漏洞有什么区别 What’s the difference between a Hotspot and a Vulnerability? 漏洞是代码中可以攻击的点。安全热点是安全敏感的代码段，应由具有安全审计员帽的人仔细审查。 安全热点的主要目标是帮助集中手动审查应用程序源代码的安全审核员的工作。第二个目标是教育开发人员并提高他们的安全意识。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:34:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"为什么某些热点和漏洞非常相似 Why are some Hotspot and Vulnerability rules very similar? 它们是故意重叠的。热点规则应该包括漏洞规则的所有匹配，以及污点分析引擎无法检测漏洞的情况。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:34:3","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"为什么我看不到任何热点 Why are some Hotspot and Vulnerability rules very similar? 有三个原因: 可能真的没有它们，因为代码是在没有使用任何安全敏感API的情况下编写的 热点规则可能可用，但尚未在你的质量配置文件中激活，因此自然不会引发任何问题 你正在使用的语言分析器可能还没有提供热点规则，所以它不会引发任何热点 \r\r","date":"0001-01-01","objectID":"/sonarqube/:34:4","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"为什么我看不到任何漏洞 由于一些热点原因，你可能没有看到任何漏洞的，但你可能会看到项目主页中报告了一些漏洞，而安全报告中没有漏洞。这是因为语言分析器可能尚未提供安全报告中可见问题所需的安全标准的元数据。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:34:5","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"开发者是否应该关心热点 可能并不需要。热点并不是真正可行的，它们只是标记潜在的问题，所以在代码上没有立即做任何事情。这就是为什么在引发热点问题时没有收到通知。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:34:6","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"如果热点确实标记为漏洞怎么办 如果您查看引发热点的代码并意识到确实存在问题，请单击当前状态以注册您在代码中检测到漏洞。完成后，它将转换为漏洞，最后触摸该行的开发人员将收到新问题通知。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:34:7","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"热点变为漏洞后会发生什么 一旦您检测到热点位置确实存在问题，它将被分配给相应的开发人员，他们将进行修复，然后必须通过UI请求审核。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:34:8","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"热点被标记为不会修复是什么意思 What does it mean for a Hotspot to be marked “Won’t Fix”? 不会修复标记用于表示已经审查了热点，并且目前无法利用这段代码创建攻击。 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:34:9","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"用户账户 User Account SonarQube用户可拥有自己的空间，可查看与自己相关的内容。 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:35:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"User Token 每个用户都可生成令牌，这些令牌可用于运行分析或调用Web服务，而无需用户的实际凭据。 \r\r \r\r项目管理 Project Administration \r","date":"0001-01-01","objectID":"/sonarqube/:36:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"项目存在 Project Existence 通常，项目在第一次分析时创建，不会删除(除非手动删除)。你可以管你你有权限管理的项目。 在第一次分析之前配置项目 配置还未分析的项目 修改项目权限(Private/Public) - 默认情况下，任何新创建的项目都被视为Public。这意味着每个经过认证的用户都能够Browse和See Source Code 删除项目 查找不再分析的项目 \r\r","date":"0001-01-01","objectID":"/sonarqube/:37:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"管理项目历史 Managing Project History SonarQube最强大的功能之一是它不仅向你展示了你今天的项目健康状况，还展示了它随时间的变化情况。它通过有选择地保留以前分析的数据来做到这一点。它没有保留所有以前的分析——这会使数据库膨胀。同样，对于它确实存在的分析，SonarQube不会保留所有数据。一旦项目快照(snapshot)从最后分析(Last analysis)移动到项目历史的一部分，项目级别下面的数据就会被清除——再次放置数据库膨胀。 通常这些都不是你需要考虑的事情。SonarQube只为你专门处理它们。但有时你可能需要从项目的历史记录中删除错误的快照或修改内存处理算法。 可查看数据库表大小: #sonarUSEinformation_schema;DESCRIBETABLES;SELECTTABLE_SCHEMA,TABLE_NAME,TABLE_ROWS,DATA_LENGTHFROMTABLESWHERETABLE_SCHEMA='sonar'ORDERBYDATA_LENGTHDESC; 有时你可能需要手动删除项目快照，无论是因为使用了错误的质量配置文件，还是因为分析存在问题…请注意，永远不能删除最新的快照。 对于每个快照，可以手动: Add, rename or remove a version Add, rename or remove an event Delete the snapshot \r\r","date":"0001-01-01","objectID":"/sonarqube/:38:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"缩小关注点 Narrowing the Focus 如果SonarQube的结果不相关，那么没有人会想要使用它。这就是为什么精确配置每个项目要分析的内容是非常重要的一步。 SonarQube为你提供了几种选项，可以准确配置要分析的内容。你可以: 完全忽略一些文件或目录 从问题中排除文件或目录，但分析所有其它方面 从重复性中排除文件或目录，但分析所有其它方面 从覆盖率中排除文件或目录，但分析其它所有方面 你可以在全局或项目级别配置它们。 \r","date":"0001-01-01","objectID":"/sonarqube/:39:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"忽略文件 Ignore Files 建议你从库中排除生成的代码，源代码等。有四种不同的方法可将分析范围缩小到与开发团队相关的源代码。 源目录(Source Directories) 文件后缀(File Suffixes) 选择文件(Choosing Files) 源文件排除(Source File Exclusions) 测试文件排除(Test File Exclusions) 源文件包含(Source File Inclusions) 测试文件包含(Test File Inclusions) \r\r","date":"0001-01-01","objectID":"/sonarqube/:39:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"忽略问题 Ignore Issues 可使用SonarQube忽略某些组件和某些编码规则的问题。Administration \u003e General Settings \u003e Analysis Scope \u003e Issues。 请注意，以下属性只能通过Web界面设置，因为它们是多值的。 Ignore Issues on Files Ignore Issues in Blocks Ignore Issues on Multiple Criteria Restrict Scope of Coding Rules \r\r","date":"0001-01-01","objectID":"/sonarqube/:39:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"忽略重复 Ignore Duplications 可在SonarQube中阻止检查某些文件的重复性。Administration \u003e General Settings \u003e Analysis Scope \u003e Duplications。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:39:3","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"忽略代码覆盖率 Ignore Code Coverage 可以通过单元测试防止某些文件考虑用于代码覆盖。Administration \u003e General Settings \u003e Analysis Scope \u003e Code Coverage \u003e Coverage Exclusions。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:39:4","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"模式 Patterns SonarQube中可以使用以下通配符: * - 零个或多个字符(zero or more characters) ** - 零个或多个目录(zero or more directories) ? - 单个字符(a single character) \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:39:5","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"项目设置 Project Settings \r","date":"0001-01-01","objectID":"/sonarqube/:40:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"Tags 项目标签(tags) 允许对项目进行分类和分组，以便在项目页面上更容易地选择。可以从项目主页管理项目标签。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:40:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"管理项 Administration Items: Adding a Project Analysis Report Processing Deleting a Project Setting the New Code Period Updating Project Key Default Issue Assignee Setting Quality Gate and Quality Profiles Setting Exclusions Customizing Links \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:40:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"Webhooks 网络调用(Webhooks) 在项目完成分析后通知外部服——An HTTP POST request including a JSON payload is sent to each URL。可在项目级别和全局指定URL。项目级别的配置不会取代全局的配置，两个级别的所有Webhooks都被调用。 HTTP(s) 调用: 无论后台任务的状态如何 使用POST方法将JSON文档作为负载 使用UTF-8编码的内容类型application/json \r","date":"0001-01-01","objectID":"/sonarqube/:41:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"Delivery and Payload Webhook 管理控制台显示每个Webhook的最新交付的结果和时间戳，其中有效负载可通过列表图标获得。默认保留30天的记录。URL必须在10s响应，否则传递将标记为失败。 发送带有project key的 HTTP header X-SonarQube-Project，以便快速识别所涉及的项目。 Payload是一个JSON文档，包括: 什么时候运行分析(analysedAt) 分析的项目的标识(project) 每个质量阈标准和状态(qualityGate) 每个项目的质量阈状态(qualityGate.status) 后台任务的状态和标识(status, taskId) 用于定义的属性(properties) 栗子: { \"analysedAt\": \"2016-11-18T10:46:28+0100\", \"project\": { \"key\": \"org.sonarqube:example\", \"name\": \"Example\" }, \"properties\": { }, \"qualityGate\": { \"conditions\": [ { \"errorThreshold\": \"1\", \"metric\": \"new_security_rating\", \"onLeakPeriod\": true, \"operator\": \"GREATER_THAN\", \"status\": \"OK\", \"value\": \"1\" }, { \"errorThreshold\": \"1\", \"metric\": \"new_reliability_rating\", \"onLeakPeriod\": true, \"operator\": \"GREATER_THAN\", \"status\": \"OK\", \"value\": \"1\" }, { \"errorThreshold\": \"1\", \"metric\": \"new_maintainability_rating\", \"onLeakPeriod\": true, \"operator\": \"GREATER_THAN\", \"status\": \"OK\", \"value\": \"1\" }, { \"errorThreshold\": \"80\", \"metric\": \"new_coverage\", \"onLeakPeriod\": true, \"operator\": \"LESS_THAN\", \"status\": \"NO_VALUE\" } ], \"name\": \"SonarQube way\", \"status\": \"OK\" }, \"serverUrl\": \"http://localhost:9000\", \"status\": \"SUCCESS\", \"taskId\": \"AVh21JS2JepAEhwQ-b3u\" } \r\r","date":"0001-01-01","objectID":"/sonarqube/:41:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"附加参数 Additional parameters 通过在Webhook的URL中提供user/passwd来支持基本的身份认证机制。(如: https://myLogin:myPassword@my_server/foo) 如果使用了sonar.analysis.*属性为SonarScanner提供其它属性，则这些属性将自动添加到有效负载的properties部分。 栗子: sonar-scanner -Dsonar.analysis.scmRevision=628f5175ada0d685fd7164baa7c6382c1f25cab4 -Dsonar.analysis.buildNumber=12345 \r\r \r\r实例管理 Instance Administration \r","date":"0001-01-01","objectID":"/sonarqube/:41:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"质量配置 Quality Profiles \r","date":"0001-01-01","objectID":"/sonarqube/:42:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"概述 质量配置(Quality Profiles)服务是SonarQube的核心，因为它是您通过定义规则集来定义需求的地方。。 理想情况下，对于任何给定的语言，所有项目都将使用相同的配置文件进行测量，但这并不总是实用的。 这就是为什么您可以根据需要定义尽可能多的质量配置文件，即使建议尽可能少的质量配置文件以确保公司项目的一致性。 每个语言都带有预定义的內建配置文件(通常称为 Sonar way)，因此你可以使用SonarQube分析进行快速开始。这就是为什么只要安装新的语言插件，就可以使用至少一个配置文件。 默认的Sonar way配置文件，它包含了通常适用于大多数项目的所有规则。但作为最佳实践，你应该创建一个新的配置文件(你可以通过复制Sonar way的内容来填充它)，并使用它。 因为默认的Sonar way是不可编辑的，因此你无法根据需要对其进行自定义。此外，这使你可将Sonar way视为一个基线，可在对其进行更改时跟踪自己的配置文件。此外Sonar way通常会随插件的每个新版本更新，已添加规则，有时还会调整规则严重性。任何继承自內建Sonar way的配置文件都将在事实上同时自动更新。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:42:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"我该怎么做 \r####　将质量配置管理的权限移交给其他人 Delegate the management of Quality Profiles to someone else? 默认情况下，管理员才有此权限。但你可以授予用户/组权限来编辑配置文件。例如将Java配置文件权限分配给Java开发专家，将Python配置文件权限分配给Python专家… \r\r将规则从一个配置复制到另一个配置 Copy the rules from one profile to another? 许多时候，人们希望使用基于內建的配置文件的配置文件进行工作，而无实际需要使用內建配置文件。 \r\r了解配置中有什么改变 Know what’s changed in a profile? 当SonarQube注意到使用与先前分析不同的配置文件执行分析时，会将质量配置文件事件添加到项目的事件日志中。 \r\r将配置文件从一个实例复制到另一个实例 Copy a profile from one SonarQube instance to another? 使用实例上的备份(Back UP)功能将配置文件导出到XML文件。然后在另一个实例中选择恢复(Restore)。 \r\r将一组核心规则和附加规则应用于项目 Apply a core set of rules plus additional rules to a project? 使用继承，从root继承核心规则集。然后创建一个子配置文件(Sprout)，修改从Root继承，然后添加缺少的规则。 \r\r确保我的非默认配置文件应用于项目 Make sure my non-default profile is used on a project? \r\r确保我的个人配置中包含所有相关的新规则 Make sure I’ve got all the relevant new rules in my profile? \r\r比较两个规则 Compare two profiles? \r\r确保我的配置中没有任何弃用的规则 Make sure I don’t have any deprecated rules in my profile? \r\r安全 Security 任何用户都可以访问质量配置服务，你可以给他们配置质量配置管理权限，让他们可以创建，删除质量配置。 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:42:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"安全 \r","date":"0001-01-01","objectID":"/sonarqube/:43:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"概述 SonarQube具有许多全局安全功能: 认证和授权机制 强制身份认证 委派认证 除此之外，还可在group/user级别配置: 查看一个已存在的项目 访问项目的源代码 管理一个项目 管理质量配置，质量阈，实例… \r\r","date":"0001-01-01","objectID":"/sonarqube/:43:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"认证 Authentication 第一个问题: 匿名用户是否可以浏览SonarQube实例？ 当然不行！那就需要强制用户认证。 认证机制(Authentication Mechanisms) 可通过多种方式来管理认证机制: 通过SonarQube內建的user/group数据库 通过外部程序(如LDAP) 通过HTTP headers 技术用户(Technical Users) 当你在SonarQube数据库中创建用户时，他将被视为本地用户，并且针对SonarQube自己的user/group数据库进行身份认证，而不是通过任何外部工具。 默认情况下，admin是本地账户。 同样，所有非本地(non-local)账户将仅针对外部工具进行身份认证。 管理员可以管理所有用户的Tokens——创建和删除。一旦创建，Token就是运行分析所需的唯一凭证，作为sonar.login属性的值来传递。 默认管理员(Default Admin Credentials) 当安装SonarQube时，会自动创建具有管理系统权限的默认用户: user:adminpasswd:admin \r\r","date":"0001-01-01","objectID":"/sonarqube/:43:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"重置管理员密码 Reinstating Admin Access 如果你修改了管理员密码，但又忘记了: USEsonar;updateuserssetcrypted_password='$2a$12$uCkkXmhW5ThVK8mpBvnXOOJRLd64LJeHTeCkSuB3lfaR2N0AYBaSi',salt=null,hash_method='BCRYPT'wherelogin='admin' 如果您删除了管理员并随后锁定了具有全局管理权限的其他用户: USEsonar;INSERTINTOuser_roles(user_id,role)VALUES((selectidfromuserswherelogin='mylogin'),'admin'); \r\r","date":"0001-01-01","objectID":"/sonarqube/:43:3","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"授权 Authorization 对不同组、不同用于仅限权限分配，以访问不同的资源。 user group Global Permissions Administer System Administer Quality Profiles Administer Quality Gates Execute Analysis Create Projects Create Applications Create Portfolios Project Permissions Public and Private Administer Issues Administer Security Hotspots Administer Execute Analysis Private Browse See Source Code \r\r","date":"0001-01-01","objectID":"/sonarqube/:43:4","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"默认权限的权限模板 Permission Templates for Default Permissions SonarQube附带默认权限模板，该模板在创建项目，项目组合或应用程序自动授予特定组的特定权限。管理员可以编辑此模板。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:43:5","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"加密 Encryption 加密主要用于从设置中删除明文密码。实现的解决方案是基于对称密钥算法，关键是密钥存储在磁盘上的安全文件中。此文件必须由运行SonarQube Server的系统账户拥有和读取。 该算法是AES 128位。 Generate the secret key Store the secret key on the SonarQube server Generate the encrypted values of your settings Use the encrypted values in your SonarQube server configuration 必须在SonarQube基础架构的所有部分之间共享唯一的密钥。在Administration \u003e Configuration \u003e Encryption生成密钥。 生成密钥之后，会显示如何使用此密钥。 之后便可以为你设置的值进行加密。同样在前面的加密下进行配置。 之后在SonarQube Server中使用加密后的值: # conf/sonar.properties sonar.jdbc.password={aes}CCGCFg4Xpm6r+PiJb1Swfg== # Encrypted DB password ... sonar.secretKeyPath=C:/path/to/my/secure/location/my_secret_key.txt \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:43:6","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"委托认证 Delegating Authentication docs: https://docs.sonarqube.org/latest/instance-administration/delegated-auth/ SonarQube认证: 自带用户数据库认证 外部 HTTP header LDAP … \r","date":"0001-01-01","objectID":"/sonarqube/:44:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"HTTP header认证 \r\r","date":"0001-01-01","objectID":"/sonarqube/:44:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"LDAP认证 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:44:2","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"通知 Notifications 可以通过邮件配置，向用户发送分析的信息的通知。 \r\r \r\r使用实践 注意: 由于使用的是SonarQube CE(社区版)，因此不支持在IDE中上传分析数据，也不支持多分支(branch)分析。所以需要对这些方面做一些规范。 \rSonarQube的使用主要分为两个方面: 开发者 IDE CI SonarScanner \r","date":"0001-01-01","objectID":"/sonarqube/:45:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"CI CI端 需先安装 SonarQube Scanner 应用程序，并配置相应的路径和token。 由于社区版的缘故，我只对测试分支的CI进行SonarScanner分析，并将结果上传到SonarQube Server对应项目的路径。 由于测试分支(stage)的代码都是由开发者现在本地IDE中检测过代码质量(Code Quality)之后才MR过来，所以这样更方便和实用些。 CI SonarScanner分析上传之后，SonarQube会通知项目负责人此项目代码相关情况。由项目负责人去SonarQube Web UI上再去核查相关issues，核查无误之后，才能将测试分支的代码上线。 如果项目负责人检查出相关代码的某些问题，请于相关分支开发者交流，叮嘱他们现在本地IDE自测，通过之后在MR代码。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:46:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"IDE 只需在IDE中下载SonarLint插件，并配置上运维人员提供的地址和token就可以使用了。 由于社区版的缘故，我这里让开发者自己的分支在IDE中调用远程SonarQube进行本地代码质量检查，并不需要将开发者的分支代码情况上传到SonarQube Server端。 开发者自己检查和核对自己分支的代码质量，确认之后才将自己的代码MR到dev分支。 如果项目负责人检测到某位开发者的分支代码存在问题，则这个责任由分支开发者负责和处理。 \r\r","date":"0001-01-01","objectID":"/sonarqube/:47:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"权限问题 权限有一些地方需要注意: 将项目设置为私有(默认: public) 项目对应项目组(group)，对应项目成员(user) 项目组中的CI, IDE用户具有不同的权限 … 具体配置可以在使用的时候灵活修改！ \r\r \r\rAPI 可通过SonarQube API 进行许多操作。 # 如导出python的代码规则 curl -X GET -v -u user:passwd http://localhost:9000/api/rules/search?language=python \u003e python.json \r\r \r\rScanner docs: https://docs.sonarqube.org/display/SCAN 建议将SonarQube Scanner用作使用SonarQube分析项目的默认扫描程序。 \r","date":"0001-01-01","objectID":"/sonarqube/:48:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"安装 \r","date":"0001-01-01","objectID":"/sonarqube/:49:0","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"OS 平台: Linux Mac OS Windows 下载对应平台的Sonar Scanner应用程序，将它们解压之后加入系统路径($PATH)。 \r\r\r","date":"0001-01-01","objectID":"/sonarqube/:49:1","tags":null,"title":"","uri":"/sonarqube/"},{"categories":null,"content":"IDE Sonar Scanner 支持的 IDE 有: MSBuild Maven Gradle Ant Jenkins JetBrains 在IDE中下载SonarLint插件，之后配置SonarQube Server地址和管理员给的Token便可以正常使用。 社区版的SonarQube 只能在IDE中检测，无法上传。 ","date":"0001-01-01","objectID":"/sonarqube/:49:2","tags":null,"title":"","uri":"/sonarqube/"}]